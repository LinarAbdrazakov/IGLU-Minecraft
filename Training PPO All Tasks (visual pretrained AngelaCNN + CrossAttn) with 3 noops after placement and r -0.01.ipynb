{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0c14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dim_feedforward=None, activation=nn.ELU):\n",
    "        super().__init__()\n",
    "        if dim_feedforward is None:\n",
    "            dim_feedforward = 4 * d_model\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads, dropout=0.0, batch_first=True)\n",
    "        # Implementation of feedforward model\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "        self.activation = activation()\n",
    "        \n",
    "    def forward(self, query, key, value):\n",
    "        src = query\n",
    "        src2 = self.self_attn(query=query, key=key, value=value)[0]\n",
    "        src = src + src2\n",
    "        src2 = self.linear2(self.activation(self.linear1(src2)))\n",
    "        src = src + src2\n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6104f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionNet(nn.Module):\n",
    "    def __init__(self, d_model=8, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.img_preproc = nn.Sequential(\n",
    "            nn.Linear(512, 2048),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        self.target_cross_attn_1 = TransformerEncoderLayer(d_model=d_model, num_heads=num_heads)\n",
    "        self.img_cross_attn_1 = TransformerEncoderLayer(d_model=d_model, num_heads=num_heads)\n",
    "        self.conv_1 = nn.Conv3d(d_model, 2 * d_model, kernel_size=3, stride=1)\n",
    "        self.act_1 = nn.ELU()\n",
    "        \n",
    "        self.target_cross_attn_2 = TransformerEncoderLayer(d_model=2 * d_model, num_heads=num_heads)\n",
    "        self.img_cross_attn_2 = TransformerEncoderLayer(d_model=2 * d_model, num_heads=num_heads)\n",
    "        self.conv_2 = nn.Conv3d(2 * d_model, 4 * d_model, kernel_size=3, stride=1)\n",
    "        self.act_2 = nn.ELU()\n",
    "        \n",
    "        self.target_cross_attn_3 = TransformerEncoderLayer(d_model=4 * d_model, num_heads=num_heads)\n",
    "        self.img_cross_attn_3 = TransformerEncoderLayer(d_model=4 * d_model, num_heads=num_heads)\n",
    "        self.conv_3 = nn.Conv3d(4 * d_model, 8 * d_model, kernel_size=3, stride=1)\n",
    "        self.act_3 = nn.ELU()\n",
    "        \n",
    "        self.target_cross_attn_4 = TransformerEncoderLayer(d_model=8 * d_model, num_heads=num_heads)\n",
    "        self.img_cross_attn_4 = TransformerEncoderLayer(d_model=8 * d_model, num_heads=num_heads)\n",
    "        self.conv_4 = nn.Conv3d(8 * d_model, 16 * d_model, kernel_size=3, stride=1)\n",
    "        self.act_4 = nn.ELU()\n",
    "        \n",
    "        self.max_pool = nn.MaxPool3d(kernel_size=(1, 3, 3))\n",
    "        \n",
    "        \n",
    "    def forward(self, target, img_features):\n",
    "        batch_size = target.shape[0]\n",
    "        \n",
    "        img_features = self.img_preproc(img_features)\n",
    "        \n",
    "        # layer 1\n",
    "        target = target.permute(0, 2, 3, 4, 1).reshape(batch_size, 9*11*11, 8)\n",
    "        img = img_features.reshape(batch_size, 256, 8)\n",
    "        target_1 = self.target_cross_attn_1(query=target, key=img, value=img)\n",
    "        img_1 = self.img_cross_attn_1(query=img, key=target, value=target)\n",
    "        target_1 = target_1.reshape(batch_size, 9, 11, 11, 8).permute(0, 4, 1, 2, 3)\n",
    "        target_1 = self.act_1(self.conv_1(target_1))\n",
    "        img_1 = img_1.reshape(batch_size, 2048)\n",
    "        \n",
    "        # layer 2\n",
    "        target_1 = target_1.permute(0, 2, 3, 4, 1).reshape(batch_size, 7*9*9, 16)\n",
    "        img_1 = img_1.reshape(batch_size, 128, 16)\n",
    "        target_2 = self.target_cross_attn_2(query=target_1, key=img_1, value=img_1)\n",
    "        img_2 = self.img_cross_attn_2(query=img_1, key=target_1, value=target_1)\n",
    "        target_2 = target_2.reshape(batch_size, 7, 9, 9, 16).permute(0, 4, 1, 2, 3)\n",
    "        target_2 = self.act_2(self.conv_2(target_2))\n",
    "        img_2 = img_2.reshape(batch_size, 2048)\n",
    "        \n",
    "        # layer 3\n",
    "        target_2 = target_2.permute(0, 2, 3, 4, 1).reshape(batch_size, 5*7*7, 32)\n",
    "        img_2 = img_2.reshape(batch_size, 64, 32)\n",
    "        target_3 = self.target_cross_attn_3(query=target_2, key=img_2, value=img_2)\n",
    "        img_3 = self.img_cross_attn_3(query=img_2, key=target_2, value=target_2)\n",
    "        target_3 = target_3.reshape(batch_size, 5, 7, 7, 32).permute(0, 4, 1, 2, 3)\n",
    "        target_3 = self.act_3(self.conv_3(target_3))\n",
    "        img_3 = img_3.reshape(batch_size, 2048)\n",
    "        \n",
    "        # layer 4\n",
    "        target_3 = target_3.permute(0, 2, 3, 4, 1).reshape(batch_size, 3*5*5, 64)\n",
    "        img_3 = img_3.reshape(batch_size, 32, 64)\n",
    "        target_4 = self.target_cross_attn_4(query=target_3, key=img_3, value=img_3)\n",
    "        img_4 = self.img_cross_attn_4(query=img_3, key=target_3, value=target_3)\n",
    "        target_4 = target_4.reshape(batch_size, 3, 5, 5, 64).permute(0, 4, 1, 2, 3)\n",
    "        target_4 = self.act_4(self.conv_4(target_4))\n",
    "        img_4 = img_4.reshape(batch_size, 2048)\n",
    "        \n",
    "        \n",
    "        target_4 = self.max_pool(target_4)\n",
    "        \n",
    "        features = target_4.reshape(batch_size, -1)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 8, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 128 \n",
    "        self.policy_network = FusionNet()\n",
    "        \n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        \n",
    "        features = self.policy_network(target_features, visual_features)\n",
    "        \n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "tasks = []\n",
    "for i in range(1,156):\n",
    "    if ('C'+str(i)) == 'C38': continue\n",
    "    tasks.append('C'+str(i))\n",
    "    \n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "            \n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=250)\n",
    "    env.update_taskset(TaskSet(preset=tasks))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n",
      "2021-11-14 14:38:42,674\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-11-14 14:38:42,686\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id 04314_00000 but id 907c1_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO All Tasks pretrained (visual pretrained AngelaCNN + CrossAttn) (3 noops after placement) r: -0.01 div10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/907c1_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/907c1_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211114_143843-907c1_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m 2021-11-14 14:38:46,158\tWARNING ppo.py:143 -- `train_batch_size` (5000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1666.\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m 2021-11-14 14:38:46,158\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m 2021-11-14 14:38:46,158\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m 2021-11-14 14:38:54,731\tINFO trainable.py:109 -- Trainable.setup took 11.081 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=154354)\u001b[0m 2021-11-14 14:38:54,732\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 9996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_14-45-00\n",
      "  done: false\n",
      "  episode_len_mean: 99.03030303030303\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.700000000000003\n",
      "  episode_reward_mean: -0.5804040404040409\n",
      "  episode_reward_min: -1.450000000000001\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 99\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.8841074453459847\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.004704763754277773\n",
      "          policy_loss: -0.011509279726853228\n",
      "          total_loss: 0.040411061462030835\n",
      "          vf_explained_var: -0.3121291697025299\n",
      "          vf_loss: 0.07982046209319503\n",
      "    num_agent_steps_sampled: 9996\n",
      "    num_agent_steps_trained: 9996\n",
      "    num_steps_sampled: 9996\n",
      "    num_steps_trained: 9996\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.29311663479925\n",
      "    ram_util_percent: 36.19923518164437\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048040997947451015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 54.80254200747374\n",
      "    mean_inference_ms: 8.617984758566491\n",
      "    mean_raw_obs_processing_ms: 0.6844258234493492\n",
      "  time_since_restore: 366.175776720047\n",
      "  time_this_iter_s: 366.175776720047\n",
      "  time_total_s: 366.175776720047\n",
      "  timers:\n",
      "    learn_throughput: 69.004\n",
      "    learn_time_ms: 144860.804\n",
      "    load_throughput: 90078.577\n",
      "    load_time_ms: 110.97\n",
      "    sample_throughput: 45.195\n",
      "    sample_time_ms: 221172.685\n",
      "    update_time_ms: 6.99\n",
      "  timestamp: 1636901100\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9996\n",
      "  training_iteration: 1\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         366.176</td><td style=\"text-align: right;\">9996</td><td style=\"text-align: right;\">-0.580404</td><td style=\"text-align: right;\">                 4.7</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           99.0303</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 19992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_14-49-26\n",
      "  done: false\n",
      "  episode_len_mean: 100.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.930000000000001\n",
      "  episode_reward_mean: -0.7361000000000005\n",
      "  episode_reward_min: -1.6000000000000008\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 199\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.872266720400916\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.007915726438018678\n",
      "          policy_loss: -0.01592555729767833\n",
      "          total_loss: 0.020403559366241098\n",
      "          vf_explained_var: -0.07412627339363098\n",
      "          vf_loss: 0.06426021011280589\n",
      "    num_agent_steps_sampled: 19992\n",
      "    num_agent_steps_trained: 19992\n",
      "    num_steps_sampled: 19992\n",
      "    num_steps_trained: 19992\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.08968253968254\n",
      "    ram_util_percent: 40.81851851851852\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04867785010942372\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.47225888152813\n",
      "    mean_inference_ms: 8.619138654693119\n",
      "    mean_raw_obs_processing_ms: 0.638052561546034\n",
      "  time_since_restore: 631.5633075237274\n",
      "  time_this_iter_s: 265.3875308036804\n",
      "  time_total_s: 631.5633075237274\n",
      "  timers:\n",
      "    learn_throughput: 69.022\n",
      "    learn_time_ms: 144823.626\n",
      "    load_throughput: 77629.367\n",
      "    load_time_ms: 128.766\n",
      "    sample_throughput: 58.525\n",
      "    sample_time_ms: 170799.002\n",
      "    update_time_ms: 6.011\n",
      "  timestamp: 1636901366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19992\n",
      "  training_iteration: 2\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         631.563</td><td style=\"text-align: right;\">19992</td><td style=\"text-align: right;\"> -0.7361</td><td style=\"text-align: right;\">                4.93</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">            100.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 29988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_14-53-56\n",
      "  done: false\n",
      "  episode_len_mean: 100.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.730000000000006\n",
      "  episode_reward_mean: 0.15750000000000042\n",
      "  episode_reward_min: -1.730000000000001\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 298\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.839373106528551\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.010519051259605366\n",
      "          policy_loss: -0.021232346243137478\n",
      "          total_loss: 0.18197832048749232\n",
      "          vf_explained_var: 0.0877896323800087\n",
      "          vf_loss: 0.23055249153393614\n",
      "    num_agent_steps_sampled: 29988\n",
      "    num_agent_steps_trained: 29988\n",
      "    num_steps_sampled: 29988\n",
      "    num_steps_trained: 29988\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.06217616580311\n",
      "    ram_util_percent: 40.70233160621762\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0489545428098754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.15415495292398\n",
      "    mean_inference_ms: 8.614063839239552\n",
      "    mean_raw_obs_processing_ms: 0.6406829489778322\n",
      "  time_since_restore: 901.4337737560272\n",
      "  time_this_iter_s: 269.8704662322998\n",
      "  time_total_s: 901.4337737560272\n",
      "  timers:\n",
      "    learn_throughput: 68.998\n",
      "    learn_time_ms: 144872.798\n",
      "    load_throughput: 77825.559\n",
      "    load_time_ms: 128.441\n",
      "    sample_throughput: 64.306\n",
      "    sample_time_ms: 155445.109\n",
      "    update_time_ms: 7.823\n",
      "  timestamp: 1636901636\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29988\n",
      "  training_iteration: 3\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         901.434</td><td style=\"text-align: right;\">29988</td><td style=\"text-align: right;\">  0.1575</td><td style=\"text-align: right;\">                4.73</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">            100.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 39984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_14-58-51\n",
      "  done: false\n",
      "  episode_len_mean: 97.14563106796116\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.710000000000005\n",
      "  episode_reward_mean: 0.5757281553398065\n",
      "  episode_reward_min: -1.8300000000000007\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 401\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.811861156194638\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011586275796279816\n",
      "          policy_loss: -0.02427993158284479\n",
      "          total_loss: 0.2371059584005489\n",
      "          vf_explained_var: 0.19990791380405426\n",
      "          vf_loss: 0.28834587312820886\n",
      "    num_agent_steps_sampled: 39984\n",
      "    num_agent_steps_trained: 39984\n",
      "    num_steps_sampled: 39984\n",
      "    num_steps_trained: 39984\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02238095238094\n",
      "    ram_util_percent: 41.01547619047619\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04883012843662368\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.46164447990399\n",
      "    mean_inference_ms: 8.624421217838952\n",
      "    mean_raw_obs_processing_ms: 2.0787208793923577\n",
      "  time_since_restore: 1196.4260656833649\n",
      "  time_this_iter_s: 294.99229192733765\n",
      "  time_total_s: 1196.4260656833649\n",
      "  timers:\n",
      "    learn_throughput: 68.979\n",
      "    learn_time_ms: 144914.323\n",
      "    load_throughput: 80463.214\n",
      "    load_time_ms: 124.231\n",
      "    sample_throughput: 64.893\n",
      "    sample_time_ms: 154037.368\n",
      "    update_time_ms: 8.52\n",
      "  timestamp: 1636901931\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39984\n",
      "  training_iteration: 4\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         1196.43</td><td style=\"text-align: right;\">39984</td><td style=\"text-align: right;\">0.575728</td><td style=\"text-align: right;\">                4.71</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">           97.1456</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 49980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-03-31\n",
      "  done: false\n",
      "  episode_len_mean: 97.65686274509804\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.530000000000014\n",
      "  episode_reward_mean: 1.14294117647059\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 503\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7914847830421903\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01291240033164486\n",
      "          policy_loss: -0.02431462747721463\n",
      "          total_loss: 0.38614972693065547\n",
      "          vf_explained_var: 0.2639394998550415\n",
      "          vf_loss: 0.437087961875348\n",
      "    num_agent_steps_sampled: 49980\n",
      "    num_agent_steps_trained: 49980\n",
      "    num_steps_sampled: 49980\n",
      "    num_steps_trained: 49980\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.069\n",
      "    ram_util_percent: 41.44325\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048508938984994664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.69086700701841\n",
      "    mean_inference_ms: 8.608214583256773\n",
      "    mean_raw_obs_processing_ms: 1.8056772685510314\n",
      "  time_since_restore: 1476.736932516098\n",
      "  time_this_iter_s: 280.31086683273315\n",
      "  time_total_s: 1476.736932516098\n",
      "  timers:\n",
      "    learn_throughput: 68.975\n",
      "    learn_time_ms: 144922.973\n",
      "    load_throughput: 82016.697\n",
      "    load_time_ms: 121.878\n",
      "    sample_throughput: 66.518\n",
      "    sample_time_ms: 150274.483\n",
      "    update_time_ms: 7.833\n",
      "  timestamp: 1636902211\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 49980\n",
      "  training_iteration: 5\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         1476.74</td><td style=\"text-align: right;\">49980</td><td style=\"text-align: right;\"> 1.14294</td><td style=\"text-align: right;\">                8.53</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">           97.6569</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 59976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-08-10\n",
      "  done: false\n",
      "  episode_len_mean: 99.87128712871286\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.260000000000012\n",
      "  episode_reward_mean: 1.2247524752475272\n",
      "  episode_reward_min: -1.9499999999999995\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 604\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7712131653076564\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.012632949608454996\n",
      "          policy_loss: -0.02826809365159044\n",
      "          total_loss: 0.3065449736855176\n",
      "          vf_explained_var: 0.37885403633117676\n",
      "          vf_loss: 0.36126190269541025\n",
      "    num_agent_steps_sampled: 59976\n",
      "    num_agent_steps_trained: 59976\n",
      "    num_steps_sampled: 59976\n",
      "    num_steps_trained: 59976\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.19673366834172\n",
      "    ram_util_percent: 41.28241206030152\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048629714266874194\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.12024447685897\n",
      "    mean_inference_ms: 8.599174633906923\n",
      "    mean_raw_obs_processing_ms: 1.6262490555701368\n",
      "  time_since_restore: 1755.4120795726776\n",
      "  time_this_iter_s: 278.6751470565796\n",
      "  time_total_s: 1755.4120795726776\n",
      "  timers:\n",
      "    learn_throughput: 68.971\n",
      "    learn_time_ms: 144931.076\n",
      "    load_throughput: 83109.746\n",
      "    load_time_ms: 120.275\n",
      "    sample_throughput: 67.775\n",
      "    sample_time_ms: 147489.082\n",
      "    update_time_ms: 9.357\n",
      "  timestamp: 1636902490\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59976\n",
      "  training_iteration: 6\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         1755.41</td><td style=\"text-align: right;\">59976</td><td style=\"text-align: right;\"> 1.22475</td><td style=\"text-align: right;\">               10.26</td><td style=\"text-align: right;\">               -1.95</td><td style=\"text-align: right;\">           99.8713</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 69972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-13-05\n",
      "  done: false\n",
      "  episode_len_mean: 100.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.530000000000015\n",
      "  episode_reward_mean: 1.2506000000000028\n",
      "  episode_reward_min: -1.9600000000000009\n",
      "  episodes_this_iter: 99\n",
      "  episodes_total: 703\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.747085771805201\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019294186270850836\n",
      "          policy_loss: -0.034431641933341056\n",
      "          total_loss: 0.2905691921695048\n",
      "          vf_explained_var: 0.4129098951816559\n",
      "          vf_loss: 0.35054227306117486\n",
      "    num_agent_steps_sampled: 69972\n",
      "    num_agent_steps_trained: 69972\n",
      "    num_steps_sampled: 69972\n",
      "    num_steps_trained: 69972\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.92280285035629\n",
      "    ram_util_percent: 41.083847980997625\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048729713562477156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.712074190558006\n",
      "    mean_inference_ms: 8.588028029135184\n",
      "    mean_raw_obs_processing_ms: 1.7324583329550924\n",
      "  time_since_restore: 2050.596774339676\n",
      "  time_this_iter_s: 295.1846947669983\n",
      "  time_total_s: 2050.596774339676\n",
      "  timers:\n",
      "    learn_throughput: 68.97\n",
      "    learn_time_ms: 144932.616\n",
      "    load_throughput: 83843.662\n",
      "    load_time_ms: 119.222\n",
      "    sample_throughput: 67.603\n",
      "    sample_time_ms: 147863.097\n",
      "    update_time_ms: 8.765\n",
      "  timestamp: 1636902785\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69972\n",
      "  training_iteration: 7\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">          2050.6</td><td style=\"text-align: right;\">69972</td><td style=\"text-align: right;\">  1.2506</td><td style=\"text-align: right;\">                6.53</td><td style=\"text-align: right;\">               -1.96</td><td style=\"text-align: right;\">            100.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 79968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-18-05\n",
      "  done: false\n",
      "  episode_len_mean: 99.54455445544555\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.820000000000013\n",
      "  episode_reward_mean: 0.9281188118811902\n",
      "  episode_reward_min: -1.9200000000000013\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 804\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.09999999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.716490948302114\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0277014662107412\n",
      "          policy_loss: -0.038532258618352376\n",
      "          total_loss: 0.23172735154517313\n",
      "          vf_explained_var: 0.5254629254341125\n",
      "          vf_loss: 0.2946543720467255\n",
      "    num_agent_steps_sampled: 79968\n",
      "    num_agent_steps_trained: 79968\n",
      "    num_steps_sampled: 79968\n",
      "    num_steps_trained: 79968\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.38648018648017\n",
      "    ram_util_percent: 41.68857808857809\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048801743160853124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.49751144878873\n",
      "    mean_inference_ms: 8.577275307009673\n",
      "    mean_raw_obs_processing_ms: 2.0538957283971824\n",
      "  time_since_restore: 2350.985038995743\n",
      "  time_this_iter_s: 300.3882646560669\n",
      "  time_total_s: 2350.985038995743\n",
      "  timers:\n",
      "    learn_throughput: 68.972\n",
      "    learn_time_ms: 144928.161\n",
      "    load_throughput: 84556.906\n",
      "    load_time_ms: 118.216\n",
      "    sample_throughput: 67.178\n",
      "    sample_time_ms: 148799.699\n",
      "    update_time_ms: 9.468\n",
      "  timestamp: 1636903085\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 79968\n",
      "  training_iteration: 8\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         2350.99</td><td style=\"text-align: right;\">79968</td><td style=\"text-align: right;\">0.928119</td><td style=\"text-align: right;\">                4.82</td><td style=\"text-align: right;\">               -1.92</td><td style=\"text-align: right;\">           99.5446</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 89964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-22-46\n",
      "  done: false\n",
      "  episode_len_mean: 101.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.870000000000013\n",
      "  episode_reward_mean: 0.8922000000000024\n",
      "  episode_reward_min: -2.05\n",
      "  episodes_this_iter: 98\n",
      "  episodes_total: 902\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.15\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6958542383634128\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.029198183727480908\n",
      "          policy_loss: -0.03811441195261084\n",
      "          total_loss: 0.21304377028439989\n",
      "          vf_explained_var: 0.549401044845581\n",
      "          vf_loss: 0.2737369965594739\n",
      "    num_agent_steps_sampled: 89964\n",
      "    num_agent_steps_trained: 89964\n",
      "    num_steps_sampled: 89964\n",
      "    num_steps_trained: 89964\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.20049999999999\n",
      "    ram_util_percent: 41.924\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049055570381558\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.26280427151571\n",
      "    mean_inference_ms: 8.573797281309385\n",
      "    mean_raw_obs_processing_ms: 1.9045449643858905\n",
      "  time_since_restore: 2631.3918561935425\n",
      "  time_this_iter_s: 280.4068171977997\n",
      "  time_total_s: 2631.3918561935425\n",
      "  timers:\n",
      "    learn_throughput: 68.967\n",
      "    learn_time_ms: 144937.857\n",
      "    load_throughput: 84930.654\n",
      "    load_time_ms: 117.696\n",
      "    sample_throughput: 67.864\n",
      "    sample_time_ms: 147293.923\n",
      "    update_time_ms: 10.254\n",
      "  timestamp: 1636903366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 89964\n",
      "  training_iteration: 9\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         2631.39</td><td style=\"text-align: right;\">89964</td><td style=\"text-align: right;\">  0.8922</td><td style=\"text-align: right;\">                6.87</td><td style=\"text-align: right;\">               -2.05</td><td style=\"text-align: right;\">            101.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 99960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-27-31\n",
      "  done: false\n",
      "  episode_len_mean: 98.76470588235294\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.750000000000012\n",
      "  episode_reward_mean: 1.419803921568631\n",
      "  episode_reward_min: -2.000000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 1004\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.22500000000000006\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6617645257558578\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.03276358538475574\n",
      "          policy_loss: -0.044040175498678134\n",
      "          total_loss: 0.23528799822327132\n",
      "          vf_explained_var: 0.5880103707313538\n",
      "          vf_loss: 0.2985740117099868\n",
      "    num_agent_steps_sampled: 99960\n",
      "    num_agent_steps_trained: 99960\n",
      "    num_steps_sampled: 99960\n",
      "    num_steps_trained: 99960\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.19533169533169\n",
      "    ram_util_percent: 41.73710073710075\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04897665824090076\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.19138504417229\n",
      "    mean_inference_ms: 8.573704299616555\n",
      "    mean_raw_obs_processing_ms: 1.7865184073053881\n",
      "  time_since_restore: 2916.8921689987183\n",
      "  time_this_iter_s: 285.5003128051758\n",
      "  time_total_s: 2916.8921689987183\n",
      "  timers:\n",
      "    learn_throughput: 68.968\n",
      "    learn_time_ms: 144937.401\n",
      "    load_throughput: 85215.981\n",
      "    load_time_ms: 117.302\n",
      "    sample_throughput: 68.182\n",
      "    sample_time_ms: 146608.041\n",
      "    update_time_ms: 9.715\n",
      "  timestamp: 1636903651\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 99960\n",
      "  training_iteration: 10\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2916.89</td><td style=\"text-align: right;\">99960</td><td style=\"text-align: right;\">  1.4198</td><td style=\"text-align: right;\">                8.75</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           98.7647</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 109956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-32-35\n",
      "  done: false\n",
      "  episode_len_mean: 95.24038461538461\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.360000000000014\n",
      "  episode_reward_mean: 1.7176923076923116\n",
      "  episode_reward_min: -1.6100000000000005\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1108\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.33749999999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6492050871889816\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.029999021829840426\n",
      "          policy_loss: -0.04716765971070267\n",
      "          total_loss: 0.20583039400322983\n",
      "          vf_explained_var: 0.6615533828735352\n",
      "          vf_loss: 0.2693654337563576\n",
      "    num_agent_steps_sampled: 109956\n",
      "    num_agent_steps_trained: 109956\n",
      "    num_steps_sampled: 109956\n",
      "    num_steps_trained: 109956\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77188940092167\n",
      "    ram_util_percent: 41.89447004608295\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04882698525532606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.197213567963544\n",
      "    mean_inference_ms: 8.570099426404301\n",
      "    mean_raw_obs_processing_ms: 2.1624070340749975\n",
      "  time_since_restore: 3220.9023168087006\n",
      "  time_this_iter_s: 304.0101478099823\n",
      "  time_total_s: 3220.9023168087006\n",
      "  timers:\n",
      "    learn_throughput: 68.965\n",
      "    learn_time_ms: 144942.148\n",
      "    load_throughput: 85090.317\n",
      "    load_time_ms: 117.475\n",
      "    sample_throughput: 71.203\n",
      "    sample_time_ms: 140387.578\n",
      "    update_time_ms: 9.845\n",
      "  timestamp: 1636903955\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109956\n",
      "  training_iteration: 11\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">          3220.9</td><td style=\"text-align: right;\">109956</td><td style=\"text-align: right;\"> 1.71769</td><td style=\"text-align: right;\">                8.36</td><td style=\"text-align: right;\">               -1.61</td><td style=\"text-align: right;\">           95.2404</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 119952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-37-24\n",
      "  done: false\n",
      "  episode_len_mean: 96.23076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.760000000000005\n",
      "  episode_reward_mean: 1.5182692307692345\n",
      "  episode_reward_min: -2.0200000000000005\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1212\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.50625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6219841663654035\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.028015319427843768\n",
      "          policy_loss: -0.046292343868826254\n",
      "          total_loss: 0.19925196828304703\n",
      "          vf_explained_var: 0.6058682203292847\n",
      "          vf_loss: 0.2575813973823992\n",
      "    num_agent_steps_sampled: 119952\n",
      "    num_agent_steps_trained: 119952\n",
      "    num_steps_sampled: 119952\n",
      "    num_steps_trained: 119952\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.16739659367397\n",
      "    ram_util_percent: 42.03892944038929\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048669129132758955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.158868558636556\n",
      "    mean_inference_ms: 8.567346658839769\n",
      "    mean_raw_obs_processing_ms: 2.0428828252453366\n",
      "  time_since_restore: 3509.0462403297424\n",
      "  time_this_iter_s: 288.14392352104187\n",
      "  time_total_s: 3509.0462403297424\n",
      "  timers:\n",
      "    learn_throughput: 68.958\n",
      "    learn_time_ms: 144957.433\n",
      "    load_throughput: 87658.39\n",
      "    load_time_ms: 114.034\n",
      "    sample_throughput: 70.072\n",
      "    sample_time_ms: 142652.339\n",
      "    update_time_ms: 9.893\n",
      "  timestamp: 1636904244\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 119952\n",
      "  training_iteration: 12\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         3509.05</td><td style=\"text-align: right;\">119952</td><td style=\"text-align: right;\"> 1.51827</td><td style=\"text-align: right;\">                8.76</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           96.2308</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 129948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-42-11\n",
      "  done: false\n",
      "  episode_len_mean: 96.58653846153847\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.190000000000015\n",
      "  episode_reward_mean: 1.6795192307692342\n",
      "  episode_reward_min: -2.1100000000000003\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1316\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6332171709109575\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.024243443993249278\n",
      "          policy_loss: -0.050442353914627154\n",
      "          total_loss: 0.24711239260569628\n",
      "          vf_explained_var: 0.5755695104598999\n",
      "          vf_loss: 0.3054770540095802\n",
      "    num_agent_steps_sampled: 129948\n",
      "    num_agent_steps_trained: 129948\n",
      "    num_steps_sampled: 129948\n",
      "    num_steps_trained: 129948\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.28146341463413\n",
      "    ram_util_percent: 41.979756097560966\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04860948067547906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.14700498734259\n",
      "    mean_inference_ms: 8.56368565995646\n",
      "    mean_raw_obs_processing_ms: 1.9397280796199097\n",
      "  time_since_restore: 3796.481033563614\n",
      "  time_this_iter_s: 287.43479323387146\n",
      "  time_total_s: 3796.481033563614\n",
      "  timers:\n",
      "    learn_throughput: 68.962\n",
      "    learn_time_ms: 144949.684\n",
      "    load_throughput: 88833.697\n",
      "    load_time_ms: 112.525\n",
      "    sample_throughput: 69.215\n",
      "    sample_time_ms: 144419.032\n",
      "    update_time_ms: 9.839\n",
      "  timestamp: 1636904531\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 129948\n",
      "  training_iteration: 13\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         3796.48</td><td style=\"text-align: right;\">129948</td><td style=\"text-align: right;\"> 1.67952</td><td style=\"text-align: right;\">               10.19</td><td style=\"text-align: right;\">               -2.11</td><td style=\"text-align: right;\">           96.5865</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 139944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-47-16\n",
      "  done: false\n",
      "  episode_len_mean: 95.20192307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.870000000000012\n",
      "  episode_reward_mean: 1.2180769230769264\n",
      "  episode_reward_min: -1.8100000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1420\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.614535803468818\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02094004718509212\n",
      "          policy_loss: -0.049892968075891206\n",
      "          total_loss: 0.17042035843667566\n",
      "          vf_explained_var: 0.6678788661956787\n",
      "          vf_loss: 0.2226066606091415\n",
      "    num_agent_steps_sampled: 139944\n",
      "    num_agent_steps_trained: 139944\n",
      "    num_steps_sampled: 139944\n",
      "    num_steps_trained: 139944\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13379310344827\n",
      "    ram_util_percent: 41.72390804597701\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048717008198523606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.1421603719103\n",
      "    mean_inference_ms: 8.557110879244933\n",
      "    mean_raw_obs_processing_ms: 2.0958057154007648\n",
      "  time_since_restore: 4101.065110206604\n",
      "  time_this_iter_s: 304.5840766429901\n",
      "  time_total_s: 4101.065110206604\n",
      "  timers:\n",
      "    learn_throughput: 68.967\n",
      "    learn_time_ms: 144938.28\n",
      "    load_throughput: 88774.316\n",
      "    load_time_ms: 112.6\n",
      "    sample_throughput: 68.753\n",
      "    sample_time_ms: 145390.371\n",
      "    update_time_ms: 9.474\n",
      "  timestamp: 1636904836\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 139944\n",
      "  training_iteration: 14\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         4101.07</td><td style=\"text-align: right;\">139944</td><td style=\"text-align: right;\"> 1.21808</td><td style=\"text-align: right;\">                6.87</td><td style=\"text-align: right;\">               -1.81</td><td style=\"text-align: right;\">           95.2019</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 149940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-52-12\n",
      "  done: false\n",
      "  episode_len_mean: 95.82692307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.470000000000017\n",
      "  episode_reward_mean: 1.651826923076927\n",
      "  episode_reward_min: -1.7800000000000007\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 1524\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.7085937500000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5801324088349302\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019684808400661603\n",
      "          policy_loss: -0.04797709975670227\n",
      "          total_loss: 0.19475129989958886\n",
      "          vf_explained_var: 0.7160896062850952\n",
      "          vf_loss: 0.23489638360647055\n",
      "    num_agent_steps_sampled: 149940\n",
      "    num_agent_steps_trained: 149940\n",
      "    num_steps_sampled: 149940\n",
      "    num_steps_trained: 149940\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.72434988179667\n",
      "    ram_util_percent: 42.04066193853427\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04873330308479576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.04914193007246\n",
      "    mean_inference_ms: 8.552553162331188\n",
      "    mean_raw_obs_processing_ms: 2.1135578021266253\n",
      "  time_since_restore: 4397.3837723731995\n",
      "  time_this_iter_s: 296.31866216659546\n",
      "  time_total_s: 4397.3837723731995\n",
      "  timers:\n",
      "    learn_throughput: 68.972\n",
      "    learn_time_ms: 144929.18\n",
      "    load_throughput: 88769.109\n",
      "    load_time_ms: 112.607\n",
      "    sample_throughput: 68.0\n",
      "    sample_time_ms: 147000.017\n",
      "    update_time_ms: 9.799\n",
      "  timestamp: 1636905132\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 149940\n",
      "  training_iteration: 15\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         4397.38</td><td style=\"text-align: right;\">149940</td><td style=\"text-align: right;\"> 1.65183</td><td style=\"text-align: right;\">                8.47</td><td style=\"text-align: right;\">               -1.78</td><td style=\"text-align: right;\">           95.8269</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 159936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_15-56-54\n",
      "  done: false\n",
      "  episode_len_mean: 96.11428571428571\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.81000000000001\n",
      "  episode_reward_mean: 1.754476190476195\n",
      "  episode_reward_min: -2.289999999999996\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 1629\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.7085937500000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5887092774749823\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01763131987004727\n",
      "          policy_loss: -0.05092837934055899\n",
      "          total_loss: 0.16808417862058322\n",
      "          vf_explained_var: 0.7048277258872986\n",
      "          vf_loss: 0.21477488728088892\n",
      "    num_agent_steps_sampled: 159936\n",
      "    num_agent_steps_trained: 159936\n",
      "    num_steps_sampled: 159936\n",
      "    num_steps_trained: 159936\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.19925373134328\n",
      "    ram_util_percent: 41.921144278606974\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048715279889541\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00930927576109\n",
      "    mean_inference_ms: 8.550144080988598\n",
      "    mean_raw_obs_processing_ms: 2.024771814077573\n",
      "  time_since_restore: 4679.75058221817\n",
      "  time_this_iter_s: 282.3668098449707\n",
      "  time_total_s: 4679.75058221817\n",
      "  timers:\n",
      "    learn_throughput: 68.974\n",
      "    learn_time_ms: 144924.397\n",
      "    load_throughput: 88777.906\n",
      "    load_time_ms: 112.596\n",
      "    sample_throughput: 67.827\n",
      "    sample_time_ms: 147374.44\n",
      "    update_time_ms: 8.938\n",
      "  timestamp: 1636905414\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 159936\n",
      "  training_iteration: 16\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         4679.75</td><td style=\"text-align: right;\">159936</td><td style=\"text-align: right;\"> 1.75448</td><td style=\"text-align: right;\">                8.81</td><td style=\"text-align: right;\">               -2.29</td><td style=\"text-align: right;\">           96.1143</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 169932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-01-37\n",
      "  done: false\n",
      "  episode_len_mean: 96.94174757281553\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.64000000000002\n",
      "  episode_reward_mean: 1.5957281553398093\n",
      "  episode_reward_min: -1.9100000000000013\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 1732\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.7085937500000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.600336382429824\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015568854749177555\n",
      "          policy_loss: -0.056665287115491736\n",
      "          total_loss: 0.12470793101486838\n",
      "          vf_explained_var: 0.7119825482368469\n",
      "          vf_loss: 0.18077573356552956\n",
      "    num_agent_steps_sampled: 169932\n",
      "    num_agent_steps_trained: 169932\n",
      "    num_steps_sampled: 169932\n",
      "    num_steps_trained: 169932\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.18737623762375\n",
      "    ram_util_percent: 41.75297029702971\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048827430842570324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.972664698746314\n",
      "    mean_inference_ms: 8.550584879635956\n",
      "    mean_raw_obs_processing_ms: 1.9462665948106368\n",
      "  time_since_restore: 4962.586815834045\n",
      "  time_this_iter_s: 282.83623361587524\n",
      "  time_total_s: 4962.586815834045\n",
      "  timers:\n",
      "    learn_throughput: 68.974\n",
      "    learn_time_ms: 144923.26\n",
      "    load_throughput: 88795.731\n",
      "    load_time_ms: 112.573\n",
      "    sample_throughput: 68.4\n",
      "    sample_time_ms: 146140.928\n",
      "    update_time_ms: 9.108\n",
      "  timestamp: 1636905697\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 169932\n",
      "  training_iteration: 17\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         4962.59</td><td style=\"text-align: right;\">169932</td><td style=\"text-align: right;\"> 1.59573</td><td style=\"text-align: right;\">                8.64</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           96.9417</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 179928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-06-39\n",
      "  done: false\n",
      "  episode_len_mean: 92.03669724770643\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.740000000000014\n",
      "  episode_reward_mean: 1.929816513761472\n",
      "  episode_reward_min: -1.7500000000000009\n",
      "  episodes_this_iter: 109\n",
      "  episodes_total: 1841\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.7085937500000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5967230091747058\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.021757631094439362\n",
      "          policy_loss: -0.045536717239958356\n",
      "          total_loss: 0.2753134146675022\n",
      "          vf_explained_var: 0.6728546023368835\n",
      "          vf_loss: 0.30964240723838793\n",
      "    num_agent_steps_sampled: 179928\n",
      "    num_agent_steps_trained: 179928\n",
      "    num_steps_sampled: 179928\n",
      "    num_steps_trained: 179928\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.04372093023257\n",
      "    ram_util_percent: 42.28162790697676\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04896256002083444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.942299932403806\n",
      "    mean_inference_ms: 8.548981863142263\n",
      "    mean_raw_obs_processing_ms: 2.157976838707284\n",
      "  time_since_restore: 5264.191482543945\n",
      "  time_this_iter_s: 301.6046667098999\n",
      "  time_total_s: 5264.191482543945\n",
      "  timers:\n",
      "    learn_throughput: 68.975\n",
      "    learn_time_ms: 144921.625\n",
      "    load_throughput: 88628.878\n",
      "    load_time_ms: 112.785\n",
      "    sample_throughput: 68.342\n",
      "    sample_time_ms: 146263.324\n",
      "    update_time_ms: 9.332\n",
      "  timestamp: 1636905999\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 179928\n",
      "  training_iteration: 18\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         5264.19</td><td style=\"text-align: right;\">179928</td><td style=\"text-align: right;\"> 1.92982</td><td style=\"text-align: right;\">                9.74</td><td style=\"text-align: right;\">               -1.75</td><td style=\"text-align: right;\">           92.0367</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 189924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-11-47\n",
      "  done: false\n",
      "  episode_len_mean: 95.28571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.680000000000007\n",
      "  episode_reward_mean: 1.5261904761904797\n",
      "  episode_reward_min: -2.0900000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 1946\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5923866663223656\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014990808165429826\n",
      "          policy_loss: -0.05124915889424519\n",
      "          total_loss: 0.17733568799896882\n",
      "          vf_explained_var: 0.725115954875946\n",
      "          vf_loss: 0.21608891286489226\n",
      "    num_agent_steps_sampled: 189924\n",
      "    num_agent_steps_trained: 189924\n",
      "    num_steps_sampled: 189924\n",
      "    num_steps_trained: 189924\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.96068181818183\n",
      "    ram_util_percent: 42.778181818181814\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04888471737729681\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.8099601872348\n",
      "    mean_inference_ms: 8.54060254247935\n",
      "    mean_raw_obs_processing_ms: 2.268498181073895\n",
      "  time_since_restore: 5572.056156635284\n",
      "  time_this_iter_s: 307.8646740913391\n",
      "  time_total_s: 5572.056156635284\n",
      "  timers:\n",
      "    learn_throughput: 68.982\n",
      "    learn_time_ms: 144906.872\n",
      "    load_throughput: 88776.177\n",
      "    load_time_ms: 112.598\n",
      "    sample_throughput: 67.076\n",
      "    sample_time_ms: 149024.671\n",
      "    update_time_ms: 8.284\n",
      "  timestamp: 1636906307\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 189924\n",
      "  training_iteration: 19\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         5572.06</td><td style=\"text-align: right;\">189924</td><td style=\"text-align: right;\"> 1.52619</td><td style=\"text-align: right;\">                8.68</td><td style=\"text-align: right;\">               -2.09</td><td style=\"text-align: right;\">           95.2857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 199920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-16-30\n",
      "  done: false\n",
      "  episode_len_mean: 96.14423076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.810000000000013\n",
      "  episode_reward_mean: 1.977019230769235\n",
      "  episode_reward_min: -1.660000000000001\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 2050\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5920385914990027\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014553636918623747\n",
      "          policy_loss: -0.050832802840731404\n",
      "          total_loss: 0.1898929063636714\n",
      "          vf_explained_var: 0.6800243258476257\n",
      "          vf_loss: 0.22934671548975266\n",
      "    num_agent_steps_sampled: 199920\n",
      "    num_agent_steps_trained: 199920\n",
      "    num_steps_sampled: 199920\n",
      "    num_steps_trained: 199920\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.28759305210919\n",
      "    ram_util_percent: 42.81414392059553\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04896685741431954\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.788861424352238\n",
      "    mean_inference_ms: 8.541263043997768\n",
      "    mean_raw_obs_processing_ms: 2.187163920747485\n",
      "  time_since_restore: 5854.993953227997\n",
      "  time_this_iter_s: 282.9377965927124\n",
      "  time_total_s: 5854.993953227997\n",
      "  timers:\n",
      "    learn_throughput: 68.984\n",
      "    learn_time_ms: 144904.044\n",
      "    load_throughput: 89007.124\n",
      "    load_time_ms: 112.306\n",
      "    sample_throughput: 67.19\n",
      "    sample_time_ms: 148771.383\n",
      "    update_time_ms: 8.286\n",
      "  timestamp: 1636906590\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 199920\n",
      "  training_iteration: 20\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5854.99</td><td style=\"text-align: right;\">199920</td><td style=\"text-align: right;\"> 1.97702</td><td style=\"text-align: right;\">                8.81</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           96.1442</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 209916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-21-29\n",
      "  done: false\n",
      "  episode_len_mean: 95.3076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.690000000000014\n",
      "  episode_reward_mean: 1.4474038461538492\n",
      "  episode_reward_min: -2.229999999999996\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 2154\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.573831805612287\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01478891218465308\n",
      "          policy_loss: -0.054327342605106854\n",
      "          total_loss: 0.14469867380073245\n",
      "          vf_explained_var: 0.7236766219139099\n",
      "          vf_loss: 0.18686197163720225\n",
      "    num_agent_steps_sampled: 209916\n",
      "    num_agent_steps_trained: 209916\n",
      "    num_steps_sampled: 209916\n",
      "    num_steps_trained: 209916\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.55747663551404\n",
      "    ram_util_percent: 43.011214953271036\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048894985260995755\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.73109892834176\n",
      "    mean_inference_ms: 8.537856472962542\n",
      "    mean_raw_obs_processing_ms: 2.2813711459380284\n",
      "  time_since_restore: 6154.497422218323\n",
      "  time_this_iter_s: 299.5034689903259\n",
      "  time_total_s: 6154.497422218323\n",
      "  timers:\n",
      "    learn_throughput: 68.985\n",
      "    learn_time_ms: 144901.947\n",
      "    load_throughput: 88904.469\n",
      "    load_time_ms: 112.435\n",
      "    sample_throughput: 67.394\n",
      "    sample_time_ms: 148322.668\n",
      "    update_time_ms: 8.039\n",
      "  timestamp: 1636906889\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 209916\n",
      "  training_iteration: 21\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">          6154.5</td><td style=\"text-align: right;\">209916</td><td style=\"text-align: right;\">  1.4474</td><td style=\"text-align: right;\">               12.69</td><td style=\"text-align: right;\">               -2.23</td><td style=\"text-align: right;\">           95.3077</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 219912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-26-28\n",
      "  done: false\n",
      "  episode_len_mean: 94.97169811320755\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.540000000000015\n",
      "  episode_reward_mean: 1.9624528301886834\n",
      "  episode_reward_min: -1.9100000000000008\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 2260\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.577983933738154\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016482307783089026\n",
      "          policy_loss: -0.05310742948920681\n",
      "          total_loss: 0.20362163194630326\n",
      "          vf_explained_var: 0.7068442702293396\n",
      "          vf_loss: 0.24026654987699456\n",
      "    num_agent_steps_sampled: 219912\n",
      "    num_agent_steps_trained: 219912\n",
      "    num_steps_sampled: 219912\n",
      "    num_steps_trained: 219912\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.39812206572769\n",
      "    ram_util_percent: 42.57723004694836\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0488423735717476\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.727136543193375\n",
      "    mean_inference_ms: 8.53698994459014\n",
      "    mean_raw_obs_processing_ms: 2.2839992332105767\n",
      "  time_since_restore: 6453.205862045288\n",
      "  time_this_iter_s: 298.70843982696533\n",
      "  time_total_s: 6453.205862045288\n",
      "  timers:\n",
      "    learn_throughput: 68.985\n",
      "    learn_time_ms: 144901.921\n",
      "    load_throughput: 88816.817\n",
      "    load_time_ms: 112.546\n",
      "    sample_throughput: 66.917\n",
      "    sample_time_ms: 149378.688\n",
      "    update_time_ms: 8.282\n",
      "  timestamp: 1636907188\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 219912\n",
      "  training_iteration: 22\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         6453.21</td><td style=\"text-align: right;\">219912</td><td style=\"text-align: right;\"> 1.96245</td><td style=\"text-align: right;\">                8.54</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">           94.9717</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 229908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-31-12\n",
      "  done: false\n",
      "  episode_len_mean: 94.78095238095239\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.540000000000017\n",
      "  episode_reward_mean: 1.8037142857142896\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 2365\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5670608746699797\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01626357898875941\n",
      "          policy_loss: -0.052882363696972655\n",
      "          total_loss: 0.20770867521452727\n",
      "          vf_explained_var: 0.7249283194541931\n",
      "          vf_loss: 0.24457987422664834\n",
      "    num_agent_steps_sampled: 229908\n",
      "    num_agent_steps_trained: 229908\n",
      "    num_steps_sampled: 229908\n",
      "    num_steps_trained: 229908\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.2074074074074\n",
      "    ram_util_percent: 42.440987654320985\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04890959637341081\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.729670841584344\n",
      "    mean_inference_ms: 8.537817662743795\n",
      "    mean_raw_obs_processing_ms: 2.2171668643479285\n",
      "  time_since_restore: 6737.408773183823\n",
      "  time_this_iter_s: 284.20291113853455\n",
      "  time_total_s: 6737.408773183823\n",
      "  timers:\n",
      "    learn_throughput: 68.984\n",
      "    learn_time_ms: 144902.262\n",
      "    load_throughput: 88577.591\n",
      "    load_time_ms: 112.85\n",
      "    sample_throughput: 67.063\n",
      "    sample_time_ms: 149054.808\n",
      "    update_time_ms: 8.415\n",
      "  timestamp: 1636907472\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 229908\n",
      "  training_iteration: 23\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         6737.41</td><td style=\"text-align: right;\">229908</td><td style=\"text-align: right;\"> 1.80371</td><td style=\"text-align: right;\">                8.54</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">            94.781</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 239904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-35-57\n",
      "  done: false\n",
      "  episode_len_mean: 94.12264150943396\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.420000000000016\n",
      "  episode_reward_mean: 1.6654716981132118\n",
      "  episode_reward_min: -2.0200000000000005\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 2471\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5606892810927495\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015767214697755196\n",
      "          policy_loss: -0.05150007929127568\n",
      "          total_loss: 0.16309441970163782\n",
      "          vf_explained_var: 0.7561711072921753\n",
      "          vf_loss: 0.19979174573722686\n",
      "    num_agent_steps_sampled: 239904\n",
      "    num_agent_steps_trained: 239904\n",
      "    num_steps_sampled: 239904\n",
      "    num_steps_trained: 239904\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.33243243243244\n",
      "    ram_util_percent: 42.23390663390664\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04888920662134338\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.742081616804587\n",
      "    mean_inference_ms: 8.538687908971912\n",
      "    mean_raw_obs_processing_ms: 2.1575968289570744\n",
      "  time_since_restore: 7022.313279867172\n",
      "  time_this_iter_s: 284.9045066833496\n",
      "  time_total_s: 7022.313279867172\n",
      "  timers:\n",
      "    learn_throughput: 68.986\n",
      "    learn_time_ms: 144898.75\n",
      "    load_throughput: 88529.672\n",
      "    load_time_ms: 112.911\n",
      "    sample_throughput: 67.959\n",
      "    sample_time_ms: 147089.655\n",
      "    update_time_ms: 9.008\n",
      "  timestamp: 1636907757\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 239904\n",
      "  training_iteration: 24\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         7022.31</td><td style=\"text-align: right;\">239904</td><td style=\"text-align: right;\"> 1.66547</td><td style=\"text-align: right;\">               12.42</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           94.1226</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 249900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-41-11\n",
      "  done: false\n",
      "  episode_len_mean: 90.7909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.810000000000011\n",
      "  episode_reward_mean: 1.8768181818181864\n",
      "  episode_reward_min: -2.229999999999999\n",
      "  episodes_this_iter: 110\n",
      "  episodes_total: 2581\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.584720910920037\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015708214264731103\n",
      "          policy_loss: -0.05371588069834134\n",
      "          total_loss: 0.19130616118737426\n",
      "          vf_explained_var: 0.7147061228752136\n",
      "          vf_loss: 0.23061081553674023\n",
      "    num_agent_steps_sampled: 249900\n",
      "    num_agent_steps_trained: 249900\n",
      "    num_steps_sampled: 249900\n",
      "    num_steps_trained: 249900\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13668903803132\n",
      "    ram_util_percent: 42.9268456375839\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048810650686508\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.704967210486476\n",
      "    mean_inference_ms: 8.530586720992407\n",
      "    mean_raw_obs_processing_ms: 2.2951102866435353\n",
      "  time_since_restore: 7335.724592208862\n",
      "  time_this_iter_s: 313.41131234169006\n",
      "  time_total_s: 7335.724592208862\n",
      "  timers:\n",
      "    learn_throughput: 68.984\n",
      "    learn_time_ms: 144903.24\n",
      "    load_throughput: 88557.646\n",
      "    load_time_ms: 112.876\n",
      "    sample_throughput: 67.18\n",
      "    sample_time_ms: 148794.808\n",
      "    update_time_ms: 8.679\n",
      "  timestamp: 1636908071\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 249900\n",
      "  training_iteration: 25\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         7335.72</td><td style=\"text-align: right;\">249900</td><td style=\"text-align: right;\"> 1.87682</td><td style=\"text-align: right;\">               10.81</td><td style=\"text-align: right;\">               -2.23</td><td style=\"text-align: right;\">           90.7909</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 259896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-45-53\n",
      "  done: false\n",
      "  episode_len_mean: 95.88571428571429\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.820000000000014\n",
      "  episode_reward_mean: 1.9579047619047671\n",
      "  episode_reward_min: -2.0700000000000007\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 2686\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5596622325416303\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015764957250735318\n",
      "          policy_loss: -0.05896871415420603\n",
      "          total_loss: 0.16775916708537783\n",
      "          vf_explained_var: 0.7666202187538147\n",
      "          vf_loss: 0.21192064354371312\n",
      "    num_agent_steps_sampled: 259896\n",
      "    num_agent_steps_trained: 259896\n",
      "    num_steps_sampled: 259896\n",
      "    num_steps_trained: 259896\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.32009925558313\n",
      "    ram_util_percent: 43.011662531017365\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0488279991394578\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.68425807260318\n",
      "    mean_inference_ms: 8.530980418328635\n",
      "    mean_raw_obs_processing_ms: 2.233318414919613\n",
      "  time_since_restore: 7618.064697742462\n",
      "  time_this_iter_s: 282.34010553359985\n",
      "  time_total_s: 7618.064697742462\n",
      "  timers:\n",
      "    learn_throughput: 68.982\n",
      "    learn_time_ms: 144908.142\n",
      "    load_throughput: 88756.894\n",
      "    load_time_ms: 112.622\n",
      "    sample_throughput: 67.183\n",
      "    sample_time_ms: 148787.287\n",
      "    update_time_ms: 9.08\n",
      "  timestamp: 1636908353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259896\n",
      "  training_iteration: 26\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         7618.06</td><td style=\"text-align: right;\">259896</td><td style=\"text-align: right;\">  1.9579</td><td style=\"text-align: right;\">               10.82</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           95.8857</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 269892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-51-04\n",
      "  done: false\n",
      "  episode_len_mean: 93.59433962264151\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.600000000000014\n",
      "  episode_reward_mean: 1.6884905660377398\n",
      "  episode_reward_min: -2.2199999999999993\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 2792\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.573404266895392\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014795967476210993\n",
      "          policy_loss: -0.060399559496814366\n",
      "          total_loss: 0.1477896484070752\n",
      "          vf_explained_var: 0.7464619278907776\n",
      "          vf_loss: 0.1960028048023645\n",
      "    num_agent_steps_sampled: 269892\n",
      "    num_agent_steps_trained: 269892\n",
      "    num_steps_sampled: 269892\n",
      "    num_steps_trained: 269892\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.71328828828828\n",
      "    ram_util_percent: 42.867792792792784\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04882500022651797\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.67915529274574\n",
      "    mean_inference_ms: 8.528343266347715\n",
      "    mean_raw_obs_processing_ms: 2.2793117719688696\n",
      "  time_since_restore: 7929.0835156440735\n",
      "  time_this_iter_s: 311.0188179016113\n",
      "  time_total_s: 7929.0835156440735\n",
      "  timers:\n",
      "    learn_throughput: 68.982\n",
      "    learn_time_ms: 144908.135\n",
      "    load_throughput: 88721.002\n",
      "    load_time_ms: 112.668\n",
      "    sample_throughput: 65.934\n",
      "    sample_time_ms: 151605.73\n",
      "    update_time_ms: 9.316\n",
      "  timestamp: 1636908664\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 269892\n",
      "  training_iteration: 27\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         7929.08</td><td style=\"text-align: right;\">269892</td><td style=\"text-align: right;\"> 1.68849</td><td style=\"text-align: right;\">                 6.6</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">           93.5943</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 279888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_16-56-02\n",
      "  done: false\n",
      "  episode_len_mean: 93.71296296296296\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.010000000000014\n",
      "  episode_reward_mean: 2.0086111111111147\n",
      "  episode_reward_min: -1.800000000000001\n",
      "  episodes_this_iter: 108\n",
      "  episodes_total: 2900\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5691857629352146\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016589410967632265\n",
      "          policy_loss: -0.05413030481172933\n",
      "          total_loss: 0.18442133229751234\n",
      "          vf_explained_var: 0.7092527151107788\n",
      "          vf_loss: 0.22172664952758922\n",
      "    num_agent_steps_sampled: 279888\n",
      "    num_agent_steps_trained: 279888\n",
      "    num_steps_sampled: 279888\n",
      "    num_steps_trained: 279888\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.63655660377357\n",
      "    ram_util_percent: 42.94622641509433\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0488380641166758\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.666967672183496\n",
      "    mean_inference_ms: 8.525704026411947\n",
      "    mean_raw_obs_processing_ms: 2.2838915428529187\n",
      "  time_since_restore: 8226.582585334778\n",
      "  time_this_iter_s: 297.49906969070435\n",
      "  time_total_s: 8226.582585334778\n",
      "  timers:\n",
      "    learn_throughput: 68.979\n",
      "    learn_time_ms: 144913.193\n",
      "    load_throughput: 89395.341\n",
      "    load_time_ms: 111.818\n",
      "    sample_throughput: 66.115\n",
      "    sample_time_ms: 151190.521\n",
      "    update_time_ms: 10.068\n",
      "  timestamp: 1636908962\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 279888\n",
      "  training_iteration: 28\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         8226.58</td><td style=\"text-align: right;\">279888</td><td style=\"text-align: right;\"> 2.00861</td><td style=\"text-align: right;\">               11.01</td><td style=\"text-align: right;\">                -1.8</td><td style=\"text-align: right;\">            93.713</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 289884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-01-04\n",
      "  done: false\n",
      "  episode_len_mean: 94.14150943396227\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000013\n",
      "  episode_reward_mean: 1.8386792452830225\n",
      "  episode_reward_min: -2.2199999999999984\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 3006\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.582319697049948\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014526438856344704\n",
      "          policy_loss: -0.057790955503144836\n",
      "          total_loss: 0.1470491826777052\n",
      "          vf_explained_var: 0.7188235521316528\n",
      "          vf_loss: 0.19343366217759683\n",
      "    num_agent_steps_sampled: 289884\n",
      "    num_agent_steps_trained: 289884\n",
      "    num_steps_sampled: 289884\n",
      "    num_steps_trained: 289884\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.71157407407406\n",
      "    ram_util_percent: 42.25555555555556\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048825668668122026\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.66498428129597\n",
      "    mean_inference_ms: 8.52369868920889\n",
      "    mean_raw_obs_processing_ms: 2.2884016912237355\n",
      "  time_since_restore: 8528.876385688782\n",
      "  time_this_iter_s: 302.2938003540039\n",
      "  time_total_s: 8528.876385688782\n",
      "  timers:\n",
      "    learn_throughput: 68.975\n",
      "    learn_time_ms: 144922.496\n",
      "    load_throughput: 89464.356\n",
      "    load_time_ms: 111.732\n",
      "    sample_throughput: 66.364\n",
      "    sample_time_ms: 150624.615\n",
      "    update_time_ms: 10.079\n",
      "  timestamp: 1636909264\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 289884\n",
      "  training_iteration: 29\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         8528.88</td><td style=\"text-align: right;\">289884</td><td style=\"text-align: right;\"> 1.83868</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">           94.1415</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 299880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-05-56\n",
      "  done: false\n",
      "  episode_len_mean: 94.60952380952381\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.810000000000011\n",
      "  episode_reward_mean: 1.920380952380957\n",
      "  episode_reward_min: -1.7000000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3111\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5851261117519475\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014818931295880404\n",
      "          policy_loss: -0.05378797799348831\n",
      "          total_loss: 0.16705890245831165\n",
      "          vf_explained_var: 0.7302387952804565\n",
      "          vf_loss: 0.2087188432383168\n",
      "    num_agent_steps_sampled: 299880\n",
      "    num_agent_steps_trained: 299880\n",
      "    num_steps_sampled: 299880\n",
      "    num_steps_trained: 299880\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.17139423076924\n",
      "    ram_util_percent: 42.28966346153846\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04887167426490818\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.710770948682708\n",
      "    mean_inference_ms: 8.522498275860183\n",
      "    mean_raw_obs_processing_ms: 2.236919320991838\n",
      "  time_since_restore: 8820.881980657578\n",
      "  time_this_iter_s: 292.0055949687958\n",
      "  time_total_s: 8820.881980657578\n",
      "  timers:\n",
      "    learn_throughput: 68.975\n",
      "    learn_time_ms: 144921.83\n",
      "    load_throughput: 89216.204\n",
      "    load_time_ms: 112.042\n",
      "    sample_throughput: 65.967\n",
      "    sample_time_ms: 151530.718\n",
      "    update_time_ms: 10.876\n",
      "  timestamp: 1636909556\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 299880\n",
      "  training_iteration: 30\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         8820.88</td><td style=\"text-align: right;\">299880</td><td style=\"text-align: right;\"> 1.92038</td><td style=\"text-align: right;\">                8.81</td><td style=\"text-align: right;\">                -1.7</td><td style=\"text-align: right;\">           94.6095</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 309876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-11-07\n",
      "  done: false\n",
      "  episode_len_mean: 93.16822429906541\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 2.1513084112149574\n",
      "  episode_reward_min: -1.9000000000000012\n",
      "  episodes_this_iter: 107\n",
      "  episodes_total: 3218\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5808543984706587\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016710962400869445\n",
      "          policy_loss: -0.05846476658510092\n",
      "          total_loss: 0.18203106402761787\n",
      "          vf_explained_var: 0.7445911169052124\n",
      "          vf_loss: 0.22347600632546166\n",
      "    num_agent_steps_sampled: 309876\n",
      "    num_agent_steps_trained: 309876\n",
      "    num_steps_sampled: 309876\n",
      "    num_steps_trained: 309876\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.60743243243243\n",
      "    ram_util_percent: 42.71283783783784\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04886948297200591\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.70361194755933\n",
      "    mean_inference_ms: 8.519236254174105\n",
      "    mean_raw_obs_processing_ms: 2.3009404779474694\n",
      "  time_since_restore: 9132.0304210186\n",
      "  time_this_iter_s: 311.14844036102295\n",
      "  time_total_s: 9132.0304210186\n",
      "  timers:\n",
      "    learn_throughput: 68.974\n",
      "    learn_time_ms: 144923.845\n",
      "    load_throughput: 89312.388\n",
      "    load_time_ms: 111.922\n",
      "    sample_throughput: 65.465\n",
      "    sample_time_ms: 152693.205\n",
      "    update_time_ms: 11.009\n",
      "  timestamp: 1636909867\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 309876\n",
      "  training_iteration: 31\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         9132.03</td><td style=\"text-align: right;\">309876</td><td style=\"text-align: right;\"> 2.15131</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                -1.9</td><td style=\"text-align: right;\">           93.1682</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 319872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-16-08\n",
      "  done: false\n",
      "  episode_len_mean: 94.80952380952381\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.830000000000014\n",
      "  episode_reward_mean: 1.5287619047619085\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3323\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5896173026826648\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014390020027995568\n",
      "          policy_loss: -0.06033985315201183\n",
      "          total_loss: 0.15838939999270008\n",
      "          vf_explained_var: 0.7431181073188782\n",
      "          vf_loss: 0.20774537968393575\n",
      "    num_agent_steps_sampled: 319872\n",
      "    num_agent_steps_trained: 319872\n",
      "    num_steps_sampled: 319872\n",
      "    num_steps_trained: 319872\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.67186046511627\n",
      "    ram_util_percent: 42.386046511627924\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04883839271778385\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.700749947377492\n",
      "    mean_inference_ms: 8.516103906098545\n",
      "    mean_raw_obs_processing_ms: 2.3055876445285786\n",
      "  time_since_restore: 9433.009431362152\n",
      "  time_this_iter_s: 300.97901034355164\n",
      "  time_total_s: 9433.009431362152\n",
      "  timers:\n",
      "    learn_throughput: 68.977\n",
      "    learn_time_ms: 144916.973\n",
      "    load_throughput: 89452.407\n",
      "    load_time_ms: 111.747\n",
      "    sample_throughput: 65.365\n",
      "    sample_time_ms: 152925.043\n",
      "    update_time_ms: 11.778\n",
      "  timestamp: 1636910168\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319872\n",
      "  training_iteration: 32\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         9433.01</td><td style=\"text-align: right;\">319872</td><td style=\"text-align: right;\"> 1.52876</td><td style=\"text-align: right;\">                6.83</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           94.8095</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 329868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-21-05\n",
      "  done: false\n",
      "  episode_len_mean: 95.87619047619047\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.66000000000001\n",
      "  episode_reward_mean: 2.235238095238101\n",
      "  episode_reward_min: -1.9600000000000013\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3428\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5857653080907643\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01626686169534125\n",
      "          policy_loss: -0.057534125109768325\n",
      "          total_loss: 0.16942929432202036\n",
      "          vf_explained_var: 0.7877746820449829\n",
      "          vf_loss: 0.21113088652093567\n",
      "    num_agent_steps_sampled: 329868\n",
      "    num_agent_steps_trained: 329868\n",
      "    num_steps_sampled: 329868\n",
      "    num_steps_trained: 329868\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.76170212765956\n",
      "    ram_util_percent: 42.76548463356973\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04886492532875061\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.68623182503863\n",
      "    mean_inference_ms: 8.515036711779917\n",
      "    mean_raw_obs_processing_ms: 2.30564862022989\n",
      "  time_since_restore: 9729.387799739838\n",
      "  time_this_iter_s: 296.37836837768555\n",
      "  time_total_s: 9729.387799739838\n",
      "  timers:\n",
      "    learn_throughput: 68.976\n",
      "    learn_time_ms: 144920.192\n",
      "    load_throughput: 89718.75\n",
      "    load_time_ms: 111.415\n",
      "    sample_throughput: 64.85\n",
      "    sample_time_ms: 154140.419\n",
      "    update_time_ms: 11.028\n",
      "  timestamp: 1636910465\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 329868\n",
      "  training_iteration: 33\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         9729.39</td><td style=\"text-align: right;\">329868</td><td style=\"text-align: right;\"> 2.23524</td><td style=\"text-align: right;\">                8.66</td><td style=\"text-align: right;\">               -1.96</td><td style=\"text-align: right;\">           95.8762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 339864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-26-12\n",
      "  done: false\n",
      "  episode_len_mean: 94.98095238095237\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.010000000000016\n",
      "  episode_reward_mean: 2.045428571428577\n",
      "  episode_reward_min: -1.7100000000000006\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3533\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.559666298291622\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016356336874932775\n",
      "          policy_loss: -0.062473083486478044\n",
      "          total_loss: 0.15810741582073462\n",
      "          vf_explained_var: 0.7880002856254578\n",
      "          vf_loss: 0.20425766033924417\n",
      "    num_agent_steps_sampled: 339864\n",
      "    num_agent_steps_trained: 339864\n",
      "    num_steps_sampled: 339864\n",
      "    num_steps_trained: 339864\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.96924829157176\n",
      "    ram_util_percent: 43.07152619589978\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04886373229816507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.72632117212596\n",
      "    mean_inference_ms: 8.519628934667146\n",
      "    mean_raw_obs_processing_ms: 2.3081132976695393\n",
      "  time_since_restore: 10037.028620004654\n",
      "  time_this_iter_s: 307.6408202648163\n",
      "  time_total_s: 10037.028620004654\n",
      "  timers:\n",
      "    learn_throughput: 68.863\n",
      "    learn_time_ms: 145158.184\n",
      "    load_throughput: 89599.127\n",
      "    load_time_ms: 111.564\n",
      "    sample_throughput: 64.005\n",
      "    sample_time_ms: 156176.518\n",
      "    update_time_ms: 10.366\n",
      "  timestamp: 1636910772\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 339864\n",
      "  training_iteration: 34\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">           10037</td><td style=\"text-align: right;\">339864</td><td style=\"text-align: right;\"> 2.04543</td><td style=\"text-align: right;\">                9.01</td><td style=\"text-align: right;\">               -1.71</td><td style=\"text-align: right;\">            94.981</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 349860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-31-16\n",
      "  done: false\n",
      "  episode_len_mean: 94.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.450000000000017\n",
      "  episode_reward_mean: 1.8481132075471747\n",
      "  episode_reward_min: -1.980000000000001\n",
      "  episodes_this_iter: 106\n",
      "  episodes_total: 3639\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5613448188855097\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015348474480575422\n",
      "          policy_loss: -0.06234284111569261\n",
      "          total_loss: 0.12560899546389812\n",
      "          vf_explained_var: 0.7819280624389648\n",
      "          vf_loss: 0.1742288253039249\n",
      "    num_agent_steps_sampled: 349860\n",
      "    num_agent_steps_trained: 349860\n",
      "    num_steps_sampled: 349860\n",
      "    num_steps_trained: 349860\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.2189376443418\n",
      "    ram_util_percent: 43.187759815242494\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04886953306167206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.742332007160943\n",
      "    mean_inference_ms: 8.520152108928961\n",
      "    mean_raw_obs_processing_ms: 2.310027608875683\n",
      "  time_since_restore: 10340.603357076645\n",
      "  time_this_iter_s: 303.57473707199097\n",
      "  time_total_s: 10340.603357076645\n",
      "  timers:\n",
      "    learn_throughput: 68.707\n",
      "    learn_time_ms: 145486.316\n",
      "    load_throughput: 89521.052\n",
      "    load_time_ms: 111.661\n",
      "    sample_throughput: 64.548\n",
      "    sample_time_ms: 154861.349\n",
      "    update_time_ms: 11.729\n",
      "  timestamp: 1636911076\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 349860\n",
      "  training_iteration: 35\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         10340.6</td><td style=\"text-align: right;\">349860</td><td style=\"text-align: right;\"> 1.84811</td><td style=\"text-align: right;\">               10.45</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">              94.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 359856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-36-23\n",
      "  done: false\n",
      "  episode_len_mean: 96.14423076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.280000000000017\n",
      "  episode_reward_mean: 2.070480769230775\n",
      "  episode_reward_min: -2.259999999999998\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 3743\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.560037349941384\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01489954991172307\n",
      "          policy_loss: -0.06522251498849632\n",
      "          total_loss: 0.12923692465306091\n",
      "          vf_explained_var: 0.749926745891571\n",
      "          vf_loss: 0.1818738979104365\n",
      "    num_agent_steps_sampled: 359856\n",
      "    num_agent_steps_trained: 359856\n",
      "    num_steps_sampled: 359856\n",
      "    num_steps_trained: 359856\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.02648401826482\n",
      "    ram_util_percent: 43.43401826484019\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04893971521494434\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.76388744562911\n",
      "    mean_inference_ms: 8.530791553235272\n",
      "    mean_raw_obs_processing_ms: 2.3124122605578106\n",
      "  time_since_restore: 10647.575882434845\n",
      "  time_this_iter_s: 306.9725253582001\n",
      "  time_total_s: 10647.575882434845\n",
      "  timers:\n",
      "    learn_throughput: 68.645\n",
      "    learn_time_ms: 145618.675\n",
      "    load_throughput: 89114.183\n",
      "    load_time_ms: 112.171\n",
      "    sample_throughput: 63.592\n",
      "    sample_time_ms: 157190.599\n",
      "    update_time_ms: 12.402\n",
      "  timestamp: 1636911383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 359856\n",
      "  training_iteration: 36\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         10647.6</td><td style=\"text-align: right;\">359856</td><td style=\"text-align: right;\"> 2.07048</td><td style=\"text-align: right;\">               10.28</td><td style=\"text-align: right;\">               -2.26</td><td style=\"text-align: right;\">           96.1442</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 369852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-41-26\n",
      "  done: false\n",
      "  episode_len_mean: 95.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.750000000000018\n",
      "  episode_reward_mean: 2.5010476190476245\n",
      "  episode_reward_min: -1.7300000000000009\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 3848\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5612338684562945\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016568342916479\n",
      "          policy_loss: -0.06030153909729969\n",
      "          total_loss: 0.1614219836365336\n",
      "          vf_explained_var: 0.8153680562973022\n",
      "          vf_loss: 0.2048730126924367\n",
      "    num_agent_steps_sampled: 369852\n",
      "    num_agent_steps_trained: 369852\n",
      "    num_steps_sampled: 369852\n",
      "    num_steps_trained: 369852\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.38240740740741\n",
      "    ram_util_percent: 43.244675925925925\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.048943513906673584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.78717497354928\n",
      "    mean_inference_ms: 8.531339777946869\n",
      "    mean_raw_obs_processing_ms: 2.3179296092133823\n",
      "  time_since_restore: 10950.859977722168\n",
      "  time_this_iter_s: 303.284095287323\n",
      "  time_total_s: 10950.859977722168\n",
      "  timers:\n",
      "    learn_throughput: 68.613\n",
      "    learn_time_ms: 145687.649\n",
      "    load_throughput: 89176.221\n",
      "    load_time_ms: 112.093\n",
      "    sample_throughput: 63.935\n",
      "    sample_time_ms: 156347.379\n",
      "    update_time_ms: 12.726\n",
      "  timestamp: 1636911686\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 369852\n",
      "  training_iteration: 37\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         10950.9</td><td style=\"text-align: right;\">369852</td><td style=\"text-align: right;\"> 2.50105</td><td style=\"text-align: right;\">               12.75</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">                95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 379848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-46-27\n",
      "  done: false\n",
      "  episode_len_mean: 96.09615384615384\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.300000000000017\n",
      "  episode_reward_mean: 2.296923076923083\n",
      "  episode_reward_min: -2.0200000000000005\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 3952\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5830588850200686\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015432534270562591\n",
      "          policy_loss: -0.058273292255675437\n",
      "          total_loss: 0.15640810851791762\n",
      "          vf_explained_var: 0.8080220222473145\n",
      "          vf_loss: 0.20096009283676808\n",
      "    num_agent_steps_sampled: 379848\n",
      "    num_agent_steps_trained: 379848\n",
      "    num_steps_sampled: 379848\n",
      "    num_steps_trained: 379848\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.34139534883721\n",
      "    ram_util_percent: 43.47488372093022\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04895877933254744\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.77223478677487\n",
      "    mean_inference_ms: 8.533109157277158\n",
      "    mean_raw_obs_processing_ms: 2.3174960746591067\n",
      "  time_since_restore: 11251.740082979202\n",
      "  time_this_iter_s: 300.8801052570343\n",
      "  time_total_s: 11251.740082979202\n",
      "  timers:\n",
      "    learn_throughput: 68.43\n",
      "    learn_time_ms: 146075.219\n",
      "    load_throughput: 88389.394\n",
      "    load_time_ms: 113.09\n",
      "    sample_throughput: 63.955\n",
      "    sample_time_ms: 156297.771\n",
      "    update_time_ms: 11.561\n",
      "  timestamp: 1636911987\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 379848\n",
      "  training_iteration: 38\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         11251.7</td><td style=\"text-align: right;\">379848</td><td style=\"text-align: right;\"> 2.29692</td><td style=\"text-align: right;\">                10.3</td><td style=\"text-align: right;\">               -2.02</td><td style=\"text-align: right;\">           96.0962</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 389844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-51-29\n",
      "  done: false\n",
      "  episode_len_mean: 97.25242718446601\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.610000000000017\n",
      "  episode_reward_mean: 1.9056310679611708\n",
      "  episode_reward_min: -2.149999999999998\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4055\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.583685732091594\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015040750830955197\n",
      "          policy_loss: -0.0636506521055459\n",
      "          total_loss: 0.13192660332076314\n",
      "          vf_explained_var: 0.7843947410583496\n",
      "          vf_loss: 0.18286631515520252\n",
      "    num_agent_steps_sampled: 389844\n",
      "    num_agent_steps_trained: 389844\n",
      "    num_steps_sampled: 389844\n",
      "    num_steps_trained: 389844\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.3306976744186\n",
      "    ram_util_percent: 43.78697674418605\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04899847505105046\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.745378971826778\n",
      "    mean_inference_ms: 8.53316606419393\n",
      "    mean_raw_obs_processing_ms: 2.319049221778193\n",
      "  time_since_restore: 11553.516698598862\n",
      "  time_this_iter_s: 301.7766156196594\n",
      "  time_total_s: 11553.516698598862\n",
      "  timers:\n",
      "    learn_throughput: 68.22\n",
      "    learn_time_ms: 146526.816\n",
      "    load_throughput: 88181.775\n",
      "    load_time_ms: 113.357\n",
      "    sample_throughput: 64.162\n",
      "    sample_time_ms: 155793.606\n",
      "    update_time_ms: 12.197\n",
      "  timestamp: 1636912289\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 389844\n",
      "  training_iteration: 39\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         11553.5</td><td style=\"text-align: right;\">389844</td><td style=\"text-align: right;\"> 1.90563</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">               -2.15</td><td style=\"text-align: right;\">           97.2524</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 399840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_17-56-31\n",
      "  done: false\n",
      "  episode_len_mean: 96.0673076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.610000000000014\n",
      "  episode_reward_mean: 1.513173076923081\n",
      "  episode_reward_min: -2.079999999999999\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 4159\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.588281627903637\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013877036709522603\n",
      "          policy_loss: -0.06546299894873658\n",
      "          total_loss: 0.11415193341990822\n",
      "          vf_explained_var: 0.7516317367553711\n",
      "          vf_loss: 0.16993242299550365\n",
      "    num_agent_steps_sampled: 399840\n",
      "    num_agent_steps_trained: 399840\n",
      "    num_steps_sampled: 399840\n",
      "    num_steps_trained: 399840\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.81716937354987\n",
      "    ram_util_percent: 44.12088167053364\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04906340501891292\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.741606909159408\n",
      "    mean_inference_ms: 8.536938655470644\n",
      "    mean_raw_obs_processing_ms: 2.3719442956157413\n",
      "  time_since_restore: 11855.142507314682\n",
      "  time_this_iter_s: 301.6258087158203\n",
      "  time_total_s: 11855.142507314682\n",
      "  timers:\n",
      "    learn_throughput: 68.207\n",
      "    learn_time_ms: 146554.299\n",
      "    load_throughput: 87948.0\n",
      "    load_time_ms: 113.658\n",
      "    sample_throughput: 63.779\n",
      "    sample_time_ms: 156728.865\n",
      "    update_time_ms: 11.395\n",
      "  timestamp: 1636912591\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 399840\n",
      "  training_iteration: 40\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         11855.1</td><td style=\"text-align: right;\">399840</td><td style=\"text-align: right;\"> 1.51317</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">               -2.08</td><td style=\"text-align: right;\">           96.0673</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 409836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-01-29\n",
      "  done: false\n",
      "  episode_len_mean: 95.66666666666667\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.10000000000001\n",
      "  episode_reward_mean: 2.126857142857147\n",
      "  episode_reward_min: -2.1199999999999983\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 4264\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5762263618982755\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015821370600555343\n",
      "          policy_loss: -0.0641740671528153\n",
      "          total_loss: 0.12568211444597852\n",
      "          vf_explained_var: 0.8009827136993408\n",
      "          vf_loss: 0.17507000355503688\n",
      "    num_agent_steps_sampled: 409836\n",
      "    num_agent_steps_trained: 409836\n",
      "    num_steps_sampled: 409836\n",
      "    num_steps_trained: 409836\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.75835294117648\n",
      "    ram_util_percent: 43.86070588235294\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04906840319337418\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.723959688729735\n",
      "    mean_inference_ms: 8.536454108287314\n",
      "    mean_raw_obs_processing_ms: 2.3692361642927566\n",
      "  time_since_restore: 12153.170394659042\n",
      "  time_this_iter_s: 298.02788734436035\n",
      "  time_total_s: 12153.170394659042\n",
      "  timers:\n",
      "    learn_throughput: 68.195\n",
      "    learn_time_ms: 146580.259\n",
      "    load_throughput: 87903.911\n",
      "    load_time_ms: 113.715\n",
      "    sample_throughput: 64.328\n",
      "    sample_time_ms: 155390.816\n",
      "    update_time_ms: 11.594\n",
      "  timestamp: 1636912889\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 409836\n",
      "  training_iteration: 41\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         12153.2</td><td style=\"text-align: right;\">409836</td><td style=\"text-align: right;\"> 2.12686</td><td style=\"text-align: right;\">                11.1</td><td style=\"text-align: right;\">               -2.12</td><td style=\"text-align: right;\">           95.6667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 419832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-06-20\n",
      "  done: false\n",
      "  episode_len_mean: 98.89108910891089\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.680000000000014\n",
      "  episode_reward_mean: 1.9891089108910942\n",
      "  episode_reward_min: -2.0700000000000007\n",
      "  episodes_this_iter: 101\n",
      "  episodes_total: 4365\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5894092527210204\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015754456086417484\n",
      "          policy_loss: -0.06015002717518717\n",
      "          total_loss: 0.13434963416483284\n",
      "          vf_explained_var: 0.7770410776138306\n",
      "          vf_loss: 0.18001680749221743\n",
      "    num_agent_steps_sampled: 419832\n",
      "    num_agent_steps_trained: 419832\n",
      "    num_steps_sampled: 419832\n",
      "    num_steps_trained: 419832\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.51514423076922\n",
      "    ram_util_percent: 43.46346153846154\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049064538878324813\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.736112108972566\n",
      "    mean_inference_ms: 8.543317799201654\n",
      "    mean_raw_obs_processing_ms: 2.3324786821976957\n",
      "  time_since_restore: 12444.801079750061\n",
      "  time_this_iter_s: 291.6306850910187\n",
      "  time_total_s: 12444.801079750061\n",
      "  timers:\n",
      "    learn_throughput: 67.981\n",
      "    learn_time_ms: 147041.741\n",
      "    load_throughput: 87615.085\n",
      "    load_time_ms: 114.09\n",
      "    sample_throughput: 64.91\n",
      "    sample_time_ms: 153996.7\n",
      "    update_time_ms: 11.061\n",
      "  timestamp: 1636913180\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 419832\n",
      "  training_iteration: 42\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         12444.8</td><td style=\"text-align: right;\">419832</td><td style=\"text-align: right;\"> 1.98911</td><td style=\"text-align: right;\">                8.68</td><td style=\"text-align: right;\">               -2.07</td><td style=\"text-align: right;\">           98.8911</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 429828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-11-11\n",
      "  done: false\n",
      "  episode_len_mean: 97.96078431372548\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.490000000000016\n",
      "  episode_reward_mean: 1.9486274509803974\n",
      "  episode_reward_min: -1.980000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 4467\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5749557081450765\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014576571356247278\n",
      "          policy_loss: -0.06364019793243363\n",
      "          total_loss: 0.11612465370756885\n",
      "          vf_explained_var: 0.8113839626312256\n",
      "          vf_loss: 0.16815625105658147\n",
      "    num_agent_steps_sampled: 429828\n",
      "    num_agent_steps_trained: 429828\n",
      "    num_steps_sampled: 429828\n",
      "    num_steps_trained: 429828\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.30337349397591\n",
      "    ram_util_percent: 43.53180722891565\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04909534211129701\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.747533177282566\n",
      "    mean_inference_ms: 8.547709964209842\n",
      "    mean_raw_obs_processing_ms: 2.2950724280810078\n",
      "  time_since_restore: 12735.39778828621\n",
      "  time_this_iter_s: 290.59670853614807\n",
      "  time_total_s: 12735.39778828621\n",
      "  timers:\n",
      "    learn_throughput: 67.833\n",
      "    learn_time_ms: 147362.717\n",
      "    load_throughput: 87441.619\n",
      "    load_time_ms: 114.316\n",
      "    sample_throughput: 65.292\n",
      "    sample_time_ms: 153096.33\n",
      "    update_time_ms: 11.671\n",
      "  timestamp: 1636913471\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 429828\n",
      "  training_iteration: 43\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         12735.4</td><td style=\"text-align: right;\">429828</td><td style=\"text-align: right;\"> 1.94863</td><td style=\"text-align: right;\">               10.49</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           97.9608</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 439824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-16-49\n",
      "  done: false\n",
      "  episode_len_mean: 94.95192307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.660000000000014\n",
      "  episode_reward_mean: 2.071250000000005\n",
      "  episode_reward_min: -2.219999999999998\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 4571\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5755681451569257\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015923553186511327\n",
      "          policy_loss: -0.06246066974798361\n",
      "          total_loss: 0.1371981978870164\n",
      "          vf_explained_var: 0.7613310813903809\n",
      "          vf_loss: 0.18460422446712468\n",
      "    num_agent_steps_sampled: 439824\n",
      "    num_agent_steps_trained: 439824\n",
      "    num_steps_sampled: 439824\n",
      "    num_steps_trained: 439824\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.38856548856549\n",
      "    ram_util_percent: 44.80270270270271\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04914223068893068\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.792684726372542\n",
      "    mean_inference_ms: 8.557731930760403\n",
      "    mean_raw_obs_processing_ms: 2.372697059994338\n",
      "  time_since_restore: 13073.037734508514\n",
      "  time_this_iter_s: 337.6399462223053\n",
      "  time_total_s: 13073.037734508514\n",
      "  timers:\n",
      "    learn_throughput: 67.369\n",
      "    learn_time_ms: 148376.064\n",
      "    load_throughput: 87426.011\n",
      "    load_time_ms: 114.337\n",
      "    sample_throughput: 64.456\n",
      "    sample_time_ms: 155082.881\n",
      "    update_time_ms: 11.666\n",
      "  timestamp: 1636913809\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 439824\n",
      "  training_iteration: 44\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">           13073</td><td style=\"text-align: right;\">439824</td><td style=\"text-align: right;\"> 2.07125</td><td style=\"text-align: right;\">               12.66</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">           94.9519</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 449820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-21-50\n",
      "  done: false\n",
      "  episode_len_mean: 98.46601941747574\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.680000000000016\n",
      "  episode_reward_mean: 2.037281553398064\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4674\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5734053449753005\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014926903928372641\n",
      "          policy_loss: -0.06521144844949818\n",
      "          total_loss: 0.11814858285256494\n",
      "          vf_explained_var: 0.7864267230033875\n",
      "          vf_loss: 0.17083806361223006\n",
      "    num_agent_steps_sampled: 449820\n",
      "    num_agent_steps_trained: 449820\n",
      "    num_steps_sampled: 449820\n",
      "    num_steps_trained: 449820\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 93.01832946635732\n",
      "    ram_util_percent: 45.44849187935035\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04918925606922543\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.82332653715503\n",
      "    mean_inference_ms: 8.569207988596082\n",
      "    mean_raw_obs_processing_ms: 2.338250950728623\n",
      "  time_since_restore: 13374.862491607666\n",
      "  time_this_iter_s: 301.8247570991516\n",
      "  time_total_s: 13374.862491607666\n",
      "  timers:\n",
      "    learn_throughput: 67.03\n",
      "    learn_time_ms: 149128.314\n",
      "    load_throughput: 87286.117\n",
      "    load_time_ms: 114.52\n",
      "    sample_throughput: 64.843\n",
      "    sample_time_ms: 154156.092\n",
      "    update_time_ms: 11.253\n",
      "  timestamp: 1636914110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 449820\n",
      "  training_iteration: 45\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         13374.9</td><td style=\"text-align: right;\">449820</td><td style=\"text-align: right;\"> 2.03728</td><td style=\"text-align: right;\">               10.68</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">            98.466</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 459816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-27-04\n",
      "  done: false\n",
      "  episode_len_mean: 96.67961165048544\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.010000000000012\n",
      "  episode_reward_mean: 2.4835922330097144\n",
      "  episode_reward_min: -1.880000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4777\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5662724315610705\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016925706331568768\n",
      "          policy_loss: -0.06522116734622381\n",
      "          total_loss: 0.1492521928722819\n",
      "          vf_explained_var: 0.7851283550262451\n",
      "          vf_loss: 0.1967573508524742\n",
      "    num_agent_steps_sampled: 459816\n",
      "    num_agent_steps_trained: 459816\n",
      "    num_steps_sampled: 459816\n",
      "    num_steps_trained: 459816\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.04933035714285\n",
      "    ram_util_percent: 45.75825892857143\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04919899375624564\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.83953056126168\n",
      "    mean_inference_ms: 8.577840832410129\n",
      "    mean_raw_obs_processing_ms: 2.3440752378743097\n",
      "  time_since_restore: 13688.77789402008\n",
      "  time_this_iter_s: 313.91540241241455\n",
      "  time_total_s: 13688.77789402008\n",
      "  timers:\n",
      "    learn_throughput: 66.682\n",
      "    learn_time_ms: 149904.997\n",
      "    load_throughput: 87533.1\n",
      "    load_time_ms: 114.197\n",
      "    sample_throughput: 64.877\n",
      "    sample_time_ms: 154075.936\n",
      "    update_time_ms: 10.054\n",
      "  timestamp: 1636914424\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 459816\n",
      "  training_iteration: 46\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         13688.8</td><td style=\"text-align: right;\">459816</td><td style=\"text-align: right;\"> 2.48359</td><td style=\"text-align: right;\">               11.01</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           96.6796</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 469812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-32-27\n",
      "  done: false\n",
      "  episode_len_mean: 96.80582524271844\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.419999999999963\n",
      "  episode_reward_mean: 1.8071844660194212\n",
      "  episode_reward_min: -1.730000000000001\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4880\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.56159122693233\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016070698658833087\n",
      "          policy_loss: -0.06289070767119655\n",
      "          total_loss: 0.1547669149748185\n",
      "          vf_explained_var: 0.781723141670227\n",
      "          vf_loss: 0.20208609324609303\n",
      "    num_agent_steps_sampled: 469812\n",
      "    num_agent_steps_trained: 469812\n",
      "    num_steps_sampled: 469812\n",
      "    num_steps_trained: 469812\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.62152173913044\n",
      "    ram_util_percent: 45.963478260869564\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049254439897742704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.864394519960527\n",
      "    mean_inference_ms: 8.587617053691215\n",
      "    mean_raw_obs_processing_ms: 2.349871853557815\n",
      "  time_since_restore: 14010.928398132324\n",
      "  time_this_iter_s: 322.15050411224365\n",
      "  time_total_s: 14010.928398132324\n",
      "  timers:\n",
      "    learn_throughput: 66.032\n",
      "    learn_time_ms: 151380.126\n",
      "    load_throughput: 86571.244\n",
      "    load_time_ms: 115.466\n",
      "    sample_throughput: 64.705\n",
      "    sample_time_ms: 154486.345\n",
      "    update_time_ms: 9.619\n",
      "  timestamp: 1636914747\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 469812\n",
      "  training_iteration: 47\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         14010.9</td><td style=\"text-align: right;\">469812</td><td style=\"text-align: right;\"> 1.80718</td><td style=\"text-align: right;\">               16.42</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           96.8058</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 479808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-37-56\n",
      "  done: false\n",
      "  episode_len_mean: 96.96116504854369\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.470000000000013\n",
      "  episode_reward_mean: 2.2660194174757335\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 4983\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.568333717696687\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016492835037834486\n",
      "          policy_loss: -0.0642034399163965\n",
      "          total_loss: 0.14482020382554486\n",
      "          vf_explained_var: 0.7662680149078369\n",
      "          vf_loss: 0.19243764904622213\n",
      "    num_agent_steps_sampled: 479808\n",
      "    num_agent_steps_trained: 479808\n",
      "    num_steps_sampled: 479808\n",
      "    num_steps_trained: 479808\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.2456289978678\n",
      "    ram_util_percent: 46.30852878464819\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04932749645386349\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.898503397627103\n",
      "    mean_inference_ms: 8.603761304600464\n",
      "    mean_raw_obs_processing_ms: 2.401105200894955\n",
      "  time_since_restore: 14339.851336479187\n",
      "  time_this_iter_s: 328.9229383468628\n",
      "  time_total_s: 14339.851336479187\n",
      "  timers:\n",
      "    learn_throughput: 65.695\n",
      "    learn_time_ms: 152158.575\n",
      "    load_throughput: 86023.395\n",
      "    load_time_ms: 116.201\n",
      "    sample_throughput: 63.868\n",
      "    sample_time_ms: 156510.144\n",
      "    update_time_ms: 8.843\n",
      "  timestamp: 1636915076\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 479808\n",
      "  training_iteration: 48\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         14339.9</td><td style=\"text-align: right;\">479808</td><td style=\"text-align: right;\"> 2.26602</td><td style=\"text-align: right;\">               10.47</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">           96.9612</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 489804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-42-56\n",
      "  done: false\n",
      "  episode_len_mean: 96.64423076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.420000000000012\n",
      "  episode_reward_mean: 2.8210576923076993\n",
      "  episode_reward_min: -2.0099999999999993\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 5087\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.555722782652602\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015873147133034112\n",
      "          policy_loss: -0.06911472527222692\n",
      "          total_loss: 0.11072130407421635\n",
      "          vf_explained_var: 0.8455419540405273\n",
      "          vf_loss: 0.16471211756300977\n",
      "    num_agent_steps_sampled: 489804\n",
      "    num_agent_steps_trained: 489804\n",
      "    num_steps_sampled: 489804\n",
      "    num_steps_trained: 489804\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.77943925233645\n",
      "    ram_util_percent: 44.48855140186915\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04935811786897092\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.92580082091255\n",
      "    mean_inference_ms: 8.610785251526229\n",
      "    mean_raw_obs_processing_ms: 2.366434419479308\n",
      "  time_since_restore: 14639.873039960861\n",
      "  time_this_iter_s: 300.0217034816742\n",
      "  time_total_s: 14639.873039960861\n",
      "  timers:\n",
      "    learn_throughput: 65.462\n",
      "    learn_time_ms: 152698.632\n",
      "    load_throughput: 85952.94\n",
      "    load_time_ms: 116.296\n",
      "    sample_throughput: 64.161\n",
      "    sample_time_ms: 155794.565\n",
      "    update_time_ms: 8.273\n",
      "  timestamp: 1636915376\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 489804\n",
      "  training_iteration: 49\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         14639.9</td><td style=\"text-align: right;\">489804</td><td style=\"text-align: right;\"> 2.82106</td><td style=\"text-align: right;\">               12.42</td><td style=\"text-align: right;\">               -2.01</td><td style=\"text-align: right;\">           96.6442</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 499800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-47-52\n",
      "  done: false\n",
      "  episode_len_mean: 99.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.490000000000016\n",
      "  episode_reward_mean: 2.142900000000006\n",
      "  episode_reward_min: -1.830000000000001\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 5187\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.56054032765902\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01662307405462549\n",
      "          policy_loss: -0.06482438477767138\n",
      "          total_loss: 0.14611082546389065\n",
      "          vf_explained_var: 0.8170629739761353\n",
      "          vf_loss: 0.1939374939005217\n",
      "    num_agent_steps_sampled: 499800\n",
      "    num_agent_steps_trained: 499800\n",
      "    num_steps_sampled: 499800\n",
      "    num_steps_trained: 499800\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.5175355450237\n",
      "    ram_util_percent: 44.31184834123222\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0494112132181651\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.933962959389472\n",
      "    mean_inference_ms: 8.616737696864897\n",
      "    mean_raw_obs_processing_ms: 2.33184442216124\n",
      "  time_since_restore: 14935.961206674576\n",
      "  time_this_iter_s: 296.0881667137146\n",
      "  time_total_s: 14935.961206674576\n",
      "  timers:\n",
      "    learn_throughput: 65.125\n",
      "    learn_time_ms: 153490.586\n",
      "    load_throughput: 86311.15\n",
      "    load_time_ms: 115.814\n",
      "    sample_throughput: 64.72\n",
      "    sample_time_ms: 154448.833\n",
      "    update_time_ms: 8.853\n",
      "  timestamp: 1636915672\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 499800\n",
      "  training_iteration: 50\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">           14936</td><td style=\"text-align: right;\">499800</td><td style=\"text-align: right;\">  2.1429</td><td style=\"text-align: right;\">                8.49</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">             99.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 509796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-53-15\n",
      "  done: false\n",
      "  episode_len_mean: 94.64761904761905\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.9000000000000155\n",
      "  episode_reward_mean: 1.6574285714285755\n",
      "  episode_reward_min: -1.9800000000000009\n",
      "  episodes_this_iter: 105\n",
      "  episodes_total: 5292\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5728517648501272\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015414993540687138\n",
      "          policy_loss: -0.06842817571252967\n",
      "          total_loss: 0.12108448853210793\n",
      "          vf_explained_var: 0.7387208938598633\n",
      "          vf_loss: 0.17573424040212526\n",
      "    num_agent_steps_sampled: 509796\n",
      "    num_agent_steps_trained: 509796\n",
      "    num_steps_sampled: 509796\n",
      "    num_steps_trained: 509796\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.67960954446855\n",
      "    ram_util_percent: 44.41496746203904\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049437682517371836\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.921063051859328\n",
      "    mean_inference_ms: 8.61918033738965\n",
      "    mean_raw_obs_processing_ms: 2.4034203493126176\n",
      "  time_since_restore: 15259.108875751495\n",
      "  time_this_iter_s: 323.14766907691956\n",
      "  time_total_s: 15259.108875751495\n",
      "  timers:\n",
      "    learn_throughput: 64.779\n",
      "    learn_time_ms: 154309.68\n",
      "    load_throughput: 86625.047\n",
      "    load_time_ms: 115.394\n",
      "    sample_throughput: 64.019\n",
      "    sample_time_ms: 156142.006\n",
      "    update_time_ms: 8.85\n",
      "  timestamp: 1636915995\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 509796\n",
      "  training_iteration: 51\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         15259.1</td><td style=\"text-align: right;\">509796</td><td style=\"text-align: right;\"> 1.65743</td><td style=\"text-align: right;\">                 6.9</td><td style=\"text-align: right;\">               -1.98</td><td style=\"text-align: right;\">           94.6476</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 519792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_18-58-46\n",
      "  done: false\n",
      "  episode_len_mean: 97.41176470588235\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.060000000000013\n",
      "  episode_reward_mean: 2.326764705882358\n",
      "  episode_reward_min: -1.790000000000001\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 5394\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5635588821182904\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01670597467390989\n",
      "          policy_loss: -0.06633417455750143\n",
      "          total_loss: 0.12356031411924423\n",
      "          vf_explained_var: 0.7999658584594727\n",
      "          vf_loss: 0.1727144927618245\n",
      "    num_agent_steps_sampled: 519792\n",
      "    num_agent_steps_trained: 519792\n",
      "    num_steps_sampled: 519792\n",
      "    num_steps_trained: 519792\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.09386892177591\n",
      "    ram_util_percent: 44.61416490486258\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049483756821304174\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.888021883374293\n",
      "    mean_inference_ms: 8.619275987382176\n",
      "    mean_raw_obs_processing_ms: 2.46256475734667\n",
      "  time_since_restore: 15590.235189676285\n",
      "  time_this_iter_s: 331.12631392478943\n",
      "  time_total_s: 15590.235189676285\n",
      "  timers:\n",
      "    learn_throughput: 64.625\n",
      "    learn_time_ms: 154677.801\n",
      "    load_throughput: 86932.618\n",
      "    load_time_ms: 114.986\n",
      "    sample_throughput: 62.583\n",
      "    sample_time_ms: 159723.743\n",
      "    update_time_ms: 8.632\n",
      "  timestamp: 1636916326\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 519792\n",
      "  training_iteration: 52\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         15590.2</td><td style=\"text-align: right;\">519792</td><td style=\"text-align: right;\"> 2.32676</td><td style=\"text-align: right;\">               11.06</td><td style=\"text-align: right;\">               -1.79</td><td style=\"text-align: right;\">           97.4118</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 529788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-03-44\n",
      "  done: false\n",
      "  episode_len_mean: 97.47572815533981\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.100000000000012\n",
      "  episode_reward_mean: 1.8826213592233056\n",
      "  episode_reward_min: -1.9400000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 5497\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5643992714392834\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01694179143524277\n",
      "          policy_loss: -0.0630826420421338\n",
      "          total_loss: 0.1367810504273193\n",
      "          vf_explained_var: 0.8140629529953003\n",
      "          vf_loss: 0.18208772794216171\n",
      "    num_agent_steps_sampled: 529788\n",
      "    num_agent_steps_trained: 529788\n",
      "    num_steps_sampled: 529788\n",
      "    num_steps_trained: 529788\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.52729411764706\n",
      "    ram_util_percent: 44.23223529411764\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049524567847285296\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.903917519596565\n",
      "    mean_inference_ms: 8.624880884040344\n",
      "    mean_raw_obs_processing_ms: 2.4252548229216804\n",
      "  time_since_restore: 15888.032472133636\n",
      "  time_this_iter_s: 297.7972824573517\n",
      "  time_total_s: 15888.032472133636\n",
      "  timers:\n",
      "    learn_throughput: 64.394\n",
      "    learn_time_ms: 155232.228\n",
      "    load_throughput: 87308.529\n",
      "    load_time_ms: 114.491\n",
      "    sample_throughput: 62.518\n",
      "    sample_time_ms: 159889.862\n",
      "    update_time_ms: 8.835\n",
      "  timestamp: 1636916624\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 529788\n",
      "  training_iteration: 53\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">           15888</td><td style=\"text-align: right;\">529788</td><td style=\"text-align: right;\"> 1.88262</td><td style=\"text-align: right;\">                 9.1</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           97.4757</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 539784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-08-40\n",
      "  done: false\n",
      "  episode_len_mean: 99.01960784313725\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.250000000000016\n",
      "  episode_reward_mean: 2.2787254901960847\n",
      "  episode_reward_min: -1.7200000000000009\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 5599\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5650242653667417\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015093052584488913\n",
      "          policy_loss: -0.07204266106908838\n",
      "          total_loss: 0.09134344308175402\n",
      "          vf_explained_var: 0.8394483327865601\n",
      "          vf_loss: 0.15035450451800392\n",
      "    num_agent_steps_sampled: 539784\n",
      "    num_agent_steps_trained: 539784\n",
      "    num_steps_sampled: 539784\n",
      "    num_steps_trained: 539784\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.52962085308057\n",
      "    ram_util_percent: 44.01753554502369\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049550848789506004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.91153129139135\n",
      "    mean_inference_ms: 8.629089182713464\n",
      "    mean_raw_obs_processing_ms: 2.3989403776454465\n",
      "  time_since_restore: 16184.078197956085\n",
      "  time_this_iter_s: 296.04572582244873\n",
      "  time_total_s: 16184.078197956085\n",
      "  timers:\n",
      "    learn_throughput: 64.558\n",
      "    learn_time_ms: 154838.244\n",
      "    load_throughput: 87303.62\n",
      "    load_time_ms: 114.497\n",
      "    sample_throughput: 64.026\n",
      "    sample_time_ms: 156124.158\n",
      "    update_time_ms: 8.862\n",
      "  timestamp: 1636916920\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 539784\n",
      "  training_iteration: 54\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         16184.1</td><td style=\"text-align: right;\">539784</td><td style=\"text-align: right;\"> 2.27873</td><td style=\"text-align: right;\">               10.25</td><td style=\"text-align: right;\">               -1.72</td><td style=\"text-align: right;\">           99.0196</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 549780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-13-50\n",
      "  done: false\n",
      "  episode_len_mean: 95.25961538461539\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.240000000000014\n",
      "  episode_reward_mean: 1.8837500000000058\n",
      "  episode_reward_min: -2.11\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 5703\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5664462346297046\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016794230592454523\n",
      "          policy_loss: -0.07028174814171134\n",
      "          total_loss: 0.11398230192219663\n",
      "          vf_explained_var: 0.8116009831428528\n",
      "          vf_loss: 0.16688673812617413\n",
      "    num_agent_steps_sampled: 549780\n",
      "    num_agent_steps_trained: 549780\n",
      "    num_steps_sampled: 549780\n",
      "    num_steps_trained: 549780\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.03755656108596\n",
      "    ram_util_percent: 44.42986425339367\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049548856152048584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.90868090438702\n",
      "    mean_inference_ms: 8.632359303178674\n",
      "    mean_raw_obs_processing_ms: 2.4306582868327813\n",
      "  time_since_restore: 16493.66888666153\n",
      "  time_this_iter_s: 309.59068870544434\n",
      "  time_total_s: 16493.66888666153\n",
      "  timers:\n",
      "    learn_throughput: 64.686\n",
      "    learn_time_ms: 154532.297\n",
      "    load_throughput: 87620.194\n",
      "    load_time_ms: 114.083\n",
      "    sample_throughput: 63.584\n",
      "    sample_time_ms: 157209.402\n",
      "    update_time_ms: 7.888\n",
      "  timestamp: 1636917230\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 549780\n",
      "  training_iteration: 55\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         16493.7</td><td style=\"text-align: right;\">549780</td><td style=\"text-align: right;\"> 1.88375</td><td style=\"text-align: right;\">                7.24</td><td style=\"text-align: right;\">               -2.11</td><td style=\"text-align: right;\">           95.2596</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 559776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-19-03\n",
      "  done: false\n",
      "  episode_len_mean: 95.75961538461539\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.310000000000016\n",
      "  episode_reward_mean: 2.2206730769230827\n",
      "  episode_reward_min: -1.9400000000000013\n",
      "  episodes_this_iter: 104\n",
      "  episodes_total: 5807\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.570980368822049\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01622199195330858\n",
      "          policy_loss: -0.06567862729987718\n",
      "          total_loss: 0.11127333860629453\n",
      "          vf_explained_var: 0.8532184958457947\n",
      "          vf_loss: 0.16108658016125998\n",
      "    num_agent_steps_sampled: 559776\n",
      "    num_agent_steps_trained: 559776\n",
      "    num_steps_sampled: 559776\n",
      "    num_steps_trained: 559776\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.03803131991052\n",
      "    ram_util_percent: 44.8986577181208\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.049559445519021625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.924850294371446\n",
      "    mean_inference_ms: 8.635216354205518\n",
      "    mean_raw_obs_processing_ms: 2.4307190862833967\n",
      "  time_since_restore: 16807.177783489227\n",
      "  time_this_iter_s: 313.50889682769775\n",
      "  time_total_s: 16807.177783489227\n",
      "  timers:\n",
      "    learn_throughput: 64.709\n",
      "    learn_time_ms: 154476.728\n",
      "    load_throughput: 87290.933\n",
      "    load_time_ms: 114.514\n",
      "    sample_throughput: 63.578\n",
      "    sample_time_ms: 157223.176\n",
      "    update_time_ms: 8.458\n",
      "  timestamp: 1636917543\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 559776\n",
      "  training_iteration: 56\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         16807.2</td><td style=\"text-align: right;\">559776</td><td style=\"text-align: right;\"> 2.22067</td><td style=\"text-align: right;\">               10.31</td><td style=\"text-align: right;\">               -1.94</td><td style=\"text-align: right;\">           95.7596</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 569772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-24-16\n",
      "  done: false\n",
      "  episode_len_mean: 98.33980582524272\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.800000000000015\n",
      "  episode_reward_mean: 2.0951456310679664\n",
      "  episode_reward_min: -1.8800000000000012\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 5910\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5658853833491984\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01619378611772238\n",
      "          policy_loss: -0.06474879480516299\n",
      "          total_loss: 0.1200120730795221\n",
      "          vf_explained_var: 0.7873438000679016\n",
      "          vf_loss: 0.16891682003107336\n",
      "    num_agent_steps_sampled: 569772\n",
      "    num_agent_steps_trained: 569772\n",
      "    num_steps_sampled: 569772\n",
      "    num_steps_trained: 569772\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.05739910313903\n",
      "    ram_util_percent: 44.94663677130043\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0495489710393506\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.93868799466182\n",
      "    mean_inference_ms: 8.637309900573626\n",
      "    mean_raw_obs_processing_ms: 2.4297802460926543\n",
      "  time_since_restore: 17119.756508350372\n",
      "  time_this_iter_s: 312.578724861145\n",
      "  time_total_s: 17119.756508350372\n",
      "  timers:\n",
      "    learn_throughput: 65.009\n",
      "    learn_time_ms: 153763.354\n",
      "    load_throughput: 88256.935\n",
      "    load_time_ms: 113.26\n",
      "    sample_throughput: 63.677\n",
      "    sample_time_ms: 156980.415\n",
      "    update_time_ms: 8.586\n",
      "  timestamp: 1636917856\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 569772\n",
      "  training_iteration: 57\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         17119.8</td><td style=\"text-align: right;\">569772</td><td style=\"text-align: right;\"> 2.09515</td><td style=\"text-align: right;\">                12.8</td><td style=\"text-align: right;\">               -1.88</td><td style=\"text-align: right;\">           98.3398</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154349)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 579768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-29-31\n",
      "  done: false\n",
      "  episode_len_mean: 95.54368932038835\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.620000000000017\n",
      "  episode_reward_mean: 2.3000970873786466\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 6013\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5499601354965797\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015548596245024046\n",
      "          policy_loss: -0.06934854329452236\n",
      "          total_loss: 0.09234743708720765\n",
      "          vf_explained_var: 0.860692024230957\n",
      "          vf_loss: 0.14734623023054094\n",
      "    num_agent_steps_sampled: 579768\n",
      "    num_agent_steps_trained: 579768\n",
      "    num_steps_sampled: 579768\n",
      "    num_steps_trained: 579768\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.88222222222223\n",
      "    ram_util_percent: 44.93933333333333\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04954249066473287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.974997933096272\n",
      "    mean_inference_ms: 8.640398522128146\n",
      "    mean_raw_obs_processing_ms: 2.433387326553652\n",
      "  time_since_restore: 17435.230506420135\n",
      "  time_this_iter_s: 315.4739980697632\n",
      "  time_total_s: 17435.230506420135\n",
      "  timers:\n",
      "    learn_throughput: 65.162\n",
      "    learn_time_ms: 153403.458\n",
      "    load_throughput: 88761.63\n",
      "    load_time_ms: 112.616\n",
      "    sample_throughput: 64.078\n",
      "    sample_time_ms: 155996.733\n",
      "    update_time_ms: 9.937\n",
      "  timestamp: 1636918171\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 579768\n",
      "  training_iteration: 58\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         17435.2</td><td style=\"text-align: right;\">579768</td><td style=\"text-align: right;\">  2.3001</td><td style=\"text-align: right;\">                8.62</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           95.5437</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154353)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=154352)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 589764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-35-11\n",
      "  done: false\n",
      "  episode_len_mean: 97.36893203883496\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.760000000000002\n",
      "  episode_reward_mean: 2.061650485436899\n",
      "  episode_reward_min: -1.7300000000000004\n",
      "  episodes_this_iter: 103\n",
      "  episodes_total: 6116\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5746788846121893\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016106837603738735\n",
      "          policy_loss: -0.0678455212006234\n",
      "          total_loss: 0.12461793024140673\n",
      "          vf_explained_var: 0.7892800569534302\n",
      "          vf_loss: 0.17693017796796356\n",
      "    num_agent_steps_sampled: 589764\n",
      "    num_agent_steps_trained: 589764\n",
      "    num_steps_sampled: 589764\n",
      "    num_steps_trained: 589764\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.44742268041237\n",
      "    ram_util_percent: 44.64989690721649\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04953982911925703\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.971912492822337\n",
      "    mean_inference_ms: 8.64174595480943\n",
      "    mean_raw_obs_processing_ms: 2.490898304461661\n",
      "  time_since_restore: 17775.083691358566\n",
      "  time_this_iter_s: 339.8531849384308\n",
      "  time_total_s: 17775.083691358566\n",
      "  timers:\n",
      "    learn_throughput: 65.222\n",
      "    learn_time_ms: 153260.912\n",
      "    load_throughput: 88592.939\n",
      "    load_time_ms: 112.831\n",
      "    sample_throughput: 62.427\n",
      "    sample_time_ms: 160122.174\n",
      "    update_time_ms: 10.292\n",
      "  timestamp: 1636918511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 589764\n",
      "  training_iteration: 59\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         17775.1</td><td style=\"text-align: right;\">589764</td><td style=\"text-align: right;\"> 2.06165</td><td style=\"text-align: right;\">                9.76</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">           97.3689</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_907c1_00000:\n",
      "  agent_timesteps_total: 599760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-14_19-40-04\n",
      "  done: false\n",
      "  episode_len_mean: 99.27450980392157\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.34000000000002\n",
      "  episode_reward_mean: 2.465294117647065\n",
      "  episode_reward_min: -2.0599999999999987\n",
      "  episodes_this_iter: 102\n",
      "  episodes_total: 6218\n",
      "  experiment_id: 214763e727544e648f411667af87eede\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.562890625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.577608354275043\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015623231323259202\n",
      "          policy_loss: -0.06602522920833057\n",
      "          total_loss: 0.08886749180328324\n",
      "          vf_explained_var: 0.8619842529296875\n",
      "          vf_loss: 0.14062817245522816\n",
      "    num_agent_steps_sampled: 599760\n",
      "    num_agent_steps_trained: 599760\n",
      "    num_steps_sampled: 599760\n",
      "    num_steps_trained: 599760\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.5525059665871\n",
      "    ram_util_percent: 44.44940334128879\n",
      "  pid: 154354\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04959778455102987\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.969930552244186\n",
      "    mean_inference_ms: 8.646262780400864\n",
      "    mean_raw_obs_processing_ms: 2.457260151136393\n",
      "  time_since_restore: 18068.227132320404\n",
      "  time_this_iter_s: 293.14344096183777\n",
      "  time_total_s: 18068.227132320404\n",
      "  timers:\n",
      "    learn_throughput: 65.22\n",
      "    learn_time_ms: 153265.779\n",
      "    load_throughput: 88178.789\n",
      "    load_time_ms: 113.361\n",
      "    sample_throughput: 62.544\n",
      "    sample_time_ms: 159822.977\n",
      "    update_time_ms: 9.711\n",
      "  timestamp: 1636918804\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 599760\n",
      "  training_iteration: 60\n",
      "  trial_id: 907c1_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/25.26 GiB heap, 0.0/12.63 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_cross_attn/PPO_2021-11-14_14-38-42<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_907c1_00000</td><td>RUNNING </td><td>192.168.3.5:154354</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         18068.2</td><td style=\"text-align: right;\">599760</td><td style=\"text-align: right;\"> 2.46529</td><td style=\"text-align: right;\">               10.34</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">           99.2745</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 128,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 5_000,\n",
    "             #\"lr\": 1e-4,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO All Tasks pretrained (visual pretrained AngelaCNN + CrossAttn) (3 noops after placement) r: -0.01 div10\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/all_tasks_cross_attn\",\n",
    "        keep_checkpoints_num=50,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
