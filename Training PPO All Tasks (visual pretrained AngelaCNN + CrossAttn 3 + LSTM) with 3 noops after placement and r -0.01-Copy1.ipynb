{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ffe905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model=6):\n",
    "        super().__init__()\n",
    "        self.d_model= d_model\n",
    "        if self.d_model % 6 != 0:\n",
    "            raise ValueError(\"d_models must be divedable on 6!\")\n",
    "\n",
    "        pe = np.zeros((9, 11, 11, d_model))\n",
    "\n",
    "        for pos_x in range(9):\n",
    "            pe[pos_x,:,:,0:d_model//3:2] = np.sin(0.33 * pos_x / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "            pe[pos_x,:,:,1:d_model//3:2] = np.cos(0.33 * pos_x / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "\n",
    "        for pos_y in range(11):\n",
    "            pe[:,pos_y,:,d_model//3:2*d_model//3:2] = np.sin(0.33 * pos_y / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "            pe[:,pos_y,:,1+d_model//3:2*d_model//3:2] = np.cos(0.33 * pos_y / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "\n",
    "        for pos_z in range(11):\n",
    "            pe[:,:,pos_z,2*d_model//3::2] = np.sin(0.33 * pos_z / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "            pe[:,:,pos_z,1+2*d_model//3::2] = np.cos(0.33 * pos_z / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "            \n",
    "        pe = pe.reshape(9 * 11 * 11, d_model)\n",
    "        self.pe = torch.tensor(pe).float()\n",
    "        \n",
    "    def forward(self):\n",
    "        #x = x * math.sqrt(d_model // 3) # is it needed?\n",
    "        #x = x + self.pe\n",
    "        return self.pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49072be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionNet(nn.Module):\n",
    "    def __init__(self, d_model=6, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pe = nn.Parameter(PositionalEncoder(d_model)())\n",
    "        \n",
    "        self.img_preproc = nn.Sequential(\n",
    "            nn.Linear(512, 60),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        self.cross_attn = nn.MultiheadAttention(d_model, num_heads, batch_first=True)\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads, batch_first=True)\n",
    "        \n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv3d(6, 8, kernel_size=3, padding=1),            # perceptive field = 3\n",
    "            nn.ELU(),\n",
    "            nn.Conv3d(8, 16, kernel_size=3, padding=1),           # perceptive field = 5\n",
    "            nn.ELU(),\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1),          # perceptive field = 7\n",
    "            nn.ELU(),\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),          # perceptive field = 9\n",
    "            nn.ELU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),         # perceptive field = 11\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool3d(kernel_size=(9, 11, 11))\n",
    "        )\n",
    "        \n",
    "        self.img_mlp = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(128 + 128, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, target_features, img_features):\n",
    "        batch_size = target_features.shape[0]\n",
    "        \n",
    "        img_features2 = self.img_preproc(img_features)\n",
    "        target_features = target_features.permute(0, 2, 3, 4, 1).reshape(batch_size, 9 * 11 * 11, self.d_model)\n",
    "        img_features2 = img_features2.reshape(batch_size, -1, self.d_model)\n",
    "        target_features += self.cross_attn(key=img_features2, value=img_features2, query=target_features)[0]\n",
    "        k = q = target_features + self.pe\n",
    "        target_features += self.self_attn(key=k, value=target_features, query=q)[0]\n",
    "        \n",
    "        target_features = target_features.reshape(batch_size, 9, 11, 11, self.d_model).permute(0, 4, 1, 2, 3)\n",
    "        target_features = self.conv_net(target_features).reshape(batch_size, -1)\n",
    "        \n",
    "        img_features = self.img_mlp(img_features)\n",
    "        \n",
    "        features = torch.cat([target_features, img_features], dim=1)\n",
    "        features = self.mlp(features)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae5aace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628762"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FusionNet()\n",
    "sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 6, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 256 \n",
    "        self.policy_network = FusionNet()\n",
    "        \n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        \n",
    "        features = self.policy_network(target_features, visual_features)\n",
    "        \n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value\n",
    "\n",
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2850 tasks in total.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from iglu.tasks import CustomTasks\n",
    "task_names = ['C3', 'C17', 'C32']\n",
    "tasks = []\n",
    "augmented_chats = np.load(\"data/augmented_chats.npy\")\n",
    "augmented_tasks = np.load(\"data/augmented_targets.npy\")\n",
    "augmented_target_names = np.load(\"data/augmented_target_name.npy\")\n",
    "\n",
    "for i in range(augmented_chats.shape[0]):\n",
    "    if augmented_target_names[i] in task_names or True:\n",
    "        task = (augmented_chats[i], augmented_tasks[i])\n",
    "        tasks.append(task)\n",
    "print(\"{} tasks in total.\".format(len(tasks)))\n",
    "    \n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew = 0\n",
    "            \n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=125)\n",
    "    env.update_taskset(CustomTasks(tasks))\n",
    "    #env.update_taskset(TaskSet(preset=['C3', 'C17', 'C32']))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f83b8068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 18:18:03,986\tWARNING ppo.py:143 -- `train_batch_size` (5000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1666.\n",
      "\u001b[2m\u001b[36m(pid=364)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=364)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=367)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=367)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=370)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=370)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2021-11-27 18:18:46,104\tINFO trainable.py:109 -- Trainable.setup took 42.207 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2021-11-27 18:18:46,105\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "config={\n",
    "     \"env\": \"my_env\", \n",
    "     \"framework\": \"torch\",\n",
    "     \"num_gpus\": 1,\n",
    "     \"num_workers\": 3,\n",
    "     \"sgd_minibatch_size\": 60,\n",
    "     \"clip_param\": 0.2,\n",
    "     \"entropy_coeff\": 0.01,\n",
    "     \"lambda\": 0.95,\n",
    "     \"train_batch_size\": 5_000,\n",
    "     #\"lr\": 1e-4,\n",
    "     #\"gamma\": 0.99,\n",
    "     \"model\": {\n",
    "            # Specify our custom model from above.\n",
    "            \"custom_model\": \"my_torch_model\",\n",
    "            # Extra kwargs to be passed to your model's c'tor.\n",
    "            \"custom_model_config\": {},\n",
    "      },\n",
    "     \"logger_config\": {\n",
    "          \"wandb\": {\n",
    "              \"project\": \"IGLU-Minecraft\",\n",
    "              \"name\": \"PPO (AUG ALL) pretrained (visual pretrained AngelaCNN + CrossAttn 3) 1->0\"\n",
    "          }\n",
    "      }\n",
    "\n",
    "}\n",
    "\n",
    "agent = PPOTrainer(config, env=\"my_env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cf19be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 18:20:52,648\tINFO trainable.py:383 -- Restored on 192.168.3.5 from checkpoint: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46/PPO_my_env_9f6d0_00000_0_2021-11-21_00-54-46/checkpoint_000960/checkpoint-960\n",
      "2021-11-27 18:20:52,648\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 960, '_timesteps_total': None, '_time_total': 502059.3793668747, '_episodes_total': 173197}\n"
     ]
    }
   ],
   "source": [
    "agent.restore(\"/IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46/PPO_my_env_9f6d0_00000_0_2021-11-21_00-54-46/checkpoint_000960/checkpoint-960\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7407d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class CrossAttn_LSTM(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 6, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 256 \n",
    "        self.policy_network = FusionNet()\n",
    "        \n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        \n",
    "        features = self.policy_network(target_features, visual_features)\n",
    "        \n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value\n",
    "\n",
    "ModelCatalog.register_custom_model(\"CrossAttn_LSTM\", CrossAttn_LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c65cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301eec98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb6f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b434f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 8.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-21 00:54:47,033\tINFO trainable.py:76 -- Checkpoint size is 10703071 bytes\n",
      "2021-11-21 00:54:47,043\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-11-21 00:54:47,058\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id ab24a_00000 but id 9f6d0_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=133291)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133291)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO (AUG ALL) pretrained (visual pretrained AngelaCNN + CrossAttn 3) 1->0</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/9f6d0_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/9f6d0_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211121_005447-9f6d0_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133291)\u001b[0m 2021-11-21 00:54:50,672\tWARNING ppo.py:143 -- `train_batch_size` (5000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1666.\n",
      "\u001b[2m\u001b[36m(pid=133291)\u001b[0m 2021-11-21 00:54:50,672\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=133291)\u001b[0m 2021-11-21 00:54:50,672\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133291)\u001b[0m 2021-11-21 00:55:33,664\tINFO trainable.py:109 -- Trainable.setup took 45.601 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=133291)\u001b[0m 2021-11-21 00:55:33,665\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=133291)\u001b[0m 2021-11-21 00:55:33,700\tINFO trainable.py:383 -- Restored on 192.168.3.5 from checkpoint: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46/PPO_my_env_9f6d0_00000_0_2021-11-21_00-54-46/tmp76z18i28restore_from_object/checkpoint-400\n",
      "\u001b[2m\u001b[36m(pid=133291)\u001b[0m 2021-11-21 00:55:33,700\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 400, '_timesteps_total': None, '_time_total': 194817.3635854721, '_episodes_total': 66731}\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3408546\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_01-06-09\n",
      "  done: false\n",
      "  episode_len_mean: 49.585\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 4.310000000000003\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 200\n",
      "  episodes_total: 66931\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.200193782575638\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.03092679460174876\n",
      "          policy_loss: -0.07231750708771986\n",
      "          total_loss: 0.052229352827667885\n",
      "          vf_explained_var: 0.9009210467338562\n",
      "          vf_loss: 0.14036343848299102\n",
      "    num_agent_steps_sampled: 3408546\n",
      "    num_agent_steps_trained: 3408546\n",
      "    num_steps_sampled: 3408546\n",
      "    num_steps_trained: 3408546\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.32136563876652\n",
      "    ram_util_percent: 44.377533039647574\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.055778261208155114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 53.45402659148094\n",
      "    mean_inference_ms: 19.725230265908372\n",
      "    mean_raw_obs_processing_ms: 4.937121664980599\n",
      "  time_since_restore: 635.9329533576965\n",
      "  time_this_iter_s: 635.9329533576965\n",
      "  time_total_s: 195453.2965388298\n",
      "  timers:\n",
      "    learn_throughput: 28.198\n",
      "    learn_time_ms: 354488.597\n",
      "    load_throughput: 89277.566\n",
      "    load_time_ms: 111.965\n",
      "    sample_throughput: 35.533\n",
      "    sample_time_ms: 281313.142\n",
      "    update_time_ms: 6.015\n",
      "  timestamp: 1637456769\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3408546\n",
      "  training_iteration: 401\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   401</td><td style=\"text-align: right;\">          195453</td><td style=\"text-align: right;\">3408546</td><td style=\"text-align: right;\">    4.31</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">            49.585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3418542\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_01-15-36\n",
      "  done: false\n",
      "  episode_len_mean: 49.504950495049506\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.680000000000005\n",
      "  episode_reward_mean: 4.8373267326732705\n",
      "  episode_reward_min: -0.5000000000000004\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 67133\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1679479569077014\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.038529437175046165\n",
      "          policy_loss: -0.07817128649217321\n",
      "          total_loss: 0.061509842705507536\n",
      "          vf_explained_var: 0.9329590797424316\n",
      "          vf_loss: 0.14980177771960232\n",
      "    num_agent_steps_sampled: 3418542\n",
      "    num_agent_steps_trained: 3418542\n",
      "    num_steps_sampled: 3418542\n",
      "    num_steps_trained: 3418542\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.44474660074167\n",
      "    ram_util_percent: 49.36946847960444\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05788318553026173\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 43.004758002781344\n",
      "    mean_inference_ms: 20.07692118056478\n",
      "    mean_raw_obs_processing_ms: 4.483743969586774\n",
      "  time_since_restore: 1202.8664598464966\n",
      "  time_this_iter_s: 566.9335064888\n",
      "  time_total_s: 196020.2300453186\n",
      "  timers:\n",
      "    learn_throughput: 28.215\n",
      "    learn_time_ms: 354283.022\n",
      "    load_throughput: 87038.03\n",
      "    load_time_ms: 114.846\n",
      "    sample_throughput: 40.467\n",
      "    sample_time_ms: 247016.839\n",
      "    update_time_ms: 6.186\n",
      "  timestamp: 1637457336\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3418542\n",
      "  training_iteration: 402\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   402</td><td style=\"text-align: right;\">          196020</td><td style=\"text-align: right;\">3418542</td><td style=\"text-align: right;\"> 4.83733</td><td style=\"text-align: right;\">               15.68</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">            49.505</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3428538\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_01-24-51\n",
      "  done: false\n",
      "  episode_len_mean: 48.97549019607843\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.720000000000004\n",
      "  episode_reward_mean: 4.600784313725494\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 67337\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.45000000000000007\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1755959026545404\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.030961752294377986\n",
      "          policy_loss: -0.08398848792983253\n",
      "          total_loss: 0.026495607597979573\n",
      "          vf_explained_var: 0.9504941701889038\n",
      "          vf_loss: 0.11830726745164388\n",
      "    num_agent_steps_sampled: 3428538\n",
      "    num_agent_steps_trained: 3428538\n",
      "    num_steps_sampled: 3428538\n",
      "    num_steps_trained: 3428538\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.62996207332489\n",
      "    ram_util_percent: 50.330088495575225\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.057087181466241275\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 39.56392558349984\n",
      "    mean_inference_ms: 19.955225140761492\n",
      "    mean_raw_obs_processing_ms: 4.0690140995855115\n",
      "  time_since_restore: 1757.4810409545898\n",
      "  time_this_iter_s: 554.6145811080933\n",
      "  time_total_s: 196574.8446264267\n",
      "  timers:\n",
      "    learn_throughput: 28.239\n",
      "    learn_time_ms: 353982.677\n",
      "    load_throughput: 88337.85\n",
      "    load_time_ms: 113.156\n",
      "    sample_throughput: 43.14\n",
      "    sample_time_ms: 231711.482\n",
      "    update_time_ms: 6.495\n",
      "  timestamp: 1637457891\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3428538\n",
      "  training_iteration: 403\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   403</td><td style=\"text-align: right;\">          196575</td><td style=\"text-align: right;\">3428538</td><td style=\"text-align: right;\"> 4.60078</td><td style=\"text-align: right;\">               11.72</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           48.9755</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3438534\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_01-34-00\n",
      "  done: false\n",
      "  episode_len_mean: 49.03431372549019\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.710000000000004\n",
      "  episode_reward_mean: 4.579754901960787\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 67541\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1690342714987607\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.029013735609475146\n",
      "          policy_loss: -0.0833084141061499\n",
      "          total_loss: 0.03912782540817088\n",
      "          vf_explained_var: 0.9443672895431519\n",
      "          vf_loss: 0.12454231013179229\n",
      "    num_agent_steps_sampled: 3438534\n",
      "    num_agent_steps_trained: 3438534\n",
      "    num_steps_sampled: 3438534\n",
      "    num_steps_trained: 3438534\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.86424010217115\n",
      "    ram_util_percent: 50.066028097062585\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.056465587029771454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 37.839093814850635\n",
      "    mean_inference_ms: 19.799616623214227\n",
      "    mean_raw_obs_processing_ms: 3.8147147319563226\n",
      "  time_since_restore: 2306.2620027065277\n",
      "  time_this_iter_s: 548.7809617519379\n",
      "  time_total_s: 197123.62558817863\n",
      "  timers:\n",
      "    learn_throughput: 28.26\n",
      "    learn_time_ms: 353715.431\n",
      "    load_throughput: 88305.74\n",
      "    load_time_ms: 113.198\n",
      "    sample_throughput: 44.882\n",
      "    sample_time_ms: 222716.611\n",
      "    update_time_ms: 6.649\n",
      "  timestamp: 1637458440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3438534\n",
      "  training_iteration: 404\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   404</td><td style=\"text-align: right;\">          197124</td><td style=\"text-align: right;\">3438534</td><td style=\"text-align: right;\"> 4.57975</td><td style=\"text-align: right;\">               13.71</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           49.0343</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3448530\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_01-43-09\n",
      "  done: false\n",
      "  episode_len_mean: 49.53465346534654\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 4.523960396039607\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 67743\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1675691311857306\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.026228705960480308\n",
      "          policy_loss: -0.08076940090092491\n",
      "          total_loss: 0.05896018733879886\n",
      "          vf_explained_var: 0.9401130080223083\n",
      "          vf_loss: 0.13484871268074167\n",
      "    num_agent_steps_sampled: 3448530\n",
      "    num_agent_steps_trained: 3448530\n",
      "    num_steps_sampled: 3448530\n",
      "    num_steps_trained: 3448530\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81288265306121\n",
      "    ram_util_percent: 49.75331632653062\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.055511873637928935\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.83009299094639\n",
      "    mean_inference_ms: 19.69757613923977\n",
      "    mean_raw_obs_processing_ms: 3.6663506915947135\n",
      "  time_since_restore: 2855.7585213184357\n",
      "  time_this_iter_s: 549.496518611908\n",
      "  time_total_s: 197673.12210679054\n",
      "  timers:\n",
      "    learn_throughput: 28.267\n",
      "    learn_time_ms: 353633.059\n",
      "    load_throughput: 88450.165\n",
      "    load_time_ms: 113.013\n",
      "    sample_throughput: 45.983\n",
      "    sample_time_ms: 217383.545\n",
      "    update_time_ms: 6.265\n",
      "  timestamp: 1637458989\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3448530\n",
      "  training_iteration: 405\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   405</td><td style=\"text-align: right;\">          197673</td><td style=\"text-align: right;\">3448530</td><td style=\"text-align: right;\"> 4.52396</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           49.5347</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3458526\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_01-52-17\n",
      "  done: false\n",
      "  episode_len_mean: 49.6865671641791\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.620000000000005\n",
      "  episode_reward_mean: 4.6980099502487604\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 67944\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1767602116228586\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02140068157684134\n",
      "          policy_loss: -0.07523903867283176\n",
      "          total_loss: 0.0717563625402279\n",
      "          vf_explained_var: 0.9458786249160767\n",
      "          vf_loss: 0.13626071846834478\n",
      "    num_agent_steps_sampled: 3458526\n",
      "    num_agent_steps_trained: 3458526\n",
      "    num_steps_sampled: 3458526\n",
      "    num_steps_trained: 3458526\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.76342710997443\n",
      "    ram_util_percent: 49.93452685421995\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05509600086313952\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.03731940251662\n",
      "    mean_inference_ms: 19.61861892622705\n",
      "    mean_raw_obs_processing_ms: 3.598023667473119\n",
      "  time_since_restore: 3404.1302211284637\n",
      "  time_this_iter_s: 548.3716998100281\n",
      "  time_total_s: 198221.49380660057\n",
      "  timers:\n",
      "    learn_throughput: 28.265\n",
      "    learn_time_ms: 353653.9\n",
      "    load_throughput: 88494.225\n",
      "    load_time_ms: 112.957\n",
      "    sample_throughput: 46.805\n",
      "    sample_time_ms: 213567.309\n",
      "    update_time_ms: 5.848\n",
      "  timestamp: 1637459537\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3458526\n",
      "  training_iteration: 406\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   406</td><td style=\"text-align: right;\">          198221</td><td style=\"text-align: right;\">3458526</td><td style=\"text-align: right;\"> 4.69801</td><td style=\"text-align: right;\">               11.62</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           49.6866</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3468522\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_02-01-28\n",
      "  done: false\n",
      "  episode_len_mean: 49.15686274509804\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000005\n",
      "  episode_reward_mean: 4.74338235294118\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 68148\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.170133454277812\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01672114028795331\n",
      "          policy_loss: -0.07353135058588396\n",
      "          total_loss: 0.06870607189968511\n",
      "          vf_explained_var: 0.9439539313316345\n",
      "          vf_loss: 0.1258459076817413\n",
      "    num_agent_steps_sampled: 3468522\n",
      "    num_agent_steps_trained: 3468522\n",
      "    num_steps_sampled: 3468522\n",
      "    num_steps_trained: 3468522\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.78025477707007\n",
      "    ram_util_percent: 50.90878980891719\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05466122005244504\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.580688187091084\n",
      "    mean_inference_ms: 19.555992117706342\n",
      "    mean_raw_obs_processing_ms: 3.5083984759973115\n",
      "  time_since_restore: 3954.1314146518707\n",
      "  time_this_iter_s: 550.001193523407\n",
      "  time_total_s: 198771.49500012398\n",
      "  timers:\n",
      "    learn_throughput: 28.264\n",
      "    learn_time_ms: 353663.188\n",
      "    load_throughput: 88452.564\n",
      "    load_time_ms: 113.01\n",
      "    sample_throughput: 47.357\n",
      "    sample_time_ms: 211079.509\n",
      "    update_time_ms: 5.601\n",
      "  timestamp: 1637460088\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3468522\n",
      "  training_iteration: 407\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   407</td><td style=\"text-align: right;\">          198771</td><td style=\"text-align: right;\">3468522</td><td style=\"text-align: right;\"> 4.74338</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           49.1569</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3478518\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_02-10-26\n",
      "  done: false\n",
      "  episode_len_mean: 48.12019230769231\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.590000000000007\n",
      "  episode_reward_mean: 4.663894230769235\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 68356\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.15771398319298\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01640385570533209\n",
      "          policy_loss: -0.0741542227734013\n",
      "          total_loss: 0.1023397530894405\n",
      "          vf_explained_var: 0.9350979924201965\n",
      "          vf_loss: 0.16070108078897044\n",
      "    num_agent_steps_sampled: 3478518\n",
      "    num_agent_steps_trained: 3478518\n",
      "    num_steps_sampled: 3478518\n",
      "    num_steps_trained: 3478518\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.23641092327699\n",
      "    ram_util_percent: 50.97620286085825\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05446988688654552\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.38250561142211\n",
      "    mean_inference_ms: 19.536069267066303\n",
      "    mean_raw_obs_processing_ms: 3.243898510412454\n",
      "  time_since_restore: 4492.926074981689\n",
      "  time_this_iter_s: 538.7946603298187\n",
      "  time_total_s: 199310.2896604538\n",
      "  timers:\n",
      "    learn_throughput: 28.259\n",
      "    learn_time_ms: 353729.476\n",
      "    load_throughput: 88552.797\n",
      "    load_time_ms: 112.882\n",
      "    sample_throughput: 48.115\n",
      "    sample_time_ms: 207752.819\n",
      "    update_time_ms: 5.937\n",
      "  timestamp: 1637460626\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3478518\n",
      "  training_iteration: 408\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   408</td><td style=\"text-align: right;\">          199310</td><td style=\"text-align: right;\">3478518</td><td style=\"text-align: right;\"> 4.66389</td><td style=\"text-align: right;\">               13.59</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           48.1202</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3488514\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_02-19-36\n",
      "  done: false\n",
      "  episode_len_mean: 48.300970873786405\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.650000000000006\n",
      "  episode_reward_mean: 4.563786407766993\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 68562\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.165860636358759\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015618529875685223\n",
      "          policy_loss: -0.07537195493406841\n",
      "          total_loss: 0.05714551004621244\n",
      "          vf_explained_var: 0.9443585872650146\n",
      "          vf_loss: 0.11859510741832416\n",
      "    num_agent_steps_sampled: 3488514\n",
      "    num_agent_steps_trained: 3488514\n",
      "    num_steps_sampled: 3488514\n",
      "    num_steps_trained: 3488514\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.79247448979592\n",
      "    ram_util_percent: 49.352168367346934\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05439526728251482\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.11475306826531\n",
      "    mean_inference_ms: 19.507754594330006\n",
      "    mean_raw_obs_processing_ms: 3.2224453008629212\n",
      "  time_since_restore: 5042.965873479843\n",
      "  time_this_iter_s: 550.0397984981537\n",
      "  time_total_s: 199860.32945895195\n",
      "  timers:\n",
      "    learn_throughput: 28.256\n",
      "    learn_time_ms: 353763.32\n",
      "    load_throughput: 88597.139\n",
      "    load_time_ms: 112.825\n",
      "    sample_throughput: 48.422\n",
      "    sample_time_ms: 206433.524\n",
      "    update_time_ms: 5.629\n",
      "  timestamp: 1637461176\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3488514\n",
      "  training_iteration: 409\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   409</td><td style=\"text-align: right;\">          199860</td><td style=\"text-align: right;\">3488514</td><td style=\"text-align: right;\"> 4.56379</td><td style=\"text-align: right;\">               13.65</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">            48.301</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3498510\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_02-29-03\n",
      "  done: false\n",
      "  episode_len_mean: 47.98557692307692\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.670000000000003\n",
      "  episode_reward_mean: 4.838509615384618\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 68770\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.152287675434327\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016354095882487076\n",
      "          policy_loss: -0.07485868171051076\n",
      "          total_loss: 0.07348306436391115\n",
      "          vf_explained_var: 0.9405243992805481\n",
      "          vf_loss: 0.13260794739439022\n",
      "    num_agent_steps_sampled: 3498510\n",
      "    num_agent_steps_trained: 3498510\n",
      "    num_steps_sampled: 3498510\n",
      "    num_steps_trained: 3498510\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.65055624227442\n",
      "    ram_util_percent: 50.86242274412855\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054030320281626285\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.85700870329812\n",
      "    mean_inference_ms: 19.46530115735451\n",
      "    mean_raw_obs_processing_ms: 3.4071085009330937\n",
      "  time_since_restore: 5609.786543130875\n",
      "  time_this_iter_s: 566.8206696510315\n",
      "  time_total_s: 200427.15012860298\n",
      "  timers:\n",
      "    learn_throughput: 28.252\n",
      "    learn_time_ms: 353821.261\n",
      "    load_throughput: 88435.893\n",
      "    load_time_ms: 113.031\n",
      "    sample_throughput: 48.284\n",
      "    sample_time_ms: 207024.549\n",
      "    update_time_ms: 5.608\n",
      "  timestamp: 1637461743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3498510\n",
      "  training_iteration: 410\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   410</td><td style=\"text-align: right;\">          200427</td><td style=\"text-align: right;\">3498510</td><td style=\"text-align: right;\"> 4.83851</td><td style=\"text-align: right;\">               11.67</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           47.9856</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3508506\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_02-38-00\n",
      "  done: false\n",
      "  episode_len_mean: 48.853658536585364\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000005\n",
      "  episode_reward_mean: 4.722975609756101\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 68975\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1789592105461413\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01627043230497233\n",
      "          policy_loss: -0.07538058222081567\n",
      "          total_loss: 0.07148870322167955\n",
      "          vf_explained_var: 0.9498631954193115\n",
      "          vf_loss: 0.13159279875638688\n",
      "    num_agent_steps_sampled: 3508506\n",
      "    num_agent_steps_trained: 3508506\n",
      "    num_steps_sampled: 3508506\n",
      "    num_steps_trained: 3508506\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.99073107049608\n",
      "    ram_util_percent: 51.18368146214099\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0541123154657923\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.72276168690299\n",
      "    mean_inference_ms: 19.45607707345475\n",
      "    mean_raw_obs_processing_ms: 3.225281796103362\n",
      "  time_since_restore: 6146.619162082672\n",
      "  time_this_iter_s: 536.8326189517975\n",
      "  time_total_s: 200963.98274755478\n",
      "  timers:\n",
      "    learn_throughput: 28.253\n",
      "    learn_time_ms: 353801.447\n",
      "    load_throughput: 88230.376\n",
      "    load_time_ms: 113.294\n",
      "    sample_throughput: 50.707\n",
      "    sample_time_ms: 197132.96\n",
      "    update_time_ms: 5.426\n",
      "  timestamp: 1637462280\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3508506\n",
      "  training_iteration: 411\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   411</td><td style=\"text-align: right;\">          200964</td><td style=\"text-align: right;\">3508506</td><td style=\"text-align: right;\"> 4.72298</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           48.8537</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3518502\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_02-47-40\n",
      "  done: false\n",
      "  episode_len_mean: 47.44549763033175\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.750000000000004\n",
      "  episode_reward_mean: 4.524075829383889\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 211\n",
      "  episodes_total: 69186\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1914987323753325\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016158363204840192\n",
      "          policy_loss: -0.08308332698168772\n",
      "          total_loss: 0.05767535509269995\n",
      "          vf_explained_var: 0.9490606784820557\n",
      "          vf_loss: 0.12586289715320134\n",
      "    num_agent_steps_sampled: 3518502\n",
      "    num_agent_steps_trained: 3518502\n",
      "    num_steps_sampled: 3518502\n",
      "    num_steps_trained: 3518502\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.0590084643289\n",
      "    ram_util_percent: 51.82974607013302\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05394918339251315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.58993971185919\n",
      "    mean_inference_ms: 19.420440522931678\n",
      "    mean_raw_obs_processing_ms: 3.488498633400485\n",
      "  time_since_restore: 6726.448799133301\n",
      "  time_this_iter_s: 579.8296370506287\n",
      "  time_total_s: 201543.8123846054\n",
      "  timers:\n",
      "    learn_throughput: 28.252\n",
      "    learn_time_ms: 353810.685\n",
      "    load_throughput: 88581.09\n",
      "    load_time_ms: 112.846\n",
      "    sample_throughput: 50.38\n",
      "    sample_time_ms: 198413.915\n",
      "    update_time_ms: 5.337\n",
      "  timestamp: 1637462860\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3518502\n",
      "  training_iteration: 412\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   412</td><td style=\"text-align: right;\">          201544</td><td style=\"text-align: right;\">3518502</td><td style=\"text-align: right;\"> 4.52408</td><td style=\"text-align: right;\">               13.75</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           47.4455</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3528498\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_02-56-55\n",
      "  done: false\n",
      "  episode_len_mean: 48.08173076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000005\n",
      "  episode_reward_mean: 4.626971153846157\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 69394\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1485744424613125\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01587085827799107\n",
      "          policy_loss: -0.0742857746197959\n",
      "          total_loss: 0.06210954498303444\n",
      "          vf_explained_var: 0.9554295539855957\n",
      "          vf_loss: 0.12172526374625708\n",
      "    num_agent_steps_sampled: 3528498\n",
      "    num_agent_steps_trained: 3528498\n",
      "    num_steps_sampled: 3528498\n",
      "    num_steps_trained: 3528498\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.73219696969696\n",
      "    ram_util_percent: 50.773106060606054\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05384810465000119\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.5097433391525\n",
      "    mean_inference_ms: 19.410915924708075\n",
      "    mean_raw_obs_processing_ms: 3.5985731374310106\n",
      "  time_since_restore: 7281.433398008347\n",
      "  time_this_iter_s: 554.9845988750458\n",
      "  time_total_s: 202098.79698348045\n",
      "  timers:\n",
      "    learn_throughput: 28.246\n",
      "    learn_time_ms: 353886.688\n",
      "    load_throughput: 88316.538\n",
      "    load_time_ms: 113.184\n",
      "    sample_throughput: 50.39\n",
      "    sample_time_ms: 198373.354\n",
      "    update_time_ms: 5.35\n",
      "  timestamp: 1637463415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3528498\n",
      "  training_iteration: 413\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   413</td><td style=\"text-align: right;\">          202099</td><td style=\"text-align: right;\">3528498</td><td style=\"text-align: right;\"> 4.62697</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           48.0817</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3538494\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_03-06-17\n",
      "  done: false\n",
      "  episode_len_mean: 48.14009661835749\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000005\n",
      "  episode_reward_mean: 4.677004830917878\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 69601\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1854875765890482\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01632410055980715\n",
      "          policy_loss: -0.07096352096559713\n",
      "          total_loss: 0.0916743326570644\n",
      "          vf_explained_var: 0.9260156154632568\n",
      "          vf_loss: 0.1473043874892627\n",
      "    num_agent_steps_sampled: 3538494\n",
      "    num_agent_steps_trained: 3538494\n",
      "    num_steps_sampled: 3538494\n",
      "    num_steps_trained: 3538494\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.6069825436409\n",
      "    ram_util_percent: 50.505860349127175\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05370949022421578\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.32781233582987\n",
      "    mean_inference_ms: 19.379205686377045\n",
      "    mean_raw_obs_processing_ms: 3.6497153794996446\n",
      "  time_since_restore: 7843.791925191879\n",
      "  time_this_iter_s: 562.3585271835327\n",
      "  time_total_s: 202661.155510664\n",
      "  timers:\n",
      "    learn_throughput: 28.235\n",
      "    learn_time_ms: 354029.38\n",
      "    load_throughput: 88379.277\n",
      "    load_time_ms: 113.103\n",
      "    sample_throughput: 50.083\n",
      "    sample_time_ms: 199588.571\n",
      "    update_time_ms: 5.696\n",
      "  timestamp: 1637463977\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3538494\n",
      "  training_iteration: 414\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   414</td><td style=\"text-align: right;\">          202661</td><td style=\"text-align: right;\">3538494</td><td style=\"text-align: right;\">   4.677</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           48.1401</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3548490\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_03-15-16\n",
      "  done: false\n",
      "  episode_len_mean: 48.39613526570049\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.720000000000004\n",
      "  episode_reward_mean: 4.984444444444447\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 69808\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.15248876178121\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01589445122469998\n",
      "          policy_loss: -0.07227696069037474\n",
      "          total_loss: 0.08001332461193304\n",
      "          vf_explained_var: 0.9598656296730042\n",
      "          vf_loss: 0.13760562605751925\n",
      "    num_agent_steps_sampled: 3548490\n",
      "    num_agent_steps_trained: 3548490\n",
      "    num_steps_sampled: 3548490\n",
      "    num_steps_trained: 3548490\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.86067708333333\n",
      "    ram_util_percent: 50.307812500000004\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05364524891130148\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.29177721355428\n",
      "    mean_inference_ms: 19.378498890008355\n",
      "    mean_raw_obs_processing_ms: 3.5048326302204766\n",
      "  time_since_restore: 8382.054542541504\n",
      "  time_this_iter_s: 538.2626173496246\n",
      "  time_total_s: 203199.4181280136\n",
      "  timers:\n",
      "    learn_throughput: 28.227\n",
      "    learn_time_ms: 354126.013\n",
      "    load_throughput: 88541.955\n",
      "    load_time_ms: 112.896\n",
      "    sample_throughput: 50.391\n",
      "    sample_time_ms: 198369.756\n",
      "    update_time_ms: 5.627\n",
      "  timestamp: 1637464516\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3548490\n",
      "  training_iteration: 415\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   415</td><td style=\"text-align: right;\">          203199</td><td style=\"text-align: right;\">3548490</td><td style=\"text-align: right;\"> 4.98444</td><td style=\"text-align: right;\">               13.72</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           48.3961</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3558486\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_03-24-34\n",
      "  done: false\n",
      "  episode_len_mean: 47.33175355450237\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.650000000000006\n",
      "  episode_reward_mean: 4.5258293838862595\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 211\n",
      "  episodes_total: 70019\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.17581731981063\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015884735031890154\n",
      "          policy_loss: -0.08029936735626093\n",
      "          total_loss: 0.06522661381381456\n",
      "          vf_explained_var: 0.9475409388542175\n",
      "          vf_loss: 0.13109674138422817\n",
      "    num_agent_steps_sampled: 3558486\n",
      "    num_agent_steps_trained: 3558486\n",
      "    num_steps_sampled: 3558486\n",
      "    num_steps_trained: 3558486\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.4853199498118\n",
      "    ram_util_percent: 51.68883312421581\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053408397729255076\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.24106049147825\n",
      "    mean_inference_ms: 19.360291986259124\n",
      "    mean_raw_obs_processing_ms: 3.6168221479921066\n",
      "  time_since_restore: 8940.79720544815\n",
      "  time_this_iter_s: 558.7426629066467\n",
      "  time_total_s: 203758.16079092026\n",
      "  timers:\n",
      "    learn_throughput: 28.226\n",
      "    learn_time_ms: 354146.694\n",
      "    load_throughput: 88605.97\n",
      "    load_time_ms: 112.814\n",
      "    sample_throughput: 50.134\n",
      "    sample_time_ms: 199385.899\n",
      "    update_time_ms: 5.723\n",
      "  timestamp: 1637465074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3558486\n",
      "  training_iteration: 416\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   416</td><td style=\"text-align: right;\">          203758</td><td style=\"text-align: right;\">3558486</td><td style=\"text-align: right;\"> 4.52583</td><td style=\"text-align: right;\">               13.65</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           47.3318</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3568482\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_03-34-05\n",
      "  done: false\n",
      "  episode_len_mean: 47.80861244019139\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.780000000000003\n",
      "  episode_reward_mean: 5.213157894736845\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 70228\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1238779293485432\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01599631675376845\n",
      "          policy_loss: -0.0766507928718403\n",
      "          total_loss: 0.06821537824747588\n",
      "          vf_explained_var: 0.9560762643814087\n",
      "          vf_loss: 0.12966334038165334\n",
      "    num_agent_steps_sampled: 3568482\n",
      "    num_agent_steps_trained: 3568482\n",
      "    num_steps_sampled: 3568482\n",
      "    num_steps_trained: 3568482\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.36855036855037\n",
      "    ram_util_percent: 51.4561425061425\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05325446349672508\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.18997074084892\n",
      "    mean_inference_ms: 19.339300141407197\n",
      "    mean_raw_obs_processing_ms: 3.6670709823743546\n",
      "  time_since_restore: 9510.843901872635\n",
      "  time_this_iter_s: 570.0466964244843\n",
      "  time_total_s: 204328.20748734474\n",
      "  timers:\n",
      "    learn_throughput: 28.22\n",
      "    learn_time_ms: 354216.832\n",
      "    load_throughput: 88559.068\n",
      "    load_time_ms: 112.874\n",
      "    sample_throughput: 49.652\n",
      "    sample_time_ms: 201320.12\n",
      "    update_time_ms: 5.769\n",
      "  timestamp: 1637465645\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3568482\n",
      "  training_iteration: 417\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   417</td><td style=\"text-align: right;\">          204328</td><td style=\"text-align: right;\">3568482</td><td style=\"text-align: right;\"> 5.21316</td><td style=\"text-align: right;\">               11.78</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           47.8086</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3578478\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_03-43-33\n",
      "  done: false\n",
      "  episode_len_mean: 48.56310679611651\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 4.933398058252431\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 70434\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1543777179526518\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015814321739185164\n",
      "          policy_loss: -0.07747842032025451\n",
      "          total_loss: 0.06513637920731588\n",
      "          vf_explained_var: 0.944657564163208\n",
      "          vf_loss: 0.12813157401146763\n",
      "    num_agent_steps_sampled: 3578478\n",
      "    num_agent_steps_trained: 3578478\n",
      "    num_steps_sampled: 3578478\n",
      "    num_steps_trained: 3578478\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.65339087546238\n",
      "    ram_util_percent: 50.5170160295931\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05313443080402718\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.12935978853007\n",
      "    mean_inference_ms: 19.319823681666524\n",
      "    mean_raw_obs_processing_ms: 3.855547732239931\n",
      "  time_since_restore: 10079.706377506256\n",
      "  time_this_iter_s: 568.8624756336212\n",
      "  time_total_s: 204897.06996297836\n",
      "  timers:\n",
      "    learn_throughput: 28.218\n",
      "    learn_time_ms: 354238.541\n",
      "    load_throughput: 88528.064\n",
      "    load_time_ms: 112.913\n",
      "    sample_throughput: 48.927\n",
      "    sample_time_ms: 204305.664\n",
      "    update_time_ms: 5.392\n",
      "  timestamp: 1637466213\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3578478\n",
      "  training_iteration: 418\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   418</td><td style=\"text-align: right;\">          204897</td><td style=\"text-align: right;\">3578478</td><td style=\"text-align: right;\">  4.9334</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           48.5631</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3588474\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_03-52-53\n",
      "  done: false\n",
      "  episode_len_mean: 49.17156862745098\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.720000000000004\n",
      "  episode_reward_mean: 4.656960784313728\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 70638\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.162404299261101\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015237738402496112\n",
      "          policy_loss: -0.07741685931888245\n",
      "          total_loss: 0.05785802046829263\n",
      "          vf_explained_var: 0.9218599796295166\n",
      "          vf_loss: 0.12218544798174753\n",
      "    num_agent_steps_sampled: 3588474\n",
      "    num_agent_steps_trained: 3588474\n",
      "    num_steps_sampled: 3588474\n",
      "    num_steps_trained: 3588474\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.44593241551941\n",
      "    ram_util_percent: 50.202628285356695\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05326169792927201\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.99988207982687\n",
      "    mean_inference_ms: 19.30995079921947\n",
      "    mean_raw_obs_processing_ms: 3.8840000668123515\n",
      "  time_since_restore: 10639.276819944382\n",
      "  time_this_iter_s: 559.5704424381256\n",
      "  time_total_s: 205456.6404054165\n",
      "  timers:\n",
      "    learn_throughput: 28.217\n",
      "    learn_time_ms: 354254.412\n",
      "    load_throughput: 88398.861\n",
      "    load_time_ms: 113.078\n",
      "    sample_throughput: 48.704\n",
      "    sample_time_ms: 205241.714\n",
      "    update_time_ms: 5.795\n",
      "  timestamp: 1637466773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3588474\n",
      "  training_iteration: 419\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   419</td><td style=\"text-align: right;\">          205457</td><td style=\"text-align: right;\">3588474</td><td style=\"text-align: right;\"> 4.65696</td><td style=\"text-align: right;\">               13.72</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           49.1716</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3598470\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_04-02-02\n",
      "  done: false\n",
      "  episode_len_mean: 49.32673267326733\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 4.903861386138618\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 70840\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.151966855420645\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016313315406282454\n",
      "          policy_loss: -0.07429225414086092\n",
      "          total_loss: 0.06832960664478269\n",
      "          vf_explained_var: 0.9426409006118774\n",
      "          vf_loss: 0.1269777568229231\n",
      "    num_agent_steps_sampled: 3598470\n",
      "    num_agent_steps_trained: 3598470\n",
      "    num_steps_sampled: 3598470\n",
      "    num_steps_trained: 3598470\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.66628352490422\n",
      "    ram_util_percent: 51.56756066411239\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05319130945039906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.915844865980176\n",
      "    mean_inference_ms: 19.2918456932985\n",
      "    mean_raw_obs_processing_ms: 3.9326465160203923\n",
      "  time_since_restore: 11188.497012615204\n",
      "  time_this_iter_s: 549.2201926708221\n",
      "  time_total_s: 206005.8605980873\n",
      "  timers:\n",
      "    learn_throughput: 28.218\n",
      "    learn_time_ms: 354236.999\n",
      "    load_throughput: 88445.426\n",
      "    load_time_ms: 113.019\n",
      "    sample_throughput: 49.121\n",
      "    sample_time_ms: 203499.273\n",
      "    update_time_ms: 5.921\n",
      "  timestamp: 1637467322\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3598470\n",
      "  training_iteration: 420\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   420</td><td style=\"text-align: right;\">          206006</td><td style=\"text-align: right;\">3598470</td><td style=\"text-align: right;\"> 4.90386</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           49.3267</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3608466\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_04-11-11\n",
      "  done: false\n",
      "  episode_len_mean: 49.48019801980198\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.780000000000003\n",
      "  episode_reward_mean: 4.884158415841588\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 71042\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.157275920220647\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0154388976841473\n",
      "          policy_loss: -0.07858186429050959\n",
      "          total_loss: 0.060862771479429305\n",
      "          vf_explained_var: 0.9529964327812195\n",
      "          vf_loss: 0.12584565469750156\n",
      "    num_agent_steps_sampled: 3608466\n",
      "    num_agent_steps_trained: 3608466\n",
      "    num_steps_sampled: 3608466\n",
      "    num_steps_trained: 3608466\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81085568326947\n",
      "    ram_util_percent: 52.79157088122606\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05318137570866291\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.82785872822262\n",
      "    mean_inference_ms: 19.284436998195645\n",
      "    mean_raw_obs_processing_ms: 3.884672385584549\n",
      "  time_since_restore: 11737.135910987854\n",
      "  time_this_iter_s: 548.6388983726501\n",
      "  time_total_s: 206554.49949645996\n",
      "  timers:\n",
      "    learn_throughput: 28.217\n",
      "    learn_time_ms: 354254.27\n",
      "    load_throughput: 88420.86\n",
      "    load_time_ms: 113.05\n",
      "    sample_throughput: 48.841\n",
      "    sample_time_ms: 204663.52\n",
      "    update_time_ms: 5.918\n",
      "  timestamp: 1637467871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3608466\n",
      "  training_iteration: 421\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   421</td><td style=\"text-align: right;\">          206554</td><td style=\"text-align: right;\">3608466</td><td style=\"text-align: right;\"> 4.88416</td><td style=\"text-align: right;\">               13.78</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           49.4802</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3618462\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_04-20-07\n",
      "  done: false\n",
      "  episode_len_mean: 49.351485148514854\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.660000000000005\n",
      "  episode_reward_mean: 4.843613861386142\n",
      "  episode_reward_min: -0.4600000000000002\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 71244\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.18199263935587\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014819877214665643\n",
      "          policy_loss: -0.07768205114608795\n",
      "          total_loss: 0.04953177942923094\n",
      "          vf_explained_var: 0.9587133526802063\n",
      "          vf_loss: 0.11527222370921474\n",
      "    num_agent_steps_sampled: 3618462\n",
      "    num_agent_steps_trained: 3618462\n",
      "    num_steps_sampled: 3618462\n",
      "    num_steps_trained: 3618462\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.97660130718955\n",
      "    ram_util_percent: 50.9640522875817\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05312999132870837\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.792459623755384\n",
      "    mean_inference_ms: 19.29347043970759\n",
      "    mean_raw_obs_processing_ms: 3.769818216913496\n",
      "  time_since_restore: 12272.94412612915\n",
      "  time_this_iter_s: 535.8082151412964\n",
      "  time_total_s: 207090.30771160126\n",
      "  timers:\n",
      "    learn_throughput: 28.216\n",
      "    learn_time_ms: 354268.058\n",
      "    load_throughput: 88540.16\n",
      "    load_time_ms: 112.898\n",
      "    sample_throughput: 49.918\n",
      "    sample_time_ms: 200247.357\n",
      "    update_time_ms: 6.092\n",
      "  timestamp: 1637468407\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3618462\n",
      "  training_iteration: 422\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   422</td><td style=\"text-align: right;\">          207090</td><td style=\"text-align: right;\">3618462</td><td style=\"text-align: right;\"> 4.84361</td><td style=\"text-align: right;\">               11.66</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           49.3515</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3628458\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_04-29-33\n",
      "  done: false\n",
      "  episode_len_mean: 48.87317073170732\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000007\n",
      "  episode_reward_mean: 4.768000000000003\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 71449\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1775937391093456\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016352150176937974\n",
      "          policy_loss: -0.0746065208265562\n",
      "          total_loss: 0.07324952365108628\n",
      "          vf_explained_var: 0.9495317339897156\n",
      "          vf_loss: 0.13237973775679104\n",
      "    num_agent_steps_sampled: 3628458\n",
      "    num_agent_steps_trained: 3628458\n",
      "    num_steps_sampled: 3628458\n",
      "    num_steps_trained: 3628458\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.26208178438662\n",
      "    ram_util_percent: 51.64399008674101\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0531273221331938\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.74366573408081\n",
      "    mean_inference_ms: 19.28499475040816\n",
      "    mean_raw_obs_processing_ms: 3.809654749823238\n",
      "  time_since_restore: 12839.12271618843\n",
      "  time_this_iter_s: 566.1785900592804\n",
      "  time_total_s: 207656.48630166054\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354300.771\n",
      "    load_throughput: 88592.059\n",
      "    load_time_ms: 112.832\n",
      "    sample_throughput: 49.648\n",
      "    sample_time_ms: 201335.481\n",
      "    update_time_ms: 5.81\n",
      "  timestamp: 1637468973\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3628458\n",
      "  training_iteration: 423\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   423</td><td style=\"text-align: right;\">          207656</td><td style=\"text-align: right;\">3628458</td><td style=\"text-align: right;\">   4.768</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           48.8732</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3638454\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_04-38-42\n",
      "  done: false\n",
      "  episode_len_mean: 49.26600985221675\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000005\n",
      "  episode_reward_mean: 4.60546798029557\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 203\n",
      "  episodes_total: 71652\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.170955098800391\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014945778557310364\n",
      "          policy_loss: -0.07890647319146085\n",
      "          total_loss: 0.04989142625149926\n",
      "          vf_explained_var: 0.9480834603309631\n",
      "          vf_loss: 0.11645909679247568\n",
      "    num_agent_steps_sampled: 3638454\n",
      "    num_agent_steps_trained: 3638454\n",
      "    num_steps_sampled: 3638454\n",
      "    num_steps_trained: 3638454\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.76913265306122\n",
      "    ram_util_percent: 51.46798469387755\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05322817263902315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.7065486240013\n",
      "    mean_inference_ms: 19.28488136301148\n",
      "    mean_raw_obs_processing_ms: 3.7672794986924467\n",
      "  time_since_restore: 13388.61493229866\n",
      "  time_this_iter_s: 549.4922161102295\n",
      "  time_total_s: 208205.97851777077\n",
      "  timers:\n",
      "    learn_throughput: 28.212\n",
      "    learn_time_ms: 354313.571\n",
      "    load_throughput: 88507.601\n",
      "    load_time_ms: 112.939\n",
      "    sample_throughput: 49.971\n",
      "    sample_time_ms: 200036.499\n",
      "    update_time_ms: 5.161\n",
      "  timestamp: 1637469522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3638454\n",
      "  training_iteration: 424\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   424</td><td style=\"text-align: right;\">          208206</td><td style=\"text-align: right;\">3638454</td><td style=\"text-align: right;\"> 4.60547</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">            49.266</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3648450\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_04-47-37\n",
      "  done: false\n",
      "  episode_len_mean: 50.4263959390863\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.689999999999994\n",
      "  episode_reward_mean: 5.019340101522847\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 197\n",
      "  episodes_total: 71849\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1565069990943235\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015748957073002386\n",
      "          policy_loss: -0.07410296170072757\n",
      "          total_loss: 0.0655954224281034\n",
      "          vf_explained_var: 0.9479078650474548\n",
      "          vf_loss: 0.12538536036944384\n",
      "    num_agent_steps_sampled: 3648450\n",
      "    num_agent_steps_trained: 3648450\n",
      "    num_steps_sampled: 3648450\n",
      "    num_steps_trained: 3648450\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.05832241153342\n",
      "    ram_util_percent: 50.586238532110094\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05326189116136751\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.65344636681371\n",
      "    mean_inference_ms: 19.29297789925167\n",
      "    mean_raw_obs_processing_ms: 3.6704267285061034\n",
      "  time_since_restore: 13923.010773897171\n",
      "  time_this_iter_s: 534.3958415985107\n",
      "  time_total_s: 208740.37435936928\n",
      "  timers:\n",
      "    learn_throughput: 28.208\n",
      "    learn_time_ms: 354365.253\n",
      "    load_throughput: 88415.77\n",
      "    load_time_ms: 113.057\n",
      "    sample_throughput: 50.081\n",
      "    sample_time_ms: 199598.02\n",
      "    update_time_ms: 5.25\n",
      "  timestamp: 1637470057\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3648450\n",
      "  training_iteration: 425\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   425</td><td style=\"text-align: right;\">          208740</td><td style=\"text-align: right;\">3648450</td><td style=\"text-align: right;\"> 5.01934</td><td style=\"text-align: right;\">               17.69</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           50.4264</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3658446\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_04-57-02\n",
      "  done: false\n",
      "  episode_len_mean: 48.858536585365854\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 5.048097560975614\n",
      "  episode_reward_min: -0.4200000000000002\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 72054\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.154323020326086\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015215965829666138\n",
      "          policy_loss: -0.07493956084089656\n",
      "          total_loss: 0.06301036129969646\n",
      "          vf_explained_var: 0.956092119216919\n",
      "          vf_loss: 0.124829278920448\n",
      "    num_agent_steps_sampled: 3658446\n",
      "    num_agent_steps_trained: 3658446\n",
      "    num_steps_sampled: 3658446\n",
      "    num_steps_trained: 3658446\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.55099255583127\n",
      "    ram_util_percent: 50.69987593052109\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053180078055304385\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.600513707903126\n",
      "    mean_inference_ms: 19.283498224772156\n",
      "    mean_raw_obs_processing_ms: 3.716799481816246\n",
      "  time_since_restore: 14487.926712751389\n",
      "  time_this_iter_s: 564.9159388542175\n",
      "  time_total_s: 209305.2902982235\n",
      "  timers:\n",
      "    learn_throughput: 28.204\n",
      "    learn_time_ms: 354419.532\n",
      "    load_throughput: 88597.245\n",
      "    load_time_ms: 112.825\n",
      "    sample_throughput: 49.94\n",
      "    sample_time_ms: 200161.373\n",
      "    update_time_ms: 5.556\n",
      "  timestamp: 1637470622\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3658446\n",
      "  training_iteration: 426\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   426</td><td style=\"text-align: right;\">          209305</td><td style=\"text-align: right;\">3658446</td><td style=\"text-align: right;\">  5.0481</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">               -0.42</td><td style=\"text-align: right;\">           48.8585</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3668442\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_05-06-10\n",
      "  done: false\n",
      "  episode_len_mean: 49.791044776119406\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.660000000000005\n",
      "  episode_reward_mean: 4.916019900497516\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 72255\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.169194159402426\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015193557251391265\n",
      "          policy_loss: -0.07619675773966297\n",
      "          total_loss: 0.05865903365418226\n",
      "          vf_explained_var: 0.9533183574676514\n",
      "          vf_loss: 0.12193490897995386\n",
      "    num_agent_steps_sampled: 3668442\n",
      "    num_agent_steps_trained: 3668442\n",
      "    num_steps_sampled: 3668442\n",
      "    num_steps_trained: 3668442\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7725063938619\n",
      "    ram_util_percent: 51.16700767263428\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053082976657613266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.55000746143446\n",
      "    mean_inference_ms: 19.276125492073678\n",
      "    mean_raw_obs_processing_ms: 3.693235549995614\n",
      "  time_since_restore: 15036.240513563156\n",
      "  time_this_iter_s: 548.3138008117676\n",
      "  time_total_s: 209853.60409903526\n",
      "  timers:\n",
      "    learn_throughput: 28.205\n",
      "    learn_time_ms: 354410.638\n",
      "    load_throughput: 88985.191\n",
      "    load_time_ms: 112.333\n",
      "    sample_throughput: 50.486\n",
      "    sample_time_ms: 197997.413\n",
      "    update_time_ms: 5.837\n",
      "  timestamp: 1637471170\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3668442\n",
      "  training_iteration: 427\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   427</td><td style=\"text-align: right;\">          209854</td><td style=\"text-align: right;\">3668442</td><td style=\"text-align: right;\"> 4.91602</td><td style=\"text-align: right;\">               13.66</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">            49.791</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3678438\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_05-15-19\n",
      "  done: false\n",
      "  episode_len_mean: 49.475247524752476\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.66\n",
      "  episode_reward_mean: 4.814108910891093\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 72457\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.164518617793738\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01518456445443593\n",
      "          policy_loss: -0.07220587928995774\n",
      "          total_loss: 0.06542152929019451\n",
      "          vf_explained_var: 0.9472803473472595\n",
      "          vf_loss: 0.12468025697503672\n",
      "    num_agent_steps_sampled: 3678438\n",
      "    num_agent_steps_trained: 3678438\n",
      "    num_steps_sampled: 3678438\n",
      "    num_steps_trained: 3678438\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82104591836735\n",
      "    ram_util_percent: 51.738392857142856\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05309970418723249\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.506309814314164\n",
      "    mean_inference_ms: 19.276309881523837\n",
      "    mean_raw_obs_processing_ms: 3.659331863567651\n",
      "  time_since_restore: 15585.286748409271\n",
      "  time_this_iter_s: 549.0462348461151\n",
      "  time_total_s: 210402.65033388138\n",
      "  timers:\n",
      "    learn_throughput: 28.205\n",
      "    learn_time_ms: 354403.654\n",
      "    load_throughput: 89040.185\n",
      "    load_time_ms: 112.264\n",
      "    sample_throughput: 50.994\n",
      "    sample_time_ms: 196022.743\n",
      "    update_time_ms: 5.856\n",
      "  timestamp: 1637471719\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3678438\n",
      "  training_iteration: 428\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   428</td><td style=\"text-align: right;\">          210403</td><td style=\"text-align: right;\">3678438</td><td style=\"text-align: right;\"> 4.81411</td><td style=\"text-align: right;\">               17.66</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           49.4752</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3688434\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_05-24-55\n",
      "  done: false\n",
      "  episode_len_mean: 49.80597014925373\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.740000000000004\n",
      "  episode_reward_mean: 4.644975124378114\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 72658\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1717574285455497\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014797702146072867\n",
      "          policy_loss: -0.07578228854025615\n",
      "          total_loss: 0.05319261284008338\n",
      "          vf_explained_var: 0.9421861171722412\n",
      "          vf_loss: 0.11698145944827112\n",
      "    num_agent_steps_sampled: 3688434\n",
      "    num_agent_steps_trained: 3688434\n",
      "    num_steps_sampled: 3688434\n",
      "    num_steps_trained: 3688434\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.13211678832117\n",
      "    ram_util_percent: 50.6639902676399\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302212750815568\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.39752733080041\n",
      "    mean_inference_ms: 19.253529455635054\n",
      "    mean_raw_obs_processing_ms: 3.788589382824532\n",
      "  time_since_restore: 16161.46699666977\n",
      "  time_this_iter_s: 576.180248260498\n",
      "  time_total_s: 210978.83058214188\n",
      "  timers:\n",
      "    learn_throughput: 28.204\n",
      "    learn_time_ms: 354421.622\n",
      "    load_throughput: 89073.63\n",
      "    load_time_ms: 112.222\n",
      "    sample_throughput: 50.57\n",
      "    sample_time_ms: 197666.398\n",
      "    update_time_ms: 5.463\n",
      "  timestamp: 1637472295\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3688434\n",
      "  training_iteration: 429\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   429</td><td style=\"text-align: right;\">          210979</td><td style=\"text-align: right;\">3688434</td><td style=\"text-align: right;\"> 4.64498</td><td style=\"text-align: right;\">               11.74</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">            49.806</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3698430\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_05-33-51\n",
      "  done: false\n",
      "  episode_len_mean: 49.36945812807882\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000007\n",
      "  episode_reward_mean: 4.568719211822664\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 203\n",
      "  episodes_total: 72861\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1760070472357262\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0147388385402182\n",
      "          policy_loss: -0.07872667708116828\n",
      "          total_loss: 0.04573870369015595\n",
      "          vf_explained_var: 0.9521480202674866\n",
      "          vf_loss: 0.11264853315562548\n",
      "    num_agent_steps_sampled: 3698430\n",
      "    num_agent_steps_trained: 3698430\n",
      "    num_steps_sampled: 3698430\n",
      "    num_steps_trained: 3698430\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01204188481677\n",
      "    ram_util_percent: 50.825\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303952710031457\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.3758080866443\n",
      "    mean_inference_ms: 19.26036433942445\n",
      "    mean_raw_obs_processing_ms: 3.7050627636946576\n",
      "  time_since_restore: 16697.102478981018\n",
      "  time_this_iter_s: 535.6354823112488\n",
      "  time_total_s: 211514.46606445312\n",
      "  timers:\n",
      "    learn_throughput: 28.204\n",
      "    learn_time_ms: 354419.381\n",
      "    load_throughput: 89257.343\n",
      "    load_time_ms: 111.991\n",
      "    sample_throughput: 50.919\n",
      "    sample_time_ms: 196310.238\n",
      "    update_time_ms: 5.504\n",
      "  timestamp: 1637472831\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3698430\n",
      "  training_iteration: 430\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   430</td><td style=\"text-align: right;\">          211514</td><td style=\"text-align: right;\">3698430</td><td style=\"text-align: right;\"> 4.56872</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           49.3695</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3708426\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_05-43-13\n",
      "  done: false\n",
      "  episode_len_mean: 48.916666666666664\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.660000000000005\n",
      "  episode_reward_mean: 4.393088235294122\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 73065\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.191637620437576\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014540408624818403\n",
      "          policy_loss: -0.07735767245462757\n",
      "          total_loss: 0.046923784144521606\n",
      "          vf_explained_var: 0.9399353265762329\n",
      "          vf_loss: 0.11307296391368944\n",
      "    num_agent_steps_sampled: 3708426\n",
      "    num_agent_steps_trained: 3708426\n",
      "    num_steps_sampled: 3708426\n",
      "    num_steps_trained: 3708426\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.56234413965088\n",
      "    ram_util_percent: 52.07842892768081\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053022616019974725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.332126758359635\n",
      "    mean_inference_ms: 19.252792475590404\n",
      "    mean_raw_obs_processing_ms: 3.7388459155103155\n",
      "  time_since_restore: 17258.83073949814\n",
      "  time_this_iter_s: 561.7282605171204\n",
      "  time_total_s: 212076.19432497025\n",
      "  timers:\n",
      "    learn_throughput: 28.206\n",
      "    learn_time_ms: 354396.455\n",
      "    load_throughput: 89344.801\n",
      "    load_time_ms: 111.881\n",
      "    sample_throughput: 50.576\n",
      "    sample_time_ms: 197642.462\n",
      "    update_time_ms: 5.796\n",
      "  timestamp: 1637473393\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3708426\n",
      "  training_iteration: 431\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   431</td><td style=\"text-align: right;\">          212076</td><td style=\"text-align: right;\">3708426</td><td style=\"text-align: right;\"> 4.39309</td><td style=\"text-align: right;\">               13.66</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           48.9167</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3718422\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_05-53-01\n",
      "  done: false\n",
      "  episode_len_mean: 49.08866995073892\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.629999999999992\n",
      "  episode_reward_mean: 4.684285714285718\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 203\n",
      "  episodes_total: 73268\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.192750055004794\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01605895866799508\n",
      "          policy_loss: -0.07873974230572213\n",
      "          total_loss: 0.0650182657104775\n",
      "          vf_explained_var: 0.9408880472183228\n",
      "          vf_loss: 0.12910119116962718\n",
      "    num_agent_steps_sampled: 3718422\n",
      "    num_agent_steps_trained: 3718422\n",
      "    num_steps_sampled: 3718422\n",
      "    num_steps_trained: 3718422\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.15816448152562\n",
      "    ram_util_percent: 50.833253873659125\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05299805524464745\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.32940760456796\n",
      "    mean_inference_ms: 19.259205261813467\n",
      "    mean_raw_obs_processing_ms: 3.8274240129673163\n",
      "  time_since_restore: 17846.8684630394\n",
      "  time_this_iter_s: 588.0377235412598\n",
      "  time_total_s: 212664.2320485115\n",
      "  timers:\n",
      "    learn_throughput: 28.205\n",
      "    learn_time_ms: 354403.743\n",
      "    load_throughput: 89387.126\n",
      "    load_time_ms: 111.828\n",
      "    sample_throughput: 49.276\n",
      "    sample_time_ms: 202858.385\n",
      "    update_time_ms: 5.778\n",
      "  timestamp: 1637473981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3718422\n",
      "  training_iteration: 432\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   432</td><td style=\"text-align: right;\">          212664</td><td style=\"text-align: right;\">3718422</td><td style=\"text-align: right;\"> 4.68429</td><td style=\"text-align: right;\">               17.63</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           49.0887</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3728418\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_06-02-08\n",
      "  done: false\n",
      "  episode_len_mean: 49.885572139303484\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.730000000000004\n",
      "  episode_reward_mean: 4.585124378109457\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 73469\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.178925366645836\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014897294823903841\n",
      "          policy_loss: -0.07824255513429183\n",
      "          total_loss: 0.0545672998240866\n",
      "          vf_explained_var: 0.9453961253166199\n",
      "          vf_loss: 0.12066120754143814\n",
      "    num_agent_steps_sampled: 3728418\n",
      "    num_agent_steps_trained: 3728418\n",
      "    num_steps_sampled: 3728418\n",
      "    num_steps_trained: 3728418\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7076824583867\n",
      "    ram_util_percent: 50.60435339308579\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052942810996765254\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.301670287827974\n",
      "    mean_inference_ms: 19.25892393019691\n",
      "    mean_raw_obs_processing_ms: 3.807168011428373\n",
      "  time_since_restore: 18394.33406496048\n",
      "  time_this_iter_s: 547.4656019210815\n",
      "  time_total_s: 213211.6976504326\n",
      "  timers:\n",
      "    learn_throughput: 28.207\n",
      "    learn_time_ms: 354383.991\n",
      "    load_throughput: 89379.428\n",
      "    load_time_ms: 111.838\n",
      "    sample_throughput: 49.73\n",
      "    sample_time_ms: 201007.176\n",
      "    update_time_ms: 5.743\n",
      "  timestamp: 1637474528\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3728418\n",
      "  training_iteration: 433\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   433</td><td style=\"text-align: right;\">          213212</td><td style=\"text-align: right;\">3728418</td><td style=\"text-align: right;\"> 4.58512</td><td style=\"text-align: right;\">               13.73</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           49.8856</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3738414\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_06-11-48\n",
      "  done: false\n",
      "  episode_len_mean: 49.34158415841584\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000005\n",
      "  episode_reward_mean: 4.796485148514855\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 73671\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1801374736081165\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014986835996619754\n",
      "          policy_loss: -0.08371758996768203\n",
      "          total_loss: 0.03702923084129436\n",
      "          vf_explained_var: 0.9429067969322205\n",
      "          vf_loss: 0.10840630856853158\n",
      "    num_agent_steps_sampled: 3738414\n",
      "    num_agent_steps_trained: 3738414\n",
      "    num_steps_sampled: 3738414\n",
      "    num_steps_trained: 3738414\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.85574365175331\n",
      "    ram_util_percent: 51.66928657799274\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529272802767369\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.266991186274836\n",
      "    mean_inference_ms: 19.251386730309164\n",
      "    mean_raw_obs_processing_ms: 3.8770740241813613\n",
      "  time_since_restore: 18973.88410639763\n",
      "  time_this_iter_s: 579.550041437149\n",
      "  time_total_s: 213791.24769186974\n",
      "  timers:\n",
      "    learn_throughput: 28.208\n",
      "    learn_time_ms: 354371.641\n",
      "    load_throughput: 89340.745\n",
      "    load_time_ms: 111.886\n",
      "    sample_throughput: 48.994\n",
      "    sample_time_ms: 204025.373\n",
      "    update_time_ms: 5.654\n",
      "  timestamp: 1637475108\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3738414\n",
      "  training_iteration: 434\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   434</td><td style=\"text-align: right;\">          213791</td><td style=\"text-align: right;\">3738414</td><td style=\"text-align: right;\"> 4.79649</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           49.3416</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3748410\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_06-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 48.71844660194175\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.620000000000006\n",
      "  episode_reward_mean: 4.475097087378645\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 73877\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1940031495917753\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014906730649934518\n",
      "          policy_loss: -0.07687353200875856\n",
      "          total_loss: 0.059289514228850794\n",
      "          vf_explained_var: 0.9191843271255493\n",
      "          vf_loss: 0.12414368049940094\n",
      "    num_agent_steps_sampled: 3748410\n",
      "    num_agent_steps_trained: 3748410\n",
      "    num_steps_sampled: 3748410\n",
      "    num_steps_trained: 3748410\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75842839036754\n",
      "    ram_util_percent: 52.06210392902408\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05291451676551766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.265946941801474\n",
      "    mean_inference_ms: 19.253525910284758\n",
      "    mean_raw_obs_processing_ms: 3.8477005080216964\n",
      "  time_since_restore: 19527.41150379181\n",
      "  time_this_iter_s: 553.5273973941803\n",
      "  time_total_s: 214344.77508926392\n",
      "  timers:\n",
      "    learn_throughput: 28.21\n",
      "    learn_time_ms: 354341.169\n",
      "    load_throughput: 89236.598\n",
      "    load_time_ms: 112.017\n",
      "    sample_throughput: 48.532\n",
      "    sample_time_ms: 205969.241\n",
      "    update_time_ms: 5.478\n",
      "  timestamp: 1637475662\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3748410\n",
      "  training_iteration: 435\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   435</td><td style=\"text-align: right;\">          214345</td><td style=\"text-align: right;\">3748410</td><td style=\"text-align: right;\">  4.4751</td><td style=\"text-align: right;\">               13.62</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           48.7184</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3758406\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_06-30-15\n",
      "  done: false\n",
      "  episode_len_mean: 49.02450980392157\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.660000000000005\n",
      "  episode_reward_mean: 4.806421568627454\n",
      "  episode_reward_min: -0.4200000000000002\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 74081\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1700214669168236\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015351684290202058\n",
      "          policy_loss: -0.07640338075700757\n",
      "          total_loss: 0.06829640462798037\n",
      "          vf_explained_var: 0.9455568194389343\n",
      "          vf_loss: 0.131426941905915\n",
      "    num_agent_steps_sampled: 3758406\n",
      "    num_agent_steps_trained: 3758406\n",
      "    num_steps_sampled: 3758406\n",
      "    num_steps_trained: 3758406\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.55101265822788\n",
      "    ram_util_percent: 50.243037974683546\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05307301959551161\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.2731579610199\n",
      "    mean_inference_ms: 19.2615639835832\n",
      "    mean_raw_obs_processing_ms: 3.8245424584654777\n",
      "  time_since_restore: 20081.0032081604\n",
      "  time_this_iter_s: 553.5917043685913\n",
      "  time_total_s: 214898.3667936325\n",
      "  timers:\n",
      "    learn_throughput: 28.209\n",
      "    learn_time_ms: 354360.914\n",
      "    load_throughput: 88943.755\n",
      "    load_time_ms: 112.386\n",
      "    sample_throughput: 48.805\n",
      "    sample_time_ms: 204816.491\n",
      "    update_time_ms: 5.168\n",
      "  timestamp: 1637476215\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3758406\n",
      "  training_iteration: 436\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   436</td><td style=\"text-align: right;\">          214898</td><td style=\"text-align: right;\">3758406</td><td style=\"text-align: right;\"> 4.80642</td><td style=\"text-align: right;\">               13.66</td><td style=\"text-align: right;\">               -0.42</td><td style=\"text-align: right;\">           49.0245</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3768402\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_06-39-36\n",
      "  done: false\n",
      "  episode_len_mean: 49.48756218905473\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 4.717810945273635\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 74282\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1673317788834554\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015407339343018887\n",
      "          policy_loss: -0.0780470002667733\n",
      "          total_loss: 0.05940907627660767\n",
      "          vf_explained_var: 0.9505224227905273\n",
      "          vf_loss: 0.12402954846901079\n",
      "    num_agent_steps_sampled: 3768402\n",
      "    num_agent_steps_trained: 3768402\n",
      "    num_steps_sampled: 3768402\n",
      "    num_steps_trained: 3768402\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.57702871410739\n",
      "    ram_util_percent: 51.20299625468166\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05306752064158285\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.23654509826468\n",
      "    mean_inference_ms: 19.253526211146003\n",
      "    mean_raw_obs_processing_ms: 3.844423146786433\n",
      "  time_since_restore: 20642.11671590805\n",
      "  time_this_iter_s: 561.1135077476501\n",
      "  time_total_s: 215459.48030138016\n",
      "  timers:\n",
      "    learn_throughput: 28.209\n",
      "    learn_time_ms: 354355.095\n",
      "    load_throughput: 88776.233\n",
      "    load_time_ms: 112.598\n",
      "    sample_throughput: 48.5\n",
      "    sample_time_ms: 206101.721\n",
      "    update_time_ms: 5.175\n",
      "  timestamp: 1637476776\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3768402\n",
      "  training_iteration: 437\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   437</td><td style=\"text-align: right;\">          215459</td><td style=\"text-align: right;\">3768402</td><td style=\"text-align: right;\"> 4.71781</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           49.4876</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3778398\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_06-48-31\n",
      "  done: false\n",
      "  episode_len_mean: 49.65346534653465\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.068910891089113\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 74484\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1677443190990204\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014943438398932007\n",
      "          policy_loss: -0.08041458166114893\n",
      "          total_loss: 0.0611392560683932\n",
      "          vf_explained_var: 0.9395925402641296\n",
      "          vf_loss: 0.12918825934932804\n",
      "    num_agent_steps_sampled: 3778398\n",
      "    num_agent_steps_trained: 3778398\n",
      "    num_steps_sampled: 3778398\n",
      "    num_steps_trained: 3778398\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.06395806028834\n",
      "    ram_util_percent: 51.29017038007864\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303427918055542\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.225544546792925\n",
      "    mean_inference_ms: 19.259946048235612\n",
      "    mean_raw_obs_processing_ms: 3.7858811607338985\n",
      "  time_since_restore: 21177.082310438156\n",
      "  time_this_iter_s: 534.9655945301056\n",
      "  time_total_s: 215994.44589591026\n",
      "  timers:\n",
      "    learn_throughput: 28.207\n",
      "    learn_time_ms: 354380.197\n",
      "    load_throughput: 88583.636\n",
      "    load_time_ms: 112.843\n",
      "    sample_throughput: 48.84\n",
      "    sample_time_ms: 204668.658\n",
      "    update_time_ms: 5.049\n",
      "  timestamp: 1637477311\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3778398\n",
      "  training_iteration: 438\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   438</td><td style=\"text-align: right;\">          215994</td><td style=\"text-align: right;\">3778398</td><td style=\"text-align: right;\"> 5.06891</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           49.6535</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3788394\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_06-57-40\n",
      "  done: false\n",
      "  episode_len_mean: 49.41871921182266\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000005\n",
      "  episode_reward_mean: 4.542709359605914\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 203\n",
      "  episodes_total: 74687\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.176641442330487\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015110874714723223\n",
      "          policy_loss: -0.07845088801069765\n",
      "          total_loss: 0.049745643788220884\n",
      "          vf_explained_var: 0.9467602968215942\n",
      "          vf_loss: 0.11553848418566103\n",
      "    num_agent_steps_sampled: 3788394\n",
      "    num_agent_steps_trained: 3788394\n",
      "    num_steps_sampled: 3788394\n",
      "    num_steps_trained: 3788394\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.90114795918367\n",
      "    ram_util_percent: 51.19528061224491\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05298996281111015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.20782267850608\n",
      "    mean_inference_ms: 19.2587977841206\n",
      "    mean_raw_obs_processing_ms: 3.761749173264692\n",
      "  time_since_restore: 21726.140053987503\n",
      "  time_this_iter_s: 549.0577435493469\n",
      "  time_total_s: 216543.5036394596\n",
      "  timers:\n",
      "    learn_throughput: 28.208\n",
      "    learn_time_ms: 354372.428\n",
      "    load_throughput: 88314.417\n",
      "    load_time_ms: 113.187\n",
      "    sample_throughput: 49.494\n",
      "    sample_time_ms: 201963.831\n",
      "    update_time_ms: 5.083\n",
      "  timestamp: 1637477860\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3788394\n",
      "  training_iteration: 439\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   439</td><td style=\"text-align: right;\">          216544</td><td style=\"text-align: right;\">3788394</td><td style=\"text-align: right;\"> 4.54271</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           49.4187</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3798390\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_07-06-49\n",
      "  done: false\n",
      "  episode_len_mean: 49.815\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.530000000000008\n",
      "  episode_reward_mean: 4.588850000000003\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 200\n",
      "  episodes_total: 74887\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1510483770246007\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015266891697966474\n",
      "          policy_loss: -0.07591270228674118\n",
      "          total_loss: 0.05053323126509884\n",
      "          vf_explained_var: 0.9399974942207336\n",
      "          vf_loss: 0.1131765279575741\n",
      "    num_agent_steps_sampled: 3798390\n",
      "    num_agent_steps_trained: 3798390\n",
      "    num_steps_sampled: 3798390\n",
      "    num_steps_trained: 3798390\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.68644501278771\n",
      "    ram_util_percent: 50.31841432225064\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053008910817747425\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.17594410557766\n",
      "    mean_inference_ms: 19.259710119920122\n",
      "    mean_raw_obs_processing_ms: 3.739927897917083\n",
      "  time_since_restore: 22274.70622396469\n",
      "  time_this_iter_s: 548.5661699771881\n",
      "  time_total_s: 217092.0698094368\n",
      "  timers:\n",
      "    learn_throughput: 28.207\n",
      "    learn_time_ms: 354382.627\n",
      "    load_throughput: 88200.14\n",
      "    load_time_ms: 113.333\n",
      "    sample_throughput: 49.182\n",
      "    sample_time_ms: 203246.44\n",
      "    update_time_ms: 5.061\n",
      "  timestamp: 1637478409\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3798390\n",
      "  training_iteration: 440\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   440</td><td style=\"text-align: right;\">          217092</td><td style=\"text-align: right;\">3798390</td><td style=\"text-align: right;\"> 4.58885</td><td style=\"text-align: right;\">               13.53</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">            49.815</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3808386\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_07-16-24\n",
      "  done: false\n",
      "  episode_len_mean: 48.81951219512195\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000005\n",
      "  episode_reward_mean: 5.00975609756098\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 75092\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.137221434844067\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014887165850254862\n",
      "          policy_loss: -0.08071920625861456\n",
      "          total_loss: 0.058152687048843556\n",
      "          vf_explained_var: 0.9575442671775818\n",
      "          vf_loss: 0.12632928256657963\n",
      "    num_agent_steps_sampled: 3808386\n",
      "    num_agent_steps_trained: 3808386\n",
      "    num_steps_sampled: 3808386\n",
      "    num_steps_trained: 3808386\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.94573170731708\n",
      "    ram_util_percent: 51.240121951219514\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052975682182011256\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.15179535608564\n",
      "    mean_inference_ms: 19.254249318974274\n",
      "    mean_raw_obs_processing_ms: 3.7919593193297016\n",
      "  time_since_restore: 22849.494116544724\n",
      "  time_this_iter_s: 574.7878925800323\n",
      "  time_total_s: 217666.85770201683\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354424.243\n",
      "    load_throughput: 88293.29\n",
      "    load_time_ms: 113.214\n",
      "    sample_throughput: 48.878\n",
      "    sample_time_ms: 204510.144\n",
      "    update_time_ms: 5.96\n",
      "  timestamp: 1637478984\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3808386\n",
      "  training_iteration: 441\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   441</td><td style=\"text-align: right;\">          217667</td><td style=\"text-align: right;\">3808386</td><td style=\"text-align: right;\"> 5.00976</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           48.8195</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3818382\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_07-25-35\n",
      "  done: false\n",
      "  episode_len_mean: 49.12807881773399\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 4.659014778325126\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 203\n",
      "  episodes_total: 75295\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1652499095024353\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015150077279667471\n",
      "          policy_loss: -0.07177340430656089\n",
      "          total_loss: 0.06672366590998707\n",
      "          vf_explained_var: 0.9519090056419373\n",
      "          vf_loss: 0.12563579902885086\n",
      "    num_agent_steps_sampled: 3818382\n",
      "    num_agent_steps_trained: 3818382\n",
      "    num_steps_sampled: 3818382\n",
      "    num_steps_trained: 3818382\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.90775095298602\n",
      "    ram_util_percent: 52.024523506988565\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05301869744411115\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.135720987291805\n",
      "    mean_inference_ms: 19.252164441289036\n",
      "    mean_raw_obs_processing_ms: 3.764551967072431\n",
      "  time_since_restore: 23400.77619767189\n",
      "  time_this_iter_s: 551.2820811271667\n",
      "  time_total_s: 218218.139783144\n",
      "  timers:\n",
      "    learn_throughput: 28.201\n",
      "    learn_time_ms: 354452.904\n",
      "    load_throughput: 88185.985\n",
      "    load_time_ms: 113.351\n",
      "    sample_throughput: 49.779\n",
      "    sample_time_ms: 200806.02\n",
      "    update_time_ms: 5.719\n",
      "  timestamp: 1637479535\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3818382\n",
      "  training_iteration: 442\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   442</td><td style=\"text-align: right;\">          218218</td><td style=\"text-align: right;\">3818382</td><td style=\"text-align: right;\"> 4.65901</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           49.1281</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3828378\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_07-34-34\n",
      "  done: false\n",
      "  episode_len_mean: 48.58048780487805\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.730000000000004\n",
      "  episode_reward_mean: 4.825609756097564\n",
      "  episode_reward_min: -0.4100000000000002\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 75500\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1738638749802446\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014926989223198957\n",
      "          policy_loss: -0.07828427869043732\n",
      "          total_loss: 0.055948745065252006\n",
      "          vf_explained_var: 0.9405080080032349\n",
      "          vf_loss: 0.12196611421403426\n",
      "    num_agent_steps_sampled: 3828378\n",
      "    num_agent_steps_trained: 3828378\n",
      "    num_steps_sampled: 3828378\n",
      "    num_steps_trained: 3828378\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.95344603381014\n",
      "    ram_util_percent: 50.043563068920676\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0530309387826302\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.15314484969038\n",
      "    mean_inference_ms: 19.257662155292987\n",
      "    mean_raw_obs_processing_ms: 3.7110198430355155\n",
      "  time_since_restore: 23939.632351875305\n",
      "  time_this_iter_s: 538.8561542034149\n",
      "  time_total_s: 218756.9959373474\n",
      "  timers:\n",
      "    learn_throughput: 28.202\n",
      "    learn_time_ms: 354446.743\n",
      "    load_throughput: 88286.503\n",
      "    load_time_ms: 113.222\n",
      "    sample_throughput: 49.992\n",
      "    sample_time_ms: 199950.764\n",
      "    update_time_ms: 6.051\n",
      "  timestamp: 1637480074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3828378\n",
      "  training_iteration: 443\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   443</td><td style=\"text-align: right;\">          218757</td><td style=\"text-align: right;\">3828378</td><td style=\"text-align: right;\"> 4.82561</td><td style=\"text-align: right;\">               11.73</td><td style=\"text-align: right;\">               -0.41</td><td style=\"text-align: right;\">           48.5805</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3838374\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_07-43-46\n",
      "  done: false\n",
      "  episode_len_mean: 48.81553398058252\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000003\n",
      "  episode_reward_mean: 4.49961165048544\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 75706\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.208290288534509\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014397431547881999\n",
      "          policy_loss: -0.07967661782153826\n",
      "          total_loss: 0.04630718429677461\n",
      "          vf_explained_var: 0.941429853439331\n",
      "          vf_loss: 0.11526755484524202\n",
      "    num_agent_steps_sampled: 3838374\n",
      "    num_agent_steps_trained: 3838374\n",
      "    num_steps_sampled: 3838374\n",
      "    num_steps_trained: 3838374\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69364675984754\n",
      "    ram_util_percent: 50.92655654383735\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302492068750092\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.148140789635114\n",
      "    mean_inference_ms: 19.256526946038555\n",
      "    mean_raw_obs_processing_ms: 3.7417137709292136\n",
      "  time_since_restore: 24491.437819480896\n",
      "  time_this_iter_s: 551.8054676055908\n",
      "  time_total_s: 219308.801404953\n",
      "  timers:\n",
      "    learn_throughput: 28.204\n",
      "    learn_time_ms: 354421.284\n",
      "    load_throughput: 88422.426\n",
      "    load_time_ms: 113.048\n",
      "    sample_throughput: 50.689\n",
      "    sample_time_ms: 197201.952\n",
      "    update_time_ms: 6.154\n",
      "  timestamp: 1637480626\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3838374\n",
      "  training_iteration: 444\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   444</td><td style=\"text-align: right;\">          219309</td><td style=\"text-align: right;\">3838374</td><td style=\"text-align: right;\"> 4.49961</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           48.8155</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3848370\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_07-52-47\n",
      "  done: false\n",
      "  episode_len_mean: 48.40096618357488\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.590000000000007\n",
      "  episode_reward_mean: 4.720338164251211\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 75913\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.18846899464906\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01545114646966887\n",
      "          policy_loss: -0.07774906791174475\n",
      "          total_loss: 0.060823778962647006\n",
      "          vf_explained_var: 0.9482285380363464\n",
      "          vf_loss: 0.12525789241903054\n",
      "    num_agent_steps_sampled: 3848370\n",
      "    num_agent_steps_trained: 3848370\n",
      "    num_steps_sampled: 3848370\n",
      "    num_steps_trained: 3848370\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.06321243523318\n",
      "    ram_util_percent: 50.87810880829016\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053041584610862204\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.179955522816165\n",
      "    mean_inference_ms: 19.26046720102185\n",
      "    mean_raw_obs_processing_ms: 3.6911485669203246\n",
      "  time_since_restore: 25032.67994952202\n",
      "  time_this_iter_s: 541.2421300411224\n",
      "  time_total_s: 219850.04353499413\n",
      "  timers:\n",
      "    learn_throughput: 28.206\n",
      "    learn_time_ms: 354390.361\n",
      "    load_throughput: 88404.118\n",
      "    load_time_ms: 113.072\n",
      "    sample_throughput: 50.999\n",
      "    sample_time_ms: 196004.127\n",
      "    update_time_ms: 6.309\n",
      "  timestamp: 1637481167\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3848370\n",
      "  training_iteration: 445\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   445</td><td style=\"text-align: right;\">          219850</td><td style=\"text-align: right;\">3848370</td><td style=\"text-align: right;\"> 4.72034</td><td style=\"text-align: right;\">               13.59</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">            48.401</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3858366\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_08-02-23\n",
      "  done: false\n",
      "  episode_len_mean: 48.34634146341463\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.700000000000001\n",
      "  episode_reward_mean: 4.275609756097564\n",
      "  episode_reward_min: -0.4600000000000002\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 76118\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1835218633274476\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015106304193725658\n",
      "          policy_loss: -0.0793708154776875\n",
      "          total_loss: 0.054918331139206966\n",
      "          vf_explained_var: 0.9377947449684143\n",
      "          vf_loss: 0.12171031594618661\n",
      "    num_agent_steps_sampled: 3858366\n",
      "    num_agent_steps_trained: 3858366\n",
      "    num_steps_sampled: 3858366\n",
      "    num_steps_trained: 3858366\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.09002433090025\n",
      "    ram_util_percent: 51.02396593673966\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529833666967577\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.173643245251604\n",
      "    mean_inference_ms: 19.255299521452375\n",
      "    mean_raw_obs_processing_ms: 3.7327022856315115\n",
      "  time_since_restore: 25608.372653245926\n",
      "  time_this_iter_s: 575.6927037239075\n",
      "  time_total_s: 220425.73623871803\n",
      "  timers:\n",
      "    learn_throughput: 28.208\n",
      "    learn_time_ms: 354364.283\n",
      "    load_throughput: 88507.059\n",
      "    load_time_ms: 112.94\n",
      "    sample_throughput: 50.424\n",
      "    sample_time_ms: 198240.531\n",
      "    update_time_ms: 6.487\n",
      "  timestamp: 1637481743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3858366\n",
      "  training_iteration: 446\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   446</td><td style=\"text-align: right;\">          220426</td><td style=\"text-align: right;\">3858366</td><td style=\"text-align: right;\"> 4.27561</td><td style=\"text-align: right;\">                11.7</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           48.3463</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3868362\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_08-11-34\n",
      "  done: false\n",
      "  episode_len_mean: 48.47572815533981\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.690000000000005\n",
      "  episode_reward_mean: 4.527961165048548\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 76324\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.19343691336582\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015098819832634664\n",
      "          policy_loss: -0.07794383818105548\n",
      "          total_loss: 0.049112360006501946\n",
      "          vf_explained_var: 0.9537760615348816\n",
      "          vf_loss: 0.11459356703193312\n",
      "    num_agent_steps_sampled: 3868362\n",
      "    num_agent_steps_trained: 3868362\n",
      "    num_steps_sampled: 3868362\n",
      "    num_steps_trained: 3868362\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.55834394904458\n",
      "    ram_util_percent: 50.72802547770701\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053041199323218095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.17605378188261\n",
      "    mean_inference_ms: 19.257320772587157\n",
      "    mean_raw_obs_processing_ms: 3.7118607923418545\n",
      "  time_since_restore: 26159.097897529602\n",
      "  time_this_iter_s: 550.7252442836761\n",
      "  time_total_s: 220976.4614830017\n",
      "  timers:\n",
      "    learn_throughput: 28.209\n",
      "    learn_time_ms: 354358.915\n",
      "    load_throughput: 88377.693\n",
      "    load_time_ms: 113.105\n",
      "    sample_throughput: 50.688\n",
      "    sample_time_ms: 197207.304\n",
      "    update_time_ms: 6.06\n",
      "  timestamp: 1637482294\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3868362\n",
      "  training_iteration: 447\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   447</td><td style=\"text-align: right;\">          220976</td><td style=\"text-align: right;\">3868362</td><td style=\"text-align: right;\"> 4.52796</td><td style=\"text-align: right;\">               11.69</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           48.4757</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3878358\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_08-20-34\n",
      "  done: false\n",
      "  episode_len_mean: 48.66990291262136\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.610000000000005\n",
      "  episode_reward_mean: 4.583543689320392\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 76530\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1758462815878383\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014881400286513182\n",
      "          policy_loss: -0.07971215124405746\n",
      "          total_loss: 0.05837734304044292\n",
      "          vf_explained_var: 0.9424855709075928\n",
      "          vf_loss: 0.12594626493121772\n",
      "    num_agent_steps_sampled: 3878358\n",
      "    num_agent_steps_trained: 3878358\n",
      "    num_steps_sampled: 3878358\n",
      "    num_steps_trained: 3878358\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00064766839378\n",
      "    ram_util_percent: 51.206735751295334\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05311112147546561\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.198813152655326\n",
      "    mean_inference_ms: 19.264279137452082\n",
      "    mean_raw_obs_processing_ms: 3.6665008754371273\n",
      "  time_since_restore: 26699.726281404495\n",
      "  time_this_iter_s: 540.6283838748932\n",
      "  time_total_s: 221517.0898668766\n",
      "  timers:\n",
      "    learn_throughput: 28.211\n",
      "    learn_time_ms: 354334.328\n",
      "    load_throughput: 88479.994\n",
      "    load_time_ms: 112.975\n",
      "    sample_throughput: 50.536\n",
      "    sample_time_ms: 197798.36\n",
      "    update_time_ms: 6.176\n",
      "  timestamp: 1637482834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3878358\n",
      "  training_iteration: 448\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   448</td><td style=\"text-align: right;\">          221517</td><td style=\"text-align: right;\">3878358</td><td style=\"text-align: right;\"> 4.58354</td><td style=\"text-align: right;\">               13.61</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           48.6699</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3888354\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_08-30-00\n",
      "  done: false\n",
      "  episode_len_mean: 47.84688995215311\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 4.961578947368425\n",
      "  episode_reward_min: -0.3900000000000002\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 76739\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.144270350703274\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014950247080612544\n",
      "          policy_loss: -0.07481407008337088\n",
      "          total_loss: 0.05866095710232211\n",
      "          vf_explained_var: 0.9309216141700745\n",
      "          vf_loss: 0.12085919809961565\n",
      "    num_agent_steps_sampled: 3888354\n",
      "    num_agent_steps_trained: 3888354\n",
      "    num_steps_sampled: 3888354\n",
      "    num_steps_trained: 3888354\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.54882280049567\n",
      "    ram_util_percent: 51.856753407682774\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05314375998270183\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.19488405437825\n",
      "    mean_inference_ms: 19.259726112437114\n",
      "    mean_raw_obs_processing_ms: 3.72180128795614\n",
      "  time_since_restore: 27265.154601812363\n",
      "  time_this_iter_s: 565.4283204078674\n",
      "  time_total_s: 222082.51818728447\n",
      "  timers:\n",
      "    learn_throughput: 28.211\n",
      "    learn_time_ms: 354331.091\n",
      "    load_throughput: 88780.651\n",
      "    load_time_ms: 112.592\n",
      "    sample_throughput: 50.121\n",
      "    sample_time_ms: 199438.852\n",
      "    update_time_ms: 6.526\n",
      "  timestamp: 1637483400\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3888354\n",
      "  training_iteration: 449\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   449</td><td style=\"text-align: right;\">          222083</td><td style=\"text-align: right;\">3888354</td><td style=\"text-align: right;\"> 4.96158</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">               -0.39</td><td style=\"text-align: right;\">           47.8469</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3898350\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_08-39-14\n",
      "  done: false\n",
      "  episode_len_mean: 48.25480769230769\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.620000000000008\n",
      "  episode_reward_mean: 4.490480769230772\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 76947\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1900250899504465\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014698088676053494\n",
      "          policy_loss: -0.07666521762786238\n",
      "          total_loss: 0.048252533993358354\n",
      "          vf_explained_var: 0.9450881481170654\n",
      "          vf_loss: 0.11333391822090963\n",
      "    num_agent_steps_sampled: 3898350\n",
      "    num_agent_steps_trained: 3898350\n",
      "    num_steps_sampled: 3898350\n",
      "    num_steps_trained: 3898350\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8858407079646\n",
      "    ram_util_percent: 50.32389380530974\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05315100844003552\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.20101477924039\n",
      "    mean_inference_ms: 19.26021250416168\n",
      "    mean_raw_obs_processing_ms: 3.7146778935412508\n",
      "  time_since_restore: 27819.587961912155\n",
      "  time_this_iter_s: 554.4333600997925\n",
      "  time_total_s: 222636.95154738426\n",
      "  timers:\n",
      "    learn_throughput: 28.211\n",
      "    learn_time_ms: 354330.264\n",
      "    load_throughput: 88764.749\n",
      "    load_time_ms: 112.612\n",
      "    sample_throughput: 49.973\n",
      "    sample_time_ms: 200026.296\n",
      "    update_time_ms: 6.644\n",
      "  timestamp: 1637483954\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3898350\n",
      "  training_iteration: 450\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   450</td><td style=\"text-align: right;\">          222637</td><td style=\"text-align: right;\">3898350</td><td style=\"text-align: right;\"> 4.49048</td><td style=\"text-align: right;\">               13.62</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           48.2548</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3908346\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_08-48-17\n",
      "  done: false\n",
      "  episode_len_mean: 47.89423076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000004\n",
      "  episode_reward_mean: 4.641634615384619\n",
      "  episode_reward_min: -0.4600000000000002\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 77155\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1896198179348407\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01428284648131432\n",
      "          policy_loss: -0.0817582230183119\n",
      "          total_loss: 0.034385946385506565\n",
      "          vf_explained_var: 0.9587282538414001\n",
      "          vf_loss: 0.10550225709712724\n",
      "    num_agent_steps_sampled: 3908346\n",
      "    num_agent_steps_trained: 3908346\n",
      "    num_steps_sampled: 3908346\n",
      "    num_steps_trained: 3908346\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.04108527131785\n",
      "    ram_util_percent: 50.60387596899224\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053128015167090197\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.22917091319898\n",
      "    mean_inference_ms: 19.265040133297745\n",
      "    mean_raw_obs_processing_ms: 3.6653807251591792\n",
      "  time_since_restore: 28362.087584018707\n",
      "  time_this_iter_s: 542.4996221065521\n",
      "  time_total_s: 223179.4511694908\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354308.274\n",
      "    load_throughput: 88759.243\n",
      "    load_time_ms: 112.619\n",
      "    sample_throughput: 50.787\n",
      "    sample_time_ms: 196820.259\n",
      "    update_time_ms: 5.476\n",
      "  timestamp: 1637484497\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3908346\n",
      "  training_iteration: 451\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   451</td><td style=\"text-align: right;\">          223179</td><td style=\"text-align: right;\">3908346</td><td style=\"text-align: right;\"> 4.64163</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           47.8942</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3918342\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_08-57-32\n",
      "  done: false\n",
      "  episode_len_mean: 48.066985645933016\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.720000000000004\n",
      "  episode_reward_mean: 4.624736842105267\n",
      "  episode_reward_min: -0.4100000000000002\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 77364\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.180290333765099\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015282080299251002\n",
      "          policy_loss: -0.07910561631137952\n",
      "          total_loss: 0.049906834139943956\n",
      "          vf_explained_var: 0.9520941376686096\n",
      "          vf_loss: 0.11600086339450176\n",
      "    num_agent_steps_sampled: 3918342\n",
      "    num_agent_steps_trained: 3918342\n",
      "    num_steps_sampled: 3918342\n",
      "    num_steps_trained: 3918342\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.61125158027814\n",
      "    ram_util_percent: 50.93805309734513\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05307404687661581\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.245166683609135\n",
      "    mean_inference_ms: 19.27067983298977\n",
      "    mean_raw_obs_processing_ms: 3.6505288758981025\n",
      "  time_since_restore: 28917.008274316788\n",
      "  time_this_iter_s: 554.9206902980804\n",
      "  time_total_s: 223734.3718597889\n",
      "  timers:\n",
      "    learn_throughput: 28.214\n",
      "    learn_time_ms: 354286.5\n",
      "    load_throughput: 88890.445\n",
      "    load_time_ms: 112.453\n",
      "    sample_throughput: 50.688\n",
      "    sample_time_ms: 197205.888\n",
      "    update_time_ms: 5.712\n",
      "  timestamp: 1637485052\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3918342\n",
      "  training_iteration: 452\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   452</td><td style=\"text-align: right;\">          223734</td><td style=\"text-align: right;\">3918342</td><td style=\"text-align: right;\"> 4.62474</td><td style=\"text-align: right;\">               11.72</td><td style=\"text-align: right;\">               -0.41</td><td style=\"text-align: right;\">            48.067</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3928338\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_09-06-59\n",
      "  done: false\n",
      "  episode_len_mean: 47.7799043062201\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 4.369569377990434\n",
      "  episode_reward_min: -0.47000000000000036\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 77573\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.187475083487101\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014389981256148966\n",
      "          policy_loss: -0.07714908462668998\n",
      "          total_loss: 0.030231811385810686\n",
      "          vf_explained_var: 0.9351078271865845\n",
      "          vf_loss: 0.09647346990983409\n",
      "    num_agent_steps_sampled: 3928338\n",
      "    num_agent_steps_trained: 3928338\n",
      "    num_steps_sampled: 3928338\n",
      "    num_steps_trained: 3928338\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.72855377008652\n",
      "    ram_util_percent: 50.83201483312732\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05306722866406746\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.247823631963904\n",
      "    mean_inference_ms: 19.266998989817132\n",
      "    mean_raw_obs_processing_ms: 3.67963014862139\n",
      "  time_since_restore: 29483.782572746277\n",
      "  time_this_iter_s: 566.7742984294891\n",
      "  time_total_s: 224301.14615821838\n",
      "  timers:\n",
      "    learn_throughput: 28.216\n",
      "    learn_time_ms: 354268.67\n",
      "    load_throughput: 88831.533\n",
      "    load_time_ms: 112.528\n",
      "    sample_throughput: 49.976\n",
      "    sample_time_ms: 200015.645\n",
      "    update_time_ms: 5.719\n",
      "  timestamp: 1637485619\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3928338\n",
      "  training_iteration: 453\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   453</td><td style=\"text-align: right;\">          224301</td><td style=\"text-align: right;\">3928338</td><td style=\"text-align: right;\"> 4.36957</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           47.7799</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3938334\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_09-15-58\n",
      "  done: false\n",
      "  episode_len_mean: 48.35436893203884\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.700000000000005\n",
      "  episode_reward_mean: 5.00577669902913\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 77779\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.171466203602442\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01568050691330901\n",
      "          policy_loss: -0.0742391711511823\n",
      "          total_loss: 0.06299582371732149\n",
      "          vf_explained_var: 0.9561370611190796\n",
      "          vf_loss: 0.1232275011174074\n",
      "    num_agent_steps_sampled: 3938334\n",
      "    num_agent_steps_trained: 3938334\n",
      "    num_steps_sampled: 3938334\n",
      "    num_steps_trained: 3938334\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02275682704811\n",
      "    ram_util_percent: 50.31027308192458\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053084857781871435\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.25871516374894\n",
      "    mean_inference_ms: 19.26974837650174\n",
      "    mean_raw_obs_processing_ms: 3.6284654482112977\n",
      "  time_since_restore: 30022.717757940292\n",
      "  time_this_iter_s: 538.9351851940155\n",
      "  time_total_s: 224840.0813434124\n",
      "  timers:\n",
      "    learn_throughput: 28.21\n",
      "    learn_time_ms: 354345.462\n",
      "    load_throughput: 89028.803\n",
      "    load_time_ms: 112.278\n",
      "    sample_throughput: 50.319\n",
      "    sample_time_ms: 198651.803\n",
      "    update_time_ms: 5.777\n",
      "  timestamp: 1637486158\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3938334\n",
      "  training_iteration: 454\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   454</td><td style=\"text-align: right;\">          224840</td><td style=\"text-align: right;\">3938334</td><td style=\"text-align: right;\"> 5.00578</td><td style=\"text-align: right;\">                11.7</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           48.3544</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3948330\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_09-25-21\n",
      "  done: false\n",
      "  episode_len_mean: 47.803827751196174\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.640000000000006\n",
      "  episode_reward_mean: 4.750095693779907\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 77988\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.17520494946993\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015886194047871914\n",
      "          policy_loss: -0.07408989692390225\n",
      "          total_loss: 0.0654841427776956\n",
      "          vf_explained_var: 0.9488665461540222\n",
      "          vf_loss: 0.12513535094669978\n",
      "    num_agent_steps_sampled: 3948330\n",
      "    num_agent_steps_trained: 3948330\n",
      "    num_steps_sampled: 3948330\n",
      "    num_steps_trained: 3948330\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.51242236024845\n",
      "    ram_util_percent: 51.04608695652174\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05309440330107247\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.24764011408164\n",
      "    mean_inference_ms: 19.26513754325799\n",
      "    mean_raw_obs_processing_ms: 3.653660548516606\n",
      "  time_since_restore: 30586.62528848648\n",
      "  time_this_iter_s: 563.9075305461884\n",
      "  time_total_s: 225403.9888739586\n",
      "  timers:\n",
      "    learn_throughput: 28.206\n",
      "    learn_time_ms: 354389.421\n",
      "    load_throughput: 89285.361\n",
      "    load_time_ms: 111.956\n",
      "    sample_throughput: 49.762\n",
      "    sample_time_ms: 200874.62\n",
      "    update_time_ms: 5.766\n",
      "  timestamp: 1637486721\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3948330\n",
      "  training_iteration: 455\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   455</td><td style=\"text-align: right;\">          225404</td><td style=\"text-align: right;\">3948330</td><td style=\"text-align: right;\">  4.7501</td><td style=\"text-align: right;\">               13.64</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           47.8038</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3958326\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_09-34-48\n",
      "  done: false\n",
      "  episode_len_mean: 47.628571428571426\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000009\n",
      "  episode_reward_mean: 4.612809523809528\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 210\n",
      "  episodes_total: 78198\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.172380560349269\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015610906610594987\n",
      "          policy_loss: -0.07758702663367327\n",
      "          total_loss: 0.07326398441443187\n",
      "          vf_explained_var: 0.9388830661773682\n",
      "          vf_loss: 0.13701121878738226\n",
      "    num_agent_steps_sampled: 3958326\n",
      "    num_agent_steps_trained: 3958326\n",
      "    num_steps_sampled: 3958326\n",
      "    num_steps_trained: 3958326\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.53292079207921\n",
      "    ram_util_percent: 51.71361386138614\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053046709351211994\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.24828824908934\n",
      "    mean_inference_ms: 19.26295100879352\n",
      "    mean_raw_obs_processing_ms: 3.66482082572442\n",
      "  time_since_restore: 31153.091260910034\n",
      "  time_this_iter_s: 566.4659724235535\n",
      "  time_total_s: 225970.45484638214\n",
      "  timers:\n",
      "    learn_throughput: 28.206\n",
      "    learn_time_ms: 354386.424\n",
      "    load_throughput: 89426.096\n",
      "    load_time_ms: 111.779\n",
      "    sample_throughput: 49.991\n",
      "    sample_time_ms: 199955.126\n",
      "    update_time_ms: 5.697\n",
      "  timestamp: 1637487288\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3958326\n",
      "  training_iteration: 456\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   456</td><td style=\"text-align: right;\">          225970</td><td style=\"text-align: right;\">3958326</td><td style=\"text-align: right;\"> 4.61281</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           47.6286</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3968322\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_09-43-49\n",
      "  done: false\n",
      "  episode_len_mean: 47.99519230769231\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 4.811634615384619\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 78406\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1478600516376725\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015018142751111923\n",
      "          policy_loss: -0.07621690357502164\n",
      "          total_loss: 0.058781430228266186\n",
      "          vf_explained_var: 0.9419919848442078\n",
      "          vf_loss: 0.12226372580062672\n",
      "    num_agent_steps_sampled: 3968322\n",
      "    num_agent_steps_trained: 3968322\n",
      "    num_steps_sampled: 3968322\n",
      "    num_steps_trained: 3968322\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13458549222797\n",
      "    ram_util_percent: 50.41502590673576\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05308719041808331\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.26819721494345\n",
      "    mean_inference_ms: 19.267419715708925\n",
      "    mean_raw_obs_processing_ms: 3.626114315736581\n",
      "  time_since_restore: 31694.27246427536\n",
      "  time_this_iter_s: 541.1812033653259\n",
      "  time_total_s: 226511.63604974747\n",
      "  timers:\n",
      "    learn_throughput: 28.207\n",
      "    learn_time_ms: 354384.029\n",
      "    load_throughput: 89949.771\n",
      "    load_time_ms: 111.129\n",
      "    sample_throughput: 50.23\n",
      "    sample_time_ms: 199002.974\n",
      "    update_time_ms: 5.795\n",
      "  timestamp: 1637487829\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3968322\n",
      "  training_iteration: 457\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   457</td><td style=\"text-align: right;\">          226512</td><td style=\"text-align: right;\">3968322</td><td style=\"text-align: right;\"> 4.81163</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           47.9952</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3978318\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_09-53-01\n",
      "  done: false\n",
      "  episode_len_mean: 48.359223300970875\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000007\n",
      "  episode_reward_mean: 4.58708737864078\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 78612\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1724299400207028\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015261400474669971\n",
      "          policy_loss: -0.07275253369648838\n",
      "          total_loss: 0.06917464963405884\n",
      "          vf_explained_var: 0.9212479591369629\n",
      "          vf_loss: 0.12888410410630596\n",
      "    num_agent_steps_sampled: 3978318\n",
      "    num_agent_steps_trained: 3978318\n",
      "    num_steps_sampled: 3978318\n",
      "    num_steps_trained: 3978318\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81497461928936\n",
      "    ram_util_percent: 51.10431472081218\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05309667748503235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28096614234306\n",
      "    mean_inference_ms: 19.26790758018278\n",
      "    mean_raw_obs_processing_ms: 3.620947235387154\n",
      "  time_since_restore: 32246.42795276642\n",
      "  time_this_iter_s: 552.1554884910583\n",
      "  time_total_s: 227063.79153823853\n",
      "  timers:\n",
      "    learn_throughput: 28.207\n",
      "    learn_time_ms: 354382.242\n",
      "    load_throughput: 89831.764\n",
      "    load_time_ms: 111.275\n",
      "    sample_throughput: 49.941\n",
      "    sample_time_ms: 200157.327\n",
      "    update_time_ms: 5.703\n",
      "  timestamp: 1637488381\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3978318\n",
      "  training_iteration: 458\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   458</td><td style=\"text-align: right;\">          227064</td><td style=\"text-align: right;\">3978318</td><td style=\"text-align: right;\"> 4.58709</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           48.3592</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3988314\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_10-02-14\n",
      "  done: false\n",
      "  episode_len_mean: 48.34928229665072\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 4.9864593301435445\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 78821\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.148751169108004\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01579171966252731\n",
      "          policy_loss: -0.07685947990136763\n",
      "          total_loss: 0.08077194371939968\n",
      "          vf_explained_var: 0.9450455904006958\n",
      "          vf_loss: 0.14314342165341504\n",
      "    num_agent_steps_sampled: 3988314\n",
      "    num_agent_steps_trained: 3988314\n",
      "    num_steps_sampled: 3988314\n",
      "    num_steps_trained: 3988314\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81548223350255\n",
      "    ram_util_percent: 51.486548223350255\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053059226460909666\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28130084732894\n",
      "    mean_inference_ms: 19.269554791706838\n",
      "    mean_raw_obs_processing_ms: 3.608983201141507\n",
      "  time_since_restore: 32798.93021941185\n",
      "  time_this_iter_s: 552.5022666454315\n",
      "  time_total_s: 227616.29380488396\n",
      "  timers:\n",
      "    learn_throughput: 28.205\n",
      "    learn_time_ms: 354399.824\n",
      "    load_throughput: 89919.406\n",
      "    load_time_ms: 111.166\n",
      "    sample_throughput: 50.27\n",
      "    sample_time_ms: 198847.347\n",
      "    update_time_ms: 5.317\n",
      "  timestamp: 1637488934\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3988314\n",
      "  training_iteration: 459\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   459</td><td style=\"text-align: right;\">          227616</td><td style=\"text-align: right;\">3988314</td><td style=\"text-align: right;\"> 4.98646</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           48.3493</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 3998310\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_10-11-26\n",
      "  done: false\n",
      "  episode_len_mean: 48.71078431372549\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 4.602843137254905\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 79025\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1771307125149004\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016433182655074135\n",
      "          policy_loss: -0.07767185374369988\n",
      "          total_loss: 0.07271465442616931\n",
      "          vf_explained_var: 0.9481737613677979\n",
      "          vf_loss: 0.13472097002411165\n",
      "    num_agent_steps_sampled: 3998310\n",
      "    num_agent_steps_trained: 3998310\n",
      "    num_steps_sampled: 3998310\n",
      "    num_steps_trained: 3998310\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.68147208121827\n",
      "    ram_util_percent: 50.578807106598994\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053047177443032625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.276139101758034\n",
      "    mean_inference_ms: 19.26958261251112\n",
      "    mean_raw_obs_processing_ms: 3.6045603247936095\n",
      "  time_since_restore: 33351.42985510826\n",
      "  time_this_iter_s: 552.4996356964111\n",
      "  time_total_s: 228168.79344058037\n",
      "  timers:\n",
      "    learn_throughput: 28.205\n",
      "    learn_time_ms: 354403.659\n",
      "    load_throughput: 90095.921\n",
      "    load_time_ms: 110.948\n",
      "    sample_throughput: 50.319\n",
      "    sample_time_ms: 198650.709\n",
      "    update_time_ms: 5.193\n",
      "  timestamp: 1637489486\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3998310\n",
      "  training_iteration: 460\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   460</td><td style=\"text-align: right;\">          228169</td><td style=\"text-align: right;\">3998310</td><td style=\"text-align: right;\"> 4.60284</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           48.7108</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4008306\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_10-20-40\n",
      "  done: false\n",
      "  episode_len_mean: 48.10576923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.89\n",
      "  episode_reward_mean: 4.2964423076923115\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 79233\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.191100105415865\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015152404257824104\n",
      "          policy_loss: -0.07307548963298648\n",
      "          total_loss: 0.058989973298374965\n",
      "          vf_explained_var: 0.9385526776313782\n",
      "          vf_loss: 0.11945739093897714\n",
      "    num_agent_steps_sampled: 4008306\n",
      "    num_agent_steps_trained: 4008306\n",
      "    num_steps_sampled: 4008306\n",
      "    num_steps_trained: 4008306\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.43886075949368\n",
      "    ram_util_percent: 50.54898734177215\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303216958872942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28406083301876\n",
      "    mean_inference_ms: 19.272312486044793\n",
      "    mean_raw_obs_processing_ms: 3.591739630651281\n",
      "  time_since_restore: 33905.29900407791\n",
      "  time_this_iter_s: 553.8691489696503\n",
      "  time_total_s: 228722.66258955002\n",
      "  timers:\n",
      "    learn_throughput: 28.207\n",
      "    learn_time_ms: 354380.184\n",
      "    load_throughput: 90132.527\n",
      "    load_time_ms: 110.903\n",
      "    sample_throughput: 50.027\n",
      "    sample_time_ms: 199811.311\n",
      "    update_time_ms: 5.164\n",
      "  timestamp: 1637490040\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4008306\n",
      "  training_iteration: 461\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   461</td><td style=\"text-align: right;\">          228723</td><td style=\"text-align: right;\">4008306</td><td style=\"text-align: right;\"> 4.29644</td><td style=\"text-align: right;\">               11.89</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           48.1058</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4018302\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_10-30-12\n",
      "  done: false\n",
      "  episode_len_mean: 48.04807692307692\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.640000000000006\n",
      "  episode_reward_mean: 4.792307692307696\n",
      "  episode_reward_min: -0.4500000000000002\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 79441\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.161437741652071\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015329923025311354\n",
      "          policy_loss: -0.07551355490158856\n",
      "          total_loss: 0.06197961888611027\n",
      "          vf_explained_var: 0.9496448636054993\n",
      "          vf_loss: 0.12418406879993148\n",
      "    num_agent_steps_sampled: 4018302\n",
      "    num_agent_steps_trained: 4018302\n",
      "    num_steps_sampled: 4018302\n",
      "    num_steps_trained: 4018302\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.99889705882353\n",
      "    ram_util_percent: 51.3639705882353\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302129968079789\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28814072698378\n",
      "    mean_inference_ms: 19.27172774744849\n",
      "    mean_raw_obs_processing_ms: 3.6162354016542335\n",
      "  time_since_restore: 34477.24941253662\n",
      "  time_this_iter_s: 571.9504084587097\n",
      "  time_total_s: 229294.61299800873\n",
      "  timers:\n",
      "    learn_throughput: 28.209\n",
      "    learn_time_ms: 354356.691\n",
      "    load_throughput: 90026.353\n",
      "    load_time_ms: 111.034\n",
      "    sample_throughput: 49.599\n",
      "    sample_time_ms: 201537.803\n",
      "    update_time_ms: 4.784\n",
      "  timestamp: 1637490612\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4018302\n",
      "  training_iteration: 462\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   462</td><td style=\"text-align: right;\">          229295</td><td style=\"text-align: right;\">4018302</td><td style=\"text-align: right;\"> 4.79231</td><td style=\"text-align: right;\">               11.64</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">           48.0481</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4028298\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_10-39-24\n",
      "  done: false\n",
      "  episode_len_mean: 48.16346153846154\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.630000000000006\n",
      "  episode_reward_mean: 4.799086538461543\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 79649\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1544633122572456\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015648200525440064\n",
      "          policy_loss: -0.07878873434442447\n",
      "          total_loss: 0.06927181120944693\n",
      "          vf_explained_var: 0.9546553492546082\n",
      "          vf_loss: 0.1339566208614807\n",
      "    num_agent_steps_sampled: 4028298\n",
      "    num_agent_steps_trained: 4028298\n",
      "    num_steps_sampled: 4028298\n",
      "    num_steps_trained: 4028298\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8523506988564\n",
      "    ram_util_percent: 51.02185514612452\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302201444348158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.285500690477406\n",
      "    mean_inference_ms: 19.27116147841073\n",
      "    mean_raw_obs_processing_ms: 3.6090786456421364\n",
      "  time_since_restore: 35028.66365289688\n",
      "  time_this_iter_s: 551.41424036026\n",
      "  time_total_s: 229846.027238369\n",
      "  timers:\n",
      "    learn_throughput: 28.206\n",
      "    learn_time_ms: 354396.399\n",
      "    load_throughput: 90111.954\n",
      "    load_time_ms: 110.929\n",
      "    sample_throughput: 49.989\n",
      "    sample_time_ms: 199962.762\n",
      "    update_time_ms: 4.429\n",
      "  timestamp: 1637491164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4028298\n",
      "  training_iteration: 463\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   463</td><td style=\"text-align: right;\">          229846</td><td style=\"text-align: right;\">4028298</td><td style=\"text-align: right;\"> 4.79909</td><td style=\"text-align: right;\">               17.63</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           48.1635</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4038294\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_10-48-34\n",
      "  done: false\n",
      "  episode_len_mean: 48.1207729468599\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000005\n",
      "  episode_reward_mean: 4.209565217391307\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 79856\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.203166263146573\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014767991150775896\n",
      "          policy_loss: -0.0760730107778895\n",
      "          total_loss: 0.06942823770887153\n",
      "          vf_explained_var: 0.9183452725410461\n",
      "          vf_loss: 0.13388957981699068\n",
      "    num_agent_steps_sampled: 4038294\n",
      "    num_agent_steps_trained: 4038294\n",
      "    num_steps_sampled: 4038294\n",
      "    num_steps_trained: 4038294\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.89351145038168\n",
      "    ram_util_percent: 50.59770992366413\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303983863348399\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28777612160598\n",
      "    mean_inference_ms: 19.271506204663496\n",
      "    mean_raw_obs_processing_ms: 3.5977384519656552\n",
      "  time_since_restore: 35579.33909654617\n",
      "  time_this_iter_s: 550.675443649292\n",
      "  time_total_s: 230396.70268201828\n",
      "  timers:\n",
      "    learn_throughput: 28.21\n",
      "    learn_time_ms: 354339.949\n",
      "    load_throughput: 89927.892\n",
      "    load_time_ms: 111.156\n",
      "    sample_throughput: 49.684\n",
      "    sample_time_ms: 201192.917\n",
      "    update_time_ms: 4.327\n",
      "  timestamp: 1637491714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4038294\n",
      "  training_iteration: 464\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   464</td><td style=\"text-align: right;\">          230397</td><td style=\"text-align: right;\">4038294</td><td style=\"text-align: right;\"> 4.20957</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           48.1208</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4048290\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_10-57-50\n",
      "  done: false\n",
      "  episode_len_mean: 47.24528301886792\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.710000000000003\n",
      "  episode_reward_mean: 4.7851886792452865\n",
      "  episode_reward_min: -0.4399999999999995\n",
      "  episodes_this_iter: 212\n",
      "  episodes_total: 80068\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1785489819136012\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014715844978092571\n",
      "          policy_loss: -0.07681541187288472\n",
      "          total_loss: 0.05657357359122258\n",
      "          vf_explained_var: 0.9529961347579956\n",
      "          vf_loss: 0.12164994015210648\n",
      "    num_agent_steps_sampled: 4048290\n",
      "    num_agent_steps_trained: 4048290\n",
      "    num_steps_sampled: 4048290\n",
      "    num_steps_trained: 4048290\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.85391414141412\n",
      "    ram_util_percent: 51.5114898989899\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05305454346670181\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.302295785198886\n",
      "    mean_inference_ms: 19.271261717225148\n",
      "    mean_raw_obs_processing_ms: 3.59190264763094\n",
      "  time_since_restore: 36134.464594602585\n",
      "  time_this_iter_s: 555.1254980564117\n",
      "  time_total_s: 230951.8281800747\n",
      "  timers:\n",
      "    learn_throughput: 28.21\n",
      "    learn_time_ms: 354337.967\n",
      "    load_throughput: 89865.825\n",
      "    load_time_ms: 111.232\n",
      "    sample_throughput: 49.901\n",
      "    sample_time_ms: 200316.658\n",
      "    update_time_ms: 4.367\n",
      "  timestamp: 1637492270\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4048290\n",
      "  training_iteration: 465\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   465</td><td style=\"text-align: right;\">          230952</td><td style=\"text-align: right;\">4048290</td><td style=\"text-align: right;\"> 4.78519</td><td style=\"text-align: right;\">               15.71</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           47.2453</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4058286\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_11-07-03\n",
      "  done: false\n",
      "  episode_len_mean: 47.99519230769231\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000007\n",
      "  episode_reward_mean: 4.9448076923076965\n",
      "  episode_reward_min: -0.45000000000000023\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 80276\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1630608386064627\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014682616715896147\n",
      "          policy_loss: -0.07678403697681567\n",
      "          total_loss: 0.05177134378127046\n",
      "          vf_explained_var: 0.954839289188385\n",
      "          vf_loss: 0.11673715240976597\n",
      "    num_agent_steps_sampled: 4058286\n",
      "    num_agent_steps_trained: 4058286\n",
      "    num_steps_sampled: 4058286\n",
      "    num_steps_trained: 4058286\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.92179974651457\n",
      "    ram_util_percent: 52.14980988593157\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05301464507003242\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.30449452365057\n",
      "    mean_inference_ms: 19.27077451355063\n",
      "    mean_raw_obs_processing_ms: 3.5783202455259695\n",
      "  time_since_restore: 36687.70379424095\n",
      "  time_this_iter_s: 553.2391996383667\n",
      "  time_total_s: 231505.06737971306\n",
      "  timers:\n",
      "    learn_throughput: 28.21\n",
      "    learn_time_ms: 354342.282\n",
      "    load_throughput: 89705.773\n",
      "    load_time_ms: 111.431\n",
      "    sample_throughput: 50.234\n",
      "    sample_time_ms: 198989.365\n",
      "    update_time_ms: 4.584\n",
      "  timestamp: 1637492823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4058286\n",
      "  training_iteration: 466\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   466</td><td style=\"text-align: right;\">          231505</td><td style=\"text-align: right;\">4058286</td><td style=\"text-align: right;\"> 4.94481</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">           47.9952</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4068282\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_11-16-27\n",
      "  done: false\n",
      "  episode_len_mean: 47.91866028708134\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.750000000000004\n",
      "  episode_reward_mean: 4.662105263157898\n",
      "  episode_reward_min: -0.4200000000000002\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 80485\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1577921257200967\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01516821458785881\n",
      "          policy_loss: -0.07599838756391382\n",
      "          total_loss: 0.06277546551567478\n",
      "          vf_explained_var: 0.9577246308326721\n",
      "          vf_loss: 0.1257966842017058\n",
      "    num_agent_steps_sampled: 4068282\n",
      "    num_agent_steps_trained: 4068282\n",
      "    num_steps_sampled: 4068282\n",
      "    num_steps_trained: 4068282\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.61714285714284\n",
      "    ram_util_percent: 51.18099378881987\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05299840977576481\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.29593862163288\n",
      "    mean_inference_ms: 19.266759755221432\n",
      "    mean_raw_obs_processing_ms: 3.5987241847399685\n",
      "  time_since_restore: 37251.72495174408\n",
      "  time_this_iter_s: 564.021157503128\n",
      "  time_total_s: 232069.0885372162\n",
      "  timers:\n",
      "    learn_throughput: 28.209\n",
      "    learn_time_ms: 354349.714\n",
      "    load_throughput: 89188.21\n",
      "    load_time_ms: 112.078\n",
      "    sample_throughput: 49.666\n",
      "    sample_time_ms: 201265.37\n",
      "    update_time_ms: 4.537\n",
      "  timestamp: 1637493387\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4068282\n",
      "  training_iteration: 467\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   467</td><td style=\"text-align: right;\">          232069</td><td style=\"text-align: right;\">4068282</td><td style=\"text-align: right;\"> 4.66211</td><td style=\"text-align: right;\">               11.75</td><td style=\"text-align: right;\">               -0.42</td><td style=\"text-align: right;\">           47.9187</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4078278\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_11-25-38\n",
      "  done: false\n",
      "  episode_len_mean: 48.37864077669903\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.640000000000006\n",
      "  episode_reward_mean: 4.744902912621363\n",
      "  episode_reward_min: -0.45000000000000023\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 80691\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1539613596406806\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01500184047053943\n",
      "          policy_loss: -0.07175303969919017\n",
      "          total_loss: 0.07643823916287476\n",
      "          vf_explained_var: 0.9509563446044922\n",
      "          vf_loss: 0.13555482271058208\n",
      "    num_agent_steps_sampled: 4078278\n",
      "    num_agent_steps_trained: 4078278\n",
      "    num_steps_sampled: 4078278\n",
      "    num_steps_trained: 4078278\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82557251908396\n",
      "    ram_util_percent: 51.162595419847335\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303444264761493\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.298304245703484\n",
      "    mean_inference_ms: 19.267101323460597\n",
      "    mean_raw_obs_processing_ms: 3.587638494383366\n",
      "  time_since_restore: 37802.89380145073\n",
      "  time_this_iter_s: 551.1688497066498\n",
      "  time_total_s: 232620.25738692284\n",
      "  timers:\n",
      "    learn_throughput: 28.21\n",
      "    learn_time_ms: 354340.55\n",
      "    load_throughput: 89121.495\n",
      "    load_time_ms: 112.161\n",
      "    sample_throughput: 49.688\n",
      "    sample_time_ms: 201175.556\n",
      "    update_time_ms: 4.874\n",
      "  timestamp: 1637493938\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4078278\n",
      "  training_iteration: 468\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   468</td><td style=\"text-align: right;\">          232620</td><td style=\"text-align: right;\">4078278</td><td style=\"text-align: right;\">  4.7449</td><td style=\"text-align: right;\">               13.64</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">           48.3786</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4088274\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_11-34-51\n",
      "  done: false\n",
      "  episode_len_mean: 48.14903846153846\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.690000000000005\n",
      "  episode_reward_mean: 4.8512019230769265\n",
      "  episode_reward_min: -0.4300000000000002\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 80899\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1541817574137188\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014634402282067516\n",
      "          policy_loss: -0.07554044471872479\n",
      "          total_loss: 0.06581749241112919\n",
      "          vf_explained_var: 0.9424532055854797\n",
      "          vf_loss: 0.12956075552966909\n",
      "    num_agent_steps_sampled: 4088274\n",
      "    num_agent_steps_trained: 4088274\n",
      "    num_steps_sampled: 4088274\n",
      "    num_steps_trained: 4088274\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.80481622306718\n",
      "    ram_util_percent: 51.54854245880862\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053008699114529885\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.30464296371056\n",
      "    mean_inference_ms: 19.26686214034858\n",
      "    mean_raw_obs_processing_ms: 3.580675203732229\n",
      "  time_since_restore: 38355.99492621422\n",
      "  time_this_iter_s: 553.1011247634888\n",
      "  time_total_s: 233173.35851168633\n",
      "  timers:\n",
      "    learn_throughput: 28.212\n",
      "    learn_time_ms: 354321.912\n",
      "    load_throughput: 89117.915\n",
      "    load_time_ms: 112.166\n",
      "    sample_throughput: 49.669\n",
      "    sample_time_ms: 201253.904\n",
      "    update_time_ms: 5.265\n",
      "  timestamp: 1637494491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4088274\n",
      "  training_iteration: 469\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   469</td><td style=\"text-align: right;\">          233173</td><td style=\"text-align: right;\">4088274</td><td style=\"text-align: right;\">  4.8512</td><td style=\"text-align: right;\">               15.69</td><td style=\"text-align: right;\">               -0.43</td><td style=\"text-align: right;\">            48.149</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4098270\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_11-44-05\n",
      "  done: false\n",
      "  episode_len_mean: 48.1256038647343\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.640000000000004\n",
      "  episode_reward_mean: 4.7556038647343035\n",
      "  episode_reward_min: -0.42000000000000015\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 81106\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1397353886839854\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015216789220793812\n",
      "          policy_loss: -0.07237690763814393\n",
      "          total_loss: 0.07494023395920375\n",
      "          vf_explained_var: 0.9472171068191528\n",
      "          vf_loss: 0.13404874614763437\n",
      "    num_agent_steps_sampled: 4098270\n",
      "    num_agent_steps_trained: 4098270\n",
      "    num_steps_sampled: 4098270\n",
      "    num_steps_trained: 4098270\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.63696202531645\n",
      "    ram_util_percent: 49.82683544303797\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05300728102650197\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.31210455177527\n",
      "    mean_inference_ms: 19.270712719210824\n",
      "    mean_raw_obs_processing_ms: 3.573553967198872\n",
      "  time_since_restore: 38909.4608399868\n",
      "  time_this_iter_s: 553.465913772583\n",
      "  time_total_s: 233726.8244254589\n",
      "  timers:\n",
      "    learn_throughput: 28.212\n",
      "    learn_time_ms: 354314.419\n",
      "    load_throughput: 88830.63\n",
      "    load_time_ms: 112.529\n",
      "    sample_throughput: 49.643\n",
      "    sample_time_ms: 201357.857\n",
      "    update_time_ms: 5.108\n",
      "  timestamp: 1637495045\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4098270\n",
      "  training_iteration: 470\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   470</td><td style=\"text-align: right;\">          233727</td><td style=\"text-align: right;\">4098270</td><td style=\"text-align: right;\">  4.7556</td><td style=\"text-align: right;\">               17.64</td><td style=\"text-align: right;\">               -0.42</td><td style=\"text-align: right;\">           48.1256</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4108266\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_11-53-06\n",
      "  done: false\n",
      "  episode_len_mean: 48.34782608695652\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 4.829371980676332\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 81313\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.146537560607535\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015594265049337464\n",
      "          policy_loss: -0.07568198000665882\n",
      "          total_loss: 0.07294344629093297\n",
      "          vf_explained_var: 0.9372114539146423\n",
      "          vf_loss: 0.13456511595436038\n",
      "    num_agent_steps_sampled: 4108266\n",
      "    num_agent_steps_trained: 4108266\n",
      "    num_steps_sampled: 4108266\n",
      "    num_steps_trained: 4108266\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.09196891191709\n",
      "    ram_util_percent: 50.15673575129534\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052975779030185875\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.32856352306966\n",
      "    mean_inference_ms: 19.273607148857455\n",
      "    mean_raw_obs_processing_ms: 3.5394917390804506\n",
      "  time_since_restore: 39450.50881075859\n",
      "  time_this_iter_s: 541.0479707717896\n",
      "  time_total_s: 234267.8723962307\n",
      "  timers:\n",
      "    learn_throughput: 28.212\n",
      "    learn_time_ms: 354322.742\n",
      "    load_throughput: 88873.713\n",
      "    load_time_ms: 112.474\n",
      "    sample_throughput: 49.963\n",
      "    sample_time_ms: 200067.366\n",
      "    update_time_ms: 5.139\n",
      "  timestamp: 1637495586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4108266\n",
      "  training_iteration: 471\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   471</td><td style=\"text-align: right;\">          234268</td><td style=\"text-align: right;\">4108266</td><td style=\"text-align: right;\"> 4.82937</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           48.3478</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4118262\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_12-02-33\n",
      "  done: false\n",
      "  episode_len_mean: 48.43689320388349\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 4.7845145631068\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 81519\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1507322008351246\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015275915322458158\n",
      "          policy_loss: -0.07461787324260133\n",
      "          total_loss: 0.06278819654421039\n",
      "          vf_explained_var: 0.9244546294212341\n",
      "          vf_loss: 0.12411294625679323\n",
      "    num_agent_steps_sampled: 4118262\n",
      "    num_agent_steps_trained: 4118262\n",
      "    num_steps_sampled: 4118262\n",
      "    num_steps_trained: 4118262\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.25802469135803\n",
      "    ram_util_percent: 51.348765432098766\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302252498915242\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.32640981474266\n",
      "    mean_inference_ms: 19.27361555408626\n",
      "    mean_raw_obs_processing_ms: 3.5575589566131502\n",
      "  time_since_restore: 40018.07520365715\n",
      "  time_this_iter_s: 567.5663928985596\n",
      "  time_total_s: 234835.43878912926\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354298.978\n",
      "    load_throughput: 89006.84\n",
      "    load_time_ms: 112.306\n",
      "    sample_throughput: 50.067\n",
      "    sample_time_ms: 199652.303\n",
      "    update_time_ms: 5.314\n",
      "  timestamp: 1637496153\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4118262\n",
      "  training_iteration: 472\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   472</td><td style=\"text-align: right;\">          234835</td><td style=\"text-align: right;\">4118262</td><td style=\"text-align: right;\"> 4.78451</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           48.4369</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4128258\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_12-12-24\n",
      "  done: false\n",
      "  episode_len_mean: 48.17307692307692\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000007\n",
      "  episode_reward_mean: 4.757692307692311\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 81727\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.163319004371942\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015418615225512864\n",
      "          policy_loss: -0.07970399278478743\n",
      "          total_loss: 0.0631381672357694\n",
      "          vf_explained_var: 0.9513898491859436\n",
      "          vf_loss: 0.12934981613189925\n",
      "    num_agent_steps_sampled: 4128258\n",
      "    num_agent_steps_trained: 4128258\n",
      "    num_steps_sampled: 4128258\n",
      "    num_steps_trained: 4128258\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.85931198102016\n",
      "    ram_util_percent: 51.28837485172006\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05297078692447363\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.303693135786396\n",
      "    mean_inference_ms: 19.264464200971112\n",
      "    mean_raw_obs_processing_ms: 3.6118957577660074\n",
      "  time_since_restore: 40608.96485042572\n",
      "  time_this_iter_s: 590.88964676857\n",
      "  time_total_s: 235426.32843589783\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354300.958\n",
      "    load_throughput: 88884.226\n",
      "    load_time_ms: 112.461\n",
      "    sample_throughput: 49.097\n",
      "    sample_time_ms: 203596.943\n",
      "    update_time_ms: 5.659\n",
      "  timestamp: 1637496744\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4128258\n",
      "  training_iteration: 473\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   473</td><td style=\"text-align: right;\">          235426</td><td style=\"text-align: right;\">4128258</td><td style=\"text-align: right;\"> 4.75769</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           48.1731</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4138254\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_12-21-24\n",
      "  done: false\n",
      "  episode_len_mean: 48.08653846153846\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.580000000000007\n",
      "  episode_reward_mean: 4.761875000000003\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 81935\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.162716326153422\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014782865803374472\n",
      "          policy_loss: -0.07791348079213989\n",
      "          total_loss: 0.05364975722920232\n",
      "          vf_explained_var: 0.9566330909729004\n",
      "          vf_loss: 0.1195131830153912\n",
      "    num_agent_steps_sampled: 4138254\n",
      "    num_agent_steps_trained: 4138254\n",
      "    num_steps_sampled: 4138254\n",
      "    num_steps_trained: 4138254\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01883116883117\n",
      "    ram_util_percent: 50.655064935064935\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052987396968904824\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.31315073174897\n",
      "    mean_inference_ms: 19.266772050411465\n",
      "    mean_raw_obs_processing_ms: 3.5854739709466674\n",
      "  time_since_restore: 41148.740652799606\n",
      "  time_this_iter_s: 539.7758023738861\n",
      "  time_total_s: 235966.1042382717\n",
      "  timers:\n",
      "    learn_throughput: 28.21\n",
      "    learn_time_ms: 354338.192\n",
      "    load_throughput: 88881.758\n",
      "    load_time_ms: 112.464\n",
      "    sample_throughput: 49.37\n",
      "    sample_time_ms: 202469.7\n",
      "    update_time_ms: 5.851\n",
      "  timestamp: 1637497284\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4138254\n",
      "  training_iteration: 474\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   474</td><td style=\"text-align: right;\">          235966</td><td style=\"text-align: right;\">4138254</td><td style=\"text-align: right;\"> 4.76188</td><td style=\"text-align: right;\">               13.58</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           48.0865</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4148250\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_12-30-23\n",
      "  done: false\n",
      "  episode_len_mean: 48.650485436893206\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.679999999999993\n",
      "  episode_reward_mean: 4.597524271844663\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 82141\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1683902518337512\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015825240248420903\n",
      "          policy_loss: -0.07551504226589659\n",
      "          total_loss: 0.06832541643885766\n",
      "          vf_explained_var: 0.9334242939949036\n",
      "          vf_loss: 0.1294724843764012\n",
      "    num_agent_steps_sampled: 4148250\n",
      "    num_agent_steps_trained: 4148250\n",
      "    num_steps_sampled: 4148250\n",
      "    num_steps_trained: 4148250\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02330729166665\n",
      "    ram_util_percent: 50.99609375\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05299301662420852\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.31947032217904\n",
      "    mean_inference_ms: 19.271325667284874\n",
      "    mean_raw_obs_processing_ms: 3.5536460591748282\n",
      "  time_since_restore: 41687.15935564041\n",
      "  time_this_iter_s: 538.418702840805\n",
      "  time_total_s: 236504.52294111252\n",
      "  timers:\n",
      "    learn_throughput: 28.211\n",
      "    learn_time_ms: 354326.104\n",
      "    load_throughput: 88770.838\n",
      "    load_time_ms: 112.605\n",
      "    sample_throughput: 49.778\n",
      "    sample_time_ms: 200810.801\n",
      "    update_time_ms: 6.106\n",
      "  timestamp: 1637497823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4148250\n",
      "  training_iteration: 475\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   475</td><td style=\"text-align: right;\">          236505</td><td style=\"text-align: right;\">4148250</td><td style=\"text-align: right;\"> 4.59752</td><td style=\"text-align: right;\">               17.68</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           48.6505</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4158246\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_12-40-03\n",
      "  done: false\n",
      "  episode_len_mean: 48.02884615384615\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.740000000000004\n",
      "  episode_reward_mean: 4.530721153846158\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 82349\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1517241909561386\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01450249708076564\n",
      "          policy_loss: -0.07655714787092675\n",
      "          total_loss: 0.056320012745302496\n",
      "          vf_explained_var: 0.9515449404716492\n",
      "          vf_loss: 0.12135589985021701\n",
      "    num_agent_steps_sampled: 4158246\n",
      "    num_agent_steps_trained: 4158246\n",
      "    num_steps_sampled: 4158246\n",
      "    num_steps_trained: 4158246\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.33091787439614\n",
      "    ram_util_percent: 51.43212560386474\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529820069991751\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.30253455618784\n",
      "    mean_inference_ms: 19.265648620626354\n",
      "    mean_raw_obs_processing_ms: 3.59948451121235\n",
      "  time_since_restore: 42267.79948425293\n",
      "  time_this_iter_s: 580.6401286125183\n",
      "  time_total_s: 237085.16306972504\n",
      "  timers:\n",
      "    learn_throughput: 28.212\n",
      "    learn_time_ms: 354318.138\n",
      "    load_throughput: 88753.55\n",
      "    load_time_ms: 112.626\n",
      "    sample_throughput: 49.106\n",
      "    sample_time_ms: 203559.116\n",
      "    update_time_ms: 5.637\n",
      "  timestamp: 1637498403\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4158246\n",
      "  training_iteration: 476\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   476</td><td style=\"text-align: right;\">          237085</td><td style=\"text-align: right;\">4158246</td><td style=\"text-align: right;\"> 4.53072</td><td style=\"text-align: right;\">               13.74</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           48.0288</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4168242\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_12-49-15\n",
      "  done: false\n",
      "  episode_len_mean: 48.07692307692308\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.68999999999998\n",
      "  episode_reward_mean: 4.665096153846156\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 82557\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.142909423917173\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015047463344105045\n",
      "          policy_loss: -0.07454034387638131\n",
      "          total_loss: 0.05519834866141339\n",
      "          vf_explained_var: 0.9472811222076416\n",
      "          vf_loss: 0.11688778287624514\n",
      "    num_agent_steps_sampled: 4168242\n",
      "    num_agent_steps_trained: 4168242\n",
      "    num_steps_sampled: 4168242\n",
      "    num_steps_trained: 4168242\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7247461928934\n",
      "    ram_util_percent: 50.973477157360406\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05297975490184189\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.30252790756405\n",
      "    mean_inference_ms: 19.265125688555614\n",
      "    mean_raw_obs_processing_ms: 3.588197833555463\n",
      "  time_since_restore: 42819.63331460953\n",
      "  time_this_iter_s: 551.8338303565979\n",
      "  time_total_s: 237636.99690008163\n",
      "  timers:\n",
      "    learn_throughput: 28.215\n",
      "    learn_time_ms: 354281.618\n",
      "    load_throughput: 89059.382\n",
      "    load_time_ms: 112.24\n",
      "    sample_throughput: 49.393\n",
      "    sample_time_ms: 202376.535\n",
      "    update_time_ms: 5.714\n",
      "  timestamp: 1637498955\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4168242\n",
      "  training_iteration: 477\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   477</td><td style=\"text-align: right;\">          237637</td><td style=\"text-align: right;\">4168242</td><td style=\"text-align: right;\">  4.6651</td><td style=\"text-align: right;\">               17.69</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           48.0769</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4178238\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_12-58-56\n",
      "  done: false\n",
      "  episode_len_mean: 48.03365384615385\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000004\n",
      "  episode_reward_mean: 4.899951923076927\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 82765\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.154285291208321\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014802065238830956\n",
      "          policy_loss: -0.07643829377864962\n",
      "          total_loss: 0.05046304718061764\n",
      "          vf_explained_var: 0.9605068564414978\n",
      "          vf_loss: 0.11472323830220774\n",
      "    num_agent_steps_sampled: 4178238\n",
      "    num_agent_steps_trained: 4178238\n",
      "    num_steps_sampled: 4178238\n",
      "    num_steps_trained: 4178238\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.92846803377563\n",
      "    ram_util_percent: 51.5431845597105\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293808976915444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.29033207720376\n",
      "    mean_inference_ms: 19.260191594043697\n",
      "    mean_raw_obs_processing_ms: 3.625207102101177\n",
      "  time_since_restore: 43400.70605802536\n",
      "  time_this_iter_s: 581.0727434158325\n",
      "  time_total_s: 238218.06964349747\n",
      "  timers:\n",
      "    learn_throughput: 28.219\n",
      "    learn_time_ms: 354227.553\n",
      "    load_throughput: 89219.716\n",
      "    load_time_ms: 112.038\n",
      "    sample_throughput: 48.661\n",
      "    sample_time_ms: 205420.974\n",
      "    update_time_ms: 5.455\n",
      "  timestamp: 1637499536\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4178238\n",
      "  training_iteration: 478\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   478</td><td style=\"text-align: right;\">          238218</td><td style=\"text-align: right;\">4178238</td><td style=\"text-align: right;\"> 4.89995</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           48.0337</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4188234\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_13-08-07\n",
      "  done: false\n",
      "  episode_len_mean: 48.872549019607845\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.710000000000004\n",
      "  episode_reward_mean: 4.636911764705886\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 82969\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1421089600367718\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015677711596613044\n",
      "          policy_loss: -0.07468274892454506\n",
      "          total_loss: 0.06493452797815161\n",
      "          vf_explained_var: 0.9452487826347351\n",
      "          vf_loss: 0.1253225787805513\n",
      "    num_agent_steps_sampled: 4188234\n",
      "    num_agent_steps_trained: 4188234\n",
      "    num_steps_sampled: 4188234\n",
      "    num_steps_trained: 4188234\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.86361323155215\n",
      "    ram_util_percent: 50.78422391857506\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293822787595139\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.290502209400394\n",
      "    mean_inference_ms: 19.26114985685495\n",
      "    mean_raw_obs_processing_ms: 3.617731225473175\n",
      "  time_since_restore: 43951.460569143295\n",
      "  time_this_iter_s: 550.7545111179352\n",
      "  time_total_s: 238768.8241546154\n",
      "  timers:\n",
      "    learn_throughput: 28.225\n",
      "    learn_time_ms: 354153.436\n",
      "    load_throughput: 89120.794\n",
      "    load_time_ms: 112.162\n",
      "    sample_throughput: 48.699\n",
      "    sample_time_ms: 205260.739\n",
      "    update_time_ms: 5.157\n",
      "  timestamp: 1637500087\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4188234\n",
      "  training_iteration: 479\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   479</td><td style=\"text-align: right;\">          238769</td><td style=\"text-align: right;\">4188234</td><td style=\"text-align: right;\"> 4.63691</td><td style=\"text-align: right;\">               13.71</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           48.8725</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4198230\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_13-17-19\n",
      "  done: false\n",
      "  episode_len_mean: 48.111111111111114\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.560000000000008\n",
      "  episode_reward_mean: 4.84618357487923\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 83176\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.158820813654896\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015188976877190254\n",
      "          policy_loss: -0.07321184910345266\n",
      "          total_loss: 0.07478334994422883\n",
      "          vf_explained_var: 0.9494154453277588\n",
      "          vf_loss: 0.1349810186363981\n",
      "    num_agent_steps_sampled: 4198230\n",
      "    num_agent_steps_trained: 4198230\n",
      "    num_steps_sampled: 4198230\n",
      "    num_steps_trained: 4198230\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.84098984771575\n",
      "    ram_util_percent: 50.07982233502538\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529681958790696\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.29377588437289\n",
      "    mean_inference_ms: 19.262111792207946\n",
      "    mean_raw_obs_processing_ms: 3.6126297039936377\n",
      "  time_since_restore: 44503.880929231644\n",
      "  time_this_iter_s: 552.4203600883484\n",
      "  time_total_s: 239321.24451470375\n",
      "  timers:\n",
      "    learn_throughput: 28.229\n",
      "    learn_time_ms: 354104.58\n",
      "    load_throughput: 89335.453\n",
      "    load_time_ms: 111.893\n",
      "    sample_throughput: 48.712\n",
      "    sample_time_ms: 205204.628\n",
      "    update_time_ms: 5.771\n",
      "  timestamp: 1637500639\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4198230\n",
      "  training_iteration: 480\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   480</td><td style=\"text-align: right;\">          239321</td><td style=\"text-align: right;\">4198230</td><td style=\"text-align: right;\"> 4.84618</td><td style=\"text-align: right;\">               15.56</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           48.1111</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4208226\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_13-26-19\n",
      "  done: false\n",
      "  episode_len_mean: 48.3768115942029\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.67\n",
      "  episode_reward_mean: 4.931449275362322\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 83383\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1384525899666857\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015234376521683518\n",
      "          policy_loss: -0.07607471108936609\n",
      "          total_loss: 0.07084932545821135\n",
      "          vf_explained_var: 0.9508056640625\n",
      "          vf_loss: 0.13360274693289076\n",
      "    num_agent_steps_sampled: 4208226\n",
      "    num_agent_steps_trained: 4208226\n",
      "    num_steps_sampled: 4208226\n",
      "    num_steps_trained: 4208226\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.06371911573473\n",
      "    ram_util_percent: 50.75422626788036\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05295829759616043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.30056891462469\n",
      "    mean_inference_ms: 19.26472859652126\n",
      "    mean_raw_obs_processing_ms: 3.583293136271672\n",
      "  time_since_restore: 45043.07541680336\n",
      "  time_this_iter_s: 539.1944875717163\n",
      "  time_total_s: 239860.43900227547\n",
      "  timers:\n",
      "    learn_throughput: 28.233\n",
      "    learn_time_ms: 354054.925\n",
      "    load_throughput: 89479.44\n",
      "    load_time_ms: 111.713\n",
      "    sample_throughput: 48.745\n",
      "    sample_time_ms: 205068.672\n",
      "    update_time_ms: 6.089\n",
      "  timestamp: 1637501179\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4208226\n",
      "  training_iteration: 481\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   481</td><td style=\"text-align: right;\">          239860</td><td style=\"text-align: right;\">4208226</td><td style=\"text-align: right;\"> 4.93145</td><td style=\"text-align: right;\">               17.67</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           48.3768</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4218222\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_13-35-27\n",
      "  done: false\n",
      "  episode_len_mean: 49.633663366336634\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.169207920792083\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 83585\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.134675973175041\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01503009979170253\n",
      "          policy_loss: -0.07780666926754196\n",
      "          total_loss: 0.058945189755102906\n",
      "          vf_explained_var: 0.9541347026824951\n",
      "          vf_loss: 0.12385817063966743\n",
      "    num_agent_steps_sampled: 4218222\n",
      "    num_agent_steps_trained: 4218222\n",
      "    num_steps_sampled: 4218222\n",
      "    num_steps_trained: 4218222\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77263427109975\n",
      "    ram_util_percent: 51.85959079283887\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052950197405883664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.288204994988426\n",
      "    mean_inference_ms: 19.263079286467356\n",
      "    mean_raw_obs_processing_ms: 3.575851800883707\n",
      "  time_since_restore: 45591.06539416313\n",
      "  time_this_iter_s: 547.9899773597717\n",
      "  time_total_s: 240408.42897963524\n",
      "  timers:\n",
      "    learn_throughput: 28.236\n",
      "    learn_time_ms: 354020.264\n",
      "    load_throughput: 89328.601\n",
      "    load_time_ms: 111.901\n",
      "    sample_throughput: 49.206\n",
      "    sample_time_ms: 203145.61\n",
      "    update_time_ms: 6.314\n",
      "  timestamp: 1637501727\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4218222\n",
      "  training_iteration: 482\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   482</td><td style=\"text-align: right;\">          240408</td><td style=\"text-align: right;\">4218222</td><td style=\"text-align: right;\"> 5.16921</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           49.6337</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4228218\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_13-44-52\n",
      "  done: false\n",
      "  episode_len_mean: 47.8421052631579\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000005\n",
      "  episode_reward_mean: 5.100526315789477\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 83794\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.134994918945803\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015018455119744572\n",
      "          policy_loss: -0.07541470876532116\n",
      "          total_loss: 0.06508973770620455\n",
      "          vf_explained_var: 0.9484106302261353\n",
      "          vf_loss: 0.1276404766117159\n",
      "    num_agent_steps_sampled: 4228218\n",
      "    num_agent_steps_trained: 4228218\n",
      "    num_steps_sampled: 4228218\n",
      "    num_steps_trained: 4228218\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.63506815365551\n",
      "    ram_util_percent: 51.219454770755895\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05292887102812109\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28753385380464\n",
      "    mean_inference_ms: 19.260451781904617\n",
      "    mean_raw_obs_processing_ms: 3.588782663597022\n",
      "  time_since_restore: 46156.78401494026\n",
      "  time_this_iter_s: 565.7186207771301\n",
      "  time_total_s: 240974.14760041237\n",
      "  timers:\n",
      "    learn_throughput: 28.233\n",
      "    learn_time_ms: 354055.838\n",
      "    load_throughput: 89323.482\n",
      "    load_time_ms: 111.908\n",
      "    sample_throughput: 49.832\n",
      "    sample_time_ms: 200593.59\n",
      "    update_time_ms: 6.051\n",
      "  timestamp: 1637502292\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4228218\n",
      "  training_iteration: 483\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   483</td><td style=\"text-align: right;\">          240974</td><td style=\"text-align: right;\">4228218</td><td style=\"text-align: right;\"> 5.10053</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           47.8421</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4238214\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_13-53-51\n",
      "  done: false\n",
      "  episode_len_mean: 48.6747572815534\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000007\n",
      "  episode_reward_mean: 4.3716990291262166\n",
      "  episode_reward_min: -0.4800000000000002\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 84000\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1747472422429355\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014237223596526552\n",
      "          policy_loss: -0.07723927749556968\n",
      "          total_loss: 0.041634050546666176\n",
      "          vf_explained_var: 0.9412339925765991\n",
      "          vf_loss: 0.10818662428863751\n",
      "    num_agent_steps_sampled: 4238214\n",
      "    num_agent_steps_trained: 4238214\n",
      "    num_steps_sampled: 4238214\n",
      "    num_steps_trained: 4238214\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02080624187256\n",
      "    ram_util_percent: 51.77373211963589\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293627046730065\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.29272528512938\n",
      "    mean_inference_ms: 19.264102985823627\n",
      "    mean_raw_obs_processing_ms: 3.5613980329558528\n",
      "  time_since_restore: 46695.60079622269\n",
      "  time_this_iter_s: 538.8167812824249\n",
      "  time_total_s: 241512.9643816948\n",
      "  timers:\n",
      "    learn_throughput: 28.229\n",
      "    learn_time_ms: 354100.96\n",
      "    load_throughput: 89271.749\n",
      "    load_time_ms: 111.973\n",
      "    sample_throughput: 49.867\n",
      "    sample_time_ms: 200452.461\n",
      "    update_time_ms: 6.054\n",
      "  timestamp: 1637502831\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4238214\n",
      "  training_iteration: 484\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   484</td><td style=\"text-align: right;\">          241513</td><td style=\"text-align: right;\">4238214</td><td style=\"text-align: right;\">  4.3717</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           48.6748</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4248210\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_14-03-03\n",
      "  done: false\n",
      "  episode_len_mean: 48.398058252427184\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.640000000000006\n",
      "  episode_reward_mean: 5.1411650485436935\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 84206\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.132552768188308\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01534516251389677\n",
      "          policy_loss: -0.07480397236677346\n",
      "          total_loss: 0.06784613007851341\n",
      "          vf_explained_var: 0.9574026465415955\n",
      "          vf_loss: 0.12901743020634185\n",
      "    num_agent_steps_sampled: 4248210\n",
      "    num_agent_steps_trained: 4248210\n",
      "    num_steps_sampled: 4248210\n",
      "    num_steps_trained: 4248210\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.79885641677257\n",
      "    ram_util_percent: 52.51232528589581\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05291746691497029\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.29385189769116\n",
      "    mean_inference_ms: 19.264156756929594\n",
      "    mean_raw_obs_processing_ms: 3.5562829030183725\n",
      "  time_since_restore: 47247.210936784744\n",
      "  time_this_iter_s: 551.6101405620575\n",
      "  time_total_s: 242064.57452225685\n",
      "  timers:\n",
      "    learn_throughput: 28.233\n",
      "    learn_time_ms: 354058.513\n",
      "    load_throughput: 89219.849\n",
      "    load_time_ms: 112.038\n",
      "    sample_throughput: 49.531\n",
      "    sample_time_ms: 201813.91\n",
      "    update_time_ms: 5.687\n",
      "  timestamp: 1637503383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4248210\n",
      "  training_iteration: 485\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   485</td><td style=\"text-align: right;\">          242065</td><td style=\"text-align: right;\">4248210</td><td style=\"text-align: right;\"> 5.14117</td><td style=\"text-align: right;\">               13.64</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           48.3981</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4258206\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_14-12-16\n",
      "  done: false\n",
      "  episode_len_mean: 48.57560975609756\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000005\n",
      "  episode_reward_mean: 4.462682926829271\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 84411\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.143595189574253\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014866112535327096\n",
      "          policy_loss: -0.07504381659615669\n",
      "          total_loss: 0.054627478702605\n",
      "          vf_explained_var: 0.9505674839019775\n",
      "          vf_loss: 0.11724038301709007\n",
      "    num_agent_steps_sampled: 4258206\n",
      "    num_agent_steps_trained: 4258206\n",
      "    num_steps_sampled: 4258206\n",
      "    num_steps_trained: 4258206\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75766793409377\n",
      "    ram_util_percent: 51.51242078580482\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052902605533852905\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28787377024741\n",
      "    mean_inference_ms: 19.26365027832251\n",
      "    mean_raw_obs_processing_ms: 3.5729100794014426\n",
      "  time_since_restore: 47799.840368270874\n",
      "  time_this_iter_s: 552.6294314861298\n",
      "  time_total_s: 242617.20395374298\n",
      "  timers:\n",
      "    learn_throughput: 28.235\n",
      "    learn_time_ms: 354031.334\n",
      "    load_throughput: 89415.264\n",
      "    load_time_ms: 111.793\n",
      "    sample_throughput: 50.221\n",
      "    sample_time_ms: 199039.642\n",
      "    update_time_ms: 5.832\n",
      "  timestamp: 1637503936\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4258206\n",
      "  training_iteration: 486\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   486</td><td style=\"text-align: right;\">          242617</td><td style=\"text-align: right;\">4258206</td><td style=\"text-align: right;\"> 4.46268</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           48.5756</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4268202\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_14-21-28\n",
      "  done: false\n",
      "  episode_len_mean: 47.98086124401914\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 4.56813397129187\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 84620\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1575727542241414\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014835797123919258\n",
      "          policy_loss: -0.07600733107910472\n",
      "          total_loss: 0.04937331079609468\n",
      "          vf_explained_var: 0.9574404358863831\n",
      "          vf_loss: 0.11315856756844435\n",
      "    num_agent_steps_sampled: 4268202\n",
      "    num_agent_steps_trained: 4268202\n",
      "    num_steps_sampled: 4268202\n",
      "    num_steps_trained: 4268202\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81979695431473\n",
      "    ram_util_percent: 51.688197969543154\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288059404944848\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.2887754784345\n",
      "    mean_inference_ms: 19.262474576927044\n",
      "    mean_raw_obs_processing_ms: 3.5665863645136993\n",
      "  time_since_restore: 48352.21265864372\n",
      "  time_this_iter_s: 552.3722903728485\n",
      "  time_total_s: 243169.57624411583\n",
      "  timers:\n",
      "    learn_throughput: 28.232\n",
      "    learn_time_ms: 354069.32\n",
      "    load_throughput: 89285.228\n",
      "    load_time_ms: 111.956\n",
      "    sample_throughput: 50.217\n",
      "    sample_time_ms: 199056.212\n",
      "    update_time_ms: 6.108\n",
      "  timestamp: 1637504488\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4268202\n",
      "  training_iteration: 487\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   487</td><td style=\"text-align: right;\">          243170</td><td style=\"text-align: right;\">4268202</td><td style=\"text-align: right;\"> 4.56813</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           47.9809</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4278198\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_14-30-39\n",
      "  done: false\n",
      "  episode_len_mean: 48.80975609756098\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 4.889804878048785\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 84825\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1460834879951785\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014349111875437732\n",
      "          policy_loss: -0.07618936496991333\n",
      "          total_loss: 0.0517690355781967\n",
      "          vf_explained_var: 0.945921003818512\n",
      "          vf_loss: 0.11673016464739784\n",
      "    num_agent_steps_sampled: 4278198\n",
      "    num_agent_steps_trained: 4278198\n",
      "    num_steps_sampled: 4278198\n",
      "    num_steps_trained: 4278198\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82076433121017\n",
      "    ram_util_percent: 51.97108280254778\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05286537984840722\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.281835959231394\n",
      "    mean_inference_ms: 19.261819048024677\n",
      "    mean_raw_obs_processing_ms: 3.560471595079844\n",
      "  time_since_restore: 48902.982308387756\n",
      "  time_this_iter_s: 550.7696497440338\n",
      "  time_total_s: 243720.34589385986\n",
      "  timers:\n",
      "    learn_throughput: 28.224\n",
      "    learn_time_ms: 354172.657\n",
      "    load_throughput: 89347.523\n",
      "    load_time_ms: 111.878\n",
      "    sample_throughput: 51.02\n",
      "    sample_time_ms: 195923.102\n",
      "    update_time_ms: 6.019\n",
      "  timestamp: 1637505039\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4278198\n",
      "  training_iteration: 488\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   488</td><td style=\"text-align: right;\">          243720</td><td style=\"text-align: right;\">4278198</td><td style=\"text-align: right;\">  4.8898</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           48.8098</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4288194\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_14-39-53\n",
      "  done: false\n",
      "  episode_len_mean: 47.856459330143544\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 5.309712918660291\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 85034\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1261339751113373\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015362579390397544\n",
      "          policy_loss: -0.07232370864364483\n",
      "          total_loss: 0.07138759079988884\n",
      "          vf_explained_var: 0.9506874084472656\n",
      "          vf_loss: 0.12997476185151155\n",
      "    num_agent_steps_sampled: 4288194\n",
      "    num_agent_steps_trained: 4288194\n",
      "    num_steps_sampled: 4288194\n",
      "    num_steps_trained: 4288194\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8566371681416\n",
      "    ram_util_percent: 50.91504424778761\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05285043772800302\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.287634913263105\n",
      "    mean_inference_ms: 19.26341715826147\n",
      "    mean_raw_obs_processing_ms: 3.554534466160637\n",
      "  time_since_restore: 49456.90622854233\n",
      "  time_this_iter_s: 553.9239201545715\n",
      "  time_total_s: 244274.26981401443\n",
      "  timers:\n",
      "    learn_throughput: 28.215\n",
      "    learn_time_ms: 354279.834\n",
      "    load_throughput: 89487.901\n",
      "    load_time_ms: 111.702\n",
      "    sample_throughput: 50.965\n",
      "    sample_time_ms: 196133.003\n",
      "    update_time_ms: 5.932\n",
      "  timestamp: 1637505593\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4288194\n",
      "  training_iteration: 489\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   489</td><td style=\"text-align: right;\">          244274</td><td style=\"text-align: right;\">4288194</td><td style=\"text-align: right;\"> 5.30971</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           47.8565</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4298190\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_14-49-21\n",
      "  done: false\n",
      "  episode_len_mean: 47.67788461538461\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000005\n",
      "  episode_reward_mean: 4.873221153846158\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 85242\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.118584254635386\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015520775744521329\n",
      "          policy_loss: -0.0752549256776074\n",
      "          total_loss: 0.06987416778087735\n",
      "          vf_explained_var: 0.936764657497406\n",
      "          vf_loss: 0.13095666773123554\n",
      "    num_agent_steps_sampled: 4298190\n",
      "    num_agent_steps_trained: 4298190\n",
      "    num_steps_sampled: 4298190\n",
      "    num_steps_trained: 4298190\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.6232098765432\n",
      "    ram_util_percent: 51.4183950617284\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05283659667830494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.284000068010066\n",
      "    mean_inference_ms: 19.2610663180214\n",
      "    mean_raw_obs_processing_ms: 3.5694533843596363\n",
      "  time_since_restore: 50024.66609501839\n",
      "  time_this_iter_s: 567.759866476059\n",
      "  time_total_s: 244842.0296804905\n",
      "  timers:\n",
      "    learn_throughput: 28.212\n",
      "    learn_time_ms: 354319.946\n",
      "    load_throughput: 89738.645\n",
      "    load_time_ms: 111.39\n",
      "    sample_throughput: 50.58\n",
      "    sample_time_ms: 197627.514\n",
      "    update_time_ms: 5.502\n",
      "  timestamp: 1637506161\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4298190\n",
      "  training_iteration: 490\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   490</td><td style=\"text-align: right;\">          244842</td><td style=\"text-align: right;\">4298190</td><td style=\"text-align: right;\"> 4.87322</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           47.6779</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4308186\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_14-58-21\n",
      "  done: false\n",
      "  episode_len_mean: 47.904761904761905\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.640000000000006\n",
      "  episode_reward_mean: 4.765000000000004\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 210\n",
      "  episodes_total: 85452\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1020290979659224\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015424343159486492\n",
      "          policy_loss: -0.07508050428693376\n",
      "          total_loss: 0.06916845860505344\n",
      "          vf_explained_var: 0.95048987865448\n",
      "          vf_loss: 0.1301306704739969\n",
      "    num_agent_steps_sampled: 4308186\n",
      "    num_agent_steps_trained: 4308186\n",
      "    num_steps_sampled: 4308186\n",
      "    num_steps_trained: 4308186\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.05836575875486\n",
      "    ram_util_percent: 51.62230869001297\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528178509037619\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.29164447226877\n",
      "    mean_inference_ms: 19.263058566363302\n",
      "    mean_raw_obs_processing_ms: 3.545830295677889\n",
      "  time_since_restore: 50565.12668848038\n",
      "  time_this_iter_s: 540.4605934619904\n",
      "  time_total_s: 245382.49027395248\n",
      "  timers:\n",
      "    learn_throughput: 28.206\n",
      "    learn_time_ms: 354392.231\n",
      "    load_throughput: 89483.088\n",
      "    load_time_ms: 111.708\n",
      "    sample_throughput: 50.566\n",
      "    sample_time_ms: 197682.111\n",
      "    update_time_ms: 5.149\n",
      "  timestamp: 1637506701\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4308186\n",
      "  training_iteration: 491\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   491</td><td style=\"text-align: right;\">          245382</td><td style=\"text-align: right;\">4308186</td><td style=\"text-align: right;\">   4.765</td><td style=\"text-align: right;\">               13.64</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           47.9048</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4318182\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_15-07-33\n",
      "  done: false\n",
      "  episode_len_mean: 48.616504854368934\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.710000000000004\n",
      "  episode_reward_mean: 5.0361165048543715\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 85658\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.114856803058142\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01581596640867787\n",
      "          policy_loss: -0.06781254022738224\n",
      "          total_loss: 0.08433496075578667\n",
      "          vf_explained_var: 0.9476137161254883\n",
      "          vf_loss: 0.13726531896201602\n",
      "    num_agent_steps_sampled: 4318182\n",
      "    num_agent_steps_trained: 4318182\n",
      "    num_steps_sampled: 4318182\n",
      "    num_steps_trained: 4318182\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.90609911054639\n",
      "    ram_util_percent: 50.86581956797966\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281637962095714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28948037000721\n",
      "    mean_inference_ms: 19.263000046971662\n",
      "    mean_raw_obs_processing_ms: 3.55535154157875\n",
      "  time_since_restore: 51116.902244091034\n",
      "  time_this_iter_s: 551.7755556106567\n",
      "  time_total_s: 245934.26582956314\n",
      "  timers:\n",
      "    learn_throughput: 28.199\n",
      "    learn_time_ms: 354474.778\n",
      "    load_throughput: 89323.215\n",
      "    load_time_ms: 111.908\n",
      "    sample_throughput: 50.49\n",
      "    sample_time_ms: 197978.186\n",
      "    update_time_ms: 4.973\n",
      "  timestamp: 1637507253\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4318182\n",
      "  training_iteration: 492\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   492</td><td style=\"text-align: right;\">          245934</td><td style=\"text-align: right;\">4318182</td><td style=\"text-align: right;\"> 5.03612</td><td style=\"text-align: right;\">               13.71</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           48.6165</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4328178\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_15-16-47\n",
      "  done: false\n",
      "  episode_len_mean: 48.5219512195122\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.550000000000008\n",
      "  episode_reward_mean: 4.729512195121955\n",
      "  episode_reward_min: -0.45000000000000023\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 85863\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.12505681294514\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015093008807079254\n",
      "          policy_loss: -0.07555754783876094\n",
      "          total_loss: 0.06204811115415772\n",
      "          vf_explained_var: 0.9543329477310181\n",
      "          vf_loss: 0.12447246487708725\n",
      "    num_agent_steps_sampled: 4328178\n",
      "    num_agent_steps_trained: 4328178\n",
      "    num_steps_sampled: 4328178\n",
      "    num_steps_trained: 4328178\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.06965865992416\n",
      "    ram_util_percent: 51.17180783817953\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052792278722067786\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28857622241864\n",
      "    mean_inference_ms: 19.263693764825753\n",
      "    mean_raw_obs_processing_ms: 3.551087701146653\n",
      "  time_since_restore: 51670.97294545174\n",
      "  time_this_iter_s: 554.0707013607025\n",
      "  time_total_s: 246488.33653092384\n",
      "  timers:\n",
      "    learn_throughput: 28.181\n",
      "    learn_time_ms: 354709.632\n",
      "    load_throughput: 89297.304\n",
      "    load_time_ms: 111.941\n",
      "    sample_throughput: 50.85\n",
      "    sample_time_ms: 196578.372\n",
      "    update_time_ms: 5.233\n",
      "  timestamp: 1637507807\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4328178\n",
      "  training_iteration: 493\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   493</td><td style=\"text-align: right;\">          246488</td><td style=\"text-align: right;\">4328178</td><td style=\"text-align: right;\"> 4.72951</td><td style=\"text-align: right;\">               15.55</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">            48.522</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4338174\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_15-26-00\n",
      "  done: false\n",
      "  episode_len_mean: 49.181372549019606\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 4.875784313725494\n",
      "  episode_reward_min: -0.45000000000000023\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 86067\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.114587903046704\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015236000136068809\n",
      "          policy_loss: -0.07577485638473325\n",
      "          total_loss: 0.06345924429666944\n",
      "          vf_explained_var: 0.9524962902069092\n",
      "          vf_loss: 0.1256704658222194\n",
      "    num_agent_steps_sampled: 4338174\n",
      "    num_agent_steps_trained: 4338174\n",
      "    num_steps_sampled: 4338174\n",
      "    num_steps_trained: 4338174\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8873257287706\n",
      "    ram_util_percent: 51.88491761723701\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052783412695446535\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.29164043217208\n",
      "    mean_inference_ms: 19.265226762587996\n",
      "    mean_raw_obs_processing_ms: 3.5445059037212125\n",
      "  time_since_restore: 52223.87602519989\n",
      "  time_this_iter_s: 552.9030797481537\n",
      "  time_total_s: 247041.239610672\n",
      "  timers:\n",
      "    learn_throughput: 28.177\n",
      "    learn_time_ms: 354751.811\n",
      "    load_throughput: 89304.874\n",
      "    load_time_ms: 111.931\n",
      "    sample_throughput: 50.499\n",
      "    sample_time_ms: 197945.053\n",
      "    update_time_ms: 5.099\n",
      "  timestamp: 1637508360\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4338174\n",
      "  training_iteration: 494\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   494</td><td style=\"text-align: right;\">          247041</td><td style=\"text-align: right;\">4338174</td><td style=\"text-align: right;\"> 4.87578</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">           49.1814</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4348170\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_15-35-15\n",
      "  done: false\n",
      "  episode_len_mean: 49.25615763546798\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.710000000000004\n",
      "  episode_reward_mean: 5.2064039408867036\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 203\n",
      "  episodes_total: 86270\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.085638584358146\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015799587280374273\n",
      "          policy_loss: -0.07126488119099512\n",
      "          total_loss: 0.09659617165202088\n",
      "          vf_explained_var: 0.9369630813598633\n",
      "          vf_loss: 0.152724002960772\n",
      "    num_agent_steps_sampled: 4348170\n",
      "    num_agent_steps_trained: 4348170\n",
      "    num_steps_sampled: 4348170\n",
      "    num_steps_trained: 4348170\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81641414141414\n",
      "    ram_util_percent: 50.67550505050505\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278091297284051\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.291801878460475\n",
      "    mean_inference_ms: 19.267341549979736\n",
      "    mean_raw_obs_processing_ms: 3.5395173674107716\n",
      "  time_since_restore: 52779.06114912033\n",
      "  time_this_iter_s: 555.1851239204407\n",
      "  time_total_s: 247596.42473459244\n",
      "  timers:\n",
      "    learn_throughput: 28.169\n",
      "    learn_time_ms: 354853.193\n",
      "    load_throughput: 89476.041\n",
      "    load_time_ms: 111.717\n",
      "    sample_throughput: 50.434\n",
      "    sample_time_ms: 198201.224\n",
      "    update_time_ms: 5.188\n",
      "  timestamp: 1637508915\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4348170\n",
      "  training_iteration: 495\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   495</td><td style=\"text-align: right;\">          247596</td><td style=\"text-align: right;\">4348170</td><td style=\"text-align: right;\">  5.2064</td><td style=\"text-align: right;\">               15.71</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           49.2562</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4358166\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_15-44-21\n",
      "  done: false\n",
      "  episode_len_mean: 49.73134328358209\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.690000000000005\n",
      "  episode_reward_mean: 4.810447761194034\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 86471\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1182275162403843\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01519677771253406\n",
      "          policy_loss: -0.07291868612386072\n",
      "          total_loss: 0.0715923981352143\n",
      "          vf_explained_var: 0.9472105503082275\n",
      "          vf_loss: 0.13107319840054255\n",
      "    num_agent_steps_sampled: 4358166\n",
      "    num_agent_steps_trained: 4358166\n",
      "    num_steps_sampled: 4358166\n",
      "    num_steps_trained: 4358166\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.46983311938382\n",
      "    ram_util_percent: 50.4836970474968\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278070920393859\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.30085213951358\n",
      "    mean_inference_ms: 19.272125296293535\n",
      "    mean_raw_obs_processing_ms: 3.5170748731843107\n",
      "  time_since_restore: 53325.20532274246\n",
      "  time_this_iter_s: 546.1441736221313\n",
      "  time_total_s: 248142.56890821457\n",
      "  timers:\n",
      "    learn_throughput: 28.129\n",
      "    learn_time_ms: 355361.683\n",
      "    load_throughput: 89241.118\n",
      "    load_time_ms: 112.011\n",
      "    sample_throughput: 50.73\n",
      "    sample_time_ms: 197044.132\n",
      "    update_time_ms: 5.56\n",
      "  timestamp: 1637509461\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4358166\n",
      "  training_iteration: 496\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   496</td><td style=\"text-align: right;\">          248143</td><td style=\"text-align: right;\">4358166</td><td style=\"text-align: right;\"> 4.81045</td><td style=\"text-align: right;\">               15.69</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           49.7313</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4368162\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_15-53-41\n",
      "  done: false\n",
      "  episode_len_mean: 48.86764705882353\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.680000000000005\n",
      "  episode_reward_mean: 5.103431372549023\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 86675\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1106245870092306\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015439381977495881\n",
      "          policy_loss: -0.07521024293012792\n",
      "          total_loss: 0.0667867700238629\n",
      "          vf_explained_var: 0.9523615837097168\n",
      "          vf_loss: 0.12793041513035874\n",
      "    num_agent_steps_sampled: 4368162\n",
      "    num_agent_steps_trained: 4368162\n",
      "    num_steps_sampled: 4368162\n",
      "    num_steps_trained: 4368162\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.27521902377971\n",
      "    ram_util_percent: 50.63792240300375\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279925573107316\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.31141450796895\n",
      "    mean_inference_ms: 19.277440981853093\n",
      "    mean_raw_obs_processing_ms: 3.5142190308550494\n",
      "  time_since_restore: 53885.211505651474\n",
      "  time_this_iter_s: 560.0061829090118\n",
      "  time_total_s: 248702.57509112358\n",
      "  timers:\n",
      "    learn_throughput: 28.094\n",
      "    learn_time_ms: 355811.189\n",
      "    load_throughput: 88702.457\n",
      "    load_time_ms: 112.691\n",
      "    sample_throughput: 50.649\n",
      "    sample_time_ms: 197357.78\n",
      "    update_time_ms: 5.286\n",
      "  timestamp: 1637510021\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4368162\n",
      "  training_iteration: 497\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   497</td><td style=\"text-align: right;\">          248703</td><td style=\"text-align: right;\">4368162</td><td style=\"text-align: right;\"> 5.10343</td><td style=\"text-align: right;\">               15.68</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           48.8676</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4378158\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_16-03-00\n",
      "  done: false\n",
      "  episode_len_mean: 49.935\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.640000000000006\n",
      "  episode_reward_mean: 4.668750000000004\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 200\n",
      "  episodes_total: 86875\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0948841613938054\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014765705167666022\n",
      "          policy_loss: -0.07231884447912205\n",
      "          total_loss: 0.06871197767223021\n",
      "          vf_explained_var: 0.9548239707946777\n",
      "          vf_loss: 0.12834154023755207\n",
      "    num_agent_steps_sampled: 4378158\n",
      "    num_agent_steps_trained: 4378158\n",
      "    num_steps_sampled: 4378158\n",
      "    num_steps_trained: 4378158\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13174404015056\n",
      "    ram_util_percent: 51.32409033877039\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282908691106107\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.31083526063341\n",
      "    mean_inference_ms: 19.280114383221047\n",
      "    mean_raw_obs_processing_ms: 3.507491040801572\n",
      "  time_since_restore: 54443.630353689194\n",
      "  time_this_iter_s: 558.4188480377197\n",
      "  time_total_s: 249260.9939391613\n",
      "  timers:\n",
      "    learn_throughput: 28.066\n",
      "    learn_time_ms: 356154.333\n",
      "    load_throughput: 89036.422\n",
      "    load_time_ms: 112.269\n",
      "    sample_throughput: 50.541\n",
      "    sample_time_ms: 197779.521\n",
      "    update_time_ms: 5.513\n",
      "  timestamp: 1637510580\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4378158\n",
      "  training_iteration: 498\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   498</td><td style=\"text-align: right;\">          249261</td><td style=\"text-align: right;\">4378158</td><td style=\"text-align: right;\"> 4.66875</td><td style=\"text-align: right;\">               13.64</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">            49.935</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4388154\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_16-12-26\n",
      "  done: false\n",
      "  episode_len_mean: 50.97969543147208\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.690000000000005\n",
      "  episode_reward_mean: 4.864619289340106\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 197\n",
      "  episodes_total: 87072\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1032592241543844\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015398482989090252\n",
      "          policy_loss: -0.07488687852681644\n",
      "          total_loss: 0.0720999665656801\n",
      "          vf_explained_var: 0.9379308223724365\n",
      "          vf_loss: 0.13293976789821\n",
      "    num_agent_steps_sampled: 4388154\n",
      "    num_agent_steps_trained: 4388154\n",
      "    num_steps_sampled: 4388154\n",
      "    num_steps_trained: 4388154\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.97682775712514\n",
      "    ram_util_percent: 52.95563816604709\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052833189409771164\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.29443146844543\n",
      "    mean_inference_ms: 19.28039510308797\n",
      "    mean_raw_obs_processing_ms: 3.535683935058387\n",
      "  time_since_restore: 55009.51433992386\n",
      "  time_this_iter_s: 565.8839862346649\n",
      "  time_total_s: 249826.87792539597\n",
      "  timers:\n",
      "    learn_throughput: 28.031\n",
      "    learn_time_ms: 356608.294\n",
      "    load_throughput: 88591.647\n",
      "    load_time_ms: 112.832\n",
      "    sample_throughput: 50.352\n",
      "    sample_time_ms: 198520.466\n",
      "    update_time_ms: 5.605\n",
      "  timestamp: 1637511146\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4388154\n",
      "  training_iteration: 499\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   499</td><td style=\"text-align: right;\">          249827</td><td style=\"text-align: right;\">4388154</td><td style=\"text-align: right;\"> 4.86462</td><td style=\"text-align: right;\">               15.69</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           50.9797</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4398150\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_16-21-44\n",
      "  done: false\n",
      "  episode_len_mean: 50.776649746192895\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.281472081218279\n",
      "  episode_reward_min: -0.43000000000000016\n",
      "  episodes_this_iter: 197\n",
      "  episodes_total: 87269\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.070782761952006\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015758530698497145\n",
      "          policy_loss: -0.07051582570082622\n",
      "          total_loss: 0.08126320113119162\n",
      "          vf_explained_var: 0.9586511850357056\n",
      "          vf_loss: 0.13658695175540614\n",
      "    num_agent_steps_sampled: 4398150\n",
      "    num_agent_steps_trained: 4398150\n",
      "    num_steps_sampled: 4398150\n",
      "    num_steps_trained: 4398150\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.23655778894475\n",
      "    ram_util_percent: 52.155150753768844\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05283650204303546\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.291795988673805\n",
      "    mean_inference_ms: 19.286196579846855\n",
      "    mean_raw_obs_processing_ms: 3.528360690584701\n",
      "  time_since_restore: 55567.56495523453\n",
      "  time_this_iter_s: 558.050615310669\n",
      "  time_total_s: 250384.92854070663\n",
      "  timers:\n",
      "    learn_throughput: 27.993\n",
      "    learn_time_ms: 357095.024\n",
      "    load_throughput: 87718.637\n",
      "    load_time_ms: 113.955\n",
      "    sample_throughput: 50.725\n",
      "    sample_time_ms: 197061.388\n",
      "    update_time_ms: 5.371\n",
      "  timestamp: 1637511704\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4398150\n",
      "  training_iteration: 500\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">          250385</td><td style=\"text-align: right;\">4398150</td><td style=\"text-align: right;\"> 5.28147</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.43</td><td style=\"text-align: right;\">           50.7766</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4408146\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_16-30-49\n",
      "  done: false\n",
      "  episode_len_mean: 50.93877551020408\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 5.115765306122452\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 196\n",
      "  episodes_total: 87465\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0824343729210666\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016011372019379327\n",
      "          policy_loss: -0.07089523468944445\n",
      "          total_loss: 0.08835470336522581\n",
      "          vf_explained_var: 0.9223991632461548\n",
      "          vf_loss: 0.1435983740516104\n",
      "    num_agent_steps_sampled: 4408146\n",
      "    num_agent_steps_trained: 4408146\n",
      "    num_steps_sampled: 4408146\n",
      "    num_steps_trained: 4408146\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.40629820051414\n",
      "    ram_util_percent: 52.00269922879177\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052879127897110086\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.295431509628045\n",
      "    mean_inference_ms: 19.292949603968832\n",
      "    mean_raw_obs_processing_ms: 3.50843623815943\n",
      "  time_since_restore: 56113.0577609539\n",
      "  time_this_iter_s: 545.4928057193756\n",
      "  time_total_s: 250930.421346426\n",
      "  timers:\n",
      "    learn_throughput: 27.958\n",
      "    learn_time_ms: 357531.703\n",
      "    load_throughput: 86851.67\n",
      "    load_time_ms: 115.093\n",
      "    sample_throughput: 50.709\n",
      "    sample_time_ms: 197126.453\n",
      "    update_time_ms: 5.407\n",
      "  timestamp: 1637512249\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4408146\n",
      "  training_iteration: 501\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   501</td><td style=\"text-align: right;\">          250930</td><td style=\"text-align: right;\">4408146</td><td style=\"text-align: right;\"> 5.11577</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           50.9388</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4418142\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_16-40-03\n",
      "  done: false\n",
      "  episode_len_mean: 51.46907216494845\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.720000000000002\n",
      "  episode_reward_mean: 4.8967525773195915\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 87659\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.106802829082711\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015751309439563172\n",
      "          policy_loss: -0.07260546151954142\n",
      "          total_loss: 0.07779822730393146\n",
      "          vf_explained_var: 0.9319349527359009\n",
      "          vf_loss: 0.1355882646467342\n",
      "    num_agent_steps_sampled: 4418142\n",
      "    num_agent_steps_trained: 4418142\n",
      "    num_steps_sampled: 4418142\n",
      "    num_steps_trained: 4418142\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.04962025316455\n",
      "    ram_util_percent: 52.107088607594925\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052864751202154316\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.28154524852791\n",
      "    mean_inference_ms: 19.296165758570393\n",
      "    mean_raw_obs_processing_ms: 3.5201188962744783\n",
      "  time_since_restore: 56666.565356492996\n",
      "  time_this_iter_s: 553.507595539093\n",
      "  time_total_s: 251483.9289419651\n",
      "  timers:\n",
      "    learn_throughput: 27.927\n",
      "    learn_time_ms: 357932.848\n",
      "    load_throughput: 86689.473\n",
      "    load_time_ms: 115.308\n",
      "    sample_throughput: 50.767\n",
      "    sample_time_ms: 196898.295\n",
      "    update_time_ms: 5.414\n",
      "  timestamp: 1637512803\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4418142\n",
      "  training_iteration: 502\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   502</td><td style=\"text-align: right;\">          251484</td><td style=\"text-align: right;\">4418142</td><td style=\"text-align: right;\"> 4.89675</td><td style=\"text-align: right;\">               13.72</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           51.4691</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4428138\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_16-49-31\n",
      "  done: false\n",
      "  episode_len_mean: 51.927083333333336\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000005\n",
      "  episode_reward_mean: 4.72354166666667\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 87851\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.110912274093513\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015759944435928347\n",
      "          policy_loss: -0.07367085517290474\n",
      "          total_loss: 0.07268986697020019\n",
      "          vf_explained_var: 0.9429516792297363\n",
      "          vf_loss: 0.13156672036667993\n",
      "    num_agent_steps_sampled: 4428138\n",
      "    num_agent_steps_trained: 4428138\n",
      "    num_steps_sampled: 4428138\n",
      "    num_steps_trained: 4428138\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8395061728395\n",
      "    ram_util_percent: 51.11617283950617\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287092737304822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.26442126687204\n",
      "    mean_inference_ms: 19.295571370923373\n",
      "    mean_raw_obs_processing_ms: 3.5348504918412273\n",
      "  time_since_restore: 57234.59893321991\n",
      "  time_this_iter_s: 568.0335767269135\n",
      "  time_total_s: 252051.96251869202\n",
      "  timers:\n",
      "    learn_throughput: 27.913\n",
      "    learn_time_ms: 358110.58\n",
      "    load_throughput: 86674.007\n",
      "    load_time_ms: 115.329\n",
      "    sample_throughput: 50.455\n",
      "    sample_time_ms: 198115.962\n",
      "    update_time_ms: 5.804\n",
      "  timestamp: 1637513371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4428138\n",
      "  training_iteration: 503\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   503</td><td style=\"text-align: right;\">          252052</td><td style=\"text-align: right;\">4428138</td><td style=\"text-align: right;\"> 4.72354</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           51.9271</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4438134\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_16-58-42\n",
      "  done: false\n",
      "  episode_len_mean: 52.213541666666664\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.700000000000005\n",
      "  episode_reward_mean: 4.949583333333337\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 88043\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0628356959685745\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014435238413113527\n",
      "          policy_loss: -0.07654797177624806\n",
      "          total_loss: 0.057457975503582046\n",
      "          vf_explained_var: 0.951920747756958\n",
      "          vf_loss: 0.12174902582629005\n",
      "    num_agent_steps_sampled: 4438134\n",
      "    num_agent_steps_trained: 4438134\n",
      "    num_steps_sampled: 4438134\n",
      "    num_steps_trained: 4438134\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00991105463787\n",
      "    ram_util_percent: 51.324015247776366\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05286437698571073\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.25293487417184\n",
      "    mean_inference_ms: 19.30076414559233\n",
      "    mean_raw_obs_processing_ms: 3.5306471024862573\n",
      "  time_since_restore: 57785.67945456505\n",
      "  time_this_iter_s: 551.0805213451385\n",
      "  time_total_s: 252603.04304003716\n",
      "  timers:\n",
      "    learn_throughput: 27.907\n",
      "    learn_time_ms: 358186.677\n",
      "    load_throughput: 86584.456\n",
      "    load_time_ms: 115.448\n",
      "    sample_throughput: 50.521\n",
      "    sample_time_ms: 197856.988\n",
      "    update_time_ms: 6.116\n",
      "  timestamp: 1637513922\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4438134\n",
      "  training_iteration: 504\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   504</td><td style=\"text-align: right;\">          252603</td><td style=\"text-align: right;\">4438134</td><td style=\"text-align: right;\"> 4.94958</td><td style=\"text-align: right;\">                13.7</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           52.2135</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4448130\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_17-07-33\n",
      "  done: false\n",
      "  episode_len_mean: 53.224598930481285\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000009\n",
      "  episode_reward_mean: 5.072352941176475\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 88230\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.073093560613303\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01510933373587989\n",
      "          policy_loss: -0.07255625660454898\n",
      "          total_loss: 0.07515877701445284\n",
      "          vf_explained_var: 0.9431435465812683\n",
      "          vf_loss: 0.13402501693337662\n",
      "    num_agent_steps_sampled: 4448130\n",
      "    num_agent_steps_trained: 4448130\n",
      "    num_steps_sampled: 4448130\n",
      "    num_steps_trained: 4448130\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.89339498018492\n",
      "    ram_util_percent: 51.67516512549538\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287199665363467\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.23449168891637\n",
      "    mean_inference_ms: 19.302463844062085\n",
      "    mean_raw_obs_processing_ms: 3.506385495440513\n",
      "  time_since_restore: 58316.793362379074\n",
      "  time_this_iter_s: 531.1139078140259\n",
      "  time_total_s: 253134.15694785118\n",
      "  timers:\n",
      "    learn_throughput: 27.907\n",
      "    learn_time_ms: 358185.756\n",
      "    load_throughput: 86452.569\n",
      "    load_time_ms: 115.624\n",
      "    sample_throughput: 51.143\n",
      "    sample_time_ms: 195450.424\n",
      "    update_time_ms: 6.381\n",
      "  timestamp: 1637514453\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4448130\n",
      "  training_iteration: 505\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   505</td><td style=\"text-align: right;\">          253134</td><td style=\"text-align: right;\">4448130</td><td style=\"text-align: right;\"> 5.07235</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.2246</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4458126\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_17-16-38\n",
      "  done: false\n",
      "  episode_len_mean: 52.12435233160622\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.610000000000007\n",
      "  episode_reward_mean: 4.869067357512957\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 88423\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0713444990565977\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014603594864613451\n",
      "          policy_loss: -0.06806703730040338\n",
      "          total_loss: 0.06669262918403693\n",
      "          vf_explained_var: 0.9464341998100281\n",
      "          vf_loss: 0.12220429553244502\n",
      "    num_agent_steps_sampled: 4458126\n",
      "    num_agent_steps_trained: 4458126\n",
      "    num_steps_sampled: 4458126\n",
      "    num_steps_trained: 4458126\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.72275064267353\n",
      "    ram_util_percent: 50.999100257069415\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052866176713919015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.216130293543976\n",
      "    mean_inference_ms: 19.300996433098238\n",
      "    mean_raw_obs_processing_ms: 3.5170968616750407\n",
      "  time_since_restore: 58861.73927640915\n",
      "  time_this_iter_s: 544.9459140300751\n",
      "  time_total_s: 253679.10286188126\n",
      "  timers:\n",
      "    learn_throughput: 27.943\n",
      "    learn_time_ms: 357728.216\n",
      "    load_throughput: 86597.171\n",
      "    load_time_ms: 115.431\n",
      "    sample_throughput: 51.055\n",
      "    sample_time_ms: 195788.558\n",
      "    update_time_ms: 5.977\n",
      "  timestamp: 1637514998\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4458126\n",
      "  training_iteration: 506\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   506</td><td style=\"text-align: right;\">          253679</td><td style=\"text-align: right;\">4458126</td><td style=\"text-align: right;\"> 4.86907</td><td style=\"text-align: right;\">               13.61</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           52.1244</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4468122\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_17-25-46\n",
      "  done: false\n",
      "  episode_len_mean: 51.885416666666664\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.66999999999998\n",
      "  episode_reward_mean: 5.554375000000004\n",
      "  episode_reward_min: -0.4100000000000002\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 88615\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.069133011428228\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01589231215332938\n",
      "          policy_loss: -0.0646299991870317\n",
      "          total_loss: 0.09919766967545163\n",
      "          vf_explained_var: 0.9468445777893066\n",
      "          vf_loss: 0.1483143240984821\n",
      "    num_agent_steps_sampled: 4468122\n",
      "    num_agent_steps_trained: 4468122\n",
      "    num_steps_sampled: 4468122\n",
      "    num_steps_trained: 4468122\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.38681177976953\n",
      "    ram_util_percent: 50.7877080665813\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05284814670073481\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.20016363157318\n",
      "    mean_inference_ms: 19.303297625675977\n",
      "    mean_raw_obs_processing_ms: 3.5128180383716416\n",
      "  time_since_restore: 59409.083511829376\n",
      "  time_this_iter_s: 547.344235420227\n",
      "  time_total_s: 254226.44709730148\n",
      "  timers:\n",
      "    learn_throughput: 27.974\n",
      "    learn_time_ms: 357335.196\n",
      "    load_throughput: 87165.549\n",
      "    load_time_ms: 114.678\n",
      "    sample_throughput: 51.284\n",
      "    sample_time_ms: 194916.043\n",
      "    update_time_ms: 6.413\n",
      "  timestamp: 1637515546\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4468122\n",
      "  training_iteration: 507\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   507</td><td style=\"text-align: right;\">          254226</td><td style=\"text-align: right;\">4468122</td><td style=\"text-align: right;\"> 5.55438</td><td style=\"text-align: right;\">               21.67</td><td style=\"text-align: right;\">               -0.41</td><td style=\"text-align: right;\">           51.8854</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4478118\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_17-34-38\n",
      "  done: false\n",
      "  episode_len_mean: 52.142105263157895\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.690000000000005\n",
      "  episode_reward_mean: 5.236000000000003\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 88805\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.067214713254607\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015711770980552493\n",
      "          policy_loss: -0.07185263042428996\n",
      "          total_loss: 0.08188072477778807\n",
      "          vf_explained_var: 0.9454730749130249\n",
      "          vf_loss: 0.13861212244642576\n",
      "    num_agent_steps_sampled: 4478118\n",
      "    num_agent_steps_trained: 4478118\n",
      "    num_steps_sampled: 4478118\n",
      "    num_steps_trained: 4478118\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.94368421052633\n",
      "    ram_util_percent: 51.15105263157894\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05285685528105358\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.18921497896603\n",
      "    mean_inference_ms: 19.30466536844566\n",
      "    mean_raw_obs_processing_ms: 3.4928282573750966\n",
      "  time_since_restore: 59941.914684057236\n",
      "  time_this_iter_s: 532.8311722278595\n",
      "  time_total_s: 254759.27826952934\n",
      "  timers:\n",
      "    learn_throughput: 28.001\n",
      "    learn_time_ms: 356989.659\n",
      "    load_throughput: 87050.681\n",
      "    load_time_ms: 114.83\n",
      "    sample_throughput: 51.873\n",
      "    sample_time_ms: 192702.117\n",
      "    update_time_ms: 6.558\n",
      "  timestamp: 1637516078\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4478118\n",
      "  training_iteration: 508\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   508</td><td style=\"text-align: right;\">          254759</td><td style=\"text-align: right;\">4478118</td><td style=\"text-align: right;\">   5.236</td><td style=\"text-align: right;\">               15.69</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           52.1421</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4488114\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_17-43-31\n",
      "  done: false\n",
      "  episode_len_mean: 52.05181347150259\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.167202072538864\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 88998\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0800717665967214\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015255520221640373\n",
      "          policy_loss: -0.0689258933031088\n",
      "          total_loss: 0.07938454180775185\n",
      "          vf_explained_var: 0.9501486420631409\n",
      "          vf_loss: 0.13435716988429067\n",
      "    num_agent_steps_sampled: 4488114\n",
      "    num_agent_steps_trained: 4488114\n",
      "    num_steps_sampled: 4488114\n",
      "    num_steps_trained: 4488114\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9880420499343\n",
      "    ram_util_percent: 49.99408672798949\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287646448999448\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.177452834093025\n",
      "    mean_inference_ms: 19.308830106787134\n",
      "    mean_raw_obs_processing_ms: 3.4708545258226553\n",
      "  time_since_restore: 60474.94611668587\n",
      "  time_this_iter_s: 533.0314326286316\n",
      "  time_total_s: 255292.30970215797\n",
      "  timers:\n",
      "    learn_throughput: 28.036\n",
      "    learn_time_ms: 356542.362\n",
      "    load_throughput: 87590.411\n",
      "    load_time_ms: 114.122\n",
      "    sample_throughput: 52.648\n",
      "    sample_time_ms: 189865.253\n",
      "    update_time_ms: 6.855\n",
      "  timestamp: 1637516611\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4488114\n",
      "  training_iteration: 509\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   509</td><td style=\"text-align: right;\">          255292</td><td style=\"text-align: right;\">4488114</td><td style=\"text-align: right;\">  5.1672</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           52.0518</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4498110\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_17-52-50\n",
      "  done: false\n",
      "  episode_len_mean: 52.083333333333336\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.690000000000005\n",
      "  episode_reward_mean: 4.894739583333338\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 89190\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.070629341128361\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014628445897997359\n",
      "          policy_loss: -0.07471450375634674\n",
      "          total_loss: 0.07499932911823307\n",
      "          vf_explained_var: 0.9525302648544312\n",
      "          vf_loss: 0.13709469735987082\n",
      "    num_agent_steps_sampled: 4498110\n",
      "    num_agent_steps_trained: 4498110\n",
      "    num_steps_sampled: 4498110\n",
      "    num_steps_trained: 4498110\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.50778894472361\n",
      "    ram_util_percent: 51.45389447236181\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052859973709797364\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.15291220090813\n",
      "    mean_inference_ms: 19.306215416843127\n",
      "    mean_raw_obs_processing_ms: 3.4798449490036774\n",
      "  time_since_restore: 61033.15619921684\n",
      "  time_this_iter_s: 558.2100825309753\n",
      "  time_total_s: 255850.51978468895\n",
      "  timers:\n",
      "    learn_throughput: 28.07\n",
      "    learn_time_ms: 356111.344\n",
      "    load_throughput: 88281.949\n",
      "    load_time_ms: 113.228\n",
      "    sample_throughput: 52.524\n",
      "    sample_time_ms: 190313.213\n",
      "    update_time_ms: 7.093\n",
      "  timestamp: 1637517170\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4498110\n",
      "  training_iteration: 510\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   510</td><td style=\"text-align: right;\">          255851</td><td style=\"text-align: right;\">4498110</td><td style=\"text-align: right;\"> 4.89474</td><td style=\"text-align: right;\">               15.69</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           52.0833</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4508106\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_18-01-53\n",
      "  done: false\n",
      "  episode_len_mean: 52.166666666666664\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.540000000000006\n",
      "  episode_reward_mean: 5.646458333333338\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 89382\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.05083752056681\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015468998038500046\n",
      "          policy_loss: -0.07017125693269137\n",
      "          total_loss: 0.08779499149384785\n",
      "          vf_explained_var: 0.9496524930000305\n",
      "          vf_loss: 0.1432343109822215\n",
      "    num_agent_steps_sampled: 4508106\n",
      "    num_agent_steps_trained: 4508106\n",
      "    num_steps_sampled: 4508106\n",
      "    num_steps_trained: 4508106\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81238709677419\n",
      "    ram_util_percent: 51.599870967741936\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052846038035747035\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.133611551643604\n",
      "    mean_inference_ms: 19.305881030351586\n",
      "    mean_raw_obs_processing_ms: 3.477099515370618\n",
      "  time_since_restore: 61576.18860888481\n",
      "  time_this_iter_s: 543.0324096679688\n",
      "  time_total_s: 256393.55219435692\n",
      "  timers:\n",
      "    learn_throughput: 28.101\n",
      "    learn_time_ms: 355714.716\n",
      "    load_throughput: 89229.21\n",
      "    load_time_ms: 112.026\n",
      "    sample_throughput: 52.482\n",
      "    sample_time_ms: 190464.852\n",
      "    update_time_ms: 7.359\n",
      "  timestamp: 1637517713\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4508106\n",
      "  training_iteration: 511\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   511</td><td style=\"text-align: right;\">          256394</td><td style=\"text-align: right;\">4508106</td><td style=\"text-align: right;\"> 5.64646</td><td style=\"text-align: right;\">               15.54</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           52.1667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4518102\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_18-10-59\n",
      "  done: false\n",
      "  episode_len_mean: 52.225130890052355\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 5.0922513089005275\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 89573\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.063202642867843\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015040587263254445\n",
      "          policy_loss: -0.07114556427593918\n",
      "          total_loss: 0.07667346331938432\n",
      "          vf_explained_var: 0.9440317153930664\n",
      "          vf_loss: 0.13418671507743676\n",
      "    num_agent_steps_sampled: 4518102\n",
      "    num_agent_steps_trained: 4518102\n",
      "    num_steps_sampled: 4518102\n",
      "    num_steps_trained: 4518102\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.11386392811296\n",
      "    ram_util_percent: 50.43825417201541\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05285255260290657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.126250701313516\n",
      "    mean_inference_ms: 19.31033878142764\n",
      "    mean_raw_obs_processing_ms: 3.4567799813748112\n",
      "  time_since_restore: 62122.1143655777\n",
      "  time_this_iter_s: 545.9257566928864\n",
      "  time_total_s: 256939.4779510498\n",
      "  timers:\n",
      "    learn_throughput: 28.039\n",
      "    learn_time_ms: 356498.392\n",
      "    load_throughput: 89574.701\n",
      "    load_time_ms: 111.594\n",
      "    sample_throughput: 52.91\n",
      "    sample_time_ms: 188923.659\n",
      "    update_time_ms: 7.305\n",
      "  timestamp: 1637518259\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4518102\n",
      "  training_iteration: 512\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   512</td><td style=\"text-align: right;\">          256939</td><td style=\"text-align: right;\">4518102</td><td style=\"text-align: right;\"> 5.09225</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           52.2251</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4528098\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_18-20-38\n",
      "  done: false\n",
      "  episode_len_mean: 51.43298969072165\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.550000000000008\n",
      "  episode_reward_mean: 5.327164948453612\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 89767\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.064634620377338\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01565944539918317\n",
      "          policy_loss: -0.06932042748180701\n",
      "          total_loss: 0.08477932982192511\n",
      "          vf_explained_var: 0.9329443573951721\n",
      "          vf_loss: 0.13907192859604176\n",
      "    num_agent_steps_sampled: 4528098\n",
      "    num_agent_steps_trained: 4528098\n",
      "    num_steps_sampled: 4528098\n",
      "    num_steps_trained: 4528098\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.10955259975817\n",
      "    ram_util_percent: 51.34014510278112\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05286160815689413\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.16625205923693\n",
      "    mean_inference_ms: 19.313035648323478\n",
      "    mean_raw_obs_processing_ms: 3.4546033261807794\n",
      "  time_since_restore: 62701.66284441948\n",
      "  time_this_iter_s: 579.5484788417816\n",
      "  time_total_s: 257519.0264298916\n",
      "  timers:\n",
      "    learn_throughput: 27.984\n",
      "    learn_time_ms: 357198.03\n",
      "    load_throughput: 89481.617\n",
      "    load_time_ms: 111.71\n",
      "    sample_throughput: 52.784\n",
      "    sample_time_ms: 189376.026\n",
      "    update_time_ms: 6.608\n",
      "  timestamp: 1637518838\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4528098\n",
      "  training_iteration: 513\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   513</td><td style=\"text-align: right;\">          257519</td><td style=\"text-align: right;\">4528098</td><td style=\"text-align: right;\"> 5.32716</td><td style=\"text-align: right;\">               15.55</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">            51.433</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4538094\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_18-30-14\n",
      "  done: false\n",
      "  episode_len_mean: 50.676767676767675\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 4.856818181818186\n",
      "  episode_reward_min: -0.4300000000000002\n",
      "  episodes_this_iter: 198\n",
      "  episodes_total: 89965\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.093088465833281\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014691287988430734\n",
      "          policy_loss: -0.0728336851272864\n",
      "          total_loss: 0.061084307222077465\n",
      "          vf_explained_var: 0.9478856921195984\n",
      "          vf_loss: 0.12138028449190025\n",
      "    num_agent_steps_sampled: 4538094\n",
      "    num_agent_steps_trained: 4538094\n",
      "    num_steps_sampled: 4538094\n",
      "    num_steps_trained: 4538094\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.18136419001219\n",
      "    ram_util_percent: 52.67904993909866\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052862179957888694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.158966750214\n",
      "    mean_inference_ms: 19.314800244180088\n",
      "    mean_raw_obs_processing_ms: 3.4825256739958665\n",
      "  time_since_restore: 63277.1521897316\n",
      "  time_this_iter_s: 575.4893453121185\n",
      "  time_total_s: 258094.5157752037\n",
      "  timers:\n",
      "    learn_throughput: 27.937\n",
      "    learn_time_ms: 357808.979\n",
      "    load_throughput: 89525.047\n",
      "    load_time_ms: 111.656\n",
      "    sample_throughput: 52.279\n",
      "    sample_time_ms: 191206.021\n",
      "    update_time_ms: 6.197\n",
      "  timestamp: 1637519414\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4538094\n",
      "  training_iteration: 514\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   514</td><td style=\"text-align: right;\">          258095</td><td style=\"text-align: right;\">4538094</td><td style=\"text-align: right;\"> 4.85682</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.43</td><td style=\"text-align: right;\">           50.6768</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4548090\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_18-39-38\n",
      "  done: false\n",
      "  episode_len_mean: 52.37696335078534\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 4.94361256544503\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 90156\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.094090547619096\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014930951410258322\n",
      "          policy_loss: -0.07731967262333087\n",
      "          total_loss: 0.06012911529071726\n",
      "          vf_explained_var: 0.9185881018638611\n",
      "          vf_loss: 0.12437511852453369\n",
      "    num_agent_steps_sampled: 4548090\n",
      "    num_agent_steps_trained: 4548090\n",
      "    num_steps_sampled: 4548090\n",
      "    num_steps_trained: 4548090\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.28981366459628\n",
      "    ram_util_percent: 52.34844720496894\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052914520945461306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.147616453410855\n",
      "    mean_inference_ms: 19.319057737342053\n",
      "    mean_raw_obs_processing_ms: 3.477032972474054\n",
      "  time_since_restore: 63841.54989552498\n",
      "  time_this_iter_s: 564.3977057933807\n",
      "  time_total_s: 258658.9134809971\n",
      "  timers:\n",
      "    learn_throughput: 27.828\n",
      "    learn_time_ms: 359202.703\n",
      "    load_throughput: 88936.774\n",
      "    load_time_ms: 112.394\n",
      "    sample_throughput: 51.756\n",
      "    sample_time_ms: 193137.96\n",
      "    update_time_ms: 6.195\n",
      "  timestamp: 1637519978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4548090\n",
      "  training_iteration: 515\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   515</td><td style=\"text-align: right;\">          258659</td><td style=\"text-align: right;\">4548090</td><td style=\"text-align: right;\"> 4.94361</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">            52.377</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4558086\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_18-48-39\n",
      "  done: false\n",
      "  episode_len_mean: 52.17277486910995\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.730000000000006\n",
      "  episode_reward_mean: 5.4538219895288\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 90347\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0521024191475297\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01480108785230703\n",
      "          policy_loss: -0.07271241767150194\n",
      "          total_loss: 0.07780562274092372\n",
      "          vf_explained_var: 0.9515458345413208\n",
      "          vf_loss: 0.13732033453359976\n",
      "    num_agent_steps_sampled: 4558086\n",
      "    num_agent_steps_trained: 4558086\n",
      "    num_steps_sampled: 4558086\n",
      "    num_steps_trained: 4558086\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1383916990921\n",
      "    ram_util_percent: 52.74811932555124\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529504080546662\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.14009354526319\n",
      "    mean_inference_ms: 19.324096338440864\n",
      "    mean_raw_obs_processing_ms: 3.4582685531429194\n",
      "  time_since_restore: 64382.03091740608\n",
      "  time_this_iter_s: 540.4810218811035\n",
      "  time_total_s: 259199.3945028782\n",
      "  timers:\n",
      "    learn_throughput: 27.794\n",
      "    learn_time_ms: 359650.978\n",
      "    load_throughput: 88742.485\n",
      "    load_time_ms: 112.641\n",
      "    sample_throughput: 51.997\n",
      "    sample_time_ms: 192242.827\n",
      "    update_time_ms: 6.24\n",
      "  timestamp: 1637520519\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4558086\n",
      "  training_iteration: 516\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   516</td><td style=\"text-align: right;\">          259199</td><td style=\"text-align: right;\">4558086</td><td style=\"text-align: right;\"> 5.45382</td><td style=\"text-align: right;\">               15.73</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           52.1728</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4568082\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_18-57-55\n",
      "  done: false\n",
      "  episode_len_mean: 52.15625\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 4.589687500000004\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 90539\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0897003079513947\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014431862372386752\n",
      "          policy_loss: -0.07600744958027612\n",
      "          total_loss: 0.052176402409704274\n",
      "          vf_explained_var: 0.9455350637435913\n",
      "          vf_loss: 0.11620326781052587\n",
      "    num_agent_steps_sampled: 4568082\n",
      "    num_agent_steps_trained: 4568082\n",
      "    num_steps_sampled: 4568082\n",
      "    num_steps_trained: 4568082\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.18398486759142\n",
      "    ram_util_percent: 53.067843631778054\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05295706407395965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.13479435788806\n",
      "    mean_inference_ms: 19.32770073325744\n",
      "    mean_raw_obs_processing_ms: 3.455801737259346\n",
      "  time_since_restore: 64937.99376106262\n",
      "  time_this_iter_s: 555.9628436565399\n",
      "  time_total_s: 259755.35734653473\n",
      "  timers:\n",
      "    learn_throughput: 27.752\n",
      "    learn_time_ms: 360186.778\n",
      "    load_throughput: 88452.255\n",
      "    load_time_ms: 113.01\n",
      "    sample_throughput: 51.909\n",
      "    sample_time_ms: 192567.472\n",
      "    update_time_ms: 6.064\n",
      "  timestamp: 1637521075\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4568082\n",
      "  training_iteration: 517\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   517</td><td style=\"text-align: right;\">          259755</td><td style=\"text-align: right;\">4568082</td><td style=\"text-align: right;\"> 4.58969</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           52.1562</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4578078\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_19-07-17\n",
      "  done: false\n",
      "  episode_len_mean: 52.44502617801047\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.61\n",
      "  episode_reward_mean: 5.758062827225134\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 90730\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0332104680528604\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015693820034390692\n",
      "          policy_loss: -0.07291060110798414\n",
      "          total_loss: 0.08240090547854828\n",
      "          vf_explained_var: 0.9541924595832825\n",
      "          vf_loss: 0.13989112638320444\n",
      "    num_agent_steps_sampled: 4578078\n",
      "    num_agent_steps_trained: 4578078\n",
      "    num_steps_sampled: 4578078\n",
      "    num_steps_trained: 4578078\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.4708229426434\n",
      "    ram_util_percent: 53.39389027431421\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052945036376287974\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.118962825800004\n",
      "    mean_inference_ms: 19.32844814167779\n",
      "    mean_raw_obs_processing_ms: 3.4653571770523603\n",
      "  time_since_restore: 65499.895228624344\n",
      "  time_this_iter_s: 561.9014675617218\n",
      "  time_total_s: 260317.25881409645\n",
      "  timers:\n",
      "    learn_throughput: 27.741\n",
      "    learn_time_ms: 360332.661\n",
      "    load_throughput: 88182.461\n",
      "    load_time_ms: 113.356\n",
      "    sample_throughput: 51.175\n",
      "    sample_time_ms: 195328.841\n",
      "    update_time_ms: 5.676\n",
      "  timestamp: 1637521637\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4578078\n",
      "  training_iteration: 518\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   518</td><td style=\"text-align: right;\">          260317</td><td style=\"text-align: right;\">4578078</td><td style=\"text-align: right;\"> 5.75806</td><td style=\"text-align: right;\">               17.61</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">            52.445</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4588074\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_19-16-26\n",
      "  done: false\n",
      "  episode_len_mean: 52.57068062827225\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000007\n",
      "  episode_reward_mean: 5.025445026178015\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 90921\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0671349882600776\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015544903496238247\n",
      "          policy_loss: -0.07171429885381503\n",
      "          total_loss: 0.08487473695198107\n",
      "          vf_explained_var: 0.9456016421318054\n",
      "          vf_loss: 0.1418471517569636\n",
      "    num_agent_steps_sampled: 4588074\n",
      "    num_agent_steps_trained: 4588074\n",
      "    num_steps_sampled: 4588074\n",
      "    num_steps_trained: 4588074\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.71938775510205\n",
      "    ram_util_percent: 53.865306122448985\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052949945177663854\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.106252959451844\n",
      "    mean_inference_ms: 19.330957516637454\n",
      "    mean_raw_obs_processing_ms: 3.4601088403728695\n",
      "  time_since_restore: 66049.32695102692\n",
      "  time_this_iter_s: 549.4317224025726\n",
      "  time_total_s: 260866.69053649902\n",
      "  timers:\n",
      "    learn_throughput: 27.735\n",
      "    learn_time_ms: 360409.586\n",
      "    load_throughput: 87998.338\n",
      "    load_time_ms: 113.593\n",
      "    sample_throughput: 50.769\n",
      "    sample_time_ms: 196891.736\n",
      "    update_time_ms: 5.365\n",
      "  timestamp: 1637522186\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4588074\n",
      "  training_iteration: 519\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   519</td><td style=\"text-align: right;\">          260867</td><td style=\"text-align: right;\">4588074</td><td style=\"text-align: right;\"> 5.02545</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           52.5707</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4598070\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_19-25-45\n",
      "  done: false\n",
      "  episode_len_mean: 52.98930481283423\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.580000000000005\n",
      "  episode_reward_mean: 5.178823529411769\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 91108\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.065710394521315\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015503798500245122\n",
      "          policy_loss: -0.07433665858505806\n",
      "          total_loss: 0.06864787584150894\n",
      "          vf_explained_var: 0.9503821730613708\n",
      "          vf_loss: 0.1283220462991957\n",
      "    num_agent_steps_sampled: 4598070\n",
      "    num_agent_steps_trained: 4598070\n",
      "    num_steps_sampled: 4598070\n",
      "    num_steps_trained: 4598070\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.43074027603512\n",
      "    ram_util_percent: 53.73864491844416\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052914847395150386\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.074145435223585\n",
      "    mean_inference_ms: 19.32745078332413\n",
      "    mean_raw_obs_processing_ms: 3.486465273217116\n",
      "  time_since_restore: 66607.99252963066\n",
      "  time_this_iter_s: 558.6655786037445\n",
      "  time_total_s: 261425.35611510277\n",
      "  timers:\n",
      "    learn_throughput: 27.73\n",
      "    learn_time_ms: 360474.788\n",
      "    load_throughput: 87904.317\n",
      "    load_time_ms: 113.715\n",
      "    sample_throughput: 50.774\n",
      "    sample_time_ms: 196872.697\n",
      "    update_time_ms: 5.026\n",
      "  timestamp: 1637522745\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4598070\n",
      "  training_iteration: 520\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   520</td><td style=\"text-align: right;\">          261425</td><td style=\"text-align: right;\">4598070</td><td style=\"text-align: right;\"> 5.17882</td><td style=\"text-align: right;\">               17.58</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           52.9893</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4608066\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_19-35-05\n",
      "  done: false\n",
      "  episode_len_mean: 52.57068062827225\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.58999999999997\n",
      "  episode_reward_mean: 5.137801047120424\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 91299\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0535942094153667\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015195802619638906\n",
      "          policy_loss: -0.07314230538421064\n",
      "          total_loss: 0.07443387151327248\n",
      "          vf_explained_var: 0.9275346398353577\n",
      "          vf_loss: 0.13349418033598867\n",
      "    num_agent_steps_sampled: 4608066\n",
      "    num_agent_steps_trained: 4608066\n",
      "    num_steps_sampled: 4608066\n",
      "    num_steps_trained: 4608066\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.04387500000001\n",
      "    ram_util_percent: 53.6815\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05290324362195518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.049088012419965\n",
      "    mean_inference_ms: 19.323798767910617\n",
      "    mean_raw_obs_processing_ms: 3.5144144377223183\n",
      "  time_since_restore: 67168.3639614582\n",
      "  time_this_iter_s: 560.3714318275452\n",
      "  time_total_s: 261985.7275469303\n",
      "  timers:\n",
      "    learn_throughput: 27.726\n",
      "    learn_time_ms: 360521.54\n",
      "    load_throughput: 87890.68\n",
      "    load_time_ms: 113.732\n",
      "    sample_throughput: 50.343\n",
      "    sample_time_ms: 198559.478\n",
      "    update_time_ms: 5.064\n",
      "  timestamp: 1637523305\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4608066\n",
      "  training_iteration: 521\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   521</td><td style=\"text-align: right;\">          261986</td><td style=\"text-align: right;\">4608066</td><td style=\"text-align: right;\">  5.1378</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           52.5707</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4618062\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_19-43-56\n",
      "  done: false\n",
      "  episode_len_mean: 54.15217391304348\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000005\n",
      "  episode_reward_mean: 5.073043478260875\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 91483\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0557689106368637\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014816684652896546\n",
      "          policy_loss: -0.07582888865485052\n",
      "          total_loss: 0.06371149479792113\n",
      "          vf_explained_var: 0.9408073425292969\n",
      "          vf_loss: 0.12634381194024843\n",
      "    num_agent_steps_sampled: 4618062\n",
      "    num_agent_steps_trained: 4618062\n",
      "    num_steps_sampled: 4618062\n",
      "    num_steps_trained: 4618062\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.05297225891678\n",
      "    ram_util_percent: 53.46063408190224\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05291450337834725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.03010302719969\n",
      "    mean_inference_ms: 19.324799805644307\n",
      "    mean_raw_obs_processing_ms: 3.4970847643848924\n",
      "  time_since_restore: 67699.20469117165\n",
      "  time_this_iter_s: 530.8407297134399\n",
      "  time_total_s: 262516.56827664375\n",
      "  timers:\n",
      "    learn_throughput: 27.799\n",
      "    learn_time_ms: 359577.394\n",
      "    load_throughput: 87745.072\n",
      "    load_time_ms: 113.921\n",
      "    sample_throughput: 50.486\n",
      "    sample_time_ms: 197994.977\n",
      "    update_time_ms: 5.081\n",
      "  timestamp: 1637523836\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4618062\n",
      "  training_iteration: 522\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   522</td><td style=\"text-align: right;\">          262517</td><td style=\"text-align: right;\">4618062</td><td style=\"text-align: right;\"> 5.07304</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           54.1522</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4628058\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_19-53-05\n",
      "  done: false\n",
      "  episode_len_mean: 53.33510638297872\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.63999999999999\n",
      "  episode_reward_mean: 4.880212765957451\n",
      "  episode_reward_min: -0.6200000000000003\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 91671\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0459156219739034\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015396405244616069\n",
      "          policy_loss: -0.07137805025193952\n",
      "          total_loss: 0.06557153086431056\n",
      "          vf_explained_var: 0.9457404017448425\n",
      "          vf_loss: 0.1223337996377045\n",
      "    num_agent_steps_sampled: 4628058\n",
      "    num_agent_steps_trained: 4628058\n",
      "    num_steps_sampled: 4628058\n",
      "    num_steps_trained: 4628058\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.85798212005109\n",
      "    ram_util_percent: 52.25095785440613\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05290524771133299\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.01704012119552\n",
      "    mean_inference_ms: 19.327193185274837\n",
      "    mean_raw_obs_processing_ms: 3.4925644875684143\n",
      "  time_since_restore: 68247.88202738762\n",
      "  time_this_iter_s: 548.6773362159729\n",
      "  time_total_s: 263065.2456128597\n",
      "  timers:\n",
      "    learn_throughput: 27.865\n",
      "    learn_time_ms: 358723.586\n",
      "    load_throughput: 87915.671\n",
      "    load_time_ms: 113.7\n",
      "    sample_throughput: 51.062\n",
      "    sample_time_ms: 195761.817\n",
      "    update_time_ms: 5.316\n",
      "  timestamp: 1637524385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4628058\n",
      "  training_iteration: 523\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   523</td><td style=\"text-align: right;\">          263065</td><td style=\"text-align: right;\">4628058</td><td style=\"text-align: right;\"> 4.88021</td><td style=\"text-align: right;\">               19.64</td><td style=\"text-align: right;\">               -0.62</td><td style=\"text-align: right;\">           53.3351</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4638054\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_20-02-56\n",
      "  done: false\n",
      "  episode_len_mean: 53.50802139037433\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 5.385133689839577\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 91858\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0373066291033504\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016080904105271146\n",
      "          policy_loss: -0.07050866002015488\n",
      "          total_loss: 0.08609627782840165\n",
      "          vf_explained_var: 0.9430322051048279\n",
      "          vf_loss: 0.14034369367298233\n",
      "    num_agent_steps_sampled: 4638054\n",
      "    num_agent_steps_trained: 4638054\n",
      "    num_steps_sampled: 4638054\n",
      "    num_steps_trained: 4638054\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.52360616844602\n",
      "    ram_util_percent: 52.760023724792404\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288919119028835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.987592982911664\n",
      "    mean_inference_ms: 19.325322943242096\n",
      "    mean_raw_obs_processing_ms: 3.5302260010494284\n",
      "  time_since_restore: 68838.79778337479\n",
      "  time_this_iter_s: 590.9157559871674\n",
      "  time_total_s: 263656.1613688469\n",
      "  timers:\n",
      "    learn_throughput: 27.912\n",
      "    learn_time_ms: 358129.282\n",
      "    load_throughput: 88069.819\n",
      "    load_time_ms: 113.501\n",
      "    sample_throughput: 50.511\n",
      "    sample_time_ms: 197899.348\n",
      "    update_time_ms: 5.626\n",
      "  timestamp: 1637524976\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4638054\n",
      "  training_iteration: 524\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   524</td><td style=\"text-align: right;\">          263656</td><td style=\"text-align: right;\">4638054</td><td style=\"text-align: right;\"> 5.38513</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">            53.508</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4648050\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_20-12-05\n",
      "  done: false\n",
      "  episode_len_mean: 54.17391304347826\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.650000000000006\n",
      "  episode_reward_mean: 5.422826086956526\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 92042\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0320108492929774\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015835482715298454\n",
      "          policy_loss: -0.07320550284924442\n",
      "          total_loss: 0.075625084510455\n",
      "          vf_explained_var: 0.9469926357269287\n",
      "          vf_loss: 0.13307548524815604\n",
      "    num_agent_steps_sampled: 4648050\n",
      "    num_agent_steps_trained: 4648050\n",
      "    num_steps_sampled: 4648050\n",
      "    num_steps_trained: 4648050\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.78341836734694\n",
      "    ram_util_percent: 53.17614795918368\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05289406614685268\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.97170730756892\n",
      "    mean_inference_ms: 19.328787574093994\n",
      "    mean_raw_obs_processing_ms: 3.5384803537727136\n",
      "  time_since_restore: 69388.2468495369\n",
      "  time_this_iter_s: 549.4490661621094\n",
      "  time_total_s: 264205.610435009\n",
      "  timers:\n",
      "    learn_throughput: 28.01\n",
      "    learn_time_ms: 356871.497\n",
      "    load_throughput: 88772.756\n",
      "    load_time_ms: 112.602\n",
      "    sample_throughput: 50.57\n",
      "    sample_time_ms: 197665.682\n",
      "    update_time_ms: 5.603\n",
      "  timestamp: 1637525525\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4648050\n",
      "  training_iteration: 525\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   525</td><td style=\"text-align: right;\">          264206</td><td style=\"text-align: right;\">4648050</td><td style=\"text-align: right;\"> 5.42283</td><td style=\"text-align: right;\">               15.65</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           54.1739</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4658046\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_20-21-21\n",
      "  done: false\n",
      "  episode_len_mean: 53.62903225806452\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.589999999999996\n",
      "  episode_reward_mean: 5.509731182795703\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 92228\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.007595822777614\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01645021363233512\n",
      "          policy_loss: -0.06598751909828827\n",
      "          total_loss: 0.09629917828445991\n",
      "          vf_explained_var: 0.9436135292053223\n",
      "          vf_loss: 0.14488701152813482\n",
      "    num_agent_steps_sampled: 4658046\n",
      "    num_agent_steps_trained: 4658046\n",
      "    num_steps_sampled: 4658046\n",
      "    num_steps_trained: 4658046\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.53505674653216\n",
      "    ram_util_percent: 52.837074401008834\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052881436298105766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.949097047810106\n",
      "    mean_inference_ms: 19.32864711747393\n",
      "    mean_raw_obs_processing_ms: 3.5445212365637113\n",
      "  time_since_restore: 69943.88586258888\n",
      "  time_this_iter_s: 555.6390130519867\n",
      "  time_total_s: 264761.249448061\n",
      "  timers:\n",
      "    learn_throughput: 28.039\n",
      "    learn_time_ms: 356508.147\n",
      "    load_throughput: 88700.336\n",
      "    load_time_ms: 112.694\n",
      "    sample_throughput: 50.094\n",
      "    sample_time_ms: 199544.521\n",
      "    update_time_ms: 5.868\n",
      "  timestamp: 1637526081\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4658046\n",
      "  training_iteration: 526\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   526</td><td style=\"text-align: right;\">          264761</td><td style=\"text-align: right;\">4658046</td><td style=\"text-align: right;\"> 5.50973</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">            53.629</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4668042\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_20-30-15\n",
      "  done: false\n",
      "  episode_len_mean: 53.854838709677416\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.700000000000005\n",
      "  episode_reward_mean: 5.365913978494628\n",
      "  episode_reward_min: -0.4600000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 92414\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0010005437466036\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0149260726665556\n",
      "          policy_loss: -0.0720185830625656\n",
      "          total_loss: 0.07337007096506583\n",
      "          vf_explained_var: 0.9539527297019958\n",
      "          vf_loss: 0.13139519884108927\n",
      "    num_agent_steps_sampled: 4668042\n",
      "    num_agent_steps_trained: 4668042\n",
      "    num_steps_sampled: 4668042\n",
      "    num_steps_trained: 4668042\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.03797634691195\n",
      "    ram_util_percent: 53.10486202365309\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05289134382371997\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.93886582564514\n",
      "    mean_inference_ms: 19.33305103441765\n",
      "    mean_raw_obs_processing_ms: 3.5253607622339684\n",
      "  time_since_restore: 70477.46601748466\n",
      "  time_this_iter_s: 533.5801548957825\n",
      "  time_total_s: 265294.8296029568\n",
      "  timers:\n",
      "    learn_throughput: 28.077\n",
      "    learn_time_ms: 356021.815\n",
      "    load_throughput: 88684.069\n",
      "    load_time_ms: 112.715\n",
      "    sample_throughput: 50.537\n",
      "    sample_time_ms: 197794.256\n",
      "    update_time_ms: 5.482\n",
      "  timestamp: 1637526615\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4668042\n",
      "  training_iteration: 527\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   527</td><td style=\"text-align: right;\">          265295</td><td style=\"text-align: right;\">4668042</td><td style=\"text-align: right;\"> 5.36591</td><td style=\"text-align: right;\">                15.7</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           53.8548</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4678038\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_20-39-05\n",
      "  done: false\n",
      "  episode_len_mean: 55.62222222222222\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.650000000000006\n",
      "  episode_reward_mean: 5.251111111111117\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 92594\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.010565014177537\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01431201872840609\n",
      "          policy_loss: -0.07308578608937576\n",
      "          total_loss: 0.06477756548332048\n",
      "          vf_explained_var: 0.9520248174667358\n",
      "          vf_loss: 0.12536443267073707\n",
      "    num_agent_steps_sampled: 4678038\n",
      "    num_agent_steps_trained: 4678038\n",
      "    num_steps_sampled: 4678038\n",
      "    num_steps_trained: 4678038\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.24729194187584\n",
      "    ram_util_percent: 52.39735799207398\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293631313502908\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.922608056475866\n",
      "    mean_inference_ms: 19.336946674999187\n",
      "    mean_raw_obs_processing_ms: 3.511267278877019\n",
      "  time_since_restore: 71007.89354300499\n",
      "  time_this_iter_s: 530.4275255203247\n",
      "  time_total_s: 265825.2571284771\n",
      "  timers:\n",
      "    learn_throughput: 28.085\n",
      "    learn_time_ms: 355920.441\n",
      "    load_throughput: 88383.152\n",
      "    load_time_ms: 113.098\n",
      "    sample_throughput: 51.328\n",
      "    sample_time_ms: 194748.185\n",
      "    update_time_ms: 5.466\n",
      "  timestamp: 1637527145\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4678038\n",
      "  training_iteration: 528\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   528</td><td style=\"text-align: right;\">          265825</td><td style=\"text-align: right;\">4678038</td><td style=\"text-align: right;\"> 5.25111</td><td style=\"text-align: right;\">               11.65</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           55.6222</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4688034\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_20-48-09\n",
      "  done: false\n",
      "  episode_len_mean: 54.13513513513514\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000007\n",
      "  episode_reward_mean: 5.1536216216216255\n",
      "  episode_reward_min: -0.44000000000000017\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 92779\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0111942620162506\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015150032826450336\n",
      "          policy_loss: -0.07156006118810479\n",
      "          total_loss: 0.07996056400637311\n",
      "          vf_explained_var: 0.9541788101196289\n",
      "          vf_loss: 0.13711889816792194\n",
      "    num_agent_steps_sampled: 4688034\n",
      "    num_agent_steps_trained: 4688034\n",
      "    num_steps_sampled: 4688034\n",
      "    num_steps_trained: 4688034\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.34548969072166\n",
      "    ram_util_percent: 53.8041237113402\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293915584522399\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.904601770522845\n",
      "    mean_inference_ms: 19.33797996790598\n",
      "    mean_raw_obs_processing_ms: 3.5308828640321632\n",
      "  time_since_restore: 71552.25323367119\n",
      "  time_this_iter_s: 544.3596906661987\n",
      "  time_total_s: 266369.6168191433\n",
      "  timers:\n",
      "    learn_throughput: 28.098\n",
      "    learn_time_ms: 355750.395\n",
      "    load_throughput: 88330.474\n",
      "    load_time_ms: 113.166\n",
      "    sample_throughput: 51.417\n",
      "    sample_time_ms: 194410.57\n",
      "    update_time_ms: 5.487\n",
      "  timestamp: 1637527689\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4688034\n",
      "  training_iteration: 529\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   529</td><td style=\"text-align: right;\">          266370</td><td style=\"text-align: right;\">4688034</td><td style=\"text-align: right;\"> 5.15362</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           54.1351</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4698030\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_20-57-10\n",
      "  done: false\n",
      "  episode_len_mean: 54.972375690607734\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 5.226574585635363\n",
      "  episode_reward_min: -0.7100000000000004\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 92960\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0365129737250776\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014748679155509446\n",
      "          policy_loss: -0.07521061892412949\n",
      "          total_loss: 0.05923846684645395\n",
      "          vf_explained_var: 0.9473373889923096\n",
      "          vf_loss: 0.12121487952783763\n",
      "    num_agent_steps_sampled: 4698030\n",
      "    num_agent_steps_trained: 4698030\n",
      "    num_steps_sampled: 4698030\n",
      "    num_steps_trained: 4698030\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.0158031088083\n",
      "    ram_util_percent: 54.48523316062176\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05297133778774315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.8820483874014\n",
      "    mean_inference_ms: 19.33829548310412\n",
      "    mean_raw_obs_processing_ms: 3.530241546009711\n",
      "  time_since_restore: 72093.15709161758\n",
      "  time_this_iter_s: 540.9038579463959\n",
      "  time_total_s: 266910.5206770897\n",
      "  timers:\n",
      "    learn_throughput: 28.107\n",
      "    learn_time_ms: 355635.43\n",
      "    load_throughput: 86568.044\n",
      "    load_time_ms: 115.47\n",
      "    sample_throughput: 51.861\n",
      "    sample_time_ms: 192746.639\n",
      "    update_time_ms: 5.823\n",
      "  timestamp: 1637528230\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4698030\n",
      "  training_iteration: 530\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   530</td><td style=\"text-align: right;\">          266911</td><td style=\"text-align: right;\">4698030</td><td style=\"text-align: right;\"> 5.22657</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.71</td><td style=\"text-align: right;\">           54.9724</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4708026\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_21-06-01\n",
      "  done: false\n",
      "  episode_len_mean: 54.62841530054645\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.116284153005468\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 93143\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0117522588695387\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015002496465921866\n",
      "          policy_loss: -0.06884072856412833\n",
      "          total_loss: 0.0758607337557334\n",
      "          vf_explained_var: 0.9413124918937683\n",
      "          vf_loss: 0.13064142230180015\n",
      "    num_agent_steps_sampled: 4708026\n",
      "    num_agent_steps_trained: 4708026\n",
      "    num_steps_sampled: 4708026\n",
      "    num_steps_trained: 4708026\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.0348745046235\n",
      "    ram_util_percent: 52.847952443857324\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05298207638632339\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.86849738997645\n",
      "    mean_inference_ms: 19.34236821055759\n",
      "    mean_raw_obs_processing_ms: 3.5111358448523147\n",
      "  time_since_restore: 72623.9132835865\n",
      "  time_this_iter_s: 530.7561919689178\n",
      "  time_total_s: 267441.2768690586\n",
      "  timers:\n",
      "    learn_throughput: 28.112\n",
      "    learn_time_ms: 355578.73\n",
      "    load_throughput: 86452.088\n",
      "    load_time_ms: 115.625\n",
      "    sample_throughput: 52.654\n",
      "    sample_time_ms: 189841.841\n",
      "    update_time_ms: 5.503\n",
      "  timestamp: 1637528761\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4708026\n",
      "  training_iteration: 531\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   531</td><td style=\"text-align: right;\">          267441</td><td style=\"text-align: right;\">4708026</td><td style=\"text-align: right;\"> 5.11628</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           54.6284</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4718022\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_21-15-05\n",
      "  done: false\n",
      "  episode_len_mean: 54.38918918918919\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.59\n",
      "  episode_reward_mean: 5.509243243243247\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 93328\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.031583364541272\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016024269218686493\n",
      "          policy_loss: -0.07105126618547049\n",
      "          total_loss: 0.08278214596068144\n",
      "          vf_explained_var: 0.9189639687538147\n",
      "          vf_loss: 0.13764395605301463\n",
      "    num_agent_steps_sampled: 4718022\n",
      "    num_agent_steps_trained: 4718022\n",
      "    num_steps_sampled: 4718022\n",
      "    num_steps_trained: 4718022\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.76280566280566\n",
      "    ram_util_percent: 53.28108108108108\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529766728097831\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.85355578402986\n",
      "    mean_inference_ms: 19.344149336068227\n",
      "    mean_raw_obs_processing_ms: 3.507514090001231\n",
      "  time_since_restore: 73168.064889431\n",
      "  time_this_iter_s: 544.1516058444977\n",
      "  time_total_s: 267985.4284749031\n",
      "  timers:\n",
      "    learn_throughput: 28.129\n",
      "    learn_time_ms: 355365.375\n",
      "    load_throughput: 86492.305\n",
      "    load_time_ms: 115.571\n",
      "    sample_throughput: 52.23\n",
      "    sample_time_ms: 191385.377\n",
      "    update_time_ms: 5.717\n",
      "  timestamp: 1637529305\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4718022\n",
      "  training_iteration: 532\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   532</td><td style=\"text-align: right;\">          267985</td><td style=\"text-align: right;\">4718022</td><td style=\"text-align: right;\"> 5.50924</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           54.3892</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4728018\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_21-25-01\n",
      "  done: false\n",
      "  episode_len_mean: 53.36021505376344\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.594731182795703\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 93514\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0244479758911824\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015304435728751144\n",
      "          policy_loss: -0.07106822202653691\n",
      "          total_loss: 0.07758730012097935\n",
      "          vf_explained_var: 0.9519456624984741\n",
      "          vf_loss: 0.13403458303255758\n",
      "    num_agent_steps_sampled: 4728018\n",
      "    num_agent_steps_trained: 4728018\n",
      "    num_steps_sampled: 4728018\n",
      "    num_steps_trained: 4728018\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.43235294117648\n",
      "    ram_util_percent: 54.02082352941177\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052960498901750995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.83285903444907\n",
      "    mean_inference_ms: 19.341565010583114\n",
      "    mean_raw_obs_processing_ms: 3.5537482968148066\n",
      "  time_since_restore: 73763.67093229294\n",
      "  time_this_iter_s: 595.6060428619385\n",
      "  time_total_s: 268581.03451776505\n",
      "  timers:\n",
      "    learn_throughput: 28.149\n",
      "    learn_time_ms: 355114.606\n",
      "    load_throughput: 86213.375\n",
      "    load_time_ms: 115.945\n",
      "    sample_throughput: 50.915\n",
      "    sample_time_ms: 196329.056\n",
      "    update_time_ms: 5.575\n",
      "  timestamp: 1637529901\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4728018\n",
      "  training_iteration: 533\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   533</td><td style=\"text-align: right;\">          268581</td><td style=\"text-align: right;\">4728018</td><td style=\"text-align: right;\"> 5.59473</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           53.3602</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4738014\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_21-34-02\n",
      "  done: false\n",
      "  episode_len_mean: 55.209944751381215\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.689999999999987\n",
      "  episode_reward_mean: 5.686132596685089\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 93695\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0113661764855366\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015621784861927324\n",
      "          policy_loss: -0.07241613710273186\n",
      "          total_loss: 0.08108803230130711\n",
      "          vf_explained_var: 0.9404204487800598\n",
      "          vf_loss: 0.13802945093536023\n",
      "    num_agent_steps_sampled: 4738014\n",
      "    num_agent_steps_trained: 4738014\n",
      "    num_steps_sampled: 4738014\n",
      "    num_steps_trained: 4738014\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.66761658031088\n",
      "    ram_util_percent: 53.66761658031087\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05295987269266575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.811033797112444\n",
      "    mean_inference_ms: 19.342474909828145\n",
      "    mean_raw_obs_processing_ms: 3.551553495728029\n",
      "  time_since_restore: 74304.94896578789\n",
      "  time_this_iter_s: 541.2780334949493\n",
      "  time_total_s: 269122.31255126\n",
      "  timers:\n",
      "    learn_throughput: 28.163\n",
      "    learn_time_ms: 354936.236\n",
      "    load_throughput: 86085.798\n",
      "    load_time_ms: 116.117\n",
      "    sample_throughput: 52.187\n",
      "    sample_time_ms: 191543.447\n",
      "    update_time_ms: 5.242\n",
      "  timestamp: 1637530442\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4738014\n",
      "  training_iteration: 534\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   534</td><td style=\"text-align: right;\">          269122</td><td style=\"text-align: right;\">4738014</td><td style=\"text-align: right;\"> 5.68613</td><td style=\"text-align: right;\">               19.69</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           55.2099</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4748010\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_21-42-55\n",
      "  done: false\n",
      "  episode_len_mean: 54.167567567567566\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000006\n",
      "  episode_reward_mean: 4.89567567567568\n",
      "  episode_reward_min: -0.4300000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 93880\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0519156026074206\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014531420717097891\n",
      "          policy_loss: -0.0731228079526831\n",
      "          total_loss: 0.054256683993016266\n",
      "          vf_explained_var: 0.9460033774375916\n",
      "          vf_loss: 0.11479425480389167\n",
      "    num_agent_steps_sampled: 4748010\n",
      "    num_agent_steps_trained: 4748010\n",
      "    num_steps_sampled: 4748010\n",
      "    num_steps_trained: 4748010\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.09513157894736\n",
      "    ram_util_percent: 53.463289473684206\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05295945365241109\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.80060783095714\n",
      "    mean_inference_ms: 19.345190046203424\n",
      "    mean_raw_obs_processing_ms: 3.5353980556558082\n",
      "  time_since_restore: 74837.76708340645\n",
      "  time_this_iter_s: 532.8181176185608\n",
      "  time_total_s: 269655.13066887856\n",
      "  timers:\n",
      "    learn_throughput: 28.176\n",
      "    learn_time_ms: 354774.501\n",
      "    load_throughput: 85851.615\n",
      "    load_time_ms: 116.433\n",
      "    sample_throughput: 52.599\n",
      "    sample_time_ms: 190041.779\n",
      "    update_time_ms: 4.857\n",
      "  timestamp: 1637530975\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4748010\n",
      "  training_iteration: 535\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   535</td><td style=\"text-align: right;\">          269655</td><td style=\"text-align: right;\">4748010</td><td style=\"text-align: right;\"> 4.89568</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -0.43</td><td style=\"text-align: right;\">           54.1676</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4758006\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_21-51-57\n",
      "  done: false\n",
      "  episode_len_mean: 55.361111111111114\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.690000000000003\n",
      "  episode_reward_mean: 5.375388888888893\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 94060\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.035837312874545\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01598225948388379\n",
      "          policy_loss: -0.06677236181542878\n",
      "          total_loss: 0.08743653439107227\n",
      "          vf_explained_var: 0.9487535953521729\n",
      "          vf_loss: 0.13815768318658464\n",
      "    num_agent_steps_sampled: 4758006\n",
      "    num_agent_steps_trained: 4758006\n",
      "    num_steps_sampled: 4758006\n",
      "    num_steps_trained: 4758006\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82739018087857\n",
      "    ram_util_percent: 52.544444444444444\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052947243972546215\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.783263057209695\n",
      "    mean_inference_ms: 19.34722100573624\n",
      "    mean_raw_obs_processing_ms: 3.529019178288345\n",
      "  time_since_restore: 75379.80007004738\n",
      "  time_this_iter_s: 542.0329866409302\n",
      "  time_total_s: 270197.1636555195\n",
      "  timers:\n",
      "    learn_throughput: 28.181\n",
      "    learn_time_ms: 354701.984\n",
      "    load_throughput: 85856.678\n",
      "    load_time_ms: 116.427\n",
      "    sample_throughput: 52.958\n",
      "    sample_time_ms: 188754.192\n",
      "    update_time_ms: 4.659\n",
      "  timestamp: 1637531517\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4758006\n",
      "  training_iteration: 536\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   536</td><td style=\"text-align: right;\">          270197</td><td style=\"text-align: right;\">4758006</td><td style=\"text-align: right;\"> 5.37539</td><td style=\"text-align: right;\">               15.69</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           55.3611</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4768002\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_22-01-00\n",
      "  done: false\n",
      "  episode_len_mean: 55.773480662983424\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000007\n",
      "  episode_reward_mean: 5.486464088397795\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 94241\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0383548186486027\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015177771565088797\n",
      "          policy_loss: -0.07238312415934617\n",
      "          total_loss: 0.07816716006035052\n",
      "          vf_explained_var: 0.9425229430198669\n",
      "          vf_loss: 0.1363569712579572\n",
      "    num_agent_steps_sampled: 4768002\n",
      "    num_agent_steps_trained: 4768002\n",
      "    num_steps_sampled: 4768002\n",
      "    num_steps_trained: 4768002\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77028423772609\n",
      "    ram_util_percent: 53.04883720930233\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05294322440302681\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.76416424973522\n",
      "    mean_inference_ms: 19.348428005384736\n",
      "    mean_raw_obs_processing_ms: 3.5224722552253493\n",
      "  time_since_restore: 75922.34347891808\n",
      "  time_this_iter_s: 542.543408870697\n",
      "  time_total_s: 270739.7070643902\n",
      "  timers:\n",
      "    learn_throughput: 28.186\n",
      "    learn_time_ms: 354638.663\n",
      "    load_throughput: 85922.907\n",
      "    load_time_ms: 116.337\n",
      "    sample_throughput: 52.69\n",
      "    sample_time_ms: 189712.978\n",
      "    update_time_ms: 5.46\n",
      "  timestamp: 1637532060\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4768002\n",
      "  training_iteration: 537\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   537</td><td style=\"text-align: right;\">          270740</td><td style=\"text-align: right;\">4768002</td><td style=\"text-align: right;\"> 5.48646</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           55.7735</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4777998\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_22-10-04\n",
      "  done: false\n",
      "  episode_len_mean: 54.80110497237569\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.650000000000006\n",
      "  episode_reward_mean: 5.448674033149176\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 94422\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.024294603912227\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015115498345440358\n",
      "          policy_loss: -0.06781315335871939\n",
      "          total_loss: 0.10479751709389526\n",
      "          vf_explained_var: 0.9220715165138245\n",
      "          vf_loss: 0.1584186213110652\n",
      "    num_agent_steps_sampled: 4777998\n",
      "    num_agent_steps_trained: 4777998\n",
      "    num_steps_sampled: 4777998\n",
      "    num_steps_trained: 4777998\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.80103092783506\n",
      "    ram_util_percent: 52.76894329896907\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052959012790782294\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.751389135865566\n",
      "    mean_inference_ms: 19.35025779433892\n",
      "    mean_raw_obs_processing_ms: 3.517862983048765\n",
      "  time_since_restore: 76466.47586131096\n",
      "  time_this_iter_s: 544.1323823928833\n",
      "  time_total_s: 271283.83944678307\n",
      "  timers:\n",
      "    learn_throughput: 28.189\n",
      "    learn_time_ms: 354612.12\n",
      "    load_throughput: 86248.208\n",
      "    load_time_ms: 115.898\n",
      "    sample_throughput: 52.305\n",
      "    sample_time_ms: 191110.53\n",
      "    update_time_ms: 5.486\n",
      "  timestamp: 1637532604\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4777998\n",
      "  training_iteration: 538\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   538</td><td style=\"text-align: right;\">          271284</td><td style=\"text-align: right;\">4777998</td><td style=\"text-align: right;\"> 5.44867</td><td style=\"text-align: right;\">               15.65</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           54.8011</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4787994\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_22-18-55\n",
      "  done: false\n",
      "  episode_len_mean: 55.87640449438202\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.59\n",
      "  episode_reward_mean: 5.191516853932589\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 178\n",
      "  episodes_total: 94600\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.026301320346005\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01493500022497062\n",
      "          policy_loss: -0.07313873727729019\n",
      "          total_loss: 0.07789827655375398\n",
      "          vf_explained_var: 0.9432740807533264\n",
      "          vf_loss: 0.1372762289303112\n",
      "    num_agent_steps_sampled: 4787994\n",
      "    num_agent_steps_trained: 4787994\n",
      "    num_steps_sampled: 4787994\n",
      "    num_steps_trained: 4787994\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.07216358839052\n",
      "    ram_util_percent: 52.64934036939314\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052968854763552224\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.73776244756029\n",
      "    mean_inference_ms: 19.35294496209054\n",
      "    mean_raw_obs_processing_ms: 3.5052734277446445\n",
      "  time_since_restore: 76997.64814352989\n",
      "  time_this_iter_s: 531.1722822189331\n",
      "  time_total_s: 271815.011729002\n",
      "  timers:\n",
      "    learn_throughput: 28.175\n",
      "    learn_time_ms: 354776.721\n",
      "    load_throughput: 86148.681\n",
      "    load_time_ms: 116.032\n",
      "    sample_throughput: 52.714\n",
      "    sample_time_ms: 189627.309\n",
      "    update_time_ms: 5.905\n",
      "  timestamp: 1637533135\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4787994\n",
      "  training_iteration: 539\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   539</td><td style=\"text-align: right;\">          271815</td><td style=\"text-align: right;\">4787994</td><td style=\"text-align: right;\"> 5.19152</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           55.8764</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4797990\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_22-27-59\n",
      "  done: false\n",
      "  episode_len_mean: 55.34615384615385\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.157967032967038\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 94782\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0204462428887684\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014991155655642267\n",
      "          policy_loss: -0.06861311094837447\n",
      "          total_loss: 0.08306717306316233\n",
      "          vf_explained_var: 0.9324744343757629\n",
      "          vf_loss: 0.13773301917794029\n",
      "    num_agent_steps_sampled: 4797990\n",
      "    num_agent_steps_trained: 4797990\n",
      "    num_steps_sampled: 4797990\n",
      "    num_steps_trained: 4797990\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.83801546391751\n",
      "    ram_util_percent: 53.021649484536084\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05294983411471911\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.721097058883544\n",
      "    mean_inference_ms: 19.354079589768478\n",
      "    mean_raw_obs_processing_ms: 3.4980310476485412\n",
      "  time_since_restore: 77541.59531378746\n",
      "  time_this_iter_s: 543.9471702575684\n",
      "  time_total_s: 272358.95889925957\n",
      "  timers:\n",
      "    learn_throughput: 28.167\n",
      "    learn_time_ms: 354887.236\n",
      "    load_throughput: 88124.52\n",
      "    load_time_ms: 113.43\n",
      "    sample_throughput: 52.66\n",
      "    sample_time_ms: 189822.874\n",
      "    update_time_ms: 5.801\n",
      "  timestamp: 1637533679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4797990\n",
      "  training_iteration: 540\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   540</td><td style=\"text-align: right;\">          272359</td><td style=\"text-align: right;\">4797990</td><td style=\"text-align: right;\"> 5.15797</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           55.3462</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4807986\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_22-37-03\n",
      "  done: false\n",
      "  episode_len_mean: 55.58659217877095\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.62\n",
      "  episode_reward_mean: 5.229441340782127\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 179\n",
      "  episodes_total: 94961\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.000171615237213\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01563458809804132\n",
      "          policy_loss: -0.062125926372939656\n",
      "          total_loss: 0.11528759466180921\n",
      "          vf_explained_var: 0.918452799320221\n",
      "          vf_loss: 0.1617976903569432\n",
      "    num_agent_steps_sampled: 4807986\n",
      "    num_agent_steps_trained: 4807986\n",
      "    num_steps_sampled: 4807986\n",
      "    num_steps_trained: 4807986\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.84072164948455\n",
      "    ram_util_percent: 52.686082474226794\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05295247583714493\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.70420854314436\n",
      "    mean_inference_ms: 19.35566612779946\n",
      "    mean_raw_obs_processing_ms: 3.494973013732945\n",
      "  time_since_restore: 78085.31275081635\n",
      "  time_this_iter_s: 543.7174370288849\n",
      "  time_total_s: 272902.67633628845\n",
      "  timers:\n",
      "    learn_throughput: 28.161\n",
      "    learn_time_ms: 354960.796\n",
      "    load_throughput: 87963.758\n",
      "    load_time_ms: 113.638\n",
      "    sample_throughput: 52.322\n",
      "    sample_time_ms: 191045.925\n",
      "    update_time_ms: 5.884\n",
      "  timestamp: 1637534223\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4807986\n",
      "  training_iteration: 541\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   541</td><td style=\"text-align: right;\">          272903</td><td style=\"text-align: right;\">4807986</td><td style=\"text-align: right;\"> 5.22944</td><td style=\"text-align: right;\">               17.62</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           55.5866</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4817982\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_22-46-07\n",
      "  done: false\n",
      "  episode_len_mean: 55.175824175824175\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.629999999999992\n",
      "  episode_reward_mean: 5.361153846153851\n",
      "  episode_reward_min: -0.6300000000000003\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 95143\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.038417901116681\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014480128447194072\n",
      "          policy_loss: -0.07461159019444037\n",
      "          total_loss: 0.07334218591300544\n",
      "          vf_explained_var: 0.9340832829475403\n",
      "          vf_loss: 0.1353504108320211\n",
      "    num_agent_steps_sampled: 4817982\n",
      "    num_agent_steps_trained: 4817982\n",
      "    num_steps_sampled: 4817982\n",
      "    num_steps_trained: 4817982\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.87074742268041\n",
      "    ram_util_percent: 53.48840206185567\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293650199649822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.689962042317624\n",
      "    mean_inference_ms: 19.357426859491486\n",
      "    mean_raw_obs_processing_ms: 3.4908650465461926\n",
      "  time_since_restore: 78629.49037623405\n",
      "  time_this_iter_s: 544.1776254177094\n",
      "  time_total_s: 273446.85396170616\n",
      "  timers:\n",
      "    learn_throughput: 28.156\n",
      "    learn_time_ms: 355019.463\n",
      "    load_throughput: 87769.668\n",
      "    load_time_ms: 113.889\n",
      "    sample_throughput: 52.338\n",
      "    sample_time_ms: 190989.564\n",
      "    update_time_ms: 6.272\n",
      "  timestamp: 1637534767\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4817982\n",
      "  training_iteration: 542\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   542</td><td style=\"text-align: right;\">          273447</td><td style=\"text-align: right;\">4817982</td><td style=\"text-align: right;\"> 5.36115</td><td style=\"text-align: right;\">               19.63</td><td style=\"text-align: right;\">               -0.63</td><td style=\"text-align: right;\">           55.1758</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4827978\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_22-54-58\n",
      "  done: false\n",
      "  episode_len_mean: 55.73184357541899\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.590000000000003\n",
      "  episode_reward_mean: 5.53011173184358\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 179\n",
      "  episodes_total: 95322\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0126301727620475\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014921176137167872\n",
      "          policy_loss: -0.0702027494640642\n",
      "          total_loss: 0.09038509299953075\n",
      "          vf_explained_var: 0.9423823952674866\n",
      "          vf_loss: 0.1467218378219327\n",
      "    num_agent_steps_sampled: 4827978\n",
      "    num_agent_steps_trained: 4827978\n",
      "    num_steps_sampled: 4827978\n",
      "    num_steps_trained: 4827978\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.95791556728233\n",
      "    ram_util_percent: 52.41094986807388\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529325817194708\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.67572417915022\n",
      "    mean_inference_ms: 19.360302815836075\n",
      "    mean_raw_obs_processing_ms: 3.4734284262380872\n",
      "  time_since_restore: 79160.50281357765\n",
      "  time_this_iter_s: 531.0124373435974\n",
      "  time_total_s: 273977.86639904976\n",
      "  timers:\n",
      "    learn_throughput: 28.154\n",
      "    learn_time_ms: 355050.515\n",
      "    load_throughput: 88262.75\n",
      "    load_time_ms: 113.253\n",
      "    sample_throughput: 54.179\n",
      "    sample_time_ms: 184499.765\n",
      "    update_time_ms: 6.533\n",
      "  timestamp: 1637535298\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4827978\n",
      "  training_iteration: 543\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   543</td><td style=\"text-align: right;\">          273978</td><td style=\"text-align: right;\">4827978</td><td style=\"text-align: right;\"> 5.53011</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           55.7318</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4837974\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_23-03-59\n",
      "  done: false\n",
      "  episode_len_mean: 56.40677966101695\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.589999999999996\n",
      "  episode_reward_mean: 5.43203389830509\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 177\n",
      "  episodes_total: 95499\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0237041960519\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016270225413492823\n",
      "          policy_loss: -0.06739758193400347\n",
      "          total_loss: 0.1081351223598651\n",
      "          vf_explained_var: 0.9430162310600281\n",
      "          vf_loss: 0.15870413844497971\n",
      "    num_agent_steps_sampled: 4837974\n",
      "    num_agent_steps_trained: 4837974\n",
      "    num_steps_sampled: 4837974\n",
      "    num_steps_trained: 4837974\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.65569948186528\n",
      "    ram_util_percent: 53.330829015544055\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293704886726342\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.654139863920136\n",
      "    mean_inference_ms: 19.361949086529535\n",
      "    mean_raw_obs_processing_ms: 3.4835845766952396\n",
      "  time_since_restore: 79701.63277959824\n",
      "  time_this_iter_s: 541.1299660205841\n",
      "  time_total_s: 274518.99636507034\n",
      "  timers:\n",
      "    learn_throughput: 28.148\n",
      "    learn_time_ms: 355121.934\n",
      "    load_throughput: 88257.529\n",
      "    load_time_ms: 113.259\n",
      "    sample_throughput: 54.204\n",
      "    sample_time_ms: 184413.586\n",
      "    update_time_ms: 6.931\n",
      "  timestamp: 1637535839\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4837974\n",
      "  training_iteration: 544\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   544</td><td style=\"text-align: right;\">          274519</td><td style=\"text-align: right;\">4837974</td><td style=\"text-align: right;\"> 5.43203</td><td style=\"text-align: right;\">               19.59</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           56.4068</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4847970\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_23-12-51\n",
      "  done: false\n",
      "  episode_len_mean: 55.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.435611111111116\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 95679\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.010287365975629\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01504188248546603\n",
      "          policy_loss: -0.06937123165938186\n",
      "          total_loss: 0.10776044014532397\n",
      "          vf_explained_var: 0.936235249042511\n",
      "          vf_loss: 0.16296725537745754\n",
      "    num_agent_steps_sampled: 4847970\n",
      "    num_agent_steps_trained: 4847970\n",
      "    num_steps_sampled: 4847970\n",
      "    num_steps_trained: 4847970\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.97364953886694\n",
      "    ram_util_percent: 52.43175230566535\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052922317166606406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.64293371804569\n",
      "    mean_inference_ms: 19.364998146116207\n",
      "    mean_raw_obs_processing_ms: 3.4663813227867006\n",
      "  time_since_restore: 80233.53453350067\n",
      "  time_this_iter_s: 531.9017539024353\n",
      "  time_total_s: 275050.8981189728\n",
      "  timers:\n",
      "    learn_throughput: 28.143\n",
      "    learn_time_ms: 355183.376\n",
      "    load_throughput: 88180.532\n",
      "    load_time_ms: 113.358\n",
      "    sample_throughput: 54.249\n",
      "    sample_time_ms: 184260.236\n",
      "    update_time_ms: 7.328\n",
      "  timestamp: 1637536371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4847970\n",
      "  training_iteration: 545\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   545</td><td style=\"text-align: right;\">          275051</td><td style=\"text-align: right;\">4847970</td><td style=\"text-align: right;\"> 5.43561</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">             55.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4857966\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_23-21-57\n",
      "  done: false\n",
      "  episode_len_mean: 54.52173913043478\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.610000000000007\n",
      "  episode_reward_mean: 5.517554347826092\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 95863\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0215483945057575\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014868530535251431\n",
      "          policy_loss: -0.06871909098576907\n",
      "          total_loss: 0.08570553435578528\n",
      "          vf_explained_var: 0.9493282437324524\n",
      "          vf_loss: 0.14076773626767247\n",
      "    num_agent_steps_sampled: 4857966\n",
      "    num_agent_steps_trained: 4857966\n",
      "    num_steps_sampled: 4857966\n",
      "    num_steps_trained: 4857966\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.67201540436457\n",
      "    ram_util_percent: 52.84942233632862\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05294043521876807\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.63016508574471\n",
      "    mean_inference_ms: 19.366340931157584\n",
      "    mean_raw_obs_processing_ms: 3.465047017308049\n",
      "  time_since_restore: 80779.43692040443\n",
      "  time_this_iter_s: 545.9023869037628\n",
      "  time_total_s: 275596.80050587654\n",
      "  timers:\n",
      "    learn_throughput: 28.138\n",
      "    learn_time_ms: 355245.846\n",
      "    load_throughput: 88587.323\n",
      "    load_time_ms: 112.838\n",
      "    sample_throughput: 54.154\n",
      "    sample_time_ms: 184585.392\n",
      "    update_time_ms: 7.128\n",
      "  timestamp: 1637536917\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4857966\n",
      "  training_iteration: 546\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   546</td><td style=\"text-align: right;\">          275597</td><td style=\"text-align: right;\">4857966</td><td style=\"text-align: right;\"> 5.51755</td><td style=\"text-align: right;\">               13.61</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           54.5217</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4867962\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_23-31-08\n",
      "  done: false\n",
      "  episode_len_mean: 54.53804347826087\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.023967391304352\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 96047\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0645932915938427\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014588750117109969\n",
      "          policy_loss: -0.06913067350070784\n",
      "          total_loss: 0.07560231995244159\n",
      "          vf_explained_var: 0.9312735199928284\n",
      "          vf_loss: 0.13214392930981758\n",
      "    num_agent_steps_sampled: 4867962\n",
      "    num_agent_steps_trained: 4867962\n",
      "    num_steps_sampled: 4867962\n",
      "    num_steps_trained: 4867962\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.65936305732485\n",
      "    ram_util_percent: 52.88840764331209\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05295673518676513\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.61590377209165\n",
      "    mean_inference_ms: 19.366685953963408\n",
      "    mean_raw_obs_processing_ms: 3.4674148570230408\n",
      "  time_since_restore: 81329.85418534279\n",
      "  time_this_iter_s: 550.4172649383545\n",
      "  time_total_s: 276147.2177708149\n",
      "  timers:\n",
      "    learn_throughput: 28.132\n",
      "    learn_time_ms: 355330.865\n",
      "    load_throughput: 88551.324\n",
      "    load_time_ms: 112.884\n",
      "    sample_throughput: 53.948\n",
      "    sample_time_ms: 185288.318\n",
      "    update_time_ms: 6.607\n",
      "  timestamp: 1637537468\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4867962\n",
      "  training_iteration: 547\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   547</td><td style=\"text-align: right;\">          276147</td><td style=\"text-align: right;\">4867962</td><td style=\"text-align: right;\"> 5.02397</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">            54.538</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4877958\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_23-40-27\n",
      "  done: false\n",
      "  episode_len_mean: 55.21546961325967\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.589999999999986\n",
      "  episode_reward_mean: 5.244696132596689\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 96228\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.038540347512946\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014560973662563953\n",
      "          policy_loss: -0.07416402394041852\n",
      "          total_loss: 0.08132506103315444\n",
      "          vf_explained_var: 0.9345823526382446\n",
      "          vf_loss: 0.14270276969521264\n",
      "    num_agent_steps_sampled: 4877958\n",
      "    num_agent_steps_trained: 4877958\n",
      "    num_steps_sampled: 4877958\n",
      "    num_steps_trained: 4877958\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.4314930991217\n",
      "    ram_util_percent: 53.52521957340025\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052934990884511285\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.59810652408314\n",
      "    mean_inference_ms: 19.367363833262853\n",
      "    mean_raw_obs_processing_ms: 3.471097878054738\n",
      "  time_since_restore: 81888.81773877144\n",
      "  time_this_iter_s: 558.9635534286499\n",
      "  time_total_s: 276706.18132424355\n",
      "  timers:\n",
      "    learn_throughput: 28.125\n",
      "    learn_time_ms: 355414.569\n",
      "    load_throughput: 88230.431\n",
      "    load_time_ms: 113.294\n",
      "    sample_throughput: 53.544\n",
      "    sample_time_ms: 186686.977\n",
      "    update_time_ms: 7.017\n",
      "  timestamp: 1637538027\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4877958\n",
      "  training_iteration: 548\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   548</td><td style=\"text-align: right;\">          276706</td><td style=\"text-align: right;\">4877958</td><td style=\"text-align: right;\">  5.2447</td><td style=\"text-align: right;\">               19.59</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           55.2155</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4887954\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_23-49-17\n",
      "  done: false\n",
      "  episode_len_mean: 55.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 4.977722222222226\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 96408\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.079494252262345\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01458553990402748\n",
      "          policy_loss: -0.07335825939637661\n",
      "          total_loss: 0.062002793999915255\n",
      "          vf_explained_var: 0.9428742527961731\n",
      "          vf_loss: 0.12292831113363754\n",
      "    num_agent_steps_sampled: 4887954\n",
      "    num_agent_steps_trained: 4887954\n",
      "    num_steps_sampled: 4887954\n",
      "    num_steps_trained: 4887954\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.94861294583883\n",
      "    ram_util_percent: 52.85746367239101\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052924235646510595\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.58543797693729\n",
      "    mean_inference_ms: 19.369899993636817\n",
      "    mean_raw_obs_processing_ms: 3.459812068667313\n",
      "  time_since_restore: 82419.06927657127\n",
      "  time_this_iter_s: 530.2515377998352\n",
      "  time_total_s: 277236.4328620434\n",
      "  timers:\n",
      "    learn_throughput: 28.12\n",
      "    learn_time_ms: 355474.562\n",
      "    load_throughput: 88207.469\n",
      "    load_time_ms: 113.324\n",
      "    sample_throughput: 53.588\n",
      "    sample_time_ms: 186534.007\n",
      "    update_time_ms: 6.814\n",
      "  timestamp: 1637538557\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4887954\n",
      "  training_iteration: 549\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   549</td><td style=\"text-align: right;\">          277236</td><td style=\"text-align: right;\">4887954</td><td style=\"text-align: right;\"> 4.97772</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">              55.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4897950\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-21_23-58-09\n",
      "  done: false\n",
      "  episode_len_mean: 54.83516483516483\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.60999999999998\n",
      "  episode_reward_mean: 5.151703296703301\n",
      "  episode_reward_min: -0.5200000000000004\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 96590\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.067940811220422\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015144861873759264\n",
      "          policy_loss: -0.07070221619775023\n",
      "          total_loss: 0.0774910659193563\n",
      "          vf_explained_var: 0.9457582235336304\n",
      "          vf_loss: 0.13437080064650073\n",
      "    num_agent_steps_sampled: 4897950\n",
      "    num_agent_steps_trained: 4897950\n",
      "    num_steps_sampled: 4897950\n",
      "    num_steps_trained: 4897950\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.0463768115942\n",
      "    ram_util_percent: 52.61238471673255\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05291787867500818\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.57487151126777\n",
      "    mean_inference_ms: 19.371140027003545\n",
      "    mean_raw_obs_processing_ms: 3.441395443719029\n",
      "  time_since_restore: 82951.30147647858\n",
      "  time_this_iter_s: 532.2321999073029\n",
      "  time_total_s: 277768.6650619507\n",
      "  timers:\n",
      "    learn_throughput: 28.117\n",
      "    learn_time_ms: 355513.223\n",
      "    load_throughput: 87958.794\n",
      "    load_time_ms: 113.644\n",
      "    sample_throughput: 53.938\n",
      "    sample_time_ms: 185323.805\n",
      "    update_time_ms: 6.965\n",
      "  timestamp: 1637539089\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4897950\n",
      "  training_iteration: 550\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   550</td><td style=\"text-align: right;\">          277769</td><td style=\"text-align: right;\">4897950</td><td style=\"text-align: right;\">  5.1517</td><td style=\"text-align: right;\">               17.61</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           54.8352</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4907946\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_00-07-29\n",
      "  done: false\n",
      "  episode_len_mean: 55.13812154696133\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.65999999999999\n",
      "  episode_reward_mean: 5.169226519337021\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 96771\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.078392409296878\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014930904625651697\n",
      "          policy_loss: -0.06684870715339841\n",
      "          total_loss: 0.08103046296076805\n",
      "          vf_explained_var: 0.9398439526557922\n",
      "          vf_loss: 0.13464862574181746\n",
      "    num_agent_steps_sampled: 4907946\n",
      "    num_agent_steps_trained: 4907946\n",
      "    num_steps_sampled: 4907946\n",
      "    num_steps_trained: 4907946\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.45857321652065\n",
      "    ram_util_percent: 52.924030037546935\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05292858781849631\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.56026675515085\n",
      "    mean_inference_ms: 19.37218212002477\n",
      "    mean_raw_obs_processing_ms: 3.450952812426452\n",
      "  time_since_restore: 83511.23576378822\n",
      "  time_this_iter_s: 559.9342873096466\n",
      "  time_total_s: 278328.59934926033\n",
      "  timers:\n",
      "    learn_throughput: 28.115\n",
      "    learn_time_ms: 355545.747\n",
      "    load_throughput: 88127.039\n",
      "    load_time_ms: 113.427\n",
      "    sample_throughput: 53.48\n",
      "    sample_time_ms: 186912.662\n",
      "    update_time_ms: 7.101\n",
      "  timestamp: 1637539649\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4907946\n",
      "  training_iteration: 551\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   551</td><td style=\"text-align: right;\">          278329</td><td style=\"text-align: right;\">4907946</td><td style=\"text-align: right;\"> 5.16923</td><td style=\"text-align: right;\">               19.66</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           55.1381</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4917942\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_00-16-30\n",
      "  done: false\n",
      "  episode_len_mean: 55.28021978021978\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000007\n",
      "  episode_reward_mean: 5.014945054945059\n",
      "  episode_reward_min: -0.6400000000000003\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 96953\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0552289284137357\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015793580189338276\n",
      "          policy_loss: -0.06760424404434805\n",
      "          total_loss: 0.09743495909057753\n",
      "          vf_explained_var: 0.9371140599250793\n",
      "          vf_loss: 0.14961174050482537\n",
      "    num_agent_steps_sampled: 4917942\n",
      "    num_agent_steps_trained: 4917942\n",
      "    num_steps_sampled: 4917942\n",
      "    num_steps_trained: 4917942\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.86588845654994\n",
      "    ram_util_percent: 53.25654993514916\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293139666465729\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.5409661695905\n",
      "    mean_inference_ms: 19.372795289356933\n",
      "    mean_raw_obs_processing_ms: 3.4481716733104424\n",
      "  time_since_restore: 84051.70622968674\n",
      "  time_this_iter_s: 540.4704658985138\n",
      "  time_total_s: 278869.06981515884\n",
      "  timers:\n",
      "    learn_throughput: 28.113\n",
      "    learn_time_ms: 355570.33\n",
      "    load_throughput: 88686.752\n",
      "    load_time_ms: 112.711\n",
      "    sample_throughput: 53.593\n",
      "    sample_time_ms: 186518.543\n",
      "    update_time_ms: 6.551\n",
      "  timestamp: 1637540190\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4917942\n",
      "  training_iteration: 552\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   552</td><td style=\"text-align: right;\">          278869</td><td style=\"text-align: right;\">4917942</td><td style=\"text-align: right;\"> 5.01495</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.64</td><td style=\"text-align: right;\">           55.2802</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4927938\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_00-25-21\n",
      "  done: false\n",
      "  episode_len_mean: 54.675824175824175\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 4.681208791208795\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 97135\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.088294063634183\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014014975193131352\n",
      "          policy_loss: -0.073183256388051\n",
      "          total_loss: 0.05662458460806138\n",
      "          vf_explained_var: 0.9397945404052734\n",
      "          vf_loss: 0.11876291599756772\n",
      "    num_agent_steps_sampled: 4927938\n",
      "    num_agent_steps_trained: 4927938\n",
      "    num_steps_sampled: 4927938\n",
      "    num_steps_trained: 4927938\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.96213720316624\n",
      "    ram_util_percent: 53.07757255936676\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052935040350849366\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.53265506229717\n",
      "    mean_inference_ms: 19.375029477491466\n",
      "    mean_raw_obs_processing_ms: 3.433755918431511\n",
      "  time_since_restore: 84582.9456050396\n",
      "  time_this_iter_s: 531.2393753528595\n",
      "  time_total_s: 279400.3091905117\n",
      "  timers:\n",
      "    learn_throughput: 28.108\n",
      "    learn_time_ms: 355623.528\n",
      "    load_throughput: 88055.355\n",
      "    load_time_ms: 113.52\n",
      "    sample_throughput: 53.602\n",
      "    sample_time_ms: 186486.977\n",
      "    update_time_ms: 6.281\n",
      "  timestamp: 1637540721\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4927938\n",
      "  training_iteration: 553\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   553</td><td style=\"text-align: right;\">          279400</td><td style=\"text-align: right;\">4927938</td><td style=\"text-align: right;\"> 4.68121</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           54.6758</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4937934\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_00-34-11\n",
      "  done: false\n",
      "  episode_len_mean: 55.53333333333333\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.580000000000002\n",
      "  episode_reward_mean: 4.961444444444449\n",
      "  episode_reward_min: -0.6300000000000003\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 97315\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.071085844078217\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01544418496525428\n",
      "          policy_loss: -0.0666668844463422\n",
      "          total_loss: 0.08297739188683262\n",
      "          vf_explained_var: 0.9196906685829163\n",
      "          vf_loss: 0.13517135007673478\n",
      "    num_agent_steps_sampled: 4937934\n",
      "    num_agent_steps_trained: 4937934\n",
      "    num_steps_sampled: 4937934\n",
      "    num_steps_trained: 4937934\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.99285714285715\n",
      "    ram_util_percent: 52.81269841269842\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293268232814589\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.51866277993284\n",
      "    mean_inference_ms: 19.377790372790315\n",
      "    mean_raw_obs_processing_ms: 3.416651000959704\n",
      "  time_since_restore: 85112.7632548809\n",
      "  time_this_iter_s: 529.8176498413086\n",
      "  time_total_s: 279930.126840353\n",
      "  timers:\n",
      "    learn_throughput: 28.106\n",
      "    learn_time_ms: 355655.699\n",
      "    load_throughput: 88079.274\n",
      "    load_time_ms: 113.489\n",
      "    sample_throughput: 53.938\n",
      "    sample_time_ms: 185323.556\n",
      "    update_time_ms: 5.887\n",
      "  timestamp: 1637541251\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4937934\n",
      "  training_iteration: 554\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   554</td><td style=\"text-align: right;\">          279930</td><td style=\"text-align: right;\">4937934</td><td style=\"text-align: right;\"> 4.96144</td><td style=\"text-align: right;\">               17.58</td><td style=\"text-align: right;\">               -0.63</td><td style=\"text-align: right;\">           55.5333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4947930\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_00-43-28\n",
      "  done: false\n",
      "  episode_len_mean: 54.988950276243095\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.63\n",
      "  episode_reward_mean: 5.195856353591164\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 97496\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0259331025272966\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01468584764843218\n",
      "          policy_loss: -0.07223874558214857\n",
      "          total_loss: 0.08559487630440103\n",
      "          vf_explained_var: 0.9419647455215454\n",
      "          vf_loss: 0.1446367547082449\n",
      "    num_agent_steps_sampled: 4947930\n",
      "    num_agent_steps_trained: 4947930\n",
      "    num_steps_sampled: 4947930\n",
      "    num_steps_trained: 4947930\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.5606289308176\n",
      "    ram_util_percent: 53.5051572327044\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293207551249533\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.49847813486526\n",
      "    mean_inference_ms: 19.37725024011819\n",
      "    mean_raw_obs_processing_ms: 3.4276891403657905\n",
      "  time_since_restore: 85669.84135007858\n",
      "  time_this_iter_s: 557.0780951976776\n",
      "  time_total_s: 280487.2049355507\n",
      "  timers:\n",
      "    learn_throughput: 28.105\n",
      "    learn_time_ms: 355662.756\n",
      "    load_throughput: 88161.526\n",
      "    load_time_ms: 113.383\n",
      "    sample_throughput: 53.217\n",
      "    sample_time_ms: 187834.564\n",
      "    update_time_ms: 5.547\n",
      "  timestamp: 1637541808\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4947930\n",
      "  training_iteration: 555\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   555</td><td style=\"text-align: right;\">          280487</td><td style=\"text-align: right;\">4947930</td><td style=\"text-align: right;\"> 5.19586</td><td style=\"text-align: right;\">               17.63</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">            54.989</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4957926\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_00-52-32\n",
      "  done: false\n",
      "  episode_len_mean: 54.71739130434783\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.619999999999997\n",
      "  episode_reward_mean: 4.756521739130439\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 97680\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.100419657752217\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014608865974021891\n",
      "          policy_loss: -0.06746124408835377\n",
      "          total_loss: 0.07398530134548006\n",
      "          vf_explained_var: 0.9360494613647461\n",
      "          vf_loss: 0.1291699180496393\n",
      "    num_agent_steps_sampled: 4957926\n",
      "    num_agent_steps_trained: 4957926\n",
      "    num_steps_sampled: 4957926\n",
      "    num_steps_trained: 4957926\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.85431145431146\n",
      "    ram_util_percent: 53.58108108108108\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052944914753609795\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.4844828108091\n",
      "    mean_inference_ms: 19.37739067828554\n",
      "    mean_raw_obs_processing_ms: 3.4251426156374816\n",
      "  time_since_restore: 86214.05409884453\n",
      "  time_this_iter_s: 544.2127487659454\n",
      "  time_total_s: 281031.41768431664\n",
      "  timers:\n",
      "    learn_throughput: 28.107\n",
      "    learn_time_ms: 355647.075\n",
      "    load_throughput: 87679.16\n",
      "    load_time_ms: 114.007\n",
      "    sample_throughput: 53.261\n",
      "    sample_time_ms: 187680.255\n",
      "    update_time_ms: 5.828\n",
      "  timestamp: 1637542352\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4957926\n",
      "  training_iteration: 556\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   556</td><td style=\"text-align: right;\">          281031</td><td style=\"text-align: right;\">4957926</td><td style=\"text-align: right;\"> 4.75652</td><td style=\"text-align: right;\">               17.62</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           54.7174</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4967922\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_01-01-42\n",
      "  done: false\n",
      "  episode_len_mean: 54.54945054945055\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.689999999999998\n",
      "  episode_reward_mean: 5.233241758241762\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 97862\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0672979072633995\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014938494866909026\n",
      "          policy_loss: -0.07219338299421735\n",
      "          total_loss: 0.06766234743967559\n",
      "          vf_explained_var: 0.932979166507721\n",
      "          vf_loss: 0.12649694972925907\n",
      "    num_agent_steps_sampled: 4967922\n",
      "    num_agent_steps_trained: 4967922\n",
      "    num_steps_sampled: 4967922\n",
      "    num_steps_trained: 4967922\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.72193877551021\n",
      "    ram_util_percent: 53.75229591836735\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293424614011034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.46792709009468\n",
      "    mean_inference_ms: 19.37796366805516\n",
      "    mean_raw_obs_processing_ms: 3.4272844793897734\n",
      "  time_since_restore: 86764.09346294403\n",
      "  time_this_iter_s: 550.0393640995026\n",
      "  time_total_s: 281581.45704841614\n",
      "  timers:\n",
      "    learn_throughput: 28.116\n",
      "    learn_time_ms: 355529.369\n",
      "    load_throughput: 87673.018\n",
      "    load_time_ms: 114.015\n",
      "    sample_throughput: 53.238\n",
      "    sample_time_ms: 187760.081\n",
      "    update_time_ms: 5.553\n",
      "  timestamp: 1637542902\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4967922\n",
      "  training_iteration: 557\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   557</td><td style=\"text-align: right;\">          281581</td><td style=\"text-align: right;\">4967922</td><td style=\"text-align: right;\"> 5.23324</td><td style=\"text-align: right;\">               17.69</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           54.5495</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4977918\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_01-10-34\n",
      "  done: false\n",
      "  episode_len_mean: 54.78142076502732\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.629999999999992\n",
      "  episode_reward_mean: 4.696448087431698\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 98045\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.096775496939579\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015012916787490777\n",
      "          policy_loss: -0.06856794741639007\n",
      "          total_loss: 0.07633675420131412\n",
      "          vf_explained_var: 0.9266807436943054\n",
      "          vf_loss: 0.13167115415205213\n",
      "    num_agent_steps_sampled: 4977918\n",
      "    num_agent_steps_trained: 4977918\n",
      "    num_steps_sampled: 4977918\n",
      "    num_steps_trained: 4977918\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01725955204216\n",
      "    ram_util_percent: 52.546113306982875\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05293528592777684\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.46009954960511\n",
      "    mean_inference_ms: 19.38102547519907\n",
      "    mean_raw_obs_processing_ms: 3.4143741164895527\n",
      "  time_since_restore: 87295.82693958282\n",
      "  time_this_iter_s: 531.733476638794\n",
      "  time_total_s: 282113.19052505493\n",
      "  timers:\n",
      "    learn_throughput: 28.126\n",
      "    learn_time_ms: 355405.846\n",
      "    load_throughput: 87977.546\n",
      "    load_time_ms: 113.62\n",
      "    sample_throughput: 53.985\n",
      "    sample_time_ms: 185161.062\n",
      "    update_time_ms: 5.506\n",
      "  timestamp: 1637543434\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4977918\n",
      "  training_iteration: 558\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   558</td><td style=\"text-align: right;\">          282113</td><td style=\"text-align: right;\">4977918</td><td style=\"text-align: right;\"> 4.69645</td><td style=\"text-align: right;\">               17.63</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           54.7814</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4987914\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_01-19-35\n",
      "  done: false\n",
      "  episode_len_mean: 55.13259668508287\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.56000000000001\n",
      "  episode_reward_mean: 4.729889502762435\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 98226\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0652557463052283\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01432984306504529\n",
      "          policy_loss: -0.0689034445839785\n",
      "          total_loss: 0.06888787875090777\n",
      "          vf_explained_var: 0.9365155100822449\n",
      "          vf_loss: 0.1257987049570958\n",
      "    num_agent_steps_sampled: 4987914\n",
      "    num_agent_steps_trained: 4987914\n",
      "    num_steps_sampled: 4987914\n",
      "    num_steps_trained: 4987914\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.90492227979276\n",
      "    ram_util_percent: 53.37163212435233\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052922476676704834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.44333119933523\n",
      "    mean_inference_ms: 19.38149381632311\n",
      "    mean_raw_obs_processing_ms: 3.4219430712762775\n",
      "  time_since_restore: 87836.81028294563\n",
      "  time_this_iter_s: 540.9833433628082\n",
      "  time_total_s: 282654.17386841774\n",
      "  timers:\n",
      "    learn_throughput: 28.141\n",
      "    learn_time_ms: 355208.196\n",
      "    load_throughput: 88113.501\n",
      "    load_time_ms: 113.445\n",
      "    sample_throughput: 53.617\n",
      "    sample_time_ms: 186432.988\n",
      "    update_time_ms: 5.416\n",
      "  timestamp: 1637543975\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4987914\n",
      "  training_iteration: 559\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   559</td><td style=\"text-align: right;\">          282654</td><td style=\"text-align: right;\">4987914</td><td style=\"text-align: right;\"> 4.72989</td><td style=\"text-align: right;\">               13.56</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           55.1326</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 4997910\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_01-28-24\n",
      "  done: false\n",
      "  episode_len_mean: 56.26815642458101\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.023128491620116\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 179\n",
      "  episodes_total: 98405\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.077030060951968\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015163585849701525\n",
      "          policy_loss: -0.07641300513365408\n",
      "          total_loss: 0.08029643088952561\n",
      "          vf_explained_var: 0.9307213425636292\n",
      "          vf_loss: 0.14293519032092383\n",
      "    num_agent_steps_sampled: 4997910\n",
      "    num_agent_steps_trained: 4997910\n",
      "    num_steps_sampled: 4997910\n",
      "    num_steps_trained: 4997910\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.99403183023873\n",
      "    ram_util_percent: 53.11631299734748\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05291924652649375\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.4280211001121\n",
      "    mean_inference_ms: 19.38397702876492\n",
      "    mean_raw_obs_processing_ms: 3.405983676134442\n",
      "  time_since_restore: 88365.54212522507\n",
      "  time_this_iter_s: 528.7318422794342\n",
      "  time_total_s: 283182.9057106972\n",
      "  timers:\n",
      "    learn_throughput: 28.149\n",
      "    learn_time_ms: 355110.038\n",
      "    load_throughput: 88048.772\n",
      "    load_time_ms: 113.528\n",
      "    sample_throughput: 53.689\n",
      "    sample_time_ms: 186181.774\n",
      "    update_time_ms: 5.21\n",
      "  timestamp: 1637544504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4997910\n",
      "  training_iteration: 560\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   560</td><td style=\"text-align: right;\">          283183</td><td style=\"text-align: right;\">4997910</td><td style=\"text-align: right;\"> 5.02313</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           56.2682</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5007906\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_01-37-40\n",
      "  done: false\n",
      "  episode_len_mean: 55.327777777777776\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.590000000000005\n",
      "  episode_reward_mean: 5.178666666666671\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 98585\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0638184063405878\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0149890617910007\n",
      "          policy_loss: -0.0712766948897286\n",
      "          total_loss: 0.08767528354731048\n",
      "          vf_explained_var: 0.9420664310455322\n",
      "          vf_loss: 0.14544320449655704\n",
      "    num_agent_steps_sampled: 5007906\n",
      "    num_agent_steps_trained: 5007906\n",
      "    num_steps_sampled: 5007906\n",
      "    num_steps_trained: 5007906\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.51813602015115\n",
      "    ram_util_percent: 53.92481108312343\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05291914930038602\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.409345842811916\n",
      "    mean_inference_ms: 19.382757180210675\n",
      "    mean_raw_obs_processing_ms: 3.4173873343703174\n",
      "  time_since_restore: 88921.98594522476\n",
      "  time_this_iter_s: 556.4438199996948\n",
      "  time_total_s: 283739.34953069687\n",
      "  timers:\n",
      "    learn_throughput: 28.159\n",
      "    learn_time_ms: 354978.791\n",
      "    load_throughput: 88146.42\n",
      "    load_time_ms: 113.402\n",
      "    sample_throughput: 53.752\n",
      "    sample_time_ms: 185964.376\n",
      "    update_time_ms: 5.015\n",
      "  timestamp: 1637545060\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5007906\n",
      "  training_iteration: 561\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   561</td><td style=\"text-align: right;\">          283739</td><td style=\"text-align: right;\">5007906</td><td style=\"text-align: right;\"> 5.17867</td><td style=\"text-align: right;\">               13.59</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           55.3278</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5017902\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_01-46-42\n",
      "  done: false\n",
      "  episode_len_mean: 55.33701657458563\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.530000000000008\n",
      "  episode_reward_mean: 4.713259668508292\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 98766\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.079499497279585\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015346984924540999\n",
      "          policy_loss: -0.0720507785875851\n",
      "          total_loss: 0.07145817773301226\n",
      "          vf_explained_var: 0.9258275032043457\n",
      "          vf_loss: 0.1293416001244886\n",
      "    num_agent_steps_sampled: 5017902\n",
      "    num_agent_steps_trained: 5017902\n",
      "    num_steps_sampled: 5017902\n",
      "    num_steps_trained: 5017902\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.71836998706337\n",
      "    ram_util_percent: 53.51668822768434\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052922514285797244\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.39457153389656\n",
      "    mean_inference_ms: 19.382997638490547\n",
      "    mean_raw_obs_processing_ms: 3.4151014968105637\n",
      "  time_since_restore: 89463.82972931862\n",
      "  time_this_iter_s: 541.8437840938568\n",
      "  time_total_s: 284281.1933147907\n",
      "  timers:\n",
      "    learn_throughput: 28.167\n",
      "    learn_time_ms: 354887.56\n",
      "    load_throughput: 87827.125\n",
      "    load_time_ms: 113.814\n",
      "    sample_throughput: 53.686\n",
      "    sample_time_ms: 186192.72\n",
      "    update_time_ms: 5.168\n",
      "  timestamp: 1637545602\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5017902\n",
      "  training_iteration: 562\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   562</td><td style=\"text-align: right;\">          284281</td><td style=\"text-align: right;\">5017902</td><td style=\"text-align: right;\"> 4.71326</td><td style=\"text-align: right;\">               15.53</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">            55.337</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5027898\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_01-55-45\n",
      "  done: false\n",
      "  episode_len_mean: 55.43888888888889\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.57\n",
      "  episode_reward_mean: 5.011388888888893\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 98946\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0371680565627224\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015259883577545225\n",
      "          policy_loss: -0.06716721529869263\n",
      "          total_loss: 0.11571304523382847\n",
      "          vf_explained_var: 0.9252233505249023\n",
      "          vf_loss: 0.1684880172355983\n",
      "    num_agent_steps_sampled: 5027898\n",
      "    num_agent_steps_trained: 5027898\n",
      "    num_steps_sampled: 5027898\n",
      "    num_steps_trained: 5027898\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.85264516129031\n",
      "    ram_util_percent: 53.403870967741945\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529224108921904\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.38061845839615\n",
      "    mean_inference_ms: 19.383698153042022\n",
      "    mean_raw_obs_processing_ms: 3.409650763738694\n",
      "  time_since_restore: 90006.563205719\n",
      "  time_this_iter_s: 542.7334764003754\n",
      "  time_total_s: 284823.9267911911\n",
      "  timers:\n",
      "    learn_throughput: 28.175\n",
      "    learn_time_ms: 354779.484\n",
      "    load_throughput: 88524.887\n",
      "    load_time_ms: 112.917\n",
      "    sample_throughput: 53.326\n",
      "    sample_time_ms: 187450.743\n",
      "    update_time_ms: 5.394\n",
      "  timestamp: 1637546145\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5027898\n",
      "  training_iteration: 563\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   563</td><td style=\"text-align: right;\">          284824</td><td style=\"text-align: right;\">5027898</td><td style=\"text-align: right;\"> 5.01139</td><td style=\"text-align: right;\">               17.57</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           55.4389</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5037894\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_02-04-34\n",
      "  done: false\n",
      "  episode_len_mean: 56.67231638418079\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.590000000000003\n",
      "  episode_reward_mean: 5.093107344632772\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 177\n",
      "  episodes_total: 99123\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0716832888892376\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015734721988596233\n",
      "          policy_loss: -0.06854801071929827\n",
      "          total_loss: 0.0883976979568345\n",
      "          vf_explained_var: 0.9225409626960754\n",
      "          vf_loss: 0.14181687750191574\n",
      "    num_agent_steps_sampled: 5037894\n",
      "    num_agent_steps_trained: 5037894\n",
      "    num_steps_sampled: 5037894\n",
      "    num_steps_trained: 5037894\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.06807947019867\n",
      "    ram_util_percent: 53.15629139072848\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529254629909408\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.36912479528874\n",
      "    mean_inference_ms: 19.386818058540637\n",
      "    mean_raw_obs_processing_ms: 3.395189876364272\n",
      "  time_since_restore: 90535.81369042397\n",
      "  time_this_iter_s: 529.2504847049713\n",
      "  time_total_s: 285353.1772758961\n",
      "  timers:\n",
      "    learn_throughput: 28.185\n",
      "    learn_time_ms: 354661.479\n",
      "    load_throughput: 88425.466\n",
      "    load_time_ms: 113.044\n",
      "    sample_throughput: 53.309\n",
      "    sample_time_ms: 187511.244\n",
      "    update_time_ms: 5.837\n",
      "  timestamp: 1637546674\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5037894\n",
      "  training_iteration: 564\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   564</td><td style=\"text-align: right;\">          285353</td><td style=\"text-align: right;\">5037894</td><td style=\"text-align: right;\"> 5.09311</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           56.6723</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5047890\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_02-13-37\n",
      "  done: false\n",
      "  episode_len_mean: 56.46590909090909\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.550000000000008\n",
      "  episode_reward_mean: 4.974488636363641\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 176\n",
      "  episodes_total: 99299\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0705346309995076\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015254393811308786\n",
      "          policy_loss: -0.07273538051111493\n",
      "          total_loss: 0.0913007697507866\n",
      "          vf_explained_var: 0.9256713390350342\n",
      "          vf_loss: 0.14999007976101525\n",
      "    num_agent_steps_sampled: 5047890\n",
      "    num_agent_steps_trained: 5047890\n",
      "    num_steps_sampled: 5047890\n",
      "    num_steps_trained: 5047890\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.76632258064515\n",
      "    ram_util_percent: 53.153935483870974\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05294400906178507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.3555422803584\n",
      "    mean_inference_ms: 19.3876469455002\n",
      "    mean_raw_obs_processing_ms: 3.3932865651144626\n",
      "  time_since_restore: 91079.15940380096\n",
      "  time_this_iter_s: 543.3457133769989\n",
      "  time_total_s: 285896.5229892731\n",
      "  timers:\n",
      "    learn_throughput: 28.193\n",
      "    learn_time_ms: 354556.777\n",
      "    load_throughput: 88509.936\n",
      "    load_time_ms: 112.936\n",
      "    sample_throughput: 53.672\n",
      "    sample_time_ms: 186242.69\n",
      "    update_time_ms: 5.793\n",
      "  timestamp: 1637547217\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5047890\n",
      "  training_iteration: 565\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   565</td><td style=\"text-align: right;\">          285897</td><td style=\"text-align: right;\">5047890</td><td style=\"text-align: right;\"> 4.97449</td><td style=\"text-align: right;\">               15.55</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           56.4659</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5057886\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_02-22-54\n",
      "  done: false\n",
      "  episode_len_mean: 55.26519337016575\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.58\n",
      "  episode_reward_mean: 4.870607734806633\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 99480\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.060622893208002\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014188026351622139\n",
      "          policy_loss: -0.06404947203504652\n",
      "          total_loss: 0.07732465294700953\n",
      "          vf_explained_var: 0.9181507229804993\n",
      "          vf_loss: 0.12965825529568958\n",
      "    num_agent_steps_sampled: 5057886\n",
      "    num_agent_steps_trained: 5057886\n",
      "    num_steps_sampled: 5057886\n",
      "    num_steps_trained: 5057886\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.47531486146094\n",
      "    ram_util_percent: 54.23274559193955\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05292862120712437\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.338411715102964\n",
      "    mean_inference_ms: 19.386343115104395\n",
      "    mean_raw_obs_processing_ms: 3.4101583920064367\n",
      "  time_since_restore: 91635.84929180145\n",
      "  time_this_iter_s: 556.6898880004883\n",
      "  time_total_s: 286453.21287727356\n",
      "  timers:\n",
      "    learn_throughput: 28.202\n",
      "    learn_time_ms: 354437.79\n",
      "    load_throughput: 88647.523\n",
      "    load_time_ms: 112.761\n",
      "    sample_throughput: 53.281\n",
      "    sample_time_ms: 187608.94\n",
      "    update_time_ms: 5.881\n",
      "  timestamp: 1637547774\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5057886\n",
      "  training_iteration: 566\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   566</td><td style=\"text-align: right;\">          286453</td><td style=\"text-align: right;\">5057886</td><td style=\"text-align: right;\"> 4.87061</td><td style=\"text-align: right;\">               17.58</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           55.2652</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5067882\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_02-31-47\n",
      "  done: false\n",
      "  episode_len_mean: 54.62841530054645\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000009\n",
      "  episode_reward_mean: 4.875846994535524\n",
      "  episode_reward_min: -0.4800000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 99663\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0487172236404265\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014045740488840589\n",
      "          policy_loss: -0.07005157562732081\n",
      "          total_loss: 0.06961162061219599\n",
      "          vf_explained_var: 0.9383404850959778\n",
      "          vf_loss: 0.1281524143461325\n",
      "    num_agent_steps_sampled: 5067882\n",
      "    num_agent_steps_trained: 5067882\n",
      "    num_steps_sampled: 5067882\n",
      "    num_steps_trained: 5067882\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.03022339027595\n",
      "    ram_util_percent: 53.22155059132721\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529345366789259\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.33426225753619\n",
      "    mean_inference_ms: 19.389192264019336\n",
      "    mean_raw_obs_processing_ms: 3.3971491655013524\n",
      "  time_since_restore: 92168.98311138153\n",
      "  time_this_iter_s: 533.1338195800781\n",
      "  time_total_s: 286986.34669685364\n",
      "  timers:\n",
      "    learn_throughput: 28.208\n",
      "    learn_time_ms: 354368.315\n",
      "    load_throughput: 88600.072\n",
      "    load_time_ms: 112.822\n",
      "    sample_throughput: 53.745\n",
      "    sample_time_ms: 185987.818\n",
      "    update_time_ms: 6.086\n",
      "  timestamp: 1637548307\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5067882\n",
      "  training_iteration: 567\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   567</td><td style=\"text-align: right;\">          286986</td><td style=\"text-align: right;\">5067882</td><td style=\"text-align: right;\"> 4.87585</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           54.6284</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5077878\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_02-40-38\n",
      "  done: false\n",
      "  episode_len_mean: 55.74860335195531\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 4.874301675977658\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 179\n",
      "  episodes_total: 99842\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.044353840509093\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01506762577341756\n",
      "          policy_loss: -0.07032364738884518\n",
      "          total_loss: 0.0764516898186175\n",
      "          vf_explained_var: 0.9342193007469177\n",
      "          vf_loss: 0.13289293917372869\n",
      "    num_agent_steps_sampled: 5077878\n",
      "    num_agent_steps_trained: 5077878\n",
      "    num_steps_sampled: 5077878\n",
      "    num_steps_trained: 5077878\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.92509907529723\n",
      "    ram_util_percent: 53.11770145310437\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052962514645816264\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.32775834767635\n",
      "    mean_inference_ms: 19.391335151869306\n",
      "    mean_raw_obs_processing_ms: 3.3858403211386645\n",
      "  time_since_restore: 92699.47393608093\n",
      "  time_this_iter_s: 530.4908246994019\n",
      "  time_total_s: 287516.83752155304\n",
      "  timers:\n",
      "    learn_throughput: 28.215\n",
      "    learn_time_ms: 354280.314\n",
      "    load_throughput: 88591.816\n",
      "    load_time_ms: 112.832\n",
      "    sample_throughput: 53.756\n",
      "    sample_time_ms: 185951.269\n",
      "    update_time_ms: 5.934\n",
      "  timestamp: 1637548838\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5077878\n",
      "  training_iteration: 568\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   568</td><td style=\"text-align: right;\">          287517</td><td style=\"text-align: right;\">5077878</td><td style=\"text-align: right;\">  4.8743</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           55.7486</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5087874\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_02-49-30\n",
      "  done: false\n",
      "  episode_len_mean: 55.41436464088398\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.480000000000008\n",
      "  episode_reward_mean: 4.972817679558015\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 100023\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0409510204830323\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014815826181780609\n",
      "          policy_loss: -0.07164509809558531\n",
      "          total_loss: 0.07267448245245424\n",
      "          vf_explained_var: 0.9062899947166443\n",
      "          vf_loss: 0.13097678473645663\n",
      "    num_agent_steps_sampled: 5087874\n",
      "    num_agent_steps_trained: 5087874\n",
      "    num_steps_sampled: 5087874\n",
      "    num_steps_trained: 5087874\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.966534914361\n",
      "    ram_util_percent: 52.83833992094862\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052956695478338124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.32223965468509\n",
      "    mean_inference_ms: 19.393105816571257\n",
      "    mean_raw_obs_processing_ms: 3.3705563721636125\n",
      "  time_since_restore: 93231.85898780823\n",
      "  time_this_iter_s: 532.3850517272949\n",
      "  time_total_s: 288049.22257328033\n",
      "  timers:\n",
      "    learn_throughput: 28.217\n",
      "    learn_time_ms: 354252.859\n",
      "    load_throughput: 88643.231\n",
      "    load_time_ms: 112.767\n",
      "    sample_throughput: 53.998\n",
      "    sample_time_ms: 185118.953\n",
      "    update_time_ms: 5.759\n",
      "  timestamp: 1637549370\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5087874\n",
      "  training_iteration: 569\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   569</td><td style=\"text-align: right;\">          288049</td><td style=\"text-align: right;\">5087874</td><td style=\"text-align: right;\"> 4.97282</td><td style=\"text-align: right;\">               15.48</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           55.4144</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5097870\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_02-58-48\n",
      "  done: false\n",
      "  episode_len_mean: 54.67213114754098\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 5.335136612021863\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 100206\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.012044188511898\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015066703520458318\n",
      "          policy_loss: -0.07141069560036294\n",
      "          total_loss: 0.08603399635970613\n",
      "          vf_explained_var: 0.9298755526542664\n",
      "          vf_loss: 0.1432412983320399\n",
      "    num_agent_steps_sampled: 5097870\n",
      "    num_agent_steps_trained: 5097870\n",
      "    num_steps_sampled: 5097870\n",
      "    num_steps_trained: 5097870\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.6043969849246\n",
      "    ram_util_percent: 53.55251256281407\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05296292830079529\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.30717089010492\n",
      "    mean_inference_ms: 19.39127107750774\n",
      "    mean_raw_obs_processing_ms: 3.396097178492705\n",
      "  time_since_restore: 93789.40992593765\n",
      "  time_this_iter_s: 557.550938129425\n",
      "  time_total_s: 288606.77351140976\n",
      "  timers:\n",
      "    learn_throughput: 28.223\n",
      "    learn_time_ms: 354177.79\n",
      "    load_throughput: 88666.946\n",
      "    load_time_ms: 112.736\n",
      "    sample_throughput: 53.149\n",
      "    sample_time_ms: 188075.493\n",
      "    update_time_ms: 5.921\n",
      "  timestamp: 1637549928\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5097870\n",
      "  training_iteration: 570\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   570</td><td style=\"text-align: right;\">          288607</td><td style=\"text-align: right;\">5097870</td><td style=\"text-align: right;\"> 5.33514</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           54.6721</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5107866\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_03-07-50\n",
      "  done: false\n",
      "  episode_len_mean: 54.76923076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.67000000000001\n",
      "  episode_reward_mean: 4.916923076923081\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 100388\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0448204884328036\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015780551941480446\n",
      "          policy_loss: -0.0643119687209307\n",
      "          total_loss: 0.10019052994252213\n",
      "          vf_explained_var: 0.9341119527816772\n",
      "          vf_loss: 0.14900063288530865\n",
      "    num_agent_steps_sampled: 5107866\n",
      "    num_agent_steps_trained: 5107866\n",
      "    num_steps_sampled: 5107866\n",
      "    num_steps_trained: 5107866\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7523932729625\n",
      "    ram_util_percent: 53.815394566623546\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052959704848908135\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.295289983222524\n",
      "    mean_inference_ms: 19.392123942638225\n",
      "    mean_raw_obs_processing_ms: 3.3880553819082335\n",
      "  time_since_restore: 94331.22650074959\n",
      "  time_this_iter_s: 541.8165748119354\n",
      "  time_total_s: 289148.5900862217\n",
      "  timers:\n",
      "    learn_throughput: 28.23\n",
      "    learn_time_ms: 354089.96\n",
      "    load_throughput: 87679.435\n",
      "    load_time_ms: 114.006\n",
      "    sample_throughput: 53.541\n",
      "    sample_time_ms: 186699.124\n",
      "    update_time_ms: 6.37\n",
      "  timestamp: 1637550470\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5107866\n",
      "  training_iteration: 571\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   571</td><td style=\"text-align: right;\">          289149</td><td style=\"text-align: right;\">5107866</td><td style=\"text-align: right;\"> 4.91692</td><td style=\"text-align: right;\">               19.67</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           54.7692</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5117862\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_03-16-44\n",
      "  done: false\n",
      "  episode_len_mean: 53.82258064516129\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.569999999999975\n",
      "  episode_reward_mean: 5.134784946236563\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 100574\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0364712553091318\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015351652656797103\n",
      "          policy_loss: -0.06668080074563419\n",
      "          total_loss: 0.09620620980193863\n",
      "          vf_explained_var: 0.9267486929893494\n",
      "          vf_loss: 0.14827873914859754\n",
      "    num_agent_steps_sampled: 5117862\n",
      "    num_agent_steps_trained: 5117862\n",
      "    num_steps_sampled: 5117862\n",
      "    num_steps_trained: 5117862\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01535433070867\n",
      "    ram_util_percent: 53.422047244094486\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529748851791082\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.29304157938713\n",
      "    mean_inference_ms: 19.394023486010802\n",
      "    mean_raw_obs_processing_ms: 3.3793779315438286\n",
      "  time_since_restore: 94865.32775855064\n",
      "  time_this_iter_s: 534.1012578010559\n",
      "  time_total_s: 289682.69134402275\n",
      "  timers:\n",
      "    learn_throughput: 28.235\n",
      "    learn_time_ms: 354034.759\n",
      "    load_throughput: 87698.16\n",
      "    load_time_ms: 113.982\n",
      "    sample_throughput: 53.748\n",
      "    sample_time_ms: 185980.141\n",
      "    update_time_ms: 5.987\n",
      "  timestamp: 1637551004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5117862\n",
      "  training_iteration: 572\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   572</td><td style=\"text-align: right;\">          289683</td><td style=\"text-align: right;\">5117862</td><td style=\"text-align: right;\"> 5.13478</td><td style=\"text-align: right;\">               17.57</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           53.8226</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5127858\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_03-25-51\n",
      "  done: false\n",
      "  episode_len_mean: 53.806451612903224\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 4.737258064516133\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 100760\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0477752874414605\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014825607948072674\n",
      "          policy_loss: -0.07101170190807449\n",
      "          total_loss: 0.08786792892529614\n",
      "          vf_explained_var: 0.9187474250793457\n",
      "          vf_loss: 0.1455827947557309\n",
      "    num_agent_steps_sampled: 5127858\n",
      "    num_agent_steps_trained: 5127858\n",
      "    num_steps_sampled: 5127858\n",
      "    num_steps_trained: 5127858\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91549295774648\n",
      "    ram_util_percent: 53.43674775928298\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052974465289081424\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.28562269169493\n",
      "    mean_inference_ms: 19.393279721744268\n",
      "    mean_raw_obs_processing_ms: 3.37668836179429\n",
      "  time_since_restore: 95413.01636481285\n",
      "  time_this_iter_s: 547.688606262207\n",
      "  time_total_s: 290230.37995028496\n",
      "  timers:\n",
      "    learn_throughput: 28.235\n",
      "    learn_time_ms: 354022.723\n",
      "    load_throughput: 87348.364\n",
      "    load_time_ms: 114.438\n",
      "    sample_throughput: 53.601\n",
      "    sample_time_ms: 186487.707\n",
      "    update_time_ms: 5.603\n",
      "  timestamp: 1637551551\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5127858\n",
      "  training_iteration: 573\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   573</td><td style=\"text-align: right;\">          290230</td><td style=\"text-align: right;\">5127858</td><td style=\"text-align: right;\"> 4.73726</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           53.8065</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5137854\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_03-34-58\n",
      "  done: false\n",
      "  episode_len_mean: 53.623655913978496\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.620000000000008\n",
      "  episode_reward_mean: 4.911827956989252\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 100946\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.031036320436432\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015118604912822025\n",
      "          policy_loss: -0.0712703100912496\n",
      "          total_loss: 0.08804836163697831\n",
      "          vf_explained_var: 0.9353691935539246\n",
      "          vf_loss: 0.14518696136621154\n",
      "    num_agent_steps_sampled: 5137854\n",
      "    num_agent_steps_trained: 5137854\n",
      "    num_steps_sampled: 5137854\n",
      "    num_steps_trained: 5137854\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7724358974359\n",
      "    ram_util_percent: 53.04051282051283\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529691454616965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.28041063862249\n",
      "    mean_inference_ms: 19.39555892592492\n",
      "    mean_raw_obs_processing_ms: 3.370480754376384\n",
      "  time_since_restore: 95959.29887485504\n",
      "  time_this_iter_s: 546.2825100421906\n",
      "  time_total_s: 290776.66246032715\n",
      "  timers:\n",
      "    learn_throughput: 28.238\n",
      "    learn_time_ms: 353988.281\n",
      "    load_throughput: 87439.322\n",
      "    load_time_ms: 114.319\n",
      "    sample_throughput: 53.106\n",
      "    sample_time_ms: 188226.604\n",
      "    update_time_ms: 5.179\n",
      "  timestamp: 1637552098\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5137854\n",
      "  training_iteration: 574\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   574</td><td style=\"text-align: right;\">          290777</td><td style=\"text-align: right;\">5137854</td><td style=\"text-align: right;\"> 4.91183</td><td style=\"text-align: right;\">               13.62</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           53.6237</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5147850\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_03-44-03\n",
      "  done: false\n",
      "  episode_len_mean: 52.94708994708995\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.629999999999995\n",
      "  episode_reward_mean: 4.899365079365083\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 101135\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.05452205225167\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014539427165837303\n",
      "          policy_loss: -0.07083785438883379\n",
      "          total_loss: 0.09390032705759548\n",
      "          vf_explained_var: 0.939069926738739\n",
      "          vf_loss: 0.15216076821144894\n",
      "    num_agent_steps_sampled: 5147850\n",
      "    num_agent_steps_trained: 5147850\n",
      "    num_steps_sampled: 5147850\n",
      "    num_steps_trained: 5147850\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.0758354755784\n",
      "    ram_util_percent: 53.11105398457584\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05297374535021592\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.27702501005582\n",
      "    mean_inference_ms: 19.396157709415988\n",
      "    mean_raw_obs_processing_ms: 3.3690183914809735\n",
      "  time_since_restore: 96504.84281611443\n",
      "  time_this_iter_s: 545.5439412593842\n",
      "  time_total_s: 291322.20640158653\n",
      "  timers:\n",
      "    learn_throughput: 28.241\n",
      "    learn_time_ms: 353947.458\n",
      "    load_throughput: 87374.996\n",
      "    load_time_ms: 114.403\n",
      "    sample_throughput: 53.033\n",
      "    sample_time_ms: 188487.095\n",
      "    update_time_ms: 5.547\n",
      "  timestamp: 1637552643\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5147850\n",
      "  training_iteration: 575\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   575</td><td style=\"text-align: right;\">          291322</td><td style=\"text-align: right;\">5147850</td><td style=\"text-align: right;\"> 4.89937</td><td style=\"text-align: right;\">               19.63</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           52.9471</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5157846\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_03-52-54\n",
      "  done: false\n",
      "  episode_len_mean: 54.59782608695652\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000006\n",
      "  episode_reward_mean: 4.840760869565221\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 101319\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0552374958992004\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016021268128173095\n",
      "          policy_loss: -0.07081846196752195\n",
      "          total_loss: 0.09871720911989147\n",
      "          vf_explained_var: 0.9186561703681946\n",
      "          vf_loss: 0.15358959370560152\n",
      "    num_agent_steps_sampled: 5157846\n",
      "    num_agent_steps_trained: 5157846\n",
      "    num_steps_sampled: 5157846\n",
      "    num_steps_trained: 5157846\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.16446499339499\n",
      "    ram_util_percent: 52.79682959048877\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05298292883300703\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.272045836358316\n",
      "    mean_inference_ms: 19.39868439616499\n",
      "    mean_raw_obs_processing_ms: 3.3559975843388337\n",
      "  time_since_restore: 97035.28027248383\n",
      "  time_this_iter_s: 530.4374563694\n",
      "  time_total_s: 291852.64385795593\n",
      "  timers:\n",
      "    learn_throughput: 28.245\n",
      "    learn_time_ms: 353903.462\n",
      "    load_throughput: 87360.795\n",
      "    load_time_ms: 114.422\n",
      "    sample_throughput: 53.769\n",
      "    sample_time_ms: 185906.752\n",
      "    update_time_ms: 5.187\n",
      "  timestamp: 1637553174\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5157846\n",
      "  training_iteration: 576\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   576</td><td style=\"text-align: right;\">          291853</td><td style=\"text-align: right;\">5157846</td><td style=\"text-align: right;\"> 4.84076</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           54.5978</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5167842\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_04-02-10\n",
      "  done: false\n",
      "  episode_len_mean: 54.36612021857923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.620000000000006\n",
      "  episode_reward_mean: 4.934262295081973\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 101502\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0355897526185673\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015087932447286253\n",
      "          policy_loss: -0.06768720262343449\n",
      "          total_loss: 0.09107873939249558\n",
      "          vf_explained_var: 0.9216902852058411\n",
      "          vf_loss: 0.1447496422976031\n",
      "    num_agent_steps_sampled: 5167842\n",
      "    num_agent_steps_trained: 5167842\n",
      "    num_steps_sampled: 5167842\n",
      "    num_steps_trained: 5167842\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.33493064312738\n",
      "    ram_util_percent: 53.437578814628\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05297960496964931\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.26112901421196\n",
      "    mean_inference_ms: 19.39778471992212\n",
      "    mean_raw_obs_processing_ms: 3.37347869787462\n",
      "  time_since_restore: 97591.06434082985\n",
      "  time_this_iter_s: 555.7840683460236\n",
      "  time_total_s: 292408.42792630196\n",
      "  timers:\n",
      "    learn_throughput: 28.248\n",
      "    learn_time_ms: 353866.811\n",
      "    load_throughput: 87367.385\n",
      "    load_time_ms: 114.413\n",
      "    sample_throughput: 53.111\n",
      "    sample_time_ms: 188208.327\n",
      "    update_time_ms: 5.079\n",
      "  timestamp: 1637553730\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5167842\n",
      "  training_iteration: 577\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   577</td><td style=\"text-align: right;\">          292408</td><td style=\"text-align: right;\">5167842</td><td style=\"text-align: right;\"> 4.93426</td><td style=\"text-align: right;\">               13.62</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           54.3661</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5177838\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_04-11-04\n",
      "  done: false\n",
      "  episode_len_mean: 54.108108108108105\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000006\n",
      "  episode_reward_mean: 4.937135135135139\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 101687\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0349669583590635\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014660868908629032\n",
      "          policy_loss: -0.07467438972828723\n",
      "          total_loss: 0.06573892931711493\n",
      "          vf_explained_var: 0.9399524927139282\n",
      "          vf_loss: 0.12736369569320233\n",
      "    num_agent_steps_sampled: 5177838\n",
      "    num_agent_steps_trained: 5177838\n",
      "    num_steps_sampled: 5177838\n",
      "    num_steps_trained: 5177838\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13224115334206\n",
      "    ram_util_percent: 52.86343381389253\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052985828876115255\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.261377217999005\n",
      "    mean_inference_ms: 19.402291449016946\n",
      "    mean_raw_obs_processing_ms: 3.3612896477160032\n",
      "  time_since_restore: 98125.72209382057\n",
      "  time_this_iter_s: 534.6577529907227\n",
      "  time_total_s: 292943.0856792927\n",
      "  timers:\n",
      "    learn_throughput: 28.249\n",
      "    learn_time_ms: 353850.432\n",
      "    load_throughput: 87479.733\n",
      "    load_time_ms: 114.266\n",
      "    sample_throughput: 52.99\n",
      "    sample_time_ms: 188640.493\n",
      "    update_time_ms: 5.998\n",
      "  timestamp: 1637554264\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5177838\n",
      "  training_iteration: 578\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   578</td><td style=\"text-align: right;\">          292943</td><td style=\"text-align: right;\">5177838</td><td style=\"text-align: right;\"> 4.93714</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           54.1081</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5187834\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_04-20-24\n",
      "  done: false\n",
      "  episode_len_mean: 54.21739130434783\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.510000000000009\n",
      "  episode_reward_mean: 4.962826086956526\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 101871\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9894219139014861\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014791703714172428\n",
      "          policy_loss: -0.06914070126324778\n",
      "          total_loss: 0.0773416915173701\n",
      "          vf_explained_var: 0.9336490631103516\n",
      "          vf_loss: 0.1326792610867181\n",
      "    num_agent_steps_sampled: 5187834\n",
      "    num_agent_steps_trained: 5187834\n",
      "    num_steps_sampled: 5187834\n",
      "    num_steps_trained: 5187834\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.53721804511278\n",
      "    ram_util_percent: 53.32243107769425\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05298727855149039\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.25411676524232\n",
      "    mean_inference_ms: 19.401681577327892\n",
      "    mean_raw_obs_processing_ms: 3.367273430910135\n",
      "  time_since_restore: 98684.99469900131\n",
      "  time_this_iter_s: 559.2726051807404\n",
      "  time_total_s: 293502.3582844734\n",
      "  timers:\n",
      "    learn_throughput: 28.252\n",
      "    learn_time_ms: 353819.683\n",
      "    load_throughput: 86955.642\n",
      "    load_time_ms: 114.955\n",
      "    sample_throughput: 52.237\n",
      "    sample_time_ms: 191359.489\n",
      "    update_time_ms: 6.035\n",
      "  timestamp: 1637554824\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5187834\n",
      "  training_iteration: 579\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   579</td><td style=\"text-align: right;\">          293502</td><td style=\"text-align: right;\">5187834</td><td style=\"text-align: right;\"> 4.96283</td><td style=\"text-align: right;\">               15.51</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           54.2174</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5197830\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_04-29-32\n",
      "  done: false\n",
      "  episode_len_mean: 54.6448087431694\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.380000000000011\n",
      "  episode_reward_mean: 5.298469945355196\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 102054\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.992257473004391\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014963483862792752\n",
      "          policy_loss: -0.06826299364981522\n",
      "          total_loss: 0.08972792724023997\n",
      "          vf_explained_var: 0.9380208253860474\n",
      "          vf_loss: 0.1438248080308044\n",
      "    num_agent_steps_sampled: 5197830\n",
      "    num_agent_steps_trained: 5197830\n",
      "    num_steps_sampled: 5197830\n",
      "    num_steps_trained: 5197830\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.83239436619719\n",
      "    ram_util_percent: 53.15070422535211\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05299937223772294\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.24824936201236\n",
      "    mean_inference_ms: 19.401463912260297\n",
      "    mean_raw_obs_processing_ms: 3.3661753252451723\n",
      "  time_since_restore: 99232.82403635979\n",
      "  time_this_iter_s: 547.8293373584747\n",
      "  time_total_s: 294050.1876218319\n",
      "  timers:\n",
      "    learn_throughput: 28.246\n",
      "    learn_time_ms: 353888.479\n",
      "    load_throughput: 87124.124\n",
      "    load_time_ms: 114.733\n",
      "    sample_throughput: 52.522\n",
      "    sample_time_ms: 190319.172\n",
      "    update_time_ms: 5.826\n",
      "  timestamp: 1637555372\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5197830\n",
      "  training_iteration: 580\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   580</td><td style=\"text-align: right;\">          294050</td><td style=\"text-align: right;\">5197830</td><td style=\"text-align: right;\"> 5.29847</td><td style=\"text-align: right;\">               15.38</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           54.6448</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5207826\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_04-38-34\n",
      "  done: false\n",
      "  episode_len_mean: 54.23913043478261\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.609999999999978\n",
      "  episode_reward_mean: 5.173043478260873\n",
      "  episode_reward_min: -0.6000000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 102238\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0171693518219223\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015091464418776741\n",
      "          policy_loss: -0.06917197027974162\n",
      "          total_loss: 0.0832379320131465\n",
      "          vf_explained_var: 0.9304418563842773\n",
      "          vf_loss: 0.13820135136280792\n",
      "    num_agent_steps_sampled: 5207826\n",
      "    num_agent_steps_trained: 5207826\n",
      "    num_steps_sampled: 5207826\n",
      "    num_steps_trained: 5207826\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.84451612903226\n",
      "    ram_util_percent: 53.36941935483871\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05301089283214978\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.24183458602035\n",
      "    mean_inference_ms: 19.40344081233795\n",
      "    mean_raw_obs_processing_ms: 3.3639453218091644\n",
      "  time_since_restore: 99775.61556982994\n",
      "  time_this_iter_s: 542.7915334701538\n",
      "  time_total_s: 294592.97915530205\n",
      "  timers:\n",
      "    learn_throughput: 28.24\n",
      "    learn_time_ms: 353964.503\n",
      "    load_throughput: 87749.388\n",
      "    load_time_ms: 113.915\n",
      "    sample_throughput: 52.516\n",
      "    sample_time_ms: 190341.397\n",
      "    update_time_ms: 5.537\n",
      "  timestamp: 1637555914\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5207826\n",
      "  training_iteration: 581\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   581</td><td style=\"text-align: right;\">          294593</td><td style=\"text-align: right;\">5207826</td><td style=\"text-align: right;\"> 5.17304</td><td style=\"text-align: right;\">               19.61</td><td style=\"text-align: right;\">                -0.6</td><td style=\"text-align: right;\">           54.2391</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5217822\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_04-47-49\n",
      "  done: false\n",
      "  episode_len_mean: 54.30434782608695\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.57\n",
      "  episode_reward_mean: 5.103967391304352\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 102422\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0130098724460983\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01598371274687391\n",
      "          policy_loss: -0.06794231485255368\n",
      "          total_loss: 0.09071356053265121\n",
      "          vf_explained_var: 0.9107504487037659\n",
      "          vf_loss: 0.14237307634879742\n",
      "    num_agent_steps_sampled: 5217822\n",
      "    num_agent_steps_trained: 5217822\n",
      "    num_steps_sampled: 5217822\n",
      "    num_steps_trained: 5217822\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.54336283185842\n",
      "    ram_util_percent: 53.60050568900127\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053008672819116705\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.23105365811631\n",
      "    mean_inference_ms: 19.402500004012328\n",
      "    mean_raw_obs_processing_ms: 3.3701256892790736\n",
      "  time_since_restore: 100330.0808904171\n",
      "  time_this_iter_s: 554.4653205871582\n",
      "  time_total_s: 295147.4444758892\n",
      "  timers:\n",
      "    learn_throughput: 28.235\n",
      "    learn_time_ms: 354032.791\n",
      "    load_throughput: 87869.663\n",
      "    load_time_ms: 113.759\n",
      "    sample_throughput: 51.979\n",
      "    sample_time_ms: 192309.325\n",
      "    update_time_ms: 5.956\n",
      "  timestamp: 1637556469\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5217822\n",
      "  training_iteration: 582\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   582</td><td style=\"text-align: right;\">          295147</td><td style=\"text-align: right;\">5217822</td><td style=\"text-align: right;\"> 5.10397</td><td style=\"text-align: right;\">               17.57</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           54.3043</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5227818\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_04-56-51\n",
      "  done: false\n",
      "  episode_len_mean: 54.994535519125684\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.48000000000001\n",
      "  episode_reward_mean: 4.950601092896179\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 102605\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.020025741240107\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015142727471662893\n",
      "          policy_loss: -0.06204314450036372\n",
      "          total_loss: 0.09178655042589606\n",
      "          vf_explained_var: 0.9256460666656494\n",
      "          vf_loss: 0.13953292516563237\n",
      "    num_agent_steps_sampled: 5227818\n",
      "    num_agent_steps_trained: 5227818\n",
      "    num_steps_sampled: 5227818\n",
      "    num_steps_trained: 5227818\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.89870801033592\n",
      "    ram_util_percent: 53.645348837209305\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052998417385884546\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.220489310348775\n",
      "    mean_inference_ms: 19.403018347656\n",
      "    mean_raw_obs_processing_ms: 3.3653889698487913\n",
      "  time_since_restore: 100872.22472858429\n",
      "  time_this_iter_s: 542.1438381671906\n",
      "  time_total_s: 295689.5883140564\n",
      "  timers:\n",
      "    learn_throughput: 28.235\n",
      "    learn_time_ms: 354026.39\n",
      "    load_throughput: 87914.713\n",
      "    load_time_ms: 113.701\n",
      "    sample_throughput: 52.127\n",
      "    sample_time_ms: 191761.125\n",
      "    update_time_ms: 6.068\n",
      "  timestamp: 1637557011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5227818\n",
      "  training_iteration: 583\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   583</td><td style=\"text-align: right;\">          295690</td><td style=\"text-align: right;\">5227818</td><td style=\"text-align: right;\">  4.9506</td><td style=\"text-align: right;\">               15.48</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           54.9945</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5237814\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_05-05-41\n",
      "  done: false\n",
      "  episode_len_mean: 55.05524861878453\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.580000000000005\n",
      "  episode_reward_mean: 5.129447513812159\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 102786\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0169459957195572\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013907509891443723\n",
      "          policy_loss: -0.06740926096173357\n",
      "          total_loss: 0.0807089736341923\n",
      "          vf_explained_var: 0.9309860467910767\n",
      "          vf_loss: 0.13660464763611435\n",
      "    num_agent_steps_sampled: 5237814\n",
      "    num_agent_steps_trained: 5237814\n",
      "    num_steps_sampled: 5237814\n",
      "    num_steps_trained: 5237814\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.09166666666667\n",
      "    ram_util_percent: 53.47261904761905\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05300491883366517\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.21425612332582\n",
      "    mean_inference_ms: 19.40503876165826\n",
      "    mean_raw_obs_processing_ms: 3.3530806223206913\n",
      "  time_since_restore: 101402.22457742691\n",
      "  time_this_iter_s: 529.9998488426208\n",
      "  time_total_s: 296219.588162899\n",
      "  timers:\n",
      "    learn_throughput: 28.232\n",
      "    learn_time_ms: 354062.215\n",
      "    load_throughput: 87876.422\n",
      "    load_time_ms: 113.751\n",
      "    sample_throughput: 52.584\n",
      "    sample_time_ms: 190095.838\n",
      "    update_time_ms: 6.846\n",
      "  timestamp: 1637557541\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5237814\n",
      "  training_iteration: 584\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   584</td><td style=\"text-align: right;\">          296220</td><td style=\"text-align: right;\">5237814</td><td style=\"text-align: right;\"> 5.12945</td><td style=\"text-align: right;\">               17.58</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           55.0552</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5247810\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_05-14-47\n",
      "  done: false\n",
      "  episode_len_mean: 54.06521739130435\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000007\n",
      "  episode_reward_mean: 4.976630434782613\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 102970\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0228277045320793\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015090095830614264\n",
      "          policy_loss: -0.06884952533332415\n",
      "          total_loss: 0.08415646700500712\n",
      "          vf_explained_var: 0.9311182498931885\n",
      "          vf_loss: 0.13885714333021945\n",
      "    num_agent_steps_sampled: 5247810\n",
      "    num_agent_steps_trained: 5247810\n",
      "    num_steps_sampled: 5247810\n",
      "    num_steps_trained: 5247810\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98354755784064\n",
      "    ram_util_percent: 53.726349614395886\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053003994719887995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.205965829101686\n",
      "    mean_inference_ms: 19.40476493434922\n",
      "    mean_raw_obs_processing_ms: 3.3509805272411546\n",
      "  time_since_restore: 101947.78979635239\n",
      "  time_this_iter_s: 545.5652189254761\n",
      "  time_total_s: 296765.1533818245\n",
      "  timers:\n",
      "    learn_throughput: 28.226\n",
      "    learn_time_ms: 354142.732\n",
      "    load_throughput: 87868.098\n",
      "    load_time_ms: 113.761\n",
      "    sample_throughput: 52.606\n",
      "    sample_time_ms: 190017.86\n",
      "    update_time_ms: 6.462\n",
      "  timestamp: 1637558087\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5247810\n",
      "  training_iteration: 585\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   585</td><td style=\"text-align: right;\">          296765</td><td style=\"text-align: right;\">5247810</td><td style=\"text-align: right;\"> 4.97663</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           54.0652</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5257806\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_05-23-54\n",
      "  done: false\n",
      "  episode_len_mean: 53.89784946236559\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.640000000000006\n",
      "  episode_reward_mean: 4.776075268817208\n",
      "  episode_reward_min: -0.4800000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 103156\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.02444282198048\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014295705399304023\n",
      "          policy_loss: -0.06969966141132683\n",
      "          total_loss: 0.07769130162037857\n",
      "          vf_explained_var: 0.9313750863075256\n",
      "          vf_loss: 0.13506798639465273\n",
      "    num_agent_steps_sampled: 5257806\n",
      "    num_agent_steps_trained: 5257806\n",
      "    num_steps_sampled: 5257806\n",
      "    num_steps_trained: 5257806\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.66376440460947\n",
      "    ram_util_percent: 53.560691421254795\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05299711280450072\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.1999171534917\n",
      "    mean_inference_ms: 19.406975006560252\n",
      "    mean_raw_obs_processing_ms: 3.358736482931879\n",
      "  time_since_restore: 102495.24911522865\n",
      "  time_this_iter_s: 547.4593188762665\n",
      "  time_total_s: 297312.61270070076\n",
      "  timers:\n",
      "    learn_throughput: 28.216\n",
      "    learn_time_ms: 354260.831\n",
      "    load_throughput: 87854.27\n",
      "    load_time_ms: 113.779\n",
      "    sample_throughput: 52.171\n",
      "    sample_time_ms: 191601.571\n",
      "    update_time_ms: 6.795\n",
      "  timestamp: 1637558634\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5257806\n",
      "  training_iteration: 586\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   586</td><td style=\"text-align: right;\">          297313</td><td style=\"text-align: right;\">5257806</td><td style=\"text-align: right;\"> 4.77608</td><td style=\"text-align: right;\">               13.64</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           53.8978</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5267802\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_05-33-18\n",
      "  done: false\n",
      "  episode_len_mean: 54.54891304347826\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 4.8679347826087\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 103340\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0418123153558216\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014668560257670679\n",
      "          policy_loss: -0.06856866017217225\n",
      "          total_loss: 0.07405099500772942\n",
      "          vf_explained_var: 0.9061076045036316\n",
      "          vf_loss: 0.12962096301753664\n",
      "    num_agent_steps_sampled: 5267802\n",
      "    num_agent_steps_trained: 5267802\n",
      "    num_steps_sampled: 5267802\n",
      "    num_steps_trained: 5267802\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.93652173913043\n",
      "    ram_util_percent: 53.79639751552794\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053000663642353896\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.19366685452352\n",
      "    mean_inference_ms: 19.40802089667173\n",
      "    mean_raw_obs_processing_ms: 3.367153548008594\n",
      "  time_since_restore: 103059.24776673317\n",
      "  time_this_iter_s: 563.9986515045166\n",
      "  time_total_s: 297876.6113522053\n",
      "  timers:\n",
      "    learn_throughput: 28.205\n",
      "    learn_time_ms: 354408.543\n",
      "    load_throughput: 87932.469\n",
      "    load_time_ms: 113.678\n",
      "    sample_throughput: 51.988\n",
      "    sample_time_ms: 192275.423\n",
      "    update_time_ms: 6.911\n",
      "  timestamp: 1637559198\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5267802\n",
      "  training_iteration: 587\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   587</td><td style=\"text-align: right;\">          297877</td><td style=\"text-align: right;\">5267802</td><td style=\"text-align: right;\"> 4.86793</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           54.5489</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5277798\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_05-42-12\n",
      "  done: false\n",
      "  episode_len_mean: 53.832432432432434\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.560000000000008\n",
      "  episode_reward_mean: 4.557405405405409\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 103525\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0503235189072098\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0143497980993122\n",
      "          policy_loss: -0.06972740607241605\n",
      "          total_loss: 0.06830431349634414\n",
      "          vf_explained_var: 0.933291494846344\n",
      "          vf_loss: 0.1258443191947685\n",
      "    num_agent_steps_sampled: 5277798\n",
      "    num_agent_steps_trained: 5277798\n",
      "    num_steps_sampled: 5277798\n",
      "    num_steps_trained: 5277798\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1503937007874\n",
      "    ram_util_percent: 53.4501312335958\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052999237452044726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.191482603284435\n",
      "    mean_inference_ms: 19.41040729874485\n",
      "    mean_raw_obs_processing_ms: 3.3562641369224218\n",
      "  time_since_restore: 103593.38434910774\n",
      "  time_this_iter_s: 534.1365823745728\n",
      "  time_total_s: 298410.74793457985\n",
      "  timers:\n",
      "    learn_throughput: 28.191\n",
      "    learn_time_ms: 354576.163\n",
      "    load_throughput: 87998.043\n",
      "    load_time_ms: 113.593\n",
      "    sample_throughput: 52.047\n",
      "    sample_time_ms: 192057.449\n",
      "    update_time_ms: 5.796\n",
      "  timestamp: 1637559732\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5277798\n",
      "  training_iteration: 588\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   588</td><td style=\"text-align: right;\">          298411</td><td style=\"text-align: right;\">5277798</td><td style=\"text-align: right;\"> 4.55741</td><td style=\"text-align: right;\">               13.56</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.8324</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5287794\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_05-51-18\n",
      "  done: false\n",
      "  episode_len_mean: 53.28191489361702\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.143936170212769\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 103713\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.040839179955333\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01524181755181653\n",
      "          policy_loss: -0.07164869092300152\n",
      "          total_loss: 0.09133976829441262\n",
      "          vf_explained_var: 0.9400190711021423\n",
      "          vf_loss: 0.14867408441269328\n",
      "    num_agent_steps_sampled: 5287794\n",
      "    num_agent_steps_trained: 5287794\n",
      "    num_steps_sampled: 5287794\n",
      "    num_steps_trained: 5287794\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.90437017994857\n",
      "    ram_util_percent: 53.802827763496154\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529985557603014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.1864252336511\n",
      "    mean_inference_ms: 19.409725308119707\n",
      "    mean_raw_obs_processing_ms: 3.3527185962197845\n",
      "  time_since_restore: 104138.95848083496\n",
      "  time_this_iter_s: 545.5741317272186\n",
      "  time_total_s: 298956.32206630707\n",
      "  timers:\n",
      "    learn_throughput: 28.179\n",
      "    learn_time_ms: 354727.961\n",
      "    load_throughput: 88824.062\n",
      "    load_time_ms: 112.537\n",
      "    sample_throughput: 52.462\n",
      "    sample_time_ms: 190536.528\n",
      "    update_time_ms: 6.093\n",
      "  timestamp: 1637560278\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5287794\n",
      "  training_iteration: 589\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   589</td><td style=\"text-align: right;\">          298956</td><td style=\"text-align: right;\">5287794</td><td style=\"text-align: right;\"> 5.14394</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           53.2819</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5297790\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_06-00-24\n",
      "  done: false\n",
      "  episode_len_mean: 53.5668449197861\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.490000000000009\n",
      "  episode_reward_mean: 4.967005347593587\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 103900\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.021815138935564\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01514392630657703\n",
      "          policy_loss: -0.06934854431962546\n",
      "          total_loss: 0.09464364114813008\n",
      "          vf_explained_var: 0.9211416244506836\n",
      "          vf_loss: 0.14971057955684314\n",
      "    num_agent_steps_sampled: 5297790\n",
      "    num_agent_steps_trained: 5297790\n",
      "    num_steps_sampled: 5297790\n",
      "    num_steps_trained: 5297790\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.78331193838254\n",
      "    ram_util_percent: 54.1612323491656\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302146345749837\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.180507460174304\n",
      "    mean_inference_ms: 19.411084752494244\n",
      "    mean_raw_obs_processing_ms: 3.352523892161515\n",
      "  time_since_restore: 104684.8487546444\n",
      "  time_this_iter_s: 545.890273809433\n",
      "  time_total_s: 299502.2123401165\n",
      "  timers:\n",
      "    learn_throughput: 28.173\n",
      "    learn_time_ms: 354810.987\n",
      "    load_throughput: 88521.653\n",
      "    load_time_ms: 112.922\n",
      "    sample_throughput: 52.539\n",
      "    sample_time_ms: 190259.341\n",
      "    update_time_ms: 6.08\n",
      "  timestamp: 1637560824\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5297790\n",
      "  training_iteration: 590\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   590</td><td style=\"text-align: right;\">          299502</td><td style=\"text-align: right;\">5297790</td><td style=\"text-align: right;\"> 4.96701</td><td style=\"text-align: right;\">               15.49</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.5668</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5307786\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_06-09-32\n",
      "  done: false\n",
      "  episode_len_mean: 53.91891891891892\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.620000000000006\n",
      "  episode_reward_mean: 5.057621621621625\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 104085\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.044122482423323\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014586175502068366\n",
      "          policy_loss: -0.07415641232097282\n",
      "          total_loss: 0.0784289931628574\n",
      "          vf_explained_var: 0.9350923299789429\n",
      "          vf_loss: 0.13979749819366674\n",
      "    num_agent_steps_sampled: 5307786\n",
      "    num_agent_steps_trained: 5307786\n",
      "    num_steps_sampled: 5307786\n",
      "    num_steps_trained: 5307786\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91445012787725\n",
      "    ram_util_percent: 54.37250639386189\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302281888933723\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.17616418838401\n",
      "    mean_inference_ms: 19.412216139178305\n",
      "    mean_raw_obs_processing_ms: 3.3491265021452423\n",
      "  time_since_restore: 105233.0064060688\n",
      "  time_this_iter_s: 548.157651424408\n",
      "  time_total_s: 300050.3699915409\n",
      "  timers:\n",
      "    learn_throughput: 28.163\n",
      "    learn_time_ms: 354937.398\n",
      "    load_throughput: 88761.836\n",
      "    load_time_ms: 112.616\n",
      "    sample_throughput: 52.426\n",
      "    sample_time_ms: 190670.133\n",
      "    update_time_ms: 6.009\n",
      "  timestamp: 1637561372\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5307786\n",
      "  training_iteration: 591\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   591</td><td style=\"text-align: right;\">          300050</td><td style=\"text-align: right;\">5307786</td><td style=\"text-align: right;\"> 5.05762</td><td style=\"text-align: right;\">               13.62</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           53.9189</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5317782\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_06-18-53\n",
      "  done: false\n",
      "  episode_len_mean: 52.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.520000000000008\n",
      "  episode_reward_mean: 5.065894736842108\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 104275\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0347272628282447\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01434544953279092\n",
      "          policy_loss: -0.06371547416226922\n",
      "          total_loss: 0.0864937984913379\n",
      "          vf_explained_var: 0.935451090335846\n",
      "          vf_loss: 0.13787581703848165\n",
      "    num_agent_steps_sampled: 5317782\n",
      "    num_agent_steps_trained: 5317782\n",
      "    num_steps_sampled: 5317782\n",
      "    num_steps_trained: 5317782\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.68314606741575\n",
      "    ram_util_percent: 54.55555555555556\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05301274852573417\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.16959547625089\n",
      "    mean_inference_ms: 19.41107806640084\n",
      "    mean_raw_obs_processing_ms: 3.355541750486593\n",
      "  time_since_restore: 105793.77646493912\n",
      "  time_this_iter_s: 560.7700588703156\n",
      "  time_total_s: 300611.1400504112\n",
      "  timers:\n",
      "    learn_throughput: 28.158\n",
      "    learn_time_ms: 354998.426\n",
      "    load_throughput: 88433.393\n",
      "    load_time_ms: 113.034\n",
      "    sample_throughput: 52.269\n",
      "    sample_time_ms: 191239.716\n",
      "    update_time_ms: 5.722\n",
      "  timestamp: 1637561933\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5317782\n",
      "  training_iteration: 592\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   592</td><td style=\"text-align: right;\">          300611</td><td style=\"text-align: right;\">5317782</td><td style=\"text-align: right;\"> 5.06589</td><td style=\"text-align: right;\">               15.52</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">              52.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5327778\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_06-27-47\n",
      "  done: false\n",
      "  episode_len_mean: 54.47826086956522\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.51\n",
      "  episode_reward_mean: 5.551467391304351\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 104459\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.028561302923773\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014368954906630864\n",
      "          policy_loss: -0.06496892735672026\n",
      "          total_loss: 0.10605645021905839\n",
      "          vf_explained_var: 0.9363157749176025\n",
      "          vf_loss: 0.15857671475193152\n",
      "    num_agent_steps_sampled: 5327778\n",
      "    num_agent_steps_trained: 5327778\n",
      "    num_steps_sampled: 5327778\n",
      "    num_steps_trained: 5327778\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.07030223390277\n",
      "    ram_util_percent: 53.92352168199736\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302839194489523\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.165604044380586\n",
      "    mean_inference_ms: 19.413222566210397\n",
      "    mean_raw_obs_processing_ms: 3.3460274887355594\n",
      "  time_since_restore: 106327.77944397926\n",
      "  time_this_iter_s: 534.0029790401459\n",
      "  time_total_s: 301145.14302945137\n",
      "  timers:\n",
      "    learn_throughput: 28.149\n",
      "    learn_time_ms: 355115.075\n",
      "    load_throughput: 87779.408\n",
      "    load_time_ms: 113.876\n",
      "    sample_throughput: 52.525\n",
      "    sample_time_ms: 190308.321\n",
      "    update_time_ms: 5.75\n",
      "  timestamp: 1637562467\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5327778\n",
      "  training_iteration: 593\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   593</td><td style=\"text-align: right;\">          301145</td><td style=\"text-align: right;\">5327778</td><td style=\"text-align: right;\"> 5.55147</td><td style=\"text-align: right;\">               17.51</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           54.4783</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5337774\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_06-36-55\n",
      "  done: false\n",
      "  episode_len_mean: 53.74193548387097\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.03139784946237\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 104645\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0335970935572583\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014370178610965555\n",
      "          policy_loss: -0.07193431004456367\n",
      "          total_loss: 0.0746522419613526\n",
      "          vf_explained_var: 0.9310120344161987\n",
      "          vf_loss: 0.1341854585686242\n",
      "    num_agent_steps_sampled: 5337774\n",
      "    num_agent_steps_trained: 5337774\n",
      "    num_steps_sampled: 5337774\n",
      "    num_steps_trained: 5337774\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.72567049808428\n",
      "    ram_util_percent: 53.64955300127715\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303023051402711\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.16168028350624\n",
      "    mean_inference_ms: 19.414789233533778\n",
      "    mean_raw_obs_processing_ms: 3.3441301138863255\n",
      "  time_since_restore: 106876.28565239906\n",
      "  time_this_iter_s: 548.5062084197998\n",
      "  time_total_s: 301693.64923787117\n",
      "  timers:\n",
      "    learn_throughput: 28.138\n",
      "    learn_time_ms: 355249.612\n",
      "    load_throughput: 87655.293\n",
      "    load_time_ms: 114.038\n",
      "    sample_throughput: 52.056\n",
      "    sample_time_ms: 192024.971\n",
      "    update_time_ms: 5.243\n",
      "  timestamp: 1637563015\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5337774\n",
      "  training_iteration: 594\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   594</td><td style=\"text-align: right;\">          301694</td><td style=\"text-align: right;\">5337774</td><td style=\"text-align: right;\">  5.0314</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           53.7419</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5347770\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_06-46-03\n",
      "  done: false\n",
      "  episode_len_mean: 53.8054054054054\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.700000000000005\n",
      "  episode_reward_mean: 5.308000000000004\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 104830\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.027216574130767\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014586730961613954\n",
      "          policy_loss: -0.07253381861792113\n",
      "          total_loss: 0.08879385555710066\n",
      "          vf_explained_var: 0.9334452152252197\n",
      "          vf_loss: 0.1483694433114944\n",
      "    num_agent_steps_sampled: 5347770\n",
      "    num_agent_steps_trained: 5347770\n",
      "    num_steps_sampled: 5347770\n",
      "    num_steps_trained: 5347770\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91381074168798\n",
      "    ram_util_percent: 53.451918158567764\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053035027766811516\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.157342619916605\n",
      "    mean_inference_ms: 19.415333867223683\n",
      "    mean_raw_obs_processing_ms: 3.3427083690260724\n",
      "  time_since_restore: 107424.31134915352\n",
      "  time_this_iter_s: 548.0256967544556\n",
      "  time_total_s: 302241.6749346256\n",
      "  timers:\n",
      "    learn_throughput: 28.131\n",
      "    learn_time_ms: 355338.82\n",
      "    load_throughput: 87607.707\n",
      "    load_time_ms: 114.1\n",
      "    sample_throughput: 52.014\n",
      "    sample_time_ms: 192180.521\n",
      "    update_time_ms: 6.051\n",
      "  timestamp: 1637563563\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5347770\n",
      "  training_iteration: 595\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   595</td><td style=\"text-align: right;\">          302242</td><td style=\"text-align: right;\">5347770</td><td style=\"text-align: right;\">   5.308</td><td style=\"text-align: right;\">                15.7</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           53.8054</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5357766\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_06-55-10\n",
      "  done: false\n",
      "  episode_len_mean: 54.59239130434783\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.450000000000003\n",
      "  episode_reward_mean: 5.1589130434782655\n",
      "  episode_reward_min: -0.5000000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 105014\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0336307535927935\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014489056759182953\n",
      "          policy_loss: -0.06913475691791506\n",
      "          total_loss: 0.09116237792259199\n",
      "          vf_explained_var: 0.9308554530143738\n",
      "          vf_loss: 0.1476255585660178\n",
      "    num_agent_steps_sampled: 5357766\n",
      "    num_agent_steps_trained: 5357766\n",
      "    num_steps_sampled: 5357766\n",
      "    num_steps_trained: 5357766\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.83029525032092\n",
      "    ram_util_percent: 53.25442875481385\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302263295920034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.15058588341167\n",
      "    mean_inference_ms: 19.41554133974711\n",
      "    mean_raw_obs_processing_ms: 3.339588026488165\n",
      "  time_since_restore: 107970.3088107109\n",
      "  time_this_iter_s: 545.9974615573883\n",
      "  time_total_s: 302787.672396183\n",
      "  timers:\n",
      "    learn_throughput: 28.122\n",
      "    learn_time_ms: 355457.534\n",
      "    load_throughput: 87655.732\n",
      "    load_time_ms: 114.037\n",
      "    sample_throughput: 52.085\n",
      "    sample_time_ms: 191916.065\n",
      "    update_time_ms: 5.679\n",
      "  timestamp: 1637564110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5357766\n",
      "  training_iteration: 596\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   596</td><td style=\"text-align: right;\">          302788</td><td style=\"text-align: right;\">5357766</td><td style=\"text-align: right;\"> 5.15891</td><td style=\"text-align: right;\">               17.45</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           54.5924</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5367762\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_07-04-05\n",
      "  done: false\n",
      "  episode_len_mean: 53.774193548387096\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000004\n",
      "  episode_reward_mean: 4.998548387096778\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 105200\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0547234140246746\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013988305310868901\n",
      "          policy_loss: -0.07086513997503836\n",
      "          total_loss: 0.08240081311546181\n",
      "          vf_explained_var: 0.922469973564148\n",
      "          vf_loss: 0.14194607744470283\n",
      "    num_agent_steps_sampled: 5367762\n",
      "    num_agent_steps_trained: 5367762\n",
      "    num_steps_sampled: 5367762\n",
      "    num_steps_trained: 5367762\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.15497382198951\n",
      "    ram_util_percent: 53.20719895287959\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0530383527997785\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.14989933461942\n",
      "    mean_inference_ms: 19.417709479764714\n",
      "    mean_raw_obs_processing_ms: 3.329712549185725\n",
      "  time_since_restore: 108505.9570953846\n",
      "  time_this_iter_s: 535.6482846736908\n",
      "  time_total_s: 303323.3206808567\n",
      "  timers:\n",
      "    learn_throughput: 28.113\n",
      "    learn_time_ms: 355565.058\n",
      "    load_throughput: 87443.607\n",
      "    load_time_ms: 114.314\n",
      "    sample_throughput: 52.896\n",
      "    sample_time_ms: 188973.493\n",
      "    update_time_ms: 5.596\n",
      "  timestamp: 1637564645\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5367762\n",
      "  training_iteration: 597\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   597</td><td style=\"text-align: right;\">          303323</td><td style=\"text-align: right;\">5367762</td><td style=\"text-align: right;\"> 4.99855</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           53.7742</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5377758\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_07-13-24\n",
      "  done: false\n",
      "  episode_len_mean: 53.497297297297294\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.780000000000003\n",
      "  episode_reward_mean: 5.107837837837842\n",
      "  episode_reward_min: -0.4800000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 105385\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0137795587859477\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014717228703581412\n",
      "          policy_loss: -0.0711899080436586\n",
      "          total_loss: 0.08574147690636724\n",
      "          vf_explained_var: 0.9370403289794922\n",
      "          vf_loss: 0.14354149217822076\n",
      "    num_agent_steps_sampled: 5377758\n",
      "    num_agent_steps_trained: 5377758\n",
      "    num_steps_sampled: 5377758\n",
      "    num_steps_trained: 5377758\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.63312421580929\n",
      "    ram_util_percent: 53.94968632371393\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302106537364234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.142345445854346\n",
      "    mean_inference_ms: 19.417430045082035\n",
      "    mean_raw_obs_processing_ms: 3.3358591014200094\n",
      "  time_since_restore: 109064.69139695168\n",
      "  time_this_iter_s: 558.7343015670776\n",
      "  time_total_s: 303882.0549824238\n",
      "  timers:\n",
      "    learn_throughput: 28.109\n",
      "    learn_time_ms: 355616.394\n",
      "    load_throughput: 87618.18\n",
      "    load_time_ms: 114.086\n",
      "    sample_throughput: 52.231\n",
      "    sample_time_ms: 191381.602\n",
      "    update_time_ms: 5.727\n",
      "  timestamp: 1637565204\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5377758\n",
      "  training_iteration: 598\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   598</td><td style=\"text-align: right;\">          303882</td><td style=\"text-align: right;\">5377758</td><td style=\"text-align: right;\"> 5.10784</td><td style=\"text-align: right;\">               13.78</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           53.4973</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5387754\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_07-22-30\n",
      "  done: false\n",
      "  episode_len_mean: 54.0427807486631\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.69\n",
      "  episode_reward_mean: 5.022673796791449\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 105572\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0217127136078226\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015802472553141576\n",
      "          policy_loss: -0.06865143571313295\n",
      "          total_loss: 0.09961518337414824\n",
      "          vf_explained_var: 0.9245328903198242\n",
      "          vf_loss: 0.1524837364749347\n",
      "    num_agent_steps_sampled: 5387754\n",
      "    num_agent_steps_trained: 5387754\n",
      "    num_steps_sampled: 5387754\n",
      "    num_steps_trained: 5387754\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.85340179717588\n",
      "    ram_util_percent: 53.78703465982028\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303419257937798\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.13661834857302\n",
      "    mean_inference_ms: 19.418169711337793\n",
      "    mean_raw_obs_processing_ms: 3.3359142081048327\n",
      "  time_since_restore: 109610.656239748\n",
      "  time_this_iter_s: 545.9648427963257\n",
      "  time_total_s: 304428.0198252201\n",
      "  timers:\n",
      "    learn_throughput: 28.102\n",
      "    learn_time_ms: 355698.992\n",
      "    load_throughput: 87269.529\n",
      "    load_time_ms: 114.542\n",
      "    sample_throughput: 52.243\n",
      "    sample_time_ms: 191338.133\n",
      "    update_time_ms: 5.533\n",
      "  timestamp: 1637565750\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5387754\n",
      "  training_iteration: 599\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   599</td><td style=\"text-align: right;\">          304428</td><td style=\"text-align: right;\">5387754</td><td style=\"text-align: right;\"> 5.02267</td><td style=\"text-align: right;\">               17.69</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           54.0428</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5397750\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_07-31-41\n",
      "  done: false\n",
      "  episode_len_mean: 53.94054054054054\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.459999999999972\n",
      "  episode_reward_mean: 5.101459459459463\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 105757\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0184590334873125\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014718694430950962\n",
      "          policy_loss: -0.06770254790990804\n",
      "          total_loss: 0.09257638839012818\n",
      "          vf_explained_var: 0.9243140816688538\n",
      "          vf_loss: 0.14693250015488335\n",
      "    num_agent_steps_sampled: 5397750\n",
      "    num_agent_steps_trained: 5397750\n",
      "    num_steps_sampled: 5397750\n",
      "    num_steps_trained: 5397750\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.43066157760816\n",
      "    ram_util_percent: 53.14541984732825\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302906515073802\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.132978971904656\n",
      "    mean_inference_ms: 19.419770269094546\n",
      "    mean_raw_obs_processing_ms: 3.331777880944322\n",
      "  time_since_restore: 110161.48749303818\n",
      "  time_this_iter_s: 550.8312532901764\n",
      "  time_total_s: 304978.8510785103\n",
      "  timers:\n",
      "    learn_throughput: 28.101\n",
      "    learn_time_ms: 355719.676\n",
      "    load_throughput: 87368.915\n",
      "    load_time_ms: 114.411\n",
      "    sample_throughput: 52.114\n",
      "    sample_time_ms: 191811.218\n",
      "    update_time_ms: 5.535\n",
      "  timestamp: 1637566301\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5397750\n",
      "  training_iteration: 600\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   600</td><td style=\"text-align: right;\">          304979</td><td style=\"text-align: right;\">5397750</td><td style=\"text-align: right;\"> 5.10146</td><td style=\"text-align: right;\">               17.46</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.9405</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5407746\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_07-40-38\n",
      "  done: false\n",
      "  episode_len_mean: 54.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000008\n",
      "  episode_reward_mean: 5.122307692307697\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 105939\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.027273152846409\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014406627430335205\n",
      "          policy_loss: -0.06860850171291984\n",
      "          total_loss: 0.07342707194408163\n",
      "          vf_explained_var: 0.9370869994163513\n",
      "          vf_loss: 0.12948820572093983\n",
      "    num_agent_steps_sampled: 5407746\n",
      "    num_agent_steps_trained: 5407746\n",
      "    num_steps_sampled: 5407746\n",
      "    num_steps_trained: 5407746\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.16932114882505\n",
      "    ram_util_percent: 53.13616187989557\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303756682593605\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.1327257625487\n",
      "    mean_inference_ms: 19.421828220461904\n",
      "    mean_raw_obs_processing_ms: 3.3223737619850997\n",
      "  time_since_restore: 110698.39259243011\n",
      "  time_this_iter_s: 536.9050993919373\n",
      "  time_total_s: 305515.7561779022\n",
      "  timers:\n",
      "    learn_throughput: 28.1\n",
      "    learn_time_ms: 355725.585\n",
      "    load_throughput: 87879.664\n",
      "    load_time_ms: 113.746\n",
      "    sample_throughput: 52.423\n",
      "    sample_time_ms: 190680.951\n",
      "    update_time_ms: 5.367\n",
      "  timestamp: 1637566838\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5407746\n",
      "  training_iteration: 601\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   601</td><td style=\"text-align: right;\">          305516</td><td style=\"text-align: right;\">5407746</td><td style=\"text-align: right;\"> 5.12231</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">              54.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5417742\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_07-49-57\n",
      "  done: false\n",
      "  episode_len_mean: 54.145161290322584\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.49999999999999\n",
      "  episode_reward_mean: 4.961612903225811\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 106125\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0205848572723357\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01534557207916642\n",
      "          policy_loss: -0.07141521869623348\n",
      "          total_loss: 0.08996324663333337\n",
      "          vf_explained_var: 0.9304758906364441\n",
      "          vf_loss: 0.14662518190747373\n",
      "    num_agent_steps_sampled: 5417742\n",
      "    num_agent_steps_trained: 5417742\n",
      "    num_steps_sampled: 5417742\n",
      "    num_steps_trained: 5417742\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.66353383458646\n",
      "    ram_util_percent: 53.28032581453634\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053046702655953\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.12548587217519\n",
      "    mean_inference_ms: 19.42175897098934\n",
      "    mean_raw_obs_processing_ms: 3.3279595222101896\n",
      "  time_since_restore: 111257.68623042107\n",
      "  time_this_iter_s: 559.2936379909515\n",
      "  time_total_s: 306075.0498158932\n",
      "  timers:\n",
      "    learn_throughput: 28.097\n",
      "    learn_time_ms: 355765.233\n",
      "    load_throughput: 88037.031\n",
      "    load_time_ms: 113.543\n",
      "    sample_throughput: 52.474\n",
      "    sample_time_ms: 190493.843\n",
      "    update_time_ms: 5.639\n",
      "  timestamp: 1637567397\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5417742\n",
      "  training_iteration: 602\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   602</td><td style=\"text-align: right;\">          306075</td><td style=\"text-align: right;\">5417742</td><td style=\"text-align: right;\"> 4.96161</td><td style=\"text-align: right;\">                15.5</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           54.1452</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5427738\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_07-59-10\n",
      "  done: false\n",
      "  episode_len_mean: 53.22872340425532\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.660000000000005\n",
      "  episode_reward_mean: 4.669308510638301\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 106313\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.064345845161193\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014183818601034327\n",
      "          policy_loss: -0.07720824501243971\n",
      "          total_loss: 0.0630577605684204\n",
      "          vf_explained_var: 0.9288301467895508\n",
      "          vf_loss: 0.12859695142108843\n",
      "    num_agent_steps_sampled: 5427738\n",
      "    num_agent_steps_trained: 5427738\n",
      "    num_steps_sampled: 5427738\n",
      "    num_steps_trained: 5427738\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.73105196451205\n",
      "    ram_util_percent: 53.30329531051964\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0530554768982416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.12601484829668\n",
      "    mean_inference_ms: 19.422254855947237\n",
      "    mean_raw_obs_processing_ms: 3.3270078820851037\n",
      "  time_since_restore: 111810.46963477135\n",
      "  time_this_iter_s: 552.7834043502808\n",
      "  time_total_s: 306627.83322024345\n",
      "  timers:\n",
      "    learn_throughput: 28.095\n",
      "    learn_time_ms: 355794.696\n",
      "    load_throughput: 88682.643\n",
      "    load_time_ms: 112.717\n",
      "    sample_throughput: 51.97\n",
      "    sample_time_ms: 192343.31\n",
      "    update_time_ms: 5.878\n",
      "  timestamp: 1637567950\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5427738\n",
      "  training_iteration: 603\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   603</td><td style=\"text-align: right;\">          306628</td><td style=\"text-align: right;\">5427738</td><td style=\"text-align: right;\"> 4.66931</td><td style=\"text-align: right;\">               13.66</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.2287</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5437734\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_08-08-18\n",
      "  done: false\n",
      "  episode_len_mean: 54.08152173913044\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.650000000000002\n",
      "  episode_reward_mean: 4.79184782608696\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 106497\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.046438721384868\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01483815099199509\n",
      "          policy_loss: -0.06868987886733799\n",
      "          total_loss: 0.08707047881250683\n",
      "          vf_explained_var: 0.9157671928405762\n",
      "          vf_loss: 0.14242158115310333\n",
      "    num_agent_steps_sampled: 5437734\n",
      "    num_agent_steps_trained: 5437734\n",
      "    num_steps_sampled: 5437734\n",
      "    num_steps_trained: 5437734\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.97221510883483\n",
      "    ram_util_percent: 53.81882202304738\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05306385709698801\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.12234291078431\n",
      "    mean_inference_ms: 19.423753809230337\n",
      "    mean_raw_obs_processing_ms: 3.3253272087501053\n",
      "  time_since_restore: 112358.25110292435\n",
      "  time_this_iter_s: 547.7814681529999\n",
      "  time_total_s: 307175.61468839645\n",
      "  timers:\n",
      "    learn_throughput: 28.092\n",
      "    learn_time_ms: 355829.642\n",
      "    load_throughput: 88902.056\n",
      "    load_time_ms: 112.438\n",
      "    sample_throughput: 51.999\n",
      "    sample_time_ms: 192235.553\n",
      "    update_time_ms: 6.011\n",
      "  timestamp: 1637568498\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5437734\n",
      "  training_iteration: 604\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   604</td><td style=\"text-align: right;\">          307176</td><td style=\"text-align: right;\">5437734</td><td style=\"text-align: right;\"> 4.79185</td><td style=\"text-align: right;\">               17.65</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           54.0815</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5447730\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_08-17-14\n",
      "  done: false\n",
      "  episode_len_mean: 53.49197860962567\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.419999999999977\n",
      "  episode_reward_mean: 5.131818181818185\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 106684\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0324119756738823\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01523472036776269\n",
      "          policy_loss: -0.06973653940647447\n",
      "          total_loss: 0.09772676680957111\n",
      "          vf_explained_var: 0.937073290348053\n",
      "          vf_loss: 0.15308082677418344\n",
      "    num_agent_steps_sampled: 5447730\n",
      "    num_agent_steps_trained: 5447730\n",
      "    num_steps_sampled: 5447730\n",
      "    num_steps_trained: 5447730\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.21644908616189\n",
      "    ram_util_percent: 53.37637075718014\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05306949260989975\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.122621490751676\n",
      "    mean_inference_ms: 19.42591372842921\n",
      "    mean_raw_obs_processing_ms: 3.316099865773936\n",
      "  time_since_restore: 112895.00680327415\n",
      "  time_this_iter_s: 536.7557003498077\n",
      "  time_total_s: 307712.37038874626\n",
      "  timers:\n",
      "    learn_throughput: 28.087\n",
      "    learn_time_ms: 355896.475\n",
      "    load_throughput: 88935.359\n",
      "    load_time_ms: 112.396\n",
      "    sample_throughput: 52.323\n",
      "    sample_time_ms: 191042.426\n",
      "    update_time_ms: 5.859\n",
      "  timestamp: 1637569034\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5447730\n",
      "  training_iteration: 605\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   605</td><td style=\"text-align: right;\">          307712</td><td style=\"text-align: right;\">5447730</td><td style=\"text-align: right;\"> 5.13182</td><td style=\"text-align: right;\">               17.42</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">            53.492</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5457726\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_08-26-40\n",
      "  done: false\n",
      "  episode_len_mean: 53.22872340425532\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.1004255319148974\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 106872\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0557572935240334\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01458705275776454\n",
      "          policy_loss: -0.0704918373678624\n",
      "          total_loss: 0.08042081950847511\n",
      "          vf_explained_var: 0.9339661598205566\n",
      "          vf_loss: 0.13823909836458453\n",
      "    num_agent_steps_sampled: 5457726\n",
      "    num_agent_steps_trained: 5457726\n",
      "    num_steps_sampled: 5457726\n",
      "    num_steps_trained: 5457726\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.29938042131351\n",
      "    ram_util_percent: 53.73085501858736\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05305517665500913\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.119525612584646\n",
      "    mean_inference_ms: 19.426185238063837\n",
      "    mean_raw_obs_processing_ms: 3.3205857324461614\n",
      "  time_since_restore: 113460.44361948967\n",
      "  time_this_iter_s: 565.4368162155151\n",
      "  time_total_s: 308277.8072049618\n",
      "  timers:\n",
      "    learn_throughput: 28.085\n",
      "    learn_time_ms: 355918.582\n",
      "    load_throughput: 88835.523\n",
      "    load_time_ms: 112.523\n",
      "    sample_throughput: 51.803\n",
      "    sample_time_ms: 192963.476\n",
      "    update_time_ms: 6.28\n",
      "  timestamp: 1637569600\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5457726\n",
      "  training_iteration: 606\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   606</td><td style=\"text-align: right;\">          308278</td><td style=\"text-align: right;\">5457726</td><td style=\"text-align: right;\"> 5.10043</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.2287</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5467722\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_08-35-35\n",
      "  done: false\n",
      "  episode_len_mean: 53.295698924731184\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.60999999999998\n",
      "  episode_reward_mean: 5.261989247311832\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 107058\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0235125491418033\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014921481509498149\n",
      "          policy_loss: -0.0689877435149973\n",
      "          total_loss: 0.08533227144157335\n",
      "          vf_explained_var: 0.9310736060142517\n",
      "          vf_loss: 0.1405621389047725\n",
      "    num_agent_steps_sampled: 5467722\n",
      "    num_agent_steps_trained: 5467722\n",
      "    num_steps_sampled: 5467722\n",
      "    num_steps_trained: 5467722\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.17421465968586\n",
      "    ram_util_percent: 53.05392670157069\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0530552453013158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.119824621047606\n",
      "    mean_inference_ms: 19.427506088964215\n",
      "    mean_raw_obs_processing_ms: 3.3116524368756792\n",
      "  time_since_restore: 113995.71621274948\n",
      "  time_this_iter_s: 535.2725932598114\n",
      "  time_total_s: 308813.0797982216\n",
      "  timers:\n",
      "    learn_throughput: 28.084\n",
      "    learn_time_ms: 355926.97\n",
      "    load_throughput: 89101.589\n",
      "    load_time_ms: 112.187\n",
      "    sample_throughput: 51.815\n",
      "    sample_time_ms: 192917.474\n",
      "    update_time_ms: 6.544\n",
      "  timestamp: 1637570135\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5467722\n",
      "  training_iteration: 607\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   607</td><td style=\"text-align: right;\">          308813</td><td style=\"text-align: right;\">5467722</td><td style=\"text-align: right;\"> 5.26199</td><td style=\"text-align: right;\">               21.61</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.2957</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5477718\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_08-44-41\n",
      "  done: false\n",
      "  episode_len_mean: 54.497297297297294\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.63\n",
      "  episode_reward_mean: 4.770648648648652\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 107243\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0363013741960487\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013615475412487116\n",
      "          policy_loss: -0.06298168142674253\n",
      "          total_loss: 0.070054648578539\n",
      "          vf_explained_var: 0.9493324756622314\n",
      "          vf_loss: 0.12238158718159191\n",
      "    num_agent_steps_sampled: 5477718\n",
      "    num_agent_steps_trained: 5477718\n",
      "    num_steps_sampled: 5477718\n",
      "    num_steps_trained: 5477718\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7811053984576\n",
      "    ram_util_percent: 53.48804627249357\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05304903524291827\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.113630179992015\n",
      "    mean_inference_ms: 19.42781445280031\n",
      "    mean_raw_obs_processing_ms: 3.308552352455921\n",
      "  time_since_restore: 114541.40103125572\n",
      "  time_this_iter_s: 545.6848185062408\n",
      "  time_total_s: 309358.7646167278\n",
      "  timers:\n",
      "    learn_throughput: 28.082\n",
      "    learn_time_ms: 355955.42\n",
      "    load_throughput: 88625.543\n",
      "    load_time_ms: 112.789\n",
      "    sample_throughput: 52.176\n",
      "    sample_time_ms: 191583.302\n",
      "    update_time_ms: 6.762\n",
      "  timestamp: 1637570681\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5477718\n",
      "  training_iteration: 608\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   608</td><td style=\"text-align: right;\">          309359</td><td style=\"text-align: right;\">5477718</td><td style=\"text-align: right;\"> 4.77065</td><td style=\"text-align: right;\">               17.63</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           54.4973</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5487714\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_08-53-35\n",
      "  done: false\n",
      "  episode_len_mean: 53.62566844919786\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.38999999999998\n",
      "  episode_reward_mean: 5.226577540106956\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 107430\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0350410780753476\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014658741847039702\n",
      "          policy_loss: -0.07075785138197874\n",
      "          total_loss: 0.08399719313939609\n",
      "          vf_explained_var: 0.9449756741523743\n",
      "          vf_loss: 0.14171100874940107\n",
      "    num_agent_steps_sampled: 5487714\n",
      "    num_agent_steps_trained: 5487714\n",
      "    num_steps_sampled: 5487714\n",
      "    num_steps_trained: 5487714\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.03556430446193\n",
      "    ram_util_percent: 53.20905511811024\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05305388688025288\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.11408652546737\n",
      "    mean_inference_ms: 19.429585092719442\n",
      "    mean_raw_obs_processing_ms: 3.30093605298959\n",
      "  time_since_restore: 115075.70583987236\n",
      "  time_this_iter_s: 534.3048086166382\n",
      "  time_total_s: 309893.06942534447\n",
      "  timers:\n",
      "    learn_throughput: 28.084\n",
      "    learn_time_ms: 355927.732\n",
      "    load_throughput: 88672.759\n",
      "    load_time_ms: 112.729\n",
      "    sample_throughput: 52.488\n",
      "    sample_time_ms: 190444.947\n",
      "    update_time_ms: 6.735\n",
      "  timestamp: 1637571215\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5487714\n",
      "  training_iteration: 609\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   609</td><td style=\"text-align: right;\">          309893</td><td style=\"text-align: right;\">5487714</td><td style=\"text-align: right;\"> 5.22658</td><td style=\"text-align: right;\">               17.39</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           53.6257</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5497710\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_09-02-56\n",
      "  done: false\n",
      "  episode_len_mean: 53.3048128342246\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000008\n",
      "  episode_reward_mean: 5.346898395721929\n",
      "  episode_reward_min: -0.37000000000000016\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 107617\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0466857049838607\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014398658228977549\n",
      "          policy_loss: -0.07366333280440586\n",
      "          total_loss: 0.07569961505327202\n",
      "          vf_explained_var: 0.9418825507164001\n",
      "          vf_loss: 0.1370278612002693\n",
      "    num_agent_steps_sampled: 5497710\n",
      "    num_agent_steps_trained: 5497710\n",
      "    num_steps_sampled: 5497710\n",
      "    num_steps_trained: 5497710\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.6354556803995\n",
      "    ram_util_percent: 54.51535580524345\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053042615082595966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.10603563634929\n",
      "    mean_inference_ms: 19.428363228961288\n",
      "    mean_raw_obs_processing_ms: 3.314893462534731\n",
      "  time_since_restore: 115636.75138735771\n",
      "  time_this_iter_s: 561.0455474853516\n",
      "  time_total_s: 310454.1149728298\n",
      "  timers:\n",
      "    learn_throughput: 28.087\n",
      "    learn_time_ms: 355896.088\n",
      "    load_throughput: 88591.834\n",
      "    load_time_ms: 112.832\n",
      "    sample_throughput: 52.199\n",
      "    sample_time_ms: 191497.353\n",
      "    update_time_ms: 7.881\n",
      "  timestamp: 1637571776\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5497710\n",
      "  training_iteration: 610\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   610</td><td style=\"text-align: right;\">          310454</td><td style=\"text-align: right;\">5497710</td><td style=\"text-align: right;\">  5.3469</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.37</td><td style=\"text-align: right;\">           53.3048</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5507706\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_09-11-50\n",
      "  done: false\n",
      "  episode_len_mean: 53.18617021276596\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.589999999999986\n",
      "  episode_reward_mean: 5.509414893617026\n",
      "  episode_reward_min: -0.4300000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 107805\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0283674759558408\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015121195181722343\n",
      "          policy_loss: -0.07483540449553606\n",
      "          total_loss: 0.08830497669749816\n",
      "          vf_explained_var: 0.9344483613967896\n",
      "          vf_loss: 0.1489760821683325\n",
      "    num_agent_steps_sampled: 5507706\n",
      "    num_agent_steps_trained: 5507706\n",
      "    num_steps_sampled: 5507706\n",
      "    num_steps_trained: 5507706\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.09342969776611\n",
      "    ram_util_percent: 53.57503285151117\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05305559238488235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.10558725936514\n",
      "    mean_inference_ms: 19.429718211182898\n",
      "    mean_raw_obs_processing_ms: 3.3063237974909416\n",
      "  time_since_restore: 116170.30844545364\n",
      "  time_this_iter_s: 533.557058095932\n",
      "  time_total_s: 310987.67203092575\n",
      "  timers:\n",
      "    learn_throughput: 28.089\n",
      "    learn_time_ms: 355872.711\n",
      "    load_throughput: 88352.253\n",
      "    load_time_ms: 113.138\n",
      "    sample_throughput: 52.285\n",
      "    sample_time_ms: 191183.479\n",
      "    update_time_ms: 8.591\n",
      "  timestamp: 1637572310\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5507706\n",
      "  training_iteration: 611\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   611</td><td style=\"text-align: right;\">          310988</td><td style=\"text-align: right;\">5507706</td><td style=\"text-align: right;\"> 5.50941</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">               -0.43</td><td style=\"text-align: right;\">           53.1862</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5517702\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_09-20-43\n",
      "  done: false\n",
      "  episode_len_mean: 54.40217391304348\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.2018478260869605\n",
      "  episode_reward_min: -0.4200000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 107989\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0339321898887435\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015493224001479242\n",
      "          policy_loss: -0.07118085039939294\n",
      "          total_loss: 0.09949853077614315\n",
      "          vf_explained_var: 0.9304167628288269\n",
      "          vf_loss: 0.15572320093703737\n",
      "    num_agent_steps_sampled: 5517702\n",
      "    num_agent_steps_trained: 5517702\n",
      "    num_steps_sampled: 5517702\n",
      "    num_steps_trained: 5517702\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98055190538764\n",
      "    ram_util_percent: 53.195663600525634\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05306087559116662\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.10296602793911\n",
      "    mean_inference_ms: 19.431299091426578\n",
      "    mean_raw_obs_processing_ms: 3.295572810969094\n",
      "  time_since_restore: 116703.65776443481\n",
      "  time_this_iter_s: 533.3493189811707\n",
      "  time_total_s: 311521.0213499069\n",
      "  timers:\n",
      "    learn_throughput: 28.088\n",
      "    learn_time_ms: 355884.11\n",
      "    load_throughput: 88411.668\n",
      "    load_time_ms: 113.062\n",
      "    sample_throughput: 53.008\n",
      "    sample_time_ms: 188576.889\n",
      "    update_time_ms: 9.236\n",
      "  timestamp: 1637572843\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5517702\n",
      "  training_iteration: 612\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   612</td><td style=\"text-align: right;\">          311521</td><td style=\"text-align: right;\">5517702</td><td style=\"text-align: right;\"> 5.20185</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.42</td><td style=\"text-align: right;\">           54.4022</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5527698\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_09-29-52\n",
      "  done: false\n",
      "  episode_len_mean: 53.56216216216216\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000007\n",
      "  episode_reward_mean: 5.269189189189194\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 108174\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0289108605509303\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014269374554211707\n",
      "          policy_loss: -0.07223573937155287\n",
      "          total_loss: 0.06594677298171372\n",
      "          vf_explained_var: 0.9423051476478577\n",
      "          vf_loss: 0.12596419945716425\n",
      "    num_agent_steps_sampled: 5527698\n",
      "    num_agent_steps_trained: 5527698\n",
      "    num_steps_sampled: 5527698\n",
      "    num_steps_trained: 5527698\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82337164750959\n",
      "    ram_util_percent: 53.20855683269475\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053057795199074644\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.10058810149099\n",
      "    mean_inference_ms: 19.432865193534102\n",
      "    mean_raw_obs_processing_ms: 3.2962804070556557\n",
      "  time_since_restore: 117252.3368268013\n",
      "  time_this_iter_s: 548.6790623664856\n",
      "  time_total_s: 312069.7004122734\n",
      "  timers:\n",
      "    learn_throughput: 28.091\n",
      "    learn_time_ms: 355844.681\n",
      "    load_throughput: 87379.275\n",
      "    load_time_ms: 114.398\n",
      "    sample_throughput: 53.112\n",
      "    sample_time_ms: 188204.755\n",
      "    update_time_ms: 9.003\n",
      "  timestamp: 1637573392\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5527698\n",
      "  training_iteration: 613\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   613</td><td style=\"text-align: right;\">          312070</td><td style=\"text-align: right;\">5527698</td><td style=\"text-align: right;\"> 5.26919</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           53.5622</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5537694\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_09-39-16\n",
      "  done: false\n",
      "  episode_len_mean: 52.49738219895288\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.60999999999998\n",
      "  episode_reward_mean: 5.318848167539271\n",
      "  episode_reward_min: -0.5300000000000005\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 108365\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.019457296147404\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014555778444647394\n",
      "          policy_loss: -0.0719682447468169\n",
      "          total_loss: 0.07623833232263784\n",
      "          vf_explained_var: 0.9418643116950989\n",
      "          vf_loss: 0.1352412653557702\n",
      "    num_agent_steps_sampled: 5537694\n",
      "    num_agent_steps_trained: 5537694\n",
      "    num_steps_sampled: 5537694\n",
      "    num_steps_trained: 5537694\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.46878109452737\n",
      "    ram_util_percent: 54.202238805970154\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053047072415629185\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.09582328154132\n",
      "    mean_inference_ms: 19.43183501111104\n",
      "    mean_raw_obs_processing_ms: 3.31032053148524\n",
      "  time_since_restore: 117816.0164027214\n",
      "  time_this_iter_s: 563.679575920105\n",
      "  time_total_s: 312633.3799881935\n",
      "  timers:\n",
      "    learn_throughput: 28.095\n",
      "    learn_time_ms: 355797.261\n",
      "    load_throughput: 87245.485\n",
      "    load_time_ms: 114.573\n",
      "    sample_throughput: 52.654\n",
      "    sample_time_ms: 189842.853\n",
      "    update_time_ms: 8.623\n",
      "  timestamp: 1637573956\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5537694\n",
      "  training_iteration: 614\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   614</td><td style=\"text-align: right;\">          312633</td><td style=\"text-align: right;\">5537694</td><td style=\"text-align: right;\"> 5.31885</td><td style=\"text-align: right;\">               19.61</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           52.4974</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5547690\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_09-48-13\n",
      "  done: false\n",
      "  episode_len_mean: 53.34574468085106\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.630000000000006\n",
      "  episode_reward_mean: 5.114095744680855\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 108553\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.030236178038111\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014654211889326267\n",
      "          policy_loss: -0.0678615728957661\n",
      "          total_loss: 0.07795415303277903\n",
      "          vf_explained_var: 0.9458229541778564\n",
      "          vf_loss: 0.13273396138840515\n",
      "    num_agent_steps_sampled: 5547690\n",
      "    num_agent_steps_trained: 5547690\n",
      "    num_steps_sampled: 5547690\n",
      "    num_steps_trained: 5547690\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1959582790091\n",
      "    ram_util_percent: 53.525032594524106\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05304499676595299\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.09587757407182\n",
      "    mean_inference_ms: 19.433726237916577\n",
      "    mean_raw_obs_processing_ms: 3.301497256318099\n",
      "  time_since_restore: 118353.13314080238\n",
      "  time_this_iter_s: 537.1167380809784\n",
      "  time_total_s: 313170.4967262745\n",
      "  timers:\n",
      "    learn_throughput: 28.095\n",
      "    learn_time_ms: 355797.265\n",
      "    load_throughput: 87520.163\n",
      "    load_time_ms: 114.214\n",
      "    sample_throughput: 52.644\n",
      "    sample_time_ms: 189879.633\n",
      "    update_time_ms: 8.011\n",
      "  timestamp: 1637574493\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5547690\n",
      "  training_iteration: 615\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   615</td><td style=\"text-align: right;\">          313170</td><td style=\"text-align: right;\">5547690</td><td style=\"text-align: right;\">  5.1141</td><td style=\"text-align: right;\">               17.63</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           53.3457</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5557686\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_09-57-34\n",
      "  done: false\n",
      "  episode_len_mean: 53.483870967741936\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.44000000000001\n",
      "  episode_reward_mean: 4.760860215053767\n",
      "  episode_reward_min: -0.6300000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 108739\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0689973209038315\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014211749814968993\n",
      "          policy_loss: -0.06524371761828018\n",
      "          total_loss: 0.06952941276086516\n",
      "          vf_explained_var: 0.9265385866165161\n",
      "          vf_loss: 0.12308696145051529\n",
      "    num_agent_steps_sampled: 5557686\n",
      "    num_agent_steps_trained: 5557686\n",
      "    num_steps_sampled: 5557686\n",
      "    num_steps_trained: 5557686\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.50686641697878\n",
      "    ram_util_percent: 53.89038701622972\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053032865948559764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08793077180188\n",
      "    mean_inference_ms: 19.433408396391222\n",
      "    mean_raw_obs_processing_ms: 3.316715244934947\n",
      "  time_since_restore: 118914.42888140678\n",
      "  time_this_iter_s: 561.2957406044006\n",
      "  time_total_s: 313731.7924668789\n",
      "  timers:\n",
      "    learn_throughput: 28.098\n",
      "    learn_time_ms: 355748.642\n",
      "    load_throughput: 87599.562\n",
      "    load_time_ms: 114.11\n",
      "    sample_throughput: 52.745\n",
      "    sample_time_ms: 189514.734\n",
      "    update_time_ms: 7.992\n",
      "  timestamp: 1637575054\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5557686\n",
      "  training_iteration: 616\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   616</td><td style=\"text-align: right;\">          313732</td><td style=\"text-align: right;\">5557686</td><td style=\"text-align: right;\"> 4.76086</td><td style=\"text-align: right;\">               15.44</td><td style=\"text-align: right;\">               -0.63</td><td style=\"text-align: right;\">           53.4839</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5567682\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_10-06-29\n",
      "  done: false\n",
      "  episode_len_mean: 53.74331550802139\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000006\n",
      "  episode_reward_mean: 5.264117647058828\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 108926\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0259234954554395\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01450759785873209\n",
      "          policy_loss: -0.0699722961162099\n",
      "          total_loss: 0.07810341786502702\n",
      "          vf_explained_var: 0.9431240558624268\n",
      "          vf_loss: 0.13528482703207786\n",
      "    num_agent_steps_sampled: 5567682\n",
      "    num_agent_steps_trained: 5567682\n",
      "    num_steps_sampled: 5567682\n",
      "    num_steps_trained: 5567682\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.05360419397115\n",
      "    ram_util_percent: 53.77758846657929\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0530235023685139\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08591473391067\n",
      "    mean_inference_ms: 19.435913849463706\n",
      "    mean_raw_obs_processing_ms: 3.306591470184855\n",
      "  time_since_restore: 119449.4493625164\n",
      "  time_this_iter_s: 535.0204811096191\n",
      "  time_total_s: 314266.8129479885\n",
      "  timers:\n",
      "    learn_throughput: 28.101\n",
      "    learn_time_ms: 355714.911\n",
      "    load_throughput: 87524.694\n",
      "    load_time_ms: 114.208\n",
      "    sample_throughput: 52.743\n",
      "    sample_time_ms: 189523.298\n",
      "    update_time_ms: 7.678\n",
      "  timestamp: 1637575589\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5567682\n",
      "  training_iteration: 617\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   617</td><td style=\"text-align: right;\">          314267</td><td style=\"text-align: right;\">5567682</td><td style=\"text-align: right;\"> 5.26412</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           53.7433</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5577678\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_10-15-37\n",
      "  done: false\n",
      "  episode_len_mean: 53.87567567567567\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.580000000000007\n",
      "  episode_reward_mean: 5.2916756756756795\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 109111\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0360011476589492\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014240027382459906\n",
      "          policy_loss: -0.06883132238560856\n",
      "          total_loss: 0.07165834971071953\n",
      "          vf_explained_var: 0.9427934288978577\n",
      "          vf_loss: 0.1284091200152165\n",
      "    num_agent_steps_sampled: 5577678\n",
      "    num_agent_steps_trained: 5577678\n",
      "    num_steps_sampled: 5577678\n",
      "    num_steps_trained: 5577678\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7843790012804\n",
      "    ram_util_percent: 53.82330345710626\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302956718092335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08061852076519\n",
      "    mean_inference_ms: 19.436385085411814\n",
      "    mean_raw_obs_processing_ms: 3.30563281421165\n",
      "  time_since_restore: 119996.97337508202\n",
      "  time_this_iter_s: 547.5240125656128\n",
      "  time_total_s: 314814.3369605541\n",
      "  timers:\n",
      "    learn_throughput: 28.103\n",
      "    learn_time_ms: 355689.997\n",
      "    load_throughput: 87565.001\n",
      "    load_time_ms: 114.155\n",
      "    sample_throughput: 52.685\n",
      "    sample_time_ms: 189732.936\n",
      "    update_time_ms: 7.418\n",
      "  timestamp: 1637576137\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5577678\n",
      "  training_iteration: 618\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   618</td><td style=\"text-align: right;\">          314814</td><td style=\"text-align: right;\">5577678</td><td style=\"text-align: right;\"> 5.29168</td><td style=\"text-align: right;\">               13.58</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.8757</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5587674\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_10-24-51\n",
      "  done: false\n",
      "  episode_len_mean: 53.711229946524064\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000007\n",
      "  episode_reward_mean: 5.3841711229946565\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 109298\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0204595423606504\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015454212054316095\n",
      "          policy_loss: -0.0667406166084019\n",
      "          total_loss: 0.08846235365826174\n",
      "          vf_explained_var: 0.9280555844306946\n",
      "          vf_loss: 0.1402009362267914\n",
      "    num_agent_steps_sampled: 5587674\n",
      "    num_agent_steps_trained: 5587674\n",
      "    num_steps_sampled: 5587674\n",
      "    num_steps_trained: 5587674\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.42604298356511\n",
      "    ram_util_percent: 53.635524652338816\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303074697059966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08003415946557\n",
      "    mean_inference_ms: 19.438854119035593\n",
      "    mean_raw_obs_processing_ms: 3.3046919687533296\n",
      "  time_since_restore: 120551.4357380867\n",
      "  time_this_iter_s: 554.4623630046844\n",
      "  time_total_s: 315368.7993235588\n",
      "  timers:\n",
      "    learn_throughput: 28.097\n",
      "    learn_time_ms: 355763.922\n",
      "    load_throughput: 87379.075\n",
      "    load_time_ms: 114.398\n",
      "    sample_throughput: 52.151\n",
      "    sample_time_ms: 191674.35\n",
      "    update_time_ms: 7.615\n",
      "  timestamp: 1637576691\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5587674\n",
      "  training_iteration: 619\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   619</td><td style=\"text-align: right;\">          315369</td><td style=\"text-align: right;\">5587674</td><td style=\"text-align: right;\"> 5.38417</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           53.7112</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5597670\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_10-33-57\n",
      "  done: false\n",
      "  episode_len_mean: 54.93922651933702\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.409613259668514\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 109479\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0132028547396144\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0148503126143704\n",
      "          policy_loss: -0.06818616537165345\n",
      "          total_loss: 0.08901686941473205\n",
      "          vf_explained_var: 0.9477107524871826\n",
      "          vf_loss: 0.14350419328856584\n",
      "    num_agent_steps_sampled: 5597670\n",
      "    num_agent_steps_trained: 5597670\n",
      "    num_steps_sampled: 5597670\n",
      "    num_steps_trained: 5597670\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.79281129653403\n",
      "    ram_util_percent: 53.54480102695766\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05301749741056774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.07279914064735\n",
      "    mean_inference_ms: 19.440755520850104\n",
      "    mean_raw_obs_processing_ms: 3.3011953743722775\n",
      "  time_since_restore: 121096.96770954132\n",
      "  time_this_iter_s: 545.5319714546204\n",
      "  time_total_s: 315914.3312950134\n",
      "  timers:\n",
      "    learn_throughput: 28.091\n",
      "    learn_time_ms: 355849.462\n",
      "    load_throughput: 87521.99\n",
      "    load_time_ms: 114.211\n",
      "    sample_throughput: 52.6\n",
      "    sample_time_ms: 190038.196\n",
      "    update_time_ms: 6.615\n",
      "  timestamp: 1637577237\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5597670\n",
      "  training_iteration: 620\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   620</td><td style=\"text-align: right;\">          315914</td><td style=\"text-align: right;\">5597670</td><td style=\"text-align: right;\"> 5.40961</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           54.9392</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5607666\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_10-43-07\n",
      "  done: false\n",
      "  episode_len_mean: 54.22162162162162\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.700000000000005\n",
      "  episode_reward_mean: 5.017189189189193\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 109664\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0187937355663883\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014205614757974487\n",
      "          policy_loss: -0.06951712380803246\n",
      "          total_loss: 0.06884473775793609\n",
      "          vf_explained_var: 0.9296038746833801\n",
      "          vf_loss: 0.1261876309685125\n",
      "    num_agent_steps_sampled: 5607666\n",
      "    num_agent_steps_trained: 5607666\n",
      "    num_steps_sampled: 5607666\n",
      "    num_steps_trained: 5607666\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.85414012738853\n",
      "    ram_util_percent: 53.64891719745222\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302238363729947\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.06740418018528\n",
      "    mean_inference_ms: 19.441397326886577\n",
      "    mean_raw_obs_processing_ms: 3.2997216706033767\n",
      "  time_since_restore: 121647.18428015709\n",
      "  time_this_iter_s: 550.2165706157684\n",
      "  time_total_s: 316464.5478656292\n",
      "  timers:\n",
      "    learn_throughput: 28.073\n",
      "    learn_time_ms: 356074.712\n",
      "    load_throughput: 86671.552\n",
      "    load_time_ms: 115.332\n",
      "    sample_throughput: 52.204\n",
      "    sample_time_ms: 191480.069\n",
      "    update_time_ms: 5.921\n",
      "  timestamp: 1637577787\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5607666\n",
      "  training_iteration: 621\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   621</td><td style=\"text-align: right;\">          316465</td><td style=\"text-align: right;\">5607666</td><td style=\"text-align: right;\"> 5.01719</td><td style=\"text-align: right;\">                15.7</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           54.2216</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5617662\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_10-52-15\n",
      "  done: false\n",
      "  episode_len_mean: 54.650273224043715\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.680000000000005\n",
      "  episode_reward_mean: 5.443989071038256\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 109847\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0156460904452693\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014750372803523551\n",
      "          policy_loss: -0.06701750884820058\n",
      "          total_loss: 0.0903905593652499\n",
      "          vf_explained_var: 0.9430559873580933\n",
      "          vf_loss: 0.1439613340049421\n",
      "    num_agent_steps_sampled: 5617662\n",
      "    num_agent_steps_trained: 5617662\n",
      "    num_steps_sampled: 5617662\n",
      "    num_steps_trained: 5617662\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.55441741357234\n",
      "    ram_util_percent: 54.08642765685019\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303486985823114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.064359187322395\n",
      "    mean_inference_ms: 19.44295104128627\n",
      "    mean_raw_obs_processing_ms: 3.2984060710865277\n",
      "  time_since_restore: 122194.83218884468\n",
      "  time_this_iter_s: 547.6479086875916\n",
      "  time_total_s: 317012.1957743168\n",
      "  timers:\n",
      "    learn_throughput: 28.07\n",
      "    learn_time_ms: 356105.653\n",
      "    load_throughput: 86530.167\n",
      "    load_time_ms: 115.52\n",
      "    sample_throughput: 51.825\n",
      "    sample_time_ms: 192879.056\n",
      "    update_time_ms: 5.248\n",
      "  timestamp: 1637578335\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5617662\n",
      "  training_iteration: 622\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   622</td><td style=\"text-align: right;\">          317012</td><td style=\"text-align: right;\">5617662</td><td style=\"text-align: right;\"> 5.44399</td><td style=\"text-align: right;\">               15.68</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           54.6503</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5627658\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_11-01-24\n",
      "  done: false\n",
      "  episode_len_mean: 53.42780748663102\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.709999999999987\n",
      "  episode_reward_mean: 5.6645989304812865\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 110034\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.007639910585909\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014104014621843313\n",
      "          policy_loss: -0.06636508281283104\n",
      "          total_loss: 0.08370809897122997\n",
      "          vf_explained_var: 0.9416435360908508\n",
      "          vf_loss: 0.1380188720602819\n",
      "    num_agent_steps_sampled: 5627658\n",
      "    num_agent_steps_trained: 5627658\n",
      "    num_steps_sampled: 5627658\n",
      "    num_steps_trained: 5627658\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.90535714285713\n",
      "    ram_util_percent: 54.16913265306121\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053038936384072234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.06157623609085\n",
      "    mean_inference_ms: 19.44403321317934\n",
      "    mean_raw_obs_processing_ms: 3.2971721389565776\n",
      "  time_since_restore: 122744.31951451302\n",
      "  time_this_iter_s: 549.487325668335\n",
      "  time_total_s: 317561.6830999851\n",
      "  timers:\n",
      "    learn_throughput: 28.066\n",
      "    learn_time_ms: 356157.484\n",
      "    load_throughput: 87757.323\n",
      "    load_time_ms: 113.905\n",
      "    sample_throughput: 51.817\n",
      "    sample_time_ms: 192909.347\n",
      "    update_time_ms: 5.111\n",
      "  timestamp: 1637578884\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5627658\n",
      "  training_iteration: 623\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   623</td><td style=\"text-align: right;\">          317562</td><td style=\"text-align: right;\">5627658</td><td style=\"text-align: right;\">  5.6646</td><td style=\"text-align: right;\">               19.71</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.4278</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5637654\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_11-10-35\n",
      "  done: false\n",
      "  episode_len_mean: 53.564516129032256\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.103763440860219\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 110220\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0510344182152345\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014145555263098474\n",
      "          policy_loss: -0.07168102174544759\n",
      "          total_loss: 0.07041823235595221\n",
      "          vf_explained_var: 0.9333083033561707\n",
      "          vf_loss: 0.1303842543513069\n",
      "    num_agent_steps_sampled: 5637654\n",
      "    num_agent_steps_trained: 5637654\n",
      "    num_steps_sampled: 5637654\n",
      "    num_steps_trained: 5637654\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9563613231552\n",
      "    ram_util_percent: 53.87493638676845\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303842423151467\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.05901916220648\n",
      "    mean_inference_ms: 19.445763133225736\n",
      "    mean_raw_obs_processing_ms: 3.2951808189867005\n",
      "  time_since_restore: 123294.97815227509\n",
      "  time_this_iter_s: 550.6586377620697\n",
      "  time_total_s: 318112.3417377472\n",
      "  timers:\n",
      "    learn_throughput: 28.055\n",
      "    learn_time_ms: 356300.572\n",
      "    load_throughput: 87782.293\n",
      "    load_time_ms: 113.873\n",
      "    sample_throughput: 52.208\n",
      "    sample_time_ms: 191463.765\n",
      "    update_time_ms: 5.18\n",
      "  timestamp: 1637579435\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5637654\n",
      "  training_iteration: 624\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   624</td><td style=\"text-align: right;\">          318112</td><td style=\"text-align: right;\">5637654</td><td style=\"text-align: right;\"> 5.10376</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           53.5645</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5647650\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_11-19-31\n",
      "  done: false\n",
      "  episode_len_mean: 53.340425531914896\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000007\n",
      "  episode_reward_mean: 5.16425531914894\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 110408\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.055309332733652\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01466209343312654\n",
      "          policy_loss: -0.06896529878303626\n",
      "          total_loss: 0.0907270353257982\n",
      "          vf_explained_var: 0.9342118501663208\n",
      "          vf_loss: 0.14684334485230585\n",
      "    num_agent_steps_sampled: 5647650\n",
      "    num_agent_steps_trained: 5647650\n",
      "    num_steps_sampled: 5647650\n",
      "    num_steps_trained: 5647650\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.11738562091502\n",
      "    ram_util_percent: 53.586797385620926\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05304306250147285\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.05923862900754\n",
      "    mean_inference_ms: 19.446899857366535\n",
      "    mean_raw_obs_processing_ms: 3.2865416739119255\n",
      "  time_since_restore: 123831.28362798691\n",
      "  time_this_iter_s: 536.3054757118225\n",
      "  time_total_s: 318648.647213459\n",
      "  timers:\n",
      "    learn_throughput: 28.054\n",
      "    learn_time_ms: 356307.054\n",
      "    load_throughput: 87594.657\n",
      "    load_time_ms: 114.117\n",
      "    sample_throughput: 52.233\n",
      "    sample_time_ms: 191374.997\n",
      "    update_time_ms: 5.549\n",
      "  timestamp: 1637579971\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5647650\n",
      "  training_iteration: 625\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   625</td><td style=\"text-align: right;\">          318649</td><td style=\"text-align: right;\">5647650</td><td style=\"text-align: right;\"> 5.16426</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.3404</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5657646\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_11-28-42\n",
      "  done: false\n",
      "  episode_len_mean: 53.82702702702703\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.140918918918923\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 110593\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.022221385068204\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014153416125631781\n",
      "          policy_loss: -0.07186874386523955\n",
      "          total_loss: 0.08135208240790337\n",
      "          vf_explained_var: 0.9394128322601318\n",
      "          vf_loss: 0.14119978609324685\n",
      "    num_agent_steps_sampled: 5657646\n",
      "    num_agent_steps_trained: 5657646\n",
      "    num_steps_sampled: 5657646\n",
      "    num_steps_trained: 5657646\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.88015267175572\n",
      "    ram_util_percent: 53.969720101781164\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053039027551996805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.05700255441916\n",
      "    mean_inference_ms: 19.449216096134776\n",
      "    mean_raw_obs_processing_ms: 3.284699149973118\n",
      "  time_since_restore: 124381.93912672997\n",
      "  time_this_iter_s: 550.6554987430573\n",
      "  time_total_s: 319199.3027122021\n",
      "  timers:\n",
      "    learn_throughput: 28.045\n",
      "    learn_time_ms: 356425.917\n",
      "    load_throughput: 87460.261\n",
      "    load_time_ms: 114.292\n",
      "    sample_throughput: 52.558\n",
      "    sample_time_ms: 190191.573\n",
      "    update_time_ms: 5.835\n",
      "  timestamp: 1637580522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5657646\n",
      "  training_iteration: 626\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   626</td><td style=\"text-align: right;\">          319199</td><td style=\"text-align: right;\">5657646</td><td style=\"text-align: right;\"> 5.14092</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">            53.827</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5667642\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_11-37-46\n",
      "  done: false\n",
      "  episode_len_mean: 54.622950819672134\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.559999999999995\n",
      "  episode_reward_mean: 5.565901639344267\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 110776\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0209379694069245\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015137634334561813\n",
      "          policy_loss: -0.06981690260245488\n",
      "          total_loss: 0.09143370963681655\n",
      "          vf_explained_var: 0.9421535730361938\n",
      "          vf_loss: 0.14697456769710668\n",
      "    num_agent_steps_sampled: 5667642\n",
      "    num_agent_steps_trained: 5667642\n",
      "    num_steps_sampled: 5667642\n",
      "    num_steps_trained: 5667642\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.70735483870969\n",
      "    ram_util_percent: 53.954580645161286\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05304082776231795\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.047232403207936\n",
      "    mean_inference_ms: 19.448870256058356\n",
      "    mean_raw_obs_processing_ms: 3.292212639155091\n",
      "  time_since_restore: 124925.37810754776\n",
      "  time_this_iter_s: 543.4389808177948\n",
      "  time_total_s: 319742.74169301987\n",
      "  timers:\n",
      "    learn_throughput: 28.048\n",
      "    learn_time_ms: 356389.619\n",
      "    load_throughput: 87981.017\n",
      "    load_time_ms: 113.615\n",
      "    sample_throughput: 52.316\n",
      "    sample_time_ms: 191070.676\n",
      "    update_time_ms: 5.842\n",
      "  timestamp: 1637581066\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5667642\n",
      "  training_iteration: 627\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   627</td><td style=\"text-align: right;\">          319743</td><td style=\"text-align: right;\">5667642</td><td style=\"text-align: right;\">  5.5659</td><td style=\"text-align: right;\">               19.56</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">            54.623</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5677638\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_11-47-09\n",
      "  done: false\n",
      "  episode_len_mean: 53.44919786096256\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.73\n",
      "  episode_reward_mean: 4.998449197860967\n",
      "  episode_reward_min: -0.6400000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 110963\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0484623287815644\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014184546723640773\n",
      "          policy_loss: -0.06710270604698561\n",
      "          total_loss: 0.0708659978407634\n",
      "          vf_explained_var: 0.9343231320381165\n",
      "          vf_loss: 0.1261391550862608\n",
      "    num_agent_steps_sampled: 5677638\n",
      "    num_agent_steps_trained: 5677638\n",
      "    num_steps_sampled: 5677638\n",
      "    num_steps_trained: 5677638\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.16791044776119\n",
      "    ram_util_percent: 53.60845771144278\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302335381782933\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.04317207094215\n",
      "    mean_inference_ms: 19.448638227442743\n",
      "    mean_raw_obs_processing_ms: 3.2969087853850243\n",
      "  time_since_restore: 125489.17876338959\n",
      "  time_this_iter_s: 563.8006558418274\n",
      "  time_total_s: 320306.5423488617\n",
      "  timers:\n",
      "    learn_throughput: 28.054\n",
      "    learn_time_ms: 356309.557\n",
      "    load_throughput: 88297.845\n",
      "    load_time_ms: 113.208\n",
      "    sample_throughput: 51.852\n",
      "    sample_time_ms: 192778.234\n",
      "    update_time_ms: 6.067\n",
      "  timestamp: 1637581629\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5677638\n",
      "  training_iteration: 628\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   628</td><td style=\"text-align: right;\">          320307</td><td style=\"text-align: right;\">5677638</td><td style=\"text-align: right;\"> 4.99845</td><td style=\"text-align: right;\">               17.73</td><td style=\"text-align: right;\">               -0.64</td><td style=\"text-align: right;\">           53.4492</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5687634\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_11-56-23\n",
      "  done: false\n",
      "  episode_len_mean: 53.715053763440864\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 5.087311827956993\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 111149\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.07068598323079\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014134942009888993\n",
      "          policy_loss: -0.07107662363670977\n",
      "          total_loss: 0.06350574944163713\n",
      "          vf_explained_var: 0.9457156658172607\n",
      "          vf_loss: 0.12308806689777767\n",
      "    num_agent_steps_sampled: 5687634\n",
      "    num_agent_steps_trained: 5687634\n",
      "    num_steps_sampled: 5687634\n",
      "    num_steps_trained: 5687634\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.57898734177215\n",
      "    ram_util_percent: 53.756962025316454\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302265564258063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.036928810389696\n",
      "    mean_inference_ms: 19.448785918256846\n",
      "    mean_raw_obs_processing_ms: 3.3000196400408317\n",
      "  time_since_restore: 126042.49396634102\n",
      "  time_this_iter_s: 553.3152029514313\n",
      "  time_total_s: 320859.8575518131\n",
      "  timers:\n",
      "    learn_throughput: 28.064\n",
      "    learn_time_ms: 356188.643\n",
      "    load_throughput: 88430.968\n",
      "    load_time_ms: 113.037\n",
      "    sample_throughput: 51.851\n",
      "    sample_time_ms: 192784.389\n",
      "    update_time_ms: 6.001\n",
      "  timestamp: 1637582183\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5687634\n",
      "  training_iteration: 629\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   629</td><td style=\"text-align: right;\">          320860</td><td style=\"text-align: right;\">5687634</td><td style=\"text-align: right;\"> 5.08731</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.7151</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5697630\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_12-05-30\n",
      "  done: false\n",
      "  episode_len_mean: 53.32804232804233\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.650000000000006\n",
      "  episode_reward_mean: 4.898835978835983\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 111338\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0586105678215563\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016009641641656636\n",
      "          policy_loss: -0.06972239875010372\n",
      "          total_loss: 0.0957878568420148\n",
      "          vf_explained_var: 0.9020230174064636\n",
      "          vf_loss: 0.14962439635828376\n",
      "    num_agent_steps_sampled: 5697630\n",
      "    num_agent_steps_trained: 5697630\n",
      "    num_steps_sampled: 5697630\n",
      "    num_steps_trained: 5697630\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.89859154929577\n",
      "    ram_util_percent: 52.98015364916773\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302036899105441\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.033125726888\n",
      "    mean_inference_ms: 19.449608608473454\n",
      "    mean_raw_obs_processing_ms: 3.2994669061180124\n",
      "  time_since_restore: 126590.20429372787\n",
      "  time_this_iter_s: 547.7103273868561\n",
      "  time_total_s: 321407.5678792\n",
      "  timers:\n",
      "    learn_throughput: 28.074\n",
      "    learn_time_ms: 356061.873\n",
      "    load_throughput: 88537.169\n",
      "    load_time_ms: 112.902\n",
      "    sample_throughput: 51.758\n",
      "    sample_time_ms: 193129.193\n",
      "    update_time_ms: 5.952\n",
      "  timestamp: 1637582730\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5697630\n",
      "  training_iteration: 630\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   630</td><td style=\"text-align: right;\">          321408</td><td style=\"text-align: right;\">5697630</td><td style=\"text-align: right;\"> 4.89884</td><td style=\"text-align: right;\">               13.65</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">            53.328</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5707626\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_12-14-34\n",
      "  done: false\n",
      "  episode_len_mean: 53.76086956521739\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.650000000000004\n",
      "  episode_reward_mean: 5.1813043478260905\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 111522\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0546873615927486\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014697528952971297\n",
      "          policy_loss: -0.07082512186487541\n",
      "          total_loss: 0.0761969726915763\n",
      "          vf_explained_var: 0.9422051310539246\n",
      "          vf_loss: 0.13408615878936517\n",
      "    num_agent_steps_sampled: 5707626\n",
      "    num_agent_steps_trained: 5707626\n",
      "    num_steps_sampled: 5707626\n",
      "    num_steps_trained: 5707626\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77409793814435\n",
      "    ram_util_percent: 52.76804123711341\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302521823970734\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02711172682133\n",
      "    mean_inference_ms: 19.449322390475707\n",
      "    mean_raw_obs_processing_ms: 3.2971977019110015\n",
      "  time_since_restore: 127133.88649868965\n",
      "  time_this_iter_s: 543.6822049617767\n",
      "  time_total_s: 321951.25008416176\n",
      "  timers:\n",
      "    learn_throughput: 28.092\n",
      "    learn_time_ms: 355829.838\n",
      "    load_throughput: 88162.712\n",
      "    load_time_ms: 113.381\n",
      "    sample_throughput: 51.871\n",
      "    sample_time_ms: 192707.03\n",
      "    update_time_ms: 6.041\n",
      "  timestamp: 1637583274\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5707626\n",
      "  training_iteration: 631\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   631</td><td style=\"text-align: right;\">          321951</td><td style=\"text-align: right;\">5707626</td><td style=\"text-align: right;\">  5.1813</td><td style=\"text-align: right;\">               15.65</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           53.7609</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5717622\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_12-23-27\n",
      "  done: false\n",
      "  episode_len_mean: 53.90909090909091\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.58999999999999\n",
      "  episode_reward_mean: 5.573957219251342\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 111709\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.031304210232922\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014939853747545724\n",
      "          policy_loss: -0.06969654389481493\n",
      "          total_loss: 0.09761323241232221\n",
      "          vf_explained_var: 0.9360416531562805\n",
      "          vf_loss: 0.15358796305701988\n",
      "    num_agent_steps_sampled: 5717622\n",
      "    num_agent_steps_trained: 5717622\n",
      "    num_steps_sampled: 5717622\n",
      "    num_steps_trained: 5717622\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91434210526315\n",
      "    ram_util_percent: 52.963289473684206\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05303288438744548\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02397502003881\n",
      "    mean_inference_ms: 19.450240069029572\n",
      "    mean_raw_obs_processing_ms: 3.288432460252212\n",
      "  time_since_restore: 127666.2710211277\n",
      "  time_this_iter_s: 532.3845224380493\n",
      "  time_total_s: 322483.6346065998\n",
      "  timers:\n",
      "    learn_throughput: 28.101\n",
      "    learn_time_ms: 355717.205\n",
      "    load_throughput: 88221.26\n",
      "    load_time_ms: 113.306\n",
      "    sample_throughput: 52.255\n",
      "    sample_time_ms: 191294.08\n",
      "    update_time_ms: 5.666\n",
      "  timestamp: 1637583807\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5717622\n",
      "  training_iteration: 632\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   632</td><td style=\"text-align: right;\">          322484</td><td style=\"text-align: right;\">5717622</td><td style=\"text-align: right;\"> 5.57396</td><td style=\"text-align: right;\">               19.59</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           53.9091</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5727618\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_12-32-33\n",
      "  done: false\n",
      "  episode_len_mean: 53.45989304812834\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.42000000000001\n",
      "  episode_reward_mean: 5.394866310160432\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 111896\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0440923068178707\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014239969505140589\n",
      "          policy_loss: -0.07177902263020627\n",
      "          total_loss: 0.07834613110547409\n",
      "          vf_explained_var: 0.9410803318023682\n",
      "          vf_loss: 0.1381256437692118\n",
      "    num_agent_steps_sampled: 5727618\n",
      "    num_agent_steps_trained: 5727618\n",
      "    num_steps_sampled: 5727618\n",
      "    num_steps_trained: 5727618\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.76521181001284\n",
      "    ram_util_percent: 53.01360718870347\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05302365130189386\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.0203583445776\n",
      "    mean_inference_ms: 19.45090627195085\n",
      "    mean_raw_obs_processing_ms: 3.286459823251467\n",
      "  time_since_restore: 128212.63678789139\n",
      "  time_this_iter_s: 546.3657667636871\n",
      "  time_total_s: 323030.0003733635\n",
      "  timers:\n",
      "    learn_throughput: 28.103\n",
      "    learn_time_ms: 355694.063\n",
      "    load_throughput: 88191.568\n",
      "    load_time_ms: 113.344\n",
      "    sample_throughput: 52.334\n",
      "    sample_time_ms: 191005.424\n",
      "    update_time_ms: 5.66\n",
      "  timestamp: 1637584353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5727618\n",
      "  training_iteration: 633\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   633</td><td style=\"text-align: right;\">          323030</td><td style=\"text-align: right;\">5727618</td><td style=\"text-align: right;\"> 5.39487</td><td style=\"text-align: right;\">               17.42</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           53.4599</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5737614\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_12-41-56\n",
      "  done: false\n",
      "  episode_len_mean: 52.24083769633508\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.520000000000008\n",
      "  episode_reward_mean: 4.928219895287962\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 112087\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.060124005275558\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014762086289481403\n",
      "          policy_loss: -0.06911826990372394\n",
      "          total_loss: 0.08667335985281893\n",
      "          vf_explained_var: 0.9290012717247009\n",
      "          vf_loss: 0.14276299077791188\n",
      "    num_agent_steps_sampled: 5737614\n",
      "    num_agent_steps_trained: 5737614\n",
      "    num_steps_sampled: 5737614\n",
      "    num_steps_trained: 5737614\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.66749688667497\n",
      "    ram_util_percent: 53.553300124532996\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053013895974373816\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01562696778406\n",
      "    mean_inference_ms: 19.449695352540246\n",
      "    mean_raw_obs_processing_ms: 3.30018445402722\n",
      "  time_since_restore: 128775.13628077507\n",
      "  time_this_iter_s: 562.4994928836823\n",
      "  time_total_s: 323592.4998662472\n",
      "  timers:\n",
      "    learn_throughput: 28.116\n",
      "    learn_time_ms: 355521.518\n",
      "    load_throughput: 88442.87\n",
      "    load_time_ms: 113.022\n",
      "    sample_throughput: 51.964\n",
      "    sample_time_ms: 192362.472\n",
      "    update_time_ms: 5.55\n",
      "  timestamp: 1637584916\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5737614\n",
      "  training_iteration: 634\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   634</td><td style=\"text-align: right;\">          323592</td><td style=\"text-align: right;\">5737614</td><td style=\"text-align: right;\"> 4.92822</td><td style=\"text-align: right;\">               15.52</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           52.2408</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5747610\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_12-50-46\n",
      "  done: false\n",
      "  episode_len_mean: 53.60215053763441\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.46999999999998\n",
      "  episode_reward_mean: 5.319946236559144\n",
      "  episode_reward_min: -0.6500000000000004\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 112273\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0326806343942283\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014699189857102389\n",
      "          policy_loss: -0.0700087514384561\n",
      "          total_loss: 0.09034569188499306\n",
      "          vf_explained_var: 0.9118105173110962\n",
      "          vf_loss: 0.1471946560020323\n",
      "    num_agent_steps_sampled: 5747610\n",
      "    num_agent_steps_trained: 5747610\n",
      "    num_steps_sampled: 5747610\n",
      "    num_steps_trained: 5747610\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.88888888888889\n",
      "    ram_util_percent: 52.84841269841269\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053007762669372814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01124835794425\n",
      "    mean_inference_ms: 19.45063716578942\n",
      "    mean_raw_obs_processing_ms: 3.2911511039409995\n",
      "  time_since_restore: 129305.3328871727\n",
      "  time_this_iter_s: 530.1966063976288\n",
      "  time_total_s: 324122.6964726448\n",
      "  timers:\n",
      "    learn_throughput: 28.128\n",
      "    learn_time_ms: 355379.952\n",
      "    load_throughput: 88143.621\n",
      "    load_time_ms: 113.406\n",
      "    sample_throughput: 52.091\n",
      "    sample_time_ms: 191893.116\n",
      "    update_time_ms: 5.239\n",
      "  timestamp: 1637585446\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5747610\n",
      "  training_iteration: 635\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   635</td><td style=\"text-align: right;\">          324123</td><td style=\"text-align: right;\">5747610</td><td style=\"text-align: right;\"> 5.31995</td><td style=\"text-align: right;\">               19.47</td><td style=\"text-align: right;\">               -0.65</td><td style=\"text-align: right;\">           53.6022</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5757606\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_12-59-40\n",
      "  done: false\n",
      "  episode_len_mean: 54.07027027027027\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 4.9091351351351395\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 112458\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0645296943474967\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014517610338668142\n",
      "          policy_loss: -0.07059492946058431\n",
      "          total_loss: 0.08322471263472926\n",
      "          vf_explained_var: 0.9308857321739197\n",
      "          vf_loss: 0.14139200796936097\n",
      "    num_agent_steps_sampled: 5757606\n",
      "    num_agent_steps_trained: 5757606\n",
      "    num_steps_sampled: 5757606\n",
      "    num_steps_trained: 5757606\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.09737876802096\n",
      "    ram_util_percent: 52.42228047182175\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053009361382632375\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.008401691453464\n",
      "    mean_inference_ms: 19.453054022373866\n",
      "    mean_raw_obs_processing_ms: 3.2828154336975515\n",
      "  time_since_restore: 129839.82465434074\n",
      "  time_this_iter_s: 534.491767168045\n",
      "  time_total_s: 324657.18823981285\n",
      "  timers:\n",
      "    learn_throughput: 28.133\n",
      "    learn_time_ms: 355315.0\n",
      "    load_throughput: 88220.183\n",
      "    load_time_ms: 113.307\n",
      "    sample_throughput: 52.516\n",
      "    sample_time_ms: 190342.069\n",
      "    update_time_ms: 4.902\n",
      "  timestamp: 1637585980\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5757606\n",
      "  training_iteration: 636\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   636</td><td style=\"text-align: right;\">          324657</td><td style=\"text-align: right;\">5757606</td><td style=\"text-align: right;\"> 4.90914</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           54.0703</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5767602\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_13-08-45\n",
      "  done: false\n",
      "  episode_len_mean: 54.358695652173914\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 4.915217391304352\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 112642\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0707705536520624\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014370865645489084\n",
      "          policy_loss: -0.07048014069017129\n",
      "          total_loss: 0.06864415643952793\n",
      "          vf_explained_var: 0.9364398717880249\n",
      "          vf_loss: 0.12709337297114487\n",
      "    num_agent_steps_sampled: 5767602\n",
      "    num_agent_steps_trained: 5767602\n",
      "    num_steps_sampled: 5767602\n",
      "    num_steps_trained: 5767602\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.65894465894466\n",
      "    ram_util_percent: 52.48661518661518\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05301060191227585\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00311991233742\n",
      "    mean_inference_ms: 19.453600753424293\n",
      "    mean_raw_obs_processing_ms: 3.2813254549744184\n",
      "  time_since_restore: 130384.76329612732\n",
      "  time_this_iter_s: 544.9386417865753\n",
      "  time_total_s: 325202.1268815994\n",
      "  timers:\n",
      "    learn_throughput: 28.133\n",
      "    learn_time_ms: 355310.35\n",
      "    load_throughput: 87764.175\n",
      "    load_time_ms: 113.896\n",
      "    sample_throughput: 52.473\n",
      "    sample_time_ms: 190496.205\n",
      "    update_time_ms: 4.807\n",
      "  timestamp: 1637586525\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5767602\n",
      "  training_iteration: 637\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   637</td><td style=\"text-align: right;\">          325202</td><td style=\"text-align: right;\">5767602</td><td style=\"text-align: right;\"> 4.91522</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           54.3587</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5777598\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_13-18-03\n",
      "  done: false\n",
      "  episode_len_mean: 54.037837837837834\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000005\n",
      "  episode_reward_mean: 5.236864864864869\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 112827\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.044213943404845\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014481446160547142\n",
      "          policy_loss: -0.07344497907720626\n",
      "          total_loss: 0.0698556049296906\n",
      "          vf_explained_var: 0.9371852874755859\n",
      "          vf_loss: 0.1307521779849437\n",
      "    num_agent_steps_sampled: 5777598\n",
      "    num_agent_steps_trained: 5777598\n",
      "    num_steps_sampled: 5777598\n",
      "    num_steps_trained: 5777598\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.48643216080403\n",
      "    ram_util_percent: 52.72022613065327\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05300588771241844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.9941527222558\n",
      "    mean_inference_ms: 19.4526223806197\n",
      "    mean_raw_obs_processing_ms: 3.287418833741646\n",
      "  time_since_restore: 130942.95364189148\n",
      "  time_this_iter_s: 558.1903457641602\n",
      "  time_total_s: 325760.3172273636\n",
      "  timers:\n",
      "    learn_throughput: 28.131\n",
      "    learn_time_ms: 355337.574\n",
      "    load_throughput: 87660.571\n",
      "    load_time_ms: 114.031\n",
      "    sample_throughput: 52.636\n",
      "    sample_time_ms: 189908.472\n",
      "    update_time_ms: 4.449\n",
      "  timestamp: 1637587083\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5777598\n",
      "  training_iteration: 638\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   638</td><td style=\"text-align: right;\">          325760</td><td style=\"text-align: right;\">5777598</td><td style=\"text-align: right;\"> 5.23686</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           54.0378</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5787594\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_13-27-28\n",
      "  done: false\n",
      "  episode_len_mean: 53.31550802139037\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.550000000000008\n",
      "  episode_reward_mean: 5.207540106951876\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 113014\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0802018348711084\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014746220133164178\n",
      "          policy_loss: -0.07213711098613941\n",
      "          total_loss: 0.07383041879204329\n",
      "          vf_explained_var: 0.9271757006645203\n",
      "          vf_loss: 0.133175814406288\n",
      "    num_agent_steps_sampled: 5787594\n",
      "    num_agent_steps_trained: 5787594\n",
      "    num_steps_sampled: 5787594\n",
      "    num_steps_trained: 5787594\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.15229813664595\n",
      "    ram_util_percent: 53.165093167701855\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052995678514814876\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.98939015042657\n",
      "    mean_inference_ms: 19.451975135166368\n",
      "    mean_raw_obs_processing_ms: 3.29355683729829\n",
      "  time_since_restore: 131507.1923480034\n",
      "  time_this_iter_s: 564.238706111908\n",
      "  time_total_s: 326324.5559334755\n",
      "  timers:\n",
      "    learn_throughput: 28.127\n",
      "    learn_time_ms: 355382.298\n",
      "    load_throughput: 87663.98\n",
      "    load_time_ms: 114.026\n",
      "    sample_throughput: 52.347\n",
      "    sample_time_ms: 190956.389\n",
      "    update_time_ms: 4.204\n",
      "  timestamp: 1637587648\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5787594\n",
      "  training_iteration: 639\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   639</td><td style=\"text-align: right;\">          326325</td><td style=\"text-align: right;\">5787594</td><td style=\"text-align: right;\"> 5.20754</td><td style=\"text-align: right;\">               15.55</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.3155</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5797590\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_13-36-22\n",
      "  done: false\n",
      "  episode_len_mean: 53.29100529100529\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.580000000000005\n",
      "  episode_reward_mean: 5.196772486772491\n",
      "  episode_reward_min: -0.45000000000000023\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 113203\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.078857628887437\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014608663955567008\n",
      "          policy_loss: -0.06367091410251027\n",
      "          total_loss: 0.08518996936962205\n",
      "          vf_explained_var: 0.9324466586112976\n",
      "          vf_loss: 0.1363690966347524\n",
      "    num_agent_steps_sampled: 5797590\n",
      "    num_agent_steps_trained: 5797590\n",
      "    num_steps_sampled: 5797590\n",
      "    num_steps_trained: 5797590\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.07588466579291\n",
      "    ram_util_percent: 52.599606815203146\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053003416161286926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.989417467012903\n",
      "    mean_inference_ms: 19.45437717312564\n",
      "    mean_raw_obs_processing_ms: 3.285588504916147\n",
      "  time_since_restore: 132041.79570960999\n",
      "  time_this_iter_s: 534.6033616065979\n",
      "  time_total_s: 326859.1592950821\n",
      "  timers:\n",
      "    learn_throughput: 28.122\n",
      "    learn_time_ms: 355448.814\n",
      "    load_throughput: 87668.269\n",
      "    load_time_ms: 114.021\n",
      "    sample_throughput: 52.727\n",
      "    sample_time_ms: 189578.652\n",
      "    update_time_ms: 4.369\n",
      "  timestamp: 1637588182\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5797590\n",
      "  training_iteration: 640\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   640</td><td style=\"text-align: right;\">          326859</td><td style=\"text-align: right;\">5797590</td><td style=\"text-align: right;\"> 5.19677</td><td style=\"text-align: right;\">               17.58</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">            53.291</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5807586\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_13-45-30\n",
      "  done: false\n",
      "  episode_len_mean: 53.18817204301075\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.579999999999988\n",
      "  episode_reward_mean: 5.150645161290327\n",
      "  episode_reward_min: -0.6500000000000004\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 113389\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.051083304628311\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014672607417047996\n",
      "          policy_loss: -0.0640330535692164\n",
      "          total_loss: 0.09336216807842285\n",
      "          vf_explained_var: 0.9289901852607727\n",
      "          vf_loss: 0.144480019003194\n",
      "    num_agent_steps_sampled: 5807586\n",
      "    num_agent_steps_trained: 5807586\n",
      "    num_steps_sampled: 5807586\n",
      "    num_steps_trained: 5807586\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.70869565217392\n",
      "    ram_util_percent: 52.50370843989769\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05300027376408431\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.98752732141239\n",
      "    mean_inference_ms: 19.45473388058735\n",
      "    mean_raw_obs_processing_ms: 3.2838034057755103\n",
      "  time_since_restore: 132589.5642707348\n",
      "  time_this_iter_s: 547.7685611248016\n",
      "  time_total_s: 327406.9278562069\n",
      "  timers:\n",
      "    learn_throughput: 28.127\n",
      "    learn_time_ms: 355383.539\n",
      "    load_throughput: 88802.332\n",
      "    load_time_ms: 112.565\n",
      "    sample_throughput: 52.596\n",
      "    sample_time_ms: 190053.871\n",
      "    update_time_ms: 4.388\n",
      "  timestamp: 1637588730\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5807586\n",
      "  training_iteration: 641\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   641</td><td style=\"text-align: right;\">          327407</td><td style=\"text-align: right;\">5807586</td><td style=\"text-align: right;\"> 5.15065</td><td style=\"text-align: right;\">               17.58</td><td style=\"text-align: right;\">               -0.65</td><td style=\"text-align: right;\">           53.1882</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5817582\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_13-54-35\n",
      "  done: false\n",
      "  episode_len_mean: 53.53191489361702\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.610000000000007\n",
      "  episode_reward_mean: 5.351702127659578\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 113577\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0614491538350364\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014772933633116237\n",
      "          policy_loss: -0.06824270391215756\n",
      "          total_loss: 0.09138922318361803\n",
      "          vf_explained_var: 0.9476010203361511\n",
      "          vf_loss: 0.14659182752536826\n",
      "    num_agent_steps_sampled: 5817582\n",
      "    num_agent_steps_trained: 5817582\n",
      "    num_steps_sampled: 5817582\n",
      "    num_steps_trained: 5817582\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81557271557271\n",
      "    ram_util_percent: 52.656370656370655\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05299129236617203\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.983544024726626\n",
      "    mean_inference_ms: 19.45518706411063\n",
      "    mean_raw_obs_processing_ms: 3.2833943291929826\n",
      "  time_since_restore: 133134.37773895264\n",
      "  time_this_iter_s: 544.8134682178497\n",
      "  time_total_s: 327951.74132442474\n",
      "  timers:\n",
      "    learn_throughput: 28.125\n",
      "    learn_time_ms: 355407.63\n",
      "    load_throughput: 88935.152\n",
      "    load_time_ms: 112.397\n",
      "    sample_throughput: 52.26\n",
      "    sample_time_ms: 191272.853\n",
      "    update_time_ms: 4.431\n",
      "  timestamp: 1637589275\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5817582\n",
      "  training_iteration: 642\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   642</td><td style=\"text-align: right;\">          327952</td><td style=\"text-align: right;\">5817582</td><td style=\"text-align: right;\">  5.3517</td><td style=\"text-align: right;\">               13.61</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           53.5319</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5827578\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_14-03-41\n",
      "  done: false\n",
      "  episode_len_mean: 53.42780748663102\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.53000000000001\n",
      "  episode_reward_mean: 5.156203208556153\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 113764\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.082246882585158\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01439145079026499\n",
      "          policy_loss: -0.07332694528642064\n",
      "          total_loss: 0.0631520707272443\n",
      "          vf_explained_var: 0.9387286305427551\n",
      "          vf_loss: 0.12451596116557358\n",
      "    num_agent_steps_sampled: 5827578\n",
      "    num_agent_steps_trained: 5827578\n",
      "    num_steps_sampled: 5827578\n",
      "    num_steps_trained: 5827578\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7145057766367\n",
      "    ram_util_percent: 53.04634146341464\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05299579748014649\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.97866346662669\n",
      "    mean_inference_ms: 19.455104353888203\n",
      "    mean_raw_obs_processing_ms: 3.2821144783145546\n",
      "  time_since_restore: 133680.38612413406\n",
      "  time_this_iter_s: 546.008385181427\n",
      "  time_total_s: 328497.74970960617\n",
      "  timers:\n",
      "    learn_throughput: 28.133\n",
      "    learn_time_ms: 355315.123\n",
      "    load_throughput: 88729.808\n",
      "    load_time_ms: 112.657\n",
      "    sample_throughput: 52.245\n",
      "    sample_time_ms: 191329.143\n",
      "    update_time_ms: 4.623\n",
      "  timestamp: 1637589821\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5827578\n",
      "  training_iteration: 643\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   643</td><td style=\"text-align: right;\">          328498</td><td style=\"text-align: right;\">5827578</td><td style=\"text-align: right;\">  5.1562</td><td style=\"text-align: right;\">               17.53</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           53.4278</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5837574\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_14-12-49\n",
      "  done: false\n",
      "  episode_len_mean: 52.857142857142854\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000007\n",
      "  episode_reward_mean: 5.574920634920639\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 113953\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0528514152071082\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015026263761694705\n",
      "          policy_loss: -0.06932870123619433\n",
      "          total_loss: 0.08167062579946745\n",
      "          vf_explained_var: 0.9373794198036194\n",
      "          vf_loss: 0.13729613333506638\n",
      "    num_agent_steps_sampled: 5837574\n",
      "    num_agent_steps_trained: 5837574\n",
      "    num_steps_sampled: 5837574\n",
      "    num_steps_trained: 5837574\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.702304737516\n",
      "    ram_util_percent: 53.01574903969271\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052998592943509795\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.976039637866716\n",
      "    mean_inference_ms: 19.456113400830258\n",
      "    mean_raw_obs_processing_ms: 3.2808725750433565\n",
      "  time_since_restore: 134227.9019589424\n",
      "  time_this_iter_s: 547.5158348083496\n",
      "  time_total_s: 329045.2655444145\n",
      "  timers:\n",
      "    learn_throughput: 28.138\n",
      "    learn_time_ms: 355247.338\n",
      "    load_throughput: 88523.672\n",
      "    load_time_ms: 112.919\n",
      "    sample_throughput: 52.639\n",
      "    sample_time_ms: 189898.486\n",
      "    update_time_ms: 4.625\n",
      "  timestamp: 1637590369\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5837574\n",
      "  training_iteration: 644\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   644</td><td style=\"text-align: right;\">          329045</td><td style=\"text-align: right;\">5837574</td><td style=\"text-align: right;\"> 5.57492</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           52.8571</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5847570\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_14-21-55\n",
      "  done: false\n",
      "  episode_len_mean: 53.39572192513369\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.380000000000003\n",
      "  episode_reward_mean: 4.968074866310165\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 114140\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0503187716964737\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014803501904565818\n",
      "          policy_loss: -0.07311417542581233\n",
      "          total_loss: 0.06888060736971703\n",
      "          vf_explained_var: 0.9387772083282471\n",
      "          vf_loss: 0.12877374190578134\n",
      "    num_agent_steps_sampled: 5847570\n",
      "    num_agent_steps_trained: 5847570\n",
      "    num_steps_sampled: 5847570\n",
      "    num_steps_trained: 5847570\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7826923076923\n",
      "    ram_util_percent: 53.00602564102564\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052995714659374235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.97190376996716\n",
      "    mean_inference_ms: 19.455917258812196\n",
      "    mean_raw_obs_processing_ms: 3.2798131145724323\n",
      "  time_since_restore: 134774.20969319344\n",
      "  time_this_iter_s: 546.3077342510223\n",
      "  time_total_s: 329591.57327866554\n",
      "  timers:\n",
      "    learn_throughput: 28.14\n",
      "    learn_time_ms: 355227.949\n",
      "    load_throughput: 88599.548\n",
      "    load_time_ms: 112.822\n",
      "    sample_throughput: 52.19\n",
      "    sample_time_ms: 191529.546\n",
      "    update_time_ms: 4.698\n",
      "  timestamp: 1637590915\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5847570\n",
      "  training_iteration: 645\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   645</td><td style=\"text-align: right;\">          329592</td><td style=\"text-align: right;\">5847570</td><td style=\"text-align: right;\"> 4.96807</td><td style=\"text-align: right;\">               17.38</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           53.3957</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5857566\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_14-31-04\n",
      "  done: false\n",
      "  episode_len_mean: 53.48663101604278\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.47000000000001\n",
      "  episode_reward_mean: 5.138930481283427\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 114327\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0844428091642846\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014568479781745077\n",
      "          policy_loss: -0.07127328626954978\n",
      "          total_loss: 0.06617512951111952\n",
      "          vf_explained_var: 0.9442251324653625\n",
      "          vf_loss: 0.12510402441542806\n",
      "    num_agent_steps_sampled: 5857566\n",
      "    num_agent_steps_trained: 5857566\n",
      "    num_steps_sampled: 5857566\n",
      "    num_steps_trained: 5857566\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81277139208173\n",
      "    ram_util_percent: 52.90102171136654\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529889585661353\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.970402396817274\n",
      "    mean_inference_ms: 19.456603447639072\n",
      "    mean_raw_obs_processing_ms: 3.2791947417297567\n",
      "  time_since_restore: 135322.9327864647\n",
      "  time_this_iter_s: 548.7230932712555\n",
      "  time_total_s: 330140.2963719368\n",
      "  timers:\n",
      "    learn_throughput: 28.149\n",
      "    learn_time_ms: 355107.952\n",
      "    load_throughput: 88730.709\n",
      "    load_time_ms: 112.655\n",
      "    sample_throughput: 51.773\n",
      "    sample_time_ms: 193072.978\n",
      "    update_time_ms: 4.6\n",
      "  timestamp: 1637591464\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5857566\n",
      "  training_iteration: 646\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   646</td><td style=\"text-align: right;\">          330140</td><td style=\"text-align: right;\">5857566</td><td style=\"text-align: right;\"> 5.13893</td><td style=\"text-align: right;\">               15.47</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           53.4866</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5867562\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_14-40-12\n",
      "  done: false\n",
      "  episode_len_mean: 53.34574468085106\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.510000000000009\n",
      "  episode_reward_mean: 5.12202127659575\n",
      "  episode_reward_min: -0.4100000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 114515\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.06207298650799\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015020257603292253\n",
      "          policy_loss: -0.07087512940171478\n",
      "          total_loss: 0.07749730882819403\n",
      "          vf_explained_var: 0.9476809501647949\n",
      "          vf_loss: 0.13477514264011103\n",
      "    num_agent_steps_sampled: 5867562\n",
      "    num_agent_steps_trained: 5867562\n",
      "    num_steps_sampled: 5867562\n",
      "    num_steps_trained: 5867562\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.62813299232737\n",
      "    ram_util_percent: 53.429923273657295\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05297921295162238\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.96745907980051\n",
      "    mean_inference_ms: 19.456866578127844\n",
      "    mean_raw_obs_processing_ms: 3.278855226198887\n",
      "  time_since_restore: 135871.00496077538\n",
      "  time_this_iter_s: 548.0721743106842\n",
      "  time_total_s: 330688.3685462475\n",
      "  timers:\n",
      "    learn_throughput: 28.152\n",
      "    learn_time_ms: 355076.148\n",
      "    load_throughput: 88496.616\n",
      "    load_time_ms: 112.953\n",
      "    sample_throughput: 51.681\n",
      "    sample_time_ms: 193417.003\n",
      "    update_time_ms: 5.03\n",
      "  timestamp: 1637592012\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5867562\n",
      "  training_iteration: 647\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   647</td><td style=\"text-align: right;\">          330688</td><td style=\"text-align: right;\">5867562</td><td style=\"text-align: right;\"> 5.12202</td><td style=\"text-align: right;\">               15.51</td><td style=\"text-align: right;\">               -0.41</td><td style=\"text-align: right;\">           53.3457</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5877558\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_14-49-29\n",
      "  done: false\n",
      "  episode_len_mean: 54.108695652173914\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.569999999999993\n",
      "  episode_reward_mean: 5.1511413043478305\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 114699\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.061803642980545\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014635073111698616\n",
      "          policy_loss: -0.07021942718449399\n",
      "          total_loss: 0.0662292999057077\n",
      "          vf_explained_var: 0.9224540591239929\n",
      "          vf_loss: 0.12372623640561409\n",
      "    num_agent_steps_sampled: 5877558\n",
      "    num_agent_steps_trained: 5877558\n",
      "    num_steps_sampled: 5877558\n",
      "    num_steps_trained: 5877558\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.51712846347608\n",
      "    ram_util_percent: 53.86196473551637\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05296283548624343\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.959344726581065\n",
      "    mean_inference_ms: 19.455320213982336\n",
      "    mean_raw_obs_processing_ms: 3.282920157112154\n",
      "  time_since_restore: 136427.82224607468\n",
      "  time_this_iter_s: 556.8172852993011\n",
      "  time_total_s: 331245.1858315468\n",
      "  timers:\n",
      "    learn_throughput: 28.151\n",
      "    learn_time_ms: 355088.761\n",
      "    load_throughput: 88284.57\n",
      "    load_time_ms: 113.225\n",
      "    sample_throughput: 51.721\n",
      "    sample_time_ms: 193266.297\n",
      "    update_time_ms: 5.395\n",
      "  timestamp: 1637592569\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5877558\n",
      "  training_iteration: 648\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   648</td><td style=\"text-align: right;\">          331245</td><td style=\"text-align: right;\">5877558</td><td style=\"text-align: right;\"> 5.15114</td><td style=\"text-align: right;\">               17.57</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           54.1087</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5887554\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_14-58-33\n",
      "  done: false\n",
      "  episode_len_mean: 53.33510638297872\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 5.410319148936176\n",
      "  episode_reward_min: -0.4900000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 114887\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.044160015156949\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014714441968525218\n",
      "          policy_loss: -0.07050545046903166\n",
      "          total_loss: 0.07375341264081604\n",
      "          vf_explained_var: 0.9425032138824463\n",
      "          vf_loss: 0.13117912370350632\n",
      "    num_agent_steps_sampled: 5887554\n",
      "    num_agent_steps_trained: 5887554\n",
      "    num_steps_sampled: 5887554\n",
      "    num_steps_trained: 5887554\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.79175257731958\n",
      "    ram_util_percent: 54.193041237113405\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05296199432264021\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.954756121090423\n",
      "    mean_inference_ms: 19.454623008677274\n",
      "    mean_raw_obs_processing_ms: 3.288888320406046\n",
      "  time_since_restore: 136971.7240831852\n",
      "  time_this_iter_s: 543.9018371105194\n",
      "  time_total_s: 331789.0876686573\n",
      "  timers:\n",
      "    learn_throughput: 28.154\n",
      "    learn_time_ms: 355050.326\n",
      "    load_throughput: 88479.732\n",
      "    load_time_ms: 112.975\n",
      "    sample_throughput: 52.261\n",
      "    sample_time_ms: 191270.705\n",
      "    update_time_ms: 5.524\n",
      "  timestamp: 1637593113\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5887554\n",
      "  training_iteration: 649\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   649</td><td style=\"text-align: right;\">          331789</td><td style=\"text-align: right;\">5887554</td><td style=\"text-align: right;\"> 5.41032</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           53.3351</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5897550\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_15-07-39\n",
      "  done: false\n",
      "  episode_len_mean: 53.32446808510638\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.530000000000008\n",
      "  episode_reward_mean: 4.714468085106386\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 115075\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.093902541188351\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014595602867384328\n",
      "          policy_loss: -0.07012477206532372\n",
      "          total_loss: 0.06492789493204182\n",
      "          vf_explained_var: 0.9350862503051758\n",
      "          vf_loss: 0.12274108387597174\n",
      "    num_agent_steps_sampled: 5897550\n",
      "    num_agent_steps_trained: 5897550\n",
      "    num_steps_sampled: 5897550\n",
      "    num_steps_trained: 5897550\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.885\n",
      "    ram_util_percent: 53.063717948717944\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05295325512571734\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.951063251071503\n",
      "    mean_inference_ms: 19.455256854512264\n",
      "    mean_raw_obs_processing_ms: 3.2876134729820436\n",
      "  time_since_restore: 137518.36805987358\n",
      "  time_this_iter_s: 546.643976688385\n",
      "  time_total_s: 332335.7316453457\n",
      "  timers:\n",
      "    learn_throughput: 28.155\n",
      "    learn_time_ms: 355037.882\n",
      "    load_throughput: 88328.316\n",
      "    load_time_ms: 113.169\n",
      "    sample_throughput: 51.931\n",
      "    sample_time_ms: 192487.921\n",
      "    update_time_ms: 5.178\n",
      "  timestamp: 1637593659\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5897550\n",
      "  training_iteration: 650\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   650</td><td style=\"text-align: right;\">          332336</td><td style=\"text-align: right;\">5897550</td><td style=\"text-align: right;\"> 4.71447</td><td style=\"text-align: right;\">               15.53</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           53.3245</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5907546\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_15-16-36\n",
      "  done: false\n",
      "  episode_len_mean: 52.755319148936174\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.649999999999988\n",
      "  episode_reward_mean: 5.000425531914898\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 115263\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0695660971494085\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014514591564959847\n",
      "          policy_loss: -0.07250082939639667\n",
      "          total_loss: 0.06595945619450519\n",
      "          vf_explained_var: 0.9145945310592651\n",
      "          vf_loss: 0.12608989126350073\n",
      "    num_agent_steps_sampled: 5907546\n",
      "    num_agent_steps_trained: 5907546\n",
      "    num_steps_sampled: 5907546\n",
      "    num_steps_trained: 5907546\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.09516971279372\n",
      "    ram_util_percent: 52.58133159268929\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0529482602011903\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.951389312905846\n",
      "    mean_inference_ms: 19.456733270528915\n",
      "    mean_raw_obs_processing_ms: 3.278804790007518\n",
      "  time_since_restore: 138054.8108317852\n",
      "  time_this_iter_s: 536.4427719116211\n",
      "  time_total_s: 332872.1744172573\n",
      "  timers:\n",
      "    learn_throughput: 28.15\n",
      "    learn_time_ms: 355097.868\n",
      "    load_throughput: 88382.947\n",
      "    load_time_ms: 113.099\n",
      "    sample_throughput: 52.254\n",
      "    sample_time_ms: 191295.07\n",
      "    update_time_ms: 5.172\n",
      "  timestamp: 1637594196\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5907546\n",
      "  training_iteration: 651\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   651</td><td style=\"text-align: right;\">          332872</td><td style=\"text-align: right;\">5907546</td><td style=\"text-align: right;\"> 5.00043</td><td style=\"text-align: right;\">               17.65</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           52.7553</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5917542\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_15-25-53\n",
      "  done: false\n",
      "  episode_len_mean: 53.70967741935484\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.70999999999999\n",
      "  episode_reward_mean: 5.015913978494629\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 115449\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.075002136646983\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01494236150191768\n",
      "          policy_loss: -0.06968459666412778\n",
      "          total_loss: 0.07816935969985789\n",
      "          vf_explained_var: 0.9204039573669434\n",
      "          vf_loss: 0.13456340891367055\n",
      "    num_agent_steps_sampled: 5917542\n",
      "    num_agent_steps_trained: 5917542\n",
      "    num_steps_sampled: 5917542\n",
      "    num_steps_trained: 5917542\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.57459119496856\n",
      "    ram_util_percent: 52.756855345911944\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052940260296656466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.94575693948093\n",
      "    mean_inference_ms: 19.4555244161658\n",
      "    mean_raw_obs_processing_ms: 3.284039038750463\n",
      "  time_since_restore: 138612.5181953907\n",
      "  time_this_iter_s: 557.7073636054993\n",
      "  time_total_s: 333429.8817808628\n",
      "  timers:\n",
      "    learn_throughput: 28.153\n",
      "    learn_time_ms: 355060.503\n",
      "    load_throughput: 88344.806\n",
      "    load_time_ms: 113.148\n",
      "    sample_throughput: 51.894\n",
      "    sample_time_ms: 192621.605\n",
      "    update_time_ms: 5.247\n",
      "  timestamp: 1637594753\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5917542\n",
      "  training_iteration: 652\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   652</td><td style=\"text-align: right;\">          333430</td><td style=\"text-align: right;\">5917542</td><td style=\"text-align: right;\"> 5.01591</td><td style=\"text-align: right;\">               17.71</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           53.7097</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5927538\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_15-35-14\n",
      "  done: false\n",
      "  episode_len_mean: 53.9144385026738\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.699999999999996\n",
      "  episode_reward_mean: 5.46877005347594\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 115636\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.065086731087252\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01518973819547063\n",
      "          policy_loss: -0.06741425976680515\n",
      "          total_loss: 0.08836539406229532\n",
      "          vf_explained_var: 0.9458716511726379\n",
      "          vf_loss: 0.14182639793244126\n",
      "    num_agent_steps_sampled: 5927538\n",
      "    num_agent_steps_trained: 5927538\n",
      "    num_steps_sampled: 5927538\n",
      "    num_steps_trained: 5927538\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.59225967540574\n",
      "    ram_util_percent: 53.37228464419475\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05294253264115906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.940355346324566\n",
      "    mean_inference_ms: 19.45491448461683\n",
      "    mean_raw_obs_processing_ms: 3.2972813568763635\n",
      "  time_since_restore: 139173.51177954674\n",
      "  time_this_iter_s: 560.9935841560364\n",
      "  time_total_s: 333990.87536501884\n",
      "  timers:\n",
      "    learn_throughput: 28.152\n",
      "    learn_time_ms: 355069.216\n",
      "    load_throughput: 88411.22\n",
      "    load_time_ms: 113.063\n",
      "    sample_throughput: 51.496\n",
      "    sample_time_ms: 194111.852\n",
      "    update_time_ms: 5.006\n",
      "  timestamp: 1637595314\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5927538\n",
      "  training_iteration: 653\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   653</td><td style=\"text-align: right;\">          333991</td><td style=\"text-align: right;\">5927538</td><td style=\"text-align: right;\"> 5.46877</td><td style=\"text-align: right;\">                17.7</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.9144</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5937534\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_15-44-12\n",
      "  done: false\n",
      "  episode_len_mean: 53.36363636363637\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.179679144385031\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 115823\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.068321438797985\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014086869961140147\n",
      "          policy_loss: -0.07251523806207916\n",
      "          total_loss: 0.057982326048509406\n",
      "          vf_explained_var: 0.9452546238899231\n",
      "          vf_loss: 0.1190891274254784\n",
      "    num_agent_steps_sampled: 5937534\n",
      "    num_agent_steps_trained: 5937534\n",
      "    num_steps_sampled: 5937534\n",
      "    num_steps_trained: 5937534\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.12046936114731\n",
      "    ram_util_percent: 52.45462842242504\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05294111683539588\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.94266014021022\n",
      "    mean_inference_ms: 19.455816478985522\n",
      "    mean_raw_obs_processing_ms: 3.28926223850909\n",
      "  time_since_restore: 139711.47065234184\n",
      "  time_this_iter_s: 537.958872795105\n",
      "  time_total_s: 334528.83423781395\n",
      "  timers:\n",
      "    learn_throughput: 28.152\n",
      "    learn_time_ms: 355072.017\n",
      "    load_throughput: 88600.877\n",
      "    load_time_ms: 112.821\n",
      "    sample_throughput: 51.752\n",
      "    sample_time_ms: 193153.159\n",
      "    update_time_ms: 5.153\n",
      "  timestamp: 1637595852\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5937534\n",
      "  training_iteration: 654\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   654</td><td style=\"text-align: right;\">          334529</td><td style=\"text-align: right;\">5937534</td><td style=\"text-align: right;\"> 5.17968</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           53.3636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5947530\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_15-53-11\n",
      "  done: false\n",
      "  episode_len_mean: 52.75132275132275\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.520000000000007\n",
      "  episode_reward_mean: 5.139153439153442\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 116012\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0700680453853915\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01473445257999453\n",
      "          policy_loss: -0.07079976189762752\n",
      "          total_loss: 0.06893858238094706\n",
      "          vf_explained_var: 0.9421616196632385\n",
      "          vf_loss: 0.1268720980822464\n",
      "    num_agent_steps_sampled: 5947530\n",
      "    num_agent_steps_trained: 5947530\n",
      "    num_steps_sampled: 5947530\n",
      "    num_steps_trained: 5947530\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.99323797139141\n",
      "    ram_util_percent: 52.23094928478543\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052938742065207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.945756154194857\n",
      "    mean_inference_ms: 19.458141752311725\n",
      "    mean_raw_obs_processing_ms: 3.2817578112511834\n",
      "  time_since_restore: 140249.93457889557\n",
      "  time_this_iter_s: 538.4639265537262\n",
      "  time_total_s: 335067.2981643677\n",
      "  timers:\n",
      "    learn_throughput: 28.151\n",
      "    learn_time_ms: 355083.835\n",
      "    load_throughput: 88803.78\n",
      "    load_time_ms: 112.563\n",
      "    sample_throughput: 51.966\n",
      "    sample_time_ms: 192357.241\n",
      "    update_time_ms: 5.215\n",
      "  timestamp: 1637596391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5947530\n",
      "  training_iteration: 655\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   655</td><td style=\"text-align: right;\">          335067</td><td style=\"text-align: right;\">5947530</td><td style=\"text-align: right;\"> 5.13915</td><td style=\"text-align: right;\">               13.52</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           52.7513</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5957526\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_16-02-43\n",
      "  done: false\n",
      "  episode_len_mean: 51.72538860103627\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000008\n",
      "  episode_reward_mean: 5.169170984455962\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 116205\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0852166741009217\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015008508826009482\n",
      "          policy_loss: -0.07133515223655729\n",
      "          total_loss: 0.06636290902052244\n",
      "          vf_explained_var: 0.9381973147392273\n",
      "          vf_loss: 0.1243589662996319\n",
      "    num_agent_steps_sampled: 5957526\n",
      "    num_agent_steps_trained: 5957526\n",
      "    num_steps_sampled: 5957526\n",
      "    num_steps_trained: 5957526\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.16017156862745\n",
      "    ram_util_percent: 52.93247549019608\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052921910487881495\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.943271682453208\n",
      "    mean_inference_ms: 19.457338091233876\n",
      "    mean_raw_obs_processing_ms: 3.297807255632221\n",
      "  time_since_restore: 140822.15159893036\n",
      "  time_this_iter_s: 572.21702003479\n",
      "  time_total_s: 335639.51518440247\n",
      "  timers:\n",
      "    learn_throughput: 28.148\n",
      "    learn_time_ms: 355118.76\n",
      "    load_throughput: 88480.274\n",
      "    load_time_ms: 112.974\n",
      "    sample_throughput: 51.348\n",
      "    sample_time_ms: 194670.784\n",
      "    update_time_ms: 5.394\n",
      "  timestamp: 1637596963\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5957526\n",
      "  training_iteration: 656\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   656</td><td style=\"text-align: right;\">          335640</td><td style=\"text-align: right;\">5957526</td><td style=\"text-align: right;\"> 5.16917</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           51.7254</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5967522\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_16-11-49\n",
      "  done: false\n",
      "  episode_len_mean: 52.642105263157895\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.640000000000006\n",
      "  episode_reward_mean: 5.293789473684215\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 116395\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.054576787340593\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015760299179668175\n",
      "          policy_loss: -0.06638647937204761\n",
      "          total_loss: 0.087174392636356\n",
      "          vf_explained_var: 0.9385548233985901\n",
      "          vf_loss: 0.13820270680968302\n",
      "    num_agent_steps_sampled: 5967522\n",
      "    num_agent_steps_trained: 5967522\n",
      "    num_steps_sampled: 5967522\n",
      "    num_steps_trained: 5967522\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8060411311054\n",
      "    ram_util_percent: 53.07390745501285\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05291663783299238\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.941178426520153\n",
      "    mean_inference_ms: 19.457087290493142\n",
      "    mean_raw_obs_processing_ms: 3.296380893273754\n",
      "  time_since_restore: 141367.46422743797\n",
      "  time_this_iter_s: 545.3126285076141\n",
      "  time_total_s: 336184.8278129101\n",
      "  timers:\n",
      "    learn_throughput: 28.148\n",
      "    learn_time_ms: 355120.11\n",
      "    load_throughput: 88394.798\n",
      "    load_time_ms: 113.084\n",
      "    sample_throughput: 51.421\n",
      "    sample_time_ms: 194393.572\n",
      "    update_time_ms: 5.35\n",
      "  timestamp: 1637597509\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5967522\n",
      "  training_iteration: 657\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   657</td><td style=\"text-align: right;\">          336185</td><td style=\"text-align: right;\">5967522</td><td style=\"text-align: right;\"> 5.29379</td><td style=\"text-align: right;\">               13.64</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           52.6421</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5977518\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_16-20-46\n",
      "  done: false\n",
      "  episode_len_mean: 51.9375\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000006\n",
      "  episode_reward_mean: 5.165520833333338\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 116587\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0695187344129784\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014511964539438805\n",
      "          policy_loss: -0.06976058529355733\n",
      "          total_loss: 0.06477366510866064\n",
      "          vf_explained_var: 0.9419015049934387\n",
      "          vf_loss: 0.12216936765878225\n",
      "    num_agent_steps_sampled: 5977518\n",
      "    num_agent_steps_trained: 5977518\n",
      "    num_steps_sampled: 5977518\n",
      "    num_steps_trained: 5977518\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9885267275098\n",
      "    ram_util_percent: 52.54667535853977\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05292112331337657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.94383000058056\n",
      "    mean_inference_ms: 19.458038742664613\n",
      "    mean_raw_obs_processing_ms: 3.2882373162631127\n",
      "  time_since_restore: 141904.79230713844\n",
      "  time_this_iter_s: 537.32807970047\n",
      "  time_total_s: 336722.15589261055\n",
      "  timers:\n",
      "    learn_throughput: 28.15\n",
      "    learn_time_ms: 355093.935\n",
      "    load_throughput: 86249.609\n",
      "    load_time_ms: 115.896\n",
      "    sample_throughput: 51.936\n",
      "    sample_time_ms: 192467.856\n",
      "    update_time_ms: 5.109\n",
      "  timestamp: 1637598046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5977518\n",
      "  training_iteration: 658\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   658</td><td style=\"text-align: right;\">          336722</td><td style=\"text-align: right;\">5977518</td><td style=\"text-align: right;\"> 5.16552</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           51.9375</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5987514\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_16-30-17\n",
      "  done: false\n",
      "  episode_len_mean: 52.58638743455497\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 4.971099476439794\n",
      "  episode_reward_min: -0.6800000000000004\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 116778\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0457588323866984\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015142494967019802\n",
      "          policy_loss: -0.06976458057113953\n",
      "          total_loss: 0.07699660582599889\n",
      "          vf_explained_var: 0.9319100379943848\n",
      "          vf_loss: 0.13272227718565896\n",
      "    num_agent_steps_sampled: 5987514\n",
      "    num_agent_steps_trained: 5987514\n",
      "    num_steps_sampled: 5987514\n",
      "    num_steps_trained: 5987514\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.35061425061424\n",
      "    ram_util_percent: 52.56842751842751\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052917026548969966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.93893672619855\n",
      "    mean_inference_ms: 19.456890904272477\n",
      "    mean_raw_obs_processing_ms: 3.298367224426394\n",
      "  time_since_restore: 142475.3857228756\n",
      "  time_this_iter_s: 570.5934157371521\n",
      "  time_total_s: 337292.7493083477\n",
      "  timers:\n",
      "    learn_throughput: 28.152\n",
      "    learn_time_ms: 355073.396\n",
      "    load_throughput: 86086.911\n",
      "    load_time_ms: 116.115\n",
      "    sample_throughput: 51.22\n",
      "    sample_time_ms: 195157.386\n",
      "    update_time_ms: 5.367\n",
      "  timestamp: 1637598617\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5987514\n",
      "  training_iteration: 659\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   659</td><td style=\"text-align: right;\">          337293</td><td style=\"text-align: right;\">5987514</td><td style=\"text-align: right;\">  4.9711</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.68</td><td style=\"text-align: right;\">           52.5864</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 5997510\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_16-39-12\n",
      "  done: false\n",
      "  episode_len_mean: 52.60526315789474\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.769999999999996\n",
      "  episode_reward_mean: 5.226421052631584\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 116968\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0131938160902045\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015611705728600008\n",
      "          policy_loss: -0.07056169195370256\n",
      "          total_loss: 0.08506807627002062\n",
      "          vf_explained_var: 0.9280446171760559\n",
      "          vf_loss: 0.1401962870244782\n",
      "    num_agent_steps_sampled: 5997510\n",
      "    num_agent_steps_trained: 5997510\n",
      "    num_steps_sampled: 5997510\n",
      "    num_steps_trained: 5997510\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8619109947644\n",
      "    ram_util_percent: 52.19738219895287\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052909939608962654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.940335096538703\n",
      "    mean_inference_ms: 19.457980500115525\n",
      "    mean_raw_obs_processing_ms: 3.2907133367609287\n",
      "  time_since_restore: 143011.04362869263\n",
      "  time_this_iter_s: 535.6579058170319\n",
      "  time_total_s: 337828.40721416473\n",
      "  timers:\n",
      "    learn_throughput: 28.155\n",
      "    learn_time_ms: 355028.759\n",
      "    load_throughput: 86012.982\n",
      "    load_time_ms: 116.215\n",
      "    sample_throughput: 51.498\n",
      "    sample_time_ms: 194103.236\n",
      "    update_time_ms: 5.363\n",
      "  timestamp: 1637599152\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5997510\n",
      "  training_iteration: 660\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   660</td><td style=\"text-align: right;\">          337828</td><td style=\"text-align: right;\">5997510</td><td style=\"text-align: right;\"> 5.22642</td><td style=\"text-align: right;\">               15.77</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           52.6053</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6007506\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_16-48-19\n",
      "  done: false\n",
      "  episode_len_mean: 53.22994652406417\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.569999999999975\n",
      "  episode_reward_mean: 5.0105347593582925\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 117155\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0241402749555655\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01644539771257621\n",
      "          policy_loss: -0.065746110233912\n",
      "          total_loss: 0.09170421181214729\n",
      "          vf_explained_var: 0.9349476099014282\n",
      "          vf_loss: 0.1402270520641749\n",
      "    num_agent_steps_sampled: 6007506\n",
      "    num_agent_steps_trained: 6007506\n",
      "    num_steps_sampled: 6007506\n",
      "    num_steps_trained: 6007506\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7197435897436\n",
      "    ram_util_percent: 52.72166666666667\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052911911503223316\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.937422564393245\n",
      "    mean_inference_ms: 19.458281061490595\n",
      "    mean_raw_obs_processing_ms: 3.2898220057696266\n",
      "  time_since_restore: 143557.63137078285\n",
      "  time_this_iter_s: 546.5877420902252\n",
      "  time_total_s: 338374.99495625496\n",
      "  timers:\n",
      "    learn_throughput: 28.159\n",
      "    learn_time_ms: 354990.283\n",
      "    load_throughput: 86061.342\n",
      "    load_time_ms: 116.15\n",
      "    sample_throughput: 51.22\n",
      "    sample_time_ms: 195156.74\n",
      "    update_time_ms: 5.596\n",
      "  timestamp: 1637599699\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6007506\n",
      "  training_iteration: 661\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   661</td><td style=\"text-align: right;\">          338375</td><td style=\"text-align: right;\">6007506</td><td style=\"text-align: right;\"> 5.01053</td><td style=\"text-align: right;\">               17.57</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           53.2299</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6017502\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_16-57-29\n",
      "  done: false\n",
      "  episode_len_mean: 52.74074074074074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.560000000000008\n",
      "  episode_reward_mean: 5.256825396825401\n",
      "  episode_reward_min: -0.3900000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 117344\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0309103561931825\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015220019125468847\n",
      "          policy_loss: -0.06735249589620877\n",
      "          total_loss: 0.08672154592029867\n",
      "          vf_explained_var: 0.9409132599830627\n",
      "          vf_loss: 0.1397100383055819\n",
      "    num_agent_steps_sampled: 6017502\n",
      "    num_agent_steps_trained: 6017502\n",
      "    num_steps_sampled: 6017502\n",
      "    num_steps_trained: 6017502\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.46364795918367\n",
      "    ram_util_percent: 52.68852040816327\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052900233910057465\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.93813833946056\n",
      "    mean_inference_ms: 19.458427317789646\n",
      "    mean_raw_obs_processing_ms: 3.2880119033391924\n",
      "  time_since_restore: 144107.30390810966\n",
      "  time_this_iter_s: 549.6725373268127\n",
      "  time_total_s: 338924.6674935818\n",
      "  timers:\n",
      "    learn_throughput: 28.157\n",
      "    learn_time_ms: 355010.936\n",
      "    load_throughput: 86083.306\n",
      "    load_time_ms: 116.12\n",
      "    sample_throughput: 51.438\n",
      "    sample_time_ms: 194332.611\n",
      "    update_time_ms: 5.576\n",
      "  timestamp: 1637600249\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6017502\n",
      "  training_iteration: 662\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   662</td><td style=\"text-align: right;\">          338925</td><td style=\"text-align: right;\">6017502</td><td style=\"text-align: right;\"> 5.25683</td><td style=\"text-align: right;\">               15.56</td><td style=\"text-align: right;\">               -0.39</td><td style=\"text-align: right;\">           52.7407</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6027498\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_17-06-48\n",
      "  done: false\n",
      "  episode_len_mean: 52.49738219895288\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.689999999999994\n",
      "  episode_reward_mean: 5.066858638743459\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 117535\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.042133589896811\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015324487308516157\n",
      "          policy_loss: -0.06846440576432888\n",
      "          total_loss: 0.0889748728868646\n",
      "          vf_explained_var: 0.9466001987457275\n",
      "          vf_loss: 0.1429495158596862\n",
      "    num_agent_steps_sampled: 6027498\n",
      "    num_agent_steps_trained: 6027498\n",
      "    num_steps_sampled: 6027498\n",
      "    num_steps_trained: 6027498\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.47493734335839\n",
      "    ram_util_percent: 53.806516290726826\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05289206019394811\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.932692383962312\n",
      "    mean_inference_ms: 19.45683797221937\n",
      "    mean_raw_obs_processing_ms: 3.299320137310239\n",
      "  time_since_restore: 144666.30642962456\n",
      "  time_this_iter_s: 559.0025215148926\n",
      "  time_total_s: 339483.67001509666\n",
      "  timers:\n",
      "    learn_throughput: 28.161\n",
      "    learn_time_ms: 354956.666\n",
      "    load_throughput: 85849.189\n",
      "    load_time_ms: 116.437\n",
      "    sample_throughput: 51.476\n",
      "    sample_time_ms: 194186.896\n",
      "    update_time_ms: 6.01\n",
      "  timestamp: 1637600808\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6027498\n",
      "  training_iteration: 663\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   663</td><td style=\"text-align: right;\">          339484</td><td style=\"text-align: right;\">6027498</td><td style=\"text-align: right;\"> 5.06686</td><td style=\"text-align: right;\">               19.69</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           52.4974</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6037494\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_17-15-53\n",
      "  done: false\n",
      "  episode_len_mean: 52.584210526315786\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.709999999999983\n",
      "  episode_reward_mean: 5.2648421052631615\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 117725\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0541944934900505\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015903458102786955\n",
      "          policy_loss: -0.06572434778338329\n",
      "          total_loss: 0.10520183919671183\n",
      "          vf_explained_var: 0.9404842853546143\n",
      "          vf_loss: 0.15523806554601943\n",
      "    num_agent_steps_sampled: 6037494\n",
      "    num_agent_steps_trained: 6037494\n",
      "    num_steps_sampled: 6037494\n",
      "    num_steps_trained: 6037494\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.85616966580977\n",
      "    ram_util_percent: 53.5901028277635\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288852646436409\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.92896820973053\n",
      "    mean_inference_ms: 19.45660158068863\n",
      "    mean_raw_obs_processing_ms: 3.2981720346844954\n",
      "  time_since_restore: 145212.08533859253\n",
      "  time_this_iter_s: 545.7789089679718\n",
      "  time_total_s: 340029.44892406464\n",
      "  timers:\n",
      "    learn_throughput: 28.163\n",
      "    learn_time_ms: 354939.666\n",
      "    load_throughput: 85336.684\n",
      "    load_time_ms: 117.136\n",
      "    sample_throughput: 51.265\n",
      "    sample_time_ms: 194985.638\n",
      "    update_time_ms: 5.886\n",
      "  timestamp: 1637601353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6037494\n",
      "  training_iteration: 664\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   664</td><td style=\"text-align: right;\">          340029</td><td style=\"text-align: right;\">6037494</td><td style=\"text-align: right;\"> 5.26484</td><td style=\"text-align: right;\">               21.71</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           52.5842</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6047490\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_17-24-50\n",
      "  done: false\n",
      "  episode_len_mean: 52.397905759162306\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.509999999999977\n",
      "  episode_reward_mean: 5.298272251308905\n",
      "  episode_reward_min: -0.38000000000000017\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 117916\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.029645023910875\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01495006131231702\n",
      "          policy_loss: -0.0726321384424274\n",
      "          total_loss: 0.07610651761637544\n",
      "          vf_explained_var: 0.9578936696052551\n",
      "          vf_loss: 0.1349769965602444\n",
      "    num_agent_steps_sampled: 6047490\n",
      "    num_agent_steps_trained: 6047490\n",
      "    num_steps_sampled: 6047490\n",
      "    num_steps_trained: 6047490\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.99373368146216\n",
      "    ram_util_percent: 53.438642297650134\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288910730204371\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.930719609512465\n",
      "    mean_inference_ms: 19.45788593815537\n",
      "    mean_raw_obs_processing_ms: 3.290761546921478\n",
      "  time_since_restore: 145748.46269989014\n",
      "  time_this_iter_s: 536.3773612976074\n",
      "  time_total_s: 340565.82628536224\n",
      "  timers:\n",
      "    learn_throughput: 28.165\n",
      "    learn_time_ms: 354906.993\n",
      "    load_throughput: 85318.485\n",
      "    load_time_ms: 117.161\n",
      "    sample_throughput: 51.312\n",
      "    sample_time_ms: 194809.373\n",
      "    update_time_ms: 5.732\n",
      "  timestamp: 1637601890\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6047490\n",
      "  training_iteration: 665\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   665</td><td style=\"text-align: right;\">          340566</td><td style=\"text-align: right;\">6047490</td><td style=\"text-align: right;\"> 5.29827</td><td style=\"text-align: right;\">               19.51</td><td style=\"text-align: right;\">               -0.38</td><td style=\"text-align: right;\">           52.3979</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6057486\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_17-34-16\n",
      "  done: false\n",
      "  episode_len_mean: 51.984455958549226\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 5.003886010362698\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 118109\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.070487549027286\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015114228532103782\n",
      "          policy_loss: -0.06659050837569153\n",
      "          total_loss: 0.0854641343127159\n",
      "          vf_explained_var: 0.9459447264671326\n",
      "          vf_loss: 0.13832741530722448\n",
      "    num_agent_steps_sampled: 6057486\n",
      "    num_agent_steps_trained: 6057486\n",
      "    num_steps_sampled: 6057486\n",
      "    num_steps_trained: 6057486\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.16299504950497\n",
      "    ram_util_percent: 53.340099009901\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288034390641447\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.930278854289615\n",
      "    mean_inference_ms: 19.45818880478177\n",
      "    mean_raw_obs_processing_ms: 3.3024600858366435\n",
      "  time_since_restore: 146314.77182650566\n",
      "  time_this_iter_s: 566.3091266155243\n",
      "  time_total_s: 341132.13541197777\n",
      "  timers:\n",
      "    learn_throughput: 28.173\n",
      "    learn_time_ms: 354811.511\n",
      "    load_throughput: 85321.61\n",
      "    load_time_ms: 117.157\n",
      "    sample_throughput: 51.442\n",
      "    sample_time_ms: 194314.724\n",
      "    update_time_ms: 5.717\n",
      "  timestamp: 1637602456\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6057486\n",
      "  training_iteration: 666\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   666</td><td style=\"text-align: right;\">          341132</td><td style=\"text-align: right;\">6057486</td><td style=\"text-align: right;\"> 5.00389</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           51.9845</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6067482\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_17-43-28\n",
      "  done: false\n",
      "  episode_len_mean: 51.84455958549223\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 5.132849740932646\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 118302\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.059280160416561\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014839287205398033\n",
      "          policy_loss: -0.07021774447557216\n",
      "          total_loss: 0.06821607740769332\n",
      "          vf_explained_var: 0.9423972964286804\n",
      "          vf_loss: 0.1252208712692167\n",
      "    num_agent_steps_sampled: 6067482\n",
      "    num_agent_steps_trained: 6067482\n",
      "    num_steps_sampled: 6067482\n",
      "    num_steps_trained: 6067482\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.57916137229986\n",
      "    ram_util_percent: 52.7294790343075\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287738554411444\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.933834478485235\n",
      "    mean_inference_ms: 19.459552710866593\n",
      "    mean_raw_obs_processing_ms: 3.301336120619307\n",
      "  time_since_restore: 146866.4241080284\n",
      "  time_this_iter_s: 551.6522815227509\n",
      "  time_total_s: 341683.7876935005\n",
      "  timers:\n",
      "    learn_throughput: 28.174\n",
      "    learn_time_ms: 354792.817\n",
      "    load_throughput: 85493.435\n",
      "    load_time_ms: 116.921\n",
      "    sample_throughput: 51.27\n",
      "    sample_time_ms: 194967.553\n",
      "    update_time_ms: 5.511\n",
      "  timestamp: 1637603008\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6067482\n",
      "  training_iteration: 667\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   667</td><td style=\"text-align: right;\">          341684</td><td style=\"text-align: right;\">6067482</td><td style=\"text-align: right;\"> 5.13285</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           51.8446</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6077478\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_17-52-22\n",
      "  done: false\n",
      "  episode_len_mean: 52.68783068783069\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 4.858042328042331\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 118491\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.076492182222236\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015138760417117212\n",
      "          policy_loss: -0.0652843018330542\n",
      "          total_loss: 0.07191137602878113\n",
      "          vf_explained_var: 0.9254948496818542\n",
      "          vf_loss: 0.12347260966670726\n",
      "    num_agent_steps_sampled: 6077478\n",
      "    num_agent_steps_trained: 6077478\n",
      "    num_steps_sampled: 6077478\n",
      "    num_steps_trained: 6077478\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1479002624672\n",
      "    ram_util_percent: 52.148425196850404\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052876800279283834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.93498846789928\n",
      "    mean_inference_ms: 19.46129651617139\n",
      "    mean_raw_obs_processing_ms: 3.2938751979633025\n",
      "  time_since_restore: 147400.7170574665\n",
      "  time_this_iter_s: 534.2929494380951\n",
      "  time_total_s: 342218.0806429386\n",
      "  timers:\n",
      "    learn_throughput: 28.176\n",
      "    learn_time_ms: 354771.668\n",
      "    load_throughput: 87729.319\n",
      "    load_time_ms: 113.941\n",
      "    sample_throughput: 51.344\n",
      "    sample_time_ms: 194688.353\n",
      "    update_time_ms: 5.704\n",
      "  timestamp: 1637603542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6077478\n",
      "  training_iteration: 668\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   668</td><td style=\"text-align: right;\">          342218</td><td style=\"text-align: right;\">6077478</td><td style=\"text-align: right;\"> 4.85804</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           52.6878</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6087474\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_18-01-19\n",
      "  done: false\n",
      "  episode_len_mean: 51.76165803108808\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.650000000000006\n",
      "  episode_reward_mean: 4.849430051813475\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 118684\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.064583537114193\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014953541060883447\n",
      "          policy_loss: -0.06979356750424372\n",
      "          total_loss: 0.07595041766792539\n",
      "          vf_explained_var: 0.9418963193893433\n",
      "          vf_loss: 0.132323783715854\n",
      "    num_agent_steps_sampled: 6087474\n",
      "    num_agent_steps_trained: 6087474\n",
      "    num_steps_sampled: 6087474\n",
      "    num_steps_trained: 6087474\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9264667535854\n",
      "    ram_util_percent: 52.00443285528032\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052875195621658495\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.938359603520805\n",
      "    mean_inference_ms: 19.46212931823\n",
      "    mean_raw_obs_processing_ms: 3.2863630682446954\n",
      "  time_since_restore: 147937.90165519714\n",
      "  time_this_iter_s: 537.1845977306366\n",
      "  time_total_s: 342755.26524066925\n",
      "  timers:\n",
      "    learn_throughput: 28.177\n",
      "    learn_time_ms: 354756.569\n",
      "    load_throughput: 87792.715\n",
      "    load_time_ms: 113.859\n",
      "    sample_throughput: 52.236\n",
      "    sample_time_ms: 191363.247\n",
      "    update_time_ms: 5.668\n",
      "  timestamp: 1637604079\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6087474\n",
      "  training_iteration: 669\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 23.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   669</td><td style=\"text-align: right;\">          342755</td><td style=\"text-align: right;\">6087474</td><td style=\"text-align: right;\"> 4.84943</td><td style=\"text-align: right;\">               15.65</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           51.7617</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6097470\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_18-10-32\n",
      "  done: false\n",
      "  episode_len_mean: 51.865284974093264\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.510000000000009\n",
      "  episode_reward_mean: 5.023367875647672\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 118877\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.047302767861799\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015661677546807043\n",
      "          policy_loss: -0.07189504316338205\n",
      "          total_loss: 0.10958614339432383\n",
      "          vf_explained_var: 0.9105349183082581\n",
      "          vf_loss: 0.166274954499415\n",
      "    num_agent_steps_sampled: 6097470\n",
      "    num_agent_steps_trained: 6097470\n",
      "    num_steps_sampled: 6097470\n",
      "    num_steps_trained: 6097470\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.57832699619772\n",
      "    ram_util_percent: 52.84195183776932\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288048362971474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.939689551546994\n",
      "    mean_inference_ms: 19.462786190818168\n",
      "    mean_raw_obs_processing_ms: 3.291913921069504\n",
      "  time_since_restore: 148490.916182518\n",
      "  time_this_iter_s: 553.0145273208618\n",
      "  time_total_s: 343308.2797679901\n",
      "  timers:\n",
      "    learn_throughput: 28.179\n",
      "    learn_time_ms: 354727.697\n",
      "    load_throughput: 87847.551\n",
      "    load_time_ms: 113.788\n",
      "    sample_throughput: 51.758\n",
      "    sample_time_ms: 193127.744\n",
      "    update_time_ms: 5.864\n",
      "  timestamp: 1637604632\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6097470\n",
      "  training_iteration: 670\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   670</td><td style=\"text-align: right;\">          343308</td><td style=\"text-align: right;\">6097470</td><td style=\"text-align: right;\"> 5.02337</td><td style=\"text-align: right;\">               15.51</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           51.8653</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6107466\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_18-19-43\n",
      "  done: false\n",
      "  episode_len_mean: 50.98461538461538\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.780000000000005\n",
      "  episode_reward_mean: 4.909230769230772\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 195\n",
      "  episodes_total: 119072\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0649731078540463\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01567132195754745\n",
      "          policy_loss: -0.06787280860846157\n",
      "          total_loss: 0.08572503860692911\n",
      "          vf_explained_var: 0.9492601156234741\n",
      "          vf_loss: 0.13854634809180585\n",
      "    num_agent_steps_sampled: 6107466\n",
      "    num_agent_steps_trained: 6107466\n",
      "    num_steps_sampled: 6107466\n",
      "    num_steps_trained: 6107466\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.79694656488549\n",
      "    ram_util_percent: 53.059669211195924\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287938009242669\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.940945242202634\n",
      "    mean_inference_ms: 19.462171608056632\n",
      "    mean_raw_obs_processing_ms: 3.2907333422322504\n",
      "  time_since_restore: 149041.7804019451\n",
      "  time_this_iter_s: 550.8642194271088\n",
      "  time_total_s: 343859.1439874172\n",
      "  timers:\n",
      "    learn_throughput: 28.182\n",
      "    learn_time_ms: 354691.357\n",
      "    load_throughput: 87752.474\n",
      "    load_time_ms: 113.911\n",
      "    sample_throughput: 51.634\n",
      "    sample_time_ms: 193591.75\n",
      "    update_time_ms: 5.639\n",
      "  timestamp: 1637605183\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6107466\n",
      "  training_iteration: 671\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   671</td><td style=\"text-align: right;\">          343859</td><td style=\"text-align: right;\">6107466</td><td style=\"text-align: right;\"> 4.90923</td><td style=\"text-align: right;\">               15.78</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           50.9846</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6117462\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_18-28-39\n",
      "  done: false\n",
      "  episode_len_mean: 51.83419689119171\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 5.264248704663217\n",
      "  episode_reward_min: -0.7000000000000004\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 119265\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.030284382133599\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01491946258346376\n",
      "          policy_loss: -0.06866228250481977\n",
      "          total_loss: 0.08447788294376211\n",
      "          vf_explained_var: 0.9422630071640015\n",
      "          vf_loss: 0.13945460711104654\n",
      "    num_agent_steps_sampled: 6117462\n",
      "    num_agent_steps_trained: 6117462\n",
      "    num_steps_sampled: 6117462\n",
      "    num_steps_trained: 6117462\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.09594240837694\n",
      "    ram_util_percent: 52.840575916230364\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052887540807391324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.944231981893157\n",
      "    mean_inference_ms: 19.46341317637587\n",
      "    mean_raw_obs_processing_ms: 3.283408504608763\n",
      "  time_since_restore: 149577.75367808342\n",
      "  time_this_iter_s: 535.9732761383057\n",
      "  time_total_s: 344395.1172635555\n",
      "  timers:\n",
      "    learn_throughput: 28.184\n",
      "    learn_time_ms: 354673.349\n",
      "    load_throughput: 87691.502\n",
      "    load_time_ms: 113.991\n",
      "    sample_throughput: 51.998\n",
      "    sample_time_ms: 192238.71\n",
      "    update_time_ms: 5.816\n",
      "  timestamp: 1637605719\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6117462\n",
      "  training_iteration: 672\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   672</td><td style=\"text-align: right;\">          344395</td><td style=\"text-align: right;\">6117462</td><td style=\"text-align: right;\"> 5.26425</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">                -0.7</td><td style=\"text-align: right;\">           51.8342</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6127458\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_18-37-37\n",
      "  done: false\n",
      "  episode_len_mean: 51.59487179487179\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.560000000000008\n",
      "  episode_reward_mean: 5.30292307692308\n",
      "  episode_reward_min: -0.4200000000000002\n",
      "  episodes_this_iter: 195\n",
      "  episodes_total: 119460\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0565980736989093\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014709150177070793\n",
      "          policy_loss: -0.07487590799469783\n",
      "          total_loss: 0.07654878527083862\n",
      "          vf_explained_var: 0.9409933686256409\n",
      "          vf_loss: 0.138481390188882\n",
      "    num_agent_steps_sampled: 6127458\n",
      "    num_agent_steps_trained: 6127458\n",
      "    num_steps_sampled: 6127458\n",
      "    num_steps_trained: 6127458\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.04302477183833\n",
      "    ram_util_percent: 52.520469361147335\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052873990127027655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.948011503535017\n",
      "    mean_inference_ms: 19.464139932312946\n",
      "    mean_raw_obs_processing_ms: 3.276136258326787\n",
      "  time_since_restore: 150114.8574552536\n",
      "  time_this_iter_s: 537.1037771701813\n",
      "  time_total_s: 344932.2210407257\n",
      "  timers:\n",
      "    learn_throughput: 28.179\n",
      "    learn_time_ms: 354732.182\n",
      "    load_throughput: 87923.489\n",
      "    load_time_ms: 113.69\n",
      "    sample_throughput: 52.613\n",
      "    sample_time_ms: 189990.241\n",
      "    update_time_ms: 5.836\n",
      "  timestamp: 1637606257\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6127458\n",
      "  training_iteration: 673\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   673</td><td style=\"text-align: right;\">          344932</td><td style=\"text-align: right;\">6127458</td><td style=\"text-align: right;\"> 5.30292</td><td style=\"text-align: right;\">               15.56</td><td style=\"text-align: right;\">               -0.42</td><td style=\"text-align: right;\">           51.5949</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6137454\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_18-46-57\n",
      "  done: false\n",
      "  episode_len_mean: 52.415789473684214\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.550000000000008\n",
      "  episode_reward_mean: 5.050842105263161\n",
      "  episode_reward_min: -0.6200000000000003\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 119650\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0515198732715056\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015005564144110264\n",
      "          policy_loss: -0.06977159687215183\n",
      "          total_loss: 0.06946969872596416\n",
      "          vf_explained_var: 0.9513999223709106\n",
      "          vf_loss: 0.12557194299199226\n",
      "    num_agent_steps_sampled: 6137454\n",
      "    num_agent_steps_trained: 6137454\n",
      "    num_steps_sampled: 6137454\n",
      "    num_steps_trained: 6137454\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.381\n",
      "    ram_util_percent: 53.404500000000006\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052864404780867735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.944570378386068\n",
      "    mean_inference_ms: 19.46415938915478\n",
      "    mean_raw_obs_processing_ms: 3.2873323095321254\n",
      "  time_since_restore: 150675.6909890175\n",
      "  time_this_iter_s: 560.8335337638855\n",
      "  time_total_s: 345493.0545744896\n",
      "  timers:\n",
      "    learn_throughput: 28.176\n",
      "    learn_time_ms: 354776.293\n",
      "    load_throughput: 88575.252\n",
      "    load_time_ms: 112.853\n",
      "    sample_throughput: 52.211\n",
      "    sample_time_ms: 191452.126\n",
      "    update_time_ms: 6.05\n",
      "  timestamp: 1637606817\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6137454\n",
      "  training_iteration: 674\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   674</td><td style=\"text-align: right;\">          345493</td><td style=\"text-align: right;\">6137454</td><td style=\"text-align: right;\"> 5.05084</td><td style=\"text-align: right;\">               15.55</td><td style=\"text-align: right;\">               -0.62</td><td style=\"text-align: right;\">           52.4158</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6147450\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_18-55-52\n",
      "  done: false\n",
      "  episode_len_mean: 52.068062827225134\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.111151832460737\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 119841\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0639675641155626\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015172693046424157\n",
      "          policy_loss: -0.0680759010070724\n",
      "          total_loss: 0.07847780183880337\n",
      "          vf_explained_var: 0.944877564907074\n",
      "          vf_loss: 0.13262808564657638\n",
      "    num_agent_steps_sampled: 6147450\n",
      "    num_agent_steps_trained: 6147450\n",
      "    num_steps_sampled: 6147450\n",
      "    num_steps_trained: 6147450\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.07152230971128\n",
      "    ram_util_percent: 53.16902887139109\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287517892458223\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.944831211621473\n",
      "    mean_inference_ms: 19.46511845396863\n",
      "    mean_raw_obs_processing_ms: 3.2801014304559644\n",
      "  time_since_restore: 151210.11246538162\n",
      "  time_this_iter_s: 534.4214763641357\n",
      "  time_total_s: 346027.47605085373\n",
      "  timers:\n",
      "    learn_throughput: 28.171\n",
      "    learn_time_ms: 354827.616\n",
      "    load_throughput: 88748.534\n",
      "    load_time_ms: 112.633\n",
      "    sample_throughput: 52.279\n",
      "    sample_time_ms: 191206.012\n",
      "    update_time_ms: 6.0\n",
      "  timestamp: 1637607352\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6147450\n",
      "  training_iteration: 675\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   675</td><td style=\"text-align: right;\">          346027</td><td style=\"text-align: right;\">6147450</td><td style=\"text-align: right;\"> 5.11115</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           52.0681</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6157446\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_19-05-00\n",
      "  done: false\n",
      "  episode_len_mean: 53.02105263157895\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.700000000000003\n",
      "  episode_reward_mean: 5.206631578947372\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 120031\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0381848420244624\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015006673001916033\n",
      "          policy_loss: -0.06673954513675104\n",
      "          total_loss: 0.08866516918277954\n",
      "          vf_explained_var: 0.9312741160392761\n",
      "          vf_loss: 0.1415994849390758\n",
      "    num_agent_steps_sampled: 6157446\n",
      "    num_agent_steps_trained: 6157446\n",
      "    num_steps_sampled: 6157446\n",
      "    num_steps_trained: 6157446\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.78914431673051\n",
      "    ram_util_percent: 53.177394636015315\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052873539053693075\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.94341739472012\n",
      "    mean_inference_ms: 19.46590458194345\n",
      "    mean_raw_obs_processing_ms: 3.278888571082968\n",
      "  time_since_restore: 151758.6862783432\n",
      "  time_this_iter_s: 548.5738129615784\n",
      "  time_total_s: 346576.0498638153\n",
      "  timers:\n",
      "    learn_throughput: 28.166\n",
      "    learn_time_ms: 354898.459\n",
      "    load_throughput: 88865.952\n",
      "    load_time_ms: 112.484\n",
      "    sample_throughput: 52.788\n",
      "    sample_time_ms: 189361.53\n",
      "    update_time_ms: 5.987\n",
      "  timestamp: 1637607900\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6157446\n",
      "  training_iteration: 676\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   676</td><td style=\"text-align: right;\">          346576</td><td style=\"text-align: right;\">6157446</td><td style=\"text-align: right;\"> 5.20663</td><td style=\"text-align: right;\">                17.7</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           53.0211</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6167442\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_19-14-12\n",
      "  done: false\n",
      "  episode_len_mean: 52.735449735449734\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.380000000000011\n",
      "  episode_reward_mean: 4.728571428571432\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 120220\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.075902780998184\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014764033430434097\n",
      "          policy_loss: -0.0726697923859743\n",
      "          total_loss: 0.07269753461136368\n",
      "          vf_explained_var: 0.9393609762191772\n",
      "          vf_loss: 0.13249204011613422\n",
      "    num_agent_steps_sampled: 6167442\n",
      "    num_agent_steps_trained: 6167442\n",
      "    num_steps_sampled: 6167442\n",
      "    num_steps_trained: 6167442\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.76442185514613\n",
      "    ram_util_percent: 53.1120711562897\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052872431650296724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.942517802516825\n",
      "    mean_inference_ms: 19.46405585274894\n",
      "    mean_raw_obs_processing_ms: 3.2836901001690086\n",
      "  time_since_restore: 152310.3613474369\n",
      "  time_this_iter_s: 551.6750690937042\n",
      "  time_total_s: 347127.724932909\n",
      "  timers:\n",
      "    learn_throughput: 28.165\n",
      "    learn_time_ms: 354911.433\n",
      "    load_throughput: 88819.414\n",
      "    load_time_ms: 112.543\n",
      "    sample_throughput: 52.791\n",
      "    sample_time_ms: 189350.798\n",
      "    update_time_ms: 5.98\n",
      "  timestamp: 1637608452\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6167442\n",
      "  training_iteration: 677\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   677</td><td style=\"text-align: right;\">          347128</td><td style=\"text-align: right;\">6167442</td><td style=\"text-align: right;\"> 4.72857</td><td style=\"text-align: right;\">               15.38</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           52.7354</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6177438\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_19-23-12\n",
      "  done: false\n",
      "  episode_len_mean: 52.91005291005291\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.650000000000006\n",
      "  episode_reward_mean: 5.288624338624342\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 120409\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.04213205245604\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014716888478020364\n",
      "          policy_loss: -0.06604335122507934\n",
      "          total_loss: 0.08700215588984306\n",
      "          vf_explained_var: 0.9426924586296082\n",
      "          vf_loss: 0.1399399151676802\n",
      "    num_agent_steps_sampled: 6177438\n",
      "    num_agent_steps_trained: 6177438\n",
      "    num_steps_sampled: 6177438\n",
      "    num_steps_trained: 6177438\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.085084306096\n",
      "    ram_util_percent: 52.32503242542152\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052869857875284886\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.94558418878208\n",
      "    mean_inference_ms: 19.465015996433486\n",
      "    mean_raw_obs_processing_ms: 3.276366486081653\n",
      "  time_since_restore: 152850.27739715576\n",
      "  time_this_iter_s: 539.9160497188568\n",
      "  time_total_s: 347667.64098262787\n",
      "  timers:\n",
      "    learn_throughput: 28.161\n",
      "    learn_time_ms: 354960.686\n",
      "    load_throughput: 88725.395\n",
      "    load_time_ms: 112.662\n",
      "    sample_throughput: 52.648\n",
      "    sample_time_ms: 189863.657\n",
      "    update_time_ms: 5.736\n",
      "  timestamp: 1637608992\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6177438\n",
      "  training_iteration: 678\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   678</td><td style=\"text-align: right;\">          347668</td><td style=\"text-align: right;\">6177438</td><td style=\"text-align: right;\"> 5.28862</td><td style=\"text-align: right;\">               13.65</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           52.9101</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6187434\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_19-32-14\n",
      "  done: false\n",
      "  episode_len_mean: 52.518324607329845\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.609999999999975\n",
      "  episode_reward_mean: 5.471937172774873\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 120600\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0179906392193225\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015909215794979097\n",
      "          policy_loss: -0.06548373314793328\n",
      "          total_loss: 0.09338853779849028\n",
      "          vf_explained_var: 0.9470499157905579\n",
      "          vf_loss: 0.14280899474041978\n",
      "    num_agent_steps_sampled: 6187434\n",
      "    num_agent_steps_trained: 6187434\n",
      "    num_steps_sampled: 6187434\n",
      "    num_steps_trained: 6187434\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02108667529107\n",
      "    ram_util_percent: 52.21293661060801\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288894610678082\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.950426374960635\n",
      "    mean_inference_ms: 19.467309779527564\n",
      "    mean_raw_obs_processing_ms: 3.2696501903970296\n",
      "  time_since_restore: 153392.3256072998\n",
      "  time_this_iter_s: 542.048210144043\n",
      "  time_total_s: 348209.6891927719\n",
      "  timers:\n",
      "    learn_throughput: 28.158\n",
      "    learn_time_ms: 354991.575\n",
      "    load_throughput: 88751.577\n",
      "    load_time_ms: 112.629\n",
      "    sample_throughput: 52.522\n",
      "    sample_time_ms: 190318.977\n",
      "    update_time_ms: 5.338\n",
      "  timestamp: 1637609534\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6187434\n",
      "  training_iteration: 679\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   679</td><td style=\"text-align: right;\">          348210</td><td style=\"text-align: right;\">6187434</td><td style=\"text-align: right;\"> 5.47194</td><td style=\"text-align: right;\">               23.61</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           52.5183</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6197430\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_19-41-24\n",
      "  done: false\n",
      "  episode_len_mean: 53.149732620320854\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.609999999999964\n",
      "  episode_reward_mean: 5.229144385026743\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 120787\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0235907915366225\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01523975461452323\n",
      "          policy_loss: -0.06779927657678098\n",
      "          total_loss: 0.10198452566911295\n",
      "          vf_explained_var: 0.9340812563896179\n",
      "          vf_loss: 0.15530164249832312\n",
      "    num_agent_steps_sampled: 6197430\n",
      "    num_agent_steps_trained: 6197430\n",
      "    num_steps_sampled: 6197430\n",
      "    num_steps_trained: 6197430\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.83477707006368\n",
      "    ram_util_percent: 52.44000000000001\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287879439546866\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.94970479165216\n",
      "    mean_inference_ms: 19.467361177922566\n",
      "    mean_raw_obs_processing_ms: 3.2685319582992283\n",
      "  time_since_restore: 153942.23209309578\n",
      "  time_this_iter_s: 549.9064857959747\n",
      "  time_total_s: 348759.5956785679\n",
      "  timers:\n",
      "    learn_throughput: 28.154\n",
      "    learn_time_ms: 355046.596\n",
      "    load_throughput: 88978.449\n",
      "    load_time_ms: 112.342\n",
      "    sample_throughput: 52.623\n",
      "    sample_time_ms: 189953.407\n",
      "    update_time_ms: 5.065\n",
      "  timestamp: 1637610084\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6197430\n",
      "  training_iteration: 680\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   680</td><td style=\"text-align: right;\">          348760</td><td style=\"text-align: right;\">6197430</td><td style=\"text-align: right;\"> 5.22914</td><td style=\"text-align: right;\">               23.61</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           53.1497</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6207426\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_19-50-44\n",
      "  done: false\n",
      "  episode_len_mean: 53.148148148148145\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.400000000000002\n",
      "  episode_reward_mean: 5.148730158730163\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 120976\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0159726183577233\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015690927528856122\n",
      "          policy_loss: -0.06979198286049891\n",
      "          total_loss: 0.09694274922681966\n",
      "          vf_explained_var: 0.9282658100128174\n",
      "          vf_loss: 0.15114856316506053\n",
      "    num_agent_steps_sampled: 6207426\n",
      "    num_agent_steps_trained: 6207426\n",
      "    num_steps_sampled: 6207426\n",
      "    num_steps_trained: 6207426\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.55739348370926\n",
      "    ram_util_percent: 53.14298245614035\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287348754709421\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.945410173678056\n",
      "    mean_inference_ms: 19.467912141365613\n",
      "    mean_raw_obs_processing_ms: 3.2736334827282656\n",
      "  time_since_restore: 154501.97268295288\n",
      "  time_this_iter_s: 559.7405898571014\n",
      "  time_total_s: 349319.336268425\n",
      "  timers:\n",
      "    learn_throughput: 28.148\n",
      "    learn_time_ms: 355122.22\n",
      "    load_throughput: 88802.577\n",
      "    load_time_ms: 112.564\n",
      "    sample_throughput: 52.4\n",
      "    sample_time_ms: 190764.705\n",
      "    update_time_ms: 5.041\n",
      "  timestamp: 1637610644\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6207426\n",
      "  training_iteration: 681\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   681</td><td style=\"text-align: right;\">          349319</td><td style=\"text-align: right;\">6207426</td><td style=\"text-align: right;\"> 5.14873</td><td style=\"text-align: right;\">                17.4</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           53.1481</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6217422\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_19-59-39\n",
      "  done: false\n",
      "  episode_len_mean: 52.62105263157895\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.46000000000001\n",
      "  episode_reward_mean: 5.335631578947373\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 121166\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0187400438220626\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014707570343269858\n",
      "          policy_loss: -0.06532719498491206\n",
      "          total_loss: 0.09255445916843678\n",
      "          vf_explained_var: 0.9454560279846191\n",
      "          vf_loss: 0.14456337024813076\n",
      "    num_agent_steps_sampled: 6217422\n",
      "    num_agent_steps_trained: 6217422\n",
      "    num_steps_sampled: 6217422\n",
      "    num_steps_trained: 6217422\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.90773263433815\n",
      "    ram_util_percent: 52.735779816513755\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052880993745302696\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.945880244599422\n",
      "    mean_inference_ms: 19.467850161479156\n",
      "    mean_raw_obs_processing_ms: 3.2663107717209057\n",
      "  time_since_restore: 155036.73137021065\n",
      "  time_this_iter_s: 534.7586872577667\n",
      "  time_total_s: 349854.09495568275\n",
      "  timers:\n",
      "    learn_throughput: 28.147\n",
      "    learn_time_ms: 355136.146\n",
      "    load_throughput: 88842.469\n",
      "    load_time_ms: 112.514\n",
      "    sample_throughput: 52.437\n",
      "    sample_time_ms: 190630.24\n",
      "    update_time_ms: 5.165\n",
      "  timestamp: 1637611179\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6217422\n",
      "  training_iteration: 682\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   682</td><td style=\"text-align: right;\">          349854</td><td style=\"text-align: right;\">6217422</td><td style=\"text-align: right;\"> 5.33563</td><td style=\"text-align: right;\">               15.46</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           52.6211</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6227418\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_20-08-44\n",
      "  done: false\n",
      "  episode_len_mean: 53.66129032258065\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.659999999999975\n",
      "  episode_reward_mean: 5.080860215053768\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 121352\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0180623825774133\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015195738797933477\n",
      "          policy_loss: -0.06224563511815783\n",
      "          total_loss: 0.0947674511496185\n",
      "          vf_explained_var: 0.9463649392127991\n",
      "          vf_loss: 0.14257591660527222\n",
      "    num_agent_steps_sampled: 6227418\n",
      "    num_agent_steps_trained: 6227418\n",
      "    num_steps_sampled: 6227418\n",
      "    num_steps_trained: 6227418\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.74074550128535\n",
      "    ram_util_percent: 52.81580976863752\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287941287255019\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.94205755640785\n",
      "    mean_inference_ms: 19.469662288319675\n",
      "    mean_raw_obs_processing_ms: 3.2655640597455493\n",
      "  time_since_restore: 155581.87219786644\n",
      "  time_this_iter_s: 545.1408276557922\n",
      "  time_total_s: 350399.23578333855\n",
      "  timers:\n",
      "    learn_throughput: 28.149\n",
      "    learn_time_ms: 355114.24\n",
      "    load_throughput: 88777.812\n",
      "    load_time_ms: 112.596\n",
      "    sample_throughput: 52.211\n",
      "    sample_time_ms: 191455.434\n",
      "    update_time_ms: 5.514\n",
      "  timestamp: 1637611724\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6227418\n",
      "  training_iteration: 683\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   683</td><td style=\"text-align: right;\">          350399</td><td style=\"text-align: right;\">6227418</td><td style=\"text-align: right;\"> 5.08086</td><td style=\"text-align: right;\">               17.66</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           53.6613</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6237414\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_20-17-50\n",
      "  done: false\n",
      "  episode_len_mean: 53.51075268817204\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000007\n",
      "  episode_reward_mean: 5.4512903225806495\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 121538\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0074780194993957\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015297458353223816\n",
      "          policy_loss: -0.0697105207299088\n",
      "          total_loss: 0.08073006263844455\n",
      "          vf_explained_var: 0.9507426023483276\n",
      "          vf_loss: 0.13566583977136987\n",
      "    num_agent_steps_sampled: 6237414\n",
      "    num_agent_steps_trained: 6237414\n",
      "    num_steps_sampled: 6237414\n",
      "    num_steps_trained: 6237414\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.72516046213093\n",
      "    ram_util_percent: 53.23042362002566\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288374586039877\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.93859127781626\n",
      "    mean_inference_ms: 19.468744093748942\n",
      "    mean_raw_obs_processing_ms: 3.264185016774867\n",
      "  time_since_restore: 156127.73068737984\n",
      "  time_this_iter_s: 545.8584895133972\n",
      "  time_total_s: 350945.09427285194\n",
      "  timers:\n",
      "    learn_throughput: 28.152\n",
      "    learn_time_ms: 355072.796\n",
      "    load_throughput: 88527.149\n",
      "    load_time_ms: 112.915\n",
      "    sample_throughput: 52.611\n",
      "    sample_time_ms: 189998.816\n",
      "    update_time_ms: 5.467\n",
      "  timestamp: 1637612270\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6237414\n",
      "  training_iteration: 684\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   684</td><td style=\"text-align: right;\">          350945</td><td style=\"text-align: right;\">6237414</td><td style=\"text-align: right;\"> 5.45129</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.5108</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6247410\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_20-27-00\n",
      "  done: false\n",
      "  episode_len_mean: 52.43455497382199\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000008\n",
      "  episode_reward_mean: 5.011937172774872\n",
      "  episode_reward_min: -0.45000000000000023\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 121729\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0276616194640775\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015006988422828145\n",
      "          policy_loss: -0.06554726141754605\n",
      "          total_loss: 0.08396808708695978\n",
      "          vf_explained_var: 0.9361488819122314\n",
      "          vf_loss: 0.13560416822940724\n",
      "    num_agent_steps_sampled: 6247410\n",
      "    num_agent_steps_trained: 6247410\n",
      "    num_steps_sampled: 6247410\n",
      "    num_steps_trained: 6247410\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.71375796178344\n",
      "    ram_util_percent: 53.70828025477706\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288697723764473\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.93822803193304\n",
      "    mean_inference_ms: 19.469374184943437\n",
      "    mean_raw_obs_processing_ms: 3.263012798487325\n",
      "  time_since_restore: 156678.21841025352\n",
      "  time_this_iter_s: 550.4877228736877\n",
      "  time_total_s: 351495.58199572563\n",
      "  timers:\n",
      "    learn_throughput: 28.157\n",
      "    learn_time_ms: 355004.473\n",
      "    load_throughput: 88377.861\n",
      "    load_time_ms: 113.105\n",
      "    sample_throughput: 52.151\n",
      "    sample_time_ms: 191673.314\n",
      "    update_time_ms: 5.599\n",
      "  timestamp: 1637612820\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6247410\n",
      "  training_iteration: 685\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   685</td><td style=\"text-align: right;\">          351496</td><td style=\"text-align: right;\">6247410</td><td style=\"text-align: right;\"> 5.01194</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">           52.4346</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6257406\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_20-36-11\n",
      "  done: false\n",
      "  episode_len_mean: 52.6578947368421\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.650000000000006\n",
      "  episode_reward_mean: 5.135105263157898\n",
      "  episode_reward_min: -0.45000000000000023\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 121919\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0071031097906182\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01514642076896838\n",
      "          policy_loss: -0.06981962004121604\n",
      "          total_loss: 0.08506938952977139\n",
      "          vf_explained_var: 0.9174328446388245\n",
      "          vf_loss: 0.14045459911331018\n",
      "    num_agent_steps_sampled: 6257406\n",
      "    num_agent_steps_trained: 6257406\n",
      "    num_steps_sampled: 6257406\n",
      "    num_steps_trained: 6257406\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82137404580153\n",
      "    ram_util_percent: 53.68829516539439\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287592652653082\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.939220776149504\n",
      "    mean_inference_ms: 19.468788680665636\n",
      "    mean_raw_obs_processing_ms: 3.2617449795298907\n",
      "  time_since_restore: 157228.52958917618\n",
      "  time_this_iter_s: 550.3111789226532\n",
      "  time_total_s: 352045.8931746483\n",
      "  timers:\n",
      "    learn_throughput: 28.158\n",
      "    learn_time_ms: 354997.281\n",
      "    load_throughput: 88535.748\n",
      "    load_time_ms: 112.904\n",
      "    sample_throughput: 52.102\n",
      "    sample_time_ms: 191854.081\n",
      "    update_time_ms: 5.633\n",
      "  timestamp: 1637613371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6257406\n",
      "  training_iteration: 686\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   686</td><td style=\"text-align: right;\">          352046</td><td style=\"text-align: right;\">6257406</td><td style=\"text-align: right;\"> 5.13511</td><td style=\"text-align: right;\">               15.65</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">           52.6579</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6267402\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_20-45-21\n",
      "  done: false\n",
      "  episode_len_mean: 52.4869109947644\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.246910994764402\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 122110\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0081808263996996\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015511931208201253\n",
      "          policy_loss: -0.06876373069524079\n",
      "          total_loss: 0.09114956733154579\n",
      "          vf_explained_var: 0.9407913088798523\n",
      "          vf_loss: 0.1446569877023057\n",
      "    num_agent_steps_sampled: 6267402\n",
      "    num_agent_steps_trained: 6267402\n",
      "    num_steps_sampled: 6267402\n",
      "    num_steps_trained: 6267402\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81605095541401\n",
      "    ram_util_percent: 53.31222929936305\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287635096115014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.939767704665915\n",
      "    mean_inference_ms: 19.467834679302648\n",
      "    mean_raw_obs_processing_ms: 3.2607212093052467\n",
      "  time_since_restore: 157779.2666323185\n",
      "  time_this_iter_s: 550.7370431423187\n",
      "  time_total_s: 352596.6302177906\n",
      "  timers:\n",
      "    learn_throughput: 28.157\n",
      "    learn_time_ms: 355012.566\n",
      "    load_throughput: 88847.572\n",
      "    load_time_ms: 112.507\n",
      "    sample_throughput: 52.131\n",
      "    sample_time_ms: 191745.959\n",
      "    update_time_ms: 5.464\n",
      "  timestamp: 1637613921\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6267402\n",
      "  training_iteration: 687\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   687</td><td style=\"text-align: right;\">          352597</td><td style=\"text-align: right;\">6267402</td><td style=\"text-align: right;\"> 5.24691</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           52.4869</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6277398\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_20-54-36\n",
      "  done: false\n",
      "  episode_len_mean: 53.74594594594595\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.382378378378383\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 122295\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9988621851287214\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014641546661777747\n",
      "          policy_loss: -0.06897174360795519\n",
      "          total_loss: 0.06861480432871758\n",
      "          vf_explained_var: 0.9369244575500488\n",
      "          vf_loss: 0.12421989476833732\n",
      "    num_agent_steps_sampled: 6277398\n",
      "    num_agent_steps_trained: 6277398\n",
      "    num_steps_sampled: 6277398\n",
      "    num_steps_trained: 6277398\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.42045454545455\n",
      "    ram_util_percent: 52.464520202020196\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052880573007608345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.94052416047903\n",
      "    mean_inference_ms: 19.470869941101533\n",
      "    mean_raw_obs_processing_ms: 3.260025406129082\n",
      "  time_since_restore: 158334.38912963867\n",
      "  time_this_iter_s: 555.1224973201752\n",
      "  time_total_s: 353151.7527151108\n",
      "  timers:\n",
      "    learn_throughput: 28.16\n",
      "    learn_time_ms: 354965.477\n",
      "    load_throughput: 88889.05\n",
      "    load_time_ms: 112.455\n",
      "    sample_throughput: 51.709\n",
      "    sample_time_ms: 193314.224\n",
      "    update_time_ms: 5.402\n",
      "  timestamp: 1637614476\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6277398\n",
      "  training_iteration: 688\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   688</td><td style=\"text-align: right;\">          353152</td><td style=\"text-align: right;\">6277398</td><td style=\"text-align: right;\"> 5.38238</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           53.7459</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6287394\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_21-03-29\n",
      "  done: false\n",
      "  episode_len_mean: 54.11891891891892\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.660000000000004\n",
      "  episode_reward_mean: 5.1313513513513564\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 122480\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9840784682088108\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014291205735117798\n",
      "          policy_loss: -0.06617232904847266\n",
      "          total_loss: 0.07190199359273972\n",
      "          vf_explained_var: 0.9304142594337463\n",
      "          vf_loss: 0.12535795379265485\n",
      "    num_agent_steps_sampled: 6287394\n",
      "    num_agent_steps_trained: 6287394\n",
      "    num_steps_sampled: 6287394\n",
      "    num_steps_trained: 6287394\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98751642575559\n",
      "    ram_util_percent: 52.28712220762155\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288622806190796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.938279152752454\n",
      "    mean_inference_ms: 19.470945862377715\n",
      "    mean_raw_obs_processing_ms: 3.252788194091791\n",
      "  time_since_restore: 158867.2621421814\n",
      "  time_this_iter_s: 532.8730125427246\n",
      "  time_total_s: 353684.6257276535\n",
      "  timers:\n",
      "    learn_throughput: 28.16\n",
      "    learn_time_ms: 354966.949\n",
      "    load_throughput: 88849.134\n",
      "    load_time_ms: 112.505\n",
      "    sample_throughput: 51.956\n",
      "    sample_time_ms: 192395.342\n",
      "    update_time_ms: 5.583\n",
      "  timestamp: 1637615009\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6287394\n",
      "  training_iteration: 689\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   689</td><td style=\"text-align: right;\">          353685</td><td style=\"text-align: right;\">6287394</td><td style=\"text-align: right;\"> 5.13135</td><td style=\"text-align: right;\">               21.66</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           54.1189</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6297390\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_21-12-36\n",
      "  done: false\n",
      "  episode_len_mean: 53.63978494623656\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.060161290322585\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 122666\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0070484389981114\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014423201310741445\n",
      "          policy_loss: -0.06665969125352206\n",
      "          total_loss: 0.0791279100581076\n",
      "          vf_explained_var: 0.9392281770706177\n",
      "          vf_loss: 0.13300022973723888\n",
      "    num_agent_steps_sampled: 6297390\n",
      "    num_agent_steps_trained: 6297390\n",
      "    num_steps_sampled: 6297390\n",
      "    num_steps_trained: 6297390\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75551282051282\n",
      "    ram_util_percent: 52.480641025641035\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287828622886986\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.93640548808723\n",
      "    mean_inference_ms: 19.47203192841344\n",
      "    mean_raw_obs_processing_ms: 3.251619202290269\n",
      "  time_since_restore: 159414.27203559875\n",
      "  time_this_iter_s: 547.0098934173584\n",
      "  time_total_s: 354231.63562107086\n",
      "  timers:\n",
      "    learn_throughput: 28.162\n",
      "    learn_time_ms: 354941.034\n",
      "    load_throughput: 89058.172\n",
      "    load_time_ms: 112.241\n",
      "    sample_throughput: 52.027\n",
      "    sample_time_ms: 192131.852\n",
      "    update_time_ms: 5.699\n",
      "  timestamp: 1637615556\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6297390\n",
      "  training_iteration: 690\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   690</td><td style=\"text-align: right;\">          354232</td><td style=\"text-align: right;\">6297390</td><td style=\"text-align: right;\"> 5.06016</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           53.6398</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6307386\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_21-21-46\n",
      "  done: false\n",
      "  episode_len_mean: 52.536842105263155\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.629999999999992\n",
      "  episode_reward_mean: 5.203105263157899\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 122856\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0165543754656152\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014493507042888383\n",
      "          policy_loss: -0.06462987091177952\n",
      "          total_loss: 0.08976941642418773\n",
      "          vf_explained_var: 0.9152203798294067\n",
      "          vf_loss: 0.1415468103325286\n",
      "    num_agent_steps_sampled: 6307386\n",
      "    num_agent_steps_trained: 6307386\n",
      "    num_steps_sampled: 6307386\n",
      "    num_steps_trained: 6307386\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.70904458598727\n",
      "    ram_util_percent: 52.860636942675164\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052868065224149344\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.936062074686916\n",
      "    mean_inference_ms: 19.4692207208075\n",
      "    mean_raw_obs_processing_ms: 3.2503843511765385\n",
      "  time_since_restore: 159964.11560225487\n",
      "  time_this_iter_s: 549.8435666561127\n",
      "  time_total_s: 354781.479187727\n",
      "  timers:\n",
      "    learn_throughput: 28.167\n",
      "    learn_time_ms: 354882.805\n",
      "    load_throughput: 89271.73\n",
      "    load_time_ms: 111.973\n",
      "    sample_throughput: 52.28\n",
      "    sample_time_ms: 191200.933\n",
      "    update_time_ms: 5.569\n",
      "  timestamp: 1637616106\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6307386\n",
      "  training_iteration: 691\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   691</td><td style=\"text-align: right;\">          354781</td><td style=\"text-align: right;\">6307386</td><td style=\"text-align: right;\"> 5.20311</td><td style=\"text-align: right;\">               17.63</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           52.5368</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6317382\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_21-30-55\n",
      "  done: false\n",
      "  episode_len_mean: 53.47089947089947\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.530000000000008\n",
      "  episode_reward_mean: 5.281481481481486\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 123045\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0211008860882984\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01520327627463231\n",
      "          policy_loss: -0.07089085849625573\n",
      "          total_loss: 0.08195313089701418\n",
      "          vf_explained_var: 0.9317820072174072\n",
      "          vf_loss: 0.13842003360001676\n",
      "    num_agent_steps_sampled: 6317382\n",
      "    num_agent_steps_trained: 6317382\n",
      "    num_steps_sampled: 6317382\n",
      "    num_steps_trained: 6317382\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.71675191815856\n",
      "    ram_util_percent: 52.87864450127879\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287018148150386\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.936609467866536\n",
      "    mean_inference_ms: 19.471647756131972\n",
      "    mean_raw_obs_processing_ms: 3.2497789480512003\n",
      "  time_since_restore: 160512.8487446308\n",
      "  time_this_iter_s: 548.733142375946\n",
      "  time_total_s: 355330.2123301029\n",
      "  timers:\n",
      "    learn_throughput: 28.167\n",
      "    learn_time_ms: 354883.78\n",
      "    load_throughput: 89041.187\n",
      "    load_time_ms: 112.263\n",
      "    sample_throughput: 51.901\n",
      "    sample_time_ms: 192596.923\n",
      "    update_time_ms: 5.968\n",
      "  timestamp: 1637616655\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6317382\n",
      "  training_iteration: 692\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   692</td><td style=\"text-align: right;\">          355330</td><td style=\"text-align: right;\">6317382</td><td style=\"text-align: right;\"> 5.28148</td><td style=\"text-align: right;\">               15.53</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           53.4709</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6327378\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_21-40-32\n",
      "  done: false\n",
      "  episode_len_mean: 53.39784946236559\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.480000000000004\n",
      "  episode_reward_mean: 5.209086021505382\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 123231\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0231979004111156\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01506747645312324\n",
      "          policy_loss: -0.06721715445953404\n",
      "          total_loss: 0.07407876626356608\n",
      "          vf_explained_var: 0.9428805112838745\n",
      "          vf_loss: 0.1272023039688562\n",
      "    num_agent_steps_sampled: 6327378\n",
      "    num_agent_steps_trained: 6327378\n",
      "    num_steps_sampled: 6327378\n",
      "    num_steps_trained: 6327378\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.96281895504254\n",
      "    ram_util_percent: 53.44568651275821\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05287131371063321\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.93321640464789\n",
      "    mean_inference_ms: 19.472053255799974\n",
      "    mean_raw_obs_processing_ms: 3.261350598721464\n",
      "  time_since_restore: 161089.27090096474\n",
      "  time_this_iter_s: 576.4221563339233\n",
      "  time_total_s: 355906.63448643684\n",
      "  timers:\n",
      "    learn_throughput: 28.168\n",
      "    learn_time_ms: 354869.68\n",
      "    load_throughput: 89102.101\n",
      "    load_time_ms: 112.186\n",
      "    sample_throughput: 51.068\n",
      "    sample_time_ms: 195740.183\n",
      "    update_time_ms: 5.287\n",
      "  timestamp: 1637617232\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6327378\n",
      "  training_iteration: 693\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   693</td><td style=\"text-align: right;\">          355907</td><td style=\"text-align: right;\">6327378</td><td style=\"text-align: right;\"> 5.20909</td><td style=\"text-align: right;\">               17.48</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           53.3978</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6337374\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_21-49-25\n",
      "  done: false\n",
      "  episode_len_mean: 54.18378378378378\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.619999999999976\n",
      "  episode_reward_mean: 5.276378378378383\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 123416\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0183724411520134\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015034224484690809\n",
      "          policy_loss: -0.06813436801099472\n",
      "          total_loss: 0.08869789650116838\n",
      "          vf_explained_var: 0.9234012365341187\n",
      "          vf_loss: 0.14276614485301048\n",
      "    num_agent_steps_sampled: 6337374\n",
      "    num_agent_steps_trained: 6337374\n",
      "    num_steps_sampled: 6337374\n",
      "    num_steps_trained: 6337374\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.696320630749\n",
      "    ram_util_percent: 52.378843626806834\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052873330856841615\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.93012634725567\n",
      "    mean_inference_ms: 19.47307539899785\n",
      "    mean_raw_obs_processing_ms: 3.254440636364268\n",
      "  time_since_restore: 161622.50728297234\n",
      "  time_this_iter_s: 533.2363820075989\n",
      "  time_total_s: 356439.87086844444\n",
      "  timers:\n",
      "    learn_throughput: 28.166\n",
      "    learn_time_ms: 354900.877\n",
      "    load_throughput: 89104.43\n",
      "    load_time_ms: 112.183\n",
      "    sample_throughput: 51.407\n",
      "    sample_time_ms: 194447.252\n",
      "    update_time_ms: 5.133\n",
      "  timestamp: 1637617765\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6337374\n",
      "  training_iteration: 694\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   694</td><td style=\"text-align: right;\">          356440</td><td style=\"text-align: right;\">6337374</td><td style=\"text-align: right;\"> 5.27638</td><td style=\"text-align: right;\">               19.62</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           54.1838</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6347370\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_21-58-19\n",
      "  done: false\n",
      "  episode_len_mean: 53.36898395721925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000008\n",
      "  episode_reward_mean: 4.93304812834225\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 123603\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0193097075544686\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014540972270936963\n",
      "          policy_loss: -0.06684829301230313\n",
      "          total_loss: 0.07774028781061798\n",
      "          vf_explained_var: 0.9363673329353333\n",
      "          vf_loss: 0.13165552361922556\n",
      "    num_agent_steps_sampled: 6347370\n",
      "    num_agent_steps_trained: 6347370\n",
      "    num_steps_sampled: 6347370\n",
      "    num_steps_trained: 6347370\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91062992125984\n",
      "    ram_util_percent: 52.349475065616794\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288456593737086\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.928817728707777\n",
      "    mean_inference_ms: 19.472531938666624\n",
      "    mean_raw_obs_processing_ms: 3.247615986418938\n",
      "  time_since_restore: 162156.6429154873\n",
      "  time_this_iter_s: 534.1356325149536\n",
      "  time_total_s: 356974.0065009594\n",
      "  timers:\n",
      "    learn_throughput: 28.161\n",
      "    learn_time_ms: 354956.757\n",
      "    load_throughput: 89625.156\n",
      "    load_time_ms: 111.531\n",
      "    sample_throughput: 51.858\n",
      "    sample_time_ms: 192756.07\n",
      "    update_time_ms: 5.313\n",
      "  timestamp: 1637618299\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6347370\n",
      "  training_iteration: 695\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   695</td><td style=\"text-align: right;\">          356974</td><td style=\"text-align: right;\">6347370</td><td style=\"text-align: right;\"> 4.93305</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">            53.369</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6357366\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_22-07-25\n",
      "  done: false\n",
      "  episode_len_mean: 53.60215053763441\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 4.875053763440864\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 123789\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.04625949160641\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01529556376491507\n",
      "          policy_loss: -0.0715527188764596\n",
      "          total_loss: 0.07938761548182109\n",
      "          vf_explained_var: 0.9321158528327942\n",
      "          vf_loss: 0.13655772177496903\n",
      "    num_agent_steps_sampled: 6357366\n",
      "    num_agent_steps_trained: 6357366\n",
      "    num_steps_sampled: 6357366\n",
      "    num_steps_trained: 6357366\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.6537869062901\n",
      "    ram_util_percent: 52.78087291399228\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05288697961976475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.926209012075613\n",
      "    mean_inference_ms: 19.47339565573111\n",
      "    mean_raw_obs_processing_ms: 3.2467041255729625\n",
      "  time_since_restore: 162702.89032411575\n",
      "  time_this_iter_s: 546.2474086284637\n",
      "  time_total_s: 357520.25390958786\n",
      "  timers:\n",
      "    learn_throughput: 28.159\n",
      "    learn_time_ms: 354979.811\n",
      "    load_throughput: 89781.537\n",
      "    load_time_ms: 111.337\n",
      "    sample_throughput: 51.974\n",
      "    sample_time_ms: 192327.749\n",
      "    update_time_ms: 4.922\n",
      "  timestamp: 1637618845\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6357366\n",
      "  training_iteration: 696\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   696</td><td style=\"text-align: right;\">          357520</td><td style=\"text-align: right;\">6357366</td><td style=\"text-align: right;\"> 4.87505</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           53.6022</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6367362\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_22-16-33\n",
      "  done: false\n",
      "  episode_len_mean: 53.63101604278075\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.679999999999996\n",
      "  episode_reward_mean: 4.921818181818186\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 123976\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.031780816680456\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014865892527562482\n",
      "          policy_loss: -0.06686194023600164\n",
      "          total_loss: 0.07791548854762353\n",
      "          vf_explained_var: 0.9258376359939575\n",
      "          vf_loss: 0.13122887428088795\n",
      "    num_agent_steps_sampled: 6367362\n",
      "    num_agent_steps_trained: 6367362\n",
      "    num_steps_sampled: 6367362\n",
      "    num_steps_trained: 6367362\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7812020460358\n",
      "    ram_util_percent: 53.969053708439894\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052872720027875825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.923070183239627\n",
      "    mean_inference_ms: 19.47220280499456\n",
      "    mean_raw_obs_processing_ms: 3.2513717600615983\n",
      "  time_since_restore: 163250.96931147575\n",
      "  time_this_iter_s: 548.0789873600006\n",
      "  time_total_s: 358068.33289694786\n",
      "  timers:\n",
      "    learn_throughput: 28.154\n",
      "    learn_time_ms: 355044.428\n",
      "    load_throughput: 89440.633\n",
      "    load_time_ms: 111.761\n",
      "    sample_throughput: 52.063\n",
      "    sample_time_ms: 191996.439\n",
      "    update_time_ms: 5.237\n",
      "  timestamp: 1637619393\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6367362\n",
      "  training_iteration: 697\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   697</td><td style=\"text-align: right;\">          358068</td><td style=\"text-align: right;\">6367362</td><td style=\"text-align: right;\"> 4.92182</td><td style=\"text-align: right;\">               15.68</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">            53.631</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6377358\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_22-25-30\n",
      "  done: false\n",
      "  episode_len_mean: 53.16489361702128\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.184148936170217\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 124164\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.039472599848207\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014541479412358251\n",
      "          policy_loss: -0.06355821956035561\n",
      "          total_loss: 0.07918307362425617\n",
      "          vf_explained_var: 0.9274757504463196\n",
      "          vf_loss: 0.13000871040372095\n",
      "    num_agent_steps_sampled: 6377358\n",
      "    num_agent_steps_trained: 6377358\n",
      "    num_steps_sampled: 6377358\n",
      "    num_steps_trained: 6377358\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00352480417754\n",
      "    ram_util_percent: 53.17023498694518\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052881293293398315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.924233375471953\n",
      "    mean_inference_ms: 19.47474341825043\n",
      "    mean_raw_obs_processing_ms: 3.244731380736242\n",
      "  time_since_restore: 163787.42015457153\n",
      "  time_this_iter_s: 536.4508430957794\n",
      "  time_total_s: 358604.78374004364\n",
      "  timers:\n",
      "    learn_throughput: 28.147\n",
      "    learn_time_ms: 355136.477\n",
      "    load_throughput: 89285.38\n",
      "    load_time_ms: 111.956\n",
      "    sample_throughput: 52.6\n",
      "    sample_time_ms: 190036.948\n",
      "    update_time_ms: 5.225\n",
      "  timestamp: 1637619930\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6377358\n",
      "  training_iteration: 698\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   698</td><td style=\"text-align: right;\">          358605</td><td style=\"text-align: right;\">6377358</td><td style=\"text-align: right;\"> 5.18415</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           53.1649</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6387354\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_22-34-38\n",
      "  done: false\n",
      "  episode_len_mean: 53.88108108108108\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.650000000000002\n",
      "  episode_reward_mean: 5.450648648648654\n",
      "  episode_reward_min: -0.45000000000000023\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 124349\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0270362399428725\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015472279221111215\n",
      "          policy_loss: -0.06736734081812712\n",
      "          total_loss: 0.093113055103026\n",
      "          vf_explained_var: 0.9427529573440552\n",
      "          vf_loss: 0.14550297200010273\n",
      "    num_agent_steps_sampled: 6387354\n",
      "    num_agent_steps_trained: 6387354\n",
      "    num_steps_sampled: 6387354\n",
      "    num_steps_trained: 6387354\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.72560819462228\n",
      "    ram_util_percent: 53.15928297055057\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05286512837733956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.91980218931723\n",
      "    mean_inference_ms: 19.4736894545786\n",
      "    mean_raw_obs_processing_ms: 3.2437759293623705\n",
      "  time_since_restore: 164335.2457447052\n",
      "  time_this_iter_s: 547.825590133667\n",
      "  time_total_s: 359152.6093301773\n",
      "  timers:\n",
      "    learn_throughput: 28.142\n",
      "    learn_time_ms: 355197.361\n",
      "    load_throughput: 89302.705\n",
      "    load_time_ms: 111.934\n",
      "    sample_throughput: 52.206\n",
      "    sample_time_ms: 191471.248\n",
      "    update_time_ms: 5.211\n",
      "  timestamp: 1637620478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6387354\n",
      "  training_iteration: 699\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   699</td><td style=\"text-align: right;\">          359153</td><td style=\"text-align: right;\">6387354</td><td style=\"text-align: right;\"> 5.45065</td><td style=\"text-align: right;\">               17.65</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">           53.8811</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6397350\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_22-43-47\n",
      "  done: false\n",
      "  episode_len_mean: 53.095238095238095\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.4620105820105875\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 124538\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0221529467996344\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015695773322034253\n",
      "          policy_loss: -0.06529095137763458\n",
      "          total_loss: 0.0894277782676328\n",
      "          vf_explained_var: 0.9492059946060181\n",
      "          vf_loss: 0.13918332331972832\n",
      "    num_agent_steps_sampled: 6397350\n",
      "    num_agent_steps_trained: 6397350\n",
      "    num_steps_sampled: 6397350\n",
      "    num_steps_trained: 6397350\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.60560509554139\n",
      "    ram_util_percent: 52.323184713375795\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05286089996818349\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.919214490652728\n",
      "    mean_inference_ms: 19.473720104434815\n",
      "    mean_raw_obs_processing_ms: 3.242970730849954\n",
      "  time_since_restore: 164884.91514205933\n",
      "  time_this_iter_s: 549.669397354126\n",
      "  time_total_s: 359702.27872753143\n",
      "  timers:\n",
      "    learn_throughput: 28.142\n",
      "    learn_time_ms: 355197.721\n",
      "    load_throughput: 88900.491\n",
      "    load_time_ms: 112.44\n",
      "    sample_throughput: 52.134\n",
      "    sample_time_ms: 191736.397\n",
      "    update_time_ms: 5.368\n",
      "  timestamp: 1637621027\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6397350\n",
      "  training_iteration: 700\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   700</td><td style=\"text-align: right;\">          359702</td><td style=\"text-align: right;\">6397350</td><td style=\"text-align: right;\"> 5.46201</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           53.0952</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6407346\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_22-52-59\n",
      "  done: false\n",
      "  episode_len_mean: 52.7989417989418\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.649999999999984\n",
      "  episode_reward_mean: 5.341428571428575\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 124727\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0185632447880435\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016130757279548845\n",
      "          policy_loss: -0.06547668036441336\n",
      "          total_loss: 0.10680024154261844\n",
      "          vf_explained_var: 0.9354764819145203\n",
      "          vf_loss: 0.15571467096376865\n",
      "    num_agent_steps_sampled: 6407346\n",
      "    num_agent_steps_trained: 6407346\n",
      "    num_steps_sampled: 6407346\n",
      "    num_steps_trained: 6407346\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.88081321473952\n",
      "    ram_util_percent: 52.76340533672173\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05285144028641362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.920950492143774\n",
      "    mean_inference_ms: 19.475170127441675\n",
      "    mean_raw_obs_processing_ms: 3.242114178232056\n",
      "  time_since_restore: 165436.75328350067\n",
      "  time_this_iter_s: 551.8381414413452\n",
      "  time_total_s: 360254.1168689728\n",
      "  timers:\n",
      "    learn_throughput: 28.141\n",
      "    learn_time_ms: 355205.126\n",
      "    load_throughput: 88794.696\n",
      "    load_time_ms: 112.574\n",
      "    sample_throughput: 52.082\n",
      "    sample_time_ms: 191927.895\n",
      "    update_time_ms: 5.811\n",
      "  timestamp: 1637621579\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6407346\n",
      "  training_iteration: 701\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   701</td><td style=\"text-align: right;\">          360254</td><td style=\"text-align: right;\">6407346</td><td style=\"text-align: right;\"> 5.34143</td><td style=\"text-align: right;\">               17.65</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           52.7989</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6417342\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_23-01-52\n",
      "  done: false\n",
      "  episode_len_mean: 54.005405405405405\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.44000000000001\n",
      "  episode_reward_mean: 4.9456756756756795\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 124912\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.016457175598087\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014400601680144754\n",
      "          policy_loss: -0.06792697789631158\n",
      "          total_loss: 0.08426916646276952\n",
      "          vf_explained_var: 0.9188170433044434\n",
      "          vf_loss: 0.13955434448708476\n",
      "    num_agent_steps_sampled: 6417342\n",
      "    num_agent_steps_trained: 6417342\n",
      "    num_steps_sampled: 6417342\n",
      "    num_steps_trained: 6417342\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.97421052631579\n",
      "    ram_util_percent: 52.63236842105264\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05285576482035488\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.919629743955177\n",
      "    mean_inference_ms: 19.476619370225944\n",
      "    mean_raw_obs_processing_ms: 3.235577921617993\n",
      "  time_since_restore: 165969.74408364296\n",
      "  time_this_iter_s: 532.9908001422882\n",
      "  time_total_s: 360787.10766911507\n",
      "  timers:\n",
      "    learn_throughput: 28.144\n",
      "    learn_time_ms: 355176.431\n",
      "    load_throughput: 88992.067\n",
      "    load_time_ms: 112.325\n",
      "    sample_throughput: 52.505\n",
      "    sample_time_ms: 190382.271\n",
      "    update_time_ms: 5.547\n",
      "  timestamp: 1637622112\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6417342\n",
      "  training_iteration: 702\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   702</td><td style=\"text-align: right;\">          360787</td><td style=\"text-align: right;\">6417342</td><td style=\"text-align: right;\"> 4.94568</td><td style=\"text-align: right;\">               15.44</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           54.0054</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6427338\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_23-11-04\n",
      "  done: false\n",
      "  episode_len_mean: 53.543010752688176\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.46999999999999\n",
      "  episode_reward_mean: 5.594946236559144\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 125098\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0075360784329566\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014840582646898545\n",
      "          policy_loss: -0.07115433586728453\n",
      "          total_loss: 0.07213278898619989\n",
      "          vf_explained_var: 0.9429711103439331\n",
      "          vf_loss: 0.12955378208040114\n",
      "    num_agent_steps_sampled: 6427338\n",
      "    num_agent_steps_trained: 6427338\n",
      "    num_steps_sampled: 6427338\n",
      "    num_steps_trained: 6427338\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.4015228426396\n",
      "    ram_util_percent: 52.97131979695432\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05286242677004455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.919141305138314\n",
      "    mean_inference_ms: 19.476873348152683\n",
      "    mean_raw_obs_processing_ms: 3.234593294313606\n",
      "  time_since_restore: 166521.3994603157\n",
      "  time_this_iter_s: 551.6553766727448\n",
      "  time_total_s: 361338.7630457878\n",
      "  timers:\n",
      "    learn_throughput: 28.151\n",
      "    learn_time_ms: 355088.641\n",
      "    load_throughput: 88664.564\n",
      "    load_time_ms: 112.74\n",
      "    sample_throughput: 53.172\n",
      "    sample_time_ms: 187992.63\n",
      "    update_time_ms: 5.488\n",
      "  timestamp: 1637622664\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6427338\n",
      "  training_iteration: 703\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   703</td><td style=\"text-align: right;\">          361339</td><td style=\"text-align: right;\">6427338</td><td style=\"text-align: right;\"> 5.59495</td><td style=\"text-align: right;\">               17.47</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">            53.543</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6437334\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_23-20-32\n",
      "  done: false\n",
      "  episode_len_mean: 54.69398907103825\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.63\n",
      "  episode_reward_mean: 5.282404371584703\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 125281\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.021175551725679\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015172329298821686\n",
      "          policy_loss: -0.0725542885724339\n",
      "          total_loss: 0.07369460706041248\n",
      "          vf_explained_var: 0.9382842183113098\n",
      "          vf_loss: 0.13189618706059864\n",
      "    num_agent_steps_sampled: 6437334\n",
      "    num_agent_steps_trained: 6437334\n",
      "    num_steps_sampled: 6437334\n",
      "    num_steps_trained: 6437334\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.99987639060568\n",
      "    ram_util_percent: 53.44103831891222\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05285043949298542\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.909118800071003\n",
      "    mean_inference_ms: 19.475323567312447\n",
      "    mean_raw_obs_processing_ms: 3.245110704688765\n",
      "  time_since_restore: 167089.04010629654\n",
      "  time_this_iter_s: 567.640645980835\n",
      "  time_total_s: 361906.40369176865\n",
      "  timers:\n",
      "    learn_throughput: 28.161\n",
      "    learn_time_ms: 354962.335\n",
      "    load_throughput: 88682.175\n",
      "    load_time_ms: 112.717\n",
      "    sample_throughput: 52.182\n",
      "    sample_time_ms: 191559.578\n",
      "    update_time_ms: 5.582\n",
      "  timestamp: 1637623232\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6437334\n",
      "  training_iteration: 704\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   704</td><td style=\"text-align: right;\">          361906</td><td style=\"text-align: right;\">6437334</td><td style=\"text-align: right;\">  5.2824</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">            54.694</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6447330\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_23-29-33\n",
      "  done: false\n",
      "  episode_len_mean: 54.59239130434783\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.399999999999974\n",
      "  episode_reward_mean: 4.696793478260873\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 125465\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.051276261428274\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015236836212585992\n",
      "          policy_loss: -0.07254370771971229\n",
      "          total_loss: 0.07991620701674644\n",
      "          vf_explained_var: 0.9339280724525452\n",
      "          vf_loss: 0.13826125850807502\n",
      "    num_agent_steps_sampled: 6447330\n",
      "    num_agent_steps_trained: 6447330\n",
      "    num_steps_sampled: 6447330\n",
      "    num_steps_trained: 6447330\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.66623544631307\n",
      "    ram_util_percent: 53.248641655886146\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05285606049015209\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.90371771500102\n",
      "    mean_inference_ms: 19.474162811896907\n",
      "    mean_raw_obs_processing_ms: 3.2440971641045606\n",
      "  time_since_restore: 167630.22116661072\n",
      "  time_this_iter_s: 541.1810603141785\n",
      "  time_total_s: 362447.5847520828\n",
      "  timers:\n",
      "    learn_throughput: 28.173\n",
      "    learn_time_ms: 354811.745\n",
      "    load_throughput: 88216.545\n",
      "    load_time_ms: 113.312\n",
      "    sample_throughput: 51.95\n",
      "    sample_time_ms: 192414.78\n",
      "    update_time_ms: 5.465\n",
      "  timestamp: 1637623773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6447330\n",
      "  training_iteration: 705\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   705</td><td style=\"text-align: right;\">          362448</td><td style=\"text-align: right;\">6447330</td><td style=\"text-align: right;\"> 4.69679</td><td style=\"text-align: right;\">                17.4</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           54.5924</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6457326\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_23-38-23\n",
      "  done: false\n",
      "  episode_len_mean: 53.526881720430104\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.58999999999999\n",
      "  episode_reward_mean: 5.2943548387096815\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 125651\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0072182581846016\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015260505883165059\n",
      "          policy_loss: -0.0687842626112903\n",
      "          total_loss: 0.08153812277105116\n",
      "          vf_explained_var: 0.9304132461547852\n",
      "          vf_loss: 0.13562922683090017\n",
      "    num_agent_steps_sampled: 6457326\n",
      "    num_agent_steps_trained: 6457326\n",
      "    num_steps_sampled: 6457326\n",
      "    num_steps_trained: 6457326\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.03672391017173\n",
      "    ram_util_percent: 52.70369881109643\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05284404730888877\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.904563667973758\n",
      "    mean_inference_ms: 19.47583649033122\n",
      "    mean_raw_obs_processing_ms: 3.2374601090196746\n",
      "  time_since_restore: 168160.8054819107\n",
      "  time_this_iter_s: 530.5843152999878\n",
      "  time_total_s: 362978.1690673828\n",
      "  timers:\n",
      "    learn_throughput: 28.19\n",
      "    learn_time_ms: 354595.168\n",
      "    load_throughput: 88119.131\n",
      "    load_time_ms: 113.437\n",
      "    sample_throughput: 52.318\n",
      "    sample_time_ms: 191063.89\n",
      "    update_time_ms: 6.218\n",
      "  timestamp: 1637624303\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6457326\n",
      "  training_iteration: 706\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   706</td><td style=\"text-align: right;\">          362978</td><td style=\"text-align: right;\">6457326</td><td style=\"text-align: right;\"> 5.29435</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           53.5269</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6467322\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_23-47-29\n",
      "  done: false\n",
      "  episode_len_mean: 53.598930481283425\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000007\n",
      "  episode_reward_mean: 5.2485026737967955\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 125838\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9801962162596154\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014584808044756824\n",
      "          policy_loss: -0.07193864618941123\n",
      "          total_loss: 0.06458621491689616\n",
      "          vf_explained_var: 0.9472094178199768\n",
      "          vf_loss: 0.12310080568663342\n",
      "    num_agent_steps_sampled: 6467322\n",
      "    num_agent_steps_trained: 6467322\n",
      "    num_steps_sampled: 6467322\n",
      "    num_steps_trained: 6467322\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75727155727155\n",
      "    ram_util_percent: 53.05045045045045\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05284686169676588\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.9031842615601\n",
      "    mean_inference_ms: 19.476546499294777\n",
      "    mean_raw_obs_processing_ms: 3.236573543351672\n",
      "  time_since_restore: 168705.79987478256\n",
      "  time_this_iter_s: 544.9943928718567\n",
      "  time_total_s: 363523.16346025467\n",
      "  timers:\n",
      "    learn_throughput: 28.214\n",
      "    learn_time_ms: 354296.204\n",
      "    load_throughput: 88481.525\n",
      "    load_time_ms: 112.973\n",
      "    sample_throughput: 52.32\n",
      "    sample_time_ms: 191054.88\n",
      "    update_time_ms: 6.196\n",
      "  timestamp: 1637624849\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6467322\n",
      "  training_iteration: 707\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   707</td><td style=\"text-align: right;\">          363523</td><td style=\"text-align: right;\">6467322</td><td style=\"text-align: right;\">  5.2485</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           53.5989</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6477318\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-22_23-56-28\n",
      "  done: false\n",
      "  episode_len_mean: 54.10326086956522\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.720000000000004\n",
      "  episode_reward_mean: 5.495760869565221\n",
      "  episode_reward_min: -0.6200000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 126022\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0020317662193117\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01561274851063752\n",
      "          policy_loss: -0.06638791759932973\n",
      "          total_loss: 0.09048963776951942\n",
      "          vf_explained_var: 0.9459840059280396\n",
      "          vf_loss: 0.14133007761837174\n",
      "    num_agent_steps_sampled: 6477318\n",
      "    num_agent_steps_trained: 6477318\n",
      "    num_steps_sampled: 6477318\n",
      "    num_steps_trained: 6477318\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69194805194803\n",
      "    ram_util_percent: 53.417012987012995\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052828849105815236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.89839447934924\n",
      "    mean_inference_ms: 19.476311406868984\n",
      "    mean_raw_obs_processing_ms: 3.23546145248484\n",
      "  time_since_restore: 169245.5115981102\n",
      "  time_this_iter_s: 539.7117233276367\n",
      "  time_total_s: 364062.8751835823\n",
      "  timers:\n",
      "    learn_throughput: 28.232\n",
      "    learn_time_ms: 354068.787\n",
      "    load_throughput: 88540.74\n",
      "    load_time_ms: 112.897\n",
      "    sample_throughput: 52.169\n",
      "    sample_time_ms: 191608.423\n",
      "    update_time_ms: 6.347\n",
      "  timestamp: 1637625388\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6477318\n",
      "  training_iteration: 708\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   708</td><td style=\"text-align: right;\">          364063</td><td style=\"text-align: right;\">6477318</td><td style=\"text-align: right;\"> 5.49576</td><td style=\"text-align: right;\">               15.72</td><td style=\"text-align: right;\">               -0.62</td><td style=\"text-align: right;\">           54.1033</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6487314\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_00-05-32\n",
      "  done: false\n",
      "  episode_len_mean: 53.67379679144385\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.67\n",
      "  episode_reward_mean: 4.91588235294118\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 126209\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.021216569392078\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014252937406465861\n",
      "          policy_loss: -0.07412920190473309\n",
      "          total_loss: 0.06163863744616968\n",
      "          vf_explained_var: 0.948100209236145\n",
      "          vf_loss: 0.12351003146326416\n",
      "    num_agent_steps_sampled: 6487314\n",
      "    num_agent_steps_trained: 6487314\n",
      "    num_steps_sampled: 6487314\n",
      "    num_steps_trained: 6487314\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.76159793814433\n",
      "    ram_util_percent: 53.64523195876289\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528222285964271\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.89317992764299\n",
      "    mean_inference_ms: 19.475310525163508\n",
      "    mean_raw_obs_processing_ms: 3.235162571300341\n",
      "  time_since_restore: 169789.07065558434\n",
      "  time_this_iter_s: 543.5590574741364\n",
      "  time_total_s: 364606.43424105644\n",
      "  timers:\n",
      "    learn_throughput: 28.251\n",
      "    learn_time_ms: 353825.987\n",
      "    load_throughput: 88467.056\n",
      "    load_time_ms: 112.991\n",
      "    sample_throughput: 52.219\n",
      "    sample_time_ms: 191424.226\n",
      "    update_time_ms: 6.571\n",
      "  timestamp: 1637625932\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6487314\n",
      "  training_iteration: 709\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   709</td><td style=\"text-align: right;\">          364606</td><td style=\"text-align: right;\">6487314</td><td style=\"text-align: right;\"> 4.91588</td><td style=\"text-align: right;\">               17.67</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           53.6738</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6497310\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_00-14-42\n",
      "  done: false\n",
      "  episode_len_mean: 54.69230769230769\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.590000000000005\n",
      "  episode_reward_mean: 4.751538461538466\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 126391\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.053860915497125\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014294156028454838\n",
      "          policy_loss: -0.06801560786951151\n",
      "          total_loss: 0.061552499492917336\n",
      "          vf_explained_var: 0.93178790807724\n",
      "          vf_loss: 0.11754284116680767\n",
      "    num_agent_steps_sampled: 6497310\n",
      "    num_agent_steps_trained: 6497310\n",
      "    num_steps_sampled: 6497310\n",
      "    num_steps_trained: 6497310\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.47984693877551\n",
      "    ram_util_percent: 53.75599489795918\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05283828965793327\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.888649330217955\n",
      "    mean_inference_ms: 19.477338231158974\n",
      "    mean_raw_obs_processing_ms: 3.2377577026773228\n",
      "  time_since_restore: 170338.69422197342\n",
      "  time_this_iter_s: 549.6235663890839\n",
      "  time_total_s: 365156.0578074455\n",
      "  timers:\n",
      "    learn_throughput: 28.268\n",
      "    learn_time_ms: 353616.238\n",
      "    load_throughput: 88728.268\n",
      "    load_time_ms: 112.659\n",
      "    sample_throughput: 52.163\n",
      "    sample_time_ms: 191630.04\n",
      "    update_time_ms: 6.374\n",
      "  timestamp: 1637626482\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6497310\n",
      "  training_iteration: 710\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   710</td><td style=\"text-align: right;\">          365156</td><td style=\"text-align: right;\">6497310</td><td style=\"text-align: right;\"> 4.75154</td><td style=\"text-align: right;\">               13.59</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           54.6923</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6507306\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_00-23-54\n",
      "  done: false\n",
      "  episode_len_mean: 54.74863387978142\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 4.820710382513665\n",
      "  episode_reward_min: -0.4900000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 126574\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0236870214402916\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01529468183287922\n",
      "          policy_loss: -0.07152445904664409\n",
      "          total_loss: 0.07381436014837595\n",
      "          vf_explained_var: 0.9404972195625305\n",
      "          vf_loss: 0.13073249040330465\n",
      "    num_agent_steps_sampled: 6507306\n",
      "    num_agent_steps_trained: 6507306\n",
      "    num_steps_sampled: 6507306\n",
      "    num_steps_trained: 6507306\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.47170050761419\n",
      "    ram_util_percent: 53.37411167512689\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282050972196828\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.881878753566\n",
      "    mean_inference_ms: 19.47560372054181\n",
      "    mean_raw_obs_processing_ms: 3.2421517705361254\n",
      "  time_since_restore: 170890.93210744858\n",
      "  time_this_iter_s: 552.2378854751587\n",
      "  time_total_s: 365708.2956929207\n",
      "  timers:\n",
      "    learn_throughput: 28.288\n",
      "    learn_time_ms: 353362.982\n",
      "    load_throughput: 88627.004\n",
      "    load_time_ms: 112.787\n",
      "    sample_throughput: 52.083\n",
      "    sample_time_ms: 191923.444\n",
      "    update_time_ms: 6.331\n",
      "  timestamp: 1637627034\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6507306\n",
      "  training_iteration: 711\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   711</td><td style=\"text-align: right;\">          365708</td><td style=\"text-align: right;\">6507306</td><td style=\"text-align: right;\"> 4.82071</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           54.7486</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6517302\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_00-33-22\n",
      "  done: false\n",
      "  episode_len_mean: 55.111111111111114\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000003\n",
      "  episode_reward_mean: 5.396611111111115\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 126754\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.983930199093608\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015815388500204145\n",
      "          policy_loss: -0.06857226190268449\n",
      "          total_loss: 0.10990444685519607\n",
      "          vf_explained_var: 0.9325550198554993\n",
      "          vf_loss: 0.1622865775975971\n",
      "    num_agent_steps_sampled: 6517302\n",
      "    num_agent_steps_trained: 6517302\n",
      "    num_steps_sampled: 6517302\n",
      "    num_steps_trained: 6517302\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.29247842170162\n",
      "    ram_util_percent: 53.83773119605426\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052811274194097445\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.871995222727303\n",
      "    mean_inference_ms: 19.472858563790016\n",
      "    mean_raw_obs_processing_ms: 3.2531383907781777\n",
      "  time_since_restore: 171459.5878136158\n",
      "  time_this_iter_s: 568.6557061672211\n",
      "  time_total_s: 366276.9513990879\n",
      "  timers:\n",
      "    learn_throughput: 28.306\n",
      "    learn_time_ms: 353134.747\n",
      "    load_throughput: 88675.91\n",
      "    load_time_ms: 112.725\n",
      "    sample_throughput: 51.073\n",
      "    sample_time_ms: 195719.02\n",
      "    update_time_ms: 6.173\n",
      "  timestamp: 1637627602\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6517302\n",
      "  training_iteration: 712\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   712</td><td style=\"text-align: right;\">          366277</td><td style=\"text-align: right;\">6517302</td><td style=\"text-align: right;\"> 5.39661</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           55.1111</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6527298\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_00-42-12\n",
      "  done: false\n",
      "  episode_len_mean: 55.2967032967033\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.610000000000007\n",
      "  episode_reward_mean: 4.702362637362642\n",
      "  episode_reward_min: -0.4000000000000003\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 126936\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0360327816153148\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01428248793534366\n",
      "          policy_loss: -0.07234018166078116\n",
      "          total_loss: 0.06674718681140979\n",
      "          vf_explained_var: 0.9390999674797058\n",
      "          vf_loss: 0.12691040299150225\n",
      "    num_agent_steps_sampled: 6527298\n",
      "    num_agent_steps_trained: 6527298\n",
      "    num_steps_sampled: 6527298\n",
      "    num_steps_trained: 6527298\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.03253968253969\n",
      "    ram_util_percent: 53.37367724867724\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282325666151342\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.870704546471814\n",
      "    mean_inference_ms: 19.474464482343276\n",
      "    mean_raw_obs_processing_ms: 3.246606286630762\n",
      "  time_since_restore: 171989.21819067\n",
      "  time_this_iter_s: 529.6303770542145\n",
      "  time_total_s: 366806.5817761421\n",
      "  timers:\n",
      "    learn_throughput: 28.317\n",
      "    learn_time_ms: 353003.4\n",
      "    load_throughput: 88998.603\n",
      "    load_time_ms: 112.316\n",
      "    sample_throughput: 51.619\n",
      "    sample_time_ms: 193648.018\n",
      "    update_time_ms: 6.512\n",
      "  timestamp: 1637628132\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6527298\n",
      "  training_iteration: 713\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   713</td><td style=\"text-align: right;\">          366807</td><td style=\"text-align: right;\">6527298</td><td style=\"text-align: right;\"> 4.70236</td><td style=\"text-align: right;\">               13.61</td><td style=\"text-align: right;\">                -0.4</td><td style=\"text-align: right;\">           55.2967</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6537294\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_00-51-16\n",
      "  done: false\n",
      "  episode_len_mean: 54.47540983606557\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.700000000000005\n",
      "  episode_reward_mean: 4.879016393442627\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 127119\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0234951707493347\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01427482638285025\n",
      "          policy_loss: -0.06438033077269152\n",
      "          total_loss: 0.07747359251819337\n",
      "          vf_explained_var: 0.9454240798950195\n",
      "          vf_loss: 0.12956903455292723\n",
      "    num_agent_steps_sampled: 6537294\n",
      "    num_agent_steps_trained: 6537294\n",
      "    num_steps_sampled: 6537294\n",
      "    num_steps_trained: 6537294\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.59367741935485\n",
      "    ram_util_percent: 53.019225806451615\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282916105264264\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.868766359145127\n",
      "    mean_inference_ms: 19.476024027645927\n",
      "    mean_raw_obs_processing_ms: 3.2452716832311883\n",
      "  time_since_restore: 172532.6812710762\n",
      "  time_this_iter_s: 543.463080406189\n",
      "  time_total_s: 367350.0448565483\n",
      "  timers:\n",
      "    learn_throughput: 28.326\n",
      "    learn_time_ms: 352889.086\n",
      "    load_throughput: 89107.706\n",
      "    load_time_ms: 112.179\n",
      "    sample_throughput: 52.241\n",
      "    sample_time_ms: 191344.402\n",
      "    update_time_ms: 6.475\n",
      "  timestamp: 1637628676\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6537294\n",
      "  training_iteration: 714\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   714</td><td style=\"text-align: right;\">          367350</td><td style=\"text-align: right;\">6537294</td><td style=\"text-align: right;\"> 4.87902</td><td style=\"text-align: right;\">                15.7</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           54.4754</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6547290\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_01-00-10\n",
      "  done: false\n",
      "  episode_len_mean: 53.93582887700535\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000007\n",
      "  episode_reward_mean: 4.945401069518721\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 127306\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0377280809075\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014336124149429847\n",
      "          policy_loss: -0.07108926157601833\n",
      "          total_loss: 0.06355235228473022\n",
      "          vf_explained_var: 0.9419111013412476\n",
      "          vf_loss: 0.12235941091845987\n",
      "    num_agent_steps_sampled: 6547290\n",
      "    num_agent_steps_trained: 6547290\n",
      "    num_steps_sampled: 6547290\n",
      "    num_steps_trained: 6547290\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.11100917431192\n",
      "    ram_util_percent: 52.75517693315859\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052833843387688074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.870925831301253\n",
      "    mean_inference_ms: 19.47710745152745\n",
      "    mean_raw_obs_processing_ms: 3.2389394225629866\n",
      "  time_since_restore: 173067.27413511276\n",
      "  time_this_iter_s: 534.5928640365601\n",
      "  time_total_s: 367884.63772058487\n",
      "  timers:\n",
      "    learn_throughput: 28.332\n",
      "    learn_time_ms: 352815.354\n",
      "    load_throughput: 89126.08\n",
      "    load_time_ms: 112.156\n",
      "    sample_throughput: 52.401\n",
      "    sample_time_ms: 190758.855\n",
      "    update_time_ms: 6.483\n",
      "  timestamp: 1637629210\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6547290\n",
      "  training_iteration: 715\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   715</td><td style=\"text-align: right;\">          367885</td><td style=\"text-align: right;\">6547290</td><td style=\"text-align: right;\">  4.9454</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           53.9358</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6557286\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_01-09-28\n",
      "  done: false\n",
      "  episode_len_mean: 53.24731182795699\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.650000000000006\n",
      "  episode_reward_mean: 5.277096774193552\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 127492\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.027858872155109\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015211364579225445\n",
      "          policy_loss: -0.06875400648060025\n",
      "          total_loss: 0.08060448919847209\n",
      "          vf_explained_var: 0.927414059638977\n",
      "          vf_loss: 0.13498369319865622\n",
      "    num_agent_steps_sampled: 6557286\n",
      "    num_agent_steps_trained: 6557286\n",
      "    num_steps_sampled: 6557286\n",
      "    num_steps_trained: 6557286\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.52943396226415\n",
      "    ram_util_percent: 53.456226415094335\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282151196035995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.86666486201984\n",
      "    mean_inference_ms: 19.475318351119547\n",
      "    mean_raw_obs_processing_ms: 3.2486547510312134\n",
      "  time_since_restore: 173624.58830213547\n",
      "  time_this_iter_s: 557.3141670227051\n",
      "  time_total_s: 368441.9518876076\n",
      "  timers:\n",
      "    learn_throughput: 28.337\n",
      "    learn_time_ms: 352759.799\n",
      "    load_throughput: 89103.104\n",
      "    load_time_ms: 112.185\n",
      "    sample_throughput: 51.662\n",
      "    sample_time_ms: 193487.952\n",
      "    update_time_ms: 5.775\n",
      "  timestamp: 1637629768\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6557286\n",
      "  training_iteration: 716\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   716</td><td style=\"text-align: right;\">          368442</td><td style=\"text-align: right;\">6557286</td><td style=\"text-align: right;\">  5.2771</td><td style=\"text-align: right;\">               15.65</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           53.2473</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6567282\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_01-18-32\n",
      "  done: false\n",
      "  episode_len_mean: 53.68817204301075\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.669999999999995\n",
      "  episode_reward_mean: 5.602204301075273\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 127678\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9887732089044579\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01590164342281052\n",
      "          policy_loss: -0.06334871136415719\n",
      "          total_loss: 0.09726317634602778\n",
      "          vf_explained_var: 0.9500916004180908\n",
      "          vf_loss: 0.14427368740614757\n",
      "    num_agent_steps_sampled: 6567282\n",
      "    num_agent_steps_trained: 6567282\n",
      "    num_steps_sampled: 6567282\n",
      "    num_steps_trained: 6567282\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.66100386100386\n",
      "    ram_util_percent: 53.08507078507079\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282308347447469\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.86378743029559\n",
      "    mean_inference_ms: 19.47460910600852\n",
      "    mean_raw_obs_processing_ms: 3.2479204330595635\n",
      "  time_since_restore: 174169.29603910446\n",
      "  time_this_iter_s: 544.7077369689941\n",
      "  time_total_s: 368986.65962457657\n",
      "  timers:\n",
      "    learn_throughput: 28.334\n",
      "    learn_time_ms: 352790.344\n",
      "    load_throughput: 88764.862\n",
      "    load_time_ms: 112.612\n",
      "    sample_throughput: 51.678\n",
      "    sample_time_ms: 193428.781\n",
      "    update_time_ms: 5.496\n",
      "  timestamp: 1637630312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6567282\n",
      "  training_iteration: 717\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   717</td><td style=\"text-align: right;\">          368987</td><td style=\"text-align: right;\">6567282</td><td style=\"text-align: right;\">  5.6022</td><td style=\"text-align: right;\">               19.67</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           53.6882</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6577278\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_01-27-29\n",
      "  done: false\n",
      "  episode_len_mean: 53.41711229946524\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000006\n",
      "  episode_reward_mean: 5.079518716577544\n",
      "  episode_reward_min: -0.6000000000000005\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 127865\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.013868046165949\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015093428841346963\n",
      "          policy_loss: -0.07115614965596653\n",
      "          total_loss: 0.07254605087210625\n",
      "          vf_explained_var: 0.9417508840560913\n",
      "          vf_loss: 0.12945616233385127\n",
      "    num_agent_steps_sampled: 6577278\n",
      "    num_agent_steps_trained: 6577278\n",
      "    num_steps_sampled: 6577278\n",
      "    num_steps_trained: 6577278\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98627450980392\n",
      "    ram_util_percent: 53.236993464052276\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052816141953976874\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.86558334150172\n",
      "    mean_inference_ms: 19.476426959048744\n",
      "    mean_raw_obs_processing_ms: 3.241576210676241\n",
      "  time_since_restore: 174705.55284833908\n",
      "  time_this_iter_s: 536.2568092346191\n",
      "  time_total_s: 369522.9164338112\n",
      "  timers:\n",
      "    learn_throughput: 28.339\n",
      "    learn_time_ms: 352727.422\n",
      "    load_throughput: 89029.54\n",
      "    load_time_ms: 112.277\n",
      "    sample_throughput: 51.754\n",
      "    sample_time_ms: 193146.143\n",
      "    update_time_ms: 5.53\n",
      "  timestamp: 1637630849\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6577278\n",
      "  training_iteration: 718\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   718</td><td style=\"text-align: right;\">          369523</td><td style=\"text-align: right;\">6577278</td><td style=\"text-align: right;\"> 5.07952</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">                -0.6</td><td style=\"text-align: right;\">           53.4171</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6587274\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_01-36-36\n",
      "  done: false\n",
      "  episode_len_mean: 53.15873015873016\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 4.998677248677252\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 128054\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.041509723495767\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015404822001477763\n",
      "          policy_loss: -0.06788019376954363\n",
      "          total_loss: 0.08982635223084842\n",
      "          vf_explained_var: 0.9439417123794556\n",
      "          vf_loss: 0.14302753101824875\n",
      "    num_agent_steps_sampled: 6587274\n",
      "    num_agent_steps_trained: 6587274\n",
      "    num_steps_sampled: 6587274\n",
      "    num_steps_trained: 6587274\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.73597951344429\n",
      "    ram_util_percent: 52.82125480153648\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052819262661603354\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.864267888862447\n",
      "    mean_inference_ms: 19.47453782616149\n",
      "    mean_raw_obs_processing_ms: 3.2410719181735916\n",
      "  time_since_restore: 175252.89384675026\n",
      "  time_this_iter_s: 547.3409984111786\n",
      "  time_total_s: 370070.25743222237\n",
      "  timers:\n",
      "    learn_throughput: 28.347\n",
      "    learn_time_ms: 352632.04\n",
      "    load_throughput: 89068.085\n",
      "    load_time_ms: 112.229\n",
      "    sample_throughput: 51.627\n",
      "    sample_time_ms: 193619.933\n",
      "    update_time_ms: 5.505\n",
      "  timestamp: 1637631396\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6587274\n",
      "  training_iteration: 719\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   719</td><td style=\"text-align: right;\">          370070</td><td style=\"text-align: right;\">6587274</td><td style=\"text-align: right;\"> 4.99868</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           53.1587</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6597270\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_01-45-44\n",
      "  done: false\n",
      "  episode_len_mean: 53.76881720430107\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.510000000000009\n",
      "  episode_reward_mean: 4.842204301075273\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 128240\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0554941247505356\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014867579128749957\n",
      "          policy_loss: -0.0692152873225744\n",
      "          total_loss: 0.08226771387462686\n",
      "          vf_explained_var: 0.929538369178772\n",
      "          vf_loss: 0.13816773801673593\n",
      "    num_agent_steps_sampled: 6597270\n",
      "    num_agent_steps_trained: 6597270\n",
      "    num_steps_sampled: 6597270\n",
      "    num_steps_trained: 6597270\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.41163682864449\n",
      "    ram_util_percent: 52.99066496163683\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528153847899803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.864112567676823\n",
      "    mean_inference_ms: 19.477147084888465\n",
      "    mean_raw_obs_processing_ms: 3.2398680787584953\n",
      "  time_since_restore: 175800.6592347622\n",
      "  time_this_iter_s: 547.7653880119324\n",
      "  time_total_s: 370618.0228202343\n",
      "  timers:\n",
      "    learn_throughput: 28.352\n",
      "    learn_time_ms: 352568.211\n",
      "    load_throughput: 88897.324\n",
      "    load_time_ms: 112.444\n",
      "    sample_throughput: 51.66\n",
      "    sample_time_ms: 193497.208\n",
      "    update_time_ms: 5.806\n",
      "  timestamp: 1637631944\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6597270\n",
      "  training_iteration: 720\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   720</td><td style=\"text-align: right;\">          370618</td><td style=\"text-align: right;\">6597270</td><td style=\"text-align: right;\">  4.8422</td><td style=\"text-align: right;\">               15.51</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.7688</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6607266\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_01-55-45\n",
      "  done: false\n",
      "  episode_len_mean: 53.72432432432432\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000007\n",
      "  episode_reward_mean: 4.8572972972973005\n",
      "  episode_reward_min: -0.6600000000000004\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 128425\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.016139799500086\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014548022383250049\n",
      "          policy_loss: -0.0659204858024095\n",
      "          total_loss: 0.07948334736779014\n",
      "          vf_explained_var: 0.9100826978683472\n",
      "          vf_loss: 0.13242301662418857\n",
      "    num_agent_steps_sampled: 6607266\n",
      "    num_agent_steps_trained: 6607266\n",
      "    num_steps_sampled: 6607266\n",
      "    num_steps_trained: 6607266\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.154662004662\n",
      "    ram_util_percent: 53.50314685314686\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280502569462519\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.850029528770857\n",
      "    mean_inference_ms: 19.473553234270092\n",
      "    mean_raw_obs_processing_ms: 3.2688498420825245\n",
      "  time_since_restore: 176402.22178316116\n",
      "  time_this_iter_s: 601.5625483989716\n",
      "  time_total_s: 371219.58536863327\n",
      "  timers:\n",
      "    learn_throughput: 28.355\n",
      "    learn_time_ms: 352526.995\n",
      "    load_throughput: 89361.863\n",
      "    load_time_ms: 111.86\n",
      "    sample_throughput: 50.365\n",
      "    sample_time_ms: 198470.651\n",
      "    update_time_ms: 6.685\n",
      "  timestamp: 1637632545\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6607266\n",
      "  training_iteration: 721\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   721</td><td style=\"text-align: right;\">          371220</td><td style=\"text-align: right;\">6607266</td><td style=\"text-align: right;\">  4.8573</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.66</td><td style=\"text-align: right;\">           53.7243</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6617262\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_02-05-00\n",
      "  done: false\n",
      "  episode_len_mean: 53.87096774193548\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000005\n",
      "  episode_reward_mean: 5.360268817204306\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 128611\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9914565632142216\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014523432371254998\n",
      "          policy_loss: -0.06712876162906381\n",
      "          total_loss: 0.08716436327463471\n",
      "          vf_explained_var: 0.9443734884262085\n",
      "          vf_loss: 0.14112149471450733\n",
      "    num_agent_steps_sampled: 6617262\n",
      "    num_agent_steps_trained: 6617262\n",
      "    num_steps_sampled: 6617262\n",
      "    num_steps_trained: 6617262\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.34166666666667\n",
      "    ram_util_percent: 52.93800505050506\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052806101636961277\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.84480003661776\n",
      "    mean_inference_ms: 19.47427298943469\n",
      "    mean_raw_obs_processing_ms: 3.2740320904918887\n",
      "  time_since_restore: 176957.22707223892\n",
      "  time_this_iter_s: 555.0052890777588\n",
      "  time_total_s: 371774.590657711\n",
      "  timers:\n",
      "    learn_throughput: 28.359\n",
      "    learn_time_ms: 352484.351\n",
      "    load_throughput: 89366.606\n",
      "    load_time_ms: 111.854\n",
      "    sample_throughput: 50.703\n",
      "    sample_time_ms: 197147.565\n",
      "    update_time_ms: 6.69\n",
      "  timestamp: 1637633100\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6617262\n",
      "  training_iteration: 722\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   722</td><td style=\"text-align: right;\">          371775</td><td style=\"text-align: right;\">6617262</td><td style=\"text-align: right;\"> 5.36027</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">            53.871</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6627258\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_02-14-03\n",
      "  done: false\n",
      "  episode_len_mean: 54.043010752688176\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.660000000000005\n",
      "  episode_reward_mean: 5.31913978494624\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 128797\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0104186823808523\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015130945948406034\n",
      "          policy_loss: -0.06835061655470036\n",
      "          total_loss: 0.09260573820105214\n",
      "          vf_explained_var: 0.9302023649215698\n",
      "          vf_loss: 0.1465903543423951\n",
      "    num_agent_steps_sampled: 6627258\n",
      "    num_agent_steps_trained: 6627258\n",
      "    num_steps_sampled: 6627258\n",
      "    num_steps_trained: 6627258\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.74521963824287\n",
      "    ram_util_percent: 52.916279069767455\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281070194690857\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.84017321317033\n",
      "    mean_inference_ms: 19.473048852047526\n",
      "    mean_raw_obs_processing_ms: 3.272661237211013\n",
      "  time_since_restore: 177499.48477745056\n",
      "  time_this_iter_s: 542.2577052116394\n",
      "  time_total_s: 372316.84836292267\n",
      "  timers:\n",
      "    learn_throughput: 28.361\n",
      "    learn_time_ms: 352459.131\n",
      "    load_throughput: 89322.549\n",
      "    load_time_ms: 111.909\n",
      "    sample_throughput: 50.374\n",
      "    sample_time_ms: 198435.189\n",
      "    update_time_ms: 6.862\n",
      "  timestamp: 1637633643\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6627258\n",
      "  training_iteration: 723\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   723</td><td style=\"text-align: right;\">          372317</td><td style=\"text-align: right;\">6627258</td><td style=\"text-align: right;\"> 5.31914</td><td style=\"text-align: right;\">               13.66</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">            54.043</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6637254\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_02-22-52\n",
      "  done: false\n",
      "  episode_len_mean: 54.09782608695652\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.73\n",
      "  episode_reward_mean: 4.896195652173917\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 128981\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0501942627401237\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013996323719482917\n",
      "          policy_loss: -0.07002075888230316\n",
      "          total_loss: 0.07170827603151929\n",
      "          vf_explained_var: 0.9385868906974792\n",
      "          vf_loss: 0.13034560083856725\n",
      "    num_agent_steps_sampled: 6637254\n",
      "    num_agent_steps_trained: 6637254\n",
      "    num_steps_sampled: 6637254\n",
      "    num_steps_trained: 6637254\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.93523178807948\n",
      "    ram_util_percent: 52.35059602649006\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279743292959554\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.838206023695637\n",
      "    mean_inference_ms: 19.474638014215312\n",
      "    mean_raw_obs_processing_ms: 3.2665401074909393\n",
      "  time_since_restore: 178028.43081641197\n",
      "  time_this_iter_s: 528.9460389614105\n",
      "  time_total_s: 372845.7944018841\n",
      "  timers:\n",
      "    learn_throughput: 28.366\n",
      "    learn_time_ms: 352395.597\n",
      "    load_throughput: 89225.051\n",
      "    load_time_ms: 112.031\n",
      "    sample_throughput: 50.729\n",
      "    sample_time_ms: 197046.385\n",
      "    update_time_ms: 7.108\n",
      "  timestamp: 1637634172\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6637254\n",
      "  training_iteration: 724\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   724</td><td style=\"text-align: right;\">          372846</td><td style=\"text-align: right;\">6637254</td><td style=\"text-align: right;\">  4.8962</td><td style=\"text-align: right;\">               17.73</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           54.0978</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6647250\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_02-32-15\n",
      "  done: false\n",
      "  episode_len_mean: 53.202127659574465\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000006\n",
      "  episode_reward_mean: 5.290372340425536\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 129169\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.005004085163515\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014091714459911954\n",
      "          policy_loss: -0.07107668719234418\n",
      "          total_loss: 0.06764818204960994\n",
      "          vf_explained_var: 0.9491779804229736\n",
      "          vf_loss: 0.12667222128513392\n",
      "    num_agent_steps_sampled: 6647250\n",
      "    num_agent_steps_trained: 6647250\n",
      "    num_steps_sampled: 6647250\n",
      "    num_steps_trained: 6647250\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.50547263681591\n",
      "    ram_util_percent: 52.9297263681592\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279304022174621\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.833106737972724\n",
      "    mean_inference_ms: 19.473127707241982\n",
      "    mean_raw_obs_processing_ms: 3.2735535166903404\n",
      "  time_since_restore: 178592.10858893394\n",
      "  time_this_iter_s: 563.6777725219727\n",
      "  time_total_s: 373409.47217440605\n",
      "  timers:\n",
      "    learn_throughput: 28.372\n",
      "    learn_time_ms: 352315.919\n",
      "    load_throughput: 89338.08\n",
      "    load_time_ms: 111.89\n",
      "    sample_throughput: 49.971\n",
      "    sample_time_ms: 200035.112\n",
      "    update_time_ms: 7.266\n",
      "  timestamp: 1637634735\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6647250\n",
      "  training_iteration: 725\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   725</td><td style=\"text-align: right;\">          373409</td><td style=\"text-align: right;\">6647250</td><td style=\"text-align: right;\"> 5.29037</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.2021</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6657246\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_02-41-05\n",
      "  done: false\n",
      "  episode_len_mean: 54.026881720430104\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000004\n",
      "  episode_reward_mean: 5.087580645161294\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 129355\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0249487051044603\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014186976646430703\n",
      "          policy_loss: -0.069381324855982\n",
      "          total_loss: 0.06522895776245251\n",
      "          vf_explained_var: 0.9491057991981506\n",
      "          vf_loss: 0.12254006234025695\n",
      "    num_agent_steps_sampled: 6657246\n",
      "    num_agent_steps_trained: 6657246\n",
      "    num_steps_sampled: 6657246\n",
      "    num_steps_trained: 6657246\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01019867549668\n",
      "    ram_util_percent: 53.06026490066226\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280728122929064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.83151732435254\n",
      "    mean_inference_ms: 19.473876635849674\n",
      "    mean_raw_obs_processing_ms: 3.2670950484481946\n",
      "  time_since_restore: 179121.6996128559\n",
      "  time_this_iter_s: 529.5910239219666\n",
      "  time_total_s: 373939.063198328\n",
      "  timers:\n",
      "    learn_throughput: 28.376\n",
      "    learn_time_ms: 352267.276\n",
      "    load_throughput: 89340.193\n",
      "    load_time_ms: 111.887\n",
      "    sample_throughput: 50.661\n",
      "    sample_time_ms: 197311.592\n",
      "    update_time_ms: 7.196\n",
      "  timestamp: 1637635265\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6657246\n",
      "  training_iteration: 726\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   726</td><td style=\"text-align: right;\">          373939</td><td style=\"text-align: right;\">6657246</td><td style=\"text-align: right;\"> 5.08758</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           54.0269</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6667242\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_02-50-23\n",
      "  done: false\n",
      "  episode_len_mean: 53.365591397849464\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000002\n",
      "  episode_reward_mean: 5.297903225806456\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 129541\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9869587139910962\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014646302367318769\n",
      "          policy_loss: -0.06977314276539337\n",
      "          total_loss: 0.07214184259300015\n",
      "          vf_explained_var: 0.9497321248054504\n",
      "          vf_loss: 0.12841846462410228\n",
      "    num_agent_steps_sampled: 6667242\n",
      "    num_agent_steps_trained: 6667242\n",
      "    num_steps_sampled: 6667242\n",
      "    num_steps_trained: 6667242\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.51482412060302\n",
      "    ram_util_percent: 53.804522613065316\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052802797820032506\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.827013385032686\n",
      "    mean_inference_ms: 19.47232813077398\n",
      "    mean_raw_obs_processing_ms: 3.2715572233533825\n",
      "  time_since_restore: 179679.73326802254\n",
      "  time_this_iter_s: 558.033655166626\n",
      "  time_total_s: 374497.09685349464\n",
      "  timers:\n",
      "    learn_throughput: 28.382\n",
      "    learn_time_ms: 352191.462\n",
      "    load_throughput: 89400.163\n",
      "    load_time_ms: 111.812\n",
      "    sample_throughput: 50.302\n",
      "    sample_time_ms: 198720.16\n",
      "    update_time_ms: 7.172\n",
      "  timestamp: 1637635823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6667242\n",
      "  training_iteration: 727\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   727</td><td style=\"text-align: right;\">          374497</td><td style=\"text-align: right;\">6667242</td><td style=\"text-align: right;\">  5.2979</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           53.3656</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6677238\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_02-59-39\n",
      "  done: false\n",
      "  episode_len_mean: 54.25945945945946\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.680000000000007\n",
      "  episode_reward_mean: 5.197729729729734\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 129726\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0115535436145753\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01514730364971481\n",
      "          policy_loss: -0.06819287885441426\n",
      "          total_loss: 0.08412062322735671\n",
      "          vf_explained_var: 0.9303103089332581\n",
      "          vf_loss: 0.13792158600399232\n",
      "    num_agent_steps_sampled: 6677238\n",
      "    num_agent_steps_trained: 6677238\n",
      "    num_steps_sampled: 6677238\n",
      "    num_steps_trained: 6677238\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.3074307304786\n",
      "    ram_util_percent: 53.976574307304794\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527971464915028\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.821864815337214\n",
      "    mean_inference_ms: 19.472333859206376\n",
      "    mean_raw_obs_processing_ms: 3.2813070653664687\n",
      "  time_since_restore: 180235.91915273666\n",
      "  time_this_iter_s: 556.1858847141266\n",
      "  time_total_s: 375053.28273820877\n",
      "  timers:\n",
      "    learn_throughput: 28.386\n",
      "    learn_time_ms: 352148.679\n",
      "    load_throughput: 89213.508\n",
      "    load_time_ms: 112.046\n",
      "    sample_throughput: 49.792\n",
      "    sample_time_ms: 200755.261\n",
      "    update_time_ms: 8.016\n",
      "  timestamp: 1637636379\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6677238\n",
      "  training_iteration: 728\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   728</td><td style=\"text-align: right;\">          375053</td><td style=\"text-align: right;\">6677238</td><td style=\"text-align: right;\"> 5.19773</td><td style=\"text-align: right;\">               15.68</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           54.2595</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6687234\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_03-08-31\n",
      "  done: false\n",
      "  episode_len_mean: 53.494623655913976\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 4.759623655913982\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 129912\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.02263046943519\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015084784325662412\n",
      "          policy_loss: -0.07045661804813608\n",
      "          total_loss: 0.08319957280314211\n",
      "          vf_explained_var: 0.9368581771850586\n",
      "          vf_loss: 0.1395174702019786\n",
      "    num_agent_steps_sampled: 6687234\n",
      "    num_agent_steps_trained: 6687234\n",
      "    num_steps_sampled: 6687234\n",
      "    num_steps_trained: 6687234\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98563899868249\n",
      "    ram_util_percent: 53.194202898550735\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527942550747441\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.821920523633914\n",
      "    mean_inference_ms: 19.47262223246617\n",
      "    mean_raw_obs_processing_ms: 3.2749515593446534\n",
      "  time_since_restore: 180767.75516295433\n",
      "  time_this_iter_s: 531.8360102176666\n",
      "  time_total_s: 375585.11874842644\n",
      "  timers:\n",
      "    learn_throughput: 28.381\n",
      "    learn_time_ms: 352202.591\n",
      "    load_throughput: 88855.932\n",
      "    load_time_ms: 112.497\n",
      "    sample_throughput: 50.193\n",
      "    sample_time_ms: 199150.507\n",
      "    update_time_ms: 7.758\n",
      "  timestamp: 1637636911\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6687234\n",
      "  training_iteration: 729\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   729</td><td style=\"text-align: right;\">          375585</td><td style=\"text-align: right;\">6687234</td><td style=\"text-align: right;\"> 4.75962</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.4946</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6697230\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_03-17-30\n",
      "  done: false\n",
      "  episode_len_mean: 53.76881720430107\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.111075268817208\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 130098\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.993206834410089\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014813523490175446\n",
      "          policy_loss: -0.07076853191836154\n",
      "          total_loss: 0.08124375258081842\n",
      "          vf_explained_var: 0.93455970287323\n",
      "          vf_loss: 0.1381972934590675\n",
      "    num_agent_steps_sampled: 6697230\n",
      "    num_agent_steps_trained: 6697230\n",
      "    num_steps_sampled: 6697230\n",
      "    num_steps_trained: 6697230\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1745123537061\n",
      "    ram_util_percent: 52.97126137841352\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052800937892064956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.8274114519165\n",
      "    mean_inference_ms: 19.476221567323478\n",
      "    mean_raw_obs_processing_ms: 3.269228590830104\n",
      "  time_since_restore: 181306.88549256325\n",
      "  time_this_iter_s: 539.1303296089172\n",
      "  time_total_s: 376124.24907803535\n",
      "  timers:\n",
      "    learn_throughput: 28.376\n",
      "    learn_time_ms: 352275.603\n",
      "    load_throughput: 89070.356\n",
      "    load_time_ms: 112.226\n",
      "    sample_throughput: 50.43\n",
      "    sample_time_ms: 198214.446\n",
      "    update_time_ms: 7.435\n",
      "  timestamp: 1637637450\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6697230\n",
      "  training_iteration: 730\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   730</td><td style=\"text-align: right;\">          376124</td><td style=\"text-align: right;\">6697230</td><td style=\"text-align: right;\"> 5.11108</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.7688</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6707226\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_03-26-35\n",
      "  done: false\n",
      "  episode_len_mean: 53.844919786096256\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.690000000000005\n",
      "  episode_reward_mean: 5.5529411764705925\n",
      "  episode_reward_min: -0.42000000000000015\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 130285\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9767733864276764\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015086560335890765\n",
      "          policy_loss: -0.06887513068841838\n",
      "          total_loss: 0.08490015367700485\n",
      "          vf_explained_var: 0.9458453059196472\n",
      "          vf_loss: 0.1391739463487857\n",
      "    num_agent_steps_sampled: 6707226\n",
      "    num_agent_steps_trained: 6707226\n",
      "    num_steps_sampled: 6707226\n",
      "    num_steps_trained: 6707226\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.76156812339332\n",
      "    ram_util_percent: 53.134704370179946\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279177474812675\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.82313287261678\n",
      "    mean_inference_ms: 19.474650791621205\n",
      "    mean_raw_obs_processing_ms: 3.274000373448617\n",
      "  time_since_restore: 181851.83904457092\n",
      "  time_this_iter_s: 544.9535520076752\n",
      "  time_total_s: 376669.20263004303\n",
      "  timers:\n",
      "    learn_throughput: 28.371\n",
      "    learn_time_ms: 352335.528\n",
      "    load_throughput: 88583.411\n",
      "    load_time_ms: 112.843\n",
      "    sample_throughput: 51.929\n",
      "    sample_time_ms: 192493.711\n",
      "    update_time_ms: 6.57\n",
      "  timestamp: 1637637995\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6707226\n",
      "  training_iteration: 731\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   731</td><td style=\"text-align: right;\">          376669</td><td style=\"text-align: right;\">6707226</td><td style=\"text-align: right;\"> 5.55294</td><td style=\"text-align: right;\">               15.69</td><td style=\"text-align: right;\">               -0.42</td><td style=\"text-align: right;\">           53.8449</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6717222\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_03-35-49\n",
      "  done: false\n",
      "  episode_len_mean: 55.105555555555554\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.520000000000008\n",
      "  episode_reward_mean: 4.95855555555556\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 130465\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.994721248518511\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014233822087427916\n",
      "          policy_loss: -0.06685210045361455\n",
      "          total_loss: 0.07177476423953723\n",
      "          vf_explained_var: 0.9386142492294312\n",
      "          vf_loss: 0.12614765027818461\n",
      "    num_agent_steps_sampled: 6717222\n",
      "    num_agent_steps_trained: 6717222\n",
      "    num_steps_sampled: 6717222\n",
      "    num_steps_trained: 6717222\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.39721518987342\n",
      "    ram_util_percent: 53.18202531645569\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052784774332777534\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.814844141499993\n",
      "    mean_inference_ms: 19.474766098463142\n",
      "    mean_raw_obs_processing_ms: 3.286744558150335\n",
      "  time_since_restore: 182405.93200159073\n",
      "  time_this_iter_s: 554.0929570198059\n",
      "  time_total_s: 377223.29558706284\n",
      "  timers:\n",
      "    learn_throughput: 28.367\n",
      "    learn_time_ms: 352382.811\n",
      "    load_throughput: 88618.705\n",
      "    load_time_ms: 112.798\n",
      "    sample_throughput: 51.966\n",
      "    sample_time_ms: 192355.506\n",
      "    update_time_ms: 6.585\n",
      "  timestamp: 1637638549\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6717222\n",
      "  training_iteration: 732\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   732</td><td style=\"text-align: right;\">          377223</td><td style=\"text-align: right;\">6717222</td><td style=\"text-align: right;\"> 4.95856</td><td style=\"text-align: right;\">               15.52</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           55.1056</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6727218\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_03-44-58\n",
      "  done: false\n",
      "  episode_len_mean: 55.25414364640884\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.669999999999977\n",
      "  episode_reward_mean: 5.197071823204424\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 130646\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0140820068767273\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01457710924292293\n",
      "          policy_loss: -0.0698292033850689\n",
      "          total_loss: 0.06908995501942547\n",
      "          vf_explained_var: 0.9304777979850769\n",
      "          vf_loss: 0.12585149971201612\n",
      "    num_agent_steps_sampled: 6727218\n",
      "    num_agent_steps_trained: 6727218\n",
      "    num_steps_sampled: 6727218\n",
      "    num_steps_trained: 6727218\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.58620689655173\n",
      "    ram_util_percent: 53.30089399744571\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052803346181091955\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.80847059257495\n",
      "    mean_inference_ms: 19.47486974088116\n",
      "    mean_raw_obs_processing_ms: 3.288703139641837\n",
      "  time_since_restore: 182954.85152316093\n",
      "  time_this_iter_s: 548.9195215702057\n",
      "  time_total_s: 377772.21510863304\n",
      "  timers:\n",
      "    learn_throughput: 28.365\n",
      "    learn_time_ms: 352405.32\n",
      "    load_throughput: 88584.16\n",
      "    load_time_ms: 112.842\n",
      "    sample_throughput: 51.793\n",
      "    sample_time_ms: 192999.807\n",
      "    update_time_ms: 6.142\n",
      "  timestamp: 1637639098\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6727218\n",
      "  training_iteration: 733\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   733</td><td style=\"text-align: right;\">          377772</td><td style=\"text-align: right;\">6727218</td><td style=\"text-align: right;\"> 5.19707</td><td style=\"text-align: right;\">               17.67</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           55.2541</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6737214\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_03-53-45\n",
      "  done: false\n",
      "  episode_len_mean: 55.52777777777778\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.680000000000005\n",
      "  episode_reward_mean: 5.211722222222226\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 130826\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9992542268760711\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015106067891157496\n",
      "          policy_loss: -0.06896288548348996\n",
      "          total_loss: 0.08537443506942377\n",
      "          vf_explained_var: 0.9258055686950684\n",
      "          vf_loss: 0.13991635120183932\n",
      "    num_agent_steps_sampled: 6737214\n",
      "    num_agent_steps_trained: 6737214\n",
      "    num_steps_sampled: 6737214\n",
      "    num_steps_trained: 6737214\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01145139813583\n",
      "    ram_util_percent: 52.6792276964048\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279748852787315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.803243688462487\n",
      "    mean_inference_ms: 19.47412055479971\n",
      "    mean_raw_obs_processing_ms: 3.282287821449484\n",
      "  time_since_restore: 183481.19321131706\n",
      "  time_this_iter_s: 526.3416881561279\n",
      "  time_total_s: 378298.55679678917\n",
      "  timers:\n",
      "    learn_throughput: 28.358\n",
      "    learn_time_ms: 352494.984\n",
      "    load_throughput: 88254.074\n",
      "    load_time_ms: 113.264\n",
      "    sample_throughput: 51.887\n",
      "    sample_time_ms: 192649.81\n",
      "    update_time_ms: 6.101\n",
      "  timestamp: 1637639625\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6737214\n",
      "  training_iteration: 734\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   734</td><td style=\"text-align: right;\">          378299</td><td style=\"text-align: right;\">6737214</td><td style=\"text-align: right;\"> 5.21172</td><td style=\"text-align: right;\">               15.68</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           55.5278</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6747210\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_04-02-53\n",
      "  done: false\n",
      "  episode_len_mean: 54.31521739130435\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.45\n",
      "  episode_reward_mean: 5.047880434782613\n",
      "  episode_reward_min: -0.4900000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 131010\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.026323837353044\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015055550449222493\n",
      "          policy_loss: -0.0684745076232897\n",
      "          total_loss: 0.08553915830803839\n",
      "          vf_explained_var: 0.9286423921585083\n",
      "          vf_loss: 0.13997847705604471\n",
      "    num_agent_steps_sampled: 6747210\n",
      "    num_agent_steps_trained: 6747210\n",
      "    num_steps_sampled: 6747210\n",
      "    num_steps_trained: 6747210\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.33030690537085\n",
      "    ram_util_percent: 52.97148337595908\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279882100475669\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.80313579124106\n",
      "    mean_inference_ms: 19.47804246611207\n",
      "    mean_raw_obs_processing_ms: 3.281306067174245\n",
      "  time_since_restore: 184029.0479271412\n",
      "  time_this_iter_s: 547.8547158241272\n",
      "  time_total_s: 378846.4115126133\n",
      "  timers:\n",
      "    learn_throughput: 28.345\n",
      "    learn_time_ms: 352656.711\n",
      "    load_throughput: 88671.334\n",
      "    load_time_ms: 112.731\n",
      "    sample_throughput: 52.361\n",
      "    sample_time_ms: 190906.242\n",
      "    update_time_ms: 6.051\n",
      "  timestamp: 1637640173\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6747210\n",
      "  training_iteration: 735\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   735</td><td style=\"text-align: right;\">          378846</td><td style=\"text-align: right;\">6747210</td><td style=\"text-align: right;\"> 5.04788</td><td style=\"text-align: right;\">               17.45</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           54.3152</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6757206\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_04-11-54\n",
      "  done: false\n",
      "  episode_len_mean: 54.73224043715847\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.459344262295087\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 131193\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9960527467679785\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01587797998276952\n",
      "          policy_loss: -0.06698987649780873\n",
      "          total_loss: 0.1096873553817668\n",
      "          vf_explained_var: 0.9214758276939392\n",
      "          vf_loss: 0.16046573482921356\n",
      "    num_agent_steps_sampled: 6757206\n",
      "    num_agent_steps_trained: 6757206\n",
      "    num_steps_sampled: 6757206\n",
      "    num_steps_trained: 6757206\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.824191461837\n",
      "    ram_util_percent: 52.714747736093145\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052795136862059416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.798535685439013\n",
      "    mean_inference_ms: 19.477089120290977\n",
      "    mean_raw_obs_processing_ms: 3.279924503580704\n",
      "  time_since_restore: 184570.81999278069\n",
      "  time_this_iter_s: 541.7720656394958\n",
      "  time_total_s: 379388.1835782528\n",
      "  timers:\n",
      "    learn_throughput: 28.34\n",
      "    learn_time_ms: 352712.849\n",
      "    load_throughput: 88798.138\n",
      "    load_time_ms: 112.57\n",
      "    sample_throughput: 52.044\n",
      "    sample_time_ms: 192068.402\n",
      "    update_time_ms: 6.185\n",
      "  timestamp: 1637640714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6757206\n",
      "  training_iteration: 736\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   736</td><td style=\"text-align: right;\">          379388</td><td style=\"text-align: right;\">6757206</td><td style=\"text-align: right;\"> 5.45934</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           54.7322</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6767202\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_04-20-53\n",
      "  done: false\n",
      "  episode_len_mean: 55.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000005\n",
      "  episode_reward_mean: 5.293867403314922\n",
      "  episode_reward_min: -0.7300000000000004\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 131374\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0094263663493006\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015672517781829463\n",
      "          policy_loss: -0.06737209919921028\n",
      "          total_loss: 0.09250488977226319\n",
      "          vf_explained_var: 0.9398441314697266\n",
      "          vf_loss: 0.14426729640863598\n",
      "    num_agent_steps_sampled: 6767202\n",
      "    num_agent_steps_trained: 6767202\n",
      "    num_steps_sampled: 6767202\n",
      "    num_steps_trained: 6767202\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.73953185955789\n",
      "    ram_util_percent: 53.70208062418726\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278569362155534\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.792606063324428\n",
      "    mean_inference_ms: 19.476848104879583\n",
      "    mean_raw_obs_processing_ms: 3.283383130069059\n",
      "  time_since_restore: 185109.79233932495\n",
      "  time_this_iter_s: 538.9723465442657\n",
      "  time_total_s: 379927.15592479706\n",
      "  timers:\n",
      "    learn_throughput: 28.336\n",
      "    learn_time_ms: 352769.649\n",
      "    load_throughput: 88888.108\n",
      "    load_time_ms: 112.456\n",
      "    sample_throughput: 52.581\n",
      "    sample_time_ms: 190105.369\n",
      "    update_time_ms: 6.211\n",
      "  timestamp: 1637641253\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6767202\n",
      "  training_iteration: 737\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   737</td><td style=\"text-align: right;\">          379927</td><td style=\"text-align: right;\">6767202</td><td style=\"text-align: right;\"> 5.29387</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.73</td><td style=\"text-align: right;\">                55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6777198\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_04-29-44\n",
      "  done: false\n",
      "  episode_len_mean: 53.73262032085562\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.54999999999998\n",
      "  episode_reward_mean: 4.934064171122999\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 131561\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.021057398084656\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014826075400119642\n",
      "          policy_loss: -0.06782338378603694\n",
      "          total_loss: 0.08821818683871638\n",
      "          vf_explained_var: 0.9333072304725647\n",
      "          vf_loss: 0.14247649084378303\n",
      "    num_agent_steps_sampled: 6777198\n",
      "    num_agent_steps_trained: 6777198\n",
      "    num_steps_sampled: 6777198\n",
      "    num_steps_trained: 6777198\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.07129629629631\n",
      "    ram_util_percent: 53.296693121693124\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279723321669208\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.791759161040716\n",
      "    mean_inference_ms: 19.47837045188178\n",
      "    mean_raw_obs_processing_ms: 3.2776219896196395\n",
      "  time_since_restore: 185639.97140574455\n",
      "  time_this_iter_s: 530.1790664196014\n",
      "  time_total_s: 380457.33499121666\n",
      "  timers:\n",
      "    learn_throughput: 28.332\n",
      "    learn_time_ms: 352815.147\n",
      "    load_throughput: 89261.942\n",
      "    load_time_ms: 111.985\n",
      "    sample_throughput: 53.323\n",
      "    sample_time_ms: 187460.15\n",
      "    update_time_ms: 5.58\n",
      "  timestamp: 1637641784\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6777198\n",
      "  training_iteration: 738\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   738</td><td style=\"text-align: right;\">          380457</td><td style=\"text-align: right;\">6777198</td><td style=\"text-align: right;\"> 4.93406</td><td style=\"text-align: right;\">               17.55</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           53.7326</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6787194\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_04-38-45\n",
      "  done: false\n",
      "  episode_len_mean: 54.568306010928964\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.660000000000005\n",
      "  episode_reward_mean: 4.72355191256831\n",
      "  episode_reward_min: -0.6500000000000004\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 131744\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0341806427422298\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014312358619233714\n",
      "          policy_loss: -0.06552722804110644\n",
      "          total_loss: 0.09102612148152069\n",
      "          vf_explained_var: 0.9256945848464966\n",
      "          vf_loss: 0.14428981231463825\n",
      "    num_agent_steps_sampled: 6787194\n",
      "    num_agent_steps_trained: 6787194\n",
      "    num_steps_sampled: 6787194\n",
      "    num_steps_trained: 6787194\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75924967658473\n",
      "    ram_util_percent: 53.29042690815005\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527890849904929\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.787367934442\n",
      "    mean_inference_ms: 19.47779356648739\n",
      "    mean_raw_obs_processing_ms: 3.2767129432041555\n",
      "  time_since_restore: 186181.21005249023\n",
      "  time_this_iter_s: 541.2386467456818\n",
      "  time_total_s: 380998.57363796234\n",
      "  timers:\n",
      "    learn_throughput: 28.334\n",
      "    learn_time_ms: 352792.41\n",
      "    load_throughput: 89463.497\n",
      "    load_time_ms: 111.733\n",
      "    sample_throughput: 53.051\n",
      "    sample_time_ms: 188423.056\n",
      "    update_time_ms: 5.863\n",
      "  timestamp: 1637642325\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6787194\n",
      "  training_iteration: 739\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   739</td><td style=\"text-align: right;\">          380999</td><td style=\"text-align: right;\">6787194</td><td style=\"text-align: right;\"> 4.72355</td><td style=\"text-align: right;\">               13.66</td><td style=\"text-align: right;\">               -0.65</td><td style=\"text-align: right;\">           54.5683</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6797190\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_04-47-49\n",
      "  done: false\n",
      "  episode_len_mean: 54.65217391304348\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.41000000000001\n",
      "  episode_reward_mean: 5.012608695652178\n",
      "  episode_reward_min: -0.6400000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 131928\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.019425179824293\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015889405770208635\n",
      "          policy_loss: -0.07022276054996625\n",
      "          total_loss: 0.10038081736936136\n",
      "          vf_explained_var: 0.9227597117424011\n",
      "          vf_loss: 0.15459977524910481\n",
      "    num_agent_steps_sampled: 6797190\n",
      "    num_agent_steps_trained: 6797190\n",
      "    num_steps_sampled: 6797190\n",
      "    num_steps_trained: 6797190\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.84064516129033\n",
      "    ram_util_percent: 52.897161290322565\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279255288427454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.78432256927868\n",
      "    mean_inference_ms: 19.479615716705755\n",
      "    mean_raw_obs_processing_ms: 3.2760229078210243\n",
      "  time_since_restore: 186724.97900891304\n",
      "  time_this_iter_s: 543.7689564228058\n",
      "  time_total_s: 381542.34259438515\n",
      "  timers:\n",
      "    learn_throughput: 28.337\n",
      "    learn_time_ms: 352757.294\n",
      "    load_throughput: 89525.908\n",
      "    load_time_ms: 111.655\n",
      "    sample_throughput: 52.911\n",
      "    sample_time_ms: 188921.632\n",
      "    update_time_ms: 6.603\n",
      "  timestamp: 1637642869\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6797190\n",
      "  training_iteration: 740\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   740</td><td style=\"text-align: right;\">          381542</td><td style=\"text-align: right;\">6797190</td><td style=\"text-align: right;\"> 5.01261</td><td style=\"text-align: right;\">               17.41</td><td style=\"text-align: right;\">               -0.64</td><td style=\"text-align: right;\">           54.6522</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6807186\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_04-57-09\n",
      "  done: false\n",
      "  episode_len_mean: 54.53551912568306\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 5.336448087431698\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 132111\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0307764293678314\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01537408963745005\n",
      "          policy_loss: -0.06886012300602455\n",
      "          total_loss: 0.08366560777975021\n",
      "          vf_explained_var: 0.9172341823577881\n",
      "          vf_loss: 0.1378093964819531\n",
      "    num_agent_steps_sampled: 6807186\n",
      "    num_agent_steps_trained: 6807186\n",
      "    num_steps_sampled: 6807186\n",
      "    num_steps_trained: 6807186\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.23404255319149\n",
      "    ram_util_percent: 53.22365456821026\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278137464426097\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.776834683954508\n",
      "    mean_inference_ms: 19.478107607672698\n",
      "    mean_raw_obs_processing_ms: 3.2822443401533583\n",
      "  time_since_restore: 187284.95250344276\n",
      "  time_this_iter_s: 559.9734945297241\n",
      "  time_total_s: 382102.3160889149\n",
      "  timers:\n",
      "    learn_throughput: 28.338\n",
      "    learn_time_ms: 352744.135\n",
      "    load_throughput: 89517.727\n",
      "    load_time_ms: 111.665\n",
      "    sample_throughput: 52.49\n",
      "    sample_time_ms: 190437.172\n",
      "    update_time_ms: 6.242\n",
      "  timestamp: 1637643429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6807186\n",
      "  training_iteration: 741\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   741</td><td style=\"text-align: right;\">          382102</td><td style=\"text-align: right;\">6807186</td><td style=\"text-align: right;\"> 5.33645</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           54.5355</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6817182\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_05-05-57\n",
      "  done: false\n",
      "  episode_len_mean: 54.45652173913044\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000005\n",
      "  episode_reward_mean: 4.981956521739135\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 132295\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.044741813820529\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015570640996063317\n",
      "          policy_loss: -0.07445101722993958\n",
      "          total_loss: 0.08425022157514678\n",
      "          vf_explained_var: 0.9334119558334351\n",
      "          vf_loss: 0.14367678858364097\n",
      "    num_agent_steps_sampled: 6817182\n",
      "    num_agent_steps_trained: 6817182\n",
      "    num_steps_sampled: 6817182\n",
      "    num_steps_trained: 6817182\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02811671087535\n",
      "    ram_util_percent: 53.23435013262599\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278089658255643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.77405625705075\n",
      "    mean_inference_ms: 19.47762707591655\n",
      "    mean_raw_obs_processing_ms: 3.276110586994651\n",
      "  time_since_restore: 187813.095826149\n",
      "  time_this_iter_s: 528.1433227062225\n",
      "  time_total_s: 382630.4594116211\n",
      "  timers:\n",
      "    learn_throughput: 28.338\n",
      "    learn_time_ms: 352746.867\n",
      "    load_throughput: 89701.321\n",
      "    load_time_ms: 111.436\n",
      "    sample_throughput: 53.215\n",
      "    sample_time_ms: 187840.273\n",
      "    update_time_ms: 5.863\n",
      "  timestamp: 1637643957\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6817182\n",
      "  training_iteration: 742\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   742</td><td style=\"text-align: right;\">          382630</td><td style=\"text-align: right;\">6817182</td><td style=\"text-align: right;\"> 4.98196</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           54.4565</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6827178\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_05-15-00\n",
      "  done: false\n",
      "  episode_len_mean: 53.53763440860215\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.093172043010756\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 132481\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0472314174634865\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0158354089447733\n",
      "          policy_loss: -0.06767176010021596\n",
      "          total_loss: 0.12045108948476987\n",
      "          vf_explained_var: 0.927758514881134\n",
      "          vf_loss: 0.17252012183665333\n",
      "    num_agent_steps_sampled: 6827178\n",
      "    num_agent_steps_trained: 6827178\n",
      "    num_steps_sampled: 6827178\n",
      "    num_steps_trained: 6827178\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.83935483870968\n",
      "    ram_util_percent: 53.52051612903225\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052785770014347\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.771644133765587\n",
      "    mean_inference_ms: 19.476810242740378\n",
      "    mean_raw_obs_processing_ms: 3.2748768461762587\n",
      "  time_since_restore: 188356.34425091743\n",
      "  time_this_iter_s: 543.2484247684479\n",
      "  time_total_s: 383173.70783638954\n",
      "  timers:\n",
      "    learn_throughput: 28.337\n",
      "    learn_time_ms: 352752.024\n",
      "    load_throughput: 89793.516\n",
      "    load_time_ms: 111.322\n",
      "    sample_throughput: 53.378\n",
      "    sample_time_ms: 187266.997\n",
      "    update_time_ms: 6.375\n",
      "  timestamp: 1637644500\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6827178\n",
      "  training_iteration: 743\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   743</td><td style=\"text-align: right;\">          383174</td><td style=\"text-align: right;\">6827178</td><td style=\"text-align: right;\"> 5.09317</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           53.5376</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6837174\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_05-24-05\n",
      "  done: false\n",
      "  episode_len_mean: 54.108695652173914\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.54999999999998\n",
      "  episode_reward_mean: 5.1992934782608735\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 132665\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.035397347867728\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014789729627831868\n",
      "          policy_loss: -0.0647260576780811\n",
      "          total_loss: 0.09719967837350617\n",
      "          vf_explained_var: 0.9280728101730347\n",
      "          vf_loss: 0.14858685517926742\n",
      "    num_agent_steps_sampled: 6837174\n",
      "    num_agent_steps_trained: 6837174\n",
      "    num_steps_sampled: 6837174\n",
      "    num_steps_trained: 6837174\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.74234234234234\n",
      "    ram_util_percent: 53.21055341055341\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052789870916492364\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.769646543318665\n",
      "    mean_inference_ms: 19.479195151851272\n",
      "    mean_raw_obs_processing_ms: 3.274098155754326\n",
      "  time_since_restore: 188901.00891137123\n",
      "  time_this_iter_s: 544.6646604537964\n",
      "  time_total_s: 383718.37249684334\n",
      "  timers:\n",
      "    learn_throughput: 28.338\n",
      "    learn_time_ms: 352744.962\n",
      "    load_throughput: 90259.215\n",
      "    load_time_ms: 110.748\n",
      "    sample_throughput: 52.859\n",
      "    sample_time_ms: 189106.795\n",
      "    update_time_ms: 6.49\n",
      "  timestamp: 1637645045\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6837174\n",
      "  training_iteration: 744\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   744</td><td style=\"text-align: right;\">          383718</td><td style=\"text-align: right;\">6837174</td><td style=\"text-align: right;\"> 5.19929</td><td style=\"text-align: right;\">               17.55</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           54.1087</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6847170\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_05-33-31\n",
      "  done: false\n",
      "  episode_len_mean: 54.043010752688176\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.679999999999993\n",
      "  episode_reward_mean: 5.0453763440860255\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 132851\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.026441018935667\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015567076972883167\n",
      "          policy_loss: -0.06620313818214683\n",
      "          total_loss: 0.0952431769063407\n",
      "          vf_explained_var: 0.9200409054756165\n",
      "          vf_loss: 0.1462469766456933\n",
      "    num_agent_steps_sampled: 6847170\n",
      "    num_agent_steps_trained: 6847170\n",
      "    num_steps_sampled: 6847170\n",
      "    num_steps_trained: 6847170\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.30049504950496\n",
      "    ram_util_percent: 53.34690594059406\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052785737656039465\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.761843116301637\n",
      "    mean_inference_ms: 19.475790303372868\n",
      "    mean_raw_obs_processing_ms: 3.282254168157437\n",
      "  time_since_restore: 189467.31298065186\n",
      "  time_this_iter_s: 566.3040692806244\n",
      "  time_total_s: 384284.67656612396\n",
      "  timers:\n",
      "    learn_throughput: 28.349\n",
      "    learn_time_ms: 352605.212\n",
      "    load_throughput: 89881.45\n",
      "    load_time_ms: 111.213\n",
      "    sample_throughput: 52.31\n",
      "    sample_time_ms: 191091.034\n",
      "    update_time_ms: 6.29\n",
      "  timestamp: 1637645611\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6847170\n",
      "  training_iteration: 745\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   745</td><td style=\"text-align: right;\">          384285</td><td style=\"text-align: right;\">6847170</td><td style=\"text-align: right;\"> 5.04538</td><td style=\"text-align: right;\">               19.68</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">            54.043</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6857166\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_05-42-32\n",
      "  done: false\n",
      "  episode_len_mean: 53.79459459459459\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.540000000000008\n",
      "  episode_reward_mean: 5.036810810810816\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 133036\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0146496139376997\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014527092568062715\n",
      "          policy_loss: -0.07271513909571473\n",
      "          total_loss: 0.07712952008609954\n",
      "          vf_explained_var: 0.9328609108924866\n",
      "          vf_loss: 0.13689662147795847\n",
      "    num_agent_steps_sampled: 6857166\n",
      "    num_agent_steps_trained: 6857166\n",
      "    num_steps_sampled: 6857166\n",
      "    num_steps_trained: 6857166\n",
      "  iterations_since_restore: 346\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.87422279792746\n",
      "    ram_util_percent: 53.458290155440416\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278755658741461\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.758741210469225\n",
      "    mean_inference_ms: 19.476731203719975\n",
      "    mean_raw_obs_processing_ms: 3.281712364635738\n",
      "  time_since_restore: 190008.500767231\n",
      "  time_this_iter_s: 541.1877865791321\n",
      "  time_total_s: 384825.8643527031\n",
      "  timers:\n",
      "    learn_throughput: 28.351\n",
      "    learn_time_ms: 352575.333\n",
      "    load_throughput: 89905.561\n",
      "    load_time_ms: 111.183\n",
      "    sample_throughput: 52.318\n",
      "    sample_time_ms: 191062.541\n",
      "    update_time_ms: 6.313\n",
      "  timestamp: 1637646152\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6857166\n",
      "  training_iteration: 746\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   746</td><td style=\"text-align: right;\">          384826</td><td style=\"text-align: right;\">6857166</td><td style=\"text-align: right;\"> 5.03681</td><td style=\"text-align: right;\">               13.54</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           53.7946</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6867162\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_05-51-24\n",
      "  done: false\n",
      "  episode_len_mean: 53.52150537634409\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.57000000000001\n",
      "  episode_reward_mean: 5.357634408602156\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 133222\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.027343169560873\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015060225158410188\n",
      "          policy_loss: -0.06749929746836562\n",
      "          total_loss: 0.08491479258776977\n",
      "          vf_explained_var: 0.9410747289657593\n",
      "          vf_loss: 0.13837844472711375\n",
      "    num_agent_steps_sampled: 6867162\n",
      "    num_agent_steps_trained: 6867162\n",
      "    num_steps_sampled: 6867162\n",
      "    num_steps_trained: 6867162\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9836627140975\n",
      "    ram_util_percent: 53.226877470355724\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279561254240825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.758902260187924\n",
      "    mean_inference_ms: 19.478232560570525\n",
      "    mean_raw_obs_processing_ms: 3.275799283086752\n",
      "  time_since_restore: 190540.22801303864\n",
      "  time_this_iter_s: 531.7272458076477\n",
      "  time_total_s: 385357.59159851074\n",
      "  timers:\n",
      "    learn_throughput: 28.353\n",
      "    learn_time_ms: 352549.989\n",
      "    load_throughput: 89904.925\n",
      "    load_time_ms: 111.184\n",
      "    sample_throughput: 52.51\n",
      "    sample_time_ms: 190363.128\n",
      "    update_time_ms: 6.65\n",
      "  timestamp: 1637646684\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6867162\n",
      "  training_iteration: 747\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   747</td><td style=\"text-align: right;\">          385358</td><td style=\"text-align: right;\">6867162</td><td style=\"text-align: right;\"> 5.35763</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           53.5215</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6877158\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_06-00-41\n",
      "  done: false\n",
      "  episode_len_mean: 53.537234042553195\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 5.715159574468089\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 133410\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0119808103904187\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015326222684644047\n",
      "          policy_loss: -0.06971112273267462\n",
      "          total_loss: 0.09374917438212413\n",
      "          vf_explained_var: 0.952505350112915\n",
      "          vf_loss: 0.148665053291942\n",
      "    num_agent_steps_sampled: 6877158\n",
      "    num_agent_steps_trained: 6877158\n",
      "    num_steps_sampled: 6877158\n",
      "    num_steps_trained: 6877158\n",
      "  iterations_since_restore: 348\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.57220125786162\n",
      "    ram_util_percent: 53.81874213836479\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279280883730538\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.7535765254727\n",
      "    mean_inference_ms: 19.476823216099508\n",
      "    mean_raw_obs_processing_ms: 3.2851100341924884\n",
      "  time_since_restore: 191097.05240559578\n",
      "  time_this_iter_s: 556.8243925571442\n",
      "  time_total_s: 385914.4159910679\n",
      "  timers:\n",
      "    learn_throughput: 28.356\n",
      "    learn_time_ms: 352523.112\n",
      "    load_throughput: 89544.015\n",
      "    load_time_ms: 111.632\n",
      "    sample_throughput: 51.778\n",
      "    sample_time_ms: 193053.637\n",
      "    update_time_ms: 6.644\n",
      "  timestamp: 1637647241\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6877158\n",
      "  training_iteration: 748\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   748</td><td style=\"text-align: right;\">          385914</td><td style=\"text-align: right;\">6877158</td><td style=\"text-align: right;\"> 5.71516</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.5372</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6887154\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_06-09-33\n",
      "  done: false\n",
      "  episode_len_mean: 53.015957446808514\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.47000000000001\n",
      "  episode_reward_mean: 5.263510638297876\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 133598\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.03168391685888\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014998768491509006\n",
      "          policy_loss: -0.06302278299965154\n",
      "          total_loss: 0.10838991434086721\n",
      "          vf_explained_var: 0.9411893486976624\n",
      "          vf_loss: 0.1575604655971586\n",
      "    num_agent_steps_sampled: 6887154\n",
      "    num_agent_steps_trained: 6887154\n",
      "    num_steps_sampled: 6887154\n",
      "    num_steps_trained: 6887154\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.97127799736496\n",
      "    ram_util_percent: 52.6509881422925\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052800736480253525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.754254260181032\n",
      "    mean_inference_ms: 19.477844111969862\n",
      "    mean_raw_obs_processing_ms: 3.279395091772286\n",
      "  time_since_restore: 191629.23346829414\n",
      "  time_this_iter_s: 532.1810626983643\n",
      "  time_total_s: 386446.59705376625\n",
      "  timers:\n",
      "    learn_throughput: 28.354\n",
      "    learn_time_ms: 352544.503\n",
      "    load_throughput: 89618.164\n",
      "    load_time_ms: 111.54\n",
      "    sample_throughput: 52.028\n",
      "    sample_time_ms: 192126.854\n",
      "    update_time_ms: 6.289\n",
      "  timestamp: 1637647773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6887154\n",
      "  training_iteration: 749\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   749</td><td style=\"text-align: right;\">          386447</td><td style=\"text-align: right;\">6887154</td><td style=\"text-align: right;\"> 5.26351</td><td style=\"text-align: right;\">               17.47</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">            53.016</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6897150\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_06-18-54\n",
      "  done: false\n",
      "  episode_len_mean: 52.63157894736842\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.41000000000001\n",
      "  episode_reward_mean: 5.059578947368426\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 133788\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.024175001890305\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013938901963043052\n",
      "          policy_loss: -0.07282366376796792\n",
      "          total_loss: 0.05547947264733676\n",
      "          vf_explained_var: 0.9343377351760864\n",
      "          vf_loss: 0.11679032490061349\n",
      "    num_agent_steps_sampled: 6897150\n",
      "    num_agent_steps_trained: 6897150\n",
      "    num_steps_sampled: 6897150\n",
      "    num_steps_trained: 6897150\n",
      "  iterations_since_restore: 350\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.22887499999999\n",
      "    ram_util_percent: 53.51987499999999\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052795069747302664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.752089591561347\n",
      "    mean_inference_ms: 19.477480899827803\n",
      "    mean_raw_obs_processing_ms: 3.2886482250644553\n",
      "  time_since_restore: 192190.13625836372\n",
      "  time_this_iter_s: 560.9027900695801\n",
      "  time_total_s: 387007.49984383583\n",
      "  timers:\n",
      "    learn_throughput: 28.352\n",
      "    learn_time_ms: 352565.261\n",
      "    load_throughput: 89324.681\n",
      "    load_time_ms: 111.906\n",
      "    sample_throughput: 51.574\n",
      "    sample_time_ms: 193819.509\n",
      "    update_time_ms: 5.616\n",
      "  timestamp: 1637648334\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6897150\n",
      "  training_iteration: 750\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   750</td><td style=\"text-align: right;\">          387007</td><td style=\"text-align: right;\">6897150</td><td style=\"text-align: right;\"> 5.05958</td><td style=\"text-align: right;\">               15.41</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           52.6316</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6907146\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_06-27-57\n",
      "  done: false\n",
      "  episode_len_mean: 53.736559139784944\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.560000000000002\n",
      "  episode_reward_mean: 5.072043010752692\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 133974\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.009479223461036\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014470163000158227\n",
      "          policy_loss: -0.07345431857976369\n",
      "          total_loss: 0.06925961226494899\n",
      "          vf_explained_var: 0.9357457160949707\n",
      "          vf_loss: 0.12984388201482533\n",
      "    num_agent_steps_sampled: 6907146\n",
      "    num_agent_steps_trained: 6907146\n",
      "    num_steps_sampled: 6907146\n",
      "    num_steps_trained: 6907146\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.86718346253231\n",
      "    ram_util_percent: 53.116149870801046\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052802839022379484\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.748631691231584\n",
      "    mean_inference_ms: 19.477764318676755\n",
      "    mean_raw_obs_processing_ms: 3.2880400726425565\n",
      "  time_since_restore: 192732.6302230358\n",
      "  time_this_iter_s: 542.4939646720886\n",
      "  time_total_s: 387549.9938085079\n",
      "  timers:\n",
      "    learn_throughput: 28.348\n",
      "    learn_time_ms: 352620.51\n",
      "    load_throughput: 89432.372\n",
      "    load_time_ms: 111.772\n",
      "    sample_throughput: 52.058\n",
      "    sample_time_ms: 192016.592\n",
      "    update_time_ms: 5.533\n",
      "  timestamp: 1637648877\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6907146\n",
      "  training_iteration: 751\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   751</td><td style=\"text-align: right;\">          387550</td><td style=\"text-align: right;\">6907146</td><td style=\"text-align: right;\"> 5.07204</td><td style=\"text-align: right;\">               17.56</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           53.7366</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6917142\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_06-37-03\n",
      "  done: false\n",
      "  episode_len_mean: 53.972972972972975\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.530000000000005\n",
      "  episode_reward_mean: 4.802594594594599\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 134159\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.035761503689739\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014702117840883032\n",
      "          policy_loss: -0.07081096641388092\n",
      "          total_loss: 0.07332579920985008\n",
      "          vf_explained_var: 0.9260939359664917\n",
      "          vf_loss: 0.13100111798540387\n",
      "    num_agent_steps_sampled: 6917142\n",
      "    num_agent_steps_trained: 6917142\n",
      "    num_steps_sampled: 6917142\n",
      "    num_steps_trained: 6917142\n",
      "  iterations_since_restore: 352\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.45397435897436\n",
      "    ram_util_percent: 53.32910256410256\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280161197020222\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.748415303695484\n",
      "    mean_inference_ms: 19.47822408257192\n",
      "    mean_raw_obs_processing_ms: 3.2871299891017833\n",
      "  time_since_restore: 193279.04555296898\n",
      "  time_this_iter_s: 546.4153299331665\n",
      "  time_total_s: 388096.4091384411\n",
      "  timers:\n",
      "    learn_throughput: 28.344\n",
      "    learn_time_ms: 352664.67\n",
      "    load_throughput: 89220.741\n",
      "    load_time_ms: 112.037\n",
      "    sample_throughput: 51.579\n",
      "    sample_time_ms: 193799.338\n",
      "    update_time_ms: 5.745\n",
      "  timestamp: 1637649423\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6917142\n",
      "  training_iteration: 752\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   752</td><td style=\"text-align: right;\">          388096</td><td style=\"text-align: right;\">6917142</td><td style=\"text-align: right;\"> 4.80259</td><td style=\"text-align: right;\">               15.53</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">            53.973</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6927138\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_06-46-09\n",
      "  done: false\n",
      "  episode_len_mean: 53.22751322751323\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.700000000000005\n",
      "  episode_reward_mean: 5.132539682539686\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 134348\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0326269095202525\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014904736929426973\n",
      "          policy_loss: -0.06722570178319301\n",
      "          total_loss: 0.08555612250907746\n",
      "          vf_explained_var: 0.9261638522148132\n",
      "          vf_loss: 0.13915323877303176\n",
      "    num_agent_steps_sampled: 6927138\n",
      "    num_agent_steps_trained: 6927138\n",
      "    num_steps_sampled: 6927138\n",
      "    num_steps_trained: 6927138\n",
      "  iterations_since_restore: 353\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.70976863753215\n",
      "    ram_util_percent: 54.08958868894601\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052802389389200205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.746965839601106\n",
      "    mean_inference_ms: 19.47983858258467\n",
      "    mean_raw_obs_processing_ms: 3.291284396418749\n",
      "  time_since_restore: 193824.64210534096\n",
      "  time_this_iter_s: 545.5965523719788\n",
      "  time_total_s: 388642.00569081306\n",
      "  timers:\n",
      "    learn_throughput: 28.343\n",
      "    learn_time_ms: 352680.188\n",
      "    load_throughput: 89130.135\n",
      "    load_time_ms: 112.151\n",
      "    sample_throughput: 51.521\n",
      "    sample_time_ms: 194018.933\n",
      "    update_time_ms: 5.949\n",
      "  timestamp: 1637649969\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6927138\n",
      "  training_iteration: 753\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   753</td><td style=\"text-align: right;\">          388642</td><td style=\"text-align: right;\">6927138</td><td style=\"text-align: right;\"> 5.13254</td><td style=\"text-align: right;\">                15.7</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           53.2275</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6937134\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_06-55-03\n",
      "  done: false\n",
      "  episode_len_mean: 53.81521739130435\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.580000000000007\n",
      "  episode_reward_mean: 5.39239130434783\n",
      "  episode_reward_min: -0.4300000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 134532\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0209974620476303\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015219747135038604\n",
      "          policy_loss: -0.06961254443087243\n",
      "          total_loss: 0.08296393807505231\n",
      "          vf_explained_var: 0.9486626982688904\n",
      "          vf_loss: 0.13811396937836037\n",
      "    num_agent_steps_sampled: 6937134\n",
      "    num_agent_steps_trained: 6937134\n",
      "    num_steps_sampled: 6937134\n",
      "    num_steps_trained: 6937134\n",
      "  iterations_since_restore: 354\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.96290956749674\n",
      "    ram_util_percent: 53.75688073394495\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052816021140605074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.746461950758786\n",
      "    mean_inference_ms: 19.47935285323168\n",
      "    mean_raw_obs_processing_ms: 3.285661844585255\n",
      "  time_since_restore: 194358.9101717472\n",
      "  time_this_iter_s: 534.26806640625\n",
      "  time_total_s: 389176.2737572193\n",
      "  timers:\n",
      "    learn_throughput: 28.343\n",
      "    learn_time_ms: 352676.893\n",
      "    load_throughput: 89048.392\n",
      "    load_time_ms: 112.254\n",
      "    sample_throughput: 51.797\n",
      "    sample_time_ms: 192982.464\n",
      "    update_time_ms: 5.649\n",
      "  timestamp: 1637650503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6937134\n",
      "  training_iteration: 754\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   754</td><td style=\"text-align: right;\">          389176</td><td style=\"text-align: right;\">6937134</td><td style=\"text-align: right;\"> 5.39239</td><td style=\"text-align: right;\">               13.58</td><td style=\"text-align: right;\">               -0.43</td><td style=\"text-align: right;\">           53.8152</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6947130\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_07-04-17\n",
      "  done: false\n",
      "  episode_len_mean: 53.75401069518717\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.39999999999998\n",
      "  episode_reward_mean: 5.271229946524068\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 134719\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.055611884139149\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014710583659719716\n",
      "          policy_loss: -0.07079633016489231\n",
      "          total_loss: 0.07406951683529096\n",
      "          vf_explained_var: 0.9147394299507141\n",
      "          vf_loss: 0.13190941582218815\n",
      "    num_agent_steps_sampled: 6947130\n",
      "    num_agent_steps_trained: 6947130\n",
      "    num_steps_sampled: 6947130\n",
      "    num_steps_trained: 6947130\n",
      "  iterations_since_restore: 355\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.64081115335867\n",
      "    ram_util_percent: 54.025602027883394\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280234785796771\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.743609871779007\n",
      "    mean_inference_ms: 19.4796086983338\n",
      "    mean_raw_obs_processing_ms: 3.289034040024537\n",
      "  time_since_restore: 194912.44462633133\n",
      "  time_this_iter_s: 553.5344545841217\n",
      "  time_total_s: 389729.80821180344\n",
      "  timers:\n",
      "    learn_throughput: 28.335\n",
      "    learn_time_ms: 352779.388\n",
      "    load_throughput: 88600.465\n",
      "    load_time_ms: 112.821\n",
      "    sample_throughput: 52.171\n",
      "    sample_time_ms: 191602.514\n",
      "    update_time_ms: 5.848\n",
      "  timestamp: 1637651057\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6947130\n",
      "  training_iteration: 755\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   755</td><td style=\"text-align: right;\">          389730</td><td style=\"text-align: right;\">6947130</td><td style=\"text-align: right;\"> 5.27123</td><td style=\"text-align: right;\">                17.4</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">            53.754</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6957126\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_07-13-21\n",
      "  done: false\n",
      "  episode_len_mean: 53.994565217391305\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.589999999999993\n",
      "  episode_reward_mean: 5.3165217391304385\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 134903\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0286018418020992\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01472206880096235\n",
      "          policy_loss: -0.069657380432412\n",
      "          total_loss: 0.07538669138055294\n",
      "          vf_explained_var: 0.9393524527549744\n",
      "          vf_loss: 0.13179137568198981\n",
      "    num_agent_steps_sampled: 6957126\n",
      "    num_agent_steps_trained: 6957126\n",
      "    num_steps_sampled: 6957126\n",
      "    num_steps_trained: 6957126\n",
      "  iterations_since_restore: 356\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.68777348777348\n",
      "    ram_util_percent: 53.59871299871301\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527889636149113\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.739784616010844\n",
      "    mean_inference_ms: 19.477444392795633\n",
      "    mean_raw_obs_processing_ms: 3.2882823122693163\n",
      "  time_since_restore: 195456.4262084961\n",
      "  time_this_iter_s: 543.9815821647644\n",
      "  time_total_s: 390273.7897939682\n",
      "  timers:\n",
      "    learn_throughput: 28.326\n",
      "    learn_time_ms: 352894.211\n",
      "    load_throughput: 88656.202\n",
      "    load_time_ms: 112.75\n",
      "    sample_throughput: 52.126\n",
      "    sample_time_ms: 191766.488\n",
      "    update_time_ms: 6.058\n",
      "  timestamp: 1637651601\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6957126\n",
      "  training_iteration: 756\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   756</td><td style=\"text-align: right;\">          390274</td><td style=\"text-align: right;\">6957126</td><td style=\"text-align: right;\"> 5.31652</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           53.9946</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6967122\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_07-22-50\n",
      "  done: false\n",
      "  episode_len_mean: 54.193548387096776\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.649999999999988\n",
      "  episode_reward_mean: 5.640161290322584\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 135089\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0159239019734794\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015258035387613028\n",
      "          policy_loss: -0.06767427859362156\n",
      "          total_loss: 0.08320648589614864\n",
      "          vf_explained_var: 0.9370319247245789\n",
      "          vf_loss: 0.13628029052923663\n",
      "    num_agent_steps_sampled: 6967122\n",
      "    num_agent_steps_trained: 6967122\n",
      "    num_steps_sampled: 6967122\n",
      "    num_steps_trained: 6967122\n",
      "  iterations_since_restore: 357\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.21393341553637\n",
      "    ram_util_percent: 53.94093711467323\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052779561715940414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.732040203895995\n",
      "    mean_inference_ms: 19.47628157050095\n",
      "    mean_raw_obs_processing_ms: 3.2975706759771826\n",
      "  time_since_restore: 196025.36897945404\n",
      "  time_this_iter_s: 568.9427709579468\n",
      "  time_total_s: 390842.73256492615\n",
      "  timers:\n",
      "    learn_throughput: 28.317\n",
      "    learn_time_ms: 352999.855\n",
      "    load_throughput: 88490.937\n",
      "    load_time_ms: 112.961\n",
      "    sample_throughput: 51.161\n",
      "    sample_time_ms: 195382.739\n",
      "    update_time_ms: 5.739\n",
      "  timestamp: 1637652170\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6967122\n",
      "  training_iteration: 757\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   757</td><td style=\"text-align: right;\">          390843</td><td style=\"text-align: right;\">6967122</td><td style=\"text-align: right;\"> 5.64016</td><td style=\"text-align: right;\">               17.65</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           54.1935</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6977118\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_07-31-37\n",
      "  done: false\n",
      "  episode_len_mean: 54.52197802197802\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.63999999999999\n",
      "  episode_reward_mean: 5.41516483516484\n",
      "  episode_reward_min: -0.6800000000000004\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 135271\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0382408351543915\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01546451928468997\n",
      "          policy_loss: -0.06356839062888198\n",
      "          total_loss: 0.11855772782067044\n",
      "          vf_explained_var: 0.9490157961845398\n",
      "          vf_loss: 0.16727841757929857\n",
      "    num_agent_steps_sampled: 6977118\n",
      "    num_agent_steps_trained: 6977118\n",
      "    num_steps_sampled: 6977118\n",
      "    num_steps_trained: 6977118\n",
      "  iterations_since_restore: 358\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.86759628154051\n",
      "    ram_util_percent: 53.209827357237714\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278535553338671\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.729606260043127\n",
      "    mean_inference_ms: 19.478375626519604\n",
      "    mean_raw_obs_processing_ms: 3.2919389328350492\n",
      "  time_since_restore: 196552.92332839966\n",
      "  time_this_iter_s: 527.5543489456177\n",
      "  time_total_s: 391370.28691387177\n",
      "  timers:\n",
      "    learn_throughput: 28.315\n",
      "    learn_time_ms: 353033.882\n",
      "    load_throughput: 88523.653\n",
      "    load_time_ms: 112.919\n",
      "    sample_throughput: 51.948\n",
      "    sample_time_ms: 192422.203\n",
      "    update_time_ms: 5.779\n",
      "  timestamp: 1637652697\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6977118\n",
      "  training_iteration: 758\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   758</td><td style=\"text-align: right;\">          391370</td><td style=\"text-align: right;\">6977118</td><td style=\"text-align: right;\"> 5.41516</td><td style=\"text-align: right;\">               21.64</td><td style=\"text-align: right;\">               -0.68</td><td style=\"text-align: right;\">            54.522</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6987114\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_07-40-56\n",
      "  done: false\n",
      "  episode_len_mean: 52.94708994708995\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.530000000000008\n",
      "  episode_reward_mean: 5.442857142857147\n",
      "  episode_reward_min: -0.6000000000000003\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 135460\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.021507510506963\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014338902692810433\n",
      "          policy_loss: -0.07030569352382701\n",
      "          total_loss: 0.07489254383447891\n",
      "          vf_explained_var: 0.9528221487998962\n",
      "          vf_loss: 0.1327474977619138\n",
      "    num_agent_steps_sampled: 6987114\n",
      "    num_agent_steps_trained: 6987114\n",
      "    num_steps_sampled: 6987114\n",
      "    num_steps_trained: 6987114\n",
      "  iterations_since_restore: 359\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.40338770388959\n",
      "    ram_util_percent: 53.26148055207025\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05276695379728732\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.724809528073397\n",
      "    mean_inference_ms: 19.475423324070178\n",
      "    mean_raw_obs_processing_ms: 3.3006578090838268\n",
      "  time_since_restore: 197111.53055500984\n",
      "  time_this_iter_s: 558.6072266101837\n",
      "  time_total_s: 391928.89414048195\n",
      "  timers:\n",
      "    learn_throughput: 28.315\n",
      "    learn_time_ms: 353025.504\n",
      "    load_throughput: 88495.644\n",
      "    load_time_ms: 112.955\n",
      "    sample_throughput: 51.242\n",
      "    sample_time_ms: 195073.398\n",
      "    update_time_ms: 5.807\n",
      "  timestamp: 1637653256\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6987114\n",
      "  training_iteration: 759\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   759</td><td style=\"text-align: right;\">          391929</td><td style=\"text-align: right;\">6987114</td><td style=\"text-align: right;\"> 5.44286</td><td style=\"text-align: right;\">               15.53</td><td style=\"text-align: right;\">                -0.6</td><td style=\"text-align: right;\">           52.9471</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 6997110\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_07-50-02\n",
      "  done: false\n",
      "  episode_len_mean: 53.657754010695186\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.54000000000001\n",
      "  episode_reward_mean: 5.234224598930485\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 135647\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.055350554013348\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015193386183505348\n",
      "          policy_loss: -0.06992708396060462\n",
      "          total_loss: 0.08135201183611052\n",
      "          vf_explained_var: 0.9189697504043579\n",
      "          vf_loss: 0.13722016661985212\n",
      "    num_agent_steps_sampled: 6997110\n",
      "    num_agent_steps_trained: 6997110\n",
      "    num_steps_sampled: 6997110\n",
      "    num_steps_trained: 6997110\n",
      "  iterations_since_restore: 360\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7186136071887\n",
      "    ram_util_percent: 52.88228498074455\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05277763698807038\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.724203033608646\n",
      "    mean_inference_ms: 19.477699698608152\n",
      "    mean_raw_obs_processing_ms: 3.3002879494437134\n",
      "  time_since_restore: 197657.56906223297\n",
      "  time_this_iter_s: 546.0385072231293\n",
      "  time_total_s: 392474.9326477051\n",
      "  timers:\n",
      "    learn_throughput: 28.307\n",
      "    learn_time_ms: 353124.515\n",
      "    load_throughput: 88487.165\n",
      "    load_time_ms: 112.966\n",
      "    sample_throughput: 51.662\n",
      "    sample_time_ms: 193488.136\n",
      "    update_time_ms: 6.073\n",
      "  timestamp: 1637653802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6997110\n",
      "  training_iteration: 760\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   760</td><td style=\"text-align: right;\">          392475</td><td style=\"text-align: right;\">6997110</td><td style=\"text-align: right;\"> 5.23422</td><td style=\"text-align: right;\">               15.54</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           53.6578</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7007106\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_07-59-18\n",
      "  done: false\n",
      "  episode_len_mean: 53.65945945945946\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000007\n",
      "  episode_reward_mean: 5.626702702702706\n",
      "  episode_reward_min: -0.45000000000000023\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 135832\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0358319630345187\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01588318551351597\n",
      "          policy_loss: -0.07004689872865932\n",
      "          total_loss: 0.09429643487272144\n",
      "          vf_explained_var: 0.9317222237586975\n",
      "          vf_loss: 0.14851777021376694\n",
      "    num_agent_steps_sampled: 7007106\n",
      "    num_agent_steps_trained: 7007106\n",
      "    num_steps_sampled: 7007106\n",
      "    num_steps_trained: 7007106\n",
      "  iterations_since_restore: 361\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.50125944584383\n",
      "    ram_util_percent: 53.71335012594458\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278445438373323\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.71869891846031\n",
      "    mean_inference_ms: 19.478588978347844\n",
      "    mean_raw_obs_processing_ms: 3.3097376051184577\n",
      "  time_since_restore: 198213.80218100548\n",
      "  time_this_iter_s: 556.2331187725067\n",
      "  time_total_s: 393031.1657664776\n",
      "  timers:\n",
      "    learn_throughput: 28.301\n",
      "    learn_time_ms: 353201.083\n",
      "    load_throughput: 88561.706\n",
      "    load_time_ms: 112.87\n",
      "    sample_throughput: 51.318\n",
      "    sample_time_ms: 194785.483\n",
      "    update_time_ms: 6.408\n",
      "  timestamp: 1637654358\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7007106\n",
      "  training_iteration: 761\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   761</td><td style=\"text-align: right;\">          393031</td><td style=\"text-align: right;\">7007106</td><td style=\"text-align: right;\">  5.6267</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">           53.6595</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7017102\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_08-08-07\n",
      "  done: false\n",
      "  episode_len_mean: 55.03825136612022\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.540000000000006\n",
      "  episode_reward_mean: 5.37475409836066\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 136015\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0029604468958446\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014986980668952493\n",
      "          policy_loss: -0.06940128390136756\n",
      "          total_loss: 0.07691961262631469\n",
      "          vf_explained_var: 0.9399338364601135\n",
      "          vf_loss: 0.1322082842785274\n",
      "    num_agent_steps_sampled: 7017102\n",
      "    num_agent_steps_trained: 7017102\n",
      "    num_steps_sampled: 7017102\n",
      "    num_steps_trained: 7017102\n",
      "  iterations_since_restore: 362\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1632625994695\n",
      "    ram_util_percent: 53.074933687002655\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527885388019548\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.715105228546015\n",
      "    mean_inference_ms: 19.476567695955644\n",
      "    mean_raw_obs_processing_ms: 3.3037566704808357\n",
      "  time_since_restore: 198742.25564432144\n",
      "  time_this_iter_s: 528.4534633159637\n",
      "  time_total_s: 393559.61922979355\n",
      "  timers:\n",
      "    learn_throughput: 28.294\n",
      "    learn_time_ms: 353290.612\n",
      "    load_throughput: 88406.485\n",
      "    load_time_ms: 113.069\n",
      "    sample_throughput: 51.82\n",
      "    sample_time_ms: 192899.235\n",
      "    update_time_ms: 6.258\n",
      "  timestamp: 1637654887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7017102\n",
      "  training_iteration: 762\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   762</td><td style=\"text-align: right;\">          393560</td><td style=\"text-align: right;\">7017102</td><td style=\"text-align: right;\"> 5.37475</td><td style=\"text-align: right;\">               17.54</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           55.0383</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7027098\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_08-17-11\n",
      "  done: false\n",
      "  episode_len_mean: 53.49732620320856\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.539999999999978\n",
      "  episode_reward_mean: 5.083475935828881\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 136202\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.024127500722686\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014771955788956743\n",
      "          policy_loss: -0.06877148604303712\n",
      "          total_loss: 0.08040922839555865\n",
      "          vf_explained_var: 0.9332848787307739\n",
      "          vf_loss: 0.13576962636291875\n",
      "    num_agent_steps_sampled: 7027098\n",
      "    num_agent_steps_trained: 7027098\n",
      "    num_steps_sampled: 7027098\n",
      "    num_steps_trained: 7027098\n",
      "  iterations_since_restore: 363\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.15399484536083\n",
      "    ram_util_percent: 52.906443298969066\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278727936937903\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.7133210745573\n",
      "    mean_inference_ms: 19.47777928242807\n",
      "    mean_raw_obs_processing_ms: 3.302761239498974\n",
      "  time_since_restore: 199286.54366278648\n",
      "  time_this_iter_s: 544.2880184650421\n",
      "  time_total_s: 394103.9072482586\n",
      "  timers:\n",
      "    learn_throughput: 28.281\n",
      "    learn_time_ms: 353448.242\n",
      "    load_throughput: 88233.161\n",
      "    load_time_ms: 113.291\n",
      "    sample_throughput: 51.897\n",
      "    sample_time_ms: 192610.88\n",
      "    update_time_ms: 5.812\n",
      "  timestamp: 1637655431\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7027098\n",
      "  training_iteration: 763\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   763</td><td style=\"text-align: right;\">          394104</td><td style=\"text-align: right;\">7027098</td><td style=\"text-align: right;\"> 5.08348</td><td style=\"text-align: right;\">               19.54</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.4973</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7037094\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_08-26-02\n",
      "  done: false\n",
      "  episode_len_mean: 54.016216216216215\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.540000000000008\n",
      "  episode_reward_mean: 5.126864864864869\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 136387\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.034149568554867\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014315594572422825\n",
      "          policy_loss: -0.07184492327269912\n",
      "          total_loss: 0.0696627187934847\n",
      "          vf_explained_var: 0.9412981271743774\n",
      "          vf_loss: 0.12923642232430627\n",
      "    num_agent_steps_sampled: 7037094\n",
      "    num_agent_steps_trained: 7037094\n",
      "    num_steps_sampled: 7037094\n",
      "    num_steps_trained: 7037094\n",
      "  iterations_since_restore: 364\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8928759894459\n",
      "    ram_util_percent: 52.928100263852244\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052785175323535535\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.713411656089573\n",
      "    mean_inference_ms: 19.47837656102133\n",
      "    mean_raw_obs_processing_ms: 3.2969156190324416\n",
      "  time_since_restore: 199817.88807678223\n",
      "  time_this_iter_s: 531.3444139957428\n",
      "  time_total_s: 394635.25166225433\n",
      "  timers:\n",
      "    learn_throughput: 28.271\n",
      "    learn_time_ms: 353574.566\n",
      "    load_throughput: 88329.655\n",
      "    load_time_ms: 113.167\n",
      "    sample_throughput: 52.01\n",
      "    sample_time_ms: 192192.824\n",
      "    update_time_ms: 5.773\n",
      "  timestamp: 1637655962\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7037094\n",
      "  training_iteration: 764\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   764</td><td style=\"text-align: right;\">          394635</td><td style=\"text-align: right;\">7037094</td><td style=\"text-align: right;\"> 5.12686</td><td style=\"text-align: right;\">               15.54</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           54.0162</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7047090\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_08-35-13\n",
      "  done: false\n",
      "  episode_len_mean: 52.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.51999999999996\n",
      "  episode_reward_mean: 5.51268421052632\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 136577\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0298245137714477\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014517568991640261\n",
      "          policy_loss: -0.05879127342378929\n",
      "          total_loss: 0.09663333651312413\n",
      "          vf_explained_var: 0.9507020115852356\n",
      "          vf_loss: 0.14265001771268415\n",
      "    num_agent_steps_sampled: 7047090\n",
      "    num_agent_steps_trained: 7047090\n",
      "    num_steps_sampled: 7047090\n",
      "    num_steps_trained: 7047090\n",
      "  iterations_since_restore: 365\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.65796178343949\n",
      "    ram_util_percent: 53.83324840764331\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279030180315857\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.71533009732879\n",
      "    mean_inference_ms: 19.478871246269613\n",
      "    mean_raw_obs_processing_ms: 3.301209847861191\n",
      "  time_since_restore: 200368.20380330086\n",
      "  time_this_iter_s: 550.315726518631\n",
      "  time_total_s: 395185.56738877296\n",
      "  timers:\n",
      "    learn_throughput: 28.266\n",
      "    learn_time_ms: 353634.449\n",
      "    load_throughput: 88467.242\n",
      "    load_time_ms: 112.991\n",
      "    sample_throughput: 52.114\n",
      "    sample_time_ms: 191811.346\n",
      "    update_time_ms: 5.729\n",
      "  timestamp: 1637656513\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7047090\n",
      "  training_iteration: 765\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   765</td><td style=\"text-align: right;\">          395186</td><td style=\"text-align: right;\">7047090</td><td style=\"text-align: right;\"> 5.51268</td><td style=\"text-align: right;\">               19.52</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">              52.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7057086\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_08-44-24\n",
      "  done: false\n",
      "  episode_len_mean: 54.18478260869565\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.55\n",
      "  episode_reward_mean: 5.130326086956527\n",
      "  episode_reward_min: -0.7500000000000004\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 136761\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0341447005070834\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015216690175422678\n",
      "          policy_loss: -0.06491168148426091\n",
      "          total_loss: 0.09273843396231862\n",
      "          vf_explained_var: 0.9394160509109497\n",
      "          vf_loss: 0.143326039348325\n",
      "    num_agent_steps_sampled: 7057086\n",
      "    num_agent_steps_trained: 7057086\n",
      "    num_steps_sampled: 7057086\n",
      "    num_steps_trained: 7057086\n",
      "  iterations_since_restore: 366\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.58792884371029\n",
      "    ram_util_percent: 54.20902160101652\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052791379749774034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.71184489778104\n",
      "    mean_inference_ms: 19.479844778953105\n",
      "    mean_raw_obs_processing_ms: 3.303288784620659\n",
      "  time_since_restore: 200919.82128548622\n",
      "  time_this_iter_s: 551.6174821853638\n",
      "  time_total_s: 395737.1848709583\n",
      "  timers:\n",
      "    learn_throughput: 28.263\n",
      "    learn_time_ms: 353672.695\n",
      "    load_throughput: 88289.571\n",
      "    load_time_ms: 113.218\n",
      "    sample_throughput: 51.917\n",
      "    sample_time_ms: 192536.499\n",
      "    update_time_ms: 5.732\n",
      "  timestamp: 1637657064\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7057086\n",
      "  training_iteration: 766\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   766</td><td style=\"text-align: right;\">          395737</td><td style=\"text-align: right;\">7057086</td><td style=\"text-align: right;\"> 5.13033</td><td style=\"text-align: right;\">               17.55</td><td style=\"text-align: right;\">               -0.75</td><td style=\"text-align: right;\">           54.1848</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7067082\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_08-53-32\n",
      "  done: false\n",
      "  episode_len_mean: 54.344086021505376\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.55\n",
      "  episode_reward_mean: 5.29639784946237\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 136947\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0158178704570098\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015102094182316133\n",
      "          policy_loss: -0.07063186511305214\n",
      "          total_loss: 0.0906817807361733\n",
      "          vf_explained_var: 0.9375714063644409\n",
      "          vf_loss: 0.14706736526650238\n",
      "    num_agent_steps_sampled: 7067082\n",
      "    num_agent_steps_trained: 7067082\n",
      "    num_steps_sampled: 7067082\n",
      "    num_steps_trained: 7067082\n",
      "  iterations_since_restore: 367\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75262483994877\n",
      "    ram_util_percent: 54.56773367477593\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052794313200576405\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.709378940209728\n",
      "    mean_inference_ms: 19.479574072562805\n",
      "    mean_raw_obs_processing_ms: 3.3075724393739994\n",
      "  time_since_restore: 201467.19407367706\n",
      "  time_this_iter_s: 547.3727881908417\n",
      "  time_total_s: 396284.55765914917\n",
      "  timers:\n",
      "    learn_throughput: 28.263\n",
      "    learn_time_ms: 353676.806\n",
      "    load_throughput: 88505.826\n",
      "    load_time_ms: 112.942\n",
      "    sample_throughput: 52.507\n",
      "    sample_time_ms: 190375.088\n",
      "    update_time_ms: 6.139\n",
      "  timestamp: 1637657612\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7067082\n",
      "  training_iteration: 767\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   767</td><td style=\"text-align: right;\">          396285</td><td style=\"text-align: right;\">7067082</td><td style=\"text-align: right;\">  5.2964</td><td style=\"text-align: right;\">               17.55</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           54.3441</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7077078\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_09-02-53\n",
      "  done: false\n",
      "  episode_len_mean: 54.55494505494506\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000007\n",
      "  episode_reward_mean: 5.209120879120883\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 137129\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0166550524981623\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015205148044033867\n",
      "          policy_loss: -0.0658806287960106\n",
      "          total_loss: 0.09218980893345134\n",
      "          vf_explained_var: 0.9390846490859985\n",
      "          vf_loss: 0.14359775864178817\n",
      "    num_agent_steps_sampled: 7077078\n",
      "    num_agent_steps_trained: 7077078\n",
      "    num_steps_sampled: 7077078\n",
      "    num_steps_trained: 7077078\n",
      "  iterations_since_restore: 368\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.75280898876404\n",
      "    ram_util_percent: 54.3541822721598\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052780247672474905\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.703501903113228\n",
      "    mean_inference_ms: 19.478054897590148\n",
      "    mean_raw_obs_processing_ms: 3.320621562085061\n",
      "  time_since_restore: 202028.15146827698\n",
      "  time_this_iter_s: 560.9573945999146\n",
      "  time_total_s: 396845.5150537491\n",
      "  timers:\n",
      "    learn_throughput: 28.256\n",
      "    learn_time_ms: 353765.96\n",
      "    load_throughput: 88401.117\n",
      "    load_time_ms: 113.075\n",
      "    sample_throughput: 51.625\n",
      "    sample_time_ms: 193625.85\n",
      "    update_time_ms: 6.137\n",
      "  timestamp: 1637658173\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7077078\n",
      "  training_iteration: 768\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   768</td><td style=\"text-align: right;\">          396846</td><td style=\"text-align: right;\">7077078</td><td style=\"text-align: right;\"> 5.20912</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           54.5549</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7087074\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_09-11-41\n",
      "  done: false\n",
      "  episode_len_mean: 55.29834254143646\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.619999999999983\n",
      "  episode_reward_mean: 5.32519337016575\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 137310\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0076678069959204\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015833225450816113\n",
      "          policy_loss: -0.07048433666086457\n",
      "          total_loss: 0.09193983025722982\n",
      "          vf_explained_var: 0.9279422163963318\n",
      "          vf_loss: 0.14643077772469765\n",
      "    num_agent_steps_sampled: 7087074\n",
      "    num_agent_steps_trained: 7087074\n",
      "    num_steps_sampled: 7087074\n",
      "    num_steps_trained: 7087074\n",
      "  iterations_since_restore: 369\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.88499335989376\n",
      "    ram_util_percent: 53.082735723771584\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278617183055313\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.70085501974139\n",
      "    mean_inference_ms: 19.480378633144255\n",
      "    mean_raw_obs_processing_ms: 3.3154621207208783\n",
      "  time_since_restore: 202556.44823026657\n",
      "  time_this_iter_s: 528.2967619895935\n",
      "  time_total_s: 397373.8118157387\n",
      "  timers:\n",
      "    learn_throughput: 28.245\n",
      "    learn_time_ms: 353897.333\n",
      "    load_throughput: 88530.027\n",
      "    load_time_ms: 112.911\n",
      "    sample_throughput: 52.482\n",
      "    sample_time_ms: 190463.54\n",
      "    update_time_ms: 6.159\n",
      "  timestamp: 1637658701\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7087074\n",
      "  training_iteration: 769\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   769</td><td style=\"text-align: right;\">          397374</td><td style=\"text-align: right;\">7087074</td><td style=\"text-align: right;\"> 5.32519</td><td style=\"text-align: right;\">               17.62</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           55.2983</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7097070\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_09-20-45\n",
      "  done: false\n",
      "  episode_len_mean: 54.9010989010989\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.434670329670334\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 137492\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0201978806989738\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015255571802873678\n",
      "          policy_loss: -0.06634524008869305\n",
      "          total_loss: 0.0990682159392886\n",
      "          vf_explained_var: 0.9264796376228333\n",
      "          vf_loss: 0.15086133606445762\n",
      "    num_agent_steps_sampled: 7097070\n",
      "    num_agent_steps_trained: 7097070\n",
      "    num_steps_sampled: 7097070\n",
      "    num_steps_trained: 7097070\n",
      "  iterations_since_restore: 370\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.57938144329897\n",
      "    ram_util_percent: 53.06997422680413\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052788292487182475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.69692512538543\n",
      "    mean_inference_ms: 19.479940155664874\n",
      "    mean_raw_obs_processing_ms: 3.314454203006446\n",
      "  time_since_restore: 203100.28249049187\n",
      "  time_this_iter_s: 543.834260225296\n",
      "  time_total_s: 397917.646075964\n",
      "  timers:\n",
      "    learn_throughput: 28.246\n",
      "    learn_time_ms: 353896.823\n",
      "    load_throughput: 88674.991\n",
      "    load_time_ms: 112.726\n",
      "    sample_throughput: 52.543\n",
      "    sample_time_ms: 190243.371\n",
      "    update_time_ms: 5.894\n",
      "  timestamp: 1637659245\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7097070\n",
      "  training_iteration: 770\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   770</td><td style=\"text-align: right;\">          397918</td><td style=\"text-align: right;\">7097070</td><td style=\"text-align: right;\"> 5.43467</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           54.9011</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7107066\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_09-29-59\n",
      "  done: false\n",
      "  episode_len_mean: 54.45108695652174\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.550000000000008\n",
      "  episode_reward_mean: 4.918260869565222\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 137676\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0599623867067467\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014530177176119185\n",
      "          policy_loss: -0.07016032147135212\n",
      "          total_loss: 0.0790992136930123\n",
      "          vf_explained_var: 0.9310746192932129\n",
      "          vf_loss: 0.13675759836552612\n",
      "    num_agent_steps_sampled: 7107066\n",
      "    num_agent_steps_trained: 7107066\n",
      "    num_steps_sampled: 7107066\n",
      "    num_steps_trained: 7107066\n",
      "  iterations_since_restore: 371\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.50164556962025\n",
      "    ram_util_percent: 53.253291139240496\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052788435231499266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.690750557286552\n",
      "    mean_inference_ms: 19.478783926144224\n",
      "    mean_raw_obs_processing_ms: 3.317674943565819\n",
      "  time_since_restore: 203653.79072117805\n",
      "  time_this_iter_s: 553.5082306861877\n",
      "  time_total_s: 398471.15430665016\n",
      "  timers:\n",
      "    learn_throughput: 28.244\n",
      "    learn_time_ms: 353913.878\n",
      "    load_throughput: 88617.226\n",
      "    load_time_ms: 112.8\n",
      "    sample_throughput: 52.623\n",
      "    sample_time_ms: 189953.431\n",
      "    update_time_ms: 5.957\n",
      "  timestamp: 1637659799\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7107066\n",
      "  training_iteration: 771\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   771</td><td style=\"text-align: right;\">          398471</td><td style=\"text-align: right;\">7107066</td><td style=\"text-align: right;\"> 4.91826</td><td style=\"text-align: right;\">               15.55</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           54.4511</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7117062\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_09-39-04\n",
      "  done: false\n",
      "  episode_len_mean: 55.37777777777778\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.519999999999985\n",
      "  episode_reward_mean: 5.008777777777782\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 137856\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.047968835763663\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015321427289116138\n",
      "          policy_loss: -0.06604383529673974\n",
      "          total_loss: 0.09210272446607815\n",
      "          vf_explained_var: 0.9323095083236694\n",
      "          vf_loss: 0.1437221212280787\n",
      "    num_agent_steps_sampled: 7117062\n",
      "    num_agent_steps_trained: 7117062\n",
      "    num_steps_sampled: 7117062\n",
      "    num_steps_trained: 7117062\n",
      "  iterations_since_restore: 372\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.40848329048842\n",
      "    ram_util_percent: 53.48303341902314\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279508895767641\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.687946931404287\n",
      "    mean_inference_ms: 19.481464217313054\n",
      "    mean_raw_obs_processing_ms: 3.3169859054920656\n",
      "  time_since_restore: 204199.229480505\n",
      "  time_this_iter_s: 545.4387593269348\n",
      "  time_total_s: 399016.5930659771\n",
      "  timers:\n",
      "    learn_throughput: 28.242\n",
      "    learn_time_ms: 353936.839\n",
      "    load_throughput: 88741.414\n",
      "    load_time_ms: 112.642\n",
      "    sample_throughput: 52.163\n",
      "    sample_time_ms: 191629.155\n",
      "    update_time_ms: 6.238\n",
      "  timestamp: 1637660344\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7117062\n",
      "  training_iteration: 772\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   772</td><td style=\"text-align: right;\">          399017</td><td style=\"text-align: right;\">7117062</td><td style=\"text-align: right;\"> 5.00878</td><td style=\"text-align: right;\">               19.52</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           55.3778</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7127058\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_09-47-53\n",
      "  done: false\n",
      "  episode_len_mean: 55.90449438202247\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.449999999999992\n",
      "  episode_reward_mean: 5.267808988764049\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 178\n",
      "  episodes_total: 138034\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0169567248428684\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015054411429003874\n",
      "          policy_loss: -0.06713731741409258\n",
      "          total_loss: 0.07960977733656989\n",
      "          vf_explained_var: 0.9392080307006836\n",
      "          vf_loss: 0.1326208289096461\n",
      "    num_agent_steps_sampled: 7127058\n",
      "    num_agent_steps_trained: 7127058\n",
      "    num_steps_sampled: 7127058\n",
      "    num_steps_trained: 7127058\n",
      "  iterations_since_restore: 373\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.94384105960266\n",
      "    ram_util_percent: 53.3615894039735\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052792968035489614\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.684100003287718\n",
      "    mean_inference_ms: 19.480473318405377\n",
      "    mean_raw_obs_processing_ms: 3.310774040901669\n",
      "  time_since_restore: 204728.0504848957\n",
      "  time_this_iter_s: 528.8210043907166\n",
      "  time_total_s: 399545.4140703678\n",
      "  timers:\n",
      "    learn_throughput: 28.24\n",
      "    learn_time_ms: 353964.678\n",
      "    load_throughput: 88865.16\n",
      "    load_time_ms: 112.485\n",
      "    sample_throughput: 52.595\n",
      "    sample_time_ms: 190055.065\n",
      "    update_time_ms: 5.902\n",
      "  timestamp: 1637660873\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7127058\n",
      "  training_iteration: 773\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   773</td><td style=\"text-align: right;\">          399545</td><td style=\"text-align: right;\">7127058</td><td style=\"text-align: right;\"> 5.26781</td><td style=\"text-align: right;\">               17.45</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           55.9045</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7137054\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_09-57-36\n",
      "  done: false\n",
      "  episode_len_mean: 54.78804347826087\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.59\n",
      "  episode_reward_mean: 5.061304347826091\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 138218\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.044940500015236\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014638468206555396\n",
      "          policy_loss: -0.07234340859192515\n",
      "          total_loss: 0.07383033950652744\n",
      "          vf_explained_var: 0.9340908527374268\n",
      "          vf_loss: 0.13327489074256016\n",
      "    num_agent_steps_sampled: 7137054\n",
      "    num_agent_steps_trained: 7137054\n",
      "    num_steps_sampled: 7137054\n",
      "    num_steps_trained: 7137054\n",
      "  iterations_since_restore: 374\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.3233173076923\n",
      "    ram_util_percent: 54.035697115384615\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279857303689348\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.679189888063334\n",
      "    mean_inference_ms: 19.48251202522912\n",
      "    mean_raw_obs_processing_ms: 3.326978702684323\n",
      "  time_since_restore: 205311.3576478958\n",
      "  time_this_iter_s: 583.3071630001068\n",
      "  time_total_s: 400128.7212333679\n",
      "  timers:\n",
      "    learn_throughput: 28.239\n",
      "    learn_time_ms: 353975.631\n",
      "    load_throughput: 88893.31\n",
      "    load_time_ms: 112.449\n",
      "    sample_throughput: 51.198\n",
      "    sample_time_ms: 195240.266\n",
      "    update_time_ms: 5.843\n",
      "  timestamp: 1637661456\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7137054\n",
      "  training_iteration: 774\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   774</td><td style=\"text-align: right;\">          400129</td><td style=\"text-align: right;\">7137054</td><td style=\"text-align: right;\">  5.0613</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">            54.788</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7147050\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_10-06-38\n",
      "  done: false\n",
      "  episode_len_mean: 54.47540983606557\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 4.849180327868857\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 138401\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.023738563156511\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014753456056381085\n",
      "          policy_loss: -0.06971381918984519\n",
      "          total_loss: 0.08371310465395601\n",
      "          vf_explained_var: 0.9114718437194824\n",
      "          vf_loss: 0.1400540903718379\n",
      "    num_agent_steps_sampled: 7147050\n",
      "    num_agent_steps_trained: 7147050\n",
      "    num_steps_sampled: 7147050\n",
      "    num_steps_trained: 7147050\n",
      "  iterations_since_restore: 375\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77567917205693\n",
      "    ram_util_percent: 54.19624838292367\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052786741688586915\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.67485371741304\n",
      "    mean_inference_ms: 19.480852366174222\n",
      "    mean_raw_obs_processing_ms: 3.3253207296289453\n",
      "  time_since_restore: 205852.80251145363\n",
      "  time_this_iter_s: 541.4448635578156\n",
      "  time_total_s: 400670.16609692574\n",
      "  timers:\n",
      "    learn_throughput: 28.239\n",
      "    learn_time_ms: 353983.869\n",
      "    load_throughput: 89067.139\n",
      "    load_time_ms: 112.23\n",
      "    sample_throughput: 51.434\n",
      "    sample_time_ms: 194345.124\n",
      "    update_time_ms: 5.531\n",
      "  timestamp: 1637661998\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7147050\n",
      "  training_iteration: 775\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   775</td><td style=\"text-align: right;\">          400670</td><td style=\"text-align: right;\">7147050</td><td style=\"text-align: right;\"> 4.84918</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           54.4754</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7157046\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_10-15-26\n",
      "  done: false\n",
      "  episode_len_mean: 54.76923076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.600000000000005\n",
      "  episode_reward_mean: 5.408241758241762\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 138583\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.022441729604001\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015782356742937178\n",
      "          policy_loss: -0.06738052447561599\n",
      "          total_loss: 0.0987811514602459\n",
      "          vf_explained_var: 0.9320783019065857\n",
      "          vf_loss: 0.15043191202321504\n",
      "    num_agent_steps_sampled: 7157046\n",
      "    num_agent_steps_trained: 7157046\n",
      "    num_steps_sampled: 7157046\n",
      "    num_steps_trained: 7157046\n",
      "  iterations_since_restore: 376\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02257636122178\n",
      "    ram_util_percent: 53.62337317397078\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278130836278864\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.671857762671628\n",
      "    mean_inference_ms: 19.48051088765522\n",
      "    mean_raw_obs_processing_ms: 3.3196728107200366\n",
      "  time_since_restore: 206381.05234718323\n",
      "  time_this_iter_s: 528.249835729599\n",
      "  time_total_s: 401198.41593265533\n",
      "  timers:\n",
      "    learn_throughput: 28.235\n",
      "    learn_time_ms: 354029.556\n",
      "    load_throughput: 89327.84\n",
      "    load_time_ms: 111.902\n",
      "    sample_throughput: 52.072\n",
      "    sample_time_ms: 191963.711\n",
      "    update_time_ms: 5.14\n",
      "  timestamp: 1637662526\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7157046\n",
      "  training_iteration: 776\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   776</td><td style=\"text-align: right;\">          401198</td><td style=\"text-align: right;\">7157046</td><td style=\"text-align: right;\"> 5.40824</td><td style=\"text-align: right;\">                17.6</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           54.7692</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7167042\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_10-24-31\n",
      "  done: false\n",
      "  episode_len_mean: 55.23076923076923\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.610000000000003\n",
      "  episode_reward_mean: 5.498406593406598\n",
      "  episode_reward_min: -0.6300000000000003\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 138765\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0482899389592517\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01551550278819391\n",
      "          policy_loss: -0.06443905025163883\n",
      "          total_loss: 0.10034746121014233\n",
      "          vf_explained_var: 0.9264808297157288\n",
      "          vf_loss: 0.14992315406185466\n",
      "    num_agent_steps_sampled: 7167042\n",
      "    num_agent_steps_trained: 7167042\n",
      "    num_steps_sampled: 7167042\n",
      "    num_steps_trained: 7167042\n",
      "  iterations_since_restore: 377\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.3910025706941\n",
      "    ram_util_percent: 53.38226221079692\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278991527604282\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.669338865088267\n",
      "    mean_inference_ms: 19.48348813098183\n",
      "    mean_raw_obs_processing_ms: 3.319492352636718\n",
      "  time_since_restore: 206925.9930202961\n",
      "  time_this_iter_s: 544.9406731128693\n",
      "  time_total_s: 401743.3566057682\n",
      "  timers:\n",
      "    learn_throughput: 28.231\n",
      "    learn_time_ms: 354076.091\n",
      "    load_throughput: 89108.274\n",
      "    load_time_ms: 112.178\n",
      "    sample_throughput: 52.151\n",
      "    sample_time_ms: 191673.861\n",
      "    update_time_ms: 5.177\n",
      "  timestamp: 1637663071\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7167042\n",
      "  training_iteration: 777\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   777</td><td style=\"text-align: right;\">          401743</td><td style=\"text-align: right;\">7167042</td><td style=\"text-align: right;\"> 5.49841</td><td style=\"text-align: right;\">               17.61</td><td style=\"text-align: right;\">               -0.63</td><td style=\"text-align: right;\">           55.2308</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7177038\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_10-33-33\n",
      "  done: false\n",
      "  episode_len_mean: 54.77049180327869\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.560000000000008\n",
      "  episode_reward_mean: 5.210000000000004\n",
      "  episode_reward_min: -0.7100000000000004\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 138948\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0373984205674933\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01564297747201977\n",
      "          policy_loss: -0.0697254446203293\n",
      "          total_loss: 0.0927282939428244\n",
      "          vf_explained_var: 0.9185498952865601\n",
      "          vf_loss: 0.147191063556016\n",
      "    num_agent_steps_sampled: 7177038\n",
      "    num_agent_steps_trained: 7177038\n",
      "    num_steps_sampled: 7177038\n",
      "    num_steps_trained: 7177038\n",
      "  iterations_since_restore: 378\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.83557567917205\n",
      "    ram_util_percent: 53.12238033635188\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278329829948435\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.664459176166332\n",
      "    mean_inference_ms: 19.48220604295406\n",
      "    mean_raw_obs_processing_ms: 3.3181316527459255\n",
      "  time_since_restore: 207467.57250618935\n",
      "  time_this_iter_s: 541.5794858932495\n",
      "  time_total_s: 402284.93609166145\n",
      "  timers:\n",
      "    learn_throughput: 28.231\n",
      "    learn_time_ms: 354084.674\n",
      "    load_throughput: 89612.992\n",
      "    load_time_ms: 111.546\n",
      "    sample_throughput: 52.686\n",
      "    sample_time_ms: 189728.555\n",
      "    update_time_ms: 4.862\n",
      "  timestamp: 1637663613\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7177038\n",
      "  training_iteration: 778\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   778</td><td style=\"text-align: right;\">          402285</td><td style=\"text-align: right;\">7177038</td><td style=\"text-align: right;\">    5.21</td><td style=\"text-align: right;\">               15.56</td><td style=\"text-align: right;\">               -0.71</td><td style=\"text-align: right;\">           54.7705</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7187034\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_10-42-33\n",
      "  done: false\n",
      "  episode_len_mean: 54.77900552486188\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 5.7155248618784595\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 139129\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.032048925769377\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01473605423269799\n",
      "          policy_loss: -0.07145907934211582\n",
      "          total_loss: 0.08164350753606822\n",
      "          vf_explained_var: 0.9483192563056946\n",
      "          vf_loss: 0.13985250198523547\n",
      "    num_agent_steps_sampled: 7187034\n",
      "    num_agent_steps_trained: 7187034\n",
      "    num_steps_sampled: 7187034\n",
      "    num_steps_trained: 7187034\n",
      "  iterations_since_restore: 379\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.67600518806746\n",
      "    ram_util_percent: 53.46485084306097\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052790622200265036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.65946668853033\n",
      "    mean_inference_ms: 19.48252036435668\n",
      "    mean_raw_obs_processing_ms: 3.3176048623738814\n",
      "  time_since_restore: 208008.40616202354\n",
      "  time_this_iter_s: 540.833655834198\n",
      "  time_total_s: 402825.76974749565\n",
      "  timers:\n",
      "    learn_throughput: 28.231\n",
      "    learn_time_ms: 354075.66\n",
      "    load_throughput: 90343.605\n",
      "    load_time_ms: 110.644\n",
      "    sample_throughput: 52.337\n",
      "    sample_time_ms: 190992.333\n",
      "    update_time_ms: 4.782\n",
      "  timestamp: 1637664153\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7187034\n",
      "  training_iteration: 779\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   779</td><td style=\"text-align: right;\">          402826</td><td style=\"text-align: right;\">7187034</td><td style=\"text-align: right;\"> 5.71552</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">            54.779</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7197030\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_10-51-35\n",
      "  done: false\n",
      "  episode_len_mean: 54.475675675675674\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.679999999999986\n",
      "  episode_reward_mean: 4.784864864864868\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 139314\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0553309253899448\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015230639122248956\n",
      "          policy_loss: -0.07313257483246048\n",
      "          total_loss: 0.07294117759823615\n",
      "          vf_explained_var: 0.9369490742683411\n",
      "          vf_loss: 0.13192976086856759\n",
      "    num_agent_steps_sampled: 7197030\n",
      "    num_agent_steps_trained: 7197030\n",
      "    num_steps_sampled: 7197030\n",
      "    num_steps_trained: 7197030\n",
      "  iterations_since_restore: 380\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.71526520051745\n",
      "    ram_util_percent: 53.64799482535577\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052780370638220005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.65516483459201\n",
      "    mean_inference_ms: 19.481151038876476\n",
      "    mean_raw_obs_processing_ms: 3.3163683067073095\n",
      "  time_since_restore: 208550.30449795723\n",
      "  time_this_iter_s: 541.8983359336853\n",
      "  time_total_s: 403367.66808342934\n",
      "  timers:\n",
      "    learn_throughput: 28.228\n",
      "    learn_time_ms: 354118.664\n",
      "    load_throughput: 90202.395\n",
      "    load_time_ms: 110.817\n",
      "    sample_throughput: 52.402\n",
      "    sample_time_ms: 190755.615\n",
      "    update_time_ms: 4.706\n",
      "  timestamp: 1637664695\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7197030\n",
      "  training_iteration: 780\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   780</td><td style=\"text-align: right;\">          403368</td><td style=\"text-align: right;\">7197030</td><td style=\"text-align: right;\"> 4.78486</td><td style=\"text-align: right;\">               17.68</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           54.4757</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7207026\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_11-00-37\n",
      "  done: false\n",
      "  episode_len_mean: 55.105555555555554\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 5.613222222222226\n",
      "  episode_reward_min: -0.4000000000000002\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 139494\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0023205682455774\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014959447625339338\n",
      "          policy_loss: -0.07293274688853302\n",
      "          total_loss: 0.07164614303774783\n",
      "          vf_explained_var: 0.9489567875862122\n",
      "          vf_loss: 0.1305226025143526\n",
      "    num_agent_steps_sampled: 7207026\n",
      "    num_agent_steps_trained: 7207026\n",
      "    num_steps_sampled: 7207026\n",
      "    num_steps_trained: 7207026\n",
      "  iterations_since_restore: 381\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69444444444444\n",
      "    ram_util_percent: 53.762661498708006\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278849323464902\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.65128901634506\n",
      "    mean_inference_ms: 19.48310382951507\n",
      "    mean_raw_obs_processing_ms: 3.316012236857027\n",
      "  time_since_restore: 209092.44752120972\n",
      "  time_this_iter_s: 542.1430232524872\n",
      "  time_total_s: 403909.8111066818\n",
      "  timers:\n",
      "    learn_throughput: 28.225\n",
      "    learn_time_ms: 354153.379\n",
      "    load_throughput: 90212.158\n",
      "    load_time_ms: 110.805\n",
      "    sample_throughput: 52.726\n",
      "    sample_time_ms: 189584.814\n",
      "    update_time_ms: 4.431\n",
      "  timestamp: 1637665237\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7207026\n",
      "  training_iteration: 781\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   781</td><td style=\"text-align: right;\">          403910</td><td style=\"text-align: right;\">7207026</td><td style=\"text-align: right;\"> 5.61322</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">                -0.4</td><td style=\"text-align: right;\">           55.1056</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7217022\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_11-09-53\n",
      "  done: false\n",
      "  episode_len_mean: 53.6524064171123\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000007\n",
      "  episode_reward_mean: 5.388128342245993\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 139681\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.017270185597929\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016180951210254733\n",
      "          policy_loss: -0.06849934734079068\n",
      "          total_loss: 0.11229889093729692\n",
      "          vf_explained_var: 0.9221264123916626\n",
      "          vf_loss: 0.16410870966408028\n",
      "    num_agent_steps_sampled: 7217022\n",
      "    num_agent_steps_trained: 7217022\n",
      "    num_steps_sampled: 7217022\n",
      "    num_steps_trained: 7217022\n",
      "  iterations_since_restore: 382\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.52108585858585\n",
      "    ram_util_percent: 53.57790404040406\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052791809916457856\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.646709806085745\n",
      "    mean_inference_ms: 19.480459879707603\n",
      "    mean_raw_obs_processing_ms: 3.3192211367723115\n",
      "  time_since_restore: 209647.76736569405\n",
      "  time_this_iter_s: 555.3198444843292\n",
      "  time_total_s: 404465.13095116615\n",
      "  timers:\n",
      "    learn_throughput: 28.223\n",
      "    learn_time_ms: 354173.612\n",
      "    load_throughput: 90125.262\n",
      "    load_time_ms: 110.912\n",
      "    sample_throughput: 52.458\n",
      "    sample_time_ms: 190553.085\n",
      "    update_time_ms: 4.138\n",
      "  timestamp: 1637665793\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7217022\n",
      "  training_iteration: 782\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   782</td><td style=\"text-align: right;\">          404465</td><td style=\"text-align: right;\">7217022</td><td style=\"text-align: right;\"> 5.38813</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.6524</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7227018\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_11-18-46\n",
      "  done: false\n",
      "  episode_len_mean: 53.74594594594595\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.639999999999986\n",
      "  episode_reward_mean: 5.342162162162166\n",
      "  episode_reward_min: -0.45000000000000023\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 139866\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.012112274538561\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014643641174805978\n",
      "          policy_loss: -0.06320024849921198\n",
      "          total_loss: 0.09042428908847562\n",
      "          vf_explained_var: 0.9470794200897217\n",
      "          vf_loss: 0.14038561487619028\n",
      "    num_agent_steps_sampled: 7227018\n",
      "    num_agent_steps_trained: 7227018\n",
      "    num_steps_sampled: 7227018\n",
      "    num_steps_trained: 7227018\n",
      "  iterations_since_restore: 383\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01513157894736\n",
      "    ram_util_percent: 52.95486842105263\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052806824931642904\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.646420399725113\n",
      "    mean_inference_ms: 19.483342440735935\n",
      "    mean_raw_obs_processing_ms: 3.314238228379565\n",
      "  time_since_restore: 210180.39916324615\n",
      "  time_this_iter_s: 532.6317975521088\n",
      "  time_total_s: 404997.76274871826\n",
      "  timers:\n",
      "    learn_throughput: 28.22\n",
      "    learn_time_ms: 354221.715\n",
      "    load_throughput: 90243.012\n",
      "    load_time_ms: 110.768\n",
      "    sample_throughput: 52.366\n",
      "    sample_time_ms: 190885.806\n",
      "    update_time_ms: 4.517\n",
      "  timestamp: 1637666326\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7227018\n",
      "  training_iteration: 783\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   783</td><td style=\"text-align: right;\">          404998</td><td style=\"text-align: right;\">7227018</td><td style=\"text-align: right;\"> 5.34216</td><td style=\"text-align: right;\">               21.64</td><td style=\"text-align: right;\">               -0.45</td><td style=\"text-align: right;\">           53.7459</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7237014\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_11-27-40\n",
      "  done: false\n",
      "  episode_len_mean: 54.35326086956522\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.51000000000001\n",
      "  episode_reward_mean: 5.336358695652178\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 140050\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.038503879452326\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014432517779663914\n",
      "          policy_loss: -0.06599725252514789\n",
      "          total_loss: 0.0805263343046216\n",
      "          vf_explained_var: 0.9256529808044434\n",
      "          vf_loss: 0.13402954380600207\n",
      "    num_agent_steps_sampled: 7237014\n",
      "    num_agent_steps_trained: 7237014\n",
      "    num_steps_sampled: 7237014\n",
      "    num_steps_trained: 7237014\n",
      "  iterations_since_restore: 384\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.99279161205767\n",
      "    ram_util_percent: 52.83237221494101\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280460935207798\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.646281262173137\n",
      "    mean_inference_ms: 19.485091389223097\n",
      "    mean_raw_obs_processing_ms: 3.3086288582821477\n",
      "  time_since_restore: 210714.57851672173\n",
      "  time_this_iter_s: 534.1793534755707\n",
      "  time_total_s: 405531.94210219383\n",
      "  timers:\n",
      "    learn_throughput: 28.215\n",
      "    learn_time_ms: 354283.872\n",
      "    load_throughput: 89946.374\n",
      "    load_time_ms: 111.133\n",
      "    sample_throughput: 53.768\n",
      "    sample_time_ms: 185910.461\n",
      "    update_time_ms: 4.716\n",
      "  timestamp: 1637666860\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7237014\n",
      "  training_iteration: 784\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   784</td><td style=\"text-align: right;\">          405532</td><td style=\"text-align: right;\">7237014</td><td style=\"text-align: right;\"> 5.33636</td><td style=\"text-align: right;\">               17.51</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           54.3533</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7247010\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_11-36-59\n",
      "  done: false\n",
      "  episode_len_mean: 53.56149732620321\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.690000000000005\n",
      "  episode_reward_mean: 4.92540106951872\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 140237\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0533298250183045\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014667786531159296\n",
      "          policy_loss: -0.07103091138234746\n",
      "          total_loss: 0.06367497622038691\n",
      "          vf_explained_var: 0.9477348923683167\n",
      "          vf_loss: 0.1218241335884911\n",
      "    num_agent_steps_sampled: 7247010\n",
      "    num_agent_steps_trained: 7247010\n",
      "    num_steps_sampled: 7247010\n",
      "    num_steps_trained: 7247010\n",
      "  iterations_since_restore: 385\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.45538847117794\n",
      "    ram_util_percent: 53.36766917293233\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279255202492885\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.64375403998708\n",
      "    mean_inference_ms: 19.48274056250268\n",
      "    mean_raw_obs_processing_ms: 3.311593910319404\n",
      "  time_since_restore: 211274.18291401863\n",
      "  time_this_iter_s: 559.6043972969055\n",
      "  time_total_s: 406091.54649949074\n",
      "  timers:\n",
      "    learn_throughput: 28.206\n",
      "    learn_time_ms: 354396.888\n",
      "    load_throughput: 89808.98\n",
      "    load_time_ms: 111.303\n",
      "    sample_throughput: 53.28\n",
      "    sample_time_ms: 187613.242\n",
      "    update_time_ms: 4.867\n",
      "  timestamp: 1637667419\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7247010\n",
      "  training_iteration: 785\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   785</td><td style=\"text-align: right;\">          406092</td><td style=\"text-align: right;\">7247010</td><td style=\"text-align: right;\">  4.9254</td><td style=\"text-align: right;\">               15.69</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.5615</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7257006\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_11-46-17\n",
      "  done: false\n",
      "  episode_len_mean: 53.38502673796791\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000007\n",
      "  episode_reward_mean: 5.112673796791448\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 140424\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0484687426722195\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014630051739284824\n",
      "          policy_loss: -0.0692955469365473\n",
      "          total_loss: 0.0725918811270601\n",
      "          vf_explained_var: 0.9376406073570251\n",
      "          vf_loss: 0.1290430268265277\n",
      "    num_agent_steps_sampled: 7257006\n",
      "    num_agent_steps_trained: 7257006\n",
      "    num_steps_sampled: 7257006\n",
      "    num_steps_trained: 7257006\n",
      "  iterations_since_restore: 386\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.58930817610063\n",
      "    ram_util_percent: 53.92666666666666\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278841312468741\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.6399130256246\n",
      "    mean_inference_ms: 19.482948119617433\n",
      "    mean_raw_obs_processing_ms: 3.3200630378724156\n",
      "  time_since_restore: 211831.52133750916\n",
      "  time_this_iter_s: 557.3384234905243\n",
      "  time_total_s: 406648.88492298126\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354432.1\n",
      "    load_throughput: 89573.438\n",
      "    load_time_ms: 111.596\n",
      "    sample_throughput: 52.476\n",
      "    sample_time_ms: 190486.114\n",
      "    update_time_ms: 5.151\n",
      "  timestamp: 1637667977\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7257006\n",
      "  training_iteration: 786\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   786</td><td style=\"text-align: right;\">          406649</td><td style=\"text-align: right;\">7257006</td><td style=\"text-align: right;\"> 5.11267</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">            53.385</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7267002\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_11-55-09\n",
      "  done: false\n",
      "  episode_len_mean: 54.11290322580645\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000007\n",
      "  episode_reward_mean: 5.339838709677424\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 140610\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0288478426904564\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015662677595017625\n",
      "          policy_loss: -0.06472535785367975\n",
      "          total_loss: 0.10243502464328344\n",
      "          vf_explained_var: 0.9362277388572693\n",
      "          vf_loss: 0.15176732254646583\n",
      "    num_agent_steps_sampled: 7267002\n",
      "    num_agent_steps_trained: 7267002\n",
      "    num_steps_sampled: 7267002\n",
      "    num_steps_trained: 7267002\n",
      "  iterations_since_restore: 387\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01907894736843\n",
      "    ram_util_percent: 52.80723684210526\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052783664602732344\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.638323794885586\n",
      "    mean_inference_ms: 19.482984704086938\n",
      "    mean_raw_obs_processing_ms: 3.314656539680899\n",
      "  time_since_restore: 212363.7657034397\n",
      "  time_this_iter_s: 532.2443659305573\n",
      "  time_total_s: 407181.1292889118\n",
      "  timers:\n",
      "    learn_throughput: 28.195\n",
      "    learn_time_ms: 354534.639\n",
      "    load_throughput: 89900.491\n",
      "    load_time_ms: 111.19\n",
      "    sample_throughput: 52.857\n",
      "    sample_time_ms: 189114.485\n",
      "    update_time_ms: 5.069\n",
      "  timestamp: 1637668509\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7267002\n",
      "  training_iteration: 787\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   787</td><td style=\"text-align: right;\">          407181</td><td style=\"text-align: right;\">7267002</td><td style=\"text-align: right;\"> 5.33984</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           54.1129</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7276998\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_12-04-14\n",
      "  done: false\n",
      "  episode_len_mean: 53.96756756756757\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.470000000000006\n",
      "  episode_reward_mean: 5.6224864864864905\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 140795\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.008466033236569\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014587112013510206\n",
      "          policy_loss: -0.06925712056663359\n",
      "          total_loss: 0.07284083062233884\n",
      "          vf_explained_var: 0.9476286172866821\n",
      "          vf_loss: 0.12895134626074234\n",
      "    num_agent_steps_sampled: 7276998\n",
      "    num_agent_steps_trained: 7276998\n",
      "    num_steps_sampled: 7276998\n",
      "    num_steps_trained: 7276998\n",
      "  iterations_since_restore: 388\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.76666666666664\n",
      "    ram_util_percent: 53.05431145431145\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278420887219288\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.636756347028033\n",
      "    mean_inference_ms: 19.4828419096996\n",
      "    mean_raw_obs_processing_ms: 3.31354145245693\n",
      "  time_since_restore: 212908.91971635818\n",
      "  time_this_iter_s: 545.1540129184723\n",
      "  time_total_s: 407726.2833018303\n",
      "  timers:\n",
      "    learn_throughput: 28.186\n",
      "    learn_time_ms: 354648.931\n",
      "    load_throughput: 89302.515\n",
      "    load_time_ms: 111.934\n",
      "    sample_throughput: 52.789\n",
      "    sample_time_ms: 189356.971\n",
      "    update_time_ms: 5.041\n",
      "  timestamp: 1637669054\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7276998\n",
      "  training_iteration: 788\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   788</td><td style=\"text-align: right;\">          407726</td><td style=\"text-align: right;\">7276998</td><td style=\"text-align: right;\"> 5.62249</td><td style=\"text-align: right;\">               17.47</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           53.9676</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7286994\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_12-13-42\n",
      "  done: false\n",
      "  episode_len_mean: 54.52459016393443\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.46000000000001\n",
      "  episode_reward_mean: 5.2193442622950865\n",
      "  episode_reward_min: -0.7400000000000004\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 140978\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.042603491779312\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015315476682477923\n",
      "          policy_loss: -0.07101489298322722\n",
      "          total_loss: 0.08940161947966498\n",
      "          vf_explained_var: 0.9256529211997986\n",
      "          vf_loss: 0.1459519766145816\n",
      "    num_agent_steps_sampled: 7286994\n",
      "    num_agent_steps_trained: 7286994\n",
      "    num_steps_sampled: 7286994\n",
      "    num_steps_trained: 7286994\n",
      "  iterations_since_restore: 389\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.12296296296296\n",
      "    ram_util_percent: 53.191851851851844\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052787056404145445\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.63056941252463\n",
      "    mean_inference_ms: 19.483394798425085\n",
      "    mean_raw_obs_processing_ms: 3.321006923945773\n",
      "  time_since_restore: 213476.39168906212\n",
      "  time_this_iter_s: 567.4719727039337\n",
      "  time_total_s: 408293.7552745342\n",
      "  timers:\n",
      "    learn_throughput: 28.178\n",
      "    learn_time_ms: 354739.252\n",
      "    load_throughput: 88636.372\n",
      "    load_time_ms: 112.775\n",
      "    sample_throughput: 52.082\n",
      "    sample_time_ms: 191929.451\n",
      "    update_time_ms: 5.17\n",
      "  timestamp: 1637669622\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7286994\n",
      "  training_iteration: 789\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   789</td><td style=\"text-align: right;\">          408294</td><td style=\"text-align: right;\">7286994</td><td style=\"text-align: right;\"> 5.21934</td><td style=\"text-align: right;\">               15.46</td><td style=\"text-align: right;\">               -0.74</td><td style=\"text-align: right;\">           54.5246</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7296990\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_12-23-03\n",
      "  done: false\n",
      "  episode_len_mean: 53.48663101604278\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.650000000000006\n",
      "  episode_reward_mean: 5.29352941176471\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 141165\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.022129283731721\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015041844766807424\n",
      "          policy_loss: -0.067885676525662\n",
      "          total_loss: 0.07751580776254105\n",
      "          vf_explained_var: 0.9526882767677307\n",
      "          vf_loss: 0.13135557336186668\n",
      "    num_agent_steps_sampled: 7296990\n",
      "    num_agent_steps_trained: 7296990\n",
      "    num_steps_sampled: 7296990\n",
      "    num_steps_trained: 7296990\n",
      "  iterations_since_restore: 390\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.28877805486285\n",
      "    ram_util_percent: 53.75972568578554\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052778896249804495\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.62784275264566\n",
      "    mean_inference_ms: 19.482869604081667\n",
      "    mean_raw_obs_processing_ms: 3.3281074954720395\n",
      "  time_since_restore: 214038.1091041565\n",
      "  time_this_iter_s: 561.7174150943756\n",
      "  time_total_s: 408855.4726896286\n",
      "  timers:\n",
      "    learn_throughput: 28.173\n",
      "    learn_time_ms: 354802.124\n",
      "    load_throughput: 88462.874\n",
      "    load_time_ms: 112.997\n",
      "    sample_throughput: 51.566\n",
      "    sample_time_ms: 193848.059\n",
      "    update_time_ms: 5.905\n",
      "  timestamp: 1637670183\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7296990\n",
      "  training_iteration: 790\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   790</td><td style=\"text-align: right;\">          408855</td><td style=\"text-align: right;\">7296990</td><td style=\"text-align: right;\"> 5.29353</td><td style=\"text-align: right;\">               15.65</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           53.4866</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7306986\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_12-32-10\n",
      "  done: false\n",
      "  episode_len_mean: 53.82795698924731\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.479999999999983\n",
      "  episode_reward_mean: 5.718064516129036\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 141351\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.978862895568212\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01456302346013322\n",
      "          policy_loss: -0.06957649425826695\n",
      "          total_loss: 0.07676710866666304\n",
      "          vf_explained_var: 0.9490752220153809\n",
      "          vf_loss: 0.132955842855364\n",
      "    num_agent_steps_sampled: 7306986\n",
      "    num_agent_steps_trained: 7306986\n",
      "    num_steps_sampled: 7306986\n",
      "    num_steps_trained: 7306986\n",
      "  iterations_since_restore: 391\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7623076923077\n",
      "    ram_util_percent: 53.883333333333326\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05277289314783827\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.626884043671474\n",
      "    mean_inference_ms: 19.482193453875567\n",
      "    mean_raw_obs_processing_ms: 3.3269331054416527\n",
      "  time_since_restore: 214585.08417725563\n",
      "  time_this_iter_s: 546.9750730991364\n",
      "  time_total_s: 409402.44776272774\n",
      "  timers:\n",
      "    learn_throughput: 28.168\n",
      "    learn_time_ms: 354872.3\n",
      "    load_throughput: 88475.326\n",
      "    load_time_ms: 112.981\n",
      "    sample_throughput: 51.457\n",
      "    sample_time_ms: 194260.36\n",
      "    update_time_ms: 5.935\n",
      "  timestamp: 1637670730\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7306986\n",
      "  training_iteration: 791\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   791</td><td style=\"text-align: right;\">          409402</td><td style=\"text-align: right;\">7306986</td><td style=\"text-align: right;\"> 5.71806</td><td style=\"text-align: right;\">               19.48</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">            53.828</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7316982\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_12-41-15\n",
      "  done: false\n",
      "  episode_len_mean: 53.76216216216216\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.589999999999993\n",
      "  episode_reward_mean: 5.690108108108113\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 141536\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.990168864348806\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015212039289364302\n",
      "          policy_loss: -0.06295175605328077\n",
      "          total_loss: 0.11080886923892493\n",
      "          vf_explained_var: 0.9354441165924072\n",
      "          vf_loss: 0.1590073846670496\n",
      "    num_agent_steps_sampled: 7316982\n",
      "    num_agent_steps_trained: 7316982\n",
      "    num_steps_sampled: 7316982\n",
      "    num_steps_trained: 7316982\n",
      "  iterations_since_restore: 392\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81660231660231\n",
      "    ram_util_percent: 53.99897039897041\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278373481946768\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.624375333899643\n",
      "    mean_inference_ms: 19.48235412352781\n",
      "    mean_raw_obs_processing_ms: 3.3262692796682063\n",
      "  time_since_restore: 215129.360319376\n",
      "  time_this_iter_s: 544.2761421203613\n",
      "  time_total_s: 409946.7239048481\n",
      "  timers:\n",
      "    learn_throughput: 28.165\n",
      "    learn_time_ms: 354910.98\n",
      "    load_throughput: 88411.052\n",
      "    load_time_ms: 113.063\n",
      "    sample_throughput: 51.761\n",
      "    sample_time_ms: 193117.016\n",
      "    update_time_ms: 5.873\n",
      "  timestamp: 1637671275\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7316982\n",
      "  training_iteration: 792\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   792</td><td style=\"text-align: right;\">          409947</td><td style=\"text-align: right;\">7316982</td><td style=\"text-align: right;\"> 5.69011</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.7622</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7326978\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_12-50-34\n",
      "  done: false\n",
      "  episode_len_mean: 53.36363636363637\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.590000000000007\n",
      "  episode_reward_mean: 4.864385026737972\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 141723\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.049448858518677\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01490357938279307\n",
      "          policy_loss: -0.06875898259182343\n",
      "          total_loss: 0.07663995508176534\n",
      "          vf_explained_var: 0.9335517883300781\n",
      "          vf_loss: 0.13194120824439862\n",
      "    num_agent_steps_sampled: 7326978\n",
      "    num_agent_steps_trained: 7326978\n",
      "    num_steps_sampled: 7326978\n",
      "    num_steps_trained: 7326978\n",
      "  iterations_since_restore: 393\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.62409033877039\n",
      "    ram_util_percent: 53.73814303638645\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527938195440859\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.625376209345557\n",
      "    mean_inference_ms: 19.485206533340534\n",
      "    mean_raw_obs_processing_ms: 3.325708278363262\n",
      "  time_since_restore: 215688.4657678604\n",
      "  time_this_iter_s: 559.1054484844208\n",
      "  time_total_s: 410505.8293533325\n",
      "  timers:\n",
      "    learn_throughput: 28.113\n",
      "    learn_time_ms: 355563.769\n",
      "    load_throughput: 88310.957\n",
      "    load_time_ms: 113.191\n",
      "    sample_throughput: 51.232\n",
      "    sample_time_ms: 195111.914\n",
      "    update_time_ms: 5.489\n",
      "  timestamp: 1637671834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7326978\n",
      "  training_iteration: 793\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   793</td><td style=\"text-align: right;\">          410506</td><td style=\"text-align: right;\">7326978</td><td style=\"text-align: right;\"> 4.86439</td><td style=\"text-align: right;\">               13.59</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.3636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7336974\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_12-59-40\n",
      "  done: false\n",
      "  episode_len_mean: 53.68279569892473\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.700000000000005\n",
      "  episode_reward_mean: 5.076021505376349\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 141909\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0756087485566197\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014545203193747611\n",
      "          policy_loss: -0.0691787973437159\n",
      "          total_loss: 0.07664002871591231\n",
      "          vf_explained_var: 0.9164425134658813\n",
      "          vf_loss: 0.1334391208730234\n",
      "    num_agent_steps_sampled: 7336974\n",
      "    num_agent_steps_trained: 7336974\n",
      "    num_steps_sampled: 7336974\n",
      "    num_steps_trained: 7336974\n",
      "  iterations_since_restore: 394\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.63423076923078\n",
      "    ram_util_percent: 53.305512820512824\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052786391133326074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.623974612357543\n",
      "    mean_inference_ms: 19.482908068215778\n",
      "    mean_raw_obs_processing_ms: 3.323763191731792\n",
      "  time_since_restore: 216234.82393050194\n",
      "  time_this_iter_s: 546.3581626415253\n",
      "  time_total_s: 411052.18751597404\n",
      "  timers:\n",
      "    learn_throughput: 28.106\n",
      "    learn_time_ms: 355657.173\n",
      "    load_throughput: 87874.562\n",
      "    load_time_ms: 113.753\n",
      "    sample_throughput: 50.939\n",
      "    sample_time_ms: 196235.701\n",
      "    update_time_ms: 5.387\n",
      "  timestamp: 1637672380\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7336974\n",
      "  training_iteration: 794\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   794</td><td style=\"text-align: right;\">          411052</td><td style=\"text-align: right;\">7336974</td><td style=\"text-align: right;\"> 5.07602</td><td style=\"text-align: right;\">                13.7</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           53.6828</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7346970\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_13-08-58\n",
      "  done: false\n",
      "  episode_len_mean: 54.36413043478261\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.550000000000008\n",
      "  episode_reward_mean: 4.9816304347826135\n",
      "  episode_reward_min: -0.6900000000000004\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 142093\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.032797088871998\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014155335037117741\n",
      "          policy_loss: -0.07106163044491734\n",
      "          total_loss: 0.06083297734102339\n",
      "          vf_explained_var: 0.9381951689720154\n",
      "          vf_loss: 0.11997495567010917\n",
      "    num_agent_steps_sampled: 7346970\n",
      "    num_agent_steps_trained: 7346970\n",
      "    num_steps_sampled: 7346970\n",
      "    num_steps_trained: 7346970\n",
      "  iterations_since_restore: 395\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.66959798994975\n",
      "    ram_util_percent: 53.79045226130654\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279295834655811\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.6212067721846\n",
      "    mean_inference_ms: 19.484785964480892\n",
      "    mean_raw_obs_processing_ms: 3.3277088889839317\n",
      "  time_since_restore: 216792.8047952652\n",
      "  time_this_iter_s: 557.9808647632599\n",
      "  time_total_s: 411610.1683807373\n",
      "  timers:\n",
      "    learn_throughput: 28.104\n",
      "    learn_time_ms: 355673.501\n",
      "    load_throughput: 87815.554\n",
      "    load_time_ms: 113.829\n",
      "    sample_throughput: 50.985\n",
      "    sample_time_ms: 196056.73\n",
      "    update_time_ms: 5.316\n",
      "  timestamp: 1637672938\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7346970\n",
      "  training_iteration: 795\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   795</td><td style=\"text-align: right;\">          411610</td><td style=\"text-align: right;\">7346970</td><td style=\"text-align: right;\"> 4.98163</td><td style=\"text-align: right;\">               15.55</td><td style=\"text-align: right;\">               -0.69</td><td style=\"text-align: right;\">           54.3641</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7356966\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_13-18-01\n",
      "  done: false\n",
      "  episode_len_mean: 54.78021978021978\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.610000000000005\n",
      "  episode_reward_mean: 5.4126923076923115\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 142275\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0451969888555\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013469428634949467\n",
      "          policy_loss: -0.06587870057368542\n",
      "          total_loss: 0.056029942112535897\n",
      "          vf_explained_var: 0.9569765329360962\n",
      "          vf_loss: 0.11167556951448965\n",
      "    num_agent_steps_sampled: 7356966\n",
      "    num_agent_steps_trained: 7356966\n",
      "    num_steps_sampled: 7356966\n",
      "    num_steps_trained: 7356966\n",
      "  iterations_since_restore: 396\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.64948320413437\n",
      "    ram_util_percent: 53.80891472868216\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052802252125026046\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.616292155267605\n",
      "    mean_inference_ms: 19.483721542105425\n",
      "    mean_raw_obs_processing_ms: 3.327012623125248\n",
      "  time_since_restore: 217335.04132390022\n",
      "  time_this_iter_s: 542.236528635025\n",
      "  time_total_s: 412152.40490937233\n",
      "  timers:\n",
      "    learn_throughput: 28.103\n",
      "    learn_time_ms: 355690.58\n",
      "    load_throughput: 87599.196\n",
      "    load_time_ms: 114.111\n",
      "    sample_throughput: 51.386\n",
      "    sample_time_ms: 194529.529\n",
      "    update_time_ms: 5.184\n",
      "  timestamp: 1637673481\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7356966\n",
      "  training_iteration: 796\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   796</td><td style=\"text-align: right;\">          412152</td><td style=\"text-align: right;\">7356966</td><td style=\"text-align: right;\"> 5.41269</td><td style=\"text-align: right;\">               13.61</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           54.7802</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7366962\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_13-26-50\n",
      "  done: false\n",
      "  episode_len_mean: 55.54945054945055\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.318846153846159\n",
      "  episode_reward_min: -0.6300000000000003\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 142457\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.059312908764345\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015023128891271149\n",
      "          policy_loss: -0.07088506489465701\n",
      "          total_loss: 0.0796573598228364\n",
      "          vf_explained_var: 0.9314090609550476\n",
      "          vf_loss: 0.13691098744762187\n",
      "    num_agent_steps_sampled: 7366962\n",
      "    num_agent_steps_trained: 7366962\n",
      "    num_steps_sampled: 7366962\n",
      "    num_steps_trained: 7366962\n",
      "  iterations_since_restore: 397\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02883597883599\n",
      "    ram_util_percent: 53.57791005291006\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280100433812435\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.613422729607308\n",
      "    mean_inference_ms: 19.48506234793181\n",
      "    mean_raw_obs_processing_ms: 3.321553991554762\n",
      "  time_since_restore: 217864.87527275085\n",
      "  time_this_iter_s: 529.8339488506317\n",
      "  time_total_s: 412682.23885822296\n",
      "  timers:\n",
      "    learn_throughput: 28.102\n",
      "    learn_time_ms: 355710.117\n",
      "    load_throughput: 87205.852\n",
      "    load_time_ms: 114.625\n",
      "    sample_throughput: 51.455\n",
      "    sample_time_ms: 194268.459\n",
      "    update_time_ms: 4.909\n",
      "  timestamp: 1637674010\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7366962\n",
      "  training_iteration: 797\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   797</td><td style=\"text-align: right;\">          412682</td><td style=\"text-align: right;\">7366962</td><td style=\"text-align: right;\"> 5.31885</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.63</td><td style=\"text-align: right;\">           55.5495</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7376958\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_13-35-42\n",
      "  done: false\n",
      "  episode_len_mean: 55.12222222222222\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.340388888888894\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 142637\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0494095906675103\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01465198344780278\n",
      "          policy_loss: -0.06945584055705052\n",
      "          total_loss: 0.07088353144131818\n",
      "          vf_explained_var: 0.9485306739807129\n",
      "          vf_loss: 0.12745441602380295\n",
      "    num_agent_steps_sampled: 7376958\n",
      "    num_agent_steps_trained: 7376958\n",
      "    num_steps_sampled: 7376958\n",
      "    num_steps_trained: 7376958\n",
      "  iterations_since_restore: 398\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.97124010554091\n",
      "    ram_util_percent: 53.33496042216358\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052819011958805055\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.612055025055966\n",
      "    mean_inference_ms: 19.48705029341827\n",
      "    mean_raw_obs_processing_ms: 3.3165201735304284\n",
      "  time_since_restore: 218396.5853354931\n",
      "  time_this_iter_s: 531.7100627422333\n",
      "  time_total_s: 413213.9489209652\n",
      "  timers:\n",
      "    learn_throughput: 28.1\n",
      "    learn_time_ms: 355725.533\n",
      "    load_throughput: 87294.404\n",
      "    load_time_ms: 114.509\n",
      "    sample_throughput: 51.817\n",
      "    sample_time_ms: 192908.46\n",
      "    update_time_ms: 5.21\n",
      "  timestamp: 1637674542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7376958\n",
      "  training_iteration: 798\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   798</td><td style=\"text-align: right;\">          413214</td><td style=\"text-align: right;\">7376958</td><td style=\"text-align: right;\"> 5.34039</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           55.1222</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7386954\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_13-44-57\n",
      "  done: false\n",
      "  episode_len_mean: 55.082417582417584\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.620000000000008\n",
      "  episode_reward_mean: 4.968241758241762\n",
      "  episode_reward_min: -0.6300000000000003\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 142819\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.07389971503771\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014751172455213847\n",
      "          policy_loss: -0.06945301965655065\n",
      "          total_loss: 0.08292999214511812\n",
      "          vf_explained_var: 0.9329780340194702\n",
      "          vf_loss: 0.139516993113382\n",
      "    num_agent_steps_sampled: 7386954\n",
      "    num_agent_steps_trained: 7386954\n",
      "    num_steps_sampled: 7386954\n",
      "    num_steps_trained: 7386954\n",
      "  iterations_since_restore: 399\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.58282828282829\n",
      "    ram_util_percent: 53.932196969696975\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052809482759942614\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.6054477819229\n",
      "    mean_inference_ms: 19.483135422581356\n",
      "    mean_raw_obs_processing_ms: 3.319103618080491\n",
      "  time_since_restore: 218951.190864563\n",
      "  time_this_iter_s: 554.6055290699005\n",
      "  time_total_s: 413768.5544500351\n",
      "  timers:\n",
      "    learn_throughput: 28.098\n",
      "    learn_time_ms: 355760.412\n",
      "    load_throughput: 87085.867\n",
      "    load_time_ms: 114.783\n",
      "    sample_throughput: 52.175\n",
      "    sample_time_ms: 191586.426\n",
      "    update_time_ms: 5.454\n",
      "  timestamp: 1637675097\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7386954\n",
      "  training_iteration: 799\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   799</td><td style=\"text-align: right;\">          413769</td><td style=\"text-align: right;\">7386954</td><td style=\"text-align: right;\"> 4.96824</td><td style=\"text-align: right;\">               17.62</td><td style=\"text-align: right;\">               -0.63</td><td style=\"text-align: right;\">           55.0824</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7396950\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_13-54-01\n",
      "  done: false\n",
      "  episode_len_mean: 54.69945355191257\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.499999999999986\n",
      "  episode_reward_mean: 5.4486338797814255\n",
      "  episode_reward_min: -0.6000000000000003\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 143002\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0568876986762126\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014439168145623333\n",
      "          policy_loss: -0.07159508274526015\n",
      "          total_loss: 0.07582535598270784\n",
      "          vf_explained_var: 0.9182358384132385\n",
      "          vf_loss: 0.13509508493939887\n",
      "    num_agent_steps_sampled: 7396950\n",
      "    num_agent_steps_trained: 7396950\n",
      "    num_steps_sampled: 7396950\n",
      "    num_steps_trained: 7396950\n",
      "  iterations_since_restore: 400\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.68943298969072\n",
      "    ram_util_percent: 53.88260309278352\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052811357086154226\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.602622172553062\n",
      "    mean_inference_ms: 19.484161615982895\n",
      "    mean_raw_obs_processing_ms: 3.318338152921071\n",
      "  time_since_restore: 219495.4723622799\n",
      "  time_this_iter_s: 544.2814977169037\n",
      "  time_total_s: 414312.835947752\n",
      "  timers:\n",
      "    learn_throughput: 28.096\n",
      "    learn_time_ms: 355784.341\n",
      "    load_throughput: 86777.338\n",
      "    load_time_ms: 115.191\n",
      "    sample_throughput: 52.661\n",
      "    sample_time_ms: 189818.588\n",
      "    update_time_ms: 5.09\n",
      "  timestamp: 1637675641\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7396950\n",
      "  training_iteration: 800\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   800</td><td style=\"text-align: right;\">          414313</td><td style=\"text-align: right;\">7396950</td><td style=\"text-align: right;\"> 5.44863</td><td style=\"text-align: right;\">                19.5</td><td style=\"text-align: right;\">                -0.6</td><td style=\"text-align: right;\">           54.6995</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7406946\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_14-02-50\n",
      "  done: false\n",
      "  episode_len_mean: 55.22222222222222\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.45\n",
      "  episode_reward_mean: 5.350444444444449\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 180\n",
      "  episodes_total: 143182\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.045680181041779\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014513240071128362\n",
      "          policy_loss: -0.06847561663476319\n",
      "          total_loss: 0.08223113886300393\n",
      "          vf_explained_var: 0.9119109511375427\n",
      "          vf_loss: 0.1381005806759576\n",
      "    num_agent_steps_sampled: 7406946\n",
      "    num_agent_steps_trained: 7406946\n",
      "    num_steps_sampled: 7406946\n",
      "    num_steps_trained: 7406946\n",
      "  iterations_since_restore: 401\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00066312997347\n",
      "    ram_util_percent: 53.5473474801061\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282056595400457\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.599767475760032\n",
      "    mean_inference_ms: 19.486220270780805\n",
      "    mean_raw_obs_processing_ms: 3.3135203768038446\n",
      "  time_since_restore: 220023.96932148933\n",
      "  time_this_iter_s: 528.4969592094421\n",
      "  time_total_s: 414841.33290696144\n",
      "  timers:\n",
      "    learn_throughput: 28.092\n",
      "    learn_time_ms: 355831.077\n",
      "    load_throughput: 86697.755\n",
      "    load_time_ms: 115.297\n",
      "    sample_throughput: 53.192\n",
      "    sample_time_ms: 187924.701\n",
      "    update_time_ms: 5.088\n",
      "  timestamp: 1637676170\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7406946\n",
      "  training_iteration: 801\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   801</td><td style=\"text-align: right;\">          414841</td><td style=\"text-align: right;\">7406946</td><td style=\"text-align: right;\"> 5.35044</td><td style=\"text-align: right;\">               17.45</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           55.2222</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7416942\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_14-11-53\n",
      "  done: false\n",
      "  episode_len_mean: 55.60220994475138\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.46000000000001\n",
      "  episode_reward_mean: 4.919005524861883\n",
      "  episode_reward_min: -0.6200000000000003\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 143363\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.052569691806912\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014174237914515116\n",
      "          policy_loss: -0.07045870809190062\n",
      "          total_loss: 0.0747567958255249\n",
      "          vf_explained_var: 0.9243689775466919\n",
      "          vf_loss: 0.13345051483058532\n",
      "    num_agent_steps_sampled: 7416942\n",
      "    num_agent_steps_trained: 7416942\n",
      "    num_steps_sampled: 7416942\n",
      "    num_steps_trained: 7416942\n",
      "  iterations_since_restore: 402\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.46791237113403\n",
      "    ram_util_percent: 53.227190721649485\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282958786541063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.596416178149365\n",
      "    mean_inference_ms: 19.487608929945864\n",
      "    mean_raw_obs_processing_ms: 3.312593080863402\n",
      "  time_since_restore: 220567.57487916946\n",
      "  time_this_iter_s: 543.60555768013\n",
      "  time_total_s: 415384.9384646416\n",
      "  timers:\n",
      "    learn_throughput: 28.089\n",
      "    learn_time_ms: 355866.229\n",
      "    load_throughput: 86684.455\n",
      "    load_time_ms: 115.315\n",
      "    sample_throughput: 53.221\n",
      "    sample_time_ms: 187822.262\n",
      "    update_time_ms: 5.482\n",
      "  timestamp: 1637676713\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7416942\n",
      "  training_iteration: 802\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   802</td><td style=\"text-align: right;\">          415385</td><td style=\"text-align: right;\">7416942</td><td style=\"text-align: right;\"> 4.91901</td><td style=\"text-align: right;\">               15.46</td><td style=\"text-align: right;\">               -0.62</td><td style=\"text-align: right;\">           55.6022</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7426938\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_14-21-08\n",
      "  done: false\n",
      "  episode_len_mean: 54.666666666666664\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.47999999999999\n",
      "  episode_reward_mean: 5.429562841530059\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 143546\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.041600982850814\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014350078644763883\n",
      "          policy_loss: -0.0694951515914905\n",
      "          total_loss: 0.07435989650156914\n",
      "          vf_explained_var: 0.9470363855361938\n",
      "          vf_loss: 0.13157978323680988\n",
      "    num_agent_steps_sampled: 7426938\n",
      "    num_agent_steps_trained: 7426938\n",
      "    num_steps_sampled: 7426938\n",
      "    num_steps_trained: 7426938\n",
      "  iterations_since_restore: 403\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.41238938053097\n",
      "    ram_util_percent: 53.564728192161816\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282898407068547\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.591454905223593\n",
      "    mean_inference_ms: 19.48748408371157\n",
      "    mean_raw_obs_processing_ms: 3.319930476821277\n",
      "  time_since_restore: 221122.07053661346\n",
      "  time_this_iter_s: 554.4956574440002\n",
      "  time_total_s: 415939.4341220856\n",
      "  timers:\n",
      "    learn_throughput: 28.138\n",
      "    learn_time_ms: 355245.549\n",
      "    load_throughput: 86662.129\n",
      "    load_time_ms: 115.345\n",
      "    sample_throughput: 53.175\n",
      "    sample_time_ms: 187981.684\n",
      "    update_time_ms: 5.823\n",
      "  timestamp: 1637677268\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7426938\n",
      "  training_iteration: 803\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   803</td><td style=\"text-align: right;\">          415939</td><td style=\"text-align: right;\">7426938</td><td style=\"text-align: right;\"> 5.42956</td><td style=\"text-align: right;\">               17.48</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           54.6667</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7436934\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_14-30-07\n",
      "  done: false\n",
      "  episode_len_mean: 55.79329608938548\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000007\n",
      "  episode_reward_mean: 5.241787709497212\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 179\n",
      "  episodes_total: 143725\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.044591649648655\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015288456797380669\n",
      "          policy_loss: -0.06993143669715063\n",
      "          total_loss: 0.08222775820562762\n",
      "          vf_explained_var: 0.9457097053527832\n",
      "          vf_loss: 0.13777609435910637\n",
      "    num_agent_steps_sampled: 7436934\n",
      "    num_agent_steps_trained: 7436934\n",
      "    num_steps_sampled: 7436934\n",
      "    num_steps_trained: 7436934\n",
      "  iterations_since_restore: 404\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.70012987012987\n",
      "    ram_util_percent: 53.91766233766234\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528248995322538\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.58593941661012\n",
      "    mean_inference_ms: 19.486457133335616\n",
      "    mean_raw_obs_processing_ms: 3.3186137521486456\n",
      "  time_since_restore: 221661.6099331379\n",
      "  time_this_iter_s: 539.5393965244293\n",
      "  time_total_s: 416478.97351861\n",
      "  timers:\n",
      "    learn_throughput: 28.143\n",
      "    learn_time_ms: 355184.796\n",
      "    load_throughput: 85827.432\n",
      "    load_time_ms: 116.466\n",
      "    sample_throughput: 53.352\n",
      "    sample_time_ms: 187358.926\n",
      "    update_time_ms: 6.1\n",
      "  timestamp: 1637677807\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7436934\n",
      "  training_iteration: 804\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   804</td><td style=\"text-align: right;\">          416479</td><td style=\"text-align: right;\">7436934</td><td style=\"text-align: right;\"> 5.24179</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           55.7933</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7446930\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_14-39-11\n",
      "  done: false\n",
      "  episode_len_mean: 55.90395480225989\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.500000000000009\n",
      "  episode_reward_mean: 5.5018079096045245\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 177\n",
      "  episodes_total: 143902\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.025210386801915\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014630977434046183\n",
      "          policy_loss: -0.0702582816681559\n",
      "          total_loss: 0.0701446912274227\n",
      "          vf_explained_var: 0.937987208366394\n",
      "          vf_loss: 0.12732388090106647\n",
      "    num_agent_steps_sampled: 7446930\n",
      "    num_agent_steps_trained: 7446930\n",
      "    num_steps_sampled: 7446930\n",
      "    num_steps_trained: 7446930\n",
      "  iterations_since_restore: 405\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.64007731958762\n",
      "    ram_util_percent: 53.38621134020618\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282220017820248\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.581741637800288\n",
      "    mean_inference_ms: 19.488866330874732\n",
      "    mean_raw_obs_processing_ms: 3.3182174509423503\n",
      "  time_since_restore: 222205.50835347176\n",
      "  time_this_iter_s: 543.8984203338623\n",
      "  time_total_s: 417022.87193894386\n",
      "  timers:\n",
      "    learn_throughput: 28.142\n",
      "    learn_time_ms: 355204.23\n",
      "    load_throughput: 85792.447\n",
      "    load_time_ms: 116.514\n",
      "    sample_throughput: 53.762\n",
      "    sample_time_ms: 185931.733\n",
      "    update_time_ms: 6.027\n",
      "  timestamp: 1637678351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7446930\n",
      "  training_iteration: 805\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   805</td><td style=\"text-align: right;\">          417023</td><td style=\"text-align: right;\">7446930</td><td style=\"text-align: right;\"> 5.50181</td><td style=\"text-align: right;\">                15.5</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">            55.904</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7456926\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_14-48-13\n",
      "  done: false\n",
      "  episode_len_mean: 55.31868131868132\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000007\n",
      "  episode_reward_mean: 5.066428571428576\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 144084\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0484583988965275\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014423309675705025\n",
      "          policy_loss: -0.0716663234644596\n",
      "          total_loss: 0.06309853952108539\n",
      "          vf_explained_var: 0.9484769105911255\n",
      "          vf_loss: 0.12239134388005204\n",
      "    num_agent_steps_sampled: 7456926\n",
      "    num_agent_steps_trained: 7456926\n",
      "    num_steps_sampled: 7456926\n",
      "    num_steps_trained: 7456926\n",
      "  iterations_since_restore: 406\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69754204398447\n",
      "    ram_util_percent: 53.09016817593791\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052814060527319566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.5769320088135\n",
      "    mean_inference_ms: 19.48540601799706\n",
      "    mean_raw_obs_processing_ms: 3.316130507170732\n",
      "  time_since_restore: 222747.09862923622\n",
      "  time_this_iter_s: 541.5902757644653\n",
      "  time_total_s: 417564.4622147083\n",
      "  timers:\n",
      "    learn_throughput: 28.14\n",
      "    learn_time_ms: 355221.019\n",
      "    load_throughput: 85892.718\n",
      "    load_time_ms: 116.378\n",
      "    sample_throughput: 53.785\n",
      "    sample_time_ms: 185849.931\n",
      "    update_time_ms: 6.221\n",
      "  timestamp: 1637678893\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7456926\n",
      "  training_iteration: 806\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   806</td><td style=\"text-align: right;\">          417564</td><td style=\"text-align: right;\">7456926</td><td style=\"text-align: right;\"> 5.06643</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           55.3187</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7466922\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_14-57-41\n",
      "  done: false\n",
      "  episode_len_mean: 54.8021978021978\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.540000000000006\n",
      "  episode_reward_mean: 4.719340659340664\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 144266\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.073201417779348\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014769541676278128\n",
      "          policy_loss: -0.0728211385804954\n",
      "          total_loss: 0.06066310478619056\n",
      "          vf_explained_var: 0.9329639077186584\n",
      "          vf_loss: 0.12056939398774495\n",
      "    num_agent_steps_sampled: 7466922\n",
      "    num_agent_steps_trained: 7466922\n",
      "    num_steps_sampled: 7466922\n",
      "    num_steps_trained: 7466922\n",
      "  iterations_since_restore: 407\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.01950617283951\n",
      "    ram_util_percent: 53.677037037037046\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052819079789248685\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.573790189623157\n",
      "    mean_inference_ms: 19.488063701357273\n",
      "    mean_raw_obs_processing_ms: 3.32275892599422\n",
      "  time_since_restore: 223314.89242053032\n",
      "  time_this_iter_s: 567.7937912940979\n",
      "  time_total_s: 418132.2560060024\n",
      "  timers:\n",
      "    learn_throughput: 28.14\n",
      "    learn_time_ms: 355222.938\n",
      "    load_throughput: 86329.296\n",
      "    load_time_ms: 115.789\n",
      "    sample_throughput: 52.709\n",
      "    sample_time_ms: 189643.976\n",
      "    update_time_ms: 6.974\n",
      "  timestamp: 1637679461\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7466922\n",
      "  training_iteration: 807\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   807</td><td style=\"text-align: right;\">          418132</td><td style=\"text-align: right;\">7466922</td><td style=\"text-align: right;\"> 4.71934</td><td style=\"text-align: right;\">               17.54</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           54.8022</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7476918\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_15-06-28\n",
      "  done: false\n",
      "  episode_len_mean: 55.78212290502793\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.560000000000008\n",
      "  episode_reward_mean: 4.875307262569836\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 179\n",
      "  episodes_total: 144445\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.050394421648309\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014072566993122837\n",
      "          policy_loss: -0.07583576357012288\n",
      "          total_loss: 0.052212385033907405\n",
      "          vf_explained_var: 0.944295346736908\n",
      "          vf_loss: 0.11649302580042267\n",
      "    num_agent_steps_sampled: 7476918\n",
      "    num_agent_steps_trained: 7476918\n",
      "    num_steps_sampled: 7476918\n",
      "    num_steps_trained: 7476918\n",
      "  iterations_since_restore: 408\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.78579017264276\n",
      "    ram_util_percent: 53.05046480743692\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052817572820097136\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.569751335504783\n",
      "    mean_inference_ms: 19.48706059378634\n",
      "    mean_raw_obs_processing_ms: 3.317235842606967\n",
      "  time_since_restore: 223842.45688462257\n",
      "  time_this_iter_s: 527.5644640922546\n",
      "  time_total_s: 418659.8204700947\n",
      "  timers:\n",
      "    learn_throughput: 28.139\n",
      "    learn_time_ms: 355232.549\n",
      "    load_throughput: 86290.313\n",
      "    load_time_ms: 115.842\n",
      "    sample_throughput: 52.827\n",
      "    sample_time_ms: 189219.822\n",
      "    update_time_ms: 7.045\n",
      "  timestamp: 1637679988\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7476918\n",
      "  training_iteration: 808\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   808</td><td style=\"text-align: right;\">          418660</td><td style=\"text-align: right;\">7476918</td><td style=\"text-align: right;\"> 4.87531</td><td style=\"text-align: right;\">               13.56</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           55.7821</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7486914\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_15-15-31\n",
      "  done: false\n",
      "  episode_len_mean: 55.137362637362635\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.43000000000001\n",
      "  episode_reward_mean: 5.662857142857148\n",
      "  episode_reward_min: -0.6300000000000003\n",
      "  episodes_this_iter: 182\n",
      "  episodes_total: 144627\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0286678192605936\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015464479157586353\n",
      "          policy_loss: -0.06696165370262441\n",
      "          total_loss: 0.09948939670838769\n",
      "          vf_explained_var: 0.9347974061965942\n",
      "          vf_loss: 0.15150771083003545\n",
      "    num_agent_steps_sampled: 7486914\n",
      "    num_agent_steps_trained: 7486914\n",
      "    num_steps_sampled: 7486914\n",
      "    num_steps_trained: 7486914\n",
      "  iterations_since_restore: 409\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75090439276485\n",
      "    ram_util_percent: 53.09444444444445\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281819594033803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.566086254989568\n",
      "    mean_inference_ms: 19.48675637874729\n",
      "    mean_raw_obs_processing_ms: 3.316413495225066\n",
      "  time_since_restore: 224385.36989998817\n",
      "  time_this_iter_s: 542.9130153656006\n",
      "  time_total_s: 419202.7334854603\n",
      "  timers:\n",
      "    learn_throughput: 28.137\n",
      "    learn_time_ms: 355255.979\n",
      "    load_throughput: 86468.438\n",
      "    load_time_ms: 115.603\n",
      "    sample_throughput: 53.162\n",
      "    sample_time_ms: 188027.534\n",
      "    update_time_ms: 6.828\n",
      "  timestamp: 1637680531\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7486914\n",
      "  training_iteration: 809\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   809</td><td style=\"text-align: right;\">          419203</td><td style=\"text-align: right;\">7486914</td><td style=\"text-align: right;\"> 5.66286</td><td style=\"text-align: right;\">               15.43</td><td style=\"text-align: right;\">               -0.63</td><td style=\"text-align: right;\">           55.1374</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7496910\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_15-24-35\n",
      "  done: false\n",
      "  episode_len_mean: 54.29891304347826\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.60999999999998\n",
      "  episode_reward_mean: 5.580706521739135\n",
      "  episode_reward_min: -0.6200000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 144811\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0433687905949283\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014457898514649868\n",
      "          policy_loss: -0.06878819993639425\n",
      "          total_loss: 0.08887586473736292\n",
      "          vf_explained_var: 0.9456122517585754\n",
      "          vf_loss: 0.14516085115921532\n",
      "    num_agent_steps_sampled: 7496910\n",
      "    num_agent_steps_trained: 7496910\n",
      "    num_steps_sampled: 7496910\n",
      "    num_steps_trained: 7496910\n",
      "  iterations_since_restore: 410\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.66842783505155\n",
      "    ram_util_percent: 53.08466494845361\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052817773756631874\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.56279040049095\n",
      "    mean_inference_ms: 19.4845420116575\n",
      "    mean_raw_obs_processing_ms: 3.314912191465275\n",
      "  time_since_restore: 224929.47918987274\n",
      "  time_this_iter_s: 544.1092898845673\n",
      "  time_total_s: 419746.84277534485\n",
      "  timers:\n",
      "    learn_throughput: 28.139\n",
      "    learn_time_ms: 355239.296\n",
      "    load_throughput: 87399.184\n",
      "    load_time_ms: 114.372\n",
      "    sample_throughput: 53.162\n",
      "    sample_time_ms: 188028.91\n",
      "    update_time_ms: 6.599\n",
      "  timestamp: 1637681075\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7496910\n",
      "  training_iteration: 810\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   810</td><td style=\"text-align: right;\">          419747</td><td style=\"text-align: right;\">7496910</td><td style=\"text-align: right;\"> 5.58071</td><td style=\"text-align: right;\">               19.61</td><td style=\"text-align: right;\">               -0.62</td><td style=\"text-align: right;\">           54.2989</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7506906\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_15-33-53\n",
      "  done: false\n",
      "  episode_len_mean: 54.18478260869565\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.510000000000009\n",
      "  episode_reward_mean: 5.498804347826092\n",
      "  episode_reward_min: -0.6600000000000004\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 144995\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0601319915558918\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015548713574275504\n",
      "          policy_loss: -0.07077244627908369\n",
      "          total_loss: 0.0968094612982479\n",
      "          vf_explained_var: 0.9455729126930237\n",
      "          vf_loss: 0.15276131249223668\n",
      "    num_agent_steps_sampled: 7506906\n",
      "    num_agent_steps_trained: 7506906\n",
      "    num_steps_sampled: 7506906\n",
      "    num_steps_trained: 7506906\n",
      "  iterations_since_restore: 411\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.55100502512563\n",
      "    ram_util_percent: 53.50175879396985\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281954309971481\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.560657360866582\n",
      "    mean_inference_ms: 19.487242552898742\n",
      "    mean_raw_obs_processing_ms: 3.318459322960297\n",
      "  time_since_restore: 225487.38164448738\n",
      "  time_this_iter_s: 557.9024546146393\n",
      "  time_total_s: 420304.7452299595\n",
      "  timers:\n",
      "    learn_throughput: 28.141\n",
      "    learn_time_ms: 355210.441\n",
      "    load_throughput: 87528.842\n",
      "    load_time_ms: 114.202\n",
      "    sample_throughput: 52.336\n",
      "    sample_time_ms: 190998.401\n",
      "    update_time_ms: 6.591\n",
      "  timestamp: 1637681633\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7506906\n",
      "  training_iteration: 811\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   811</td><td style=\"text-align: right;\">          420305</td><td style=\"text-align: right;\">7506906</td><td style=\"text-align: right;\">  5.4988</td><td style=\"text-align: right;\">               15.51</td><td style=\"text-align: right;\">               -0.66</td><td style=\"text-align: right;\">           54.1848</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7516902\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_15-43-03\n",
      "  done: false\n",
      "  episode_len_mean: 53.45989304812834\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.43999999999998\n",
      "  episode_reward_mean: 5.548395721925137\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 145182\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0666259320864238\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015198197039804013\n",
      "          policy_loss: -0.0677294483282376\n",
      "          total_loss: 0.09488539646915203\n",
      "          vf_explained_var: 0.9542728662490845\n",
      "          vf_loss: 0.14865771021233895\n",
      "    num_agent_steps_sampled: 7516902\n",
      "    num_agent_steps_trained: 7516902\n",
      "    num_steps_sampled: 7516902\n",
      "    num_steps_trained: 7516902\n",
      "  iterations_since_restore: 412\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.62270408163266\n",
      "    ram_util_percent: 53.681250000000006\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052806661085146187\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.559100375646487\n",
      "    mean_inference_ms: 19.486019922361955\n",
      "    mean_raw_obs_processing_ms: 3.3215032871624177\n",
      "  time_since_restore: 226036.69538259506\n",
      "  time_this_iter_s: 549.3137381076813\n",
      "  time_total_s: 420854.05896806717\n",
      "  timers:\n",
      "    learn_throughput: 28.141\n",
      "    learn_time_ms: 355214.115\n",
      "    load_throughput: 87508.874\n",
      "    load_time_ms: 114.228\n",
      "    sample_throughput: 52.181\n",
      "    sample_time_ms: 191565.25\n",
      "    update_time_ms: 6.21\n",
      "  timestamp: 1637682183\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7516902\n",
      "  training_iteration: 812\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   812</td><td style=\"text-align: right;\">          420854</td><td style=\"text-align: right;\">7516902</td><td style=\"text-align: right;\">  5.5484</td><td style=\"text-align: right;\">               19.44</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.4599</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7526898\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_15-51-56\n",
      "  done: false\n",
      "  episode_len_mean: 54.32608695652174\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.190326086956526\n",
      "  episode_reward_min: -0.6000000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 145366\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.028573202967165\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015136779233691956\n",
      "          policy_loss: -0.06736965018960864\n",
      "          total_loss: 0.09291014960773943\n",
      "          vf_explained_var: 0.9466860890388489\n",
      "          vf_loss: 0.14608205586197753\n",
      "    num_agent_steps_sampled: 7526898\n",
      "    num_agent_steps_trained: 7526898\n",
      "    num_steps_sampled: 7526898\n",
      "    num_steps_trained: 7526898\n",
      "  iterations_since_restore: 413\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.86898817345599\n",
      "    ram_util_percent: 52.938107752956626\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281765579131184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.55916134512845\n",
      "    mean_inference_ms: 19.487452222914104\n",
      "    mean_raw_obs_processing_ms: 3.317069617719478\n",
      "  time_since_restore: 226569.68715190887\n",
      "  time_this_iter_s: 532.9917693138123\n",
      "  time_total_s: 421387.050737381\n",
      "  timers:\n",
      "    learn_throughput: 28.141\n",
      "    learn_time_ms: 355216.388\n",
      "    load_throughput: 87627.281\n",
      "    load_time_ms: 114.074\n",
      "    sample_throughput: 52.774\n",
      "    sample_time_ms: 189412.867\n",
      "    update_time_ms: 5.971\n",
      "  timestamp: 1637682716\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7526898\n",
      "  training_iteration: 813\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   813</td><td style=\"text-align: right;\">          421387</td><td style=\"text-align: right;\">7526898</td><td style=\"text-align: right;\"> 5.19033</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">                -0.6</td><td style=\"text-align: right;\">           54.3261</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7536894\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_16-00-50\n",
      "  done: false\n",
      "  episode_len_mean: 54.043243243243246\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.580000000000007\n",
      "  episode_reward_mean: 5.155081081081086\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 145551\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0613403080457666\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013925739924761423\n",
      "          policy_loss: -0.07018738339452778\n",
      "          total_loss: 0.06232750229554508\n",
      "          vf_explained_var: 0.9438478350639343\n",
      "          vf_loss: 0.12140371068549084\n",
      "    num_agent_steps_sampled: 7536894\n",
      "    num_agent_steps_trained: 7536894\n",
      "    num_steps_sampled: 7536894\n",
      "    num_steps_trained: 7536894\n",
      "  iterations_since_restore: 414\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.99986876640419\n",
      "    ram_util_percent: 52.80065616797899\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281957390027399\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.55857638051908\n",
      "    mean_inference_ms: 19.48887789365538\n",
      "    mean_raw_obs_processing_ms: 3.3124081025359793\n",
      "  time_since_restore: 227103.7466185093\n",
      "  time_this_iter_s: 534.0594666004181\n",
      "  time_total_s: 421921.1102039814\n",
      "  timers:\n",
      "    learn_throughput: 28.14\n",
      "    learn_time_ms: 355228.457\n",
      "    load_throughput: 88942.717\n",
      "    load_time_ms: 112.387\n",
      "    sample_throughput: 52.93\n",
      "    sample_time_ms: 188854.786\n",
      "    update_time_ms: 5.786\n",
      "  timestamp: 1637683250\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7536894\n",
      "  training_iteration: 814\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   814</td><td style=\"text-align: right;\">          421921</td><td style=\"text-align: right;\">7536894</td><td style=\"text-align: right;\"> 5.15508</td><td style=\"text-align: right;\">               13.58</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           54.0432</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7546890\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_16-10-00\n",
      "  done: false\n",
      "  episode_len_mean: 54.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.700000000000005\n",
      "  episode_reward_mean: 4.8842391304347865\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 145735\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1109852392031963\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01399752906938831\n",
      "          policy_loss: -0.0758241477614798\n",
      "          total_loss: 0.04953318078667514\n",
      "          vf_explained_var: 0.9457154870033264\n",
      "          vf_loss: 0.114579059911731\n",
      "    num_agent_steps_sampled: 7546890\n",
      "    num_agent_steps_trained: 7546890\n",
      "    num_steps_sampled: 7546890\n",
      "    num_steps_trained: 7546890\n",
      "  iterations_since_restore: 415\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.67806122448981\n",
      "    ram_util_percent: 53.254209183673474\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052819771584614914\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.557780988577573\n",
      "    mean_inference_ms: 19.489955137417454\n",
      "    mean_raw_obs_processing_ms: 3.3116965594574275\n",
      "  time_since_restore: 227653.38071489334\n",
      "  time_this_iter_s: 549.6340963840485\n",
      "  time_total_s: 422470.74430036545\n",
      "  timers:\n",
      "    learn_throughput: 28.136\n",
      "    learn_time_ms: 355275.513\n",
      "    load_throughput: 89119.052\n",
      "    load_time_ms: 112.165\n",
      "    sample_throughput: 52.782\n",
      "    sample_time_ms: 189381.379\n",
      "    update_time_ms: 5.796\n",
      "  timestamp: 1637683800\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7546890\n",
      "  training_iteration: 815\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   815</td><td style=\"text-align: right;\">          422471</td><td style=\"text-align: right;\">7546890</td><td style=\"text-align: right;\"> 4.88424</td><td style=\"text-align: right;\">                13.7</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">             54.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7556886\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_16-19-26\n",
      "  done: false\n",
      "  episode_len_mean: 53.994623655913976\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.519999999999996\n",
      "  episode_reward_mean: 5.372903225806456\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 145921\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0481115410126836\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014973528050751332\n",
      "          policy_loss: -0.06687843307736914\n",
      "          total_loss: 0.08369957614790818\n",
      "          vf_explained_var: 0.9320113658905029\n",
      "          vf_loss: 0.13694755536659312\n",
      "    num_agent_steps_sampled: 7556886\n",
      "    num_agent_steps_trained: 7556886\n",
      "    num_steps_sampled: 7556886\n",
      "    num_steps_trained: 7556886\n",
      "  iterations_since_restore: 416\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.35129789864031\n",
      "    ram_util_percent: 53.64202719406674\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280950648725699\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.556370354248973\n",
      "    mean_inference_ms: 19.48716973783924\n",
      "    mean_raw_obs_processing_ms: 3.313460746684315\n",
      "  time_since_restore: 228220.17900800705\n",
      "  time_this_iter_s: 566.7982931137085\n",
      "  time_total_s: 423037.54259347916\n",
      "  timers:\n",
      "    learn_throughput: 28.13\n",
      "    learn_time_ms: 355352.659\n",
      "    load_throughput: 89263.881\n",
      "    load_time_ms: 111.983\n",
      "    sample_throughput: 52.11\n",
      "    sample_time_ms: 191825.177\n",
      "    update_time_ms: 5.884\n",
      "  timestamp: 1637684366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7556886\n",
      "  training_iteration: 816\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   816</td><td style=\"text-align: right;\">          423038</td><td style=\"text-align: right;\">7556886</td><td style=\"text-align: right;\">  5.3729</td><td style=\"text-align: right;\">               19.52</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           53.9946</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7566882\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_16-28-23\n",
      "  done: false\n",
      "  episode_len_mean: 53.60215053763441\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.007903225806455\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 146107\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0865845464080213\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014802103998199414\n",
      "          policy_loss: -0.06673907746430284\n",
      "          total_loss: 0.0853663141476884\n",
      "          vf_explained_var: 0.9361169338226318\n",
      "          vf_loss: 0.13925019262169663\n",
      "    num_agent_steps_sampled: 7566882\n",
      "    num_agent_steps_trained: 7566882\n",
      "    num_steps_sampled: 7566882\n",
      "    num_steps_trained: 7566882\n",
      "  iterations_since_restore: 417\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02928104575163\n",
      "    ram_util_percent: 53.077516339869284\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282109156435136\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.55870376672999\n",
      "    mean_inference_ms: 19.490664064766936\n",
      "    mean_raw_obs_processing_ms: 3.3093968284643274\n",
      "  time_since_restore: 228756.60590720177\n",
      "  time_this_iter_s: 536.4268991947174\n",
      "  time_total_s: 423573.9694926739\n",
      "  timers:\n",
      "    learn_throughput: 28.127\n",
      "    learn_time_ms: 355382.293\n",
      "    load_throughput: 88993.956\n",
      "    load_time_ms: 112.322\n",
      "    sample_throughput: 52.984\n",
      "    sample_time_ms: 188658.955\n",
      "    update_time_ms: 5.084\n",
      "  timestamp: 1637684903\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7566882\n",
      "  training_iteration: 817\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   817</td><td style=\"text-align: right;\">          423574</td><td style=\"text-align: right;\">7566882</td><td style=\"text-align: right;\">  5.0079</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           53.6022</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7576878\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_16-37-45\n",
      "  done: false\n",
      "  episode_len_mean: 53.924731182795696\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.541989247311832\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 146293\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.052023299439365\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014358573563759969\n",
      "          policy_loss: -0.06618365444642314\n",
      "          total_loss: 0.07213644026674466\n",
      "          vf_explained_var: 0.9530710577964783\n",
      "          vf_loss: 0.12612970113580352\n",
      "    num_agent_steps_sampled: 7576878\n",
      "    num_agent_steps_trained: 7576878\n",
      "    num_steps_sampled: 7576878\n",
      "    num_steps_trained: 7576878\n",
      "  iterations_since_restore: 418\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.32992518703243\n",
      "    ram_util_percent: 53.59763092269326\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280867531634898\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.55829490208866\n",
      "    mean_inference_ms: 19.488208592124856\n",
      "    mean_raw_obs_processing_ms: 3.311109510947345\n",
      "  time_since_restore: 229318.39200782776\n",
      "  time_this_iter_s: 561.7861006259918\n",
      "  time_total_s: 424135.75559329987\n",
      "  timers:\n",
      "    learn_throughput: 28.126\n",
      "    learn_time_ms: 355395.669\n",
      "    load_throughput: 89296.239\n",
      "    load_time_ms: 111.942\n",
      "    sample_throughput: 52.044\n",
      "    sample_time_ms: 192068.002\n",
      "    update_time_ms: 4.735\n",
      "  timestamp: 1637685465\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7576878\n",
      "  training_iteration: 818\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   818</td><td style=\"text-align: right;\">          424136</td><td style=\"text-align: right;\">7576878</td><td style=\"text-align: right;\"> 5.54199</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           53.9247</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7586874\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_16-47-02\n",
      "  done: false\n",
      "  episode_len_mean: 52.8563829787234\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.3811170212766\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 146481\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0592285951217972\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014649875330415216\n",
      "          policy_loss: -0.06994807634189061\n",
      "          total_loss: 0.08724725504927708\n",
      "          vf_explained_var: 0.9456368684768677\n",
      "          vf_loss: 0.14441336816677966\n",
      "    num_agent_steps_sampled: 7586874\n",
      "    num_agent_steps_trained: 7586874\n",
      "    num_steps_sampled: 7586874\n",
      "    num_steps_trained: 7586874\n",
      "  iterations_since_restore: 419\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.28050314465409\n",
      "    ram_util_percent: 54.16679245283018\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280901747365971\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.557907876010727\n",
      "    mean_inference_ms: 19.48910083675564\n",
      "    mean_raw_obs_processing_ms: 3.3164031564361043\n",
      "  time_since_restore: 229875.8513095379\n",
      "  time_this_iter_s: 557.4593017101288\n",
      "  time_total_s: 424693.21489501\n",
      "  timers:\n",
      "    learn_throughput: 28.126\n",
      "    learn_time_ms: 355401.242\n",
      "    load_throughput: 89307.157\n",
      "    load_time_ms: 111.928\n",
      "    sample_throughput: 51.654\n",
      "    sample_time_ms: 193517.262\n",
      "    update_time_ms: 4.666\n",
      "  timestamp: 1637686022\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7586874\n",
      "  training_iteration: 819\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   819</td><td style=\"text-align: right;\">          424693</td><td style=\"text-align: right;\">7586874</td><td style=\"text-align: right;\"> 5.38112</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           52.8564</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7596870\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_16-55-57\n",
      "  done: false\n",
      "  episode_len_mean: 54.60109289617486\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.3600546448087485\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 146664\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.046899280682146\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01444949256048097\n",
      "          policy_loss: -0.07208169542832932\n",
      "          total_loss: 0.06767234320232018\n",
      "          vf_explained_var: 0.9498216509819031\n",
      "          vf_loss: 0.127305280768507\n",
      "    num_agent_steps_sampled: 7596870\n",
      "    num_agent_steps_trained: 7596870\n",
      "    num_steps_sampled: 7596870\n",
      "    num_steps_trained: 7596870\n",
      "  iterations_since_restore: 420\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13512450851901\n",
      "    ram_util_percent: 53.663958060288344\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052806537726563664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.55702327405912\n",
      "    mean_inference_ms: 19.490124541474362\n",
      "    mean_raw_obs_processing_ms: 3.311295636120536\n",
      "  time_since_restore: 230410.8579428196\n",
      "  time_this_iter_s: 535.0066332817078\n",
      "  time_total_s: 425228.2215282917\n",
      "  timers:\n",
      "    learn_throughput: 28.12\n",
      "    learn_time_ms: 355472.307\n",
      "    load_throughput: 88996.695\n",
      "    load_time_ms: 112.319\n",
      "    sample_throughput: 51.918\n",
      "    sample_time_ms: 192534.496\n",
      "    update_time_ms: 5.27\n",
      "  timestamp: 1637686557\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7596870\n",
      "  training_iteration: 820\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   820</td><td style=\"text-align: right;\">          425228</td><td style=\"text-align: right;\">7596870</td><td style=\"text-align: right;\"> 5.36005</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           54.6011</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7606866\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_17-04-48\n",
      "  done: false\n",
      "  episode_len_mean: 54.91256830601093\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.590000000000007\n",
      "  episode_reward_mean: 5.456284153005468\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 146847\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0592621528240573\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015045035610641485\n",
      "          policy_loss: -0.06960536205188292\n",
      "          total_loss: 0.08170252854654181\n",
      "          vf_explained_var: 0.9385778307914734\n",
      "          vf_loss: 0.13762603889670164\n",
      "    num_agent_steps_sampled: 7606866\n",
      "    num_agent_steps_trained: 7606866\n",
      "    num_steps_sampled: 7606866\n",
      "    num_steps_trained: 7606866\n",
      "  iterations_since_restore: 421\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.14068692206077\n",
      "    ram_util_percent: 53.427873183619546\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282272314026398\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.555107414069404\n",
      "    mean_inference_ms: 19.49181703546854\n",
      "    mean_raw_obs_processing_ms: 3.3068579222537258\n",
      "  time_since_restore: 230941.51569366455\n",
      "  time_this_iter_s: 530.6577508449554\n",
      "  time_total_s: 425758.87927913666\n",
      "  timers:\n",
      "    learn_throughput: 28.118\n",
      "    learn_time_ms: 355500.621\n",
      "    load_throughput: 88969.877\n",
      "    load_time_ms: 112.353\n",
      "    sample_throughput: 52.671\n",
      "    sample_time_ms: 189781.483\n",
      "    update_time_ms: 5.368\n",
      "  timestamp: 1637687088\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7606866\n",
      "  training_iteration: 821\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   821</td><td style=\"text-align: right;\">          425759</td><td style=\"text-align: right;\">7606866</td><td style=\"text-align: right;\"> 5.45628</td><td style=\"text-align: right;\">               13.59</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           54.9126</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7616862\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_17-13-55\n",
      "  done: false\n",
      "  episode_len_mean: 54.167567567567566\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.640000000000006\n",
      "  episode_reward_mean: 5.368324324324329\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 147032\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.080282715549431\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014818771884485932\n",
      "          policy_loss: -0.06689284198782332\n",
      "          total_loss: 0.07714381529888242\n",
      "          vf_explained_var: 0.9436091780662537\n",
      "          vf_loss: 0.13108046899744155\n",
      "    num_agent_steps_sampled: 7616862\n",
      "    num_agent_steps_trained: 7616862\n",
      "    num_steps_sampled: 7616862\n",
      "    num_steps_trained: 7616862\n",
      "  iterations_since_restore: 422\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69539052496798\n",
      "    ram_util_percent: 54.024711907810506\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282065376828346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.55339522779769\n",
      "    mean_inference_ms: 19.49246939738679\n",
      "    mean_raw_obs_processing_ms: 3.3063033090283604\n",
      "  time_since_restore: 231488.38819909096\n",
      "  time_this_iter_s: 546.8725054264069\n",
      "  time_total_s: 426305.75178456306\n",
      "  timers:\n",
      "    learn_throughput: 28.117\n",
      "    learn_time_ms: 355509.811\n",
      "    load_throughput: 88960.929\n",
      "    load_time_ms: 112.364\n",
      "    sample_throughput: 52.742\n",
      "    sample_time_ms: 189528.136\n",
      "    update_time_ms: 5.729\n",
      "  timestamp: 1637687635\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7616862\n",
      "  training_iteration: 822\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   822</td><td style=\"text-align: right;\">          426306</td><td style=\"text-align: right;\">7616862</td><td style=\"text-align: right;\"> 5.36832</td><td style=\"text-align: right;\">               13.64</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           54.1676</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7626858\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_17-23-14\n",
      "  done: false\n",
      "  episode_len_mean: 53.0855614973262\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.550000000000008\n",
      "  episode_reward_mean: 5.0980748663101645\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 147219\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0563204154192682\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013947066277852659\n",
      "          policy_loss: -0.07499870933040574\n",
      "          total_loss: 0.05515514624309569\n",
      "          vf_explained_var: 0.9457065463066101\n",
      "          vf_loss: 0.11894389867182283\n",
      "    num_agent_steps_sampled: 7626858\n",
      "    num_agent_steps_trained: 7626858\n",
      "    num_steps_sampled: 7626858\n",
      "    num_steps_trained: 7626858\n",
      "  iterations_since_restore: 423\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.53107769423559\n",
      "    ram_util_percent: 54.38182957393483\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281292045134527\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.549863920501128\n",
      "    mean_inference_ms: 19.49245780387518\n",
      "    mean_raw_obs_processing_ms: 3.313906732309904\n",
      "  time_since_restore: 232047.91529774666\n",
      "  time_this_iter_s: 559.5270986557007\n",
      "  time_total_s: 426865.27888321877\n",
      "  timers:\n",
      "    learn_throughput: 28.119\n",
      "    learn_time_ms: 355491.983\n",
      "    load_throughput: 89215.349\n",
      "    load_time_ms: 112.043\n",
      "    sample_throughput: 52.008\n",
      "    sample_time_ms: 192199.939\n",
      "    update_time_ms: 5.575\n",
      "  timestamp: 1637688194\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7626858\n",
      "  training_iteration: 823\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   823</td><td style=\"text-align: right;\">          426865</td><td style=\"text-align: right;\">7626858</td><td style=\"text-align: right;\"> 5.09807</td><td style=\"text-align: right;\">               15.55</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.0856</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7636854\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_17-32-06\n",
      "  done: false\n",
      "  episode_len_mean: 54.25945945945946\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.560000000000008\n",
      "  episode_reward_mean: 5.495513513513518\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 147404\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0510766255807686\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015434586752631463\n",
      "          policy_loss: -0.06683328841297762\n",
      "          total_loss: 0.09601343927211585\n",
      "          vf_explained_var: 0.944409191608429\n",
      "          vf_loss: 0.14819557437725575\n",
      "    num_agent_steps_sampled: 7636854\n",
      "    num_agent_steps_trained: 7636854\n",
      "    num_steps_sampled: 7636854\n",
      "    num_steps_trained: 7636854\n",
      "  iterations_since_restore: 424\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02476943346511\n",
      "    ram_util_percent: 54.12252964426879\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280266302940512\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.54813645729666\n",
      "    mean_inference_ms: 19.491604669270828\n",
      "    mean_raw_obs_processing_ms: 3.3085151477448695\n",
      "  time_since_restore: 232579.89736795425\n",
      "  time_this_iter_s: 531.9820702075958\n",
      "  time_total_s: 427397.26095342636\n",
      "  timers:\n",
      "    learn_throughput: 28.118\n",
      "    learn_time_ms: 355500.155\n",
      "    load_throughput: 89054.994\n",
      "    load_time_ms: 112.245\n",
      "    sample_throughput: 52.067\n",
      "    sample_time_ms: 191983.64\n",
      "    update_time_ms: 5.592\n",
      "  timestamp: 1637688726\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7636854\n",
      "  training_iteration: 824\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   824</td><td style=\"text-align: right;\">          427397</td><td style=\"text-align: right;\">7636854</td><td style=\"text-align: right;\"> 5.49551</td><td style=\"text-align: right;\">               15.56</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           54.2595</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7646850\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_17-41-13\n",
      "  done: false\n",
      "  episode_len_mean: 53.3048128342246\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000007\n",
      "  episode_reward_mean: 5.041657754010699\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 147591\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.091117333982843\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014087306269878863\n",
      "          policy_loss: -0.0676450557120923\n",
      "          total_loss: 0.07430678356539862\n",
      "          vf_explained_var: 0.9358588457107544\n",
      "          vf_loss: 0.13077036795621536\n",
      "    num_agent_steps_sampled: 7646850\n",
      "    num_agent_steps_trained: 7646850\n",
      "    num_steps_sampled: 7646850\n",
      "    num_steps_trained: 7646850\n",
      "  iterations_since_restore: 425\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.65525641025641\n",
      "    ram_util_percent: 53.9324358974359\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279985582244705\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.547121263333302\n",
      "    mean_inference_ms: 19.491062528423573\n",
      "    mean_raw_obs_processing_ms: 3.307398726828356\n",
      "  time_since_restore: 233126.59088516235\n",
      "  time_this_iter_s: 546.6935172080994\n",
      "  time_total_s: 427943.95447063446\n",
      "  timers:\n",
      "    learn_throughput: 28.124\n",
      "    learn_time_ms: 355429.899\n",
      "    load_throughput: 88815.312\n",
      "    load_time_ms: 112.548\n",
      "    sample_throughput: 52.128\n",
      "    sample_time_ms: 191759.779\n",
      "    update_time_ms: 5.614\n",
      "  timestamp: 1637689273\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7646850\n",
      "  training_iteration: 825\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   825</td><td style=\"text-align: right;\">          427944</td><td style=\"text-align: right;\">7646850</td><td style=\"text-align: right;\"> 5.04166</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           53.3048</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7656846\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_17-50-38\n",
      "  done: false\n",
      "  episode_len_mean: 53.96756756756757\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000005\n",
      "  episode_reward_mean: 5.453189189189194\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 147776\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0751068845092053\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014548158956322606\n",
      "          policy_loss: -0.06866039303788284\n",
      "          total_loss: 0.07154159007791551\n",
      "          vf_explained_var: 0.9432525038719177\n",
      "          vf_loss: 0.1278105261211048\n",
      "    num_agent_steps_sampled: 7656846\n",
      "    num_agent_steps_trained: 7656846\n",
      "    num_steps_sampled: 7656846\n",
      "    num_steps_trained: 7656846\n",
      "  iterations_since_restore: 426\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.92220843672455\n",
      "    ram_util_percent: 54.189950372208436\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528073920942157\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.544344533928257\n",
      "    mean_inference_ms: 19.493241934917872\n",
      "    mean_raw_obs_processing_ms: 3.3168747462213726\n",
      "  time_since_restore: 233691.38230347633\n",
      "  time_this_iter_s: 564.7914183139801\n",
      "  time_total_s: 428508.74588894844\n",
      "  timers:\n",
      "    learn_throughput: 28.128\n",
      "    learn_time_ms: 355381.691\n",
      "    load_throughput: 88743.218\n",
      "    load_time_ms: 112.64\n",
      "    sample_throughput: 52.169\n",
      "    sample_time_ms: 191607.532\n",
      "    update_time_ms: 5.576\n",
      "  timestamp: 1637689838\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7656846\n",
      "  training_iteration: 826\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   826</td><td style=\"text-align: right;\">          428509</td><td style=\"text-align: right;\">7656846</td><td style=\"text-align: right;\"> 5.45319</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           53.9676</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7666842\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_17-59-44\n",
      "  done: false\n",
      "  episode_len_mean: 53.946236559139784\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.660000000000005\n",
      "  episode_reward_mean: 4.799301075268821\n",
      "  episode_reward_min: -0.5600000000000004\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 147962\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.101910403622202\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014606777559661452\n",
      "          policy_loss: -0.07158009817378379\n",
      "          total_loss: 0.0600928793469477\n",
      "          vf_explained_var: 0.9245572090148926\n",
      "          vf_loss: 0.11941601621720146\n",
      "    num_agent_steps_sampled: 7666842\n",
      "    num_agent_steps_trained: 7666842\n",
      "    num_steps_sampled: 7666842\n",
      "    num_steps_trained: 7666842\n",
      "  iterations_since_restore: 427\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.90756410256411\n",
      "    ram_util_percent: 53.9126923076923\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052812922698929836\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.542567242782987\n",
      "    mean_inference_ms: 19.49389195234389\n",
      "    mean_raw_obs_processing_ms: 3.3202714094100707\n",
      "  time_since_restore: 234237.72487664223\n",
      "  time_this_iter_s: 546.3425731658936\n",
      "  time_total_s: 429055.08846211433\n",
      "  timers:\n",
      "    learn_throughput: 28.133\n",
      "    learn_time_ms: 355316.976\n",
      "    load_throughput: 88561.519\n",
      "    load_time_ms: 112.871\n",
      "    sample_throughput: 51.883\n",
      "    sample_time_ms: 192663.606\n",
      "    update_time_ms: 5.543\n",
      "  timestamp: 1637690384\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7666842\n",
      "  training_iteration: 827\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   827</td><td style=\"text-align: right;\">          429055</td><td style=\"text-align: right;\">7666842</td><td style=\"text-align: right;\">  4.7993</td><td style=\"text-align: right;\">               13.66</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.9462</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7676838\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_18-08-37\n",
      "  done: false\n",
      "  episode_len_mean: 54.21739130434783\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.560000000000008\n",
      "  episode_reward_mean: 4.911413043478265\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 148146\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.072638106322193\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014223256941696289\n",
      "          policy_loss: -0.07061623206983828\n",
      "          total_loss: 0.06624695950413444\n",
      "          vf_explained_var: 0.9295280575752258\n",
      "          vf_loss: 0.12518721601362884\n",
      "    num_agent_steps_sampled: 7676838\n",
      "    num_agent_steps_trained: 7676838\n",
      "    num_steps_sampled: 7676838\n",
      "    num_steps_trained: 7676838\n",
      "  iterations_since_restore: 428\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.08605263157894\n",
      "    ram_util_percent: 53.23671052631579\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052801590900752406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.540866884262385\n",
      "    mean_inference_ms: 19.491541093906484\n",
      "    mean_raw_obs_processing_ms: 3.314520636972274\n",
      "  time_since_restore: 234770.51120996475\n",
      "  time_this_iter_s: 532.786333322525\n",
      "  time_total_s: 429587.87479543686\n",
      "  timers:\n",
      "    learn_throughput: 28.13\n",
      "    learn_time_ms: 355352.801\n",
      "    load_throughput: 88633.056\n",
      "    load_time_ms: 112.78\n",
      "    sample_throughput: 52.686\n",
      "    sample_time_ms: 189727.915\n",
      "    update_time_ms: 5.59\n",
      "  timestamp: 1637690917\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7676838\n",
      "  training_iteration: 828\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   828</td><td style=\"text-align: right;\">          429588</td><td style=\"text-align: right;\">7676838</td><td style=\"text-align: right;\"> 4.91141</td><td style=\"text-align: right;\">               15.56</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           54.2174</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7686834\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_18-17-31\n",
      "  done: false\n",
      "  episode_len_mean: 53.74193548387097\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 5.40634408602151\n",
      "  episode_reward_min: -0.7500000000000004\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 148332\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0595484375714297\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01424598582773796\n",
      "          policy_loss: -0.06815737721519115\n",
      "          total_loss: 0.07941245777444701\n",
      "          vf_explained_var: 0.9398280382156372\n",
      "          vf_loss: 0.13571118152827533\n",
      "    num_agent_steps_sampled: 7686834\n",
      "    num_agent_steps_trained: 7686834\n",
      "    num_steps_sampled: 7686834\n",
      "    num_steps_trained: 7686834\n",
      "  iterations_since_restore: 429\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.04041994750655\n",
      "    ram_util_percent: 53.123359580052494\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282002514958956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.542267546955394\n",
      "    mean_inference_ms: 19.495484545460208\n",
      "    mean_raw_obs_processing_ms: 3.3106712242942846\n",
      "  time_since_restore: 235304.61154651642\n",
      "  time_this_iter_s: 534.1003365516663\n",
      "  time_total_s: 430121.9751319885\n",
      "  timers:\n",
      "    learn_throughput: 28.13\n",
      "    learn_time_ms: 355354.214\n",
      "    load_throughput: 88761.404\n",
      "    load_time_ms: 112.617\n",
      "    sample_throughput: 53.343\n",
      "    sample_time_ms: 187390.399\n",
      "    update_time_ms: 5.611\n",
      "  timestamp: 1637691451\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7686834\n",
      "  training_iteration: 829\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   829</td><td style=\"text-align: right;\">          430122</td><td style=\"text-align: right;\">7686834</td><td style=\"text-align: right;\"> 5.40634</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.75</td><td style=\"text-align: right;\">           53.7419</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7696830\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_18-26-41\n",
      "  done: false\n",
      "  episode_len_mean: 53.00529100529101\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.560000000000008\n",
      "  episode_reward_mean: 5.097619047619053\n",
      "  episode_reward_min: -0.7300000000000004\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 148521\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.068491136261737\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014535707388842713\n",
      "          policy_loss: -0.06459202681623673\n",
      "          total_loss: 0.09519159345517579\n",
      "          vf_explained_var: 0.9345006942749023\n",
      "          vf_loss: 0.14735437236000676\n",
      "    num_agent_steps_sampled: 7696830\n",
      "    num_agent_steps_trained: 7696830\n",
      "    num_steps_sampled: 7696830\n",
      "    num_steps_trained: 7696830\n",
      "  iterations_since_restore: 430\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00089285714286\n",
      "    ram_util_percent: 53.16441326530612\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280575163489397\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.541992958109514\n",
      "    mean_inference_ms: 19.493232332458792\n",
      "    mean_raw_obs_processing_ms: 3.308860633583638\n",
      "  time_since_restore: 235854.37381911278\n",
      "  time_this_iter_s: 549.7622725963593\n",
      "  time_total_s: 430671.7374045849\n",
      "  timers:\n",
      "    learn_throughput: 28.124\n",
      "    learn_time_ms: 355427.799\n",
      "    load_throughput: 88560.359\n",
      "    load_time_ms: 112.872\n",
      "    sample_throughput: 52.947\n",
      "    sample_time_ms: 188792.924\n",
      "    update_time_ms: 5.025\n",
      "  timestamp: 1637692001\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7696830\n",
      "  training_iteration: 830\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   830</td><td style=\"text-align: right;\">          430672</td><td style=\"text-align: right;\">7696830</td><td style=\"text-align: right;\"> 5.09762</td><td style=\"text-align: right;\">               15.56</td><td style=\"text-align: right;\">               -0.73</td><td style=\"text-align: right;\">           53.0053</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7706826\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_18-36-05\n",
      "  done: false\n",
      "  episode_len_mean: 53.56989247311828\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000005\n",
      "  episode_reward_mean: 5.424731182795703\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 148707\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.075827639792339\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014533619746199843\n",
      "          policy_loss: -0.07211176947060899\n",
      "          total_loss: 0.07427299603193122\n",
      "          vf_explained_var: 0.9523161053657532\n",
      "          vf_loss: 0.13403363851979974\n",
      "    num_agent_steps_sampled: 7706826\n",
      "    num_agent_steps_trained: 7706826\n",
      "    num_steps_sampled: 7706826\n",
      "    num_steps_trained: 7706826\n",
      "  iterations_since_restore: 431\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.40732919254657\n",
      "    ram_util_percent: 53.44012422360248\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282165083023279\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.542270279751314\n",
      "    mean_inference_ms: 19.49483659309637\n",
      "    mean_raw_obs_processing_ms: 3.313285803728619\n",
      "  time_since_restore: 236418.1363351345\n",
      "  time_this_iter_s: 563.7625160217285\n",
      "  time_total_s: 431235.4999206066\n",
      "  timers:\n",
      "    learn_throughput: 28.127\n",
      "    learn_time_ms: 355392.346\n",
      "    load_throughput: 88508.441\n",
      "    load_time_ms: 112.938\n",
      "    sample_throughput: 52.025\n",
      "    sample_time_ms: 192139.012\n",
      "    update_time_ms: 4.824\n",
      "  timestamp: 1637692565\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7706826\n",
      "  training_iteration: 831\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   831</td><td style=\"text-align: right;\">          431235</td><td style=\"text-align: right;\">7706826</td><td style=\"text-align: right;\"> 5.42473</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.5699</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7716822\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_18-44-57\n",
      "  done: false\n",
      "  episode_len_mean: 54.23783783783784\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000007\n",
      "  episode_reward_mean: 5.247729729729734\n",
      "  episode_reward_min: -0.4300000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 148892\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0454674940511404\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014578104815078268\n",
      "          policy_loss: -0.07003658812448933\n",
      "          total_loss: 0.0635166102975862\n",
      "          vf_explained_var: 0.9570499658584595\n",
      "          vf_loss: 0.12079712765209048\n",
      "    num_agent_steps_sampled: 7716822\n",
      "    num_agent_steps_trained: 7716822\n",
      "    num_steps_sampled: 7716822\n",
      "    num_steps_trained: 7716822\n",
      "  iterations_since_restore: 432\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.87849604221636\n",
      "    ram_util_percent: 53.13786279683377\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528108863528073\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.541631069114562\n",
      "    mean_inference_ms: 19.493508767592793\n",
      "    mean_raw_obs_processing_ms: 3.3078017164154616\n",
      "  time_since_restore: 236949.84743762016\n",
      "  time_this_iter_s: 531.7111024856567\n",
      "  time_total_s: 431767.21102309227\n",
      "  timers:\n",
      "    learn_throughput: 28.13\n",
      "    learn_time_ms: 355352.072\n",
      "    load_throughput: 88568.983\n",
      "    load_time_ms: 112.861\n",
      "    sample_throughput: 52.427\n",
      "    sample_time_ms: 190663.318\n",
      "    update_time_ms: 5.065\n",
      "  timestamp: 1637693097\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7716822\n",
      "  training_iteration: 832\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   832</td><td style=\"text-align: right;\">          431767</td><td style=\"text-align: right;\">7716822</td><td style=\"text-align: right;\"> 5.24773</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">               -0.43</td><td style=\"text-align: right;\">           54.2378</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7726818\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_18-53-53\n",
      "  done: false\n",
      "  episode_len_mean: 53.68817204301075\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000006\n",
      "  episode_reward_mean: 4.869516129032262\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 149078\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0936361703288604\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013795658800681463\n",
      "          policy_loss: -0.07333715167706725\n",
      "          total_loss: 0.05617226800019841\n",
      "          vf_explained_var: 0.9453451633453369\n",
      "          vf_loss: 0.11901754498393854\n",
      "    num_agent_steps_sampled: 7726818\n",
      "    num_agent_steps_trained: 7726818\n",
      "    num_steps_sampled: 7726818\n",
      "    num_steps_trained: 7726818\n",
      "  iterations_since_restore: 433\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.92784313725491\n",
      "    ram_util_percent: 52.8156862745098\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052819533960772096\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.542560685588636\n",
      "    mean_inference_ms: 19.49466479572381\n",
      "    mean_raw_obs_processing_ms: 3.3037152130632794\n",
      "  time_since_restore: 237485.8191947937\n",
      "  time_this_iter_s: 535.9717571735382\n",
      "  time_total_s: 432303.1827802658\n",
      "  timers:\n",
      "    learn_throughput: 28.131\n",
      "    learn_time_ms: 355332.107\n",
      "    load_throughput: 88612.15\n",
      "    load_time_ms: 112.806\n",
      "    sample_throughput: 53.078\n",
      "    sample_time_ms: 188327.474\n",
      "    update_time_ms: 5.224\n",
      "  timestamp: 1637693633\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7726818\n",
      "  training_iteration: 833\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   833</td><td style=\"text-align: right;\">          432303</td><td style=\"text-align: right;\">7726818</td><td style=\"text-align: right;\"> 4.86952</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.6882</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7736814\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_19-03-15\n",
      "  done: false\n",
      "  episode_len_mean: 54.043243243243246\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000007\n",
      "  episode_reward_mean: 5.108810810810814\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 149263\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.06768493049116\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015594401655799704\n",
      "          policy_loss: -0.0670823057960574\n",
      "          total_loss: 0.09364193712269689\n",
      "          vf_explained_var: 0.9387974739074707\n",
      "          vf_loss: 0.14587509473608096\n",
      "    num_agent_steps_sampled: 7736814\n",
      "    num_agent_steps_trained: 7736814\n",
      "    num_steps_sampled: 7736814\n",
      "    num_steps_trained: 7736814\n",
      "  iterations_since_restore: 434\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.40249376558604\n",
      "    ram_util_percent: 53.36521197007482\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052810844183581486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.542268390405514\n",
      "    mean_inference_ms: 19.49592450897821\n",
      "    mean_raw_obs_processing_ms: 3.3066019812517107\n",
      "  time_since_restore: 238048.31763505936\n",
      "  time_this_iter_s: 562.4984402656555\n",
      "  time_total_s: 432865.68122053146\n",
      "  timers:\n",
      "    learn_throughput: 28.135\n",
      "    learn_time_ms: 355289.679\n",
      "    load_throughput: 88814.578\n",
      "    load_time_ms: 112.549\n",
      "    sample_throughput: 52.22\n",
      "    sample_time_ms: 191422.023\n",
      "    update_time_ms: 5.393\n",
      "  timestamp: 1637694195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7736814\n",
      "  training_iteration: 834\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   834</td><td style=\"text-align: right;\">          432866</td><td style=\"text-align: right;\">7736814</td><td style=\"text-align: right;\"> 5.10881</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           54.0432</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7746810\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_19-12-20\n",
      "  done: false\n",
      "  episode_len_mean: 54.23913043478261\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 5.369184782608699\n",
      "  episode_reward_min: -0.6300000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 149447\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0712782955313305\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015868586473539364\n",
      "          policy_loss: -0.06831365432667133\n",
      "          total_loss: 0.08460998399512676\n",
      "          vf_explained_var: 0.9411525130271912\n",
      "          vf_loss: 0.13748579657548687\n",
      "    num_agent_steps_sampled: 7746810\n",
      "    num_agent_steps_trained: 7746810\n",
      "    num_steps_sampled: 7746810\n",
      "    num_steps_trained: 7746810\n",
      "  iterations_since_restore: 435\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69575835475578\n",
      "    ram_util_percent: 53.48560411311055\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280616014204876\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53885807368015\n",
      "    mean_inference_ms: 19.492772052775866\n",
      "    mean_raw_obs_processing_ms: 3.3057299240350515\n",
      "  time_since_restore: 238593.62469434738\n",
      "  time_this_iter_s: 545.3070592880249\n",
      "  time_total_s: 433410.9882798195\n",
      "  timers:\n",
      "    learn_throughput: 28.135\n",
      "    learn_time_ms: 355282.483\n",
      "    load_throughput: 89315.642\n",
      "    load_time_ms: 111.918\n",
      "    sample_throughput: 52.256\n",
      "    sample_time_ms: 191289.398\n",
      "    update_time_ms: 5.778\n",
      "  timestamp: 1637694740\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7746810\n",
      "  training_iteration: 835\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   835</td><td style=\"text-align: right;\">          433411</td><td style=\"text-align: right;\">7746810</td><td style=\"text-align: right;\"> 5.36918</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -0.63</td><td style=\"text-align: right;\">           54.2391</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7756806\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_19-21-15\n",
      "  done: false\n",
      "  episode_len_mean: 54.167567567567566\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.580000000000007\n",
      "  episode_reward_mean: 5.238594594594598\n",
      "  episode_reward_min: -0.6800000000000004\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 149632\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0879683634842254\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014662693656729668\n",
      "          policy_loss: -0.07366034545206546\n",
      "          total_loss: 0.07313780733132602\n",
      "          vf_explained_var: 0.9415249824523926\n",
      "          vf_loss: 0.13427438709228467\n",
      "    num_agent_steps_sampled: 7756806\n",
      "    num_agent_steps_trained: 7756806\n",
      "    num_steps_sampled: 7756806\n",
      "    num_steps_trained: 7756806\n",
      "  iterations_since_restore: 436\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.90354330708661\n",
      "    ram_util_percent: 53.250656167979\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281498863991224\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.540100076788598\n",
      "    mean_inference_ms: 19.496349509047853\n",
      "    mean_raw_obs_processing_ms: 3.3014842453287705\n",
      "  time_since_restore: 239127.63048410416\n",
      "  time_this_iter_s: 534.0057897567749\n",
      "  time_total_s: 433944.99406957626\n",
      "  timers:\n",
      "    learn_throughput: 28.136\n",
      "    learn_time_ms: 355278.618\n",
      "    load_throughput: 89376.36\n",
      "    load_time_ms: 111.842\n",
      "    sample_throughput: 53.11\n",
      "    sample_time_ms: 188214.833\n",
      "    update_time_ms: 5.696\n",
      "  timestamp: 1637695275\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7756806\n",
      "  training_iteration: 836\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   836</td><td style=\"text-align: right;\">          433945</td><td style=\"text-align: right;\">7756806</td><td style=\"text-align: right;\"> 5.23859</td><td style=\"text-align: right;\">               13.58</td><td style=\"text-align: right;\">               -0.68</td><td style=\"text-align: right;\">           54.1676</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7766802\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_19-30-25\n",
      "  done: false\n",
      "  episode_len_mean: 53.080213903743314\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.550000000000008\n",
      "  episode_reward_mean: 5.336577540106957\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 149819\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.065494509035325\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015016550291203265\n",
      "          policy_loss: -0.07039467347450085\n",
      "          total_loss: 0.09558866022757921\n",
      "          vf_explained_var: 0.9276180863380432\n",
      "          vf_loss: 0.1524286982733345\n",
      "    num_agent_steps_sampled: 7766802\n",
      "    num_agent_steps_trained: 7766802\n",
      "    num_steps_sampled: 7766802\n",
      "    num_steps_trained: 7766802\n",
      "  iterations_since_restore: 437\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7515923566879\n",
      "    ram_util_percent: 53.33490445859872\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281232328999315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.540472712614026\n",
      "    mean_inference_ms: 19.49615051761107\n",
      "    mean_raw_obs_processing_ms: 3.300409669878301\n",
      "  time_since_restore: 239677.6660068035\n",
      "  time_this_iter_s: 550.0355226993561\n",
      "  time_total_s: 434495.0295922756\n",
      "  timers:\n",
      "    learn_throughput: 28.133\n",
      "    learn_time_ms: 355310.756\n",
      "    load_throughput: 89496.974\n",
      "    load_time_ms: 111.691\n",
      "    sample_throughput: 53.014\n",
      "    sample_time_ms: 188552.254\n",
      "    update_time_ms: 5.647\n",
      "  timestamp: 1637695825\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7766802\n",
      "  training_iteration: 837\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   837</td><td style=\"text-align: right;\">          434495</td><td style=\"text-align: right;\">7766802</td><td style=\"text-align: right;\"> 5.33658</td><td style=\"text-align: right;\">               17.55</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           53.0802</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7776798\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_19-39-37\n",
      "  done: false\n",
      "  episode_len_mean: 53.43617021276596\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.29329787234043\n",
      "  episode_reward_min: -0.6000000000000003\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 150007\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0831099410133667\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015270570313367274\n",
      "          policy_loss: -0.066928229290614\n",
      "          total_loss: 0.09651111101567554\n",
      "          vf_explained_var: 0.9449660181999207\n",
      "          vf_loss: 0.14948217193483856\n",
      "    num_agent_steps_sampled: 7776798\n",
      "    num_agent_steps_trained: 7776798\n",
      "    num_steps_sampled: 7776798\n",
      "    num_steps_trained: 7776798\n",
      "  iterations_since_restore: 438\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69060913705583\n",
      "    ram_util_percent: 53.55824873096448\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282277939631416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.542138882501895\n",
      "    mean_inference_ms: 19.4984977448788\n",
      "    mean_raw_obs_processing_ms: 3.300329076038074\n",
      "  time_since_restore: 240229.5891392231\n",
      "  time_this_iter_s: 551.9231324195862\n",
      "  time_total_s: 435046.9527246952\n",
      "  timers:\n",
      "    learn_throughput: 28.14\n",
      "    learn_time_ms: 355224.238\n",
      "    load_throughput: 89223.475\n",
      "    load_time_ms: 112.033\n",
      "    sample_throughput: 52.458\n",
      "    sample_time_ms: 190552.752\n",
      "    update_time_ms: 5.537\n",
      "  timestamp: 1637696377\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7776798\n",
      "  training_iteration: 838\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   838</td><td style=\"text-align: right;\">          435047</td><td style=\"text-align: right;\">7776798</td><td style=\"text-align: right;\">  5.2933</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">                -0.6</td><td style=\"text-align: right;\">           53.4362</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7786794\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_19-49-11\n",
      "  done: false\n",
      "  episode_len_mean: 53.340425531914896\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.569999999999997\n",
      "  episode_reward_mean: 5.572872340425536\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 150195\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.062883195747812\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015668611055578506\n",
      "          policy_loss: -0.07386077433915211\n",
      "          total_loss: 0.09355349412231063\n",
      "          vf_explained_var: 0.9454317092895508\n",
      "          vf_loss: 0.1523480455135837\n",
      "    num_agent_steps_sampled: 7786794\n",
      "    num_agent_steps_trained: 7786794\n",
      "    num_steps_sampled: 7786794\n",
      "    num_steps_trained: 7786794\n",
      "  iterations_since_restore: 439\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.13614163614163\n",
      "    ram_util_percent: 54.16361416361416\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281660585848817\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.54132206060478\n",
      "    mean_inference_ms: 19.49522997102677\n",
      "    mean_raw_obs_processing_ms: 3.305996449215602\n",
      "  time_since_restore: 240803.98515725136\n",
      "  time_this_iter_s: 574.3960180282593\n",
      "  time_total_s: 435621.34874272346\n",
      "  timers:\n",
      "    learn_throughput: 28.145\n",
      "    learn_time_ms: 355164.361\n",
      "    load_throughput: 89077.812\n",
      "    load_time_ms: 112.216\n",
      "    sample_throughput: 51.356\n",
      "    sample_time_ms: 194641.869\n",
      "    update_time_ms: 5.798\n",
      "  timestamp: 1637696951\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7786794\n",
      "  training_iteration: 839\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   839</td><td style=\"text-align: right;\">          435621</td><td style=\"text-align: right;\">7786794</td><td style=\"text-align: right;\"> 5.57287</td><td style=\"text-align: right;\">               17.57</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           53.3404</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7796790\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_19-58-08\n",
      "  done: false\n",
      "  episode_len_mean: 54.91160220994475\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.570000000000004\n",
      "  episode_reward_mean: 4.865690607734811\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 150376\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.066285946761748\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014776069085701985\n",
      "          policy_loss: -0.07102262627592341\n",
      "          total_loss: 0.08117671239410244\n",
      "          vf_explained_var: 0.9407370686531067\n",
      "          vf_loss: 0.13920046424083637\n",
      "    num_agent_steps_sampled: 7796790\n",
      "    num_agent_steps_trained: 7796790\n",
      "    num_steps_sampled: 7796790\n",
      "    num_steps_trained: 7796790\n",
      "  iterations_since_restore: 440\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.96192959582793\n",
      "    ram_util_percent: 53.3264667535854\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05283423744981124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.542458262330246\n",
      "    mean_inference_ms: 19.496750967366136\n",
      "    mean_raw_obs_processing_ms: 3.3011994857566247\n",
      "  time_since_restore: 241341.2212331295\n",
      "  time_this_iter_s: 537.2360758781433\n",
      "  time_total_s: 436158.5848186016\n",
      "  timers:\n",
      "    learn_throughput: 28.157\n",
      "    learn_time_ms: 355010.689\n",
      "    load_throughput: 89108.804\n",
      "    load_time_ms: 112.177\n",
      "    sample_throughput: 51.648\n",
      "    sample_time_ms: 193542.23\n",
      "    update_time_ms: 5.609\n",
      "  timestamp: 1637697488\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7796790\n",
      "  training_iteration: 840\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   840</td><td style=\"text-align: right;\">          436159</td><td style=\"text-align: right;\">7796790</td><td style=\"text-align: right;\"> 4.86569</td><td style=\"text-align: right;\">               17.57</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           54.9116</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7806786\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_20-08-10\n",
      "  done: false\n",
      "  episode_len_mean: 54.31351351351351\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.509999999999998\n",
      "  episode_reward_mean: 4.617351351351355\n",
      "  episode_reward_min: -0.4400000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 150561\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0922758231321015\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014746779635746334\n",
      "          policy_loss: -0.07117097724586349\n",
      "          total_loss: 0.0859650093987431\n",
      "          vf_explained_var: 0.9282247424125671\n",
      "          vf_loss: 0.144463735998769\n",
      "    num_agent_steps_sampled: 7806786\n",
      "    num_agent_steps_trained: 7806786\n",
      "    num_steps_sampled: 7806786\n",
      "    num_steps_trained: 7806786\n",
      "  iterations_since_restore: 441\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.01981351981352\n",
      "    ram_util_percent: 53.770862470862475\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052835982015048494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53927884612279\n",
      "    mean_inference_ms: 19.496882810125495\n",
      "    mean_raw_obs_processing_ms: 3.318513106368216\n",
      "  time_since_restore: 241942.88873648643\n",
      "  time_this_iter_s: 601.6675033569336\n",
      "  time_total_s: 436760.25232195854\n",
      "  timers:\n",
      "    learn_throughput: 28.162\n",
      "    learn_time_ms: 354951.999\n",
      "    load_throughput: 89059.912\n",
      "    load_time_ms: 112.239\n",
      "    sample_throughput: 50.64\n",
      "    sample_time_ms: 197391.547\n",
      "    update_time_ms: 5.578\n",
      "  timestamp: 1637698090\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7806786\n",
      "  training_iteration: 841\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   841</td><td style=\"text-align: right;\">          436760</td><td style=\"text-align: right;\">7806786</td><td style=\"text-align: right;\"> 4.61735</td><td style=\"text-align: right;\">               17.51</td><td style=\"text-align: right;\">               -0.44</td><td style=\"text-align: right;\">           54.3135</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7816782\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_20-17-14\n",
      "  done: false\n",
      "  episode_len_mean: 54.404371584699454\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.560000000000008\n",
      "  episode_reward_mean: 5.254371584699458\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 150744\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0493860646184667\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014719683450093385\n",
      "          policy_loss: -0.07187891734802435\n",
      "          total_loss: 0.07451179881176519\n",
      "          vf_explained_var: 0.9286801218986511\n",
      "          vf_loss: 0.13335129694319348\n",
      "    num_agent_steps_sampled: 7816782\n",
      "    num_agent_steps_trained: 7816782\n",
      "    num_steps_sampled: 7816782\n",
      "    num_steps_trained: 7816782\n",
      "  iterations_since_restore: 442\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69858247422681\n",
      "    ram_util_percent: 53.57719072164949\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052832664594293595\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53649180894157\n",
      "    mean_inference_ms: 19.49542135956561\n",
      "    mean_raw_obs_processing_ms: 3.3172253637263998\n",
      "  time_since_restore: 242486.88201141357\n",
      "  time_this_iter_s: 543.9932749271393\n",
      "  time_total_s: 437304.2455968857\n",
      "  timers:\n",
      "    learn_throughput: 28.162\n",
      "    learn_time_ms: 354944.066\n",
      "    load_throughput: 89155.987\n",
      "    load_time_ms: 112.118\n",
      "    sample_throughput: 50.325\n",
      "    sample_time_ms: 198628.11\n",
      "    update_time_ms: 5.195\n",
      "  timestamp: 1637698634\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7816782\n",
      "  training_iteration: 842\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   842</td><td style=\"text-align: right;\">          437304</td><td style=\"text-align: right;\">7816782</td><td style=\"text-align: right;\"> 5.25437</td><td style=\"text-align: right;\">               15.56</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           54.4044</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7826778\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_20-26-25\n",
      "  done: false\n",
      "  episode_len_mean: 53.27807486631016\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000002\n",
      "  episode_reward_mean: 5.379197860962571\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 150931\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.054016329988418\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014867781124119996\n",
      "          policy_loss: -0.06584654832853755\n",
      "          total_loss: 0.09209709991490266\n",
      "          vf_explained_var: 0.9465339779853821\n",
      "          vf_loss: 0.14461314582011575\n",
      "    num_agent_steps_sampled: 7826778\n",
      "    num_agent_steps_trained: 7826778\n",
      "    num_steps_sampled: 7826778\n",
      "    num_steps_trained: 7826778\n",
      "  iterations_since_restore: 443\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.42659033078878\n",
      "    ram_util_percent: 53.213740458015266\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05283966582859046\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.537410585019906\n",
      "    mean_inference_ms: 19.49706204892123\n",
      "    mean_raw_obs_processing_ms: 3.3169795211673807\n",
      "  time_since_restore: 243037.50647592545\n",
      "  time_this_iter_s: 550.6244645118713\n",
      "  time_total_s: 437854.87006139755\n",
      "  timers:\n",
      "    learn_throughput: 28.164\n",
      "    learn_time_ms: 354927.251\n",
      "    load_throughput: 89006.652\n",
      "    load_time_ms: 112.306\n",
      "    sample_throughput: 49.953\n",
      "    sample_time_ms: 200108.877\n",
      "    update_time_ms: 5.434\n",
      "  timestamp: 1637699185\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7826778\n",
      "  training_iteration: 843\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   843</td><td style=\"text-align: right;\">          437855</td><td style=\"text-align: right;\">7826778</td><td style=\"text-align: right;\">  5.3792</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           53.2781</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7836774\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_20-35-19\n",
      "  done: false\n",
      "  episode_len_mean: 53.903743315508024\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.58\n",
      "  episode_reward_mean: 5.395347593582892\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 151118\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0703848834736758\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015014887176576137\n",
      "          policy_loss: -0.07026465868913516\n",
      "          total_loss: 0.08359880914906398\n",
      "          vf_explained_var: 0.9473307132720947\n",
      "          vf_loss: 0.14036152603751775\n",
      "    num_agent_steps_sampled: 7836774\n",
      "    num_agent_steps_trained: 7836774\n",
      "    num_steps_sampled: 7836774\n",
      "    num_steps_trained: 7836774\n",
      "  iterations_since_restore: 444\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1043250327654\n",
      "    ram_util_percent: 53.226605504587155\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05283820006574447\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.538207079103948\n",
      "    mean_inference_ms: 19.498083830521505\n",
      "    mean_raw_obs_processing_ms: 3.3123797068775085\n",
      "  time_since_restore: 243571.99034690857\n",
      "  time_this_iter_s: 534.4838709831238\n",
      "  time_total_s: 438389.3539323807\n",
      "  timers:\n",
      "    learn_throughput: 28.169\n",
      "    learn_time_ms: 354856.103\n",
      "    load_throughput: 88821.653\n",
      "    load_time_ms: 112.54\n",
      "    sample_throughput: 50.644\n",
      "    sample_time_ms: 197378.096\n",
      "    update_time_ms: 5.377\n",
      "  timestamp: 1637699719\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7836774\n",
      "  training_iteration: 844\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   844</td><td style=\"text-align: right;\">          438389</td><td style=\"text-align: right;\">7836774</td><td style=\"text-align: right;\"> 5.39535</td><td style=\"text-align: right;\">               17.58</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           53.9037</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7846770\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_20-44-57\n",
      "  done: false\n",
      "  episode_len_mean: 52.26842105263158\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.530000000000008\n",
      "  episode_reward_mean: 5.138842105263163\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 151308\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0878745623621118\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015160991704078194\n",
      "          policy_loss: -0.06349875178755202\n",
      "          total_loss: 0.086945379453844\n",
      "          vf_explained_var: 0.9387155771255493\n",
      "          vf_loss: 0.13678424137889456\n",
      "    num_agent_steps_sampled: 7846770\n",
      "    num_agent_steps_trained: 7846770\n",
      "    num_steps_sampled: 7846770\n",
      "    num_steps_trained: 7846770\n",
      "  iterations_since_restore: 445\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.80218446601941\n",
      "    ram_util_percent: 53.65691747572816\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052837391903106136\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.536881695962993\n",
      "    mean_inference_ms: 19.4991764539294\n",
      "    mean_raw_obs_processing_ms: 3.323604529635549\n",
      "  time_since_restore: 244149.85569763184\n",
      "  time_this_iter_s: 577.8653507232666\n",
      "  time_total_s: 438967.21928310394\n",
      "  timers:\n",
      "    learn_throughput: 28.18\n",
      "    learn_time_ms: 354723.436\n",
      "    load_throughput: 88750.6\n",
      "    load_time_ms: 112.63\n",
      "    sample_throughput: 49.789\n",
      "    sample_time_ms: 200768.11\n",
      "    update_time_ms: 5.064\n",
      "  timestamp: 1637700297\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7846770\n",
      "  training_iteration: 845\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   845</td><td style=\"text-align: right;\">          438967</td><td style=\"text-align: right;\">7846770</td><td style=\"text-align: right;\"> 5.13884</td><td style=\"text-align: right;\">               15.53</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           52.2684</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7856766\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_20-53-54\n",
      "  done: false\n",
      "  episode_len_mean: 53.22222222222222\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.539999999999978\n",
      "  episode_reward_mean: 4.947407407407411\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 151497\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.095429148922962\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015198612655670263\n",
      "          policy_loss: -0.06301753052766688\n",
      "          total_loss: 0.08743423465241366\n",
      "          vf_explained_var: 0.9442121982574463\n",
      "          vf_loss: 0.1367817155204257\n",
      "    num_agent_steps_sampled: 7856766\n",
      "    num_agent_steps_trained: 7856766\n",
      "    num_steps_sampled: 7856766\n",
      "    num_steps_trained: 7856766\n",
      "  iterations_since_restore: 446\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.92010443864228\n",
      "    ram_util_percent: 52.8798955613577\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528329256137708\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53903398627793\n",
      "    mean_inference_ms: 19.499338998873075\n",
      "    mean_raw_obs_processing_ms: 3.318685589511225\n",
      "  time_since_restore: 244686.65974640846\n",
      "  time_this_iter_s: 536.8040487766266\n",
      "  time_total_s: 439504.02333188057\n",
      "  timers:\n",
      "    learn_throughput: 28.189\n",
      "    learn_time_ms: 354600.203\n",
      "    load_throughput: 88655.059\n",
      "    load_time_ms: 112.752\n",
      "    sample_throughput: 49.689\n",
      "    sample_time_ms: 201171.322\n",
      "    update_time_ms: 4.827\n",
      "  timestamp: 1637700834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7856766\n",
      "  training_iteration: 846\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   846</td><td style=\"text-align: right;\">          439504</td><td style=\"text-align: right;\">7856766</td><td style=\"text-align: right;\"> 4.94741</td><td style=\"text-align: right;\">               17.54</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.2222</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7866762\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_21-03-15\n",
      "  done: false\n",
      "  episode_len_mean: 52.51052631578948\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.610000000000005\n",
      "  episode_reward_mean: 5.114368421052636\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 151687\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.07541342844446\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01495425664962993\n",
      "          policy_loss: -0.07105323268355365\n",
      "          total_loss: 0.07717967831945079\n",
      "          vf_explained_var: 0.9466547966003418\n",
      "          vf_loss: 0.13491937720018576\n",
      "    num_agent_steps_sampled: 7866762\n",
      "    num_agent_steps_trained: 7866762\n",
      "    num_steps_sampled: 7866762\n",
      "    num_steps_trained: 7866762\n",
      "  iterations_since_restore: 447\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.59650436953807\n",
      "    ram_util_percent: 53.362546816479394\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052829919667548186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53762250142595\n",
      "    mean_inference_ms: 19.498089572587936\n",
      "    mean_raw_obs_processing_ms: 3.3220564540590813\n",
      "  time_since_restore: 245247.98360395432\n",
      "  time_this_iter_s: 561.3238575458527\n",
      "  time_total_s: 440065.3471894264\n",
      "  timers:\n",
      "    learn_throughput: 28.201\n",
      "    learn_time_ms: 354454.19\n",
      "    load_throughput: 88975.069\n",
      "    load_time_ms: 112.346\n",
      "    sample_throughput: 49.376\n",
      "    sample_time_ms: 202446.34\n",
      "    update_time_ms: 5.216\n",
      "  timestamp: 1637701395\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7866762\n",
      "  training_iteration: 847\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   847</td><td style=\"text-align: right;\">          440065</td><td style=\"text-align: right;\">7866762</td><td style=\"text-align: right;\"> 5.11437</td><td style=\"text-align: right;\">               13.61</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           52.5105</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7876758\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_21-12-11\n",
      "  done: false\n",
      "  episode_len_mean: 52.6931216931217\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.123386243386248\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 151876\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0742627429196157\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014132212639985596\n",
      "          policy_loss: -0.06667989372773925\n",
      "          total_loss: 0.07668696957705935\n",
      "          vf_explained_var: 0.9482100009918213\n",
      "          vf_loss: 0.13191454231853122\n",
      "    num_agent_steps_sampled: 7876758\n",
      "    num_agent_steps_trained: 7876758\n",
      "    num_steps_sampled: 7876758\n",
      "    num_steps_trained: 7876758\n",
      "  iterations_since_restore: 448\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.07369109947645\n",
      "    ram_util_percent: 52.7184554973822\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052830752818666234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.540601993409496\n",
      "    mean_inference_ms: 19.501238536002674\n",
      "    mean_raw_obs_processing_ms: 3.3173395634619776\n",
      "  time_since_restore: 245783.70556521416\n",
      "  time_this_iter_s: 535.7219612598419\n",
      "  time_total_s: 440601.06915068626\n",
      "  timers:\n",
      "    learn_throughput: 28.209\n",
      "    learn_time_ms: 354353.813\n",
      "    load_throughput: 89226.248\n",
      "    load_time_ms: 112.03\n",
      "    sample_throughput: 49.75\n",
      "    sample_time_ms: 200926.467\n",
      "    update_time_ms: 5.162\n",
      "  timestamp: 1637701931\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7876758\n",
      "  training_iteration: 848\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   848</td><td style=\"text-align: right;\">          440601</td><td style=\"text-align: right;\">7876758</td><td style=\"text-align: right;\"> 5.12339</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           52.6931</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7886754\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_21-21-19\n",
      "  done: false\n",
      "  episode_len_mean: 51.89119170984456\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 5.066683937823838\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 152069\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0879877735093895\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014457785805179368\n",
      "          policy_loss: -0.06669777504917494\n",
      "          total_loss: 0.07921938328339068\n",
      "          vf_explained_var: 0.9423116445541382\n",
      "          vf_loss: 0.13386039204622457\n",
      "    num_agent_steps_sampled: 7886754\n",
      "    num_agent_steps_trained: 7886754\n",
      "    num_steps_sampled: 7886754\n",
      "    num_steps_trained: 7886754\n",
      "  iterations_since_restore: 449\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77097186700769\n",
      "    ram_util_percent: 52.88670076726343\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282704446603884\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.541721922250233\n",
      "    mean_inference_ms: 19.5012013340082\n",
      "    mean_raw_obs_processing_ms: 3.3166763366057253\n",
      "  time_since_restore: 246331.63732290268\n",
      "  time_this_iter_s: 547.9317576885223\n",
      "  time_total_s: 441149.0009083748\n",
      "  timers:\n",
      "    learn_throughput: 28.217\n",
      "    learn_time_ms: 354248.364\n",
      "    load_throughput: 89185.915\n",
      "    load_time_ms: 112.08\n",
      "    sample_throughput: 50.387\n",
      "    sample_time_ms: 198385.551\n",
      "    update_time_ms: 4.807\n",
      "  timestamp: 1637702479\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7886754\n",
      "  training_iteration: 849\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   849</td><td style=\"text-align: right;\">          441149</td><td style=\"text-align: right;\">7886754</td><td style=\"text-align: right;\"> 5.06668</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           51.8912</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7896750\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_21-30-29\n",
      "  done: false\n",
      "  episode_len_mean: 52.66315789473684\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000005\n",
      "  episode_reward_mean: 5.280052631578951\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 152259\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.082419834294951\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015503735324770599\n",
      "          policy_loss: -0.07136889397853999\n",
      "          total_loss: 0.08855109517194305\n",
      "          vf_explained_var: 0.9452254176139832\n",
      "          vf_loss: 0.14542473924335048\n",
      "    num_agent_steps_sampled: 7896750\n",
      "    num_agent_steps_trained: 7896750\n",
      "    num_steps_sampled: 7896750\n",
      "    num_steps_trained: 7896750\n",
      "  iterations_since_restore: 450\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.59388535031844\n",
      "    ram_util_percent: 52.884458598726106\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052825441582172325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.543006713578627\n",
      "    mean_inference_ms: 19.502001147751255\n",
      "    mean_raw_obs_processing_ms: 3.315759809730163\n",
      "  time_since_restore: 246881.66151285172\n",
      "  time_this_iter_s: 550.0241899490356\n",
      "  time_total_s: 441699.0250983238\n",
      "  timers:\n",
      "    learn_throughput: 28.224\n",
      "    learn_time_ms: 354169.665\n",
      "    load_throughput: 89153.599\n",
      "    load_time_ms: 112.121\n",
      "    sample_throughput: 50.044\n",
      "    sample_time_ms: 199742.902\n",
      "    update_time_ms: 5.214\n",
      "  timestamp: 1637703029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7896750\n",
      "  training_iteration: 850\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   850</td><td style=\"text-align: right;\">          441699</td><td style=\"text-align: right;\">7896750</td><td style=\"text-align: right;\"> 5.28005</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           52.6632</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7906746\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_21-39-36\n",
      "  done: false\n",
      "  episode_len_mean: 52.067708333333336\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 4.7066666666666706\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 152451\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0909976287539225\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014995778455640207\n",
      "          policy_loss: -0.06792645984019895\n",
      "          total_loss: 0.0816994704699232\n",
      "          vf_explained_var: 0.9531298875808716\n",
      "          vf_loss: 0.13637364824586753\n",
      "    num_agent_steps_sampled: 7906746\n",
      "    num_agent_steps_trained: 7906746\n",
      "    num_steps_sampled: 7906746\n",
      "    num_steps_trained: 7906746\n",
      "  iterations_since_restore: 451\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82589743589743\n",
      "    ram_util_percent: 53.062820512820515\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282691732294381\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.542782997456197\n",
      "    mean_inference_ms: 19.500375803803024\n",
      "    mean_raw_obs_processing_ms: 3.315817891626328\n",
      "  time_since_restore: 247428.74641275406\n",
      "  time_this_iter_s: 547.0848999023438\n",
      "  time_total_s: 442246.10999822617\n",
      "  timers:\n",
      "    learn_throughput: 28.228\n",
      "    learn_time_ms: 354118.582\n",
      "    load_throughput: 89102.101\n",
      "    load_time_ms: 112.186\n",
      "    sample_throughput: 51.437\n",
      "    sample_time_ms: 194335.117\n",
      "    update_time_ms: 5.407\n",
      "  timestamp: 1637703576\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7906746\n",
      "  training_iteration: 851\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   851</td><td style=\"text-align: right;\">          442246</td><td style=\"text-align: right;\">7906746</td><td style=\"text-align: right;\"> 4.70667</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           52.0677</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7916742\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_21-48-30\n",
      "  done: false\n",
      "  episode_len_mean: 52.47894736842105\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.580000000000007\n",
      "  episode_reward_mean: 4.9035263157894775\n",
      "  episode_reward_min: -0.6600000000000004\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 152641\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0971300648876943\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01479689260042725\n",
      "          policy_loss: -0.06782238652635002\n",
      "          total_loss: 0.0746152890755549\n",
      "          vf_explained_var: 0.9360598921775818\n",
      "          vf_loss: 0.12969980440411089\n",
      "    num_agent_steps_sampled: 7916742\n",
      "    num_agent_steps_trained: 7916742\n",
      "    num_steps_sampled: 7916742\n",
      "    num_steps_trained: 7916742\n",
      "  iterations_since_restore: 452\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02454068241471\n",
      "    ram_util_percent: 53.09448818897638\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528220173611817\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.544130744924633\n",
      "    mean_inference_ms: 19.499446239489266\n",
      "    mean_raw_obs_processing_ms: 3.310756596903067\n",
      "  time_since_restore: 247962.5114312172\n",
      "  time_this_iter_s: 533.7650184631348\n",
      "  time_total_s: 442779.8750166893\n",
      "  timers:\n",
      "    learn_throughput: 28.235\n",
      "    learn_time_ms: 354026.629\n",
      "    load_throughput: 89075.693\n",
      "    load_time_ms: 112.219\n",
      "    sample_throughput: 51.685\n",
      "    sample_time_ms: 193403.993\n",
      "    update_time_ms: 5.592\n",
      "  timestamp: 1637704110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7916742\n",
      "  training_iteration: 852\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   852</td><td style=\"text-align: right;\">          442780</td><td style=\"text-align: right;\">7916742</td><td style=\"text-align: right;\"> 4.90353</td><td style=\"text-align: right;\">               13.58</td><td style=\"text-align: right;\">               -0.66</td><td style=\"text-align: right;\">           52.4789</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7926738\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_21-57-38\n",
      "  done: false\n",
      "  episode_len_mean: 52.223958333333336\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 4.59182291666667\n",
      "  episode_reward_min: -0.6300000000000003\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 152833\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.090734629362941\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013988099625896741\n",
      "          policy_loss: -0.07337858491095592\n",
      "          total_loss: 0.05777370823045466\n",
      "          vf_explained_var: 0.9237919449806213\n",
      "          vf_loss: 0.12019299818071945\n",
      "    num_agent_steps_sampled: 7926738\n",
      "    num_agent_steps_trained: 7926738\n",
      "    num_steps_sampled: 7926738\n",
      "    num_steps_trained: 7926738\n",
      "  iterations_since_restore: 453\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.67484035759897\n",
      "    ram_util_percent: 53.13563218390805\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052825715007525996\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.54590290961474\n",
      "    mean_inference_ms: 19.50153085987866\n",
      "    mean_raw_obs_processing_ms: 3.3102630745216595\n",
      "  time_since_restore: 248511.02061247826\n",
      "  time_this_iter_s: 548.5091812610626\n",
      "  time_total_s: 443328.38419795036\n",
      "  timers:\n",
      "    learn_throughput: 28.244\n",
      "    learn_time_ms: 353911.059\n",
      "    load_throughput: 88948.793\n",
      "    load_time_ms: 112.379\n",
      "    sample_throughput: 51.71\n",
      "    sample_time_ms: 193309.078\n",
      "    update_time_ms: 5.404\n",
      "  timestamp: 1637704658\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7926738\n",
      "  training_iteration: 853\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   853</td><td style=\"text-align: right;\">          443328</td><td style=\"text-align: right;\">7926738</td><td style=\"text-align: right;\"> 4.59182</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.63</td><td style=\"text-align: right;\">            52.224</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7936734\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_22-06-46\n",
      "  done: false\n",
      "  episode_len_mean: 53.27127659574468\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.43000000000001\n",
      "  episode_reward_mean: 4.994414893617025\n",
      "  episode_reward_min: -0.4800000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 153021\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1017739452032678\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014648987526218906\n",
      "          policy_loss: -0.06815175480502318\n",
      "          total_loss: 0.07653080702127106\n",
      "          vf_explained_var: 0.9480049014091492\n",
      "          vf_loss: 0.13232807543644884\n",
      "    num_agent_steps_sampled: 7936734\n",
      "    num_agent_steps_trained: 7936734\n",
      "    num_steps_sampled: 7936734\n",
      "    num_steps_trained: 7936734\n",
      "  iterations_since_restore: 454\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81408450704225\n",
      "    ram_util_percent: 53.83597951344429\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05283305611305212\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.54572599794641\n",
      "    mean_inference_ms: 19.50333527297272\n",
      "    mean_raw_obs_processing_ms: 3.3101585076707907\n",
      "  time_since_restore: 249058.68463277817\n",
      "  time_this_iter_s: 547.6640202999115\n",
      "  time_total_s: 443876.0482182503\n",
      "  timers:\n",
      "    learn_throughput: 28.247\n",
      "    learn_time_ms: 353882.734\n",
      "    load_throughput: 89002.986\n",
      "    load_time_ms: 112.311\n",
      "    sample_throughput: 51.352\n",
      "    sample_time_ms: 194655.913\n",
      "    update_time_ms: 5.207\n",
      "  timestamp: 1637705206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7936734\n",
      "  training_iteration: 854\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   854</td><td style=\"text-align: right;\">          443876</td><td style=\"text-align: right;\">7936734</td><td style=\"text-align: right;\"> 4.99441</td><td style=\"text-align: right;\">               15.43</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           53.2713</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7946730\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_22-15-52\n",
      "  done: false\n",
      "  episode_len_mean: 52.47089947089947\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.609999999999985\n",
      "  episode_reward_mean: 5.029047619047622\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 153210\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.06863162993906\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014950066102814285\n",
      "          policy_loss: -0.06686041937965313\n",
      "          total_loss: 0.08880576205902839\n",
      "          vf_explained_var: 0.929641604423523\n",
      "          vf_loss: 0.14229437635657957\n",
      "    num_agent_steps_sampled: 7946730\n",
      "    num_agent_steps_trained: 7946730\n",
      "    num_steps_sampled: 7946730\n",
      "    num_steps_trained: 7946730\n",
      "  iterations_since_restore: 455\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.70551989730423\n",
      "    ram_util_percent: 54.102439024390236\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052822904640074414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.543748207872394\n",
      "    mean_inference_ms: 19.50126546253632\n",
      "    mean_raw_obs_processing_ms: 3.3091631479067405\n",
      "  time_since_restore: 249604.7920396328\n",
      "  time_this_iter_s: 546.1074068546295\n",
      "  time_total_s: 444422.1556251049\n",
      "  timers:\n",
      "    learn_throughput: 28.249\n",
      "    learn_time_ms: 353850.29\n",
      "    load_throughput: 88835.58\n",
      "    load_time_ms: 112.522\n",
      "    sample_throughput: 52.195\n",
      "    sample_time_ms: 191511.134\n",
      "    update_time_ms: 5.784\n",
      "  timestamp: 1637705752\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7946730\n",
      "  training_iteration: 855\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   855</td><td style=\"text-align: right;\">          444422</td><td style=\"text-align: right;\">7946730</td><td style=\"text-align: right;\"> 5.02905</td><td style=\"text-align: right;\">               17.61</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           52.4709</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7956726\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_22-25-27\n",
      "  done: false\n",
      "  episode_len_mean: 53.38297872340426\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.48000000000001\n",
      "  episode_reward_mean: 5.19521276595745\n",
      "  episode_reward_min: -0.7000000000000004\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 153398\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.055473898835929\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014704543245456234\n",
      "          policy_loss: -0.06305204214252272\n",
      "          total_loss: 0.08883677110477795\n",
      "          vf_explained_var: 0.9384654760360718\n",
      "          vf_loss: 0.138944763336873\n",
      "    num_agent_steps_sampled: 7956726\n",
      "    num_agent_steps_trained: 7956726\n",
      "    num_steps_sampled: 7956726\n",
      "    num_steps_trained: 7956726\n",
      "  iterations_since_restore: 456\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.14421437271619\n",
      "    ram_util_percent: 54.38940316686968\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282118371962205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.538984561037214\n",
      "    mean_inference_ms: 19.500684569912277\n",
      "    mean_raw_obs_processing_ms: 3.3173751342669577\n",
      "  time_since_restore: 250179.81896162033\n",
      "  time_this_iter_s: 575.0269219875336\n",
      "  time_total_s: 444997.18254709244\n",
      "  timers:\n",
      "    learn_throughput: 28.255\n",
      "    learn_time_ms: 353777.111\n",
      "    load_throughput: 88871.998\n",
      "    load_time_ms: 112.476\n",
      "    sample_throughput: 51.155\n",
      "    sample_time_ms: 195406.209\n",
      "    update_time_ms: 6.113\n",
      "  timestamp: 1637706327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7956726\n",
      "  training_iteration: 856\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   856</td><td style=\"text-align: right;\">          444997</td><td style=\"text-align: right;\">7956726</td><td style=\"text-align: right;\"> 5.19521</td><td style=\"text-align: right;\">               15.48</td><td style=\"text-align: right;\">                -0.7</td><td style=\"text-align: right;\">            53.383</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7966722\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_22-34-39\n",
      "  done: false\n",
      "  episode_len_mean: 53.657754010695186\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000005\n",
      "  episode_reward_mean: 5.109304812834228\n",
      "  episode_reward_min: -0.6000000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 153585\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0705362376917797\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014700008910812546\n",
      "          policy_loss: -0.0686084292716537\n",
      "          total_loss: 0.08710941805927057\n",
      "          vf_explained_var: 0.9396586418151855\n",
      "          vf_loss: 0.14293474993775093\n",
      "    num_agent_steps_sampled: 7966722\n",
      "    num_agent_steps_trained: 7966722\n",
      "    num_steps_sampled: 7966722\n",
      "    num_steps_trained: 7966722\n",
      "  iterations_since_restore: 457\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.58017789072427\n",
      "    ram_util_percent: 54.36988564167725\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282041478812034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53631475750932\n",
      "    mean_inference_ms: 19.500698993870763\n",
      "    mean_raw_obs_processing_ms: 3.3194515535023843\n",
      "  time_since_restore: 250731.578902483\n",
      "  time_this_iter_s: 551.7599408626556\n",
      "  time_total_s: 445548.9424879551\n",
      "  timers:\n",
      "    learn_throughput: 28.258\n",
      "    learn_time_ms: 353742.489\n",
      "    load_throughput: 88710.076\n",
      "    load_time_ms: 112.682\n",
      "    sample_throughput: 51.398\n",
      "    sample_time_ms: 194483.014\n",
      "    update_time_ms: 5.793\n",
      "  timestamp: 1637706879\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7966722\n",
      "  training_iteration: 857\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   857</td><td style=\"text-align: right;\">          445549</td><td style=\"text-align: right;\">7966722</td><td style=\"text-align: right;\">  5.1093</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">                -0.6</td><td style=\"text-align: right;\">           53.6578</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7976718\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_22-43-44\n",
      "  done: false\n",
      "  episode_len_mean: 53.32620320855615\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.630000000000003\n",
      "  episode_reward_mean: 5.196844919786101\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 153772\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0792717780932843\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014525046818812342\n",
      "          policy_loss: -0.06963440734660976\n",
      "          total_loss: 0.07986044197089187\n",
      "          vf_explained_var: 0.9324830770492554\n",
      "          vf_loss: 0.13719769421970493\n",
      "    num_agent_steps_sampled: 7976718\n",
      "    num_agent_steps_trained: 7976718\n",
      "    num_steps_sampled: 7976718\n",
      "    num_steps_trained: 7976718\n",
      "  iterations_since_restore: 458\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.85205655526991\n",
      "    ram_util_percent: 53.78007712082262\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282056348553963\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53548477896165\n",
      "    mean_inference_ms: 19.500836787921642\n",
      "    mean_raw_obs_processing_ms: 3.318727134956826\n",
      "  time_since_restore: 251276.51789474487\n",
      "  time_this_iter_s: 544.9389922618866\n",
      "  time_total_s: 446093.881480217\n",
      "  timers:\n",
      "    learn_throughput: 28.258\n",
      "    learn_time_ms: 353737.307\n",
      "    load_throughput: 88784.918\n",
      "    load_time_ms: 112.587\n",
      "    sample_throughput: 51.154\n",
      "    sample_time_ms: 195409.943\n",
      "    update_time_ms: 5.977\n",
      "  timestamp: 1637707424\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7976718\n",
      "  training_iteration: 858\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   858</td><td style=\"text-align: right;\">          446094</td><td style=\"text-align: right;\">7976718</td><td style=\"text-align: right;\"> 5.19684</td><td style=\"text-align: right;\">               17.63</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           53.3262</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7986714\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_22-52-37\n",
      "  done: false\n",
      "  episode_len_mean: 53.212765957446805\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000006\n",
      "  episode_reward_mean: 4.954095744680855\n",
      "  episode_reward_min: -0.4300000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 153960\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0870203044041093\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014693406769926472\n",
      "          policy_loss: -0.06892060584427653\n",
      "          total_loss: 0.08658396662043981\n",
      "          vf_explained_var: 0.9436188340187073\n",
      "          vf_loss: 0.14290135709623092\n",
      "    num_agent_steps_sampled: 7986714\n",
      "    num_agent_steps_trained: 7986714\n",
      "    num_steps_sampled: 7986714\n",
      "    num_steps_trained: 7986714\n",
      "  iterations_since_restore: 459\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91277997364955\n",
      "    ram_util_percent: 53.36745718050065\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281731453933023\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53627814339729\n",
      "    mean_inference_ms: 19.50163867695644\n",
      "    mean_raw_obs_processing_ms: 3.3136582643678776\n",
      "  time_since_restore: 251808.98936128616\n",
      "  time_this_iter_s: 532.4714665412903\n",
      "  time_total_s: 446626.35294675827\n",
      "  timers:\n",
      "    learn_throughput: 28.26\n",
      "    learn_time_ms: 353720.926\n",
      "    load_throughput: 88796.22\n",
      "    load_time_ms: 112.572\n",
      "    sample_throughput: 51.558\n",
      "    sample_time_ms: 193880.46\n",
      "    update_time_ms: 6.175\n",
      "  timestamp: 1637707957\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7986714\n",
      "  training_iteration: 859\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   859</td><td style=\"text-align: right;\">          446626</td><td style=\"text-align: right;\">7986714</td><td style=\"text-align: right;\">  4.9541</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -0.43</td><td style=\"text-align: right;\">           53.2128</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 7996710\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_23-01-43\n",
      "  done: false\n",
      "  episode_len_mean: 53.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.050215053763445\n",
      "  episode_reward_min: -0.6000000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 154146\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.098132309185932\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015003939841758424\n",
      "          policy_loss: -0.06827722027569745\n",
      "          total_loss: 0.09774586503265757\n",
      "          vf_explained_var: 0.9393900036811829\n",
      "          vf_loss: 0.15282355649667945\n",
      "    num_agent_steps_sampled: 7996710\n",
      "    num_agent_steps_trained: 7996710\n",
      "    num_steps_sampled: 7996710\n",
      "    num_steps_trained: 7996710\n",
      "  iterations_since_restore: 460\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7851282051282\n",
      "    ram_util_percent: 53.51217948717949\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281950659569244\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.535651733910615\n",
      "    mean_inference_ms: 19.501296535321917\n",
      "    mean_raw_obs_processing_ms: 3.316556906347986\n",
      "  time_since_restore: 252355.3655283451\n",
      "  time_this_iter_s: 546.3761670589447\n",
      "  time_total_s: 447172.7291138172\n",
      "  timers:\n",
      "    learn_throughput: 28.26\n",
      "    learn_time_ms: 353711.312\n",
      "    load_throughput: 88869.097\n",
      "    load_time_ms: 112.48\n",
      "    sample_throughput: 51.652\n",
      "    sample_time_ms: 193526.422\n",
      "    update_time_ms: 5.816\n",
      "  timestamp: 1637708503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7996710\n",
      "  training_iteration: 860\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   860</td><td style=\"text-align: right;\">          447173</td><td style=\"text-align: right;\">7996710</td><td style=\"text-align: right;\"> 5.05022</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">                -0.6</td><td style=\"text-align: right;\">              53.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8006706\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_23-10-55\n",
      "  done: false\n",
      "  episode_len_mean: 54.30810810810811\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.730000000000004\n",
      "  episode_reward_mean: 5.282270270270275\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 154331\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0929117592463053\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015321567072562116\n",
      "          policy_loss: -0.06639975093889934\n",
      "          total_loss: 0.07862697461953366\n",
      "          vf_explained_var: 0.9337877631187439\n",
      "          vf_loss: 0.13105139782302547\n",
      "    num_agent_steps_sampled: 8006706\n",
      "    num_agent_steps_trained: 8006706\n",
      "    num_steps_sampled: 8006706\n",
      "    num_steps_trained: 8006706\n",
      "  iterations_since_restore: 461\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.47563451776651\n",
      "    ram_util_percent: 53.41256345177667\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282713440971407\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.533468800045547\n",
      "    mean_inference_ms: 19.50284317120383\n",
      "    mean_raw_obs_processing_ms: 3.3228015806905034\n",
      "  time_since_restore: 252907.69950294495\n",
      "  time_this_iter_s: 552.3339745998383\n",
      "  time_total_s: 447725.06308841705\n",
      "  timers:\n",
      "    learn_throughput: 28.261\n",
      "    learn_time_ms: 353702.555\n",
      "    load_throughput: 88936.642\n",
      "    load_time_ms: 112.395\n",
      "    sample_throughput: 51.51\n",
      "    sample_time_ms: 194060.443\n",
      "    update_time_ms: 5.678\n",
      "  timestamp: 1637709055\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8006706\n",
      "  training_iteration: 861\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   861</td><td style=\"text-align: right;\">          447725</td><td style=\"text-align: right;\">8006706</td><td style=\"text-align: right;\"> 5.28227</td><td style=\"text-align: right;\">               15.73</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           54.3081</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8016702\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_23-19-46\n",
      "  done: false\n",
      "  episode_len_mean: 54.255434782608695\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.488206521739135\n",
      "  episode_reward_min: -0.4000000000000002\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 154515\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0795000266837307\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014686259032998588\n",
      "          policy_loss: -0.06503006837829088\n",
      "          total_loss: 0.09787903040861169\n",
      "          vf_explained_var: 0.9458919763565063\n",
      "          vf_loss: 0.1502469640000757\n",
      "    num_agent_steps_sampled: 8016702\n",
      "    num_agent_steps_trained: 8016702\n",
      "    num_steps_sampled: 8016702\n",
      "    num_steps_trained: 8016702\n",
      "  iterations_since_restore: 462\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98216644649933\n",
      "    ram_util_percent: 52.76129458388375\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282386207875322\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.531917236005093\n",
      "    mean_inference_ms: 19.500983806798533\n",
      "    mean_raw_obs_processing_ms: 3.317880239285367\n",
      "  time_since_restore: 253438.01632905006\n",
      "  time_this_iter_s: 530.3168261051178\n",
      "  time_total_s: 448255.3799145222\n",
      "  timers:\n",
      "    learn_throughput: 28.261\n",
      "    learn_time_ms: 353708.805\n",
      "    load_throughput: 89205.346\n",
      "    load_time_ms: 112.056\n",
      "    sample_throughput: 51.603\n",
      "    sample_time_ms: 193710.152\n",
      "    update_time_ms: 5.289\n",
      "  timestamp: 1637709586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8016702\n",
      "  training_iteration: 862\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   862</td><td style=\"text-align: right;\">          448255</td><td style=\"text-align: right;\">8016702</td><td style=\"text-align: right;\"> 5.48821</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">                -0.4</td><td style=\"text-align: right;\">           54.2554</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8026698\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_23-28-53\n",
      "  done: false\n",
      "  episode_len_mean: 53.854838709677416\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.56999999999998\n",
      "  episode_reward_mean: 5.073870967741939\n",
      "  episode_reward_min: -0.6300000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 154701\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.075980548686292\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015128372159660362\n",
      "          policy_loss: -0.06778976082205629\n",
      "          total_loss: 0.08804497036295199\n",
      "          vf_explained_var: 0.9178504943847656\n",
      "          vf_loss: 0.14213021334838571\n",
      "    num_agent_steps_sampled: 8026698\n",
      "    num_agent_steps_trained: 8026698\n",
      "    num_steps_sampled: 8026698\n",
      "    num_steps_trained: 8026698\n",
      "  iterations_since_restore: 463\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.86474358974358\n",
      "    ram_util_percent: 53.04666666666666\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282189155656674\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53133893383027\n",
      "    mean_inference_ms: 19.502098340971106\n",
      "    mean_raw_obs_processing_ms: 3.3174870199696227\n",
      "  time_since_restore: 253985.2844438553\n",
      "  time_this_iter_s: 547.2681148052216\n",
      "  time_total_s: 448802.6480293274\n",
      "  timers:\n",
      "    learn_throughput: 28.26\n",
      "    learn_time_ms: 353714.515\n",
      "    load_throughput: 89246.741\n",
      "    load_time_ms: 112.004\n",
      "    sample_throughput: 51.638\n",
      "    sample_time_ms: 193580.015\n",
      "    update_time_ms: 5.563\n",
      "  timestamp: 1637710133\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8026698\n",
      "  training_iteration: 863\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   863</td><td style=\"text-align: right;\">          448803</td><td style=\"text-align: right;\">8026698</td><td style=\"text-align: right;\"> 5.07387</td><td style=\"text-align: right;\">               17.57</td><td style=\"text-align: right;\">               -0.63</td><td style=\"text-align: right;\">           53.8548</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8036694\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_23-37-59\n",
      "  done: false\n",
      "  episode_len_mean: 53.516129032258064\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.710000000000003\n",
      "  episode_reward_mean: 4.731774193548391\n",
      "  episode_reward_min: -0.7300000000000004\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 154887\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1141982051263373\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01431742204531201\n",
      "          policy_loss: -0.06942349730011758\n",
      "          total_loss: 0.06427584173827608\n",
      "          vf_explained_var: 0.9446861743927002\n",
      "          vf_loss: 0.12222444347314439\n",
      "    num_agent_steps_sampled: 8036694\n",
      "    num_agent_steps_trained: 8036694\n",
      "    num_steps_sampled: 8036694\n",
      "    num_steps_trained: 8036694\n",
      "  iterations_since_restore: 464\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.71589743589743\n",
      "    ram_util_percent: 53.78628205128206\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282124019577348\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53060201768064\n",
      "    mean_inference_ms: 19.503335250483733\n",
      "    mean_raw_obs_processing_ms: 3.320990140886152\n",
      "  time_since_restore: 254531.43082761765\n",
      "  time_this_iter_s: 546.1463837623596\n",
      "  time_total_s: 449348.79441308975\n",
      "  timers:\n",
      "    learn_throughput: 28.262\n",
      "    learn_time_ms: 353696.43\n",
      "    load_throughput: 89456.339\n",
      "    load_time_ms: 111.742\n",
      "    sample_throughput: 51.673\n",
      "    sample_time_ms: 193446.397\n",
      "    update_time_ms: 5.535\n",
      "  timestamp: 1637710679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8036694\n",
      "  training_iteration: 864\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   864</td><td style=\"text-align: right;\">          449349</td><td style=\"text-align: right;\">8036694</td><td style=\"text-align: right;\"> 4.73177</td><td style=\"text-align: right;\">               11.71</td><td style=\"text-align: right;\">               -0.73</td><td style=\"text-align: right;\">           53.5161</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8046690\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_23-46-55\n",
      "  done: false\n",
      "  episode_len_mean: 52.41361256544503\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.499999999999996\n",
      "  episode_reward_mean: 5.151308900523564\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 155078\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.060156996733692\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016109911914882483\n",
      "          policy_loss: -0.06315236231302221\n",
      "          total_loss: 0.10730476020953027\n",
      "          vf_explained_var: 0.9327023029327393\n",
      "          vf_loss: 0.15435829992802536\n",
      "    num_agent_steps_sampled: 8046690\n",
      "    num_agent_steps_trained: 8046690\n",
      "    num_steps_sampled: 8046690\n",
      "    num_steps_trained: 8046690\n",
      "  iterations_since_restore: 465\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.84980392156864\n",
      "    ram_util_percent: 53.360653594771236\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05282192038545436\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.532734894052723\n",
      "    mean_inference_ms: 19.50468973735015\n",
      "    mean_raw_obs_processing_ms: 3.316565068200771\n",
      "  time_since_restore: 255067.65585064888\n",
      "  time_this_iter_s: 536.2250230312347\n",
      "  time_total_s: 449885.019436121\n",
      "  timers:\n",
      "    learn_throughput: 28.258\n",
      "    learn_time_ms: 353741.813\n",
      "    load_throughput: 89274.924\n",
      "    load_time_ms: 111.969\n",
      "    sample_throughput: 51.951\n",
      "    sample_time_ms: 192413.442\n",
      "    update_time_ms: 5.236\n",
      "  timestamp: 1637711215\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8046690\n",
      "  training_iteration: 865\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   865</td><td style=\"text-align: right;\">          449885</td><td style=\"text-align: right;\">8046690</td><td style=\"text-align: right;\"> 5.15131</td><td style=\"text-align: right;\">                17.5</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           52.4136</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8056686\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-23_23-55-50\n",
      "  done: false\n",
      "  episode_len_mean: 52.473684210526315\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000004\n",
      "  episode_reward_mean: 4.908578947368425\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 155268\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0961031412025055\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01512154803604509\n",
      "          policy_loss: -0.06939380799756391\n",
      "          total_loss: 0.09634447036439368\n",
      "          vf_explained_var: 0.9413862228393555\n",
      "          vf_loss: 0.15225053141286304\n",
      "    num_agent_steps_sampled: 8056686\n",
      "    num_agent_steps_trained: 8056686\n",
      "    num_steps_sampled: 8056686\n",
      "    num_steps_trained: 8056686\n",
      "  iterations_since_restore: 466\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01916010498688\n",
      "    ram_util_percent: 53.21089238845144\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280669704440512\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.533166623213855\n",
      "    mean_inference_ms: 19.501614570985385\n",
      "    mean_raw_obs_processing_ms: 3.3112791371149344\n",
      "  time_since_restore: 255601.69263720512\n",
      "  time_this_iter_s: 534.0367865562439\n",
      "  time_total_s: 450419.05622267723\n",
      "  timers:\n",
      "    learn_throughput: 28.253\n",
      "    learn_time_ms: 353799.031\n",
      "    load_throughput: 88958.343\n",
      "    load_time_ms: 112.367\n",
      "    sample_throughput: 53.098\n",
      "    sample_time_ms: 188257.336\n",
      "    update_time_ms: 4.823\n",
      "  timestamp: 1637711750\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8056686\n",
      "  training_iteration: 866\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   866</td><td style=\"text-align: right;\">          450419</td><td style=\"text-align: right;\">8056686</td><td style=\"text-align: right;\"> 4.90858</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           52.4737</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8066682\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_00-05-22\n",
      "  done: false\n",
      "  episode_len_mean: 52.03626943005181\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.580000000000007\n",
      "  episode_reward_mean: 4.646683937823838\n",
      "  episode_reward_min: -0.6900000000000004\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 155461\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.123744154862132\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016268257364970118\n",
      "          policy_loss: -0.06304521766087126\n",
      "          total_loss: 0.09828080898813107\n",
      "          vf_explained_var: 0.9178394079208374\n",
      "          vf_loss: 0.14550234382143656\n",
      "    num_agent_steps_sampled: 8066682\n",
      "    num_agent_steps_trained: 8066682\n",
      "    num_steps_sampled: 8066682\n",
      "    num_steps_trained: 8066682\n",
      "  iterations_since_restore: 467\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.00036764705881\n",
      "    ram_util_percent: 54.21139705882353\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052812304181829466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.532482872657347\n",
      "    mean_inference_ms: 19.503486135905234\n",
      "    mean_raw_obs_processing_ms: 3.3225552809725007\n",
      "  time_since_restore: 256174.0632326603\n",
      "  time_this_iter_s: 572.3705954551697\n",
      "  time_total_s: 450991.4268181324\n",
      "  timers:\n",
      "    learn_throughput: 28.255\n",
      "    learn_time_ms: 353777.962\n",
      "    load_throughput: 89234.813\n",
      "    load_time_ms: 112.019\n",
      "    sample_throughput: 52.516\n",
      "    sample_time_ms: 190341.285\n",
      "    update_time_ms: 4.787\n",
      "  timestamp: 1637712322\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8066682\n",
      "  training_iteration: 867\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   867</td><td style=\"text-align: right;\">          450991</td><td style=\"text-align: right;\">8066682</td><td style=\"text-align: right;\"> 4.64668</td><td style=\"text-align: right;\">               13.58</td><td style=\"text-align: right;\">               -0.69</td><td style=\"text-align: right;\">           52.0363</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8076678\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_00-14-18\n",
      "  done: false\n",
      "  episode_len_mean: 52.44210526315789\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.620000000000006\n",
      "  episode_reward_mean: 4.6238421052631615\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 155651\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.110077194372813\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014610789922296275\n",
      "          policy_loss: -0.0713559794605923\n",
      "          total_loss: 0.08194238527683768\n",
      "          vf_explained_var: 0.9306873083114624\n",
      "          vf_loss: 0.14111392972186718\n",
      "    num_agent_steps_sampled: 8076678\n",
      "    num_agent_steps_trained: 8076678\n",
      "    num_steps_sampled: 8076678\n",
      "    num_steps_trained: 8076678\n",
      "  iterations_since_restore: 468\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98616187989555\n",
      "    ram_util_percent: 53.465665796344645\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052814948201697694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.5339980121439\n",
      "    mean_inference_ms: 19.504011072613565\n",
      "    mean_raw_obs_processing_ms: 3.3181703933775095\n",
      "  time_since_restore: 256710.6066160202\n",
      "  time_this_iter_s: 536.5433833599091\n",
      "  time_total_s: 451527.9702014923\n",
      "  timers:\n",
      "    learn_throughput: 28.257\n",
      "    learn_time_ms: 353756.514\n",
      "    load_throughput: 89034.493\n",
      "    load_time_ms: 112.271\n",
      "    sample_throughput: 52.743\n",
      "    sample_time_ms: 189522.803\n",
      "    update_time_ms: 5.017\n",
      "  timestamp: 1637712858\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8076678\n",
      "  training_iteration: 868\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   868</td><td style=\"text-align: right;\">          451528</td><td style=\"text-align: right;\">8076678</td><td style=\"text-align: right;\"> 4.62384</td><td style=\"text-align: right;\">               13.62</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           52.4421</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8086674\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_00-23-18\n",
      "  done: false\n",
      "  episode_len_mean: 52.536842105263155\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.659999999999984\n",
      "  episode_reward_mean: 4.733000000000004\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 155841\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.104055559706975\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015246669808301617\n",
      "          policy_loss: -0.07060308644496513\n",
      "          total_loss: 0.07749440086975456\n",
      "          vf_explained_var: 0.9249469637870789\n",
      "          vf_loss: 0.13440422215162362\n",
      "    num_agent_steps_sampled: 8086674\n",
      "    num_agent_steps_trained: 8086674\n",
      "    num_steps_sampled: 8086674\n",
      "    num_steps_trained: 8086674\n",
      "  iterations_since_restore: 469\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.09401820546162\n",
      "    ram_util_percent: 53.2370611183355\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281867987533815\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.536027077715314\n",
      "    mean_inference_ms: 19.504312783713832\n",
      "    mean_raw_obs_processing_ms: 3.314176667829419\n",
      "  time_since_restore: 257249.88680505753\n",
      "  time_this_iter_s: 539.280189037323\n",
      "  time_total_s: 452067.25039052963\n",
      "  timers:\n",
      "    learn_throughput: 28.259\n",
      "    learn_time_ms: 353732.445\n",
      "    load_throughput: 89492.351\n",
      "    load_time_ms: 111.697\n",
      "    sample_throughput: 52.547\n",
      "    sample_time_ms: 190228.514\n",
      "    update_time_ms: 4.83\n",
      "  timestamp: 1637713398\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8086674\n",
      "  training_iteration: 869\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   869</td><td style=\"text-align: right;\">          452067</td><td style=\"text-align: right;\">8086674</td><td style=\"text-align: right;\">   4.733</td><td style=\"text-align: right;\">               13.66</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           52.5368</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8096670\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_00-32-29\n",
      "  done: false\n",
      "  episode_len_mean: 51.90155440414508\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000005\n",
      "  episode_reward_mean: 4.7486010362694335\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 156034\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0999433750847736\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014941883229253687\n",
      "          policy_loss: -0.07026846298765622\n",
      "          total_loss: 0.0828026222073156\n",
      "          vf_explained_var: 0.918011486530304\n",
      "          vf_loss: 0.14003104066605265\n",
      "    num_agent_steps_sampled: 8096670\n",
      "    num_agent_steps_trained: 8096670\n",
      "    num_steps_sampled: 8096670\n",
      "    num_steps_trained: 8096670\n",
      "  iterations_since_restore: 470\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.80203562340967\n",
      "    ram_util_percent: 53.359033078880415\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528049635323501\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53715468276536\n",
      "    mean_inference_ms: 19.503392980012823\n",
      "    mean_raw_obs_processing_ms: 3.3162838980262355\n",
      "  time_since_restore: 257800.6630177498\n",
      "  time_this_iter_s: 550.7762126922607\n",
      "  time_total_s: 452618.0266032219\n",
      "  timers:\n",
      "    learn_throughput: 28.263\n",
      "    learn_time_ms: 353673.643\n",
      "    load_throughput: 89383.029\n",
      "    load_time_ms: 111.833\n",
      "    sample_throughput: 52.41\n",
      "    sample_time_ms: 190726.913\n",
      "    update_time_ms: 4.887\n",
      "  timestamp: 1637713949\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8096670\n",
      "  training_iteration: 870\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   870</td><td style=\"text-align: right;\">          452618</td><td style=\"text-align: right;\">8096670</td><td style=\"text-align: right;\">  4.7486</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           51.9016</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8106666\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_00-42-01\n",
      "  done: false\n",
      "  episode_len_mean: 51.69430051813472\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000005\n",
      "  episode_reward_mean: 5.131761658031092\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 156227\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.058373952294928\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015590056911581234\n",
      "          policy_loss: -0.07024596091584853\n",
      "          total_loss: 0.0937953278395122\n",
      "          vf_explained_var: 0.9373788237571716\n",
      "          vf_loss: 0.1491089279353843\n",
      "    num_agent_steps_sampled: 8106666\n",
      "    num_agent_steps_trained: 8106666\n",
      "    num_steps_sampled: 8106666\n",
      "    num_steps_trained: 8106666\n",
      "  iterations_since_restore: 471\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.37356181150552\n",
      "    ram_util_percent: 53.32399020807834\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280970481805909\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.53711957304219\n",
      "    mean_inference_ms: 19.50543586632208\n",
      "    mean_raw_obs_processing_ms: 3.322927685877866\n",
      "  time_since_restore: 258373.17024874687\n",
      "  time_this_iter_s: 572.5072309970856\n",
      "  time_total_s: 453190.533834219\n",
      "  timers:\n",
      "    learn_throughput: 28.268\n",
      "    learn_time_ms: 353614.934\n",
      "    load_throughput: 89705.006\n",
      "    load_time_ms: 111.432\n",
      "    sample_throughput: 51.846\n",
      "    sample_time_ms: 192803.483\n",
      "    update_time_ms: 4.858\n",
      "  timestamp: 1637714521\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8106666\n",
      "  training_iteration: 871\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   871</td><td style=\"text-align: right;\">          453191</td><td style=\"text-align: right;\">8106666</td><td style=\"text-align: right;\"> 5.13176</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           51.6943</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8116662\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_00-50-57\n",
      "  done: false\n",
      "  episode_len_mean: 52.07253886010363\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.340414507772024\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 156420\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.056190295583273\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015292105019618696\n",
      "          policy_loss: -0.06938772154107024\n",
      "          total_loss: 0.09429819886230557\n",
      "          vf_explained_var: 0.9252455830574036\n",
      "          vf_loss: 0.14941049600506284\n",
      "    num_agent_steps_sampled: 8116662\n",
      "    num_agent_steps_trained: 8116662\n",
      "    num_steps_sampled: 8116662\n",
      "    num_steps_trained: 8116662\n",
      "  iterations_since_restore: 472\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.92941176470588\n",
      "    ram_util_percent: 52.97725490196079\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280465742448338\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.539098236075972\n",
      "    mean_inference_ms: 19.504677609806798\n",
      "    mean_raw_obs_processing_ms: 3.3180271634652767\n",
      "  time_since_restore: 258909.28586506844\n",
      "  time_this_iter_s: 536.1156163215637\n",
      "  time_total_s: 453726.64945054054\n",
      "  timers:\n",
      "    learn_throughput: 28.275\n",
      "    learn_time_ms: 353522.252\n",
      "    load_throughput: 89539.827\n",
      "    load_time_ms: 111.637\n",
      "    sample_throughput: 51.665\n",
      "    sample_time_ms: 193475.889\n",
      "    update_time_ms: 4.851\n",
      "  timestamp: 1637715057\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8116662\n",
      "  training_iteration: 872\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   872</td><td style=\"text-align: right;\">          453727</td><td style=\"text-align: right;\">8116662</td><td style=\"text-align: right;\"> 5.34041</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           52.0725</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8126658\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_00-59-52\n",
      "  done: false\n",
      "  episode_len_mean: 52.95238095238095\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.530000000000008\n",
      "  episode_reward_mean: 5.02560846560847\n",
      "  episode_reward_min: -0.6400000000000003\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 156609\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.07340078993016\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014811360471784307\n",
      "          policy_loss: -0.0648528658675056\n",
      "          total_loss: 0.08913839186519804\n",
      "          vf_explained_var: 0.9456443190574646\n",
      "          vf_loss: 0.14098313310974647\n",
      "    num_agent_steps_sampled: 8126658\n",
      "    num_agent_steps_trained: 8126658\n",
      "    num_steps_sampled: 8126658\n",
      "    num_steps_trained: 8126658\n",
      "  iterations_since_restore: 473\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.95465268676278\n",
      "    ram_util_percent: 52.89882044560944\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281428543304427\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.540282835748343\n",
      "    mean_inference_ms: 19.50399164805605\n",
      "    mean_raw_obs_processing_ms: 3.3138000738991655\n",
      "  time_since_restore: 259444.29977560043\n",
      "  time_this_iter_s: 535.0139105319977\n",
      "  time_total_s: 454261.66336107254\n",
      "  timers:\n",
      "    learn_throughput: 28.279\n",
      "    learn_time_ms: 353480.73\n",
      "    load_throughput: 89371.045\n",
      "    load_time_ms: 111.848\n",
      "    sample_throughput: 51.983\n",
      "    sample_time_ms: 192292.268\n",
      "    update_time_ms: 4.605\n",
      "  timestamp: 1637715592\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8126658\n",
      "  training_iteration: 873\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   873</td><td style=\"text-align: right;\">          454262</td><td style=\"text-align: right;\">8126658</td><td style=\"text-align: right;\"> 5.02561</td><td style=\"text-align: right;\">               15.53</td><td style=\"text-align: right;\">               -0.64</td><td style=\"text-align: right;\">           52.9524</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8136654\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_01-09-14\n",
      "  done: false\n",
      "  episode_len_mean: 52.41269841269841\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.54\n",
      "  episode_reward_mean: 4.917989417989421\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 156798\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.077288466620158\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015353053642615619\n",
      "          policy_loss: -0.06586254674660608\n",
      "          total_loss: 0.1026497471994205\n",
      "          vf_explained_var: 0.9392040967941284\n",
      "          vf_loss: 0.15430900138170725\n",
      "    num_agent_steps_sampled: 8136654\n",
      "    num_agent_steps_trained: 8136654\n",
      "    num_steps_sampled: 8136654\n",
      "    num_steps_trained: 8136654\n",
      "  iterations_since_restore: 474\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.41772784019975\n",
      "    ram_util_percent: 53.25555555555557\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528055598080179\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.540785817962362\n",
      "    mean_inference_ms: 19.502641030968203\n",
      "    mean_raw_obs_processing_ms: 3.3190932257811068\n",
      "  time_since_restore: 260005.85436534882\n",
      "  time_this_iter_s: 561.5545897483826\n",
      "  time_total_s: 454823.2179508209\n",
      "  timers:\n",
      "    learn_throughput: 28.282\n",
      "    learn_time_ms: 353445.201\n",
      "    load_throughput: 89331.323\n",
      "    load_time_ms: 111.898\n",
      "    sample_throughput: 51.561\n",
      "    sample_time_ms: 193867.99\n",
      "    update_time_ms: 5.176\n",
      "  timestamp: 1637716154\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8136654\n",
      "  training_iteration: 874\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   874</td><td style=\"text-align: right;\">          454823</td><td style=\"text-align: right;\">8136654</td><td style=\"text-align: right;\"> 4.91799</td><td style=\"text-align: right;\">               17.54</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           52.4127</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8146650\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_01-18-24\n",
      "  done: false\n",
      "  episode_len_mean: 52.177083333333336\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.609999999999985\n",
      "  episode_reward_mean: 5.158750000000004\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 156990\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0595716181050343\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01488729168437169\n",
      "          policy_loss: -0.07127973794344669\n",
      "          total_loss: 0.07312328774337604\n",
      "          vf_explained_var: 0.9458100199699402\n",
      "          vf_loss: 0.13108363038173926\n",
      "    num_agent_steps_sampled: 8146650\n",
      "    num_agent_steps_trained: 8146650\n",
      "    num_steps_sampled: 8146650\n",
      "    num_steps_trained: 8146650\n",
      "  iterations_since_restore: 475\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91261146496815\n",
      "    ram_util_percent: 53.18254777070063\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281264034895067\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.543457561330502\n",
      "    mean_inference_ms: 19.505216241982506\n",
      "    mean_raw_obs_processing_ms: 3.3196349034357078\n",
      "  time_since_restore: 260555.78798604012\n",
      "  time_this_iter_s: 549.9336206912994\n",
      "  time_total_s: 455373.1515715122\n",
      "  timers:\n",
      "    learn_throughput: 28.286\n",
      "    learn_time_ms: 353389.246\n",
      "    load_throughput: 89161.998\n",
      "    load_time_ms: 112.111\n",
      "    sample_throughput: 51.184\n",
      "    sample_time_ms: 195294.104\n",
      "    update_time_ms: 5.431\n",
      "  timestamp: 1637716704\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8146650\n",
      "  training_iteration: 875\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   875</td><td style=\"text-align: right;\">          455373</td><td style=\"text-align: right;\">8146650</td><td style=\"text-align: right;\"> 5.15875</td><td style=\"text-align: right;\">               17.61</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           52.1771</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8156646\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_01-27-21\n",
      "  done: false\n",
      "  episode_len_mean: 52.338541666666664\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.640000000000006\n",
      "  episode_reward_mean: 5.063281250000004\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 157182\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.082980143305767\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015299652552852289\n",
      "          policy_loss: -0.06384311126890227\n",
      "          total_loss: 0.09509963758904794\n",
      "          vf_explained_var: 0.94387286901474\n",
      "          vf_loss: 0.14491802841166865\n",
      "    num_agent_steps_sampled: 8156646\n",
      "    num_agent_steps_trained: 8156646\n",
      "    num_steps_sampled: 8156646\n",
      "    num_steps_trained: 8156646\n",
      "  iterations_since_restore: 476\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00770234986945\n",
      "    ram_util_percent: 53.00992167101828\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279746052742992\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.544736475048154\n",
      "    mean_inference_ms: 19.501520260929748\n",
      "    mean_raw_obs_processing_ms: 3.313807666862523\n",
      "  time_since_restore: 261092.83019971848\n",
      "  time_this_iter_s: 537.04221367836\n",
      "  time_total_s: 455910.1937851906\n",
      "  timers:\n",
      "    learn_throughput: 28.289\n",
      "    learn_time_ms: 353349.172\n",
      "    load_throughput: 90197.078\n",
      "    load_time_ms: 110.824\n",
      "    sample_throughput: 51.095\n",
      "    sample_time_ms: 195635.673\n",
      "    update_time_ms: 5.569\n",
      "  timestamp: 1637717241\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8156646\n",
      "  training_iteration: 876\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   876</td><td style=\"text-align: right;\">          455910</td><td style=\"text-align: right;\">8156646</td><td style=\"text-align: right;\"> 5.06328</td><td style=\"text-align: right;\">               13.64</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           52.3385</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8166642\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_01-36-17\n",
      "  done: false\n",
      "  episode_len_mean: 53.13903743315508\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.730000000000004\n",
      "  episode_reward_mean: 5.210000000000004\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 157369\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.067967958263604\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014178569989368433\n",
      "          policy_loss: -0.0706228646010236\n",
      "          total_loss: 0.07188304200384368\n",
      "          vf_explained_var: 0.9493025541305542\n",
      "          vf_loss: 0.13088502993883872\n",
      "    num_agent_steps_sampled: 8166642\n",
      "    num_agent_steps_trained: 8166642\n",
      "    num_steps_sampled: 8166642\n",
      "    num_steps_trained: 8166642\n",
      "  iterations_since_restore: 477\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.18429319371728\n",
      "    ram_util_percent: 52.724738219895286\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280263954306605\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.547804631278844\n",
      "    mean_inference_ms: 19.504721588030208\n",
      "    mean_raw_obs_processing_ms: 3.3101834041386637\n",
      "  time_since_restore: 261628.49420070648\n",
      "  time_this_iter_s: 535.6640009880066\n",
      "  time_total_s: 456445.8577861786\n",
      "  timers:\n",
      "    learn_throughput: 28.284\n",
      "    learn_time_ms: 353413.174\n",
      "    load_throughput: 89968.339\n",
      "    load_time_ms: 111.106\n",
      "    sample_throughput: 52.09\n",
      "    sample_time_ms: 191900.246\n",
      "    update_time_ms: 5.976\n",
      "  timestamp: 1637717777\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8166642\n",
      "  training_iteration: 877\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   877</td><td style=\"text-align: right;\">          456446</td><td style=\"text-align: right;\">8166642</td><td style=\"text-align: right;\">    5.21</td><td style=\"text-align: right;\">               15.73</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">            53.139</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8176638\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_01-45-42\n",
      "  done: false\n",
      "  episode_len_mean: 51.7319587628866\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.570000000000007\n",
      "  episode_reward_mean: 5.537422680412375\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 157563\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0548158567832657\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014848624659190374\n",
      "          policy_loss: -0.07090003009362557\n",
      "          total_loss: 0.08136274166073604\n",
      "          vf_explained_var: 0.9421766400337219\n",
      "          vf_loss: 0.13898390522619417\n",
      "    num_agent_steps_sampled: 8176638\n",
      "    num_agent_steps_trained: 8176638\n",
      "    num_steps_sampled: 8176638\n",
      "    num_steps_trained: 8176638\n",
      "  iterations_since_restore: 478\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.5530359355638\n",
      "    ram_util_percent: 53.608674101610895\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280019773408581\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.548444146530716\n",
      "    mean_inference_ms: 19.503713061803904\n",
      "    mean_raw_obs_processing_ms: 3.316905085839093\n",
      "  time_since_restore: 262193.8142454624\n",
      "  time_this_iter_s: 565.3200447559357\n",
      "  time_total_s: 457011.1778309345\n",
      "  timers:\n",
      "    learn_throughput: 28.286\n",
      "    learn_time_ms: 353389.497\n",
      "    load_throughput: 89912.676\n",
      "    load_time_ms: 111.175\n",
      "    sample_throughput: 51.314\n",
      "    sample_time_ms: 194801.393\n",
      "    update_time_ms: 5.957\n",
      "  timestamp: 1637718342\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8176638\n",
      "  training_iteration: 878\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   878</td><td style=\"text-align: right;\">          457011</td><td style=\"text-align: right;\">8176638</td><td style=\"text-align: right;\"> 5.53742</td><td style=\"text-align: right;\">               13.57</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">            51.732</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8186634\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_01-54-50\n",
      "  done: false\n",
      "  episode_len_mean: 52.77777777777778\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 4.977830687830692\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 157752\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0673165104475366\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014396326569508754\n",
      "          policy_loss: -0.06996152503091008\n",
      "          total_loss: 0.06736844443647026\n",
      "          vf_explained_var: 0.9580347537994385\n",
      "          vf_loss: 0.12520650213604875\n",
      "    num_agent_steps_sampled: 8186634\n",
      "    num_agent_steps_trained: 8186634\n",
      "    num_steps_sampled: 8186634\n",
      "    num_steps_trained: 8186634\n",
      "  iterations_since_restore: 479\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.78629961587708\n",
      "    ram_util_percent: 53.777208706786155\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280730697007871\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.549377933836055\n",
      "    mean_inference_ms: 19.507602052984293\n",
      "    mean_raw_obs_processing_ms: 3.3173530215308724\n",
      "  time_since_restore: 262741.5088956356\n",
      "  time_this_iter_s: 547.6946501731873\n",
      "  time_total_s: 457558.8724811077\n",
      "  timers:\n",
      "    learn_throughput: 28.289\n",
      "    learn_time_ms: 353358.147\n",
      "    load_throughput: 89398.505\n",
      "    load_time_ms: 111.814\n",
      "    sample_throughput: 51.085\n",
      "    sample_time_ms: 195673.288\n",
      "    update_time_ms: 6.103\n",
      "  timestamp: 1637718890\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8186634\n",
      "  training_iteration: 879\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   879</td><td style=\"text-align: right;\">          457559</td><td style=\"text-align: right;\">8186634</td><td style=\"text-align: right;\"> 4.97783</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           52.7778</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8196630\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_02-03-44\n",
      "  done: false\n",
      "  episode_len_mean: 52.73684210526316\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 5.204789473684214\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 157942\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0494489452685696\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014923578032135926\n",
      "          policy_loss: -0.06758226086260337\n",
      "          total_loss: 0.09101866927780701\n",
      "          vf_explained_var: 0.9330177307128906\n",
      "          vf_loss: 0.14509764215310506\n",
      "    num_agent_steps_sampled: 8196630\n",
      "    num_agent_steps_trained: 8196630\n",
      "    num_steps_sampled: 8196630\n",
      "    num_steps_trained: 8196630\n",
      "  iterations_since_restore: 480\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00904325032765\n",
      "    ram_util_percent: 53.466710353866326\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280525761609517\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.550389518746726\n",
      "    mean_inference_ms: 19.506049490589287\n",
      "    mean_raw_obs_processing_ms: 3.3128679769228735\n",
      "  time_since_restore: 263275.62164640427\n",
      "  time_this_iter_s: 534.1127507686615\n",
      "  time_total_s: 458092.9852318764\n",
      "  timers:\n",
      "    learn_throughput: 28.291\n",
      "    learn_time_ms: 353324.622\n",
      "    load_throughput: 89549.599\n",
      "    load_time_ms: 111.625\n",
      "    sample_throughput: 51.515\n",
      "    sample_time_ms: 194040.422\n",
      "    update_time_ms: 6.198\n",
      "  timestamp: 1637719424\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8196630\n",
      "  training_iteration: 880\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   880</td><td style=\"text-align: right;\">          458093</td><td style=\"text-align: right;\">8196630</td><td style=\"text-align: right;\"> 5.20479</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           52.7368</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8206626\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_02-12-50\n",
      "  done: false\n",
      "  episode_len_mean: 52.114583333333336\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 5.368125000000004\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 158134\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0594227497836193\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01446893482894981\n",
      "          policy_loss: -0.07386841964860826\n",
      "          total_loss: 0.08342088800509573\n",
      "          vf_explained_var: 0.9436693787574768\n",
      "          vf_loss: 0.14492149220267123\n",
      "    num_agent_steps_sampled: 8206626\n",
      "    num_agent_steps_trained: 8206626\n",
      "    num_steps_sampled: 8206626\n",
      "    num_steps_trained: 8206626\n",
      "  iterations_since_restore: 481\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8535301668806\n",
      "    ram_util_percent: 53.146341463414636\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280530110386537\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.551557933915962\n",
      "    mean_inference_ms: 19.50586839222056\n",
      "    mean_raw_obs_processing_ms: 3.3115718234608504\n",
      "  time_since_restore: 263822.05604958534\n",
      "  time_this_iter_s: 546.434403181076\n",
      "  time_total_s: 458639.41963505745\n",
      "  timers:\n",
      "    learn_throughput: 28.29\n",
      "    learn_time_ms: 353344.733\n",
      "    load_throughput: 88630.901\n",
      "    load_time_ms: 112.782\n",
      "    sample_throughput: 52.223\n",
      "    sample_time_ms: 191411.475\n",
      "    update_time_ms: 6.254\n",
      "  timestamp: 1637719970\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8206626\n",
      "  training_iteration: 881\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   881</td><td style=\"text-align: right;\">          458639</td><td style=\"text-align: right;\">8206626</td><td style=\"text-align: right;\"> 5.36813</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           52.1146</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8216622\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_02-22-27\n",
      "  done: false\n",
      "  episode_len_mean: 51.4559585492228\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.569999999999993\n",
      "  episode_reward_mean: 4.897668393782387\n",
      "  episode_reward_min: -0.6000000000000003\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 158327\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0636833903301195\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014907284897086355\n",
      "          policy_loss: -0.06802651559972941\n",
      "          total_loss: 0.09044989003305967\n",
      "          vf_explained_var: 0.9496654868125916\n",
      "          vf_loss: 0.14515257959841305\n",
      "    num_agent_steps_sampled: 8216622\n",
      "    num_agent_steps_trained: 8216622\n",
      "    num_steps_sampled: 8216622\n",
      "    num_steps_trained: 8216622\n",
      "  iterations_since_restore: 482\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.15783718104497\n",
      "    ram_util_percent: 54.07958687727825\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05281094317048448\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.551275349592416\n",
      "    mean_inference_ms: 19.506102951343916\n",
      "    mean_raw_obs_processing_ms: 3.318566100641015\n",
      "  time_since_restore: 264398.5982861519\n",
      "  time_this_iter_s: 576.5422365665436\n",
      "  time_total_s: 459215.961871624\n",
      "  timers:\n",
      "    learn_throughput: 28.287\n",
      "    learn_time_ms: 353377.389\n",
      "    load_throughput: 85467.555\n",
      "    load_time_ms: 116.957\n",
      "    sample_throughput: 51.152\n",
      "    sample_time_ms: 195417.163\n",
      "    update_time_ms: 6.223\n",
      "  timestamp: 1637720547\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8216622\n",
      "  training_iteration: 882\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   882</td><td style=\"text-align: right;\">          459216</td><td style=\"text-align: right;\">8216622</td><td style=\"text-align: right;\"> 4.89767</td><td style=\"text-align: right;\">               17.57</td><td style=\"text-align: right;\">                -0.6</td><td style=\"text-align: right;\">            51.456</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8226618\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_02-31-23\n",
      "  done: false\n",
      "  episode_len_mean: 51.93782383419689\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 5.526943005181351\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 158520\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0449714347540615\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015179785129510176\n",
      "          policy_loss: -0.0626048849705545\n",
      "          total_loss: 0.10902765638344245\n",
      "          vf_explained_var: 0.9456390142440796\n",
      "          vf_loss: 0.15750080678344566\n",
      "    num_agent_steps_sampled: 8226618\n",
      "    num_agent_steps_trained: 8226618\n",
      "    num_steps_sampled: 8226618\n",
      "    num_steps_trained: 8226618\n",
      "  iterations_since_restore: 483\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.99358638743456\n",
      "    ram_util_percent: 53.15981675392671\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280499626364941\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.55342625219814\n",
      "    mean_inference_ms: 19.505488863828226\n",
      "    mean_raw_obs_processing_ms: 3.3137199947447\n",
      "  time_since_restore: 264934.2962744236\n",
      "  time_this_iter_s: 535.6979882717133\n",
      "  time_total_s: 459751.6598598957\n",
      "  timers:\n",
      "    learn_throughput: 28.286\n",
      "    learn_time_ms: 353385.872\n",
      "    load_throughput: 85342.191\n",
      "    load_time_ms: 117.128\n",
      "    sample_throughput: 51.136\n",
      "    sample_time_ms: 195476.869\n",
      "    update_time_ms: 6.387\n",
      "  timestamp: 1637721083\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8226618\n",
      "  training_iteration: 883\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   883</td><td style=\"text-align: right;\">          459752</td><td style=\"text-align: right;\">8226618</td><td style=\"text-align: right;\"> 5.52694</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           51.9378</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8236614\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_02-40-17\n",
      "  done: false\n",
      "  episode_len_mean: 52.32984293193717\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 4.789005235602098\n",
      "  episode_reward_min: -0.6900000000000004\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 158711\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0928245465439486\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014472150916716808\n",
      "          policy_loss: -0.06856849280345441\n",
      "          total_loss: 0.08978438604235671\n",
      "          vf_explained_var: 0.9361172318458557\n",
      "          vf_loss: 0.14631175499121438\n",
      "    num_agent_steps_sampled: 8236614\n",
      "    num_agent_steps_trained: 8236614\n",
      "    num_steps_sampled: 8236614\n",
      "    num_steps_trained: 8236614\n",
      "  iterations_since_restore: 484\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.06220472440944\n",
      "    ram_util_percent: 53.096456692913385\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052796733231111205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.554781730759956\n",
      "    mean_inference_ms: 19.50444977619984\n",
      "    mean_raw_obs_processing_ms: 3.3089239485394972\n",
      "  time_since_restore: 265468.55657458305\n",
      "  time_this_iter_s: 534.2603001594543\n",
      "  time_total_s: 460285.92016005516\n",
      "  timers:\n",
      "    learn_throughput: 28.284\n",
      "    learn_time_ms: 353416.576\n",
      "    load_throughput: 85557.673\n",
      "    load_time_ms: 116.833\n",
      "    sample_throughput: 51.869\n",
      "    sample_time_ms: 192717.391\n",
      "    update_time_ms: 6.111\n",
      "  timestamp: 1637721617\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8236614\n",
      "  training_iteration: 884\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   884</td><td style=\"text-align: right;\">          460286</td><td style=\"text-align: right;\">8236614</td><td style=\"text-align: right;\"> 4.78901</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.69</td><td style=\"text-align: right;\">           52.3298</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8246610\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_02-49-28\n",
      "  done: false\n",
      "  episode_len_mean: 51.74611398963731\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.540000000000003\n",
      "  episode_reward_mean: 5.070207253886015\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 158904\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0785341149831873\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014856525899860279\n",
      "          policy_loss: -0.06760249169578436\n",
      "          total_loss: 0.08816621030995134\n",
      "          vf_explained_var: 0.9438572525978088\n",
      "          vf_loss: 0.14270901943240913\n",
      "    num_agent_steps_sampled: 8246610\n",
      "    num_agent_steps_trained: 8246610\n",
      "    num_steps_sampled: 8246610\n",
      "    num_steps_trained: 8246610\n",
      "  iterations_since_restore: 485\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7559085133418\n",
      "    ram_util_percent: 53.134053367217284\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052803512876834845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.556602842193932\n",
      "    mean_inference_ms: 19.506419021215287\n",
      "    mean_raw_obs_processing_ms: 3.312600525076949\n",
      "  time_since_restore: 266019.82614398\n",
      "  time_this_iter_s: 551.2695693969727\n",
      "  time_total_s: 460837.18972945213\n",
      "  timers:\n",
      "    learn_throughput: 28.282\n",
      "    learn_time_ms: 353436.15\n",
      "    load_throughput: 85849.347\n",
      "    load_time_ms: 116.437\n",
      "    sample_throughput: 51.838\n",
      "    sample_time_ms: 192832.288\n",
      "    update_time_ms: 5.806\n",
      "  timestamp: 1637722168\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8246610\n",
      "  training_iteration: 885\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   885</td><td style=\"text-align: right;\">          460837</td><td style=\"text-align: right;\">8246610</td><td style=\"text-align: right;\"> 5.07021</td><td style=\"text-align: right;\">               17.54</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           51.7461</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8256606\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_02-58-40\n",
      "  done: false\n",
      "  episode_len_mean: 52.02590673575129\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.739999999999995\n",
      "  episode_reward_mean: 5.150673575129538\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 159097\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0675869919928203\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014922285580118487\n",
      "          policy_loss: -0.06758769234770606\n",
      "          total_loss: 0.07505572498257351\n",
      "          vf_explained_var: 0.9333564639091492\n",
      "          vf_loss: 0.12932445473555684\n",
      "    num_agent_steps_sampled: 8256606\n",
      "    num_agent_steps_trained: 8256606\n",
      "    num_steps_sampled: 8256606\n",
      "    num_steps_trained: 8256606\n",
      "  iterations_since_restore: 486\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.46035578144853\n",
      "    ram_util_percent: 53.28703939008895\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0528098436894063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.558209083538106\n",
      "    mean_inference_ms: 19.50790191721827\n",
      "    mean_raw_obs_processing_ms: 3.3128670297376126\n",
      "  time_since_restore: 266571.1801016331\n",
      "  time_this_iter_s: 551.3539576530457\n",
      "  time_total_s: 461388.5436871052\n",
      "  timers:\n",
      "    learn_throughput: 28.282\n",
      "    learn_time_ms: 353438.706\n",
      "    load_throughput: 85047.822\n",
      "    load_time_ms: 117.534\n",
      "    sample_throughput: 51.457\n",
      "    sample_time_ms: 194259.795\n",
      "    update_time_ms: 6.065\n",
      "  timestamp: 1637722720\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8256606\n",
      "  training_iteration: 886\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   886</td><td style=\"text-align: right;\">          461389</td><td style=\"text-align: right;\">8256606</td><td style=\"text-align: right;\"> 5.15067</td><td style=\"text-align: right;\">               17.74</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           52.0259</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8266602\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_03-07-48\n",
      "  done: false\n",
      "  episode_len_mean: 52.3717277486911\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.700000000000005\n",
      "  episode_reward_mean: 4.733350785340318\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 159288\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0870563813002714\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014752296984807471\n",
      "          policy_loss: -0.06839750735818532\n",
      "          total_loss: 0.09347088050970298\n",
      "          vf_explained_var: 0.9312955737113953\n",
      "          vf_loss: 0.14913137390541967\n",
      "    num_agent_steps_sampled: 8266602\n",
      "    num_agent_steps_trained: 8266602\n",
      "    num_steps_sampled: 8266602\n",
      "    num_steps_trained: 8266602\n",
      "  iterations_since_restore: 487\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77378516624042\n",
      "    ram_util_percent: 53.38286445012789\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052804059534088205\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.559257942293783\n",
      "    mean_inference_ms: 19.508239564932918\n",
      "    mean_raw_obs_processing_ms: 3.311552648927016\n",
      "  time_since_restore: 267119.92490291595\n",
      "  time_this_iter_s: 548.7448012828827\n",
      "  time_total_s: 461937.28848838806\n",
      "  timers:\n",
      "    learn_throughput: 28.288\n",
      "    learn_time_ms: 353369.818\n",
      "    load_throughput: 85028.09\n",
      "    load_time_ms: 117.561\n",
      "    sample_throughput: 51.095\n",
      "    sample_time_ms: 195637.085\n",
      "    update_time_ms: 6.065\n",
      "  timestamp: 1637723268\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8266602\n",
      "  training_iteration: 887\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   887</td><td style=\"text-align: right;\">          461937</td><td style=\"text-align: right;\">8266602</td><td style=\"text-align: right;\"> 4.73335</td><td style=\"text-align: right;\">                13.7</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           52.3717</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8276598\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_03-17-19\n",
      "  done: false\n",
      "  episode_len_mean: 52.2565445026178\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.550000000000008\n",
      "  episode_reward_mean: 5.239947643979062\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 159479\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.065974163482467\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01603905904502645\n",
      "          policy_loss: -0.06266374959468449\n",
      "          total_loss: 0.11489586545528828\n",
      "          vf_explained_var: 0.9252812266349792\n",
      "          vf_loss: 0.16168037381296207\n",
      "    num_agent_steps_sampled: 8276598\n",
      "    num_agent_steps_trained: 8276598\n",
      "    num_steps_sampled: 8276598\n",
      "    num_steps_trained: 8276598\n",
      "  iterations_since_restore: 488\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.82776412776413\n",
      "    ram_util_percent: 53.65687960687961\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052804512810605754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.558663167229597\n",
      "    mean_inference_ms: 19.507634229588987\n",
      "    mean_raw_obs_processing_ms: 3.3200531548165166\n",
      "  time_since_restore: 267690.3873517513\n",
      "  time_this_iter_s: 570.4624488353729\n",
      "  time_total_s: 462507.75093722343\n",
      "  timers:\n",
      "    learn_throughput: 28.292\n",
      "    learn_time_ms: 353312.912\n",
      "    load_throughput: 85027.624\n",
      "    load_time_ms: 117.562\n",
      "    sample_throughput: 50.946\n",
      "    sample_time_ms: 196207.795\n",
      "    update_time_ms: 6.561\n",
      "  timestamp: 1637723839\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8276598\n",
      "  training_iteration: 888\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   888</td><td style=\"text-align: right;\">          462508</td><td style=\"text-align: right;\">8276598</td><td style=\"text-align: right;\"> 5.23995</td><td style=\"text-align: right;\">               15.55</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           52.2565</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8286594\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_03-26-30\n",
      "  done: false\n",
      "  episode_len_mean: 52.82539682539682\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.589999999999993\n",
      "  episode_reward_mean: 5.483968253968258\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 159668\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0628036843964375\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01544146833071749\n",
      "          policy_loss: -0.06761807422112742\n",
      "          total_loss: 0.10668759297118395\n",
      "          vf_explained_var: 0.9400898218154907\n",
      "          vf_loss: 0.15975610781348792\n",
      "    num_agent_steps_sampled: 8286594\n",
      "    num_agent_steps_trained: 8286594\n",
      "    num_steps_sampled: 8286594\n",
      "    num_steps_trained: 8286594\n",
      "  iterations_since_restore: 489\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.56531130876746\n",
      "    ram_util_percent: 53.54307496823381\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279766858055443\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.559915262494002\n",
      "    mean_inference_ms: 19.50621987464135\n",
      "    mean_raw_obs_processing_ms: 3.3187644865411525\n",
      "  time_since_restore: 268241.5858886242\n",
      "  time_this_iter_s: 551.1985368728638\n",
      "  time_total_s: 463058.9494740963\n",
      "  timers:\n",
      "    learn_throughput: 28.293\n",
      "    learn_time_ms: 353301.551\n",
      "    load_throughput: 85280.496\n",
      "    load_time_ms: 117.213\n",
      "    sample_throughput: 50.852\n",
      "    sample_time_ms: 196570.335\n",
      "    update_time_ms: 6.471\n",
      "  timestamp: 1637724390\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8286594\n",
      "  training_iteration: 889\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   889</td><td style=\"text-align: right;\">          463059</td><td style=\"text-align: right;\">8286594</td><td style=\"text-align: right;\"> 5.48397</td><td style=\"text-align: right;\">               17.59</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           52.8254</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8296590\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_03-35-24\n",
      "  done: false\n",
      "  episode_len_mean: 52.804232804232804\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000003\n",
      "  episode_reward_mean: 5.346296296296299\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 159857\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0757375076592686\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014586318108677115\n",
      "          policy_loss: -0.07574592879320342\n",
      "          total_loss: 0.07377663038614446\n",
      "          vf_explained_var: 0.9441472887992859\n",
      "          vf_loss: 0.13705047713284077\n",
      "    num_agent_steps_sampled: 8296590\n",
      "    num_agent_steps_trained: 8296590\n",
      "    num_steps_sampled: 8296590\n",
      "    num_steps_trained: 8296590\n",
      "  iterations_since_restore: 490\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.10157687253614\n",
      "    ram_util_percent: 52.81471747700393\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280121281242709\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.56237222750581\n",
      "    mean_inference_ms: 19.508724708591718\n",
      "    mean_raw_obs_processing_ms: 3.3146618094007505\n",
      "  time_since_restore: 268775.4264280796\n",
      "  time_this_iter_s: 533.8405394554138\n",
      "  time_total_s: 463592.7900135517\n",
      "  timers:\n",
      "    learn_throughput: 28.293\n",
      "    learn_time_ms: 353303.311\n",
      "    load_throughput: 85390.998\n",
      "    load_time_ms: 117.062\n",
      "    sample_throughput: 50.859\n",
      "    sample_time_ms: 196541.474\n",
      "    update_time_ms: 6.56\n",
      "  timestamp: 1637724924\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8296590\n",
      "  training_iteration: 890\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   890</td><td style=\"text-align: right;\">          463593</td><td style=\"text-align: right;\">8296590</td><td style=\"text-align: right;\">  5.3463</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           52.8042</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8306586\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_03-44-21\n",
      "  done: false\n",
      "  episode_len_mean: 52.208333333333336\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.579999999999988\n",
      "  episode_reward_mean: 5.034479166666671\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 160049\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.087058253819684\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014887528079246669\n",
      "          policy_loss: -0.06423102736932111\n",
      "          total_loss: 0.0941953894740102\n",
      "          vf_explained_var: 0.9376851916313171\n",
      "          vf_loss: 0.14538134809276726\n",
      "    num_agent_steps_sampled: 8306586\n",
      "    num_agent_steps_trained: 8306586\n",
      "    num_steps_sampled: 8306586\n",
      "    num_steps_trained: 8306586\n",
      "  iterations_since_restore: 491\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.12885117493472\n",
      "    ram_util_percent: 52.74543080939948\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279895234615976\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.56503703502479\n",
      "    mean_inference_ms: 19.50952927087077\n",
      "    mean_raw_obs_processing_ms: 3.31055891144009\n",
      "  time_since_restore: 269312.0662536621\n",
      "  time_this_iter_s: 536.6398255825043\n",
      "  time_total_s: 464129.4298391342\n",
      "  timers:\n",
      "    learn_throughput: 28.296\n",
      "    learn_time_ms: 353267.173\n",
      "    load_throughput: 86035.628\n",
      "    load_time_ms: 116.184\n",
      "    sample_throughput: 51.104\n",
      "    sample_time_ms: 195599.379\n",
      "    update_time_ms: 6.543\n",
      "  timestamp: 1637725461\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8306586\n",
      "  training_iteration: 891\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   891</td><td style=\"text-align: right;\">          464129</td><td style=\"text-align: right;\">8306586</td><td style=\"text-align: right;\"> 5.03448</td><td style=\"text-align: right;\">               17.58</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           52.2083</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8316582\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_03-53-33\n",
      "  done: false\n",
      "  episode_len_mean: 52.9468085106383\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000007\n",
      "  episode_reward_mean: 5.425372340425537\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 160237\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0294455937113627\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014626817926881116\n",
      "          policy_loss: -0.06294219025972801\n",
      "          total_loss: 0.09394402076138056\n",
      "          vf_explained_var: 0.9437656998634338\n",
      "          vf_loss: 0.1438589462200666\n",
      "    num_agent_steps_sampled: 8316582\n",
      "    num_agent_steps_trained: 8316582\n",
      "    num_steps_sampled: 8316582\n",
      "    num_steps_trained: 8316582\n",
      "  iterations_since_restore: 492\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.57652284263959\n",
      "    ram_util_percent: 53.13045685279188\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280546278399222\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.565729360645303\n",
      "    mean_inference_ms: 19.51179023150313\n",
      "    mean_raw_obs_processing_ms: 3.3143408588824697\n",
      "  time_since_restore: 269864.58036112785\n",
      "  time_this_iter_s: 552.514107465744\n",
      "  time_total_s: 464681.94394659996\n",
      "  timers:\n",
      "    learn_throughput: 28.293\n",
      "    learn_time_ms: 353304.594\n",
      "    load_throughput: 89406.836\n",
      "    load_time_ms: 111.804\n",
      "    sample_throughput: 51.749\n",
      "    sample_time_ms: 193163.142\n",
      "    update_time_ms: 6.939\n",
      "  timestamp: 1637726013\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8316582\n",
      "  training_iteration: 892\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   892</td><td style=\"text-align: right;\">          464682</td><td style=\"text-align: right;\">8316582</td><td style=\"text-align: right;\"> 5.42537</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           52.9468</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8326578\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_04-02-41\n",
      "  done: false\n",
      "  episode_len_mean: 51.44615384615385\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.690000000000005\n",
      "  episode_reward_mean: 4.870358974358978\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 195\n",
      "  episodes_total: 160432\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0460368870970713\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014241532336179566\n",
      "          policy_loss: -0.07202767797158399\n",
      "          total_loss: 0.07279407526954333\n",
      "          vf_explained_var: 0.9430627822875977\n",
      "          vf_loss: 0.13283812953795054\n",
      "    num_agent_steps_sampled: 8326578\n",
      "    num_agent_steps_trained: 8326578\n",
      "    num_steps_sampled: 8326578\n",
      "    num_steps_trained: 8326578\n",
      "  iterations_since_restore: 493\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.05255754475704\n",
      "    ram_util_percent: 53.63465473145779\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279323236851606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.56687067307625\n",
      "    mean_inference_ms: 19.508692867767436\n",
      "    mean_raw_obs_processing_ms: 3.312176527444921\n",
      "  time_since_restore: 270412.3263781071\n",
      "  time_this_iter_s: 547.7460169792175\n",
      "  time_total_s: 465229.6899635792\n",
      "  timers:\n",
      "    learn_throughput: 28.291\n",
      "    learn_time_ms: 353331.338\n",
      "    load_throughput: 89604.431\n",
      "    load_time_ms: 111.557\n",
      "    sample_throughput: 51.435\n",
      "    sample_time_ms: 194341.407\n",
      "    update_time_ms: 6.646\n",
      "  timestamp: 1637726561\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8326578\n",
      "  training_iteration: 893\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   893</td><td style=\"text-align: right;\">          465230</td><td style=\"text-align: right;\">8326578</td><td style=\"text-align: right;\"> 4.87036</td><td style=\"text-align: right;\">               15.69</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           51.4462</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8336574\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_04-11-37\n",
      "  done: false\n",
      "  episode_len_mean: 52.51578947368421\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.600000000000007\n",
      "  episode_reward_mean: 5.24447368421053\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 160622\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0521427211273147\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015139248608880796\n",
      "          policy_loss: -0.06387589858843502\n",
      "          total_loss: 0.11588800031484674\n",
      "          vf_explained_var: 0.9376835227012634\n",
      "          vf_loss: 0.1657962239089321\n",
      "    num_agent_steps_sampled: 8336574\n",
      "    num_agent_steps_trained: 8336574\n",
      "    num_steps_sampled: 8336574\n",
      "    num_steps_trained: 8336574\n",
      "  iterations_since_restore: 494\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01649214659686\n",
      "    ram_util_percent: 53.54541884816754\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052798301282166636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.569348494231107\n",
      "    mean_inference_ms: 19.51149404663593\n",
      "    mean_raw_obs_processing_ms: 3.309008925854852\n",
      "  time_since_restore: 270948.15748906136\n",
      "  time_this_iter_s: 535.8311109542847\n",
      "  time_total_s: 465765.52107453346\n",
      "  timers:\n",
      "    learn_throughput: 28.297\n",
      "    learn_time_ms: 353255.424\n",
      "    load_throughput: 89236.313\n",
      "    load_time_ms: 112.017\n",
      "    sample_throughput: 51.374\n",
      "    sample_time_ms: 194574.563\n",
      "    update_time_ms: 6.24\n",
      "  timestamp: 1637727097\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8336574\n",
      "  training_iteration: 894\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   894</td><td style=\"text-align: right;\">          465766</td><td style=\"text-align: right;\">8336574</td><td style=\"text-align: right;\"> 5.24447</td><td style=\"text-align: right;\">                15.6</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           52.5158</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8346570\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_04-20-32\n",
      "  done: false\n",
      "  episode_len_mean: 52.57068062827225\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.690000000000005\n",
      "  episode_reward_mean: 4.86905759162304\n",
      "  episode_reward_min: -0.6900000000000004\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 160813\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0611148431119193\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014572134560544998\n",
      "          policy_loss: -0.0647314886362978\n",
      "          total_loss: 0.08505855094175435\n",
      "          vf_explained_var: 0.9296025633811951\n",
      "          vf_loss: 0.1372040439508369\n",
      "    num_agent_steps_sampled: 8346570\n",
      "    num_agent_steps_trained: 8346570\n",
      "    num_steps_sampled: 8346570\n",
      "    num_steps_trained: 8346570\n",
      "  iterations_since_restore: 495\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.99986910994764\n",
      "    ram_util_percent: 53.26950261780104\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279922600030742\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.571001202657175\n",
      "    mean_inference_ms: 19.510341054476545\n",
      "    mean_raw_obs_processing_ms: 3.3042566073452844\n",
      "  time_since_restore: 271483.38342642784\n",
      "  time_this_iter_s: 535.2259373664856\n",
      "  time_total_s: 466300.74701189995\n",
      "  timers:\n",
      "    learn_throughput: 28.303\n",
      "    learn_time_ms: 353181.208\n",
      "    load_throughput: 89277.3\n",
      "    load_time_ms: 111.966\n",
      "    sample_throughput: 51.781\n",
      "    sample_time_ms: 193044.656\n",
      "    update_time_ms: 6.33\n",
      "  timestamp: 1637727632\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8346570\n",
      "  training_iteration: 895\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   895</td><td style=\"text-align: right;\">          466301</td><td style=\"text-align: right;\">8346570</td><td style=\"text-align: right;\"> 4.86906</td><td style=\"text-align: right;\">               15.69</td><td style=\"text-align: right;\">               -0.69</td><td style=\"text-align: right;\">           52.5707</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8356566\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_04-29-54\n",
      "  done: false\n",
      "  episode_len_mean: 52.02094240837696\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000008\n",
      "  episode_reward_mean: 4.861780104712046\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 161004\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.034049080940614\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014803810431993232\n",
      "          policy_loss: -0.06981757813894411\n",
      "          total_loss: 0.07975312560295397\n",
      "          vf_explained_var: 0.9333649277687073\n",
      "          vf_loss: 0.1361862612130816\n",
      "    num_agent_steps_sampled: 8356566\n",
      "    num_agent_steps_trained: 8356566\n",
      "    num_steps_sampled: 8356566\n",
      "    num_steps_trained: 8356566\n",
      "  iterations_since_restore: 496\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.3715710723192\n",
      "    ram_util_percent: 54.046384039900246\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052793756539069606\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.571232664814225\n",
      "    mean_inference_ms: 19.51024388666546\n",
      "    mean_raw_obs_processing_ms: 3.310164352213694\n",
      "  time_since_restore: 272045.2007148266\n",
      "  time_this_iter_s: 561.8172883987427\n",
      "  time_total_s: 466862.5643002987\n",
      "  timers:\n",
      "    learn_throughput: 28.308\n",
      "    learn_time_ms: 353114.405\n",
      "    load_throughput: 89698.96\n",
      "    load_time_ms: 111.439\n",
      "    sample_throughput: 51.484\n",
      "    sample_time_ms: 194158.207\n",
      "    update_time_ms: 6.205\n",
      "  timestamp: 1637728194\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8356566\n",
      "  training_iteration: 896\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   896</td><td style=\"text-align: right;\">          466863</td><td style=\"text-align: right;\">8356566</td><td style=\"text-align: right;\"> 4.86178</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           52.0209</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8366562\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_04-38-48\n",
      "  done: false\n",
      "  episode_len_mean: 52.182291666666664\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.69999999999998\n",
      "  episode_reward_mean: 4.982604166666671\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 161196\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.036697377402141\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014563574624459789\n",
      "          policy_loss: -0.06872925473470382\n",
      "          total_loss: 0.07593319241933902\n",
      "          vf_explained_var: 0.9432000517845154\n",
      "          vf_loss: 0.1318517752229255\n",
      "    num_agent_steps_sampled: 8366562\n",
      "    num_agent_steps_trained: 8366562\n",
      "    num_steps_sampled: 8366562\n",
      "    num_steps_trained: 8366562\n",
      "  iterations_since_restore: 497\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.16162943495401\n",
      "    ram_util_percent: 53.40670170827858\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280360997054851\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.573420141440792\n",
      "    mean_inference_ms: 19.512764750811456\n",
      "    mean_raw_obs_processing_ms: 3.3072806829841768\n",
      "  time_since_restore: 272579.0814638138\n",
      "  time_this_iter_s: 533.8807489871979\n",
      "  time_total_s: 467396.4450492859\n",
      "  timers:\n",
      "    learn_throughput: 28.304\n",
      "    learn_time_ms: 353162.549\n",
      "    load_throughput: 89631.978\n",
      "    load_time_ms: 111.523\n",
      "    sample_throughput: 51.894\n",
      "    sample_time_ms: 192622.983\n",
      "    update_time_ms: 6.196\n",
      "  timestamp: 1637728728\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8366562\n",
      "  training_iteration: 897\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   897</td><td style=\"text-align: right;\">          467396</td><td style=\"text-align: right;\">8366562</td><td style=\"text-align: right;\">  4.9826</td><td style=\"text-align: right;\">                17.7</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           52.1823</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8376558\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_04-47-55\n",
      "  done: false\n",
      "  episode_len_mean: 52.026041666666664\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.490000000000007\n",
      "  episode_reward_mean: 5.191875000000004\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 161388\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0446119396801454\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014970932179844135\n",
      "          policy_loss: -0.06996543319282499\n",
      "          total_loss: 0.08528095049194265\n",
      "          vf_explained_var: 0.9281480312347412\n",
      "          vf_loss: 0.14158684640466404\n",
      "    num_agent_steps_sampled: 8376558\n",
      "    num_agent_steps_trained: 8376558\n",
      "    num_steps_sampled: 8376558\n",
      "    num_steps_trained: 8376558\n",
      "  iterations_since_restore: 498\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.93175416133164\n",
      "    ram_util_percent: 53.433418693982084\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052796444663068764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.57341790895981\n",
      "    mean_inference_ms: 19.509996455862662\n",
      "    mean_raw_obs_processing_ms: 3.3056943852028042\n",
      "  time_since_restore: 273126.1585805416\n",
      "  time_this_iter_s: 547.077116727829\n",
      "  time_total_s: 467943.5221660137\n",
      "  timers:\n",
      "    learn_throughput: 28.298\n",
      "    learn_time_ms: 353238.081\n",
      "    load_throughput: 89557.059\n",
      "    load_time_ms: 111.616\n",
      "    sample_throughput: 52.552\n",
      "    sample_time_ms: 190209.875\n",
      "    update_time_ms: 5.347\n",
      "  timestamp: 1637729275\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8376558\n",
      "  training_iteration: 898\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   898</td><td style=\"text-align: right;\">          467944</td><td style=\"text-align: right;\">8376558</td><td style=\"text-align: right;\"> 5.19188</td><td style=\"text-align: right;\">               15.49</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">            52.026</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8386554\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_04-57-05\n",
      "  done: false\n",
      "  episode_len_mean: 51.670103092783506\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 4.817268041237117\n",
      "  episode_reward_min: -0.6600000000000004\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 161582\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0553966142326954\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014837210475747539\n",
      "          policy_loss: -0.07100682219791353\n",
      "          total_loss: 0.06609315144351022\n",
      "          vf_explained_var: 0.9202849268913269\n",
      "          vf_loss: 0.12385291799418553\n",
      "    num_agent_steps_sampled: 8386554\n",
      "    num_agent_steps_trained: 8386554\n",
      "    num_steps_sampled: 8386554\n",
      "    num_steps_trained: 8386554\n",
      "  iterations_since_restore: 499\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.6605867346939\n",
      "    ram_util_percent: 52.9375\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527987004462587\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.575666912406003\n",
      "    mean_inference_ms: 19.511400338136134\n",
      "    mean_raw_obs_processing_ms: 3.3050979282331565\n",
      "  time_since_restore: 273675.8586142063\n",
      "  time_this_iter_s: 549.7000336647034\n",
      "  time_total_s: 468493.2221996784\n",
      "  timers:\n",
      "    learn_throughput: 28.297\n",
      "    learn_time_ms: 353253.411\n",
      "    load_throughput: 89559.795\n",
      "    load_time_ms: 111.613\n",
      "    sample_throughput: 52.598\n",
      "    sample_time_ms: 190044.26\n",
      "    update_time_ms: 5.247\n",
      "  timestamp: 1637729825\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8386554\n",
      "  training_iteration: 899\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   899</td><td style=\"text-align: right;\">          468493</td><td style=\"text-align: right;\">8386554</td><td style=\"text-align: right;\"> 4.81727</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.66</td><td style=\"text-align: right;\">           51.6701</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8396550\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_05-06-14\n",
      "  done: false\n",
      "  episode_len_mean: 52.1151832460733\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 4.958743455497387\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 161773\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0290179019472205\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014963705772463766\n",
      "          policy_loss: -0.06649725025949463\n",
      "          total_loss: 0.09454122453461748\n",
      "          vf_explained_var: 0.938674807548523\n",
      "          vf_loss: 0.14723945989621331\n",
      "    num_agent_steps_sampled: 8396550\n",
      "    num_agent_steps_trained: 8396550\n",
      "    num_steps_sampled: 8396550\n",
      "    num_steps_trained: 8396550\n",
      "  iterations_since_restore: 500\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8797193877551\n",
      "    ram_util_percent: 53.536989795918366\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052800786362854506\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.578312795278066\n",
      "    mean_inference_ms: 19.51340927783825\n",
      "    mean_raw_obs_processing_ms: 3.304881125427892\n",
      "  time_since_restore: 274224.9234344959\n",
      "  time_this_iter_s: 549.0648202896118\n",
      "  time_total_s: 469042.28701996803\n",
      "  timers:\n",
      "    learn_throughput: 28.296\n",
      "    learn_time_ms: 353261.205\n",
      "    load_throughput: 89349.218\n",
      "    load_time_ms: 111.876\n",
      "    sample_throughput: 52.182\n",
      "    sample_time_ms: 191559.27\n",
      "    update_time_ms: 4.987\n",
      "  timestamp: 1637730374\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8396550\n",
      "  training_iteration: 900\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   900</td><td style=\"text-align: right;\">          469042</td><td style=\"text-align: right;\">8396550</td><td style=\"text-align: right;\"> 4.95874</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           52.1152</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8406546\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_05-15-11\n",
      "  done: false\n",
      "  episode_len_mean: 51.31122448979592\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.650000000000006\n",
      "  episode_reward_mean: 5.567653061224496\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 196\n",
      "  episodes_total: 161969\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0362877221471334\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015833057403392675\n",
      "          policy_loss: -0.0675057446781696\n",
      "          total_loss: 0.112504333685576\n",
      "          vf_explained_var: 0.9301347136497498\n",
      "          vf_loss: 0.1643032707731206\n",
      "    num_agent_steps_sampled: 8406546\n",
      "    num_agent_steps_trained: 8406546\n",
      "    num_steps_sampled: 8406546\n",
      "    num_steps_trained: 8406546\n",
      "  iterations_since_restore: 501\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.16736292428197\n",
      "    ram_util_percent: 53.11553524804179\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280415158222253\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.581200823638344\n",
      "    mean_inference_ms: 19.51394425219435\n",
      "    mean_raw_obs_processing_ms: 3.301412134995055\n",
      "  time_since_restore: 274761.7652142048\n",
      "  time_this_iter_s: 536.8417797088623\n",
      "  time_total_s: 469579.1287996769\n",
      "  timers:\n",
      "    learn_throughput: 28.294\n",
      "    learn_time_ms: 353289.637\n",
      "    load_throughput: 89533.077\n",
      "    load_time_ms: 111.646\n",
      "    sample_throughput: 52.184\n",
      "    sample_time_ms: 191551.321\n",
      "    update_time_ms: 4.925\n",
      "  timestamp: 1637730911\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8406546\n",
      "  training_iteration: 901\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   901</td><td style=\"text-align: right;\">          469579</td><td style=\"text-align: right;\">8406546</td><td style=\"text-align: right;\"> 5.56765</td><td style=\"text-align: right;\">               15.65</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           51.3112</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8416542\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_05-24-19\n",
      "  done: false\n",
      "  episode_len_mean: 51.597938144329895\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.659999999999975\n",
      "  episode_reward_mean: 5.2423711340206225\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 162163\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.036122931294652\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014592035130507096\n",
      "          policy_loss: -0.06397340917463144\n",
      "          total_loss: 0.1026333557089699\n",
      "          vf_explained_var: 0.9310716390609741\n",
      "          vf_loss: 0.1537255143675669\n",
      "    num_agent_steps_sampled: 8416542\n",
      "    num_agent_steps_trained: 8416542\n",
      "    num_steps_sampled: 8416542\n",
      "    num_steps_trained: 8416542\n",
      "  iterations_since_restore: 502\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81994884910486\n",
      "    ram_util_percent: 53.46624040920717\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280683437655321\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.582833857767813\n",
      "    mean_inference_ms: 19.51248636754148\n",
      "    mean_raw_obs_processing_ms: 3.2997898665035015\n",
      "  time_since_restore: 275310.5008044243\n",
      "  time_this_iter_s: 548.7355902194977\n",
      "  time_total_s: 470127.8643898964\n",
      "  timers:\n",
      "    learn_throughput: 28.3\n",
      "    learn_time_ms: 353217.153\n",
      "    load_throughput: 89206.712\n",
      "    load_time_ms: 112.054\n",
      "    sample_throughput: 52.268\n",
      "    sample_time_ms: 191245.203\n",
      "    update_time_ms: 4.654\n",
      "  timestamp: 1637731459\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8416542\n",
      "  training_iteration: 902\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   902</td><td style=\"text-align: right;\">          470128</td><td style=\"text-align: right;\">8416542</td><td style=\"text-align: right;\"> 5.24237</td><td style=\"text-align: right;\">               21.66</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           51.5979</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8426538\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_05-33-46\n",
      "  done: false\n",
      "  episode_len_mean: 51.324742268041234\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.560000000000008\n",
      "  episode_reward_mean: 5.183608247422685\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 162357\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0315615175239534\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014487503912415541\n",
      "          policy_loss: -0.06407489420016792\n",
      "          total_loss: 0.09419209018645829\n",
      "          vf_explained_var: 0.9440808296203613\n",
      "          vf_loss: 0.14557825265757096\n",
      "    num_agent_steps_sampled: 8426538\n",
      "    num_agent_steps_trained: 8426538\n",
      "    num_steps_sampled: 8426538\n",
      "    num_steps_trained: 8426538\n",
      "  iterations_since_restore: 503\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.47861557478367\n",
      "    ram_util_percent: 53.80432632880098\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280178477104081\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.582551170482784\n",
      "    mean_inference_ms: 19.512032715026013\n",
      "    mean_raw_obs_processing_ms: 3.303871999180972\n",
      "  time_since_restore: 275876.9625425339\n",
      "  time_this_iter_s: 566.4617381095886\n",
      "  time_total_s: 470694.326128006\n",
      "  timers:\n",
      "    learn_throughput: 28.306\n",
      "    learn_time_ms: 353146.22\n",
      "    load_throughput: 89214.381\n",
      "    load_time_ms: 112.045\n",
      "    sample_throughput: 51.742\n",
      "    sample_time_ms: 193187.755\n",
      "    update_time_ms: 4.587\n",
      "  timestamp: 1637732026\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8426538\n",
      "  training_iteration: 903\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   903</td><td style=\"text-align: right;\">          470694</td><td style=\"text-align: right;\">8426538</td><td style=\"text-align: right;\"> 5.18361</td><td style=\"text-align: right;\">               15.56</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           51.3247</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8436534\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_05-42-55\n",
      "  done: false\n",
      "  episode_len_mean: 51.15384615384615\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.599999999999984\n",
      "  episode_reward_mean: 5.462820512820517\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 195\n",
      "  episodes_total: 162552\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0253098645602843\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015270312656950934\n",
      "          policy_loss: -0.06591668847980192\n",
      "          total_loss: 0.09675079332659495\n",
      "          vf_explained_var: 0.9328515529632568\n",
      "          vf_loss: 0.14813289817172032\n",
      "    num_agent_steps_sampled: 8436534\n",
      "    num_agent_steps_trained: 8436534\n",
      "    num_steps_sampled: 8436534\n",
      "    num_steps_trained: 8436534\n",
      "  iterations_since_restore: 504\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91021711366541\n",
      "    ram_util_percent: 54.3148148148148\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280488529469585\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.585085932527914\n",
      "    mean_inference_ms: 19.513087544931256\n",
      "    mean_raw_obs_processing_ms: 3.3038442160531023\n",
      "  time_since_restore: 276426.32931518555\n",
      "  time_this_iter_s: 549.3667726516724\n",
      "  time_total_s: 471243.69290065765\n",
      "  timers:\n",
      "    learn_throughput: 28.299\n",
      "    learn_time_ms: 353233.788\n",
      "    load_throughput: 89422.873\n",
      "    load_time_ms: 111.783\n",
      "    sample_throughput: 51.406\n",
      "    sample_time_ms: 194453.208\n",
      "    update_time_ms: 4.969\n",
      "  timestamp: 1637732575\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8436534\n",
      "  training_iteration: 904\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   904</td><td style=\"text-align: right;\">          471244</td><td style=\"text-align: right;\">8436534</td><td style=\"text-align: right;\"> 5.46282</td><td style=\"text-align: right;\">                19.6</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           51.1538</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8446530\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_05-52-14\n",
      "  done: false\n",
      "  episode_len_mean: 51.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.659999999999997\n",
      "  episode_reward_mean: 4.928307692307696\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 195\n",
      "  episodes_total: 162747\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0495154293186695\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0149445599161773\n",
      "          policy_loss: -0.06981786593146298\n",
      "          total_loss: 0.09086635666100708\n",
      "          vf_explained_var: 0.9352156519889832\n",
      "          vf_loss: 0.14713380063077935\n",
      "    num_agent_steps_sampled: 8446530\n",
      "    num_agent_steps_trained: 8446530\n",
      "    num_steps_sampled: 8446530\n",
      "    num_steps_trained: 8446530\n",
      "  iterations_since_restore: 505\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.61304893350064\n",
      "    ram_util_percent: 54.14303638644918\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280787932149851\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.585964683607266\n",
      "    mean_inference_ms: 19.514087484402424\n",
      "    mean_raw_obs_processing_ms: 3.3066823068514832\n",
      "  time_since_restore: 276984.88109207153\n",
      "  time_this_iter_s: 558.5517768859863\n",
      "  time_total_s: 471802.24467754364\n",
      "  timers:\n",
      "    learn_throughput: 28.292\n",
      "    learn_time_ms: 353310.352\n",
      "    load_throughput: 89527.016\n",
      "    load_time_ms: 111.653\n",
      "    sample_throughput: 50.816\n",
      "    sample_time_ms: 196709.055\n",
      "    update_time_ms: 4.726\n",
      "  timestamp: 1637733134\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8446530\n",
      "  training_iteration: 905\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   905</td><td style=\"text-align: right;\">          471802</td><td style=\"text-align: right;\">8446530</td><td style=\"text-align: right;\"> 4.92831</td><td style=\"text-align: right;\">               17.66</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">              51.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8456526\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_06-01-25\n",
      "  done: false\n",
      "  episode_len_mean: 51.391752577319586\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.729999999999997\n",
      "  episode_reward_mean: 5.375670103092787\n",
      "  episode_reward_min: -0.48000000000000026\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 162941\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0660909198374156\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013878776253028077\n",
      "          policy_loss: -0.07039673593014256\n",
      "          total_loss: 0.07819754284583508\n",
      "          vf_explained_var: 0.9316385388374329\n",
      "          vf_loss: 0.13763759964403796\n",
      "    num_agent_steps_sampled: 8456526\n",
      "    num_agent_steps_trained: 8456526\n",
      "    num_steps_sampled: 8456526\n",
      "    num_steps_trained: 8456526\n",
      "  iterations_since_restore: 506\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.70609911054639\n",
      "    ram_util_percent: 53.949682337992385\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05280454342860574\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.587811105690797\n",
      "    mean_inference_ms: 19.513328782649577\n",
      "    mean_raw_obs_processing_ms: 3.305702343793018\n",
      "  time_since_restore: 277535.85568094254\n",
      "  time_this_iter_s: 550.9745888710022\n",
      "  time_total_s: 472353.21926641464\n",
      "  timers:\n",
      "    learn_throughput: 28.291\n",
      "    learn_time_ms: 353334.14\n",
      "    load_throughput: 89245.222\n",
      "    load_time_ms: 112.006\n",
      "    sample_throughput: 51.104\n",
      "    sample_time_ms: 195600.914\n",
      "    update_time_ms: 4.588\n",
      "  timestamp: 1637733685\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8456526\n",
      "  training_iteration: 906\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   906</td><td style=\"text-align: right;\">          472353</td><td style=\"text-align: right;\">8456526</td><td style=\"text-align: right;\"> 5.37567</td><td style=\"text-align: right;\">               17.73</td><td style=\"text-align: right;\">               -0.48</td><td style=\"text-align: right;\">           51.3918</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8466522\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_06-10-34\n",
      "  done: false\n",
      "  episode_len_mean: 51.6580310880829\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.710000000000004\n",
      "  episode_reward_mean: 5.1221243523316105\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 163134\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0465996999577825\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014574689657775391\n",
      "          policy_loss: -0.06404805238364433\n",
      "          total_loss: 0.08876624087289717\n",
      "          vf_explained_var: 0.9369776248931885\n",
      "          vf_loss: 0.140077325336291\n",
      "    num_agent_steps_sampled: 8466522\n",
      "    num_agent_steps_trained: 8466522\n",
      "    num_steps_sampled: 8466522\n",
      "    num_steps_trained: 8466522\n",
      "  iterations_since_restore: 507\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81136653895273\n",
      "    ram_util_percent: 53.612388250319285\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052795790952080084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.589955074857635\n",
      "    mean_inference_ms: 19.51444901815967\n",
      "    mean_raw_obs_processing_ms: 3.3050764043754217\n",
      "  time_since_restore: 278084.8499085903\n",
      "  time_this_iter_s: 548.9942276477814\n",
      "  time_total_s: 472902.2134940624\n",
      "  timers:\n",
      "    learn_throughput: 28.294\n",
      "    learn_time_ms: 353286.735\n",
      "    load_throughput: 89170.816\n",
      "    load_time_ms: 112.099\n",
      "    sample_throughput: 50.7\n",
      "    sample_time_ms: 197159.984\n",
      "    update_time_ms: 4.558\n",
      "  timestamp: 1637734234\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8466522\n",
      "  training_iteration: 907\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   907</td><td style=\"text-align: right;\">          472902</td><td style=\"text-align: right;\">8466522</td><td style=\"text-align: right;\"> 5.12212</td><td style=\"text-align: right;\">               15.71</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">            51.658</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8476518\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_06-19-41\n",
      "  done: false\n",
      "  episode_len_mean: 51.30102040816327\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.560000000000008\n",
      "  episode_reward_mean: 5.324591836734698\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 196\n",
      "  episodes_total: 163330\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.035855432782307\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014797624182200096\n",
      "          policy_loss: -0.06731525934433467\n",
      "          total_loss: 0.07765007992876567\n",
      "          vf_explained_var: 0.9444125890731812\n",
      "          vf_loss: 0.13161305456626113\n",
      "    num_agent_steps_sampled: 8476518\n",
      "    num_agent_steps_trained: 8476518\n",
      "    num_steps_sampled: 8476518\n",
      "    num_steps_trained: 8476518\n",
      "  iterations_since_restore: 508\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.73564102564103\n",
      "    ram_util_percent: 53.415\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052782581757615486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.58932580803868\n",
      "    mean_inference_ms: 19.510141396116282\n",
      "    mean_raw_obs_processing_ms: 3.3031385228182177\n",
      "  time_since_restore: 278631.8559293747\n",
      "  time_this_iter_s: 547.006020784378\n",
      "  time_total_s: 473449.2195148468\n",
      "  timers:\n",
      "    learn_throughput: 28.299\n",
      "    learn_time_ms: 353228.225\n",
      "    load_throughput: 89214.04\n",
      "    load_time_ms: 112.045\n",
      "    sample_throughput: 50.687\n",
      "    sample_time_ms: 197210.543\n",
      "    update_time_ms: 4.727\n",
      "  timestamp: 1637734781\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8476518\n",
      "  training_iteration: 908\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   908</td><td style=\"text-align: right;\">          473449</td><td style=\"text-align: right;\">8476518</td><td style=\"text-align: right;\"> 5.32459</td><td style=\"text-align: right;\">               15.56</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">            51.301</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8486514\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_06-29-16\n",
      "  done: false\n",
      "  episode_len_mean: 50.568527918781726\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000007\n",
      "  episode_reward_mean: 5.488832487309648\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 197\n",
      "  episodes_total: 163527\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.029497450805572\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015361268071247693\n",
      "          policy_loss: -0.0623894967481833\n",
      "          total_loss: 0.1024435690098296\n",
      "          vf_explained_var: 0.9420347213745117\n",
      "          vf_loss: 0.15013314962263657\n",
      "    num_agent_steps_sampled: 8486514\n",
      "    num_agent_steps_trained: 8486514\n",
      "    num_steps_sampled: 8486514\n",
      "    num_steps_trained: 8486514\n",
      "  iterations_since_restore: 509\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.36621951219513\n",
      "    ram_util_percent: 53.85719512195123\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279348050150317\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.592438789388783\n",
      "    mean_inference_ms: 19.51452782964366\n",
      "    mean_raw_obs_processing_ms: 3.3104305255238455\n",
      "  time_since_restore: 279206.5354781151\n",
      "  time_this_iter_s: 574.679548740387\n",
      "  time_total_s: 474023.8990635872\n",
      "  timers:\n",
      "    learn_throughput: 28.302\n",
      "    learn_time_ms: 353194.785\n",
      "    load_throughput: 88952.417\n",
      "    load_time_ms: 112.375\n",
      "    sample_throughput: 50.045\n",
      "    sample_time_ms: 199741.691\n",
      "    update_time_ms: 5.14\n",
      "  timestamp: 1637735356\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8486514\n",
      "  training_iteration: 909\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   909</td><td style=\"text-align: right;\">          474024</td><td style=\"text-align: right;\">8486514</td><td style=\"text-align: right;\"> 5.48883</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           50.5685</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8496510\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_06-38-12\n",
      "  done: false\n",
      "  episode_len_mean: 51.83419689119171\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.66\n",
      "  episode_reward_mean: 5.1110362694300555\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 163720\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.045618858801792\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014554221306229109\n",
      "          policy_loss: -0.06700039052104995\n",
      "          total_loss: 0.09749095122374657\n",
      "          vf_explained_var: 0.9240342378616333\n",
      "          vf_loss: 0.15179119318345913\n",
      "    num_agent_steps_sampled: 8496510\n",
      "    num_agent_steps_trained: 8496510\n",
      "    num_steps_sampled: 8496510\n",
      "    num_steps_trained: 8496510\n",
      "  iterations_since_restore: 510\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00339425587468\n",
      "    ram_util_percent: 53.47610966057441\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278566289993819\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.59325423878426\n",
      "    mean_inference_ms: 19.51067980421073\n",
      "    mean_raw_obs_processing_ms: 3.305325642131328\n",
      "  time_since_restore: 279743.1798672676\n",
      "  time_this_iter_s: 536.6443891525269\n",
      "  time_total_s: 474560.5434527397\n",
      "  timers:\n",
      "    learn_throughput: 28.306\n",
      "    learn_time_ms: 353146.518\n",
      "    load_throughput: 88915.008\n",
      "    load_time_ms: 112.422\n",
      "    sample_throughput: 50.346\n",
      "    sample_time_ms: 198547.446\n",
      "    update_time_ms: 5.507\n",
      "  timestamp: 1637735892\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8496510\n",
      "  training_iteration: 910\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   910</td><td style=\"text-align: right;\">          474561</td><td style=\"text-align: right;\">8496510</td><td style=\"text-align: right;\"> 5.11104</td><td style=\"text-align: right;\">               17.66</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           51.8342</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8506506\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_06-47-09\n",
      "  done: false\n",
      "  episode_len_mean: 51.402061855670105\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.610000000000007\n",
      "  episode_reward_mean: 5.2989175257732\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 163914\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.04966036332659\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015037211977164629\n",
      "          policy_loss: -0.06621545661983694\n",
      "          total_loss: 0.09250403803716434\n",
      "          vf_explained_var: 0.9334193468093872\n",
      "          vf_loss: 0.14495944842625125\n",
      "    num_agent_steps_sampled: 8506506\n",
      "    num_agent_steps_trained: 8506506\n",
      "    num_steps_sampled: 8506506\n",
      "    num_steps_trained: 8506506\n",
      "  iterations_since_restore: 511\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.05496083550915\n",
      "    ram_util_percent: 53.37859007832898\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279161375774036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.597583471481222\n",
      "    mean_inference_ms: 19.513826845323322\n",
      "    mean_raw_obs_processing_ms: 3.3022715255583424\n",
      "  time_since_restore: 280280.08656668663\n",
      "  time_this_iter_s: 536.9066994190216\n",
      "  time_total_s: 475097.45015215874\n",
      "  timers:\n",
      "    learn_throughput: 28.307\n",
      "    learn_time_ms: 353129.375\n",
      "    load_throughput: 88800.037\n",
      "    load_time_ms: 112.568\n",
      "    sample_throughput: 50.34\n",
      "    sample_time_ms: 198570.025\n",
      "    update_time_ms: 5.916\n",
      "  timestamp: 1637736429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8506506\n",
      "  training_iteration: 911\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   911</td><td style=\"text-align: right;\">          475097</td><td style=\"text-align: right;\">8506506</td><td style=\"text-align: right;\"> 5.29892</td><td style=\"text-align: right;\">               15.61</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           51.4021</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8516502\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_06-56-33\n",
      "  done: false\n",
      "  episode_len_mean: 51.13265306122449\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 4.913928571428576\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 196\n",
      "  episodes_total: 164110\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0500675396268146\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014289810542007524\n",
      "          policy_loss: -0.06946153703728519\n",
      "          total_loss: 0.08633458585600275\n",
      "          vf_explained_var: 0.9350736737251282\n",
      "          vf_loss: 0.1437428214850024\n",
      "    num_agent_steps_sampled: 8516502\n",
      "    num_agent_steps_trained: 8516502\n",
      "    num_steps_sampled: 8516502\n",
      "    num_steps_trained: 8516502\n",
      "  iterations_since_restore: 512\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.40547263681592\n",
      "    ram_util_percent: 53.68706467661692\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278489223374423\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.599834177074335\n",
      "    mean_inference_ms: 19.51327244370685\n",
      "    mean_raw_obs_processing_ms: 3.3042142584416867\n",
      "  time_since_restore: 280843.9824514389\n",
      "  time_this_iter_s: 563.8958847522736\n",
      "  time_total_s: 475661.346036911\n",
      "  timers:\n",
      "    learn_throughput: 28.302\n",
      "    learn_time_ms: 353194.154\n",
      "    load_throughput: 88990.045\n",
      "    load_time_ms: 112.327\n",
      "    sample_throughput: 49.975\n",
      "    sample_time_ms: 200021.807\n",
      "    update_time_ms: 5.872\n",
      "  timestamp: 1637736993\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8516502\n",
      "  training_iteration: 912\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   912</td><td style=\"text-align: right;\">          475661</td><td style=\"text-align: right;\">8516502</td><td style=\"text-align: right;\"> 4.91393</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           51.1327</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8526498\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_07-05-42\n",
      "  done: false\n",
      "  episode_len_mean: 51.20103092783505\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000006\n",
      "  episode_reward_mean: 5.180567010309282\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 164304\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0349069148661143\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0157953863101394\n",
      "          policy_loss: -0.0667014258044818\n",
      "          total_loss: 0.09345419724759048\n",
      "          vf_explained_var: 0.9463626742362976\n",
      "          vf_loss: 0.14452082702186872\n",
      "    num_agent_steps_sampled: 8526498\n",
      "    num_agent_steps_trained: 8526498\n",
      "    num_steps_sampled: 8526498\n",
      "    num_steps_trained: 8526498\n",
      "  iterations_since_restore: 513\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75785440613026\n",
      "    ram_util_percent: 53.34891443167304\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052795572451124435\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.602322832604447\n",
      "    mean_inference_ms: 19.515903766419857\n",
      "    mean_raw_obs_processing_ms: 3.30446009482806\n",
      "  time_since_restore: 281392.4013197422\n",
      "  time_this_iter_s: 548.418868303299\n",
      "  time_total_s: 476209.7649052143\n",
      "  timers:\n",
      "    learn_throughput: 28.295\n",
      "    learn_time_ms: 353276.613\n",
      "    load_throughput: 89134.133\n",
      "    load_time_ms: 112.146\n",
      "    sample_throughput: 50.451\n",
      "    sample_time_ms: 198134.369\n",
      "    update_time_ms: 6.249\n",
      "  timestamp: 1637737542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8526498\n",
      "  training_iteration: 913\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   913</td><td style=\"text-align: right;\">          476210</td><td style=\"text-align: right;\">8526498</td><td style=\"text-align: right;\"> 5.18057</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">            51.201</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8536494\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_07-15-37\n",
      "  done: false\n",
      "  episode_len_mean: 51.829896907216494\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.520000000000008\n",
      "  episode_reward_mean: 5.204175257731962\n",
      "  episode_reward_min: -0.49000000000000016\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 164498\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.014640753934661\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014726687867867535\n",
      "          policy_loss: -0.06331588469950815\n",
      "          total_loss: 0.10265424010577265\n",
      "          vf_explained_var: 0.9485820531845093\n",
      "          vf_loss: 0.15256729662740026\n",
      "    num_agent_steps_sampled: 8536494\n",
      "    num_agent_steps_trained: 8536494\n",
      "    num_steps_sampled: 8536494\n",
      "    num_steps_trained: 8536494\n",
      "  iterations_since_restore: 514\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.35182567726737\n",
      "    ram_util_percent: 53.49328621908127\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052790141299170555\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.602676120839327\n",
      "    mean_inference_ms: 19.51418207994516\n",
      "    mean_raw_obs_processing_ms: 3.313679024838793\n",
      "  time_since_restore: 281987.5794765949\n",
      "  time_this_iter_s: 595.1781568527222\n",
      "  time_total_s: 476804.94306206703\n",
      "  timers:\n",
      "    learn_throughput: 28.298\n",
      "    learn_time_ms: 353245.835\n",
      "    load_throughput: 88712.798\n",
      "    load_time_ms: 112.678\n",
      "    sample_throughput: 49.303\n",
      "    sample_time_ms: 202746.231\n",
      "    update_time_ms: 5.976\n",
      "  timestamp: 1637738137\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8536494\n",
      "  training_iteration: 914\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   914</td><td style=\"text-align: right;\">          476805</td><td style=\"text-align: right;\">8536494</td><td style=\"text-align: right;\"> 5.20418</td><td style=\"text-align: right;\">               15.52</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           51.8299</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8546490\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_07-24-58\n",
      "  done: false\n",
      "  episode_len_mean: 51.015306122448976\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.24571428571429\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 196\n",
      "  episodes_total: 164694\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.038533856255941\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014231531003328737\n",
      "          policy_loss: -0.06300385333177484\n",
      "          total_loss: 0.09162802505887223\n",
      "          vf_explained_var: 0.9282523393630981\n",
      "          vf_loss: 0.14259600912951995\n",
      "    num_agent_steps_sampled: 8546490\n",
      "    num_agent_steps_trained: 8546490\n",
      "    num_steps_sampled: 8546490\n",
      "    num_steps_trained: 8546490\n",
      "  iterations_since_restore: 515\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.6675\n",
      "    ram_util_percent: 53.56212500000001\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278191708340841\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.604174559126996\n",
      "    mean_inference_ms: 19.51339872521917\n",
      "    mean_raw_obs_processing_ms: 3.3152839520280795\n",
      "  time_since_restore: 282548.42886805534\n",
      "  time_this_iter_s: 560.8493914604187\n",
      "  time_total_s: 477365.79245352745\n",
      "  timers:\n",
      "    learn_throughput: 28.297\n",
      "    learn_time_ms: 353249.901\n",
      "    load_throughput: 88497.699\n",
      "    load_time_ms: 112.952\n",
      "    sample_throughput: 49.248\n",
      "    sample_time_ms: 202971.767\n",
      "    update_time_ms: 5.822\n",
      "  timestamp: 1637738698\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8546490\n",
      "  training_iteration: 915\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   915</td><td style=\"text-align: right;\">          477366</td><td style=\"text-align: right;\">8546490</td><td style=\"text-align: right;\"> 5.24571</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           51.0153</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8556486\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_07-34-09\n",
      "  done: false\n",
      "  episode_len_mean: 50.72222222222222\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.720000000000004\n",
      "  episode_reward_mean: 4.768939393939397\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 198\n",
      "  episodes_total: 164892\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0222872132517726\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014664731698652591\n",
      "          policy_loss: -0.060013748707685326\n",
      "          total_loss: 0.08446985749264256\n",
      "          vf_explained_var: 0.9456523656845093\n",
      "          vf_loss: 0.13129838641628205\n",
      "    num_agent_steps_sampled: 8556486\n",
      "    num_agent_steps_trained: 8556486\n",
      "    num_steps_sampled: 8556486\n",
      "    num_steps_trained: 8556486\n",
      "  iterations_since_restore: 516\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.8125794155019\n",
      "    ram_util_percent: 53.950825921219824\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278362243054045\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.6053325297669\n",
      "    mean_inference_ms: 19.511613000864994\n",
      "    mean_raw_obs_processing_ms: 3.314788431994421\n",
      "  time_since_restore: 283099.8788380623\n",
      "  time_this_iter_s: 551.4499700069427\n",
      "  time_total_s: 477917.2424235344\n",
      "  timers:\n",
      "    learn_throughput: 28.292\n",
      "    learn_time_ms: 353316.58\n",
      "    load_throughput: 88342.218\n",
      "    load_time_ms: 113.151\n",
      "    sample_throughput: 49.253\n",
      "    sample_time_ms: 202952.499\n",
      "    update_time_ms: 5.9\n",
      "  timestamp: 1637739249\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8556486\n",
      "  training_iteration: 916\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   916</td><td style=\"text-align: right;\">          477917</td><td style=\"text-align: right;\">8556486</td><td style=\"text-align: right;\"> 4.76894</td><td style=\"text-align: right;\">               13.72</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           50.7222</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8566482\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_07-43-27\n",
      "  done: false\n",
      "  episode_len_mean: 52.22105263157895\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000007\n",
      "  episode_reward_mean: 5.1187368421052675\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 165082\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0191791295047743\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014473185256148255\n",
      "          policy_loss: -0.06774908538714665\n",
      "          total_loss: 0.08974290687682182\n",
      "          vf_explained_var: 0.9358574748039246\n",
      "          vf_loss: 0.1447120577420471\n",
      "    num_agent_steps_sampled: 8566482\n",
      "    num_agent_steps_trained: 8566482\n",
      "    num_steps_sampled: 8566482\n",
      "    num_steps_trained: 8566482\n",
      "  iterations_since_restore: 517\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.62487437185929\n",
      "    ram_util_percent: 54.1037688442211\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278860145981889\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.605594365627574\n",
      "    mean_inference_ms: 19.513879246197785\n",
      "    mean_raw_obs_processing_ms: 3.317912388301234\n",
      "  time_since_restore: 283657.6297106743\n",
      "  time_this_iter_s: 557.7508726119995\n",
      "  time_total_s: 478474.9932961464\n",
      "  timers:\n",
      "    learn_throughput: 28.287\n",
      "    learn_time_ms: 353374.542\n",
      "    load_throughput: 88230.153\n",
      "    load_time_ms: 113.295\n",
      "    sample_throughput: 49.055\n",
      "    sample_time_ms: 203770.117\n",
      "    update_time_ms: 5.948\n",
      "  timestamp: 1637739807\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8566482\n",
      "  training_iteration: 917\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   917</td><td style=\"text-align: right;\">          478475</td><td style=\"text-align: right;\">8566482</td><td style=\"text-align: right;\"> 5.11874</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           52.2211</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8576478\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_07-52-39\n",
      "  done: false\n",
      "  episode_len_mean: 51.11734693877551\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.61999999999998\n",
      "  episode_reward_mean: 4.865816326530616\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 196\n",
      "  episodes_total: 165278\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.049158635460229\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01468464574071826\n",
      "          policy_loss: -0.06720033253645176\n",
      "          total_loss: 0.08711462281624913\n",
      "          vf_explained_var: 0.9331007599830627\n",
      "          vf_loss: 0.14135308264676166\n",
      "    num_agent_steps_sampled: 8576478\n",
      "    num_agent_steps_trained: 8576478\n",
      "    num_steps_sampled: 8576478\n",
      "    num_steps_trained: 8576478\n",
      "  iterations_since_restore: 518\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00292249047014\n",
      "    ram_util_percent: 54.24015247776366\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052777718056580214\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.607832709465768\n",
      "    mean_inference_ms: 19.51314714769496\n",
      "    mean_raw_obs_processing_ms: 3.3196006792174315\n",
      "  time_since_restore: 284209.76106357574\n",
      "  time_this_iter_s: 552.1313529014587\n",
      "  time_total_s: 479027.12464904785\n",
      "  timers:\n",
      "    learn_throughput: 28.281\n",
      "    learn_time_ms: 353454.622\n",
      "    load_throughput: 88408.815\n",
      "    load_time_ms: 113.066\n",
      "    sample_throughput: 48.951\n",
      "    sample_time_ms: 204203.267\n",
      "    update_time_ms: 5.827\n",
      "  timestamp: 1637740359\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8576478\n",
      "  training_iteration: 918\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   918</td><td style=\"text-align: right;\">          479027</td><td style=\"text-align: right;\">8576478</td><td style=\"text-align: right;\"> 4.86582</td><td style=\"text-align: right;\">               17.62</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           51.1173</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8586474\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_08-02-06\n",
      "  done: false\n",
      "  episode_len_mean: 51.47422680412371\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.195979381443303\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 165472\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0572869626633135\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014649333326473998\n",
      "          policy_loss: -0.06913758458923626\n",
      "          total_loss: 0.08420600607796294\n",
      "          vf_explained_var: 0.9434183835983276\n",
      "          vf_loss: 0.14054344648628095\n",
      "    num_agent_steps_sampled: 8586474\n",
      "    num_agent_steps_trained: 8586474\n",
      "    num_steps_sampled: 8586474\n",
      "    num_steps_trained: 8586474\n",
      "  iterations_since_restore: 519\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.25587144622992\n",
      "    ram_util_percent: 54.13374536464771\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279752972847438\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.608128371952937\n",
      "    mean_inference_ms: 19.515390410770628\n",
      "    mean_raw_obs_processing_ms: 3.3240137134615244\n",
      "  time_since_restore: 284776.33040237427\n",
      "  time_this_iter_s: 566.569338798523\n",
      "  time_total_s: 479593.6939878464\n",
      "  timers:\n",
      "    learn_throughput: 28.275\n",
      "    learn_time_ms: 353523.996\n",
      "    load_throughput: 88470.864\n",
      "    load_time_ms: 112.986\n",
      "    sample_throughput: 49.163\n",
      "    sample_time_ms: 203322.787\n",
      "    update_time_ms: 5.814\n",
      "  timestamp: 1637740926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8586474\n",
      "  training_iteration: 919\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   919</td><td style=\"text-align: right;\">          479594</td><td style=\"text-align: right;\">8586474</td><td style=\"text-align: right;\"> 5.19598</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           51.4742</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8596470\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_08-11-14\n",
      "  done: false\n",
      "  episode_len_mean: 51.292307692307695\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.510000000000009\n",
      "  episode_reward_mean: 5.011692307692312\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 195\n",
      "  episodes_total: 165667\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0465686106777574\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013627561198305693\n",
      "          policy_loss: -0.06444419737361817\n",
      "          total_loss: 0.0775127198867446\n",
      "          vf_explained_var: 0.9523164629936218\n",
      "          vf_loss: 0.13137731542577033\n",
      "    num_agent_steps_sampled: 8596470\n",
      "    num_agent_steps_trained: 8596470\n",
      "    num_steps_sampled: 8596470\n",
      "    num_steps_trained: 8596470\n",
      "  iterations_since_restore: 520\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77429667519182\n",
      "    ram_util_percent: 53.72749360613811\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527914877199651\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.608673742656357\n",
      "    mean_inference_ms: 19.51323122748385\n",
      "    mean_raw_obs_processing_ms: 3.323046393675771\n",
      "  time_since_restore: 285324.24098062515\n",
      "  time_this_iter_s: 547.910578250885\n",
      "  time_total_s: 480141.60456609726\n",
      "  timers:\n",
      "    learn_throughput: 28.269\n",
      "    learn_time_ms: 353606.579\n",
      "    load_throughput: 88497.232\n",
      "    load_time_ms: 112.953\n",
      "    sample_throughput: 48.912\n",
      "    sample_time_ms: 204366.951\n",
      "    update_time_ms: 5.74\n",
      "  timestamp: 1637741474\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8596470\n",
      "  training_iteration: 920\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   920</td><td style=\"text-align: right;\">          480142</td><td style=\"text-align: right;\">8596470</td><td style=\"text-align: right;\"> 5.01169</td><td style=\"text-align: right;\">               15.51</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           51.2923</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8606466\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_08-20-11\n",
      "  done: false\n",
      "  episode_len_mean: 51.09230769230769\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.540000000000008\n",
      "  episode_reward_mean: 4.843846153846157\n",
      "  episode_reward_min: -0.5400000000000003\n",
      "  episodes_this_iter: 195\n",
      "  episodes_total: 165862\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0703455401232924\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013750855244339923\n",
      "          policy_loss: -0.05788500037301995\n",
      "          total_loss: 0.08918355917860216\n",
      "          vf_explained_var: 0.9503427743911743\n",
      "          vf_loss: 0.13644584652464686\n",
      "    num_agent_steps_sampled: 8606466\n",
      "    num_agent_steps_trained: 8606466\n",
      "    num_steps_sampled: 8606466\n",
      "    num_steps_trained: 8606466\n",
      "  iterations_since_restore: 521\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.0229765013055\n",
      "    ram_util_percent: 53.274151436031325\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278758981690694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.6122212255057\n",
      "    mean_inference_ms: 19.51431627009396\n",
      "    mean_raw_obs_processing_ms: 3.318698789914381\n",
      "  time_since_restore: 285861.0112490654\n",
      "  time_this_iter_s: 536.7702684402466\n",
      "  time_total_s: 480678.3748345375\n",
      "  timers:\n",
      "    learn_throughput: 28.264\n",
      "    learn_time_ms: 353665.21\n",
      "    load_throughput: 88389.32\n",
      "    load_time_ms: 113.091\n",
      "    sample_throughput: 48.929\n",
      "    sample_time_ms: 204294.565\n",
      "    update_time_ms: 5.358\n",
      "  timestamp: 1637742011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8606466\n",
      "  training_iteration: 921\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   921</td><td style=\"text-align: right;\">          480678</td><td style=\"text-align: right;\">8606466</td><td style=\"text-align: right;\"> 4.84385</td><td style=\"text-align: right;\">               13.54</td><td style=\"text-align: right;\">               -0.54</td><td style=\"text-align: right;\">           51.0923</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8616462\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_08-29-35\n",
      "  done: false\n",
      "  episode_len_mean: 51.51794871794872\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.690000000000005\n",
      "  episode_reward_mean: 5.238461538461543\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 195\n",
      "  episodes_total: 166057\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0557109115114174\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014549710396351946\n",
      "          policy_loss: -0.0693264542755571\n",
      "          total_loss: 0.07791465412053393\n",
      "          vf_explained_var: 0.9499776363372803\n",
      "          vf_loss: 0.13465215721603363\n",
      "    num_agent_steps_sampled: 8616462\n",
      "    num_agent_steps_trained: 8616462\n",
      "    num_steps_sampled: 8616462\n",
      "    num_steps_trained: 8616462\n",
      "  iterations_since_restore: 522\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.57562189054725\n",
      "    ram_util_percent: 53.33246268656716\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052798117192817476\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.612831677152197\n",
      "    mean_inference_ms: 19.51515783884851\n",
      "    mean_raw_obs_processing_ms: 3.322416144751183\n",
      "  time_since_restore: 286425.1261308193\n",
      "  time_this_iter_s: 564.1148817539215\n",
      "  time_total_s: 481242.4897162914\n",
      "  timers:\n",
      "    learn_throughput: 28.264\n",
      "    learn_time_ms: 353670.393\n",
      "    load_throughput: 88383.972\n",
      "    load_time_ms: 113.097\n",
      "    sample_throughput: 48.925\n",
      "    sample_time_ms: 204311.632\n",
      "    update_time_ms: 5.661\n",
      "  timestamp: 1637742575\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8616462\n",
      "  training_iteration: 922\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   922</td><td style=\"text-align: right;\">          481242</td><td style=\"text-align: right;\">8616462</td><td style=\"text-align: right;\"> 5.23846</td><td style=\"text-align: right;\">               13.69</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           51.5179</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8626458\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_08-38-30\n",
      "  done: false\n",
      "  episode_len_mean: 51.68556701030928\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.530000000000008\n",
      "  episode_reward_mean: 5.232680412371138\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 166251\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0607611806038393\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014492798461111008\n",
      "          policy_loss: -0.06866607500397663\n",
      "          total_loss: 0.08016958431737885\n",
      "          vf_explained_var: 0.9260357618331909\n",
      "          vf_loss: 0.13642686300099374\n",
      "    num_agent_steps_sampled: 8626458\n",
      "    num_agent_steps_trained: 8626458\n",
      "    num_steps_sampled: 8626458\n",
      "    num_steps_trained: 8626458\n",
      "  iterations_since_restore: 523\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.93730366492147\n",
      "    ram_util_percent: 53.27657068062827\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279267923546735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.614458744250996\n",
      "    mean_inference_ms: 19.513284911701568\n",
      "    mean_raw_obs_processing_ms: 3.3174440375497967\n",
      "  time_since_restore: 286960.01579141617\n",
      "  time_this_iter_s: 534.8896605968475\n",
      "  time_total_s: 481777.3793768883\n",
      "  timers:\n",
      "    learn_throughput: 28.262\n",
      "    learn_time_ms: 353688.52\n",
      "    load_throughput: 88047.44\n",
      "    load_time_ms: 113.53\n",
      "    sample_throughput: 49.256\n",
      "    sample_time_ms: 202941.091\n",
      "    update_time_ms: 5.632\n",
      "  timestamp: 1637743110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8626458\n",
      "  training_iteration: 923\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   923</td><td style=\"text-align: right;\">          481777</td><td style=\"text-align: right;\">8626458</td><td style=\"text-align: right;\"> 5.23268</td><td style=\"text-align: right;\">               15.53</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           51.6856</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8636454\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_08-47-55\n",
      "  done: false\n",
      "  episode_len_mean: 51.66321243523316\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.680000000000007\n",
      "  episode_reward_mean: 5.034093264248709\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 166444\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.036828400954664\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014451350171804775\n",
      "          policy_loss: -0.07054575749245129\n",
      "          total_loss: 0.06744211913566658\n",
      "          vf_explained_var: 0.9383122324943542\n",
      "          vf_loss: 0.1254341776883903\n",
      "    num_agent_steps_sampled: 8636454\n",
      "    num_agent_steps_trained: 8636454\n",
      "    num_steps_sampled: 8636454\n",
      "    num_steps_trained: 8636454\n",
      "  iterations_since_restore: 524\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.42156133828996\n",
      "    ram_util_percent: 54.27732342007436\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052796083363675805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.615043377884387\n",
      "    mean_inference_ms: 19.514593440131364\n",
      "    mean_raw_obs_processing_ms: 3.3242804601387324\n",
      "  time_since_restore: 287525.6047363281\n",
      "  time_this_iter_s: 565.5889449119568\n",
      "  time_total_s: 482342.96832180023\n",
      "  timers:\n",
      "    learn_throughput: 28.259\n",
      "    learn_time_ms: 353727.495\n",
      "    load_throughput: 88395.507\n",
      "    load_time_ms: 113.083\n",
      "    sample_throughput: 49.994\n",
      "    sample_time_ms: 199943.829\n",
      "    update_time_ms: 5.638\n",
      "  timestamp: 1637743675\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8636454\n",
      "  training_iteration: 924\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   924</td><td style=\"text-align: right;\">          482343</td><td style=\"text-align: right;\">8636454</td><td style=\"text-align: right;\"> 5.03409</td><td style=\"text-align: right;\">               13.68</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           51.6632</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8646450\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_08-57-14\n",
      "  done: false\n",
      "  episode_len_mean: 51.90155440414508\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.549999999999994\n",
      "  episode_reward_mean: 5.486476683937828\n",
      "  episode_reward_min: -0.46000000000000024\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 166637\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.041433014592014\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015047141012118367\n",
      "          policy_loss: -0.0702596405528859\n",
      "          total_loss: 0.08416641784493754\n",
      "          vf_explained_var: 0.9544991254806519\n",
      "          vf_loss: 0.1405611194131604\n",
      "    num_agent_steps_sampled: 8646450\n",
      "    num_agent_steps_trained: 8646450\n",
      "    num_steps_sampled: 8646450\n",
      "    num_steps_trained: 8646450\n",
      "  iterations_since_restore: 525\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.20376411543286\n",
      "    ram_util_percent: 53.2966122961104\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279180587556102\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.615054772751584\n",
      "    mean_inference_ms: 19.513031810695622\n",
      "    mean_raw_obs_processing_ms: 3.328306740801581\n",
      "  time_since_restore: 288084.5357005596\n",
      "  time_this_iter_s: 558.9309642314911\n",
      "  time_total_s: 482901.8992860317\n",
      "  timers:\n",
      "    learn_throughput: 28.256\n",
      "    learn_time_ms: 353769.376\n",
      "    load_throughput: 88593.089\n",
      "    load_time_ms: 112.83\n",
      "    sample_throughput: 50.053\n",
      "    sample_time_ms: 199710.074\n",
      "    update_time_ms: 6.412\n",
      "  timestamp: 1637744234\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8646450\n",
      "  training_iteration: 925\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   925</td><td style=\"text-align: right;\">          482902</td><td style=\"text-align: right;\">8646450</td><td style=\"text-align: right;\"> 5.48648</td><td style=\"text-align: right;\">               17.55</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           51.9016</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8656446\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_09-06-14\n",
      "  done: false\n",
      "  episode_len_mean: 52.702127659574465\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.51\n",
      "  episode_reward_mean: 5.4465425531914935\n",
      "  episode_reward_min: -0.4300000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 166825\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.051307038202822\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014884141054086706\n",
      "          policy_loss: -0.06661567018650878\n",
      "          total_loss: 0.08675053569253995\n",
      "          vf_explained_var: 0.9406800866127014\n",
      "          vf_loss: 0.1399713419963153\n",
      "    num_agent_steps_sampled: 8656446\n",
      "    num_agent_steps_trained: 8656446\n",
      "    num_steps_sampled: 8656446\n",
      "    num_steps_trained: 8656446\n",
      "  iterations_since_restore: 526\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02311688311688\n",
      "    ram_util_percent: 52.984805194805176\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527954849088365\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.618467321364715\n",
      "    mean_inference_ms: 19.51462159473874\n",
      "    mean_raw_obs_processing_ms: 3.3249256534777887\n",
      "  time_since_restore: 288624.5169093609\n",
      "  time_this_iter_s: 539.9812088012695\n",
      "  time_total_s: 483441.880494833\n",
      "  timers:\n",
      "    learn_throughput: 28.255\n",
      "    learn_time_ms: 353779.714\n",
      "    load_throughput: 88758.491\n",
      "    load_time_ms: 112.62\n",
      "    sample_throughput: 50.344\n",
      "    sample_time_ms: 198552.401\n",
      "    update_time_ms: 6.993\n",
      "  timestamp: 1637744774\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8656446\n",
      "  training_iteration: 926\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   926</td><td style=\"text-align: right;\">          483442</td><td style=\"text-align: right;\">8656446</td><td style=\"text-align: right;\"> 5.44654</td><td style=\"text-align: right;\">               17.51</td><td style=\"text-align: right;\">               -0.43</td><td style=\"text-align: right;\">           52.7021</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8666442\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_09-15-35\n",
      "  done: false\n",
      "  episode_len_mean: 53.12169312169312\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.610000000000007\n",
      "  episode_reward_mean: 5.178994708994713\n",
      "  episode_reward_min: -0.6500000000000004\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 167014\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0484565265686157\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014933308734971113\n",
      "          policy_loss: -0.07117930504537948\n",
      "          total_loss: 0.08728353745816814\n",
      "          vf_explained_var: 0.9397360682487488\n",
      "          vf_loss: 0.14492746199421344\n",
      "    num_agent_steps_sampled: 8666442\n",
      "    num_agent_steps_trained: 8666442\n",
      "    num_steps_sampled: 8666442\n",
      "    num_steps_trained: 8666442\n",
      "  iterations_since_restore: 527\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81423220973782\n",
      "    ram_util_percent: 53.152184769038705\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278746923819239\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.620612963984794\n",
      "    mean_inference_ms: 19.514439613404267\n",
      "    mean_raw_obs_processing_ms: 3.325632454002002\n",
      "  time_since_restore: 289185.6913983822\n",
      "  time_this_iter_s: 561.1744890213013\n",
      "  time_total_s: 484003.0549838543\n",
      "  timers:\n",
      "    learn_throughput: 28.259\n",
      "    learn_time_ms: 353728.437\n",
      "    load_throughput: 88993.219\n",
      "    load_time_ms: 112.323\n",
      "    sample_throughput: 50.245\n",
      "    sample_time_ms: 198946.42\n",
      "    update_time_ms: 6.954\n",
      "  timestamp: 1637745335\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8666442\n",
      "  training_iteration: 927\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   927</td><td style=\"text-align: right;\">          484003</td><td style=\"text-align: right;\">8666442</td><td style=\"text-align: right;\"> 5.17899</td><td style=\"text-align: right;\">               13.61</td><td style=\"text-align: right;\">               -0.65</td><td style=\"text-align: right;\">           53.1217</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8676438\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_09-24-47\n",
      "  done: false\n",
      "  episode_len_mean: 53.58064516129032\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.520000000000008\n",
      "  episode_reward_mean: 5.158602150537639\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 167200\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0465075590763706\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014915408040421442\n",
      "          policy_loss: -0.06885753989984196\n",
      "          total_loss: 0.08473659081955337\n",
      "          vf_explained_var: 0.9231622815132141\n",
      "          vf_loss: 0.1400800419512231\n",
      "    num_agent_steps_sampled: 8676438\n",
      "    num_agent_steps_trained: 8676438\n",
      "    num_steps_sampled: 8676438\n",
      "    num_steps_trained: 8676438\n",
      "  iterations_since_restore: 528\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.823125794155\n",
      "    ram_util_percent: 53.10622617534942\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052788613300271965\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.622811769054746\n",
      "    mean_inference_ms: 19.51417659397046\n",
      "    mean_raw_obs_processing_ms: 3.3254474303693415\n",
      "  time_since_restore: 289737.42620301247\n",
      "  time_this_iter_s: 551.7348046302795\n",
      "  time_total_s: 484554.7897884846\n",
      "  timers:\n",
      "    learn_throughput: 28.268\n",
      "    learn_time_ms: 353612.796\n",
      "    load_throughput: 88778.226\n",
      "    load_time_ms: 112.595\n",
      "    sample_throughput: 50.226\n",
      "    sample_time_ms: 199022.073\n",
      "    update_time_ms: 6.937\n",
      "  timestamp: 1637745887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8676438\n",
      "  training_iteration: 928\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   928</td><td style=\"text-align: right;\">          484555</td><td style=\"text-align: right;\">8676438</td><td style=\"text-align: right;\">  5.1586</td><td style=\"text-align: right;\">               15.52</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           53.5806</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8686434\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_09-33-57\n",
      "  done: false\n",
      "  episode_len_mean: 53.66129032258065\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000007\n",
      "  episode_reward_mean: 5.351935483870972\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 167386\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0181697778194305\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015110607464650821\n",
      "          policy_loss: -0.06186889727112021\n",
      "          total_loss: 0.09674146885273699\n",
      "          vf_explained_var: 0.9499325156211853\n",
      "          vf_loss: 0.14436821063651317\n",
      "    num_agent_steps_sampled: 8686434\n",
      "    num_agent_steps_trained: 8686434\n",
      "    num_steps_sampled: 8686434\n",
      "    num_steps_trained: 8686434\n",
      "  iterations_since_restore: 529\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.89336734693877\n",
      "    ram_util_percent: 53.089285714285715\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527937511321045\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.62426707053058\n",
      "    mean_inference_ms: 19.514311373004343\n",
      "    mean_raw_obs_processing_ms: 3.3250465500495356\n",
      "  time_since_restore: 290286.9877040386\n",
      "  time_this_iter_s: 549.5615010261536\n",
      "  time_total_s: 485104.3512895107\n",
      "  timers:\n",
      "    learn_throughput: 28.271\n",
      "    learn_time_ms: 353573.19\n",
      "    load_throughput: 89028.481\n",
      "    load_time_ms: 112.279\n",
      "    sample_throughput: 50.648\n",
      "    sample_time_ms: 197361.175\n",
      "    update_time_ms: 6.958\n",
      "  timestamp: 1637746437\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8686434\n",
      "  training_iteration: 929\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   929</td><td style=\"text-align: right;\">          485104</td><td style=\"text-align: right;\">8686434</td><td style=\"text-align: right;\"> 5.35194</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.6613</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8696430\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_09-42-58\n",
      "  done: false\n",
      "  episode_len_mean: 53.80213903743316\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.570000000000006\n",
      "  episode_reward_mean: 5.3618716577540155\n",
      "  episode_reward_min: -0.4600000000000004\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 167573\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0327986125247066\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014851620795241188\n",
      "          policy_loss: -0.06781251135814517\n",
      "          total_loss: 0.08042769005815391\n",
      "          vf_explained_var: 0.9403865337371826\n",
      "          vf_loss: 0.13473433816579197\n",
      "    num_agent_steps_sampled: 8696430\n",
      "    num_agent_steps_trained: 8696430\n",
      "    num_steps_sampled: 8696430\n",
      "    num_steps_trained: 8696430\n",
      "  iterations_since_restore: 530\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.19844760672704\n",
      "    ram_util_percent: 52.90892626131954\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278784980670891\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.626819061836002\n",
      "    mean_inference_ms: 19.515257165852347\n",
      "    mean_raw_obs_processing_ms: 3.32068425594717\n",
      "  time_since_restore: 290828.33796572685\n",
      "  time_this_iter_s: 541.3502616882324\n",
      "  time_total_s: 485645.70155119896\n",
      "  timers:\n",
      "    learn_throughput: 28.266\n",
      "    learn_time_ms: 353640.0\n",
      "    load_throughput: 88868.042\n",
      "    load_time_ms: 112.481\n",
      "    sample_throughput: 50.834\n",
      "    sample_time_ms: 196638.49\n",
      "    update_time_ms: 6.701\n",
      "  timestamp: 1637746978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8696430\n",
      "  training_iteration: 930\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   930</td><td style=\"text-align: right;\">          485646</td><td style=\"text-align: right;\">8696430</td><td style=\"text-align: right;\"> 5.36187</td><td style=\"text-align: right;\">               15.57</td><td style=\"text-align: right;\">               -0.46</td><td style=\"text-align: right;\">           53.8021</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8706426\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_09-52-12\n",
      "  done: false\n",
      "  episode_len_mean: 53.04761904761905\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.640000000000006\n",
      "  episode_reward_mean: 4.947671957671962\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 167762\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.058539793553601\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014418267582683043\n",
      "          policy_loss: -0.06867907171269716\n",
      "          total_loss: 0.08421755664613487\n",
      "          vf_explained_var: 0.9401063323020935\n",
      "          vf_loss: 0.14063541004714747\n",
      "    num_agent_steps_sampled: 8706426\n",
      "    num_agent_steps_trained: 8706426\n",
      "    num_steps_sampled: 8706426\n",
      "    num_steps_trained: 8706426\n",
      "  iterations_since_restore: 531\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77101265822783\n",
      "    ram_util_percent: 53.427341772151905\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052791487759605134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.628042370398955\n",
      "    mean_inference_ms: 19.51577134361528\n",
      "    mean_raw_obs_processing_ms: 3.3205359049362815\n",
      "  time_since_restore: 291382.0247476101\n",
      "  time_this_iter_s: 553.6867818832397\n",
      "  time_total_s: 486199.3883330822\n",
      "  timers:\n",
      "    learn_throughput: 28.27\n",
      "    learn_time_ms: 353593.683\n",
      "    load_throughput: 89052.989\n",
      "    load_time_ms: 112.248\n",
      "    sample_throughput: 50.389\n",
      "    sample_time_ms: 198377.087\n",
      "    update_time_ms: 6.881\n",
      "  timestamp: 1637747532\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8706426\n",
      "  training_iteration: 931\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   931</td><td style=\"text-align: right;\">          486199</td><td style=\"text-align: right;\">8706426</td><td style=\"text-align: right;\"> 4.94767</td><td style=\"text-align: right;\">               15.64</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.0476</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8716422\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_10-01-25\n",
      "  done: false\n",
      "  episode_len_mean: 53.75675675675676\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.480000000000008\n",
      "  episode_reward_mean: 4.7461621621621655\n",
      "  episode_reward_min: -0.5900000000000003\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 167947\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.065685363107896\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014200560812869365\n",
      "          policy_loss: -0.07177725074408851\n",
      "          total_loss: 0.052053347042610026\n",
      "          vf_explained_var: 0.9550884366035461\n",
      "          vf_loss: 0.11213679758085679\n",
      "    num_agent_steps_sampled: 8716422\n",
      "    num_agent_steps_trained: 8716422\n",
      "    num_steps_sampled: 8716422\n",
      "    num_steps_trained: 8716422\n",
      "  iterations_since_restore: 532\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.36463878326995\n",
      "    ram_util_percent: 53.79036755386566\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278932510133527\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.628585640821406\n",
      "    mean_inference_ms: 19.515192109687312\n",
      "    mean_raw_obs_processing_ms: 3.3225652282735028\n",
      "  time_since_restore: 291935.3345515728\n",
      "  time_this_iter_s: 553.3098039627075\n",
      "  time_total_s: 486752.6981370449\n",
      "  timers:\n",
      "    learn_throughput: 28.272\n",
      "    learn_time_ms: 353565.312\n",
      "    load_throughput: 88984.039\n",
      "    load_time_ms: 112.335\n",
      "    sample_throughput: 50.658\n",
      "    sample_time_ms: 197324.953\n",
      "    update_time_ms: 6.582\n",
      "  timestamp: 1637748085\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8716422\n",
      "  training_iteration: 932\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   932</td><td style=\"text-align: right;\">          486753</td><td style=\"text-align: right;\">8716422</td><td style=\"text-align: right;\"> 4.74616</td><td style=\"text-align: right;\">               15.48</td><td style=\"text-align: right;\">               -0.59</td><td style=\"text-align: right;\">           53.7568</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8726418\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_10-10-37\n",
      "  done: false\n",
      "  episode_len_mean: 51.86010362694301\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.700000000000005\n",
      "  episode_reward_mean: 5.261658031088087\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 168140\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.033414740064537\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015049322621831254\n",
      "          policy_loss: -0.06790852050727705\n",
      "          total_loss: 0.10274876439997675\n",
      "          vf_explained_var: 0.928893506526947\n",
      "          vf_loss: 0.1567071941634453\n",
      "    num_agent_steps_sampled: 8726418\n",
      "    num_agent_steps_trained: 8726418\n",
      "    num_steps_sampled: 8726418\n",
      "    num_steps_trained: 8726418\n",
      "  iterations_since_restore: 533\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81702668360865\n",
      "    ram_util_percent: 53.8994917407878\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279397067573691\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.630462408653376\n",
      "    mean_inference_ms: 19.517894988894927\n",
      "    mean_raw_obs_processing_ms: 3.3227590992508538\n",
      "  time_since_restore: 292486.68171334267\n",
      "  time_this_iter_s: 551.347161769867\n",
      "  time_total_s: 487304.0452988148\n",
      "  timers:\n",
      "    learn_throughput: 28.274\n",
      "    learn_time_ms: 353538.846\n",
      "    load_throughput: 89294.432\n",
      "    load_time_ms: 111.944\n",
      "    sample_throughput: 50.232\n",
      "    sample_time_ms: 198997.8\n",
      "    update_time_ms: 6.351\n",
      "  timestamp: 1637748637\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8726418\n",
      "  training_iteration: 933\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   933</td><td style=\"text-align: right;\">          487304</td><td style=\"text-align: right;\">8726418</td><td style=\"text-align: right;\"> 5.26166</td><td style=\"text-align: right;\">                13.7</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           51.8601</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8736414\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_10-19-31\n",
      "  done: false\n",
      "  episode_len_mean: 53.22872340425532\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.639999999999986\n",
      "  episode_reward_mean: 5.684893617021282\n",
      "  episode_reward_min: -0.47000000000000025\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 168328\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.01036161083773\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015606693479719594\n",
      "          policy_loss: -0.06744301604463164\n",
      "          total_loss: 0.12241865087832692\n",
      "          vf_explained_var: 0.9403895735740662\n",
      "          vf_loss: 0.1744112839982153\n",
      "    num_agent_steps_sampled: 8736414\n",
      "    num_agent_steps_trained: 8736414\n",
      "    num_steps_sampled: 8736414\n",
      "    num_steps_trained: 8736414\n",
      "  iterations_since_restore: 534\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13175853018375\n",
      "    ram_util_percent: 53.71561679790025\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278551037952438\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.630286500083688\n",
      "    mean_inference_ms: 19.516249886870558\n",
      "    mean_raw_obs_processing_ms: 3.318214407124719\n",
      "  time_since_restore: 293020.9740021229\n",
      "  time_this_iter_s: 534.2922887802124\n",
      "  time_total_s: 487838.337587595\n",
      "  timers:\n",
      "    learn_throughput: 28.267\n",
      "    learn_time_ms: 353625.254\n",
      "    load_throughput: 89270.799\n",
      "    load_time_ms: 111.974\n",
      "    sample_throughput: 51.057\n",
      "    sample_time_ms: 195780.825\n",
      "    update_time_ms: 6.855\n",
      "  timestamp: 1637749171\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8736414\n",
      "  training_iteration: 934\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   934</td><td style=\"text-align: right;\">          487838</td><td style=\"text-align: right;\">8736414</td><td style=\"text-align: right;\"> 5.68489</td><td style=\"text-align: right;\">               19.64</td><td style=\"text-align: right;\">               -0.47</td><td style=\"text-align: right;\">           53.2287</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8746410\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_10-28-38\n",
      "  done: false\n",
      "  episode_len_mean: 53.3048128342246\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.660000000000004\n",
      "  episode_reward_mean: 5.341336898395727\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 168515\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0549057632086267\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0151469578454486\n",
      "          policy_loss: -0.06481853074537172\n",
      "          total_loss: 0.09585807082571939\n",
      "          vf_explained_var: 0.9358888864517212\n",
      "          vf_loss: 0.14671899388005666\n",
      "    num_agent_steps_sampled: 8746410\n",
      "    num_agent_steps_trained: 8746410\n",
      "    num_steps_sampled: 8746410\n",
      "    num_steps_trained: 8746410\n",
      "  iterations_since_restore: 535\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7724358974359\n",
      "    ram_util_percent: 53.530641025641025\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052785844650668594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.6295198070087\n",
      "    mean_inference_ms: 19.515693664880853\n",
      "    mean_raw_obs_processing_ms: 3.3170523679768156\n",
      "  time_since_restore: 293567.75204205513\n",
      "  time_this_iter_s: 546.778039932251\n",
      "  time_total_s: 488385.11562752724\n",
      "  timers:\n",
      "    learn_throughput: 28.264\n",
      "    learn_time_ms: 353666.643\n",
      "    load_throughput: 89310.239\n",
      "    load_time_ms: 111.924\n",
      "    sample_throughput: 51.387\n",
      "    sample_time_ms: 194524.614\n",
      "    update_time_ms: 6.074\n",
      "  timestamp: 1637749718\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8746410\n",
      "  training_iteration: 935\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   935</td><td style=\"text-align: right;\">          488385</td><td style=\"text-align: right;\">8746410</td><td style=\"text-align: right;\"> 5.34134</td><td style=\"text-align: right;\">               13.66</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           53.3048</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8756406\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_10-37-46\n",
      "  done: false\n",
      "  episode_len_mean: 53.04255319148936\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.620000000000006\n",
      "  episode_reward_mean: 4.950904255319153\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 168703\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0295978403235058\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014081008270327518\n",
      "          policy_loss: -0.06722905196268887\n",
      "          total_loss: 0.088271481577709\n",
      "          vf_explained_var: 0.9331752061843872\n",
      "          vf_loss: 0.14371821351843067\n",
      "    num_agent_steps_sampled: 8756406\n",
      "    num_agent_steps_trained: 8756406\n",
      "    num_steps_sampled: 8756406\n",
      "    num_steps_trained: 8756406\n",
      "  iterations_since_restore: 536\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69833759590792\n",
      "    ram_util_percent: 53.87289002557544\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279982706161491\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.63007253085828\n",
      "    mean_inference_ms: 19.519707982977142\n",
      "    mean_raw_obs_processing_ms: 3.3187500986863308\n",
      "  time_since_restore: 294115.6562087536\n",
      "  time_this_iter_s: 547.9041666984558\n",
      "  time_total_s: 488933.0197942257\n",
      "  timers:\n",
      "    learn_throughput: 28.257\n",
      "    learn_time_ms: 353757.161\n",
      "    load_throughput: 89313.758\n",
      "    load_time_ms: 111.92\n",
      "    sample_throughput: 51.202\n",
      "    sample_time_ms: 195226.754\n",
      "    update_time_ms: 5.321\n",
      "  timestamp: 1637750266\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8756406\n",
      "  training_iteration: 936\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   936</td><td style=\"text-align: right;\">          488933</td><td style=\"text-align: right;\">8756406</td><td style=\"text-align: right;\">  4.9509</td><td style=\"text-align: right;\">               13.62</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           53.0426</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8766402\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_10-46-54\n",
      "  done: false\n",
      "  episode_len_mean: 52.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.500000000000009\n",
      "  episode_reward_mean: 5.235421052631583\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 168893\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0424254986895134\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013576294882225561\n",
      "          policy_loss: -0.07117231621709377\n",
      "          total_loss: 0.06473129271897773\n",
      "          vf_explained_var: 0.9461368918418884\n",
      "          vf_loss: 0.12539936761749557\n",
      "    num_agent_steps_sampled: 8766402\n",
      "    num_agent_steps_trained: 8766402\n",
      "    num_steps_sampled: 8766402\n",
      "    num_steps_trained: 8766402\n",
      "  iterations_since_restore: 537\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75588235294117\n",
      "    ram_util_percent: 53.70754475703323\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052785094787738865\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.62857302033091\n",
      "    mean_inference_ms: 19.51600032708137\n",
      "    mean_raw_obs_processing_ms: 3.3159835829362656\n",
      "  time_since_restore: 294663.92730236053\n",
      "  time_this_iter_s: 548.2710936069489\n",
      "  time_total_s: 489481.29088783264\n",
      "  timers:\n",
      "    learn_throughput: 28.249\n",
      "    learn_time_ms: 353851.562\n",
      "    load_throughput: 89216.432\n",
      "    load_time_ms: 112.042\n",
      "    sample_throughput: 51.568\n",
      "    sample_time_ms: 193841.697\n",
      "    update_time_ms: 5.321\n",
      "  timestamp: 1637750814\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8766402\n",
      "  training_iteration: 937\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   937</td><td style=\"text-align: right;\">          489481</td><td style=\"text-align: right;\">8766402</td><td style=\"text-align: right;\"> 5.23542</td><td style=\"text-align: right;\">                15.5</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">              52.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8776398\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_10-55-46\n",
      "  done: false\n",
      "  episode_len_mean: 53.79144385026738\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.660000000000005\n",
      "  episode_reward_mean: 5.753636363636367\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 169080\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0108223009540374\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014741530993259878\n",
      "          policy_loss: -0.06237090428088463\n",
      "          total_loss: 0.10063434059550246\n",
      "          vf_explained_var: 0.9577852487564087\n",
      "          vf_loss: 0.14953041637361228\n",
      "    num_agent_steps_sampled: 8776398\n",
      "    num_agent_steps_trained: 8776398\n",
      "    num_steps_sampled: 8776398\n",
      "    num_steps_trained: 8776398\n",
      "  iterations_since_restore: 538\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9965744400527\n",
      "    ram_util_percent: 53.41791831357048\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279034032053725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.62908697990289\n",
      "    mean_inference_ms: 19.518362825283727\n",
      "    mean_raw_obs_processing_ms: 3.31277264305235\n",
      "  time_since_restore: 295195.4610567093\n",
      "  time_this_iter_s: 531.5337543487549\n",
      "  time_total_s: 490012.8246421814\n",
      "  timers:\n",
      "    learn_throughput: 28.236\n",
      "    learn_time_ms: 354021.643\n",
      "    load_throughput: 89277.11\n",
      "    load_time_ms: 111.966\n",
      "    sample_throughput: 52.157\n",
      "    sample_time_ms: 191651.917\n",
      "    update_time_ms: 5.365\n",
      "  timestamp: 1637751346\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8776398\n",
      "  training_iteration: 938\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   938</td><td style=\"text-align: right;\">          490013</td><td style=\"text-align: right;\">8776398</td><td style=\"text-align: right;\"> 5.75364</td><td style=\"text-align: right;\">               15.66</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           53.7914</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8786394\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_11-04-52\n",
      "  done: false\n",
      "  episode_len_mean: 54.16847826086956\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.530000000000008\n",
      "  episode_reward_mean: 5.37239130434783\n",
      "  episode_reward_min: -0.5800000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 169264\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0202962168009884\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014469293503120166\n",
      "          policy_loss: -0.06839719939594782\n",
      "          total_loss: 0.09367054268477476\n",
      "          vf_explained_var: 0.9401743412017822\n",
      "          vf_loss: 0.14930784476689066\n",
      "    num_agent_steps_sampled: 8786394\n",
      "    num_agent_steps_trained: 8786394\n",
      "    num_steps_sampled: 8786394\n",
      "    num_steps_trained: 8786394\n",
      "  iterations_since_restore: 539\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.83812580231064\n",
      "    ram_util_percent: 53.72092426187419\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279619933269975\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.62754265925951\n",
      "    mean_inference_ms: 19.51953572366978\n",
      "    mean_raw_obs_processing_ms: 3.3161430801736707\n",
      "  time_since_restore: 295741.49022459984\n",
      "  time_this_iter_s: 546.0291678905487\n",
      "  time_total_s: 490558.85381007195\n",
      "  timers:\n",
      "    learn_throughput: 28.224\n",
      "    learn_time_ms: 354165.514\n",
      "    load_throughput: 88950.567\n",
      "    load_time_ms: 112.377\n",
      "    sample_throughput: 52.293\n",
      "    sample_time_ms: 191154.902\n",
      "    update_time_ms: 5.044\n",
      "  timestamp: 1637751892\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8786394\n",
      "  training_iteration: 939\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   939</td><td style=\"text-align: right;\">          490559</td><td style=\"text-align: right;\">8786394</td><td style=\"text-align: right;\"> 5.37239</td><td style=\"text-align: right;\">               15.53</td><td style=\"text-align: right;\">               -0.58</td><td style=\"text-align: right;\">           54.1685</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8796390\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_11-13-57\n",
      "  done: false\n",
      "  episode_len_mean: 53.648648648648646\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.630000000000006\n",
      "  episode_reward_mean: 5.165837837837842\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 185\n",
      "  episodes_total: 169449\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.029232506292412\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014903139971172291\n",
      "          policy_loss: -0.06990559217753824\n",
      "          total_loss: 0.10258941048882242\n",
      "          vf_explained_var: 0.9347962141036987\n",
      "          vf_loss: 0.1588361104149895\n",
      "    num_agent_steps_sampled: 8796390\n",
      "    num_agent_steps_trained: 8796390\n",
      "    num_steps_sampled: 8796390\n",
      "    num_steps_trained: 8796390\n",
      "  iterations_since_restore: 540\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81568123393318\n",
      "    ram_util_percent: 53.421336760925456\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052783256531497576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.625684566444278\n",
      "    mean_inference_ms: 19.517998496865047\n",
      "    mean_raw_obs_processing_ms: 3.3145189890526914\n",
      "  time_since_restore: 296287.0463385582\n",
      "  time_this_iter_s: 545.5561139583588\n",
      "  time_total_s: 491104.4099240303\n",
      "  timers:\n",
      "    learn_throughput: 28.223\n",
      "    learn_time_ms: 354182.308\n",
      "    load_throughput: 89096.534\n",
      "    load_time_ms: 112.193\n",
      "    sample_throughput: 52.182\n",
      "    sample_time_ms: 191558.938\n",
      "    update_time_ms: 4.985\n",
      "  timestamp: 1637752437\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8796390\n",
      "  training_iteration: 940\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   940</td><td style=\"text-align: right;\">          491104</td><td style=\"text-align: right;\">8796390</td><td style=\"text-align: right;\"> 5.16584</td><td style=\"text-align: right;\">               15.63</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           53.6486</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8806386\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_11-22-50\n",
      "  done: false\n",
      "  episode_len_mean: 53.83870967741935\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.53999999999997\n",
      "  episode_reward_mean: 5.314946236559143\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 169635\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.040335991200673\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014742112410938368\n",
      "          policy_loss: -0.0622197135543067\n",
      "          total_loss: 0.11557726676629138\n",
      "          vf_explained_var: 0.9375296831130981\n",
      "          vf_loss: 0.16461596428715888\n",
      "    num_agent_steps_sampled: 8806386\n",
      "    num_agent_steps_trained: 8806386\n",
      "    num_steps_sampled: 8806386\n",
      "    num_steps_trained: 8806386\n",
      "  iterations_since_restore: 541\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.0313157894737\n",
      "    ram_util_percent: 52.84578947368421\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279035676014507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.626317635193207\n",
      "    mean_inference_ms: 19.519601041858714\n",
      "    mean_raw_obs_processing_ms: 3.3111635559622625\n",
      "  time_since_restore: 296819.735247612\n",
      "  time_this_iter_s: 532.6889090538025\n",
      "  time_total_s: 491637.0988330841\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354300.798\n",
      "    load_throughput: 88975.202\n",
      "    load_time_ms: 112.346\n",
      "    sample_throughput: 52.794\n",
      "    sample_time_ms: 189340.306\n",
      "    update_time_ms: 5.209\n",
      "  timestamp: 1637752970\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8806386\n",
      "  training_iteration: 941\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   941</td><td style=\"text-align: right;\">          491637</td><td style=\"text-align: right;\">8806386</td><td style=\"text-align: right;\"> 5.31495</td><td style=\"text-align: right;\">               19.54</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.8387</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8816382\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_11-31-58\n",
      "  done: false\n",
      "  episode_len_mean: 53.5668449197861\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.530000000000008\n",
      "  episode_reward_mean: 5.266417112299469\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 169822\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0320816693296395\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015277546177560464\n",
      "          policy_loss: -0.06451864817368827\n",
      "          total_loss: 0.09244736248377497\n",
      "          vf_explained_var: 0.9422403573989868\n",
      "          vf_loss: 0.14248266633914178\n",
      "    num_agent_steps_sampled: 8816382\n",
      "    num_agent_steps_trained: 8816382\n",
      "    num_steps_sampled: 8816382\n",
      "    num_steps_trained: 8816382\n",
      "  iterations_since_restore: 542\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.71470588235293\n",
      "    ram_util_percent: 52.92749360613812\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05279999540873578\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.624502991737877\n",
      "    mean_inference_ms: 19.51835513053634\n",
      "    mean_raw_obs_processing_ms: 3.3113587235212614\n",
      "  time_since_restore: 297367.62169361115\n",
      "  time_this_iter_s: 547.8864459991455\n",
      "  time_total_s: 492184.98527908325\n",
      "  timers:\n",
      "    learn_throughput: 28.205\n",
      "    learn_time_ms: 354406.702\n",
      "    load_throughput: 89013.02\n",
      "    load_time_ms: 112.298\n",
      "    sample_throughput: 52.975\n",
      "    sample_time_ms: 188691.957\n",
      "    update_time_ms: 5.376\n",
      "  timestamp: 1637753518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8816382\n",
      "  training_iteration: 942\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   942</td><td style=\"text-align: right;\">          492185</td><td style=\"text-align: right;\">8816382</td><td style=\"text-align: right;\"> 5.26642</td><td style=\"text-align: right;\">               15.53</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           53.5668</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8826378\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_11-41-16\n",
      "  done: false\n",
      "  episode_len_mean: 54.13586956521739\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.60000000000001\n",
      "  episode_reward_mean: 4.9370108695652215\n",
      "  episode_reward_min: -0.5600000000000003\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 170006\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.056452109655702\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015266843939636602\n",
      "          policy_loss: -0.06133005406777538\n",
      "          total_loss: 0.09107489832435073\n",
      "          vf_explained_var: 0.9520068764686584\n",
      "          vf_loss: 0.13818969345365437\n",
      "    num_agent_steps_sampled: 8826378\n",
      "    num_agent_steps_trained: 8826378\n",
      "    num_steps_sampled: 8826378\n",
      "    num_steps_trained: 8826378\n",
      "  iterations_since_restore: 543\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.59497487437187\n",
      "    ram_util_percent: 53.47311557788944\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278563664654901\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.622831942755877\n",
      "    mean_inference_ms: 19.51940575685096\n",
      "    mean_raw_obs_processing_ms: 3.312518371168727\n",
      "  time_since_restore: 297925.5457060337\n",
      "  time_this_iter_s: 557.9240124225616\n",
      "  time_total_s: 492742.9092915058\n",
      "  timers:\n",
      "    learn_throughput: 28.194\n",
      "    learn_time_ms: 354542.213\n",
      "    load_throughput: 89007.407\n",
      "    load_time_ms: 112.305\n",
      "    sample_throughput: 52.829\n",
      "    sample_time_ms: 189212.908\n",
      "    update_time_ms: 6.556\n",
      "  timestamp: 1637754076\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8826378\n",
      "  training_iteration: 943\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   943</td><td style=\"text-align: right;\">          492743</td><td style=\"text-align: right;\">8826378</td><td style=\"text-align: right;\"> 4.93701</td><td style=\"text-align: right;\">                17.6</td><td style=\"text-align: right;\">               -0.56</td><td style=\"text-align: right;\">           54.1359</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8836374\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_11-50-20\n",
      "  done: false\n",
      "  episode_len_mean: 54.09139784946237\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.680000000000005\n",
      "  episode_reward_mean: 5.600376344086025\n",
      "  episode_reward_min: -0.5700000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 170192\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0316638193934797\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01443255762212209\n",
      "          policy_loss: -0.06345716875887639\n",
      "          total_loss: 0.10518507568755217\n",
      "          vf_explained_var: 0.934119462966919\n",
      "          vf_loss: 0.15607971147864114\n",
      "    num_agent_steps_sampled: 8836374\n",
      "    num_agent_steps_trained: 8836374\n",
      "    num_steps_sampled: 8836374\n",
      "    num_steps_trained: 8836374\n",
      "  iterations_since_restore: 544\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.83943298969074\n",
      "    ram_util_percent: 53.10244845360825\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527896007736163\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.62082332557696\n",
      "    mean_inference_ms: 19.519418819926198\n",
      "    mean_raw_obs_processing_ms: 3.3130943430854796\n",
      "  time_since_restore: 298469.5293495655\n",
      "  time_this_iter_s: 543.9836435317993\n",
      "  time_total_s: 493286.8929350376\n",
      "  timers:\n",
      "    learn_throughput: 28.193\n",
      "    learn_time_ms: 354552.433\n",
      "    load_throughput: 89673.367\n",
      "    load_time_ms: 111.471\n",
      "    sample_throughput: 52.563\n",
      "    sample_time_ms: 190173.131\n",
      "    update_time_ms: 6.343\n",
      "  timestamp: 1637754620\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8836374\n",
      "  training_iteration: 944\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   944</td><td style=\"text-align: right;\">          493287</td><td style=\"text-align: right;\">8836374</td><td style=\"text-align: right;\"> 5.60038</td><td style=\"text-align: right;\">               15.68</td><td style=\"text-align: right;\">               -0.57</td><td style=\"text-align: right;\">           54.0914</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8846370\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_11-59-11\n",
      "  done: false\n",
      "  episode_len_mean: 54.53551912568306\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.590000000000005\n",
      "  episode_reward_mean: 5.302568306010933\n",
      "  episode_reward_min: -0.6500000000000004\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 170375\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0291319528497365\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01416140419214594\n",
      "          policy_loss: -0.06309903728795754\n",
      "          total_loss: 0.08829672519666118\n",
      "          vf_explained_var: 0.9324776530265808\n",
      "          vf_loss: 0.13942563204332273\n",
      "    num_agent_steps_sampled: 8846370\n",
      "    num_agent_steps_trained: 8846370\n",
      "    num_steps_sampled: 8846370\n",
      "    num_steps_trained: 8846370\n",
      "  iterations_since_restore: 545\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.92915567282323\n",
      "    ram_util_percent: 53.13205804749341\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278040640925239\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.618415891909187\n",
      "    mean_inference_ms: 19.516554357978503\n",
      "    mean_raw_obs_processing_ms: 3.308324879291232\n",
      "  time_since_restore: 299001.00243783\n",
      "  time_this_iter_s: 531.4730882644653\n",
      "  time_total_s: 493818.3660233021\n",
      "  timers:\n",
      "    learn_throughput: 28.19\n",
      "    learn_time_ms: 354594.004\n",
      "    load_throughput: 89544.359\n",
      "    load_time_ms: 111.632\n",
      "    sample_throughput: 53.001\n",
      "    sample_time_ms: 188600.895\n",
      "    update_time_ms: 6.431\n",
      "  timestamp: 1637755151\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8846370\n",
      "  training_iteration: 945\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   945</td><td style=\"text-align: right;\">          493818</td><td style=\"text-align: right;\">8846370</td><td style=\"text-align: right;\"> 5.30257</td><td style=\"text-align: right;\">               15.59</td><td style=\"text-align: right;\">               -0.65</td><td style=\"text-align: right;\">           54.5355</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8856366\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_12-08-31\n",
      "  done: false\n",
      "  episode_len_mean: 53.03191489361702\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.490000000000007\n",
      "  episode_reward_mean: 5.144574468085111\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 188\n",
      "  episodes_total: 170563\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.067264111238311\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014719189716056538\n",
      "          policy_loss: -0.06774465348127968\n",
      "          total_loss: 0.09868789287723496\n",
      "          vf_explained_var: 0.9321010708808899\n",
      "          vf_loss: 0.15357303215764898\n",
      "    num_agent_steps_sampled: 8856366\n",
      "    num_agent_steps_trained: 8856366\n",
      "    num_steps_sampled: 8856366\n",
      "    num_steps_trained: 8856366\n",
      "  iterations_since_restore: 546\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.65219023779726\n",
      "    ram_util_percent: 53.61489361702127\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05277514685089655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.61877531834645\n",
      "    mean_inference_ms: 19.51931498424218\n",
      "    mean_raw_obs_processing_ms: 3.310658563872629\n",
      "  time_since_restore: 299561.0516793728\n",
      "  time_this_iter_s: 560.0492415428162\n",
      "  time_total_s: 494378.4152648449\n",
      "  timers:\n",
      "    learn_throughput: 28.189\n",
      "    learn_time_ms: 354603.124\n",
      "    load_throughput: 89464.662\n",
      "    load_time_ms: 111.731\n",
      "    sample_throughput: 52.664\n",
      "    sample_time_ms: 189806.138\n",
      "    update_time_ms: 6.789\n",
      "  timestamp: 1637755711\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8856366\n",
      "  training_iteration: 946\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   946</td><td style=\"text-align: right;\">          494378</td><td style=\"text-align: right;\">8856366</td><td style=\"text-align: right;\"> 5.14457</td><td style=\"text-align: right;\">               13.49</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.0319</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8866362\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_12-17-36\n",
      "  done: false\n",
      "  episode_len_mean: 53.36363636363637\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.560000000000006\n",
      "  episode_reward_mean: 5.448983957219256\n",
      "  episode_reward_min: -0.5500000000000003\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 170750\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0389538509539333\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014218244363578781\n",
      "          policy_loss: -0.06895107091125367\n",
      "          total_loss: 0.0795991273492857\n",
      "          vf_explained_var: 0.9484196305274963\n",
      "          vf_loss: 0.13654879769843342\n",
      "    num_agent_steps_sampled: 8866362\n",
      "    num_agent_steps_trained: 8866362\n",
      "    num_steps_sampled: 8866362\n",
      "    num_steps_trained: 8866362\n",
      "  iterations_since_restore: 547\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.70785070785071\n",
      "    ram_util_percent: 53.56177606177607\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052773809916379845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.61808851213218\n",
      "    mean_inference_ms: 19.519943121609696\n",
      "    mean_raw_obs_processing_ms: 3.310079424863437\n",
      "  time_since_restore: 300105.7617754936\n",
      "  time_this_iter_s: 544.7100961208344\n",
      "  time_total_s: 494923.1253609657\n",
      "  timers:\n",
      "    learn_throughput: 28.185\n",
      "    learn_time_ms: 354659.797\n",
      "    load_throughput: 89545.487\n",
      "    load_time_ms: 111.63\n",
      "    sample_throughput: 52.779\n",
      "    sample_time_ms: 189393.528\n",
      "    update_time_ms: 6.864\n",
      "  timestamp: 1637756256\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8866362\n",
      "  training_iteration: 947\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   947</td><td style=\"text-align: right;\">          494923</td><td style=\"text-align: right;\">8866362</td><td style=\"text-align: right;\"> 5.44898</td><td style=\"text-align: right;\">               13.56</td><td style=\"text-align: right;\">               -0.55</td><td style=\"text-align: right;\">           53.3636</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8876358\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_12-26-56\n",
      "  done: false\n",
      "  episode_len_mean: 52.810526315789474\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.700000000000003\n",
      "  episode_reward_mean: 5.171684210526321\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 170940\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0331363565711134\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014191879337859759\n",
      "          policy_loss: -0.06741329170129988\n",
      "          total_loss: 0.07788590774151995\n",
      "          vf_explained_var: 0.9343903064727783\n",
      "          vf_loss: 0.13329968608356638\n",
      "    num_agent_steps_sampled: 8876358\n",
      "    num_agent_steps_trained: 8876358\n",
      "    num_steps_sampled: 8876358\n",
      "    num_steps_trained: 8876358\n",
      "  iterations_since_restore: 548\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.63987500000002\n",
      "    ram_util_percent: 53.953500000000005\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05278027132466537\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.616595040374158\n",
      "    mean_inference_ms: 19.520526064519107\n",
      "    mean_raw_obs_processing_ms: 3.3145401417889735\n",
      "  time_since_restore: 300666.0541098118\n",
      "  time_this_iter_s: 560.292334318161\n",
      "  time_total_s: 495483.4176952839\n",
      "  timers:\n",
      "    learn_throughput: 28.182\n",
      "    learn_time_ms: 354696.656\n",
      "    load_throughput: 88906.769\n",
      "    load_time_ms: 112.432\n",
      "    sample_throughput: 52.0\n",
      "    sample_time_ms: 192231.582\n",
      "    update_time_ms: 7.147\n",
      "  timestamp: 1637756816\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8876358\n",
      "  training_iteration: 948\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   948</td><td style=\"text-align: right;\">          495483</td><td style=\"text-align: right;\">8876358</td><td style=\"text-align: right;\"> 5.17168</td><td style=\"text-align: right;\">                15.7</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           52.8105</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8886354\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_12-36-05\n",
      "  done: false\n",
      "  episode_len_mean: 53.61290322580645\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.599999999999973\n",
      "  episode_reward_mean: 5.222311827956994\n",
      "  episode_reward_min: -0.6900000000000004\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 171126\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0251500253696517\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015102094012411048\n",
      "          policy_loss: -0.06365987351945583\n",
      "          total_loss: 0.09845351891355866\n",
      "          vf_explained_var: 0.9455236792564392\n",
      "          vf_loss: 0.1479604335364336\n",
      "    num_agent_steps_sampled: 8886354\n",
      "    num_agent_steps_trained: 8886354\n",
      "    num_steps_sampled: 8886354\n",
      "    num_steps_trained: 8886354\n",
      "  iterations_since_restore: 549\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.44795396419435\n",
      "    ram_util_percent: 53.30166240409206\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05277283828506858\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.61535897974177\n",
      "    mean_inference_ms: 19.518520480399413\n",
      "    mean_raw_obs_processing_ms: 3.3126035518777366\n",
      "  time_since_restore: 301214.581897974\n",
      "  time_this_iter_s: 548.5277881622314\n",
      "  time_total_s: 496031.9454834461\n",
      "  timers:\n",
      "    learn_throughput: 28.181\n",
      "    learn_time_ms: 354705.711\n",
      "    load_throughput: 89139.307\n",
      "    load_time_ms: 112.139\n",
      "    sample_throughput: 51.935\n",
      "    sample_time_ms: 192472.056\n",
      "    update_time_ms: 7.435\n",
      "  timestamp: 1637757365\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8886354\n",
      "  training_iteration: 949\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   949</td><td style=\"text-align: right;\">          496032</td><td style=\"text-align: right;\">8886354</td><td style=\"text-align: right;\"> 5.22231</td><td style=\"text-align: right;\">                19.6</td><td style=\"text-align: right;\">               -0.69</td><td style=\"text-align: right;\">           53.6129</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8896350\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_12-44-59\n",
      "  done: false\n",
      "  episode_len_mean: 53.57219251336898\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000007\n",
      "  episode_reward_mean: 5.2352406417112345\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 171313\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.017543608788027\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014251580308066461\n",
      "          policy_loss: -0.06749016875344817\n",
      "          total_loss: 0.08314770061098029\n",
      "          vf_explained_var: 0.948288083076477\n",
      "          vf_loss: 0.13834642191692423\n",
      "    num_agent_steps_sampled: 8896350\n",
      "    num_agent_steps_trained: 8896350\n",
      "    num_steps_sampled: 8896350\n",
      "    num_steps_trained: 8896350\n",
      "  iterations_since_restore: 550\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98740157480314\n",
      "    ram_util_percent: 53.04265091863517\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052776239715730595\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.617326932596132\n",
      "    mean_inference_ms: 19.52188089771763\n",
      "    mean_raw_obs_processing_ms: 3.309812108638342\n",
      "  time_since_restore: 301748.6238806248\n",
      "  time_this_iter_s: 534.0419826507568\n",
      "  time_total_s: 496565.9874660969\n",
      "  timers:\n",
      "    learn_throughput: 28.179\n",
      "    learn_time_ms: 354735.866\n",
      "    load_throughput: 89159.116\n",
      "    load_time_ms: 112.114\n",
      "    sample_throughput: 52.256\n",
      "    sample_time_ms: 191290.069\n",
      "    update_time_ms: 7.793\n",
      "  timestamp: 1637757899\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8896350\n",
      "  training_iteration: 950\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   950</td><td style=\"text-align: right;\">          496566</td><td style=\"text-align: right;\">8896350</td><td style=\"text-align: right;\"> 5.23524</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">           53.5722</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8906346\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_12-54-07\n",
      "  done: false\n",
      "  episode_len_mean: 54.18478260869565\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.530000000000008\n",
      "  episode_reward_mean: 5.134347826086961\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 184\n",
      "  episodes_total: 171497\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.058548657147281\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014362773993806324\n",
      "          policy_loss: -0.06539698780619524\n",
      "          total_loss: 0.0812699946819057\n",
      "          vf_explained_var: 0.9348485469818115\n",
      "          vf_loss: 0.13453227343770813\n",
      "    num_agent_steps_sampled: 8906346\n",
      "    num_agent_steps_trained: 8906346\n",
      "    num_steps_sampled: 8906346\n",
      "    num_steps_trained: 8906346\n",
      "  iterations_since_restore: 551\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81843790012806\n",
      "    ram_util_percent: 53.30832266325223\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05277659858399398\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.616051630658337\n",
      "    mean_inference_ms: 19.522189072144684\n",
      "    mean_raw_obs_processing_ms: 3.3091734460811706\n",
      "  time_since_restore: 302295.99895596504\n",
      "  time_this_iter_s: 547.375075340271\n",
      "  time_total_s: 497113.36254143715\n",
      "  timers:\n",
      "    learn_throughput: 28.176\n",
      "    learn_time_ms: 354772.056\n",
      "    load_throughput: 88920.515\n",
      "    load_time_ms: 112.415\n",
      "    sample_throughput: 51.867\n",
      "    sample_time_ms: 192722.144\n",
      "    update_time_ms: 7.779\n",
      "  timestamp: 1637758447\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8906346\n",
      "  training_iteration: 951\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   951</td><td style=\"text-align: right;\">          497113</td><td style=\"text-align: right;\">8906346</td><td style=\"text-align: right;\"> 5.13435</td><td style=\"text-align: right;\">               13.53</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           54.1848</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8916342\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_13-03-16\n",
      "  done: false\n",
      "  episode_len_mean: 52.94179894179894\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000007\n",
      "  episode_reward_mean: 5.063121693121697\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 171686\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0368468397592445\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.013692797902045322\n",
      "          policy_loss: -0.06776632004120947\n",
      "          total_loss: 0.06799779617311535\n",
      "          vf_explained_var: 0.943159818649292\n",
      "          vf_loss: 0.12493867767866267\n",
      "    num_agent_steps_sampled: 8916342\n",
      "    num_agent_steps_trained: 8916342\n",
      "    num_steps_sampled: 8916342\n",
      "    num_steps_trained: 8916342\n",
      "  iterations_since_restore: 552\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.59336734693878\n",
      "    ram_util_percent: 53.64783163265305\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527724806440816\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.615814653124822\n",
      "    mean_inference_ms: 19.521603458970393\n",
      "    mean_raw_obs_processing_ms: 3.3080425234313453\n",
      "  time_since_restore: 302844.98616051674\n",
      "  time_this_iter_s: 548.9872045516968\n",
      "  time_total_s: 497662.34974598885\n",
      "  timers:\n",
      "    learn_throughput: 28.172\n",
      "    learn_time_ms: 354822.152\n",
      "    load_throughput: 88656.202\n",
      "    load_time_ms: 112.75\n",
      "    sample_throughput: 51.851\n",
      "    sample_time_ms: 192782.04\n",
      "    update_time_ms: 7.792\n",
      "  timestamp: 1637758996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8916342\n",
      "  training_iteration: 952\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   952</td><td style=\"text-align: right;\">          497662</td><td style=\"text-align: right;\">8916342</td><td style=\"text-align: right;\"> 5.06312</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           52.9418</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8926338\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_13-12-25\n",
      "  done: false\n",
      "  episode_len_mean: 52.957671957671955\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.519999999999975\n",
      "  episode_reward_mean: 5.61507936507937\n",
      "  episode_reward_min: -0.6000000000000003\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 171875\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.038629170617904\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016223078726621428\n",
      "          policy_loss: -0.06562047803332977\n",
      "          total_loss: 0.11066393745728405\n",
      "          vf_explained_var: 0.9226809740066528\n",
      "          vf_loss: 0.15971250420896313\n",
      "    num_agent_steps_sampled: 8926338\n",
      "    num_agent_steps_trained: 8926338\n",
      "    num_steps_sampled: 8926338\n",
      "    num_steps_trained: 8926338\n",
      "  iterations_since_restore: 553\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91326530612245\n",
      "    ram_util_percent: 54.00459183673468\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05277316210939927\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.615920540938067\n",
      "    mean_inference_ms: 19.52314106963571\n",
      "    mean_raw_obs_processing_ms: 3.3111284590996406\n",
      "  time_since_restore: 303394.4211959839\n",
      "  time_this_iter_s: 549.4350354671478\n",
      "  time_total_s: 498211.784781456\n",
      "  timers:\n",
      "    learn_throughput: 28.166\n",
      "    learn_time_ms: 354894.301\n",
      "    load_throughput: 88676.585\n",
      "    load_time_ms: 112.724\n",
      "    sample_throughput: 52.1\n",
      "    sample_time_ms: 191861.599\n",
      "    update_time_ms: 6.872\n",
      "  timestamp: 1637759545\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8926338\n",
      "  training_iteration: 953\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   953</td><td style=\"text-align: right;\">          498212</td><td style=\"text-align: right;\">8926338</td><td style=\"text-align: right;\"> 5.61508</td><td style=\"text-align: right;\">               19.52</td><td style=\"text-align: right;\">                -0.6</td><td style=\"text-align: right;\">           52.9577</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8936334\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_13-21-37\n",
      "  done: false\n",
      "  episode_len_mean: 53.44919786096256\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000006\n",
      "  episode_reward_mean: 5.300374331550806\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 187\n",
      "  episodes_total: 172062\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.015439967098964\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01473071074508811\n",
      "          policy_loss: -0.06168114215267476\n",
      "          total_loss: 0.0979028529558089\n",
      "          vf_explained_var: 0.9477227330207825\n",
      "          vf_loss: 0.14617999341230406\n",
      "    num_agent_steps_sampled: 8936334\n",
      "    num_agent_steps_trained: 8936334\n",
      "    num_steps_sampled: 8936334\n",
      "    num_steps_trained: 8936334\n",
      "  iterations_since_restore: 554\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.89390088945362\n",
      "    ram_util_percent: 53.462897077509524\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052766681751433\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.61510793535065\n",
      "    mean_inference_ms: 19.521676405703467\n",
      "    mean_raw_obs_processing_ms: 3.3096008317079777\n",
      "  time_since_restore: 303946.5493593216\n",
      "  time_this_iter_s: 552.1281633377075\n",
      "  time_total_s: 498763.9129447937\n",
      "  timers:\n",
      "    learn_throughput: 28.14\n",
      "    learn_time_ms: 355222.546\n",
      "    load_throughput: 87726.437\n",
      "    load_time_ms: 113.945\n",
      "    sample_throughput: 51.969\n",
      "    sample_time_ms: 192346.947\n",
      "    update_time_ms: 6.621\n",
      "  timestamp: 1637760097\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8936334\n",
      "  training_iteration: 954\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   954</td><td style=\"text-align: right;\">          498764</td><td style=\"text-align: right;\">8936334</td><td style=\"text-align: right;\"> 5.30037</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           53.4492</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8946330\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_13-30-31\n",
      "  done: false\n",
      "  episode_len_mean: 53.91935483870968\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.629999999999995\n",
      "  episode_reward_mean: 5.551666666666671\n",
      "  episode_reward_min: -0.5000000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 172248\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.023955290360623\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014900132115834826\n",
      "          policy_loss: -0.06566527621181308\n",
      "          total_loss: 0.09299833659849052\n",
      "          vf_explained_var: 0.9424542784690857\n",
      "          vf_loss: 0.14495880086167554\n",
      "    num_agent_steps_sampled: 8946330\n",
      "    num_agent_steps_trained: 8946330\n",
      "    num_steps_sampled: 8946330\n",
      "    num_steps_trained: 8946330\n",
      "  iterations_since_restore: 555\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.00196850393701\n",
      "    ram_util_percent: 53.06338582677166\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052767374163789016\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.615039610420666\n",
      "    mean_inference_ms: 19.52104516858327\n",
      "    mean_raw_obs_processing_ms: 3.3058030604203803\n",
      "  time_since_restore: 304480.25064587593\n",
      "  time_this_iter_s: 533.7012865543365\n",
      "  time_total_s: 499297.61423134804\n",
      "  timers:\n",
      "    learn_throughput: 28.143\n",
      "    learn_time_ms: 355188.348\n",
      "    load_throughput: 87911.985\n",
      "    load_time_ms: 113.705\n",
      "    sample_throughput: 51.899\n",
      "    sample_time_ms: 192604.433\n",
      "    update_time_ms: 6.579\n",
      "  timestamp: 1637760631\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8946330\n",
      "  training_iteration: 955\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   955</td><td style=\"text-align: right;\">          499298</td><td style=\"text-align: right;\">8946330</td><td style=\"text-align: right;\"> 5.55167</td><td style=\"text-align: right;\">               19.63</td><td style=\"text-align: right;\">                -0.5</td><td style=\"text-align: right;\">           53.9194</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8956326\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_13-39-26\n",
      "  done: false\n",
      "  episode_len_mean: 53.543010752688176\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.629999999999985\n",
      "  episode_reward_mean: 5.417419354838714\n",
      "  episode_reward_min: -0.5100000000000002\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 172434\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.034759930554164\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014535413531985394\n",
      "          policy_loss: -0.0649596277851472\n",
      "          total_loss: 0.09961479039993427\n",
      "          vf_explained_var: 0.9369463920593262\n",
      "          vf_loss: 0.1518085277617823\n",
      "    num_agent_steps_sampled: 8956326\n",
      "    num_agent_steps_trained: 8956326\n",
      "    num_steps_sampled: 8956326\n",
      "    num_steps_trained: 8956326\n",
      "  iterations_since_restore: 556\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98099606815204\n",
      "    ram_util_percent: 52.775753604193966\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05277660537628869\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.61618407709246\n",
      "    mean_inference_ms: 19.522759796944218\n",
      "    mean_raw_obs_processing_ms: 3.3033890359100915\n",
      "  time_since_restore: 305015.3962292671\n",
      "  time_this_iter_s: 535.1455833911896\n",
      "  time_total_s: 499832.7598147392\n",
      "  timers:\n",
      "    learn_throughput: 28.146\n",
      "    learn_time_ms: 355152.864\n",
      "    load_throughput: 88005.265\n",
      "    load_time_ms: 113.584\n",
      "    sample_throughput: 52.569\n",
      "    sample_time_ms: 190149.927\n",
      "    update_time_ms: 6.252\n",
      "  timestamp: 1637761166\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8956326\n",
      "  training_iteration: 956\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   956</td><td style=\"text-align: right;\">          499833</td><td style=\"text-align: right;\">8956326</td><td style=\"text-align: right;\"> 5.41742</td><td style=\"text-align: right;\">               19.63</td><td style=\"text-align: right;\">               -0.51</td><td style=\"text-align: right;\">            53.543</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8966322\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_13-48-49\n",
      "  done: false\n",
      "  episode_len_mean: 52.42631578947368\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.670000000000005\n",
      "  episode_reward_mean: 5.15789473684211\n",
      "  episode_reward_min: -0.49000000000000027\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 172624\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0455632435748856\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014036878846392513\n",
      "          policy_loss: -0.06693663153207262\n",
      "          total_loss: 0.07707465990660053\n",
      "          vf_explained_var: 0.9358654618263245\n",
      "          vf_loss: 0.13248915745536366\n",
      "    num_agent_steps_sampled: 8966322\n",
      "    num_agent_steps_trained: 8966322\n",
      "    num_steps_sampled: 8966322\n",
      "    num_steps_trained: 8966322\n",
      "  iterations_since_restore: 557\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.72801992528021\n",
      "    ram_util_percent: 54.038107098381076\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052766651113313454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.615753872856054\n",
      "    mean_inference_ms: 19.52251473417337\n",
      "    mean_raw_obs_processing_ms: 3.307833460470525\n",
      "  time_since_restore: 305578.0426659584\n",
      "  time_this_iter_s: 562.6464366912842\n",
      "  time_total_s: 500395.4062514305\n",
      "  timers:\n",
      "    learn_throughput: 28.158\n",
      "    learn_time_ms: 354999.431\n",
      "    load_throughput: 87951.432\n",
      "    load_time_ms: 113.654\n",
      "    sample_throughput: 52.036\n",
      "    sample_time_ms: 192097.08\n",
      "    update_time_ms: 6.198\n",
      "  timestamp: 1637761729\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8966322\n",
      "  training_iteration: 957\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   957</td><td style=\"text-align: right;\">          500395</td><td style=\"text-align: right;\">8966322</td><td style=\"text-align: right;\"> 5.15789</td><td style=\"text-align: right;\">               11.67</td><td style=\"text-align: right;\">               -0.49</td><td style=\"text-align: right;\">           52.4263</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8976318\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_13-57-55\n",
      "  done: false\n",
      "  episode_len_mean: 52.82010582010582\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.650000000000004\n",
      "  episode_reward_mean: 5.110158730158734\n",
      "  episode_reward_min: -0.5200000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 172813\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.020756504095223\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014549847516608195\n",
      "          policy_loss: -0.07067969550834931\n",
      "          total_loss: 0.08266575221908619\n",
      "          vf_explained_var: 0.9270918369293213\n",
      "          vf_loss: 0.14040663986014254\n",
      "    num_agent_steps_sampled: 8976318\n",
      "    num_agent_steps_trained: 8976318\n",
      "    num_steps_sampled: 8976318\n",
      "    num_steps_trained: 8976318\n",
      "  iterations_since_restore: 558\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.80911424903724\n",
      "    ram_util_percent: 54.22631578947367\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05276961668329118\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.616145072197767\n",
      "    mean_inference_ms: 19.524349055591898\n",
      "    mean_raw_obs_processing_ms: 3.3088568799939098\n",
      "  time_since_restore: 306123.7581849098\n",
      "  time_this_iter_s: 545.715518951416\n",
      "  time_total_s: 500941.1217703819\n",
      "  timers:\n",
      "    learn_throughput: 28.168\n",
      "    learn_time_ms: 354876.268\n",
      "    load_throughput: 88598.836\n",
      "    load_time_ms: 112.823\n",
      "    sample_throughput: 52.4\n",
      "    sample_time_ms: 190763.511\n",
      "    update_time_ms: 6.007\n",
      "  timestamp: 1637762275\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8976318\n",
      "  training_iteration: 958\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   958</td><td style=\"text-align: right;\">          500941</td><td style=\"text-align: right;\">8976318</td><td style=\"text-align: right;\"> 5.11016</td><td style=\"text-align: right;\">               11.65</td><td style=\"text-align: right;\">               -0.52</td><td style=\"text-align: right;\">           52.8201</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8986314\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_14-07-01\n",
      "  done: false\n",
      "  episode_len_mean: 52.705263157894734\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.650000000000002\n",
      "  episode_reward_mean: 5.366789473684215\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 173003\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0127820288081724\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01478681427860808\n",
      "          policy_loss: -0.06469329855484844\n",
      "          total_loss: 0.09053466777482995\n",
      "          vf_explained_var: 0.9542861580848694\n",
      "          vf_loss: 0.1416695748955146\n",
      "    num_agent_steps_sampled: 8986314\n",
      "    num_agent_steps_trained: 8986314\n",
      "    num_steps_sampled: 8986314\n",
      "    num_steps_trained: 8986314\n",
      "  iterations_since_restore: 559\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.80821566110399\n",
      "    ram_util_percent: 53.65827984595636\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05276646960727614\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.617070842523724\n",
      "    mean_inference_ms: 19.52473235608079\n",
      "    mean_raw_obs_processing_ms: 3.3073748382159183\n",
      "  time_since_restore: 306669.70424723625\n",
      "  time_this_iter_s: 545.9460623264313\n",
      "  time_total_s: 501487.06783270836\n",
      "  timers:\n",
      "    learn_throughput: 28.176\n",
      "    learn_time_ms: 354766.688\n",
      "    load_throughput: 88321.952\n",
      "    load_time_ms: 113.177\n",
      "    sample_throughput: 52.441\n",
      "    sample_time_ms: 190614.831\n",
      "    update_time_ms: 5.65\n",
      "  timestamp: 1637762821\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8986314\n",
      "  training_iteration: 959\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   959</td><td style=\"text-align: right;\">          501487</td><td style=\"text-align: right;\">8986314</td><td style=\"text-align: right;\"> 5.36679</td><td style=\"text-align: right;\">               17.65</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           52.7053</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133304)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133286)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 8996310\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_14-16-33\n",
      "  done: false\n",
      "  episode_len_mean: 51.80927835051546\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.539999999999996\n",
      "  episode_reward_mean: 5.4713402061855705\n",
      "  episode_reward_min: -0.6100000000000003\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 173197\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0271983699386857\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01528316438796681\n",
      "          policy_loss: -0.061604799133232864\n",
      "          total_loss: 0.12709781099606132\n",
      "          vf_explained_var: 0.9412603378295898\n",
      "          vf_loss: 0.17415763409471655\n",
      "    num_agent_steps_sampled: 8996310\n",
      "    num_agent_steps_trained: 8996310\n",
      "    num_steps_sampled: 8996310\n",
      "    num_steps_trained: 8996310\n",
      "  iterations_since_restore: 560\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.92156862745098\n",
      "    ram_util_percent: 53.876225490196084\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0527559531973538\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.61785294070353\n",
      "    mean_inference_ms: 19.52093006943005\n",
      "    mean_raw_obs_processing_ms: 3.3151637317928677\n",
      "  time_since_restore: 307242.0157814026\n",
      "  time_this_iter_s: 572.3115341663361\n",
      "  time_total_s: 502059.3793668747\n",
      "  timers:\n",
      "    learn_throughput: 28.182\n",
      "    learn_time_ms: 354694.948\n",
      "    load_throughput: 88091.525\n",
      "    load_time_ms: 113.473\n",
      "    sample_throughput: 51.39\n",
      "    sample_time_ms: 194513.617\n",
      "    update_time_ms: 5.255\n",
      "  timestamp: 1637763393\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8996310\n",
      "  training_iteration: 960\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   960</td><td style=\"text-align: right;\">          502059</td><td style=\"text-align: right;\">8996310</td><td style=\"text-align: right;\"> 5.47134</td><td style=\"text-align: right;\">               17.54</td><td style=\"text-align: right;\">               -0.61</td><td style=\"text-align: right;\">           51.8093</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=133292)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_9f6d0_00000:\n",
      "  agent_timesteps_total: 9006306\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-24_14-25-44\n",
      "  done: false\n",
      "  episode_len_mean: 52.192708333333336\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000006\n",
      "  episode_reward_mean: 5.4918229166666706\n",
      "  episode_reward_min: -0.5300000000000002\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 173389\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0236422120567306\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014942644872522011\n",
      "          policy_loss: -0.06531815659060763\n",
      "          total_loss: 0.0981180763773822\n",
      "          vf_explained_var: 0.9484711289405823\n",
      "          vf_loss: 0.14963144206191342\n",
      "    num_agent_steps_sampled: 9006306\n",
      "    num_agent_steps_trained: 9006306\n",
      "    num_steps_sampled: 9006306\n",
      "    num_steps_trained: 9006306\n",
      "  iterations_since_restore: 561\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.78970775095299\n",
      "    ram_util_percent: 54.04968233799237\n",
      "  pid: 133291\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05277242274856395\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.62151507282049\n",
      "    mean_inference_ms: 19.526685933431093\n",
      "    mean_raw_obs_processing_ms: 3.3167280964433643\n",
      "  time_since_restore: 307793.186896801\n",
      "  time_this_iter_s: 551.171115398407\n",
      "  time_total_s: 502610.5504822731\n",
      "  timers:\n",
      "    learn_throughput: 28.188\n",
      "    learn_time_ms: 354612.749\n",
      "    load_throughput: 88081.124\n",
      "    load_time_ms: 113.486\n",
      "    sample_throughput: 51.268\n",
      "    sample_time_ms: 194976.009\n",
      "    update_time_ms: 4.864\n",
      "  timestamp: 1637763944\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9006306\n",
      "  training_iteration: 961\n",
      "  trial_id: 9f6d0_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/23.76 GiB heap, 0.0/11.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-21_00-54-46<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_9f6d0_00000</td><td>RUNNING </td><td>192.168.3.5:133291</td><td style=\"text-align: right;\">   961</td><td style=\"text-align: right;\">          502611</td><td style=\"text-align: right;\">9006306</td><td style=\"text-align: right;\"> 5.49182</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -0.53</td><td style=\"text-align: right;\">           52.1927</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 60,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 5_000,\n",
    "             #\"lr\": 1e-4,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO (AUG ALL) pretrained (visual pretrained AngelaCNN + CrossAttn 3) 1->0\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3\",\n",
    "        keep_checkpoints_num=100,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True,\n",
    "        restore=\"/IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59/PPO_my_env_ab24a_00000_0_2021-11-18_22-20-00/checkpoint_000400/checkpoint-400\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dde63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
