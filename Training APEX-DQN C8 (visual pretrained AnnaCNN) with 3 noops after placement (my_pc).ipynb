{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import dqn\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4, padding=0),  \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(64, 512, kernel_size=2, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        features_dim = 512\n",
    "        self.encoder = VisualEncoder()\n",
    "        self.encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AnnaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.qvalue_head = nn.Linear(features_dim, num_outputs)\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.encoder.cuda()\n",
    "            self.qvalue_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        if self.use_cuda:\n",
    "            obs.cuda()\n",
    "            \n",
    "        features = self.encoder(obs)\n",
    "        qvalues = self.qvalue_head(features)\n",
    "        return qvalues, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.05\n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=500)\n",
    "    env.update_taskset(TaskSet(preset=['C8']))\n",
    "    env = PovOnlyWrapper(env)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    #env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.dqn import ApexTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n",
      "2021-10-13 08:14:27,555\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-10-13 08:14:27,568\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 4.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id 9c652_00000 but id 95522_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=152)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=152)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">APEX C8 pretrained (AnnaCNN) gamma: 0.95</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/95522_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/95522_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211013_081428-95522_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=152)\u001b[0m 2021-10-13 08:14:31,038\tINFO dqn.py:188 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=152)\u001b[0m 2021-10-13 08:14:31,038\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=152)\u001b[0m 2021-10-13 08:14:37,845\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=146)\u001b[0m 2021-10-13 08:15:32,796\tINFO replay_buffer.py:46 -- Estimated max memory usage for replay buffer is 1.2314 GB (50000.0 batches of size 1, 24628 bytes each), available system memory is 50.466770944 GB\n",
      "\u001b[2m\u001b[36m(pid=151)\u001b[0m 2021-10-13 08:15:33,163\tINFO replay_buffer.py:46 -- Estimated max memory usage for replay buffer is 1.23145 GB (50000.0 batches of size 1, 24629 bytes each), available system memory is 50.466770944 GB\n",
      "\u001b[2m\u001b[36m(pid=145)\u001b[0m 2021-10-13 08:15:33,381\tINFO replay_buffer.py:46 -- Estimated max memory usage for replay buffer is 1.23145 GB (50000.0 batches of size 1, 24629 bytes each), available system memory is 50.466770944 GB\n",
      "\u001b[2m\u001b[36m(pid=148)\u001b[0m 2021-10-13 08:15:34,338\tINFO replay_buffer.py:46 -- Estimated max memory usage for replay buffer is 1.23145 GB (50000.0 batches of size 1, 24629 bytes each), available system memory is 50.466770944 GB\n",
      "2021-10-13 08:21:10,577\tWARNING logger.py:654 -- You are trying to log an invalid value (ray/tune/info/exploration_infos=[{'cur_epsilon': 0.0, 'last_timestep': 0}, {'cur_epsilon': 0.4, 'last_timestep': 24215}, {'cur_epsilon': 0.016190861620062107, 'last_timestep': 24863}, {'cur_epsilon': 0.0006553600000000003, 'last_timestep': 24551}]) via TBXLoggerCallback!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 25040\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_08-21-10\n",
      "  done: false\n",
      "  episode_len_mean: 218.6216216216216\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: 0.6756756756756757\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 37\n",
      "  episodes_total: 37\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 24215\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 24863\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 24551\n",
      "    last_target_update_ts: 6525000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.2605246603488922\n",
      "        max_q: 10.484436988830566\n",
      "        mean_q: 1.2949919700622559\n",
      "        min_q: -0.9507524967193604\n",
      "    learner_queue:\n",
      "      size_count: 1307\n",
      "      size_mean: 0.68\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.581033561853358\n",
      "    num_agent_steps_sampled: 25040\n",
      "    num_steps_sampled: 25040\n",
      "    num_steps_trained: 6535000\n",
      "    num_target_updates: 435\n",
      "    num_weight_syncs: 61\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.649\n",
      "      policy_default_policy:\n",
      "        added_count: 6248\n",
      "        est_size_bytes: 153882440\n",
      "        num_entries: 6248\n",
      "        sampled_count: 1670000\n",
      "      replay_time_ms: 334.379\n",
      "      update_priorities_time_ms: 368.904\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.27831541218639\n",
      "    ram_util_percent: 34.56505376344086\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052086736601071194\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 43.34156469206339\n",
      "    mean_inference_ms: 2.016627295253964\n",
      "    mean_raw_obs_processing_ms: 1.4329917871818312\n",
      "  time_since_restore: 392.6521668434143\n",
      "  time_this_iter_s: 392.6521668434143\n",
      "  time_total_s: 392.6521668434143\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 103.22\n",
      "    learner_grad_throughput: 32756.597\n",
      "    learner_grad_time_ms: 152.641\n",
      "    learner_overall_throughput: 19539.707\n",
      "    learner_overall_time_ms: 255.889\n",
      "  timestamp: 1634113270\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25040\n",
      "  training_iteration: 1\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 20.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         392.652</td><td style=\"text-align: right;\">25040</td><td style=\"text-align: right;\">0.675676</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">           218.622</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 50056\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_08-27-59\n",
      "  done: false\n",
      "  episode_len_mean: 204.45569620253164\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.0\n",
      "  episode_reward_mean: 0.8734177215189873\n",
      "  episode_reward_min: -2.0\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 79\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 49103\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 49847\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 49303\n",
      "    last_target_update_ts: 15270000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.2432873249053955\n",
      "        max_q: 95.32525634765625\n",
      "        mean_q: 2.972226619720459\n",
      "        min_q: -1.3175201416015625\n",
      "    learner_queue:\n",
      "      size_count: 3056\n",
      "      size_mean: 0.72\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.1000000000000014\n",
      "      - 2.0\n",
      "      size_std: 0.6337191807101944\n",
      "    num_agent_steps_sampled: 50056\n",
      "    num_steps_sampled: 50056\n",
      "    num_steps_trained: 15280000\n",
      "    num_target_updates: 1018\n",
      "    num_weight_syncs: 123\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.538\n",
      "      policy_default_policy:\n",
      "        added_count: 12112\n",
      "        est_size_bytes: 298307504\n",
      "        num_entries: 12112\n",
      "        sampled_count: 3875000\n",
      "      replay_time_ms: 343.604\n",
      "      update_priorities_time_ms: 335.981\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.13937823834196\n",
      "    ram_util_percent: 46.734024179620036\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05156326075111726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 43.74866155385442\n",
      "    mean_inference_ms: 1.9948803286981185\n",
      "    mean_raw_obs_processing_ms: 2.1670680788146117\n",
      "  time_since_restore: 801.5484442710876\n",
      "  time_this_iter_s: 408.89627742767334\n",
      "  time_total_s: 801.5484442710876\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 86.878\n",
      "    learner_grad_throughput: 32583.815\n",
      "    learner_grad_time_ms: 153.45\n",
      "    learner_overall_throughput: 20802.574\n",
      "    learner_overall_time_ms: 240.355\n",
      "  timestamp: 1634113679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 50056\n",
      "  training_iteration: 2\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         801.548</td><td style=\"text-align: right;\">50056</td><td style=\"text-align: right;\">0.873418</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">           204.456</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 75056\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_08-35-57\n",
      "  done: false\n",
      "  episode_len_mean: 184.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.0\n",
      "  episode_reward_mean: 0.92\n",
      "  episode_reward_min: -2.0\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 129\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 74503\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 75055\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 74727\n",
      "    last_target_update_ts: 25230000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.1525847166776657\n",
      "        max_q: 75.24273681640625\n",
      "        mean_q: 3.410060405731201\n",
      "        min_q: -0.6062561273574829\n",
      "    learner_queue:\n",
      "      size_count: 5047\n",
      "      size_mean: 0.54\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.6069596362197407\n",
      "    num_agent_steps_sampled: 75056\n",
      "    num_steps_sampled: 75056\n",
      "    num_steps_trained: 25230000\n",
      "    num_target_updates: 1682\n",
      "    num_weight_syncs: 187\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.548\n",
      "      policy_default_policy:\n",
      "        added_count: 18288\n",
      "        est_size_bytes: 450416816\n",
      "        num_entries: 18288\n",
      "        sampled_count: 6350000\n",
      "      replay_time_ms: 407.369\n",
      "      update_priorities_time_ms: 347.164\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.05798816568047\n",
      "    ram_util_percent: 51.51405325443787\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.051301704899319234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.33638266424239\n",
      "    mean_inference_ms: 1.973736454031786\n",
      "    mean_raw_obs_processing_ms: 2.849192803339516\n",
      "  time_since_restore: 1279.9843878746033\n",
      "  time_this_iter_s: 478.4359436035156\n",
      "  time_total_s: 1279.9843878746033\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 105.267\n",
      "    learner_grad_throughput: 30822.603\n",
      "    learner_grad_time_ms: 162.219\n",
      "    learner_overall_throughput: 18690.363\n",
      "    learner_overall_time_ms: 267.518\n",
      "  timestamp: 1634114157\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 75056\n",
      "  training_iteration: 3\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         1279.98</td><td style=\"text-align: right;\">75056</td><td style=\"text-align: right;\">    0.92</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">            184.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:41.961330, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 100056\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_08-42-51\n",
      "  done: false\n",
      "  episode_len_mean: 194.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.0\n",
      "  episode_reward_mean: 0.47\n",
      "  episode_reward_min: -2.0\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 172\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 99487\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 99655\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 99399\n",
      "    last_target_update_ts: 33525000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.18572236597537994\n",
      "        max_q: 34.8173828125\n",
      "        mean_q: 4.053640365600586\n",
      "        min_q: 0.14973044395446777\n",
      "    learner_queue:\n",
      "      size_count: 6708\n",
      "      size_mean: 0.7\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      - 2.0\n",
      "      size_std: 0.7\n",
      "    num_agent_steps_sampled: 100056\n",
      "    num_steps_sampled: 100056\n",
      "    num_steps_trained: 33535000\n",
      "    num_target_updates: 2235\n",
      "    num_weight_syncs: 248\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.536\n",
      "      policy_default_policy:\n",
      "        added_count: 24320\n",
      "        est_size_bytes: 598979656\n",
      "        num_entries: 24320\n",
      "        sampled_count: 8435000\n",
      "      replay_time_ms: 389.783\n",
      "      update_priorities_time_ms: 329.145\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.06780821917808\n",
      "    ram_util_percent: 55.89109589041096\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05140260737463622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.444609715458235\n",
      "    mean_inference_ms: 1.963025349765305\n",
      "    mean_raw_obs_processing_ms: 2.874967648070692\n",
      "  time_since_restore: 1693.2378685474396\n",
      "  time_this_iter_s: 413.2534806728363\n",
      "  time_total_s: 1693.2378685474396\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 63.733\n",
      "    learner_grad_throughput: 29115.061\n",
      "    learner_grad_time_ms: 171.732\n",
      "    learner_overall_throughput: 21232.25\n",
      "    learner_overall_time_ms: 235.491\n",
      "  timestamp: 1634114571\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 100056\n",
      "  training_iteration: 4\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         1693.24</td><td style=\"text-align: right;\">100056</td><td style=\"text-align: right;\">    0.47</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">            194.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 125056\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_08-50-36\n",
      "  done: false\n",
      "  episode_len_mean: 202.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.0\n",
      "  episode_reward_mean: 0.64\n",
      "  episode_reward_min: -2.0\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 219\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 124919\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 124895\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 124791\n",
      "    last_target_update_ts: 42750000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.11041738092899323\n",
      "        max_q: 158.53546142578125\n",
      "        mean_q: 4.642679691314697\n",
      "        min_q: -0.5573549270629883\n",
      "    learner_queue:\n",
      "      size_count: 8551\n",
      "      size_mean: 0.54\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.5\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.5730619512757761\n",
      "    num_agent_steps_sampled: 125056\n",
      "    num_steps_sampled: 125056\n",
      "    num_steps_trained: 42750000\n",
      "    num_target_updates: 2850\n",
      "    num_weight_syncs: 312\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.76\n",
      "      policy_default_policy:\n",
      "        added_count: 30456\n",
      "        est_size_bytes: 750103912\n",
      "        num_entries: 30456\n",
      "        sampled_count: 10725000\n",
      "      replay_time_ms: 408.397\n",
      "      update_priorities_time_ms: 383.298\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.06828528072838\n",
      "    ram_util_percent: 58.79650986342943\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.051377070255395146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 44.82128361585141\n",
      "    mean_inference_ms: 1.9559150148995814\n",
      "    mean_raw_obs_processing_ms: 2.7657593857960894\n",
      "  time_since_restore: 2158.6329901218414\n",
      "  time_this_iter_s: 465.39512157440186\n",
      "  time_total_s: 2158.6329901218414\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 86.391\n",
      "    learner_grad_throughput: 29419.083\n",
      "    learner_grad_time_ms: 169.958\n",
      "    learner_overall_throughput: 19502.607\n",
      "    learner_overall_time_ms: 256.376\n",
      "  timestamp: 1634115036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 125056\n",
      "  training_iteration: 5\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         2158.63</td><td style=\"text-align: right;\">125056</td><td style=\"text-align: right;\">    0.64</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">                  -2</td><td style=\"text-align: right;\">            202.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 150104\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_08-58-28\n",
      "  done: false\n",
      "  episode_len_mean: 179.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.0\n",
      "  episode_reward_mean: 0.8\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 267\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 150015\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 149127\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 150047\n",
      "    last_target_update_ts: 51945000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.1411726027727127\n",
      "        max_q: 136.02589416503906\n",
      "        mean_q: 5.371298313140869\n",
      "        min_q: -1.2066712379455566\n",
      "    learner_queue:\n",
      "      size_count: 10391\n",
      "      size_mean: 0.62\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 2.0\n",
      "      - 3.0\n",
      "      size_std: 0.7453858061433689\n",
      "    num_agent_steps_sampled: 150104\n",
      "    num_steps_sampled: 150104\n",
      "    num_steps_trained: 51945000\n",
      "    num_target_updates: 3463\n",
      "    num_weight_syncs: 375\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.567\n",
      "      policy_default_policy:\n",
      "        added_count: 36864\n",
      "        est_size_bytes: 907927064\n",
      "        num_entries: 36864\n",
      "        sampled_count: 13035000\n",
      "      replay_time_ms: 427.242\n",
      "      update_priorities_time_ms: 364.359\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.0564371257485\n",
      "    ram_util_percent: 60.406736526946105\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.051281974814810866\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.330113028831896\n",
      "    mean_inference_ms: 1.9508562905958966\n",
      "    mean_raw_obs_processing_ms: 2.9026329175013785\n",
      "  time_since_restore: 2630.6844279766083\n",
      "  time_this_iter_s: 472.05143785476685\n",
      "  time_total_s: 2630.6844279766083\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 84.248\n",
      "    learner_grad_throughput: 28319.88\n",
      "    learner_grad_time_ms: 176.554\n",
      "    learner_overall_throughput: 18341.108\n",
      "    learner_overall_time_ms: 272.612\n",
      "  timestamp: 1634115508\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 150104\n",
      "  training_iteration: 6\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 28.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         2630.68</td><td style=\"text-align: right;\">150104</td><td style=\"text-align: right;\">     0.8</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">                  -3</td><td style=\"text-align: right;\">            179.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 175120\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_09-06-18\n",
      "  done: false\n",
      "  episode_len_mean: 165.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.0\n",
      "  episode_reward_mean: 1.75\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 315\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 174943\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 174863\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 174943\n",
      "    last_target_update_ts: 60885000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.1705997735261917\n",
      "        max_q: 134.10540771484375\n",
      "        mean_q: 5.339540958404541\n",
      "        min_q: -1.3896775245666504\n",
      "    learner_queue:\n",
      "      size_count: 12179\n",
      "      size_mean: 0.52\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 3.0\n",
      "      size_std: 0.699714227381436\n",
      "    num_agent_steps_sampled: 175120\n",
      "    num_steps_sampled: 175120\n",
      "    num_steps_trained: 60895000\n",
      "    num_target_updates: 4059\n",
      "    num_weight_syncs: 437\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.87\n",
      "      policy_default_policy:\n",
      "        added_count: 43240\n",
      "        est_size_bytes: 1064962424\n",
      "        num_entries: 43240\n",
      "        sampled_count: 15260000\n",
      "      replay_time_ms: 418.313\n",
      "      update_priorities_time_ms: 344.941\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.02786144578313\n",
      "    ram_util_percent: 62.50120481927711\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.051382510723001554\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 46.33405356731006\n",
      "    mean_inference_ms: 1.9497624607011956\n",
      "    mean_raw_obs_processing_ms: 3.06459836529125\n",
      "  time_since_restore: 3100.7541818618774\n",
      "  time_this_iter_s: 470.06975388526917\n",
      "  time_total_s: 3100.7541818618774\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 83.155\n",
      "    learner_grad_throughput: 27624.714\n",
      "    learner_grad_time_ms: 180.997\n",
      "    learner_overall_throughput: 18926.374\n",
      "    learner_overall_time_ms: 264.182\n",
      "  timestamp: 1634115978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 175120\n",
      "  training_iteration: 7\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 29.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         3100.75</td><td style=\"text-align: right;\">175120</td><td style=\"text-align: right;\">    1.75</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">                  -3</td><td style=\"text-align: right;\">            165.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 200120\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_09-13-46\n",
      "  done: false\n",
      "  episode_len_mean: 161.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.0\n",
      "  episode_reward_mean: 2.43\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 360\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 199847\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 199447\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 198671\n",
      "    last_target_update_ts: 69360000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 0.3477717638015747\n",
      "        max_q: 416.7607421875\n",
      "        mean_q: 6.609777927398682\n",
      "        min_q: -2.088261365890503\n",
      "    learner_queue:\n",
      "      size_count: 13874\n",
      "      size_mean: 0.6\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 2.0\n",
      "      - 2.0\n",
      "      size_std: 0.6928203230275508\n",
      "    num_agent_steps_sampled: 200120\n",
      "    num_steps_sampled: 200120\n",
      "    num_steps_trained: 69370000\n",
      "    num_target_updates: 4624\n",
      "    num_weight_syncs: 498\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.674\n",
      "      policy_default_policy:\n",
      "        added_count: 49424\n",
      "        est_size_bytes: 1217268880\n",
      "        num_entries: 49424\n",
      "        sampled_count: 17400000\n",
      "      replay_time_ms: 382.129\n",
      "      update_priorities_time_ms: 404.271\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.06216216216215\n",
      "    ram_util_percent: 66.16025437201908\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05157455527748358\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 47.23188121675089\n",
      "    mean_inference_ms: 1.9488416080376072\n",
      "    mean_raw_obs_processing_ms: 3.195574626610487\n",
      "  time_since_restore: 3547.906522512436\n",
      "  time_this_iter_s: 447.1523406505585\n",
      "  time_total_s: 3547.906522512436\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 111.306\n",
      "    learner_grad_throughput: 32754.407\n",
      "    learner_grad_time_ms: 152.651\n",
      "    learner_overall_throughput: 18940.573\n",
      "    learner_overall_time_ms: 263.984\n",
      "  timestamp: 1634116426\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 200120\n",
      "  training_iteration: 8\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         3547.91</td><td style=\"text-align: right;\">200120</td><td style=\"text-align: right;\">    2.43</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">                  -3</td><td style=\"text-align: right;\">            161.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 225120\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_09-20-39\n",
      "  done: false\n",
      "  episode_len_mean: 171.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.0\n",
      "  episode_reward_mean: 1.58\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 46\n",
      "  episodes_total: 406\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 224743\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 224783\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 224351\n",
      "    last_target_update_ts: 77130000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 6.995969295501709\n",
      "        max_q: 7577.2861328125\n",
      "        mean_q: 272.8641662597656\n",
      "        min_q: -0.6759246587753296\n",
      "    learner_queue:\n",
      "      size_count: 15427\n",
      "      size_mean: 0.68\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      - 2.0\n",
      "      size_std: 0.7054076835419358\n",
      "    num_agent_steps_sampled: 225120\n",
      "    num_steps_sampled: 225120\n",
      "    num_steps_trained: 77130000\n",
      "    num_target_updates: 5142\n",
      "    num_weight_syncs: 561\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 1.04\n",
      "      policy_default_policy:\n",
      "        added_count: 55560\n",
      "        est_size_bytes: 1231455232\n",
      "        num_entries: 50000\n",
      "        sampled_count: 19350000\n",
      "      replay_time_ms: 405.099\n",
      "      update_priorities_time_ms: 379.235\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.03550600343053\n",
      "    ram_util_percent: 68.00034305317325\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05167242545971604\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 47.493293491331826\n",
      "    mean_inference_ms: 1.9492406063556045\n",
      "    mean_raw_obs_processing_ms: 3.1709883583628016\n",
      "  time_since_restore: 3961.5635797977448\n",
      "  time_this_iter_s: 413.65705728530884\n",
      "  time_total_s: 3961.5635797977448\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 59.634\n",
      "    learner_grad_throughput: 30195.577\n",
      "    learner_grad_time_ms: 165.587\n",
      "    learner_overall_throughput: 22197.515\n",
      "    learner_overall_time_ms: 225.25\n",
      "  timestamp: 1634116839\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 225120\n",
      "  training_iteration: 9\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 32.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         3961.56</td><td style=\"text-align: right;\">225120</td><td style=\"text-align: right;\">    1.58</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">                  -3</td><td style=\"text-align: right;\">            171.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 250152\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_09-25-59\n",
      "  done: false\n",
      "  episode_len_mean: 206.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: 0.7\n",
      "  episode_reward_min: -3.0\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 440\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 249951\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 249775\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 249671\n",
      "    last_target_update_ts: 83265000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 119.08619689941406\n",
      "        max_q: 218544.6875\n",
      "        mean_q: 9522.90234375\n",
      "        min_q: -150.47955322265625\n",
      "    learner_queue:\n",
      "      size_count: 16654\n",
      "      size_mean: 0.6\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.5\n",
      "      - 1.1000000000000014\n",
      "      - 2.0\n",
      "      size_std: 0.6633249580710799\n",
      "    num_agent_steps_sampled: 250152\n",
      "    num_steps_sampled: 250152\n",
      "    num_steps_trained: 83265000\n",
      "    num_target_updates: 5551\n",
      "    num_weight_syncs: 624\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.808\n",
      "      policy_default_policy:\n",
      "        added_count: 61744\n",
      "        est_size_bytes: 1231455232\n",
      "        num_entries: 50000\n",
      "        sampled_count: 20875000\n",
      "      replay_time_ms: 400.686\n",
      "      update_priorities_time_ms: 381.048\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.05199115044248\n",
      "    ram_util_percent: 69.16946902654867\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05176756999846219\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 46.68910480865081\n",
      "    mean_inference_ms: 1.9509220290820586\n",
      "    mean_raw_obs_processing_ms: 3.118514754388053\n",
      "  time_since_restore: 4281.43212890625\n",
      "  time_this_iter_s: 319.86854910850525\n",
      "  time_total_s: 4281.43212890625\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 121.19\n",
      "    learner_grad_throughput: 29823.345\n",
      "    learner_grad_time_ms: 167.654\n",
      "    learner_overall_throughput: 16116.115\n",
      "    learner_overall_time_ms: 310.248\n",
      "  timestamp: 1634117159\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 250152\n",
      "  training_iteration: 10\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 32.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         4281.43</td><td style=\"text-align: right;\">250152</td><td style=\"text-align: right;\">     0.7</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -3</td><td style=\"text-align: right;\">             206.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 275152\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_09-29-08\n",
      "  done: false\n",
      "  episode_len_mean: 272.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.0\n",
      "  episode_reward_mean: 0.36\n",
      "  episode_reward_min: -1.0\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 459\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 274503\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 274527\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 274871\n",
      "    last_target_update_ts: 86835000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 201.9309844970703\n",
      "        max_q: 289185.03125\n",
      "        mean_q: 9569.134765625\n",
      "        min_q: -154.4058837890625\n",
      "    learner_queue:\n",
      "      size_count: 17370\n",
      "      size_mean: 0.68\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.1000000000000014\n",
      "      - 2.0\n",
      "      size_std: 0.6462197768561404\n",
      "    num_agent_steps_sampled: 275152\n",
      "    num_steps_sampled: 275152\n",
      "    num_steps_trained: 86840000\n",
      "    num_target_updates: 5789\n",
      "    num_weight_syncs: 686\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.862\n",
      "      policy_default_policy:\n",
      "        added_count: 67528\n",
      "        est_size_bytes: 1231455232\n",
      "        num_entries: 50000\n",
      "        sampled_count: 21760000\n",
      "      replay_time_ms: 388.875\n",
      "      update_priorities_time_ms: 346.505\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.10186567164179\n",
      "    ram_util_percent: 69.40783582089553\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05183832335570565\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.64387760715548\n",
      "    mean_inference_ms: 1.9530909631405433\n",
      "    mean_raw_obs_processing_ms: 3.0456511661967354\n",
      "  time_since_restore: 4470.756553649902\n",
      "  time_this_iter_s: 189.32442474365234\n",
      "  time_total_s: 4470.756553649902\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 59.528\n",
      "    learner_grad_throughput: 27066.906\n",
      "    learner_grad_time_ms: 184.727\n",
      "    learner_overall_throughput: 20467.969\n",
      "    learner_overall_time_ms: 244.284\n",
      "  timestamp: 1634117348\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 275152\n",
      "  training_iteration: 11\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 32.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         4470.76</td><td style=\"text-align: right;\">275152</td><td style=\"text-align: right;\">    0.36</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">            272.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 300168\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_09-32-36\n",
      "  done: false\n",
      "  episode_len_mean: 316.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.0\n",
      "  episode_reward_mean: 0.02\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 480\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 299487\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 300047\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 298607\n",
      "    last_target_update_ts: 90870000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 2721.242431640625\n",
      "        max_q: 5008807.5\n",
      "        mean_q: 375669.53125\n",
      "        min_q: -20791.80859375\n",
      "    learner_queue:\n",
      "      size_count: 18179\n",
      "      size_mean: 0.78\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      - 2.0\n",
      "      size_std: 0.7291090453423273\n",
      "    num_agent_steps_sampled: 300168\n",
      "    num_steps_sampled: 300168\n",
      "    num_steps_trained: 90880000\n",
      "    num_target_updates: 6058\n",
      "    num_weight_syncs: 748\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.923\n",
      "      policy_default_policy:\n",
      "        added_count: 73840\n",
      "        est_size_bytes: 1231455232\n",
      "        num_entries: 50000\n",
      "        sampled_count: 22780000\n",
      "      replay_time_ms: 299.988\n",
      "      update_priorities_time_ms: 315.572\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 98.84353741496598\n",
      "    ram_util_percent: 69.4482993197279\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05198083381612702\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 44.06531174264552\n",
      "    mean_inference_ms: 1.9556275301672923\n",
      "    mean_raw_obs_processing_ms: 3.0084410291157506\n",
      "  time_since_restore: 4677.879992723465\n",
      "  time_this_iter_s: 207.12343907356262\n",
      "  time_total_s: 4677.879992723465\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 67.205\n",
      "    learner_grad_throughput: 33097.308\n",
      "    learner_grad_time_ms: 151.07\n",
      "    learner_overall_throughput: 22903.739\n",
      "    learner_overall_time_ms: 218.305\n",
      "  timestamp: 1634117556\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 300168\n",
      "  training_iteration: 12\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 32.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         4677.88</td><td style=\"text-align: right;\">300168</td><td style=\"text-align: right;\">    0.02</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">            316.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 325168\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_09-36-03\n",
      "  done: false\n",
      "  episode_len_mean: 388.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: 0.0\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 499\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 324215\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 324687\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 324855\n",
      "    last_target_update_ts: 95055000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 20195.0703125\n",
      "        max_q: 11120569.0\n",
      "        mean_q: 1516449.125\n",
      "        min_q: -52764.79296875\n",
      "    learner_queue:\n",
      "      size_count: 19012\n",
      "      size_mean: 0.56\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.5\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      size_std: 0.6053098380168623\n",
      "    num_agent_steps_sampled: 325168\n",
      "    num_steps_sampled: 325168\n",
      "    num_steps_trained: 95060000\n",
      "    num_target_updates: 6337\n",
      "    num_weight_syncs: 811\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.583\n",
      "      policy_default_policy:\n",
      "        added_count: 79984\n",
      "        est_size_bytes: 1231455232\n",
      "        num_entries: 50000\n",
      "        sampled_count: 23795000\n",
      "      replay_time_ms: 361.717\n",
      "      update_priorities_time_ms: 344.363\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.1170068027211\n",
      "    ram_util_percent: 69.50442176870749\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05208616336985311\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 42.271311156406654\n",
      "    mean_inference_ms: 1.9577983815509123\n",
      "    mean_raw_obs_processing_ms: 2.948482608358745\n",
      "  time_since_restore: 4885.361100912094\n",
      "  time_this_iter_s: 207.48110818862915\n",
      "  time_total_s: 4885.361100912094\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 72.42\n",
      "    learner_grad_throughput: 31756.717\n",
      "    learner_grad_time_ms: 157.447\n",
      "    learner_overall_throughput: 21749.238\n",
      "    learner_overall_time_ms: 229.893\n",
      "  timestamp: 1634117763\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 325168\n",
      "  training_iteration: 13\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 32.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         4885.36</td><td style=\"text-align: right;\">325168</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">            388.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 350200\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_09-39-24\n",
      "  done: false\n",
      "  episode_len_mean: 459.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: 0.0\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 518\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 349023\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 349999\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 349999\n",
      "    last_target_update_ts: 98970000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 26618.138671875\n",
      "        max_q: 91238752.0\n",
      "        mean_q: 5187430.5\n",
      "        min_q: -436379.09375\n",
      "    learner_queue:\n",
      "      size_count: 19798\n",
      "      size_mean: 0.76\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      - 2.0\n",
      "      size_std: 0.7088018058667741\n",
      "    num_agent_steps_sampled: 350200\n",
      "    num_steps_sampled: 350200\n",
      "    num_steps_trained: 98980000\n",
      "    num_target_updates: 6598\n",
      "    num_weight_syncs: 874\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.61\n",
      "      policy_default_policy:\n",
      "        added_count: 86136\n",
      "        est_size_bytes: 1231455232\n",
      "        num_entries: 50000\n",
      "        sampled_count: 24785000\n",
      "      replay_time_ms: 325.585\n",
      "      update_priorities_time_ms: 362.856\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.13076923076923\n",
      "    ram_util_percent: 70.43531468531468\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052195358338551365\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.43896923386755\n",
      "    mean_inference_ms: 1.9599043175751723\n",
      "    mean_raw_obs_processing_ms: 2.862961851312504\n",
      "  time_since_restore: 5086.534648656845\n",
      "  time_this_iter_s: 201.17354774475098\n",
      "  time_total_s: 5086.534648656845\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 77.202\n",
      "    learner_grad_throughput: 29324.174\n",
      "    learner_grad_time_ms: 170.508\n",
      "    learner_overall_throughput: 20044.534\n",
      "    learner_overall_time_ms: 249.445\n",
      "  timestamp: 1634117964\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 350200\n",
      "  training_iteration: 14\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 33.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         5086.53</td><td style=\"text-align: right;\">350200</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">            459.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=150)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 375208\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_09-42-57\n",
      "  done: false\n",
      "  episode_len_mean: 492.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: 0.0\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 539\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 374735\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 375167\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 374791\n",
      "    last_target_update_ts: 103185000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 76385.640625\n",
      "        max_q: 69443712.0\n",
      "        mean_q: 4168082.0\n",
      "        min_q: -2478.599853515625\n",
      "    learner_queue:\n",
      "      size_count: 20638\n",
      "      size_mean: 0.6\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 2.0\n",
      "      - 2.0\n",
      "      size_std: 0.6928203230275508\n",
      "    num_agent_steps_sampled: 375208\n",
      "    num_steps_sampled: 375208\n",
      "    num_steps_trained: 103190000\n",
      "    num_target_updates: 6879\n",
      "    num_weight_syncs: 937\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.578\n",
      "      policy_default_policy:\n",
      "        added_count: 92328\n",
      "        est_size_bytes: 1231455232\n",
      "        num_entries: 50000\n",
      "        sampled_count: 25825000\n",
      "      replay_time_ms: 461.962\n",
      "      update_priorities_time_ms: 388.414\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 99.04019933554817\n",
      "    ram_util_percent: 72.2345514950166\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.052290570416620545\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 38.27830996729187\n",
      "    mean_inference_ms: 1.9625364216399062\n",
      "    mean_raw_obs_processing_ms: 2.7435833893689345\n",
      "  time_since_restore: 5298.7860651016235\n",
      "  time_this_iter_s: 212.25141644477844\n",
      "  time_total_s: 5298.7860651016235\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 125.147\n",
      "    learner_grad_throughput: 28257.361\n",
      "    learner_grad_time_ms: 176.945\n",
      "    learner_overall_throughput: 16549.785\n",
      "    learner_overall_time_ms: 302.119\n",
      "  timestamp: 1634118177\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 375208\n",
      "  training_iteration: 15\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 34.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         5298.79</td><td style=\"text-align: right;\">375208</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">            492.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=149)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=147)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for APEX_my_env_95522_00000:\n",
      "  agent_timesteps_total: 400208\n",
      "  custom_metrics: {}\n",
      "  date: 2021-10-13_09-46-58\n",
      "  done: false\n",
      "  episode_len_mean: 490.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.0\n",
      "  episode_reward_mean: 0.0\n",
      "  episode_reward_min: 0.0\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 557\n",
      "  experiment_id: 761a764a1328456a9969c858fe012428\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    exploration_infos:\n",
      "    - cur_epsilon: 0.0\n",
      "      last_timestep: 0\n",
      "    - cur_epsilon: 0.4\n",
      "      last_timestep: 399607\n",
      "    - cur_epsilon: 0.016190861620062107\n",
      "      last_timestep: 399831\n",
      "    - cur_epsilon: 0.0006553600000000003\n",
      "      last_timestep: 399863\n",
      "    last_target_update_ts: 107295000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_lr: 0.0005\n",
      "        grad_gnorm: 5459.8154296875\n",
      "        max_q: 32462.51171875\n",
      "        mean_q: 406.15838623046875\n",
      "        min_q: -1212.914794921875\n",
      "    learner_queue:\n",
      "      size_count: 21462\n",
      "      size_mean: 0.44\n",
      "      size_quantiles:\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      size_std: 0.4963869458396343\n",
      "    num_agent_steps_sampled: 400208\n",
      "    num_steps_sampled: 400208\n",
      "    num_steps_trained: 107305000\n",
      "    num_target_updates: 7153\n",
      "    num_weight_syncs: 999\n",
      "    replay_shard_0:\n",
      "      add_batch_time_ms: 0.703\n",
      "      policy_default_policy:\n",
      "        added_count: 98088\n",
      "        est_size_bytes: 1231455232\n",
      "        num_entries: 50000\n",
      "        sampled_count: 26885000\n",
      "      replay_time_ms: 393.151\n",
      "      update_priorities_time_ms: 319.339\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33812316715543\n",
      "    ram_util_percent: 74.341642228739\n",
      "  pid: 152\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05233181609077782\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.72557921175712\n",
      "    mean_inference_ms: 1.963905446239985\n",
      "    mean_raw_obs_processing_ms: 2.683319431555111\n",
      "  time_since_restore: 5540.5293979644775\n",
      "  time_this_iter_s: 241.743332862854\n",
      "  time_total_s: 5540.5293979644775\n",
      "  timers:\n",
      "    learner_dequeue_time_ms: 53.924\n",
      "    learner_grad_throughput: 26239.915\n",
      "    learner_grad_time_ms: 190.549\n",
      "    learner_overall_throughput: 20449.854\n",
      "    learner_overall_time_ms: 244.501\n",
      "  timestamp: 1634118418\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 400208\n",
      "  training_iteration: 16\n",
      "  trial_id: '95522_00000'\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 35.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 8.0/8 CPUs, 1.0/1 GPUs, 0.0/27.98 GiB heap, 0.0/13.99 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/APEX_2021-10-13_08-14-27<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_95522_00000</td><td>RUNNING </td><td>192.168.3.5:152</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         5540.53</td><td style=\"text-align: right;\">400208</td><td style=\"text-align: right;\">       0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">                   0</td><td style=\"text-align: right;\">            490.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(ApexTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"gamma\": 0.95,\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"buffer_size\": 200000,\n",
    "             \"learning_starts\": 5000,\n",
    "             \"train_batch_size\": 5000,\n",
    "             \"target_network_update_freq\": 10000,\n",
    "             \"prioritized_replay_alpha\": 0.5,\n",
    "             \"final_prioritized_replay_beta\": 1.0,\n",
    "             \"min_iter_time_s\": 10,\n",
    "             \"rollout_fragment_length\": 8,\n",
    "             \"collect_metrics_timeout\": 1800,\n",
    "             \n",
    "             \"v_min\": -20.0,\n",
    "             \"v_max\": 20.0,\n",
    "             \n",
    "             \"exploration_config\": {\n",
    "                  \"initial_epsilon\": 1,\n",
    "                  \"epsilon_timesteps\": 500000,\n",
    "                  \"final_epsilon\": 0.05,\n",
    "              },\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"APEX C8 pretrained (AnnaCNN) gamma: 0.95\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a0386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55735f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a457f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebfaee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
