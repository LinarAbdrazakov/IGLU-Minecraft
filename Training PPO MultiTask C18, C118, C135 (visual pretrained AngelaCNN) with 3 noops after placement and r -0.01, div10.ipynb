{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 256 \n",
    "        self.policy_network = nn.Sequential(\n",
    "            nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            #nn.ELU(),\n",
    "        )\n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        target_features = target_features.reshape(target_features.shape[0], -1)\n",
    "        features = torch.cat([visual_features, target_features], dim=1)\n",
    "        features = self.policy_network(features)\n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=250)\n",
    "    env.update_taskset(TaskSet(preset=[\"C18\", \"C118\", \"C135\"]))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 3.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 03:44:58,953\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-11-09 03:44:59,031\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=170)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=170)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO MultiTask (C18, C118, C135) pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/693ef_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/693ef_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211109_034459-693ef_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=170)\u001b[0m 2021-11-09 03:45:02,453\tWARNING ppo.py:143 -- `train_batch_size` (1000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 333.\n",
      "\u001b[2m\u001b[36m(pid=170)\u001b[0m 2021-11-09 03:45:02,453\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=170)\u001b[0m 2021-11-09 03:45:02,453\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=170)\u001b[0m 2021-11-09 03:45:11,832\tINFO trainable.py:109 -- Trainable.setup took 11.904 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=170)\u001b[0m 2021-11-09 03:45:11,833\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1998\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-47-34\n",
      "  done: false\n",
      "  episode_len_mean: 97.57894736842105\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.6099999999999995\n",
      "  episode_reward_mean: -0.909473684210527\n",
      "  episode_reward_min: -1.2300000000000006\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 19\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.8806217715853735\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006584135617869674\n",
      "          policy_loss: -0.023850587968315396\n",
      "          total_loss: -0.03545709422656468\n",
      "          vf_explained_var: -0.20217332243919373\n",
      "          vf_loss: 0.015882883601478257\n",
      "    num_agent_steps_sampled: 1998\n",
      "    num_agent_steps_trained: 1998\n",
      "    num_steps_sampled: 1998\n",
      "    num_steps_trained: 1998\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.294117647058826\n",
      "    ram_util_percent: 22.08186274509804\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04362967813305646\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 197.16425936477745\n",
      "    mean_inference_ms: 4.4630756602426125\n",
      "    mean_raw_obs_processing_ms: 0.6022061430964879\n",
      "  time_since_restore: 142.8224904537201\n",
      "  time_this_iter_s: 142.8224904537201\n",
      "  time_total_s: 142.8224904537201\n",
      "  timers:\n",
      "    learn_throughput: 542.911\n",
      "    learn_time_ms: 3680.159\n",
      "    load_throughput: 57445.585\n",
      "    load_time_ms: 34.781\n",
      "    sample_throughput: 14.366\n",
      "    sample_time_ms: 139082.471\n",
      "    update_time_ms: 10.875\n",
      "  timestamp: 1636429654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1998\n",
      "  training_iteration: 1\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         142.822</td><td style=\"text-align: right;\">1998</td><td style=\"text-align: right;\">-0.909474</td><td style=\"text-align: right;\">                0.61</td><td style=\"text-align: right;\">               -1.23</td><td style=\"text-align: right;\">           97.5789</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 3996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-48-11\n",
      "  done: false\n",
      "  episode_len_mean: 98.74358974358974\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.700000000000002\n",
      "  episode_reward_mean: -0.6966666666666671\n",
      "  episode_reward_min: -1.5300000000000007\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 39\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.8770361048834663\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0066759370025840595\n",
      "          policy_loss: -0.05041158185118721\n",
      "          total_loss: 0.03938928218114944\n",
      "          vf_explained_var: -0.38334691524505615\n",
      "          vf_loss: 0.11723603822645687\n",
      "    num_agent_steps_sampled: 3996\n",
      "    num_agent_steps_trained: 3996\n",
      "    num_steps_sampled: 3996\n",
      "    num_steps_trained: 3996\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13076923076923\n",
      "    ram_util_percent: 27.84807692307692\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0432082416643283\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 158.30378564332497\n",
      "    mean_inference_ms: 3.9318242074536394\n",
      "    mean_raw_obs_processing_ms: 0.6118157320672645\n",
      "  time_since_restore: 179.31470727920532\n",
      "  time_this_iter_s: 36.49221682548523\n",
      "  time_total_s: 179.31470727920532\n",
      "  timers:\n",
      "    learn_throughput: 742.58\n",
      "    learn_time_ms: 2690.618\n",
      "    load_throughput: 59171.893\n",
      "    load_time_ms: 33.766\n",
      "    sample_throughput: 23.185\n",
      "    sample_time_ms: 86176.729\n",
      "    update_time_ms: 10.633\n",
      "  timestamp: 1636429691\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3996\n",
      "  training_iteration: 2\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         179.315</td><td style=\"text-align: right;\">3996</td><td style=\"text-align: right;\">-0.696667</td><td style=\"text-align: right;\">                 2.7</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">           98.7436</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 5994\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-48-46\n",
      "  done: false\n",
      "  episode_len_mean: 97.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.700000000000002\n",
      "  episode_reward_mean: -0.7291666666666673\n",
      "  episode_reward_min: -1.5300000000000007\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 60\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.861031421025594\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007369407822213738\n",
      "          policy_loss: -0.0378443037292787\n",
      "          total_loss: 0.013340669143058004\n",
      "          vf_explained_var: -0.006641898769885302\n",
      "          vf_loss: 0.0783214052917347\n",
      "    num_agent_steps_sampled: 5994\n",
      "    num_agent_steps_trained: 5994\n",
      "    num_steps_sampled: 5994\n",
      "    num_steps_trained: 5994\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.19803921568625\n",
      "    ram_util_percent: 27.752941176470586\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04316920646220225\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 136.0863885514258\n",
      "    mean_inference_ms: 3.6365567488379877\n",
      "    mean_raw_obs_processing_ms: 0.6113268998925688\n",
      "  time_since_restore: 215.0480682849884\n",
      "  time_this_iter_s: 35.73336100578308\n",
      "  time_total_s: 215.0480682849884\n",
      "  timers:\n",
      "    learn_throughput: 843.38\n",
      "    learn_time_ms: 2369.038\n",
      "    load_throughput: 59105.953\n",
      "    load_time_ms: 33.804\n",
      "    sample_throughput: 29.054\n",
      "    sample_time_ms: 68769.022\n",
      "    update_time_ms: 10.517\n",
      "  timestamp: 1636429726\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5994\n",
      "  training_iteration: 3\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         215.048</td><td style=\"text-align: right;\">5994</td><td style=\"text-align: right;\">-0.729167</td><td style=\"text-align: right;\">                 2.7</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">             97.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 7992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-49-10\n",
      "  done: false\n",
      "  episode_len_mean: 98.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.700000000000002\n",
      "  episode_reward_mean: -0.7448750000000006\n",
      "  episode_reward_min: -1.5300000000000007\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 80\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.848040275346665\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007734790442975093\n",
      "          policy_loss: -0.028485655607212158\n",
      "          total_loss: 0.0030356629618576597\n",
      "          vf_explained_var: 0.30136972665786743\n",
      "          vf_loss: 0.05845476226171567\n",
      "    num_agent_steps_sampled: 7992\n",
      "    num_agent_steps_trained: 7992\n",
      "    num_steps_sampled: 7992\n",
      "    num_steps_trained: 7992\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08823529411765\n",
      "    ram_util_percent: 27.564705882352943\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04319265521385029\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 121.63223187438457\n",
      "    mean_inference_ms: 3.460430076163346\n",
      "    mean_raw_obs_processing_ms: 0.6109947645621355\n",
      "  time_since_restore: 238.5671422481537\n",
      "  time_this_iter_s: 23.519073963165283\n",
      "  time_total_s: 238.5671422481537\n",
      "  timers:\n",
      "    learn_throughput: 907.952\n",
      "    learn_time_ms: 2200.557\n",
      "    load_throughput: 59148.192\n",
      "    load_time_ms: 33.78\n",
      "    sample_throughput: 35.041\n",
      "    sample_time_ms: 57019.729\n",
      "    update_time_ms: 9.985\n",
      "  timestamp: 1636429750\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7992\n",
      "  training_iteration: 4\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         238.567</td><td style=\"text-align: right;\">7992</td><td style=\"text-align: right;\">-0.744875</td><td style=\"text-align: right;\">                 2.7</td><td style=\"text-align: right;\">               -1.53</td><td style=\"text-align: right;\">             98.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 9990\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-49-34\n",
      "  done: false\n",
      "  episode_len_mean: 97.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.700000000000002\n",
      "  episode_reward_mean: -0.7832000000000003\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 102\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.831816110156831\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009299715703708309\n",
      "          policy_loss: -0.038965600977341336\n",
      "          total_loss: 0.013745234214833804\n",
      "          vf_explained_var: -0.24511729180812836\n",
      "          vf_loss: 0.07916905069280239\n",
      "    num_agent_steps_sampled: 9990\n",
      "    num_agent_steps_trained: 9990\n",
      "    num_steps_sampled: 9990\n",
      "    num_steps_trained: 9990\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.35588235294118\n",
      "    ram_util_percent: 27.291176470588237\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04328194483217647\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 108.33881833981579\n",
      "    mean_inference_ms: 3.3080817382257965\n",
      "    mean_raw_obs_processing_ms: 0.6152239087698619\n",
      "  time_since_restore: 262.4587595462799\n",
      "  time_this_iter_s: 23.89161729812622\n",
      "  time_total_s: 262.4587595462799\n",
      "  timers:\n",
      "    learn_throughput: 952.311\n",
      "    learn_time_ms: 2098.054\n",
      "    load_throughput: 59297.166\n",
      "    load_time_ms: 33.695\n",
      "    sample_throughput: 39.923\n",
      "    sample_time_ms: 50046.036\n",
      "    update_time_ms: 9.834\n",
      "  timestamp: 1636429774\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9990\n",
      "  training_iteration: 5\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         262.459</td><td style=\"text-align: right;\">9990</td><td style=\"text-align: right;\"> -0.7832</td><td style=\"text-align: right;\">                 2.7</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">              97.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 11988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-49-57\n",
      "  done: false\n",
      "  episode_len_mean: 98.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.700000000000002\n",
      "  episode_reward_mean: -0.6319000000000002\n",
      "  episode_reward_min: -1.7300000000000009\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 120\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.8040067229952133\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011525091099372225\n",
      "          policy_loss: -0.0662038639897392\n",
      "          total_loss: 0.15664281027302857\n",
      "          vf_explained_var: 0.11742359399795532\n",
      "          vf_loss: 0.2485817239398048\n",
      "    num_agent_steps_sampled: 11988\n",
      "    num_agent_steps_trained: 11988\n",
      "    num_steps_sampled: 11988\n",
      "    num_steps_trained: 11988\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.253125\n",
      "    ram_util_percent: 27.00625\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04328427737534772\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 84.69577556861668\n",
      "    mean_inference_ms: 3.012947840298109\n",
      "    mean_raw_obs_processing_ms: 0.6179812153997062\n",
      "  time_since_restore: 285.13552737236023\n",
      "  time_this_iter_s: 22.676767826080322\n",
      "  time_total_s: 285.13552737236023\n",
      "  timers:\n",
      "    learn_throughput: 982.957\n",
      "    learn_time_ms: 2032.643\n",
      "    load_throughput: 59329.197\n",
      "    load_time_ms: 33.677\n",
      "    sample_throughput: 44.212\n",
      "    sample_time_ms: 45191.255\n",
      "    update_time_ms: 9.568\n",
      "  timestamp: 1636429797\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11988\n",
      "  training_iteration: 6\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         285.136</td><td style=\"text-align: right;\">11988</td><td style=\"text-align: right;\"> -0.6319</td><td style=\"text-align: right;\">                 2.7</td><td style=\"text-align: right;\">               -1.73</td><td style=\"text-align: right;\">             98.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 13986\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-50-20\n",
      "  done: false\n",
      "  episode_len_mean: 98.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 2.880000000000003\n",
      "  episode_reward_mean: -0.5854\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 140\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.785818288439796\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009334025365896418\n",
      "          policy_loss: 2.627488048303695e-05\n",
      "          total_loss: 0.1751351712892453\n",
      "          vf_explained_var: 0.24862638115882874\n",
      "          vf_loss: 0.2011002762775336\n",
      "    num_agent_steps_sampled: 13986\n",
      "    num_agent_steps_trained: 13986\n",
      "    num_steps_sampled: 13986\n",
      "    num_steps_trained: 13986\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.26764705882353\n",
      "    ram_util_percent: 26.84705882352941\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04334927980620641\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 72.0135777088122\n",
      "    mean_inference_ms: 2.878051939811871\n",
      "    mean_raw_obs_processing_ms: 0.6206148245773474\n",
      "  time_since_restore: 308.7155649662018\n",
      "  time_this_iter_s: 23.580037593841553\n",
      "  time_total_s: 308.7155649662018\n",
      "  timers:\n",
      "    learn_throughput: 1005.312\n",
      "    learn_time_ms: 1987.443\n",
      "    load_throughput: 60229.428\n",
      "    load_time_ms: 33.173\n",
      "    sample_throughput: 47.741\n",
      "    sample_time_ms: 41851.257\n",
      "    update_time_ms: 10.064\n",
      "  timestamp: 1636429820\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13986\n",
      "  training_iteration: 7\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         308.716</td><td style=\"text-align: right;\">13986</td><td style=\"text-align: right;\"> -0.5854</td><td style=\"text-align: right;\">                2.88</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">             98.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 15984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-50-44\n",
      "  done: false\n",
      "  episode_len_mean: 100.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.250000000000012\n",
      "  episode_reward_mean: -0.3767999999999997\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 159\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.7585929757072813\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01013494827003848\n",
      "          policy_loss: 0.009691825863860902\n",
      "          total_loss: 0.2506728465624508\n",
      "          vf_explained_var: 0.3480892777442932\n",
      "          vf_loss: 0.26653996494909127\n",
      "    num_agent_steps_sampled: 15984\n",
      "    num_agent_steps_trained: 15984\n",
      "    num_steps_sampled: 15984\n",
      "    num_steps_trained: 15984\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.70294117647059\n",
      "    ram_util_percent: 26.84705882352941\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04345086531033131\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 64.08820559975443\n",
      "    mean_inference_ms: 2.806870697119663\n",
      "    mean_raw_obs_processing_ms: 0.6253600708950812\n",
      "  time_since_restore: 332.674143075943\n",
      "  time_this_iter_s: 23.95857810974121\n",
      "  time_total_s: 332.674143075943\n",
      "  timers:\n",
      "    learn_throughput: 1005.973\n",
      "    learn_time_ms: 1986.137\n",
      "    load_throughput: 58819.341\n",
      "    load_time_ms: 33.968\n",
      "    sample_throughput: 50.764\n",
      "    sample_time_ms: 39358.847\n",
      "    update_time_ms: 11.373\n",
      "  timestamp: 1636429844\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15984\n",
      "  training_iteration: 8\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         332.674</td><td style=\"text-align: right;\">15984</td><td style=\"text-align: right;\"> -0.3768</td><td style=\"text-align: right;\">                4.25</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">            100.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 17982\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-51-09\n",
      "  done: false\n",
      "  episode_len_mean: 101.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.250000000000012\n",
      "  episode_reward_mean: -0.27059999999999945\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 179\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.739664766902015\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01072021724127623\n",
      "          policy_loss: -0.06531109037321238\n",
      "          total_loss: 0.08617791839476142\n",
      "          vf_explained_var: 0.3902914822101593\n",
      "          vf_loss: 0.17674161286226342\n",
      "    num_agent_steps_sampled: 17982\n",
      "    num_agent_steps_trained: 17982\n",
      "    num_steps_sampled: 17982\n",
      "    num_steps_trained: 17982\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.49428571428572\n",
      "    ram_util_percent: 27.257142857142856\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043556634733316064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 58.336995386996676\n",
      "    mean_inference_ms: 2.7595514935018075\n",
      "    mean_raw_obs_processing_ms: 0.6324455254286891\n",
      "  time_since_restore: 357.11549282073975\n",
      "  time_this_iter_s: 24.441349744796753\n",
      "  time_total_s: 357.11549282073975\n",
      "  timers:\n",
      "    learn_throughput: 1020.431\n",
      "    learn_time_ms: 1957.997\n",
      "    load_throughput: 59035.816\n",
      "    load_time_ms: 33.844\n",
      "    sample_throughput: 53.276\n",
      "    sample_time_ms: 37502.582\n",
      "    update_time_ms: 11.739\n",
      "  timestamp: 1636429869\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17982\n",
      "  training_iteration: 9\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         357.115</td><td style=\"text-align: right;\">17982</td><td style=\"text-align: right;\"> -0.2706</td><td style=\"text-align: right;\">                4.25</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">            101.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 19980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-51-32\n",
      "  done: false\n",
      "  episode_len_mean: 103.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.250000000000012\n",
      "  episode_reward_mean: -0.041699999999998905\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 197\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.710440783273606\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010437243967857454\n",
      "          policy_loss: -0.09070835166743824\n",
      "          total_loss: 0.10713364991048972\n",
      "          vf_explained_var: 0.6435344815254211\n",
      "          vf_loss: 0.22285895812369527\n",
      "    num_agent_steps_sampled: 19980\n",
      "    num_agent_steps_trained: 19980\n",
      "    num_steps_sampled: 19980\n",
      "    num_steps_trained: 19980\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28181818181817\n",
      "    ram_util_percent: 27.239393939393942\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0435805906958287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 54.6506697180811\n",
      "    mean_inference_ms: 2.731812532514381\n",
      "    mean_raw_obs_processing_ms: 0.6367387659075424\n",
      "  time_since_restore: 380.41667437553406\n",
      "  time_this_iter_s: 23.30118155479431\n",
      "  time_total_s: 380.41667437553406\n",
      "  timers:\n",
      "    learn_throughput: 1028.644\n",
      "    learn_time_ms: 1942.362\n",
      "    load_throughput: 59419.852\n",
      "    load_time_ms: 33.625\n",
      "    sample_throughput: 55.66\n",
      "    sample_time_ms: 35896.433\n",
      "    update_time_ms: 12.184\n",
      "  timestamp: 1636429892\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19980\n",
      "  training_iteration: 10\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         380.417</td><td style=\"text-align: right;\">19980</td><td style=\"text-align: right;\"> -0.0417</td><td style=\"text-align: right;\">                4.25</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">            103.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 21978\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-51-55\n",
      "  done: false\n",
      "  episode_len_mean: 104.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.370000000000015\n",
      "  episode_reward_mean: 0.08510000000000158\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 216\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.690909316426232\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012168906313704946\n",
      "          policy_loss: -0.026069822091431844\n",
      "          total_loss: 0.15874426171538375\n",
      "          vf_explained_var: 0.3870446979999542\n",
      "          vf_loss: 0.20928939314825193\n",
      "    num_agent_steps_sampled: 21978\n",
      "    num_agent_steps_trained: 21978\n",
      "    num_steps_sampled: 21978\n",
      "    num_steps_trained: 21978\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.18787878787879\n",
      "    ram_util_percent: 27.187878787878788\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0436640212273249\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 51.40752955922822\n",
      "    mean_inference_ms: 2.7097998358360895\n",
      "    mean_raw_obs_processing_ms: 0.6404590356383644\n",
      "  time_since_restore: 402.90690445899963\n",
      "  time_this_iter_s: 22.490230083465576\n",
      "  time_total_s: 402.90690445899963\n",
      "  timers:\n",
      "    learn_throughput: 1140.912\n",
      "    learn_time_ms: 1751.23\n",
      "    load_throughput: 59293.264\n",
      "    load_time_ms: 33.697\n",
      "    sample_throughput: 83.06\n",
      "    sample_time_ms: 24054.883\n",
      "    update_time_ms: 12.059\n",
      "  timestamp: 1636429915\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21978\n",
      "  training_iteration: 11\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         402.907</td><td style=\"text-align: right;\">21978</td><td style=\"text-align: right;\">  0.0851</td><td style=\"text-align: right;\">                4.37</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">            104.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 23976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-52-17\n",
      "  done: false\n",
      "  episode_len_mean: 105.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.370000000000015\n",
      "  episode_reward_mean: 0.25850000000000206\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 234\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6625054507028487\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011115534533092164\n",
      "          policy_loss: -0.06261468574049928\n",
      "          total_loss: 0.16776738231558175\n",
      "          vf_explained_var: 0.5173304080963135\n",
      "          vf_loss: 0.2547840120182151\n",
      "    num_agent_steps_sampled: 23976\n",
      "    num_agent_steps_trained: 23976\n",
      "    num_steps_sampled: 23976\n",
      "    num_steps_trained: 23976\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.39375000000001\n",
      "    ram_util_percent: 27.09375\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04376736057547672\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 49.0503321007013\n",
      "    mean_inference_ms: 2.6948118532604037\n",
      "    mean_raw_obs_processing_ms: 0.6426465783355053\n",
      "  time_since_restore: 425.65432929992676\n",
      "  time_this_iter_s: 22.747424840927124\n",
      "  time_total_s: 425.65432929992676\n",
      "  timers:\n",
      "    learn_throughput: 1139.637\n",
      "    learn_time_ms: 1753.19\n",
      "    load_throughput: 59117.253\n",
      "    load_time_ms: 33.797\n",
      "    sample_throughput: 87.537\n",
      "    sample_time_ms: 22824.76\n",
      "    update_time_ms: 12.142\n",
      "  timestamp: 1636429937\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 23976\n",
      "  training_iteration: 12\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         425.654</td><td style=\"text-align: right;\">23976</td><td style=\"text-align: right;\">  0.2585</td><td style=\"text-align: right;\">                4.37</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">             105.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 25974\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-52-40\n",
      "  done: false\n",
      "  episode_len_mean: 106.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.520000000000007\n",
      "  episode_reward_mean: 0.34620000000000234\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 253\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.68172238327208\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012785486105883313\n",
      "          policy_loss: 0.022145873450097584\n",
      "          total_loss: 0.20181282230076336\n",
      "          vf_explained_var: 0.5174775719642639\n",
      "          vf_loss: 0.2039270740534578\n",
      "    num_agent_steps_sampled: 25974\n",
      "    num_agent_steps_trained: 25974\n",
      "    num_steps_sampled: 25974\n",
      "    num_steps_trained: 25974\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1125\n",
      "    ram_util_percent: 27.109375\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04386469119981964\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 46.94893717126064\n",
      "    mean_inference_ms: 2.681031307016201\n",
      "    mean_raw_obs_processing_ms: 0.6447192850396561\n",
      "  time_since_restore: 447.86943793296814\n",
      "  time_this_iter_s: 22.215108633041382\n",
      "  time_total_s: 447.86943793296814\n",
      "  timers:\n",
      "    learn_throughput: 1136.581\n",
      "    learn_time_ms: 1757.903\n",
      "    load_throughput: 59192.958\n",
      "    load_time_ms: 33.754\n",
      "    sample_throughput: 93.066\n",
      "    sample_time_ms: 21468.734\n",
      "    update_time_ms: 11.615\n",
      "  timestamp: 1636429960\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 25974\n",
      "  training_iteration: 13\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         447.869</td><td style=\"text-align: right;\">25974</td><td style=\"text-align: right;\">  0.3462</td><td style=\"text-align: right;\">                4.52</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">            106.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 27972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-53-04\n",
      "  done: false\n",
      "  episode_len_mean: 105.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.77000000000001\n",
      "  episode_reward_mean: 0.6131000000000029\n",
      "  episode_reward_min: -2.0599999999999996\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 273\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6799786840166364\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01297668941320265\n",
      "          policy_loss: -0.009017946961380186\n",
      "          total_loss: 0.22819045759914885\n",
      "          vf_explained_var: 0.4938800036907196\n",
      "          vf_loss: 0.26141285250584284\n",
      "    num_agent_steps_sampled: 27972\n",
      "    num_agent_steps_trained: 27972\n",
      "    num_steps_sampled: 27972\n",
      "    num_steps_trained: 27972\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.31142857142858\n",
      "    ram_util_percent: 27.062857142857144\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04397579194054637\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.14030670258444\n",
      "    mean_inference_ms: 2.6669132399106856\n",
      "    mean_raw_obs_processing_ms: 0.6457910406268905\n",
      "  time_since_restore: 472.37235260009766\n",
      "  time_this_iter_s: 24.502914667129517\n",
      "  time_total_s: 472.37235260009766\n",
      "  timers:\n",
      "    learn_throughput: 1133.533\n",
      "    learn_time_ms: 1762.631\n",
      "    load_throughput: 59173.105\n",
      "    load_time_ms: 33.765\n",
      "    sample_throughput: 92.664\n",
      "    sample_time_ms: 21561.726\n",
      "    update_time_ms: 12.051\n",
      "  timestamp: 1636429984\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 27972\n",
      "  training_iteration: 14\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         472.372</td><td style=\"text-align: right;\">27972</td><td style=\"text-align: right;\">  0.6131</td><td style=\"text-align: right;\">                6.77</td><td style=\"text-align: right;\">               -2.06</td><td style=\"text-align: right;\">            105.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 29970\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-53-27\n",
      "  done: false\n",
      "  episode_len_mean: 105.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.77000000000001\n",
      "  episode_reward_mean: 0.7318000000000027\n",
      "  episode_reward_min: -1.8500000000000008\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 292\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.648894767534165\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012303933054336656\n",
      "          policy_loss: -0.005256513719047819\n",
      "          total_loss: 0.2683465646845954\n",
      "          vf_explained_var: 0.3295733630657196\n",
      "          vf_loss: 0.2976312365915094\n",
      "    num_agent_steps_sampled: 29970\n",
      "    num_agent_steps_trained: 29970\n",
      "    num_steps_sampled: 29970\n",
      "    num_steps_trained: 29970\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.23333333333333\n",
      "    ram_util_percent: 26.990909090909092\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044052837446878976\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 43.695255016666685\n",
      "    mean_inference_ms: 2.6545994474109538\n",
      "    mean_raw_obs_processing_ms: 0.646080624262136\n",
      "  time_since_restore: 495.7312717437744\n",
      "  time_this_iter_s: 23.358919143676758\n",
      "  time_total_s: 495.7312717437744\n",
      "  timers:\n",
      "    learn_throughput: 1130.466\n",
      "    learn_time_ms: 1767.413\n",
      "    load_throughput: 59508.883\n",
      "    load_time_ms: 33.575\n",
      "    sample_throughput: 92.914\n",
      "    sample_time_ms: 21503.76\n",
      "    update_time_ms: 12.216\n",
      "  timestamp: 1636430007\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29970\n",
      "  training_iteration: 15\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         495.731</td><td style=\"text-align: right;\">29970</td><td style=\"text-align: right;\">  0.7318</td><td style=\"text-align: right;\">                6.77</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">            105.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 31968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-53-51\n",
      "  done: false\n",
      "  episode_len_mean: 104.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.77000000000001\n",
      "  episode_reward_mean: 0.8752000000000028\n",
      "  episode_reward_min: -1.8500000000000008\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 312\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6457430283228556\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010650878184077072\n",
      "          policy_loss: -0.03457434759253547\n",
      "          total_loss: 0.15997487060903084\n",
      "          vf_explained_var: 0.5131697058677673\n",
      "          vf_loss: 0.21887647098019009\n",
      "    num_agent_steps_sampled: 31968\n",
      "    num_agent_steps_trained: 31968\n",
      "    num_steps_sampled: 31968\n",
      "    num_steps_trained: 31968\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84411764705882\n",
      "    ram_util_percent: 26.985294117647058\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04405627321057576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 42.43435527436904\n",
      "    mean_inference_ms: 2.6417050289278405\n",
      "    mean_raw_obs_processing_ms: 0.6474792127947394\n",
      "  time_since_restore: 519.3124468326569\n",
      "  time_this_iter_s: 23.581175088882446\n",
      "  time_total_s: 519.3124468326569\n",
      "  timers:\n",
      "    learn_throughput: 1128.112\n",
      "    learn_time_ms: 1771.101\n",
      "    load_throughput: 59402.541\n",
      "    load_time_ms: 33.635\n",
      "    sample_throughput: 92.54\n",
      "    sample_time_ms: 21590.588\n",
      "    update_time_ms: 12.097\n",
      "  timestamp: 1636430031\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 31968\n",
      "  training_iteration: 16\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         519.312</td><td style=\"text-align: right;\">31968</td><td style=\"text-align: right;\">  0.8752</td><td style=\"text-align: right;\">                6.77</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">            104.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 33966\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-54-15\n",
      "  done: false\n",
      "  episode_len_mean: 103.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.77000000000001\n",
      "  episode_reward_mean: 0.8570000000000025\n",
      "  episode_reward_min: -1.8500000000000008\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 332\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.6360355297724407\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012597189882501674\n",
      "          policy_loss: -0.023945605435541698\n",
      "          total_loss: 0.21889139010260503\n",
      "          vf_explained_var: 0.45043864846229553\n",
      "          vf_loss: 0.2666779096637453\n",
      "    num_agent_steps_sampled: 33966\n",
      "    num_agent_steps_trained: 33966\n",
      "    num_steps_sampled: 33966\n",
      "    num_steps_trained: 33966\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11764705882354\n",
      "    ram_util_percent: 26.970588235294116\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04410016251245514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.38954230203541\n",
      "    mean_inference_ms: 2.630915621583897\n",
      "    mean_raw_obs_processing_ms: 0.6489436756625834\n",
      "  time_since_restore: 543.4371542930603\n",
      "  time_this_iter_s: 24.124707460403442\n",
      "  time_total_s: 543.4371542930603\n",
      "  timers:\n",
      "    learn_throughput: 1124.147\n",
      "    learn_time_ms: 1777.347\n",
      "    load_throughput: 59012.056\n",
      "    load_time_ms: 33.857\n",
      "    sample_throughput: 92.332\n",
      "    sample_time_ms: 21639.263\n",
      "    update_time_ms: 11.369\n",
      "  timestamp: 1636430055\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 33966\n",
      "  training_iteration: 17\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         543.437</td><td style=\"text-align: right;\">33966</td><td style=\"text-align: right;\">   0.857</td><td style=\"text-align: right;\">                6.77</td><td style=\"text-align: right;\">               -1.85</td><td style=\"text-align: right;\">            103.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 35964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-54-56\n",
      "  done: false\n",
      "  episode_len_mean: 100.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.77000000000001\n",
      "  episode_reward_mean: 0.910700000000003\n",
      "  episode_reward_min: -1.8300000000000007\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 352\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5943632137207757\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011688008011139131\n",
      "          policy_loss: -0.012254692223810015\n",
      "          total_loss: 0.257935588079549\n",
      "          vf_explained_var: 0.556313157081604\n",
      "          vf_loss: 0.2937963085160369\n",
      "    num_agent_steps_sampled: 35964\n",
      "    num_agent_steps_trained: 35964\n",
      "    num_steps_sampled: 35964\n",
      "    num_steps_trained: 35964\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.72413793103448\n",
      "    ram_util_percent: 26.615517241379308\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04415618733197596\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 40.54344770454022\n",
      "    mean_inference_ms: 2.622113642032513\n",
      "    mean_raw_obs_processing_ms: 0.7662362253231001\n",
      "  time_since_restore: 583.8991606235504\n",
      "  time_this_iter_s: 40.46200633049011\n",
      "  time_total_s: 583.8991606235504\n",
      "  timers:\n",
      "    learn_throughput: 1141.197\n",
      "    learn_time_ms: 1750.793\n",
      "    load_throughput: 59865.338\n",
      "    load_time_ms: 33.375\n",
      "    sample_throughput: 85.685\n",
      "    sample_time_ms: 23318.0\n",
      "    update_time_ms: 9.807\n",
      "  timestamp: 1636430096\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 35964\n",
      "  training_iteration: 18\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         583.899</td><td style=\"text-align: right;\">35964</td><td style=\"text-align: right;\">  0.9107</td><td style=\"text-align: right;\">                6.77</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">            100.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 37962\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-55-40\n",
      "  done: false\n",
      "  episode_len_mean: 99.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.310000000000015\n",
      "  episode_reward_mean: 0.9985000000000034\n",
      "  episode_reward_min: -1.8300000000000007\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 373\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.568525317737034\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017081214762871593\n",
      "          policy_loss: -0.042039944302468074\n",
      "          total_loss: 0.3400922513966049\n",
      "          vf_explained_var: 0.6192892789840698\n",
      "          vf_loss: 0.40440120767979393\n",
      "    num_agent_steps_sampled: 37962\n",
      "    num_agent_steps_trained: 37962\n",
      "    num_steps_sampled: 37962\n",
      "    num_steps_trained: 37962\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.64126984126985\n",
      "    ram_util_percent: 26.528571428571432\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04412145512538462\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 39.7934099094018\n",
      "    mean_inference_ms: 2.613434827558073\n",
      "    mean_raw_obs_processing_ms: 1.0566333466625752\n",
      "  time_since_restore: 627.8530006408691\n",
      "  time_this_iter_s: 43.953840017318726\n",
      "  time_total_s: 627.8530006408691\n",
      "  timers:\n",
      "    learn_throughput: 1140.369\n",
      "    learn_time_ms: 1752.064\n",
      "    load_throughput: 59880.138\n",
      "    load_time_ms: 33.367\n",
      "    sample_throughput: 79.071\n",
      "    sample_time_ms: 25268.392\n",
      "    update_time_ms: 9.271\n",
      "  timestamp: 1636430140\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 37962\n",
      "  training_iteration: 19\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         627.853</td><td style=\"text-align: right;\">37962</td><td style=\"text-align: right;\">  0.9985</td><td style=\"text-align: right;\">                8.31</td><td style=\"text-align: right;\">               -1.83</td><td style=\"text-align: right;\">             99.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 39960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-56-04\n",
      "  done: false\n",
      "  episode_len_mean: 100.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.310000000000015\n",
      "  episode_reward_mean: 1.0676000000000037\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 392\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5500413906006587\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01248535224560672\n",
      "          policy_loss: 0.02676170947296279\n",
      "          total_loss: 0.2943708825146868\n",
      "          vf_explained_var: 0.6623600721359253\n",
      "          vf_loss: 0.2906125173682258\n",
      "    num_agent_steps_sampled: 39960\n",
      "    num_agent_steps_trained: 39960\n",
      "    num_steps_sampled: 39960\n",
      "    num_steps_trained: 39960\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.18285714285713\n",
      "    ram_util_percent: 28.61714285714286\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04411983750045658\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 39.22519677434252\n",
      "    mean_inference_ms: 2.6057829492696913\n",
      "    mean_raw_obs_processing_ms: 1.3073544862267028\n",
      "  time_since_restore: 652.3733847141266\n",
      "  time_this_iter_s: 24.520384073257446\n",
      "  time_total_s: 652.3733847141266\n",
      "  timers:\n",
      "    learn_throughput: 1145.042\n",
      "    learn_time_ms: 1744.915\n",
      "    load_throughput: 59590.722\n",
      "    load_time_ms: 33.529\n",
      "    sample_throughput: 78.668\n",
      "    sample_time_ms: 25397.829\n",
      "    update_time_ms: 8.872\n",
      "  timestamp: 1636430164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39960\n",
      "  training_iteration: 20\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         652.373</td><td style=\"text-align: right;\">39960</td><td style=\"text-align: right;\">  1.0676</td><td style=\"text-align: right;\">                8.31</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">            100.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 41958\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-56-28\n",
      "  done: false\n",
      "  episode_len_mean: 100.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.310000000000015\n",
      "  episode_reward_mean: 1.107100000000004\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 410\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.581750552994864\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013472409887130221\n",
      "          policy_loss: -0.024986294745689346\n",
      "          total_loss: 0.2132646860466117\n",
      "          vf_explained_var: 0.5718298554420471\n",
      "          vf_loss: 0.26137400400780497\n",
      "    num_agent_steps_sampled: 41958\n",
      "    num_agent_steps_trained: 41958\n",
      "    num_steps_sampled: 41958\n",
      "    num_steps_trained: 41958\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92647058823529\n",
      "    ram_util_percent: 28.93823529411765\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044111298896313864\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 38.75785199898601\n",
      "    mean_inference_ms: 2.599508301546989\n",
      "    mean_raw_obs_processing_ms: 1.5323941801572998\n",
      "  time_since_restore: 676.0061590671539\n",
      "  time_this_iter_s: 23.632774353027344\n",
      "  time_total_s: 676.0061590671539\n",
      "  timers:\n",
      "    learn_throughput: 1147.687\n",
      "    learn_time_ms: 1740.892\n",
      "    load_throughput: 59917.6\n",
      "    load_time_ms: 33.346\n",
      "    sample_throughput: 78.303\n",
      "    sample_time_ms: 25516.179\n",
      "    update_time_ms: 8.714\n",
      "  timestamp: 1636430188\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 41958\n",
      "  training_iteration: 21\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         676.006</td><td style=\"text-align: right;\">41958</td><td style=\"text-align: right;\">  1.1071</td><td style=\"text-align: right;\">                8.31</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">            100.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 43956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-56-52\n",
      "  done: false\n",
      "  episode_len_mean: 101.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.310000000000015\n",
      "  episode_reward_mean: 1.3439000000000043\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 429\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5109811317353024\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01701473282308446\n",
      "          policy_loss: -0.023724676721862386\n",
      "          total_loss: 0.22323595205588\n",
      "          vf_explained_var: 0.6480076909065247\n",
      "          vf_loss: 0.26866749337031726\n",
      "    num_agent_steps_sampled: 43956\n",
      "    num_agent_steps_trained: 43956\n",
      "    num_steps_sampled: 43956\n",
      "    num_steps_trained: 43956\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94411764705882\n",
      "    ram_util_percent: 29.16470588235294\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04414999199359972\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 38.300401517563955\n",
      "    mean_inference_ms: 2.5935369476693455\n",
      "    mean_raw_obs_processing_ms: 1.7591350029250077\n",
      "  time_since_restore: 700.2040102481842\n",
      "  time_this_iter_s: 24.197851181030273\n",
      "  time_total_s: 700.2040102481842\n",
      "  timers:\n",
      "    learn_throughput: 1147.146\n",
      "    learn_time_ms: 1741.714\n",
      "    load_throughput: 59791.402\n",
      "    load_time_ms: 33.416\n",
      "    sample_throughput: 77.865\n",
      "    sample_time_ms: 25659.882\n",
      "    update_time_ms: 9.504\n",
      "  timestamp: 1636430212\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 43956\n",
      "  training_iteration: 22\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         700.204</td><td style=\"text-align: right;\">43956</td><td style=\"text-align: right;\">  1.3439</td><td style=\"text-align: right;\">                8.31</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">            101.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 45954\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-57-16\n",
      "  done: false\n",
      "  episode_len_mean: 104.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.310000000000015\n",
      "  episode_reward_mean: 1.601700000000006\n",
      "  episode_reward_min: -1.910000000000001\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 449\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.5217662334442137\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.018008268100678872\n",
      "          policy_loss: -0.01586805805563927\n",
      "          total_loss: 0.2932899527229546\n",
      "          vf_explained_var: 0.6849979758262634\n",
      "          vf_loss: 0.33077401866515477\n",
      "    num_agent_steps_sampled: 45954\n",
      "    num_agent_steps_trained: 45954\n",
      "    num_steps_sampled: 45954\n",
      "    num_steps_trained: 45954\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14117647058823\n",
      "    ram_util_percent: 29.36764705882353\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04415992455317502\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 37.86058053115085\n",
      "    mean_inference_ms: 2.587469160505768\n",
      "    mean_raw_obs_processing_ms: 1.8724250312652446\n",
      "  time_since_restore: 723.7071223258972\n",
      "  time_this_iter_s: 23.503112077713013\n",
      "  time_total_s: 723.7071223258972\n",
      "  timers:\n",
      "    learn_throughput: 1151.671\n",
      "    learn_time_ms: 1734.87\n",
      "    load_throughput: 59654.096\n",
      "    load_time_ms: 33.493\n",
      "    sample_throughput: 77.458\n",
      "    sample_time_ms: 25794.579\n",
      "    update_time_ms: 10.214\n",
      "  timestamp: 1636430236\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45954\n",
      "  training_iteration: 23\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         723.707</td><td style=\"text-align: right;\">45954</td><td style=\"text-align: right;\">  1.6017</td><td style=\"text-align: right;\">                8.31</td><td style=\"text-align: right;\">               -1.91</td><td style=\"text-align: right;\">            104.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 47952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-57-40\n",
      "  done: false\n",
      "  episode_len_mean: 106.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.570000000000013\n",
      "  episode_reward_mean: 1.6404000000000065\n",
      "  episode_reward_min: -2.2199999999999993\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 468\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.4911420878909882\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016402817961071195\n",
      "          policy_loss: -0.075735267624259\n",
      "          total_loss: 0.2106581331674187\n",
      "          vf_explained_var: 0.6794300079345703\n",
      "          vf_loss: 0.30802425770532516\n",
      "    num_agent_steps_sampled: 47952\n",
      "    num_agent_steps_trained: 47952\n",
      "    num_steps_sampled: 47952\n",
      "    num_steps_trained: 47952\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11764705882354\n",
      "    ram_util_percent: 29.45\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424802353384738\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 37.46300077266154\n",
      "    mean_inference_ms: 2.5825478250700336\n",
      "    mean_raw_obs_processing_ms: 1.8602752846405355\n",
      "  time_since_restore: 747.6810371875763\n",
      "  time_this_iter_s: 23.973914861679077\n",
      "  time_total_s: 747.6810371875763\n",
      "  timers:\n",
      "    learn_throughput: 1152.769\n",
      "    learn_time_ms: 1733.217\n",
      "    load_throughput: 60640.891\n",
      "    load_time_ms: 32.948\n",
      "    sample_throughput: 77.608\n",
      "    sample_time_ms: 25744.827\n",
      "    update_time_ms: 9.405\n",
      "  timestamp: 1636430260\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 47952\n",
      "  training_iteration: 24\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         747.681</td><td style=\"text-align: right;\">47952</td><td style=\"text-align: right;\">  1.6404</td><td style=\"text-align: right;\">                4.57</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">            106.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 49950\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-58-04\n",
      "  done: false\n",
      "  episode_len_mean: 106.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.910000000000016\n",
      "  episode_reward_mean: 1.621200000000006\n",
      "  episode_reward_min: -2.2199999999999993\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 485\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.4893398250852314\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012489598208693123\n",
      "          policy_loss: -0.05728182065344992\n",
      "          total_loss: 0.16634416159774576\n",
      "          vf_explained_var: 0.6921546459197998\n",
      "          vf_loss: 0.24602145921616328\n",
      "    num_agent_steps_sampled: 49950\n",
      "    num_agent_steps_trained: 49950\n",
      "    num_steps_sampled: 49950\n",
      "    num_steps_trained: 49950\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99117647058821\n",
      "    ram_util_percent: 29.426470588235293\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430957302587533\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 37.109227600248424\n",
      "    mean_inference_ms: 2.578483065718496\n",
      "    mean_raw_obs_processing_ms: 1.8122981632500552\n",
      "  time_since_restore: 771.5449621677399\n",
      "  time_this_iter_s: 23.863924980163574\n",
      "  time_total_s: 771.5449621677399\n",
      "  timers:\n",
      "    learn_throughput: 1151.39\n",
      "    learn_time_ms: 1735.294\n",
      "    load_throughput: 60326.412\n",
      "    load_time_ms: 33.12\n",
      "    sample_throughput: 77.461\n",
      "    sample_time_ms: 25793.615\n",
      "    update_time_ms: 8.73\n",
      "  timestamp: 1636430284\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 49950\n",
      "  training_iteration: 25\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         771.545</td><td style=\"text-align: right;\">49950</td><td style=\"text-align: right;\">  1.6212</td><td style=\"text-align: right;\">                5.91</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">            106.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 51948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-58-27\n",
      "  done: false\n",
      "  episode_len_mean: 107.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.080000000000016\n",
      "  episode_reward_mean: 1.7196000000000062\n",
      "  episode_reward_min: -2.2199999999999993\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 503\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.4727191697983515\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017460293689909652\n",
      "          policy_loss: -0.003937986635026478\n",
      "          total_loss: 0.18703427434499775\n",
      "          vf_explained_var: 0.7565370202064514\n",
      "          vf_loss: 0.2122073936675276\n",
      "    num_agent_steps_sampled: 51948\n",
      "    num_agent_steps_trained: 51948\n",
      "    num_steps_sampled: 51948\n",
      "    num_steps_trained: 51948\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.60303030303032\n",
      "    ram_util_percent: 29.390909090909094\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044370021734400654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.743664220868105\n",
      "    mean_inference_ms: 2.5744981663125577\n",
      "    mean_raw_obs_processing_ms: 1.7642128575158063\n",
      "  time_since_restore: 794.6716737747192\n",
      "  time_this_iter_s: 23.12671160697937\n",
      "  time_total_s: 794.6716737747192\n",
      "  timers:\n",
      "    learn_throughput: 1152.377\n",
      "    learn_time_ms: 1733.808\n",
      "    load_throughput: 60692.759\n",
      "    load_time_ms: 32.92\n",
      "    sample_throughput: 77.593\n",
      "    sample_time_ms: 25749.716\n",
      "    update_time_ms: 9.01\n",
      "  timestamp: 1636430307\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 51948\n",
      "  training_iteration: 26\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         794.672</td><td style=\"text-align: right;\">51948</td><td style=\"text-align: right;\">  1.7196</td><td style=\"text-align: right;\">                6.08</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">            107.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 53946\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-58-50\n",
      "  done: false\n",
      "  episode_len_mean: 107.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.080000000000016\n",
      "  episode_reward_mean: 1.8740000000000074\n",
      "  episode_reward_min: -2.2199999999999993\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 522\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.459307517324175\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016371523400949668\n",
      "          policy_loss: -0.045432296253386\n",
      "          total_loss: 0.214181174266906\n",
      "          vf_explained_var: 0.748858630657196\n",
      "          vf_loss: 0.280932240046206\n",
      "    num_agent_steps_sampled: 53946\n",
      "    num_agent_steps_trained: 53946\n",
      "    num_steps_sampled: 53946\n",
      "    num_steps_trained: 53946\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9969696969697\n",
      "    ram_util_percent: 29.433333333333334\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04442298676725564\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.38342309007215\n",
      "    mean_inference_ms: 2.570723040068744\n",
      "    mean_raw_obs_processing_ms: 1.7181816157323948\n",
      "  time_since_restore: 817.5862016677856\n",
      "  time_this_iter_s: 22.914527893066406\n",
      "  time_total_s: 817.5862016677856\n",
      "  timers:\n",
      "    learn_throughput: 1154.687\n",
      "    learn_time_ms: 1730.339\n",
      "    load_throughput: 60235.656\n",
      "    load_time_ms: 33.17\n",
      "    sample_throughput: 77.95\n",
      "    sample_time_ms: 25631.73\n",
      "    update_time_ms: 9.281\n",
      "  timestamp: 1636430330\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 53946\n",
      "  training_iteration: 27\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         817.586</td><td style=\"text-align: right;\">53946</td><td style=\"text-align: right;\">   1.874</td><td style=\"text-align: right;\">                6.08</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">            107.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 55944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-59-13\n",
      "  done: false\n",
      "  episode_len_mean: 108.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.370000000000016\n",
      "  episode_reward_mean: 1.8824000000000074\n",
      "  episode_reward_min: -2.2199999999999993\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 540\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.4099868797120596\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012732410003548536\n",
      "          policy_loss: -0.09076143212261654\n",
      "          total_loss: 0.13610822835138867\n",
      "          vf_explained_var: 0.7855714559555054\n",
      "          vf_loss: 0.24842304931510062\n",
      "    num_agent_steps_sampled: 55944\n",
      "    num_agent_steps_trained: 55944\n",
      "    num_steps_sampled: 55944\n",
      "    num_steps_trained: 55944\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33030303030303\n",
      "    ram_util_percent: 29.418181818181818\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044478184985145636\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.06232111702118\n",
      "    mean_inference_ms: 2.567300816624144\n",
      "    mean_raw_obs_processing_ms: 1.6774150486073256\n",
      "  time_since_restore: 840.7823660373688\n",
      "  time_this_iter_s: 23.19616436958313\n",
      "  time_total_s: 840.7823660373688\n",
      "  timers:\n",
      "    learn_throughput: 1153.625\n",
      "    learn_time_ms: 1731.933\n",
      "    load_throughput: 60732.345\n",
      "    load_time_ms: 32.898\n",
      "    sample_throughput: 83.584\n",
      "    sample_time_ms: 23904.045\n",
      "    update_time_ms: 9.273\n",
      "  timestamp: 1636430353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 55944\n",
      "  training_iteration: 28\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         840.782</td><td style=\"text-align: right;\">55944</td><td style=\"text-align: right;\">  1.8824</td><td style=\"text-align: right;\">                6.37</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">            108.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 57942\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_03-59-38\n",
      "  done: false\n",
      "  episode_len_mean: 108.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.370000000000016\n",
      "  episode_reward_mean: 1.893100000000008\n",
      "  episode_reward_min: -2.2199999999999993\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 559\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.4188638596307666\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.020871354639357794\n",
      "          policy_loss: -0.06565457223249334\n",
      "          total_loss: 0.4078754675086765\n",
      "          vf_explained_var: 0.6833553314208984\n",
      "          vf_loss: 0.49354440413770223\n",
      "    num_agent_steps_sampled: 57942\n",
      "    num_agent_steps_trained: 57942\n",
      "    num_steps_sampled: 57942\n",
      "    num_steps_trained: 57942\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00285714285714\n",
      "    ram_util_percent: 29.377142857142854\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0445226812172466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.7408585862634\n",
      "    mean_inference_ms: 2.5641170467153653\n",
      "    mean_raw_obs_processing_ms: 1.6364710428076885\n",
      "  time_since_restore: 865.3227858543396\n",
      "  time_this_iter_s: 24.540419816970825\n",
      "  time_total_s: 865.3227858543396\n",
      "  timers:\n",
      "    learn_throughput: 1155.642\n",
      "    learn_time_ms: 1728.91\n",
      "    load_throughput: 60384.399\n",
      "    load_time_ms: 33.088\n",
      "    sample_throughput: 90.959\n",
      "    sample_time_ms: 21965.9\n",
      "    update_time_ms: 9.045\n",
      "  timestamp: 1636430378\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 57942\n",
      "  training_iteration: 29\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         865.323</td><td style=\"text-align: right;\">57942</td><td style=\"text-align: right;\">  1.8931</td><td style=\"text-align: right;\">                6.37</td><td style=\"text-align: right;\">               -2.22</td><td style=\"text-align: right;\">            108.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 59940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 107.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.370000000000016\n",
      "  episode_reward_mean: 2.2161000000000084\n",
      "  episode_reward_min: -1.8200000000000007\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 578\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.412447778383891\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009451503430372562\n",
      "          policy_loss: 0.002894151991321927\n",
      "          total_loss: 0.31726864938225063\n",
      "          vf_explained_var: 0.6476636528968811\n",
      "          vf_loss: 0.33566352611496336\n",
      "    num_agent_steps_sampled: 59940\n",
      "    num_agent_steps_trained: 59940\n",
      "    num_steps_sampled: 59940\n",
      "    num_steps_trained: 59940\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6742857142857\n",
      "    ram_util_percent: 29.317142857142855\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04454666434311186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.45395270786887\n",
      "    mean_inference_ms: 2.5614378829125117\n",
      "    mean_raw_obs_processing_ms: 1.5986657856723658\n",
      "  time_since_restore: 889.5576169490814\n",
      "  time_this_iter_s: 24.23483109474182\n",
      "  time_total_s: 889.5576169490814\n",
      "  timers:\n",
      "    learn_throughput: 1155.892\n",
      "    learn_time_ms: 1728.536\n",
      "    load_throughput: 60043.171\n",
      "    load_time_ms: 33.276\n",
      "    sample_throughput: 91.074\n",
      "    sample_time_ms: 21938.141\n",
      "    update_time_ms: 8.359\n",
      "  timestamp: 1636430402\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59940\n",
      "  training_iteration: 30\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         889.558</td><td style=\"text-align: right;\">59940</td><td style=\"text-align: right;\">  2.2161</td><td style=\"text-align: right;\">                6.37</td><td style=\"text-align: right;\">               -1.82</td><td style=\"text-align: right;\">            107.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 61938\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-00-25\n",
      "  done: false\n",
      "  episode_len_mean: 107.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.48000000000001\n",
      "  episode_reward_mean: 2.410100000000009\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 597\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.3897206556229365\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012921445993584229\n",
      "          policy_loss: -0.019602791805352484\n",
      "          total_loss: 0.2863972791958423\n",
      "          vf_explained_var: 0.5754073262214661\n",
      "          vf_loss: 0.3260208427906036\n",
      "    num_agent_steps_sampled: 61938\n",
      "    num_agent_steps_trained: 61938\n",
      "    num_steps_sampled: 61938\n",
      "    num_steps_trained: 61938\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8030303030303\n",
      "    ram_util_percent: 29.333333333333332\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04456657808093163\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 35.188238279016424\n",
      "    mean_inference_ms: 2.5589744785436688\n",
      "    mean_raw_obs_processing_ms: 1.565333079974493\n",
      "  time_since_restore: 912.6473319530487\n",
      "  time_this_iter_s: 23.089715003967285\n",
      "  time_total_s: 912.6473319530487\n",
      "  timers:\n",
      "    learn_throughput: 1155.027\n",
      "    learn_time_ms: 1729.83\n",
      "    load_throughput: 60118.465\n",
      "    load_time_ms: 33.234\n",
      "    sample_throughput: 91.306\n",
      "    sample_time_ms: 21882.404\n",
      "    update_time_ms: 8.887\n",
      "  timestamp: 1636430425\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 61938\n",
      "  training_iteration: 31\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         912.647</td><td style=\"text-align: right;\">61938</td><td style=\"text-align: right;\">  2.4101</td><td style=\"text-align: right;\">                6.48</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">            107.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 63936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-00-49\n",
      "  done: false\n",
      "  episode_len_mean: 106.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.48000000000001\n",
      "  episode_reward_mean: 2.405600000000008\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 616\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.377284228234064\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01021831024262174\n",
      "          policy_loss: -0.07291017561441376\n",
      "          total_loss: 0.19551375416063127\n",
      "          vf_explained_var: 0.7554401159286499\n",
      "          vf_loss: 0.28913127950259615\n",
      "    num_agent_steps_sampled: 63936\n",
      "    num_agent_steps_trained: 63936\n",
      "    num_steps_sampled: 63936\n",
      "    num_steps_trained: 63936\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9970588235294\n",
      "    ram_util_percent: 29.326470588235292\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04455146945511089\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.95581243766905\n",
      "    mean_inference_ms: 2.5562551092829033\n",
      "    mean_raw_obs_processing_ms: 1.5351009982301016\n",
      "  time_since_restore: 936.4084184169769\n",
      "  time_this_iter_s: 23.761086463928223\n",
      "  time_total_s: 936.4084184169769\n",
      "  timers:\n",
      "    learn_throughput: 1155.506\n",
      "    learn_time_ms: 1729.113\n",
      "    load_throughput: 60177.306\n",
      "    load_time_ms: 33.202\n",
      "    sample_throughput: 91.481\n",
      "    sample_time_ms: 21840.628\n",
      "    update_time_ms: 7.734\n",
      "  timestamp: 1636430449\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 63936\n",
      "  training_iteration: 32\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         936.408</td><td style=\"text-align: right;\">63936</td><td style=\"text-align: right;\">  2.4056</td><td style=\"text-align: right;\">                6.48</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">            106.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 65934\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-01-12\n",
      "  done: false\n",
      "  episode_len_mean: 106.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.48000000000001\n",
      "  episode_reward_mean: 2.5955000000000092\n",
      "  episode_reward_min: -1.7400000000000009\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 633\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.39376582191104\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013254968866597723\n",
      "          policy_loss: -0.01611745141091801\n",
      "          total_loss: 0.2889775233609336\n",
      "          vf_explained_var: 0.7539677023887634\n",
      "          vf_loss: 0.3250561406924611\n",
      "    num_agent_steps_sampled: 65934\n",
      "    num_agent_steps_trained: 65934\n",
      "    num_steps_sampled: 65934\n",
      "    num_steps_trained: 65934\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.98181818181818\n",
      "    ram_util_percent: 29.32121212121212\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04456742419411139\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.76186507244424\n",
      "    mean_inference_ms: 2.5536319431713896\n",
      "    mean_raw_obs_processing_ms: 1.5095300914327543\n",
      "  time_since_restore: 959.6970710754395\n",
      "  time_this_iter_s: 23.288652658462524\n",
      "  time_total_s: 959.6970710754395\n",
      "  timers:\n",
      "    learn_throughput: 1153.805\n",
      "    learn_time_ms: 1731.661\n",
      "    load_throughput: 60333.274\n",
      "    load_time_ms: 33.116\n",
      "    sample_throughput: 91.58\n",
      "    sample_time_ms: 21816.972\n",
      "    update_time_ms: 7.503\n",
      "  timestamp: 1636430472\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 65934\n",
      "  training_iteration: 33\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         959.697</td><td style=\"text-align: right;\">65934</td><td style=\"text-align: right;\">  2.5955</td><td style=\"text-align: right;\">                6.48</td><td style=\"text-align: right;\">               -1.74</td><td style=\"text-align: right;\">            106.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 67932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-01-35\n",
      "  done: false\n",
      "  episode_len_mean: 109.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.48000000000001\n",
      "  episode_reward_mean: 2.729900000000009\n",
      "  episode_reward_min: -0.9700000000000002\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 650\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.293227023170108\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013578774451945485\n",
      "          policy_loss: -0.046204529010823794\n",
      "          total_loss: 0.2978675869426557\n",
      "          vf_explained_var: 0.6993898153305054\n",
      "          vf_loss: 0.36293075049207324\n",
      "    num_agent_steps_sampled: 67932\n",
      "    num_agent_steps_trained: 67932\n",
      "    num_steps_sampled: 67932\n",
      "    num_steps_trained: 67932\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5969696969697\n",
      "    ram_util_percent: 29.293939393939393\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044556654256458515\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.561116515633614\n",
      "    mean_inference_ms: 2.5507903165589725\n",
      "    mean_raw_obs_processing_ms: 1.48557115329735\n",
      "  time_since_restore: 982.5630438327789\n",
      "  time_this_iter_s: 22.865972757339478\n",
      "  time_total_s: 982.5630438327789\n",
      "  timers:\n",
      "    learn_throughput: 1152.242\n",
      "    learn_time_ms: 1734.011\n",
      "    load_throughput: 59324.661\n",
      "    load_time_ms: 33.679\n",
      "    sample_throughput: 92.061\n",
      "    sample_time_ms: 21702.999\n",
      "    update_time_ms: 7.991\n",
      "  timestamp: 1636430495\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 67932\n",
      "  training_iteration: 34\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         982.563</td><td style=\"text-align: right;\">67932</td><td style=\"text-align: right;\">  2.7299</td><td style=\"text-align: right;\">                6.48</td><td style=\"text-align: right;\">               -0.97</td><td style=\"text-align: right;\">             109.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 69930\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-01-57\n",
      "  done: false\n",
      "  episode_len_mean: 110.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.48000000000001\n",
      "  episode_reward_mean: 2.6163000000000096\n",
      "  episode_reward_min: -0.9700000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 668\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.3268958977290564\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013107018163233118\n",
      "          policy_loss: 0.021567413423742566\n",
      "          total_loss: 0.2388814958610705\n",
      "          vf_explained_var: 0.6692510843276978\n",
      "          vf_loss: 0.23665093334303017\n",
      "    num_agent_steps_sampled: 69930\n",
      "    num_agent_steps_trained: 69930\n",
      "    num_steps_sampled: 69930\n",
      "    num_steps_trained: 69930\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.40625\n",
      "    ram_util_percent: 29.23125\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04455176378350098\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.349896641486325\n",
      "    mean_inference_ms: 2.5482555874783244\n",
      "    mean_raw_obs_processing_ms: 1.4607698027911686\n",
      "  time_since_restore: 1005.0305774211884\n",
      "  time_this_iter_s: 22.467533588409424\n",
      "  time_total_s: 1005.0305774211884\n",
      "  timers:\n",
      "    learn_throughput: 1153.547\n",
      "    learn_time_ms: 1732.049\n",
      "    load_throughput: 59343.86\n",
      "    load_time_ms: 33.668\n",
      "    sample_throughput: 92.652\n",
      "    sample_time_ms: 21564.486\n",
      "    update_time_ms: 8.755\n",
      "  timestamp: 1636430517\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69930\n",
      "  training_iteration: 35\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         1005.03</td><td style=\"text-align: right;\">69930</td><td style=\"text-align: right;\">  2.6163</td><td style=\"text-align: right;\">                6.48</td><td style=\"text-align: right;\">               -0.97</td><td style=\"text-align: right;\">            110.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 71928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-02-21\n",
      "  done: false\n",
      "  episode_len_mean: 112.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.420000000000012\n",
      "  episode_reward_mean: 2.7084000000000104\n",
      "  episode_reward_min: -0.9700000000000002\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 685\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.281095334461757\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015510114881605086\n",
      "          policy_loss: -0.003084441034921578\n",
      "          total_loss: 0.34606841660681226\n",
      "          vf_explained_var: 0.683704674243927\n",
      "          vf_loss: 0.3673107778032621\n",
      "    num_agent_steps_sampled: 71928\n",
      "    num_agent_steps_trained: 71928\n",
      "    num_steps_sampled: 71928\n",
      "    num_steps_trained: 71928\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6939393939394\n",
      "    ram_util_percent: 29.23333333333333\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0445688656100131\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.15291150187471\n",
      "    mean_inference_ms: 2.546096668832288\n",
      "    mean_raw_obs_processing_ms: 1.4381346716197587\n",
      "  time_since_restore: 1028.2707962989807\n",
      "  time_this_iter_s: 23.24021887779236\n",
      "  time_total_s: 1028.2707962989807\n",
      "  timers:\n",
      "    learn_throughput: 1153.456\n",
      "    learn_time_ms: 1732.185\n",
      "    load_throughput: 59038.954\n",
      "    load_time_ms: 33.842\n",
      "    sample_throughput: 92.606\n",
      "    sample_time_ms: 21575.374\n",
      "    update_time_ms: 9.079\n",
      "  timestamp: 1636430541\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 71928\n",
      "  training_iteration: 36\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         1028.27</td><td style=\"text-align: right;\">71928</td><td style=\"text-align: right;\">  2.7084</td><td style=\"text-align: right;\">                8.42</td><td style=\"text-align: right;\">               -0.97</td><td style=\"text-align: right;\">            112.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 73926\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-02-45\n",
      "  done: false\n",
      "  episode_len_mean: 112.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.420000000000012\n",
      "  episode_reward_mean: 2.70770000000001\n",
      "  episode_reward_min: -0.9700000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 703\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.3526969580423263\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013992183634863114\n",
      "          policy_loss: -0.036705996983108065\n",
      "          total_loss: 0.27665467755425543\n",
      "          vf_explained_var: 0.6710766553878784\n",
      "          vf_loss: 0.3326899873358863\n",
      "    num_agent_steps_sampled: 73926\n",
      "    num_agent_steps_trained: 73926\n",
      "    num_steps_sampled: 73926\n",
      "    num_steps_trained: 73926\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9235294117647\n",
      "    ram_util_percent: 29.17941176470588\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0445757461353043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.958776795121445\n",
      "    mean_inference_ms: 2.5440920329943566\n",
      "    mean_raw_obs_processing_ms: 1.415120944824705\n",
      "  time_since_restore: 1052.1175820827484\n",
      "  time_this_iter_s: 23.8467857837677\n",
      "  time_total_s: 1052.1175820827484\n",
      "  timers:\n",
      "    learn_throughput: 1153.788\n",
      "    learn_time_ms: 1731.688\n",
      "    load_throughput: 59078.994\n",
      "    load_time_ms: 33.819\n",
      "    sample_throughput: 92.206\n",
      "    sample_time_ms: 21668.831\n",
      "    update_time_ms: 9.397\n",
      "  timestamp: 1636430565\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 73926\n",
      "  training_iteration: 37\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         1052.12</td><td style=\"text-align: right;\">73926</td><td style=\"text-align: right;\">  2.7077</td><td style=\"text-align: right;\">                8.42</td><td style=\"text-align: right;\">               -0.97</td><td style=\"text-align: right;\">            112.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 75924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-03-25\n",
      "  done: false\n",
      "  episode_len_mean: 109.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.420000000000012\n",
      "  episode_reward_mean: 2.7229000000000103\n",
      "  episode_reward_min: -0.9700000000000002\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 725\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.3127629632041566\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013500290616714964\n",
      "          policy_loss: -0.02976976219742071\n",
      "          total_loss: 0.2662973164891203\n",
      "          vf_explained_var: 0.7607832551002502\n",
      "          vf_loss: 0.3151446201971599\n",
      "    num_agent_steps_sampled: 75924\n",
      "    num_agent_steps_trained: 75924\n",
      "    num_steps_sampled: 75924\n",
      "    num_steps_trained: 75924\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.07758620689657\n",
      "    ram_util_percent: 28.91551724137931\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04455513166916434\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.730357269195686\n",
      "    mean_inference_ms: 2.5417537230678224\n",
      "    mean_raw_obs_processing_ms: 1.5390221620360154\n",
      "  time_since_restore: 1093.0101606845856\n",
      "  time_this_iter_s: 40.89257860183716\n",
      "  time_total_s: 1093.0101606845856\n",
      "  timers:\n",
      "    learn_throughput: 1153.486\n",
      "    learn_time_ms: 1732.14\n",
      "    load_throughput: 58790.404\n",
      "    load_time_ms: 33.985\n",
      "    sample_throughput: 85.249\n",
      "    sample_time_ms: 23437.312\n",
      "    update_time_ms: 9.29\n",
      "  timestamp: 1636430605\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 75924\n",
      "  training_iteration: 38\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         1093.01</td><td style=\"text-align: right;\">75924</td><td style=\"text-align: right;\">  2.7229</td><td style=\"text-align: right;\">                8.42</td><td style=\"text-align: right;\">               -0.97</td><td style=\"text-align: right;\">            109.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 77922\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-03-50\n",
      "  done: false\n",
      "  episode_len_mean: 108.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.420000000000012\n",
      "  episode_reward_mean: 2.6598000000000104\n",
      "  episode_reward_min: -0.9700000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 743\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.311455706187657\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014222167513675523\n",
      "          policy_loss: -0.00372384355536529\n",
      "          total_loss: 0.2260424382208536\n",
      "          vf_explained_var: 0.7831085324287415\n",
      "          vf_loss: 0.24861418980927694\n",
      "    num_agent_steps_sampled: 77922\n",
      "    num_agent_steps_trained: 77922\n",
      "    num_steps_sampled: 77922\n",
      "    num_steps_trained: 77922\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.70285714285716\n",
      "    ram_util_percent: 29.18285714285714\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04452157033955533\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.56346350961491\n",
      "    mean_inference_ms: 2.5402277246684974\n",
      "    mean_raw_obs_processing_ms: 1.6391474512777275\n",
      "  time_since_restore: 1117.149420261383\n",
      "  time_this_iter_s: 24.139259576797485\n",
      "  time_total_s: 1117.149420261383\n",
      "  timers:\n",
      "    learn_throughput: 1152.68\n",
      "    learn_time_ms: 1733.352\n",
      "    load_throughput: 58914.976\n",
      "    load_time_ms: 33.913\n",
      "    sample_throughput: 85.399\n",
      "    sample_time_ms: 23395.982\n",
      "    update_time_ms: 9.006\n",
      "  timestamp: 1636430630\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 77922\n",
      "  training_iteration: 39\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         1117.15</td><td style=\"text-align: right;\">77922</td><td style=\"text-align: right;\">  2.6598</td><td style=\"text-align: right;\">                8.42</td><td style=\"text-align: right;\">               -0.97</td><td style=\"text-align: right;\">            108.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 79920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-04-12\n",
      "  done: false\n",
      "  episode_len_mean: 108.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.420000000000012\n",
      "  episode_reward_mean: 2.7854000000000116\n",
      "  episode_reward_min: -0.35000000000000114\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 760\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.298102289154416\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01743934236198968\n",
      "          policy_loss: 0.011286281404041108\n",
      "          total_loss: 0.2677421232774144\n",
      "          vf_explained_var: 0.7846932411193848\n",
      "          vf_loss: 0.27420506278673806\n",
      "    num_agent_steps_sampled: 79920\n",
      "    num_agent_steps_trained: 79920\n",
      "    num_steps_sampled: 79920\n",
      "    num_steps_trained: 79920\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.975\n",
      "    ram_util_percent: 29.384375\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04451331105375937\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.41373124390348\n",
      "    mean_inference_ms: 2.53840143246198\n",
      "    mean_raw_obs_processing_ms: 1.7325936760996958\n",
      "  time_since_restore: 1139.491075515747\n",
      "  time_this_iter_s: 22.341655254364014\n",
      "  time_total_s: 1139.491075515747\n",
      "  timers:\n",
      "    learn_throughput: 1153.448\n",
      "    learn_time_ms: 1732.198\n",
      "    load_throughput: 58947.259\n",
      "    load_time_ms: 33.895\n",
      "    sample_throughput: 86.091\n",
      "    sample_time_ms: 23207.911\n",
      "    update_time_ms: 8.908\n",
      "  timestamp: 1636430652\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 79920\n",
      "  training_iteration: 40\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         1139.49</td><td style=\"text-align: right;\">79920</td><td style=\"text-align: right;\">  2.7854</td><td style=\"text-align: right;\">                8.42</td><td style=\"text-align: right;\">               -0.35</td><td style=\"text-align: right;\">            108.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 81918\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-04-36\n",
      "  done: false\n",
      "  episode_len_mean: 108.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.420000000000012\n",
      "  episode_reward_mean: 3.030800000000012\n",
      "  episode_reward_min: -0.33000000000000046\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 778\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.226231080009824\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015620006360903304\n",
      "          policy_loss: -0.04243473658072097\n",
      "          total_loss: 0.3043724107777789\n",
      "          vf_explained_var: 0.7521301507949829\n",
      "          vf_loss: 0.36438345738819666\n",
      "    num_agent_steps_sampled: 81918\n",
      "    num_agent_steps_trained: 81918\n",
      "    num_steps_sampled: 81918\n",
      "    num_steps_trained: 81918\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.06470588235295\n",
      "    ram_util_percent: 29.502941176470586\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044474957011458184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.26457209702233\n",
      "    mean_inference_ms: 2.536714338011819\n",
      "    mean_raw_obs_processing_ms: 1.8290272625662871\n",
      "  time_since_restore: 1163.7031943798065\n",
      "  time_this_iter_s: 24.21211886405945\n",
      "  time_total_s: 1163.7031943798065\n",
      "  timers:\n",
      "    learn_throughput: 1154.007\n",
      "    learn_time_ms: 1731.359\n",
      "    load_throughput: 58853.203\n",
      "    load_time_ms: 33.949\n",
      "    sample_throughput: 86.213\n",
      "    sample_time_ms: 23175.202\n",
      "    update_time_ms: 8.677\n",
      "  timestamp: 1636430676\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 81918\n",
      "  training_iteration: 41\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">          1163.7</td><td style=\"text-align: right;\">81918</td><td style=\"text-align: right;\">  3.0308</td><td style=\"text-align: right;\">                8.42</td><td style=\"text-align: right;\">               -0.33</td><td style=\"text-align: right;\">            108.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 83916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-05-00\n",
      "  done: false\n",
      "  episode_len_mean: 109.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.600000000000023\n",
      "  episode_reward_mean: 2.994400000000013\n",
      "  episode_reward_min: -0.33000000000000046\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 795\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.2189175764719646\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012986970949725406\n",
      "          policy_loss: 0.03015514433029152\n",
      "          total_loss: 0.30778085527320703\n",
      "          vf_explained_var: 0.7791894674301147\n",
      "          vf_loss: 0.29591879386987\n",
      "    num_agent_steps_sampled: 83916\n",
      "    num_agent_steps_trained: 83916\n",
      "    num_steps_sampled: 83916\n",
      "    num_steps_trained: 83916\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.80882352941178\n",
      "    ram_util_percent: 29.711764705882352\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044453139523106575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.13096519130681\n",
      "    mean_inference_ms: 2.5348358926390056\n",
      "    mean_raw_obs_processing_ms: 1.918063727648983\n",
      "  time_since_restore: 1187.217048406601\n",
      "  time_this_iter_s: 23.513854026794434\n",
      "  time_total_s: 1187.217048406601\n",
      "  timers:\n",
      "    learn_throughput: 1153.088\n",
      "    learn_time_ms: 1732.739\n",
      "    load_throughput: 58950.576\n",
      "    load_time_ms: 33.893\n",
      "    sample_throughput: 86.312\n",
      "    sample_time_ms: 23148.556\n",
      "    update_time_ms: 9.176\n",
      "  timestamp: 1636430700\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 83916\n",
      "  training_iteration: 42\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         1187.22</td><td style=\"text-align: right;\">83916</td><td style=\"text-align: right;\">  2.9944</td><td style=\"text-align: right;\">                 7.6</td><td style=\"text-align: right;\">               -0.33</td><td style=\"text-align: right;\">            109.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 85914\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-05-22\n",
      "  done: false\n",
      "  episode_len_mean: 110.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.600000000000023\n",
      "  episode_reward_mean: 3.1828000000000145\n",
      "  episode_reward_min: -0.33000000000000046\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 812\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1526499611990793\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017916374803837478\n",
      "          policy_loss: -0.04267719618621327\n",
      "          total_loss: 0.3701249635645321\n",
      "          vf_explained_var: 0.7672342658042908\n",
      "          vf_loss: 0.4289537505024955\n",
      "    num_agent_steps_sampled: 85914\n",
      "    num_agent_steps_trained: 85914\n",
      "    num_steps_sampled: 85914\n",
      "    num_steps_trained: 85914\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.93548387096774\n",
      "    ram_util_percent: 29.809677419354838\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04443737787511926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.995284988540526\n",
      "    mean_inference_ms: 2.5331867269920565\n",
      "    mean_raw_obs_processing_ms: 1.94643900464713\n",
      "  time_since_restore: 1208.91171169281\n",
      "  time_this_iter_s: 21.694663286209106\n",
      "  time_total_s: 1208.91171169281\n",
      "  timers:\n",
      "    learn_throughput: 1153.889\n",
      "    learn_time_ms: 1731.535\n",
      "    load_throughput: 58984.974\n",
      "    load_time_ms: 33.873\n",
      "    sample_throughput: 86.903\n",
      "    sample_time_ms: 22991.25\n",
      "    update_time_ms: 8.635\n",
      "  timestamp: 1636430722\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 85914\n",
      "  training_iteration: 43\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         1208.91</td><td style=\"text-align: right;\">85914</td><td style=\"text-align: right;\">  3.1828</td><td style=\"text-align: right;\">                 7.6</td><td style=\"text-align: right;\">               -0.33</td><td style=\"text-align: right;\">            110.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 87912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-05-45\n",
      "  done: false\n",
      "  episode_len_mean: 114.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.330000000000016\n",
      "  episode_reward_mean: 3.4751000000000154\n",
      "  episode_reward_min: -0.33000000000000046\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 829\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1995293912433445\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013846637441295617\n",
      "          policy_loss: -0.01947798551548095\n",
      "          total_loss: 0.2840131950520334\n",
      "          vf_explained_var: 0.7694193720817566\n",
      "          vf_loss: 0.3213324859028771\n",
      "    num_agent_steps_sampled: 87912\n",
      "    num_agent_steps_trained: 87912\n",
      "    num_steps_sampled: 87912\n",
      "    num_steps_trained: 87912\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.34242424242424\n",
      "    ram_util_percent: 29.87272727272727\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04449024386823867\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.85903593043886\n",
      "    mean_inference_ms: 2.532198463704687\n",
      "    mean_raw_obs_processing_ms: 1.9143881486543086\n",
      "  time_since_restore: 1232.256115436554\n",
      "  time_this_iter_s: 23.344403743743896\n",
      "  time_total_s: 1232.256115436554\n",
      "  timers:\n",
      "    learn_throughput: 1154.728\n",
      "    learn_time_ms: 1730.278\n",
      "    load_throughput: 59032.134\n",
      "    load_time_ms: 33.846\n",
      "    sample_throughput: 86.718\n",
      "    sample_time_ms: 23040.319\n",
      "    update_time_ms: 8.633\n",
      "  timestamp: 1636430745\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 87912\n",
      "  training_iteration: 44\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         1232.26</td><td style=\"text-align: right;\">87912</td><td style=\"text-align: right;\">  3.4751</td><td style=\"text-align: right;\">                8.33</td><td style=\"text-align: right;\">               -0.33</td><td style=\"text-align: right;\">            114.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 89910\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-06-09\n",
      "  done: false\n",
      "  episode_len_mean: 114.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.330000000000016\n",
      "  episode_reward_mean: 3.6984000000000163\n",
      "  episode_reward_min: -0.23999999999999605\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 847\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.170015975974855\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014287459125946695\n",
      "          policy_loss: -0.03816988336898032\n",
      "          total_loss: 0.28805350396959556\n",
      "          vf_explained_var: 0.7426525354385376\n",
      "          vf_loss: 0.34363730826548167\n",
      "    num_agent_steps_sampled: 89910\n",
      "    num_agent_steps_trained: 89910\n",
      "    num_steps_sampled: 89910\n",
      "    num_steps_trained: 89910\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73529411764706\n",
      "    ram_util_percent: 29.926470588235293\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044507629803431925\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.71973586874875\n",
      "    mean_inference_ms: 2.530906001769615\n",
      "    mean_raw_obs_processing_ms: 1.8832764150522912\n",
      "  time_since_restore: 1255.8446447849274\n",
      "  time_this_iter_s: 23.588529348373413\n",
      "  time_total_s: 1255.8446447849274\n",
      "  timers:\n",
      "    learn_throughput: 1153.427\n",
      "    learn_time_ms: 1732.229\n",
      "    load_throughput: 58882.646\n",
      "    load_time_ms: 33.932\n",
      "    sample_throughput: 86.304\n",
      "    sample_time_ms: 23150.781\n",
      "    update_time_ms: 8.306\n",
      "  timestamp: 1636430769\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 89910\n",
      "  training_iteration: 45\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         1255.84</td><td style=\"text-align: right;\">89910</td><td style=\"text-align: right;\">  3.6984</td><td style=\"text-align: right;\">                8.33</td><td style=\"text-align: right;\">               -0.24</td><td style=\"text-align: right;\">            114.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 91908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-06-31\n",
      "  done: false\n",
      "  episode_len_mean: 114.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.330000000000016\n",
      "  episode_reward_mean: 3.7510000000000154\n",
      "  episode_reward_min: -0.13999999999999976\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 864\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1582416347094946\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013722692981956719\n",
      "          policy_loss: -0.05983620931704839\n",
      "          total_loss: 0.22669465958717325\n",
      "          vf_explained_var: 0.7798749804496765\n",
      "          vf_loss: 0.30399647897907667\n",
      "    num_agent_steps_sampled: 91908\n",
      "    num_agent_steps_trained: 91908\n",
      "    num_steps_sampled: 91908\n",
      "    num_steps_trained: 91908\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.915625\n",
      "    ram_util_percent: 29.934375000000003\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04452150121582132\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.591037743085046\n",
      "    mean_inference_ms: 2.529906426690255\n",
      "    mean_raw_obs_processing_ms: 1.8547125433541694\n",
      "  time_since_restore: 1278.4883403778076\n",
      "  time_this_iter_s: 22.64369559288025\n",
      "  time_total_s: 1278.4883403778076\n",
      "  timers:\n",
      "    learn_throughput: 1153.042\n",
      "    learn_time_ms: 1732.807\n",
      "    load_throughput: 58789.621\n",
      "    load_time_ms: 33.986\n",
      "    sample_throughput: 86.529\n",
      "    sample_time_ms: 23090.601\n",
      "    update_time_ms: 8.146\n",
      "  timestamp: 1636430791\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 91908\n",
      "  training_iteration: 46\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         1278.49</td><td style=\"text-align: right;\">91908</td><td style=\"text-align: right;\">   3.751</td><td style=\"text-align: right;\">                8.33</td><td style=\"text-align: right;\">               -0.14</td><td style=\"text-align: right;\">            114.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 93906\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-06-54\n",
      "  done: false\n",
      "  episode_len_mean: 114.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.450000000000017\n",
      "  episode_reward_mean: 3.8621000000000167\n",
      "  episode_reward_min: -0.13999999999999976\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 882\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0943507256962004\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014561782639600061\n",
      "          policy_loss: -0.05155631626645724\n",
      "          total_loss: 0.21923157526623635\n",
      "          vf_explained_var: 0.83603435754776\n",
      "          vf_loss: 0.2873628607463269\n",
      "    num_agent_steps_sampled: 93906\n",
      "    num_agent_steps_trained: 93906\n",
      "    num_steps_sampled: 93906\n",
      "    num_steps_trained: 93906\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9939393939394\n",
      "    ram_util_percent: 29.87878787878788\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04453949689678927\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.459418024682684\n",
      "    mean_inference_ms: 2.52870796891015\n",
      "    mean_raw_obs_processing_ms: 1.8261944264107222\n",
      "  time_since_restore: 1301.6826171875\n",
      "  time_this_iter_s: 23.194276809692383\n",
      "  time_total_s: 1301.6826171875\n",
      "  timers:\n",
      "    learn_throughput: 1154.576\n",
      "    learn_time_ms: 1730.505\n",
      "    load_throughput: 58794.24\n",
      "    load_time_ms: 33.983\n",
      "    sample_throughput: 86.765\n",
      "    sample_time_ms: 23027.791\n",
      "    update_time_ms: 7.843\n",
      "  timestamp: 1636430814\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 93906\n",
      "  training_iteration: 47\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         1301.68</td><td style=\"text-align: right;\">93906</td><td style=\"text-align: right;\">  3.8621</td><td style=\"text-align: right;\">                8.45</td><td style=\"text-align: right;\">               -0.14</td><td style=\"text-align: right;\">            114.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 95904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-07-16\n",
      "  done: false\n",
      "  episode_len_mean: 115.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.450000000000017\n",
      "  episode_reward_mean: 3.916100000000017\n",
      "  episode_reward_min: -0.13999999999999976\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 898\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.083780614535014\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015066939813225306\n",
      "          policy_loss: -0.03770366607322579\n",
      "          total_loss: 0.2830055733344385\n",
      "          vf_explained_var: 0.8288822174072266\n",
      "          vf_loss: 0.337026962070238\n",
      "    num_agent_steps_sampled: 95904\n",
      "    num_agent_steps_trained: 95904\n",
      "    num_steps_sampled: 95904\n",
      "    num_steps_trained: 95904\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89354838709677\n",
      "    ram_util_percent: 29.896774193548378\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04455680756380939\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.33985247159554\n",
      "    mean_inference_ms: 2.5277004899183635\n",
      "    mean_raw_obs_processing_ms: 1.8018121193870644\n",
      "  time_since_restore: 1323.0664558410645\n",
      "  time_this_iter_s: 21.383838653564453\n",
      "  time_total_s: 1323.0664558410645\n",
      "  timers:\n",
      "    learn_throughput: 1152.477\n",
      "    learn_time_ms: 1733.657\n",
      "    load_throughput: 58768.636\n",
      "    load_time_ms: 33.998\n",
      "    sample_throughput: 94.81\n",
      "    sample_time_ms: 21073.68\n",
      "    update_time_ms: 8.634\n",
      "  timestamp: 1636430836\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 95904\n",
      "  training_iteration: 48\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         1323.07</td><td style=\"text-align: right;\">95904</td><td style=\"text-align: right;\">  3.9161</td><td style=\"text-align: right;\">                8.45</td><td style=\"text-align: right;\">               -0.14</td><td style=\"text-align: right;\">            115.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 97902\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-07-39\n",
      "  done: false\n",
      "  episode_len_mean: 115.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.450000000000017\n",
      "  episode_reward_mean: 4.130700000000017\n",
      "  episode_reward_min: 0.03999999999999878\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 916\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0423541596957615\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015095847700856643\n",
      "          policy_loss: -0.03794060459449178\n",
      "          total_loss: 0.32288464783203036\n",
      "          vf_explained_var: 0.7973204255104065\n",
      "          vf_loss: 0.3767200379854157\n",
      "    num_agent_steps_sampled: 97902\n",
      "    num_agent_steps_trained: 97902\n",
      "    num_steps_sampled: 97902\n",
      "    num_steps_trained: 97902\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.86969696969696\n",
      "    ram_util_percent: 29.818181818181817\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044561356714778524\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.214055385044105\n",
      "    mean_inference_ms: 2.5265015027987903\n",
      "    mean_raw_obs_processing_ms: 1.7757928175899138\n",
      "  time_since_restore: 1345.849478006363\n",
      "  time_this_iter_s: 22.783022165298462\n",
      "  time_total_s: 1345.849478006363\n",
      "  timers:\n",
      "    learn_throughput: 1149.411\n",
      "    learn_time_ms: 1738.281\n",
      "    load_throughput: 58481.553\n",
      "    load_time_ms: 34.165\n",
      "    sample_throughput: 95.449\n",
      "    sample_time_ms: 20932.746\n",
      "    update_time_ms: 9.183\n",
      "  timestamp: 1636430859\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 97902\n",
      "  training_iteration: 49\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         1345.85</td><td style=\"text-align: right;\">97902</td><td style=\"text-align: right;\">  4.1307</td><td style=\"text-align: right;\">                8.45</td><td style=\"text-align: right;\">                0.04</td><td style=\"text-align: right;\">            115.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 99900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-08-01\n",
      "  done: false\n",
      "  episode_len_mean: 115.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.450000000000017\n",
      "  episode_reward_mean: 4.230000000000018\n",
      "  episode_reward_min: 0.03999999999999878\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 934\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.980233969574883\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013092515067297021\n",
      "          policy_loss: -0.04181741908902214\n",
      "          total_loss: 0.25765813369126545\n",
      "          vf_explained_var: 0.8662614822387695\n",
      "          vf_loss: 0.31535013772192455\n",
      "    num_agent_steps_sampled: 99900\n",
      "    num_agent_steps_trained: 99900\n",
      "    num_steps_sampled: 99900\n",
      "    num_steps_trained: 99900\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.359375\n",
      "    ram_util_percent: 29.8625\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044553415966845124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.091977846034105\n",
      "    mean_inference_ms: 2.525117948905022\n",
      "    mean_raw_obs_processing_ms: 1.7517709593329107\n",
      "  time_since_restore: 1368.2953751087189\n",
      "  time_this_iter_s: 22.445897102355957\n",
      "  time_total_s: 1368.2953751087189\n",
      "  timers:\n",
      "    learn_throughput: 1148.48\n",
      "    learn_time_ms: 1739.69\n",
      "    load_throughput: 58585.726\n",
      "    load_time_ms: 34.104\n",
      "    sample_throughput: 95.412\n",
      "    sample_time_ms: 20940.748\n",
      "    update_time_ms: 10.164\n",
      "  timestamp: 1636430881\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 99900\n",
      "  training_iteration: 50\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">          1368.3</td><td style=\"text-align: right;\">99900</td><td style=\"text-align: right;\">    4.23</td><td style=\"text-align: right;\">                8.45</td><td style=\"text-align: right;\">                0.04</td><td style=\"text-align: right;\">            115.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 101898\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-08-24\n",
      "  done: false\n",
      "  episode_len_mean: 115.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.450000000000017\n",
      "  episode_reward_mean: 4.373400000000018\n",
      "  episode_reward_min: 0.03999999999999878\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 952\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0408249917484467\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015426255068613825\n",
      "          policy_loss: -0.007843942656403495\n",
      "          total_loss: 0.2922683711119351\n",
      "          vf_explained_var: 0.8638580441474915\n",
      "          vf_loss: 0.3158926853111812\n",
      "    num_agent_steps_sampled: 101898\n",
      "    num_agent_steps_trained: 101898\n",
      "    num_steps_sampled: 101898\n",
      "    num_steps_trained: 101898\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.340625\n",
      "    ram_util_percent: 29.778125\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04456225661067071\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.973208047445997\n",
      "    mean_inference_ms: 2.523914238295382\n",
      "    mean_raw_obs_processing_ms: 1.7281847163464068\n",
      "  time_since_restore: 1391.159279346466\n",
      "  time_this_iter_s: 22.863904237747192\n",
      "  time_total_s: 1391.159279346466\n",
      "  timers:\n",
      "    learn_throughput: 1149.484\n",
      "    learn_time_ms: 1738.172\n",
      "    load_throughput: 58662.251\n",
      "    load_time_ms: 34.059\n",
      "    sample_throughput: 95.355\n",
      "    sample_time_ms: 20953.274\n",
      "    update_time_ms: 10.327\n",
      "  timestamp: 1636430904\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 101898\n",
      "  training_iteration: 51\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         1391.16</td><td style=\"text-align: right;\">101898</td><td style=\"text-align: right;\">  4.3734</td><td style=\"text-align: right;\">                8.45</td><td style=\"text-align: right;\">                0.04</td><td style=\"text-align: right;\">            115.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 103896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-08-47\n",
      "  done: false\n",
      "  episode_len_mean: 115.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.450000000000017\n",
      "  episode_reward_mean: 4.47000000000002\n",
      "  episode_reward_min: 1.730000000000014\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 968\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0465084427878972\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01645807182411797\n",
      "          policy_loss: -0.03876154479526338\n",
      "          total_loss: 0.2996173066087067\n",
      "          vf_explained_var: 0.8239596486091614\n",
      "          vf_loss: 0.3539065139279479\n",
      "    num_agent_steps_sampled: 103896\n",
      "    num_agent_steps_trained: 103896\n",
      "    num_steps_sampled: 103896\n",
      "    num_steps_trained: 103896\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.71515151515153\n",
      "    ram_util_percent: 29.82424242424242\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044580645088454655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.874636531621064\n",
      "    mean_inference_ms: 2.5230342662010075\n",
      "    mean_raw_obs_processing_ms: 1.7075112101782326\n",
      "  time_since_restore: 1413.7763888835907\n",
      "  time_this_iter_s: 22.617109537124634\n",
      "  time_total_s: 1413.7763888835907\n",
      "  timers:\n",
      "    learn_throughput: 1149.995\n",
      "    learn_time_ms: 1737.399\n",
      "    load_throughput: 58600.802\n",
      "    load_time_ms: 34.095\n",
      "    sample_throughput: 95.757\n",
      "    sample_time_ms: 20865.209\n",
      "    update_time_ms: 9.613\n",
      "  timestamp: 1636430927\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 103896\n",
      "  training_iteration: 52\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         1413.78</td><td style=\"text-align: right;\">103896</td><td style=\"text-align: right;\">    4.47</td><td style=\"text-align: right;\">                8.45</td><td style=\"text-align: right;\">                1.73</td><td style=\"text-align: right;\">             115.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 105894\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-09-09\n",
      "  done: false\n",
      "  episode_len_mean: 115.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.240000000000018\n",
      "  episode_reward_mean: 4.60660000000002\n",
      "  episode_reward_min: 1.570000000000009\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 985\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0544229836690993\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011636676008214317\n",
      "          policy_loss: 0.04100422828147809\n",
      "          total_loss: 0.3565508488920473\n",
      "          vf_explained_var: 0.832097589969635\n",
      "          vf_loss: 0.3325998508504459\n",
      "    num_agent_steps_sampled: 105894\n",
      "    num_agent_steps_trained: 105894\n",
      "    num_steps_sampled: 105894\n",
      "    num_steps_trained: 105894\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28437500000001\n",
      "    ram_util_percent: 29.7875\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044590237158837615\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.77435849684819\n",
      "    mean_inference_ms: 2.521990528018028\n",
      "    mean_raw_obs_processing_ms: 1.6865637686065036\n",
      "  time_since_restore: 1436.4901087284088\n",
      "  time_this_iter_s: 22.713719844818115\n",
      "  time_total_s: 1436.4901087284088\n",
      "  timers:\n",
      "    learn_throughput: 1149.28\n",
      "    learn_time_ms: 1738.479\n",
      "    load_throughput: 58505.437\n",
      "    load_time_ms: 34.151\n",
      "    sample_throughput: 95.301\n",
      "    sample_time_ms: 20965.108\n",
      "    update_time_ms: 10.429\n",
      "  timestamp: 1636430949\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 105894\n",
      "  training_iteration: 53\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         1436.49</td><td style=\"text-align: right;\">105894</td><td style=\"text-align: right;\">  4.6066</td><td style=\"text-align: right;\">                8.24</td><td style=\"text-align: right;\">                1.57</td><td style=\"text-align: right;\">            115.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 107892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-09-33\n",
      "  done: false\n",
      "  episode_len_mean: 114.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.280000000000019\n",
      "  episode_reward_mean: 4.84730000000002\n",
      "  episode_reward_min: 1.3900000000000141\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1003\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0397298801512944\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012172719894203337\n",
      "          policy_loss: -0.06038928652803103\n",
      "          total_loss: 0.30116976276040075\n",
      "          vf_explained_var: 0.8240649104118347\n",
      "          vf_loss: 0.37830453188646407\n",
      "    num_agent_steps_sampled: 107892\n",
      "    num_agent_steps_trained: 107892\n",
      "    num_steps_sampled: 107892\n",
      "    num_steps_trained: 107892\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.74848484848485\n",
      "    ram_util_percent: 29.675757575757576\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04458006952825272\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.685609265533145\n",
      "    mean_inference_ms: 2.5208211324236793\n",
      "    mean_raw_obs_processing_ms: 1.6664524067238204\n",
      "  time_since_restore: 1459.716400384903\n",
      "  time_this_iter_s: 23.22629165649414\n",
      "  time_total_s: 1459.716400384903\n",
      "  timers:\n",
      "    learn_throughput: 1150.328\n",
      "    learn_time_ms: 1736.895\n",
      "    load_throughput: 58268.115\n",
      "    load_time_ms: 34.29\n",
      "    sample_throughput: 95.347\n",
      "    sample_time_ms: 20955.068\n",
      "    update_time_ms: 10.173\n",
      "  timestamp: 1636430973\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 107892\n",
      "  training_iteration: 54\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         1459.72</td><td style=\"text-align: right;\">107892</td><td style=\"text-align: right;\">  4.8473</td><td style=\"text-align: right;\">               10.28</td><td style=\"text-align: right;\">                1.39</td><td style=\"text-align: right;\">             114.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 109890\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-09-56\n",
      "  done: false\n",
      "  episode_len_mean: 113.83\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.280000000000019\n",
      "  episode_reward_mean: 4.79940000000002\n",
      "  episode_reward_min: 1.3900000000000141\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1021\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0767291250683013\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015660367380408772\n",
      "          policy_loss: -0.03878968993113154\n",
      "          total_loss: 0.33202772974258377\n",
      "          vf_explained_var: 0.8236551880836487\n",
      "          vf_loss: 0.3868866000147093\n",
      "    num_agent_steps_sampled: 109890\n",
      "    num_agent_steps_trained: 109890\n",
      "    num_steps_sampled: 109890\n",
      "    num_steps_trained: 109890\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.2909090909091\n",
      "    ram_util_percent: 29.696969696969695\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044591124541558856\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.600769383811507\n",
      "    mean_inference_ms: 2.5199706525308914\n",
      "    mean_raw_obs_processing_ms: 1.646558804738724\n",
      "  time_since_restore: 1482.8493840694427\n",
      "  time_this_iter_s: 23.132983684539795\n",
      "  time_total_s: 1482.8493840694427\n",
      "  timers:\n",
      "    learn_throughput: 1151.847\n",
      "    learn_time_ms: 1734.605\n",
      "    load_throughput: 58268.601\n",
      "    load_time_ms: 34.289\n",
      "    sample_throughput: 95.546\n",
      "    sample_time_ms: 20911.47\n",
      "    update_time_ms: 10.405\n",
      "  timestamp: 1636430996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109890\n",
      "  training_iteration: 55\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         1482.85</td><td style=\"text-align: right;\">109890</td><td style=\"text-align: right;\">  4.7994</td><td style=\"text-align: right;\">               10.28</td><td style=\"text-align: right;\">                1.39</td><td style=\"text-align: right;\">            113.83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 111888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-10-20\n",
      "  done: false\n",
      "  episode_len_mean: 113.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.280000000000019\n",
      "  episode_reward_mean: 4.82620000000002\n",
      "  episode_reward_min: 1.3900000000000141\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1040\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0977039399601165\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016980812885549933\n",
      "          policy_loss: -0.019523165472561405\n",
      "          total_loss: 0.427362242460783\n",
      "          vf_explained_var: 0.8075976967811584\n",
      "          vf_loss: 0.46276820458116985\n",
      "    num_agent_steps_sampled: 111888\n",
      "    num_agent_steps_trained: 111888\n",
      "    num_steps_sampled: 111888\n",
      "    num_steps_trained: 111888\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.44857142857143\n",
      "    ram_util_percent: 29.7\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04458867479380101\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.52490298579633\n",
      "    mean_inference_ms: 2.519287325239703\n",
      "    mean_raw_obs_processing_ms: 1.6272670010204726\n",
      "  time_since_restore: 1507.178384065628\n",
      "  time_this_iter_s: 24.328999996185303\n",
      "  time_total_s: 1507.178384065628\n",
      "  timers:\n",
      "    learn_throughput: 1153.075\n",
      "    learn_time_ms: 1732.758\n",
      "    load_throughput: 58308.171\n",
      "    load_time_ms: 34.266\n",
      "    sample_throughput: 94.776\n",
      "    sample_time_ms: 21081.387\n",
      "    update_time_ms: 10.951\n",
      "  timestamp: 1636431020\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 111888\n",
      "  training_iteration: 56\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         1507.18</td><td style=\"text-align: right;\">111888</td><td style=\"text-align: right;\">  4.8262</td><td style=\"text-align: right;\">               10.28</td><td style=\"text-align: right;\">                1.39</td><td style=\"text-align: right;\">            113.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 113886\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-10-45\n",
      "  done: false\n",
      "  episode_len_mean: 110.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.280000000000019\n",
      "  episode_reward_mean: 4.885800000000018\n",
      "  episode_reward_min: 1.3900000000000141\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1059\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.07346738917487\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014028893750474352\n",
      "          policy_loss: -0.03994331432595139\n",
      "          total_loss: 0.3133088690184411\n",
      "          vf_explained_var: 0.8264788389205933\n",
      "          vf_loss: 0.36977819076606205\n",
      "    num_agent_steps_sampled: 113886\n",
      "    num_agent_steps_trained: 113886\n",
      "    num_steps_sampled: 113886\n",
      "    num_steps_trained: 113886\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.46857142857144\n",
      "    ram_util_percent: 29.642857142857142\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04458990536456893\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.464123146040066\n",
      "    mean_inference_ms: 2.519070643860656\n",
      "    mean_raw_obs_processing_ms: 1.6079353936616783\n",
      "  time_since_restore: 1531.8853805065155\n",
      "  time_this_iter_s: 24.70699644088745\n",
      "  time_total_s: 1531.8853805065155\n",
      "  timers:\n",
      "    learn_throughput: 1150.716\n",
      "    learn_time_ms: 1736.31\n",
      "    load_throughput: 58382.508\n",
      "    load_time_ms: 34.223\n",
      "    sample_throughput: 94.117\n",
      "    sample_time_ms: 21228.867\n",
      "    update_time_ms: 11.234\n",
      "  timestamp: 1636431045\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 113886\n",
      "  training_iteration: 57\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         1531.89</td><td style=\"text-align: right;\">113886</td><td style=\"text-align: right;\">  4.8858</td><td style=\"text-align: right;\">               10.28</td><td style=\"text-align: right;\">                1.39</td><td style=\"text-align: right;\">            110.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 115884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-11-37\n",
      "  done: false\n",
      "  episode_len_mean: 109.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.280000000000019\n",
      "  episode_reward_mean: 4.791900000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1078\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0273526753698077\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.021859155400320622\n",
      "          policy_loss: -0.05940753643711408\n",
      "          total_loss: 0.28535945885592984\n",
      "          vf_explained_var: 0.848068118095398\n",
      "          vf_loss: 0.3584827768660727\n",
      "    num_agent_steps_sampled: 115884\n",
      "    num_agent_steps_trained: 115884\n",
      "    num_steps_sampled: 115884\n",
      "    num_steps_trained: 115884\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.72837837837838\n",
      "    ram_util_percent: 29.55810810810811\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044577551517925224\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.405883373059513\n",
      "    mean_inference_ms: 2.5188076537127113\n",
      "    mean_raw_obs_processing_ms: 1.6717921037773034\n",
      "  time_since_restore: 1583.8522765636444\n",
      "  time_this_iter_s: 51.966896057128906\n",
      "  time_total_s: 1583.8522765636444\n",
      "  timers:\n",
      "    learn_throughput: 1153.918\n",
      "    learn_time_ms: 1731.492\n",
      "    load_throughput: 58372.179\n",
      "    load_time_ms: 34.229\n",
      "    sample_throughput: 82.247\n",
      "    sample_time_ms: 24292.569\n",
      "    update_time_ms: 10.612\n",
      "  timestamp: 1636431097\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 115884\n",
      "  training_iteration: 58\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         1583.85</td><td style=\"text-align: right;\">115884</td><td style=\"text-align: right;\">  4.7919</td><td style=\"text-align: right;\">               10.28</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            109.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 117882\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-12-04\n",
      "  done: false\n",
      "  episode_len_mean: 108.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.280000000000019\n",
      "  episode_reward_mean: 4.8175000000000185\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1096\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0026421047392344\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014944803033317126\n",
      "          policy_loss: -0.08165990062767552\n",
      "          total_loss: 0.2779701093477862\n",
      "          vf_explained_var: 0.8640903234481812\n",
      "          vf_loss: 0.3729312678532941\n",
      "    num_agent_steps_sampled: 117882\n",
      "    num_agent_steps_trained: 117882\n",
      "    num_steps_sampled: 117882\n",
      "    num_steps_trained: 117882\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.68157894736842\n",
      "    ram_util_percent: 29.584210526315797\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044570065162754906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.36105183685464\n",
      "    mean_inference_ms: 2.5184169651211907\n",
      "    mean_raw_obs_processing_ms: 1.7328345115135744\n",
      "  time_since_restore: 1610.4449315071106\n",
      "  time_this_iter_s: 26.592654943466187\n",
      "  time_total_s: 1610.4449315071106\n",
      "  timers:\n",
      "    learn_throughput: 1155.801\n",
      "    learn_time_ms: 1728.672\n",
      "    load_throughput: 58629.254\n",
      "    load_time_ms: 34.079\n",
      "    sample_throughput: 80.967\n",
      "    sample_time_ms: 24676.649\n",
      "    update_time_ms: 10.542\n",
      "  timestamp: 1636431124\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 117882\n",
      "  training_iteration: 59\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         1610.44</td><td style=\"text-align: right;\">117882</td><td style=\"text-align: right;\">  4.8175</td><td style=\"text-align: right;\">               10.28</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            108.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 119880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-12-29\n",
      "  done: false\n",
      "  episode_len_mean: 107.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.410000000000016\n",
      "  episode_reward_mean: 4.892300000000019\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1114\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8903589174861\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013995832880996468\n",
      "          policy_loss: -0.051033693055311836\n",
      "          total_loss: 0.43096723921951796\n",
      "          vf_explained_var: 0.8192477226257324\n",
      "          vf_loss: 0.49460639726547967\n",
      "    num_agent_steps_sampled: 119880\n",
      "    num_agent_steps_trained: 119880\n",
      "    num_steps_sampled: 119880\n",
      "    num_steps_trained: 119880\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94594594594597\n",
      "    ram_util_percent: 29.93243243243243\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04456626330838543\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.32638829613784\n",
      "    mean_inference_ms: 2.5178391211155002\n",
      "    mean_raw_obs_processing_ms: 1.7932477324659908\n",
      "  time_since_restore: 1636.1168763637543\n",
      "  time_this_iter_s: 25.671944856643677\n",
      "  time_total_s: 1636.1168763637543\n",
      "  timers:\n",
      "    learn_throughput: 1156.245\n",
      "    learn_time_ms: 1728.008\n",
      "    load_throughput: 58648.375\n",
      "    load_time_ms: 34.067\n",
      "    sample_throughput: 79.917\n",
      "    sample_time_ms: 25001.065\n",
      "    update_time_ms: 9.603\n",
      "  timestamp: 1636431149\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 119880\n",
      "  training_iteration: 60\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         1636.12</td><td style=\"text-align: right;\">119880</td><td style=\"text-align: right;\">  4.8923</td><td style=\"text-align: right;\">                8.41</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            107.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 121878\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-12-54\n",
      "  done: false\n",
      "  episode_len_mean: 107.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.350000000000016\n",
      "  episode_reward_mean: 4.927700000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1133\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.960709465685345\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010383460468113613\n",
      "          policy_loss: -0.04374054469877765\n",
      "          total_loss: 0.2429510053424608\n",
      "          vf_explained_var: 0.888956606388092\n",
      "          vf_loss: 0.30162608847022054\n",
      "    num_agent_steps_sampled: 121878\n",
      "    num_agent_steps_trained: 121878\n",
      "    num_steps_sampled: 121878\n",
      "    num_steps_trained: 121878\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.32777777777777\n",
      "    ram_util_percent: 29.91944444444444\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044544077368921985\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.291507679126244\n",
      "    mean_inference_ms: 2.516984997992152\n",
      "    mean_raw_obs_processing_ms: 1.8562431737533887\n",
      "  time_since_restore: 1661.0196795463562\n",
      "  time_this_iter_s: 24.90280318260193\n",
      "  time_total_s: 1661.0196795463562\n",
      "  timers:\n",
      "    learn_throughput: 1156.682\n",
      "    learn_time_ms: 1727.355\n",
      "    load_throughput: 58901.891\n",
      "    load_time_ms: 33.921\n",
      "    sample_throughput: 79.267\n",
      "    sample_time_ms: 25205.963\n",
      "    update_time_ms: 9.442\n",
      "  timestamp: 1636431174\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 121878\n",
      "  training_iteration: 61\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         1661.02</td><td style=\"text-align: right;\">121878</td><td style=\"text-align: right;\">  4.9277</td><td style=\"text-align: right;\">                8.35</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            107.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 123876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-13-19\n",
      "  done: false\n",
      "  episode_len_mean: 107.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.040000000000019\n",
      "  episode_reward_mean: 4.909100000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1151\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8635292830921355\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012094896383081066\n",
      "          policy_loss: 0.03357324901790846\n",
      "          total_loss: 0.3739569134300663\n",
      "          vf_explained_var: 0.8956397175788879\n",
      "          vf_loss: 0.3535762541350864\n",
      "    num_agent_steps_sampled: 123876\n",
      "    num_agent_steps_trained: 123876\n",
      "    num_steps_sampled: 123876\n",
      "    num_steps_trained: 123876\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.58055555555556\n",
      "    ram_util_percent: 29.980555555555554\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044551423234217576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.252370564429775\n",
      "    mean_inference_ms: 2.5158509881413385\n",
      "    mean_raw_obs_processing_ms: 1.9155706875137337\n",
      "  time_since_restore: 1686.1532144546509\n",
      "  time_this_iter_s: 25.133534908294678\n",
      "  time_total_s: 1686.1532144546509\n",
      "  timers:\n",
      "    learn_throughput: 1157.335\n",
      "    learn_time_ms: 1726.38\n",
      "    load_throughput: 58877.599\n",
      "    load_time_ms: 33.935\n",
      "    sample_throughput: 78.484\n",
      "    sample_time_ms: 25457.578\n",
      "    update_time_ms: 10.31\n",
      "  timestamp: 1636431199\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 123876\n",
      "  training_iteration: 62\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         1686.15</td><td style=\"text-align: right;\">123876</td><td style=\"text-align: right;\">  4.9091</td><td style=\"text-align: right;\">                8.04</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            107.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 125874\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-13-44\n",
      "  done: false\n",
      "  episode_len_mean: 109.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.040000000000019\n",
      "  episode_reward_mean: 4.895500000000019\n",
      "  episode_reward_min: 1.6000000000000165\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1170\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.013200106507256\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014413913142763506\n",
      "          policy_loss: -0.004265573097481614\n",
      "          total_loss: 0.31513489628476754\n",
      "          vf_explained_var: 0.8737975358963013\n",
      "          vf_loss: 0.33304621023791176\n",
      "    num_agent_steps_sampled: 125874\n",
      "    num_agent_steps_trained: 125874\n",
      "    num_steps_sampled: 125874\n",
      "    num_steps_trained: 125874\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28571428571429\n",
      "    ram_util_percent: 30.0\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04454884828388441\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.220856022434127\n",
      "    mean_inference_ms: 2.5149152804077914\n",
      "    mean_raw_obs_processing_ms: 1.9294444325201843\n",
      "  time_since_restore: 1710.7431614398956\n",
      "  time_this_iter_s: 24.58994698524475\n",
      "  time_total_s: 1710.7431614398956\n",
      "  timers:\n",
      "    learn_throughput: 1154.789\n",
      "    learn_time_ms: 1730.185\n",
      "    load_throughput: 58768.718\n",
      "    load_time_ms: 33.998\n",
      "    sample_throughput: 77.918\n",
      "    sample_time_ms: 25642.36\n",
      "    update_time_ms: 9.468\n",
      "  timestamp: 1636431224\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 125874\n",
      "  training_iteration: 63\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         1710.74</td><td style=\"text-align: right;\">125874</td><td style=\"text-align: right;\">  4.8955</td><td style=\"text-align: right;\">                8.04</td><td style=\"text-align: right;\">                 1.6</td><td style=\"text-align: right;\">             109.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 127872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-14-09\n",
      "  done: false\n",
      "  episode_len_mean: 108.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.900000000000022\n",
      "  episode_reward_mean: 5.000200000000018\n",
      "  episode_reward_min: 1.6000000000000165\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1188\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9472735251699176\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013782804326844983\n",
      "          policy_loss: 0.0015428579368052028\n",
      "          total_loss: 0.30344329675038656\n",
      "          vf_explained_var: 0.8933245539665222\n",
      "          vf_loss: 0.31517091123830704\n",
      "    num_agent_steps_sampled: 127872\n",
      "    num_agent_steps_trained: 127872\n",
      "    num_steps_sampled: 127872\n",
      "    num_steps_trained: 127872\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.42857142857143\n",
      "    ram_util_percent: 30.062857142857144\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044565515385723516\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.190630059534836\n",
      "    mean_inference_ms: 2.5143225543774275\n",
      "    mean_raw_obs_processing_ms: 1.9096786097056075\n",
      "  time_since_restore: 1735.6116044521332\n",
      "  time_this_iter_s: 24.86844301223755\n",
      "  time_total_s: 1735.6116044521332\n",
      "  timers:\n",
      "    learn_throughput: 1154.037\n",
      "    learn_time_ms: 1731.314\n",
      "    load_throughput: 60041.149\n",
      "    load_time_ms: 33.277\n",
      "    sample_throughput: 77.424\n",
      "    sample_time_ms: 25805.974\n",
      "    update_time_ms: 9.59\n",
      "  timestamp: 1636431249\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 127872\n",
      "  training_iteration: 64\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         1735.61</td><td style=\"text-align: right;\">127872</td><td style=\"text-align: right;\">  5.0002</td><td style=\"text-align: right;\">                 7.9</td><td style=\"text-align: right;\">                 1.6</td><td style=\"text-align: right;\">            108.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 129870\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-14-32\n",
      "  done: false\n",
      "  episode_len_mean: 109.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.900000000000022\n",
      "  episode_reward_mean: 4.9543000000000195\n",
      "  episode_reward_min: 1.6000000000000165\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1205\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.828952982312157\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010641088243993006\n",
      "          policy_loss: -0.012565820504512106\n",
      "          total_loss: 0.3814888860143366\n",
      "          vf_explained_var: 0.8183948993682861\n",
      "          vf_loss: 0.407555746677376\n",
      "    num_agent_steps_sampled: 129870\n",
      "    num_agent_steps_trained: 129870\n",
      "    num_steps_sampled: 129870\n",
      "    num_steps_trained: 129870\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.25588235294119\n",
      "    ram_util_percent: 30.067647058823532\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044571798269702645\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.155972424476804\n",
      "    mean_inference_ms: 2.513599599408419\n",
      "    mean_raw_obs_processing_ms: 1.8913784504571731\n",
      "  time_since_restore: 1759.1578497886658\n",
      "  time_this_iter_s: 23.546245336532593\n",
      "  time_total_s: 1759.1578497886658\n",
      "  timers:\n",
      "    learn_throughput: 1154.137\n",
      "    learn_time_ms: 1731.163\n",
      "    load_throughput: 60290.823\n",
      "    load_time_ms: 33.139\n",
      "    sample_throughput: 77.299\n",
      "    sample_time_ms: 25847.661\n",
      "    update_time_ms: 9.757\n",
      "  timestamp: 1636431272\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 129870\n",
      "  training_iteration: 65\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         1759.16</td><td style=\"text-align: right;\">129870</td><td style=\"text-align: right;\">  4.9543</td><td style=\"text-align: right;\">                 7.9</td><td style=\"text-align: right;\">                 1.6</td><td style=\"text-align: right;\">            109.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 131868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-14-57\n",
      "  done: false\n",
      "  episode_len_mean: 110.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.900000000000022\n",
      "  episode_reward_mean: 4.926800000000019\n",
      "  episode_reward_min: 1.570000000000012\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1223\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8938475324994042\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01230171263967498\n",
      "          policy_loss: -0.06475198597514203\n",
      "          total_loss: 0.3802946381270885\n",
      "          vf_explained_var: 0.8204451203346252\n",
      "          vf_loss: 0.45844933241605756\n",
      "    num_agent_steps_sampled: 131868\n",
      "    num_agent_steps_trained: 131868\n",
      "    num_steps_sampled: 131868\n",
      "    num_steps_trained: 131868\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16176470588236\n",
      "    ram_util_percent: 30.008823529411767\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04457455647238755\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.118085733828366\n",
      "    mean_inference_ms: 2.512971407703106\n",
      "    mean_raw_obs_processing_ms: 1.8724316409607915\n",
      "  time_since_restore: 1783.3825743198395\n",
      "  time_this_iter_s: 24.224724531173706\n",
      "  time_total_s: 1783.3825743198395\n",
      "  timers:\n",
      "    learn_throughput: 1153.738\n",
      "    learn_time_ms: 1731.762\n",
      "    load_throughput: 60135.893\n",
      "    load_time_ms: 33.225\n",
      "    sample_throughput: 77.33\n",
      "    sample_time_ms: 25837.242\n",
      "    update_time_ms: 9.072\n",
      "  timestamp: 1636431297\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 131868\n",
      "  training_iteration: 66\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         1783.38</td><td style=\"text-align: right;\">131868</td><td style=\"text-align: right;\">  4.9268</td><td style=\"text-align: right;\">                 7.9</td><td style=\"text-align: right;\">                1.57</td><td style=\"text-align: right;\">            110.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 133866\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-15-20\n",
      "  done: false\n",
      "  episode_len_mean: 111.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.900000000000022\n",
      "  episode_reward_mean: 5.04430000000002\n",
      "  episode_reward_min: 1.570000000000012\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1240\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0160211636906578\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011078055796955854\n",
      "          policy_loss: -0.010015275329351425\n",
      "          total_loss: 0.3438279920213279\n",
      "          vf_explained_var: 0.8497719764709473\n",
      "          vf_loss: 0.3690183561472666\n",
      "    num_agent_steps_sampled: 133866\n",
      "    num_agent_steps_trained: 133866\n",
      "    num_steps_sampled: 133866\n",
      "    num_steps_trained: 133866\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.52352941176471\n",
      "    ram_util_percent: 29.985294117647058\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04459882188885249\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.069501685304385\n",
      "    mean_inference_ms: 2.512441635848288\n",
      "    mean_raw_obs_processing_ms: 1.8546762311228513\n",
      "  time_since_restore: 1807.0463144779205\n",
      "  time_this_iter_s: 23.663740158081055\n",
      "  time_total_s: 1807.0463144779205\n",
      "  timers:\n",
      "    learn_throughput: 1156.019\n",
      "    learn_time_ms: 1728.345\n",
      "    load_throughput: 60015.307\n",
      "    load_time_ms: 33.292\n",
      "    sample_throughput: 77.633\n",
      "    sample_time_ms: 25736.392\n",
      "    update_time_ms: 8.783\n",
      "  timestamp: 1636431320\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 133866\n",
      "  training_iteration: 67\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         1807.05</td><td style=\"text-align: right;\">133866</td><td style=\"text-align: right;\">  5.0443</td><td style=\"text-align: right;\">                 7.9</td><td style=\"text-align: right;\">                1.57</td><td style=\"text-align: right;\">            111.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 135864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-15-44\n",
      "  done: false\n",
      "  episode_len_mean: 113.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.900000000000016\n",
      "  episode_reward_mean: 5.0179000000000205\n",
      "  episode_reward_min: 1.570000000000012\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1257\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0293604680470057\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.018227676689552712\n",
      "          policy_loss: -0.06041483244903031\n",
      "          total_loss: 0.3004311767628505\n",
      "          vf_explained_var: 0.8470023274421692\n",
      "          vf_loss: 0.37293715750177703\n",
      "    num_agent_steps_sampled: 135864\n",
      "    num_agent_steps_trained: 135864\n",
      "    num_steps_sampled: 135864\n",
      "    num_steps_trained: 135864\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.47714285714287\n",
      "    ram_util_percent: 29.957142857142856\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04459080262879162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.02803356036161\n",
      "    mean_inference_ms: 2.5117368652971974\n",
      "    mean_raw_obs_processing_ms: 1.8374338786568296\n",
      "  time_since_restore: 1831.0588150024414\n",
      "  time_this_iter_s: 24.012500524520874\n",
      "  time_total_s: 1831.0588150024414\n",
      "  timers:\n",
      "    learn_throughput: 1154.98\n",
      "    learn_time_ms: 1729.9\n",
      "    load_throughput: 59529.258\n",
      "    load_time_ms: 33.563\n",
      "    sample_throughput: 87.102\n",
      "    sample_time_ms: 22938.666\n",
      "    update_time_ms: 9.235\n",
      "  timestamp: 1636431344\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 135864\n",
      "  training_iteration: 68\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         1831.06</td><td style=\"text-align: right;\">135864</td><td style=\"text-align: right;\">  5.0179</td><td style=\"text-align: right;\">                 7.9</td><td style=\"text-align: right;\">                1.57</td><td style=\"text-align: right;\">            113.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 137862\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-16-08\n",
      "  done: false\n",
      "  episode_len_mean: 114.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.870000000000019\n",
      "  episode_reward_mean: 5.00680000000002\n",
      "  episode_reward_min: 1.570000000000012\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1275\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9804128510611398\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011515350530229286\n",
      "          policy_loss: -0.030470114875407447\n",
      "          total_loss: 0.30194798700866243\n",
      "          vf_explained_var: 0.8498184680938721\n",
      "          vf_loss: 0.3470403212166968\n",
      "    num_agent_steps_sampled: 137862\n",
      "    num_agent_steps_trained: 137862\n",
      "    num_steps_sampled: 137862\n",
      "    num_steps_trained: 137862\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84545454545453\n",
      "    ram_util_percent: 29.893939393939394\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04459212474638047\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.979229083112514\n",
      "    mean_inference_ms: 2.5111780550799785\n",
      "    mean_raw_obs_processing_ms: 1.818988686429541\n",
      "  time_since_restore: 1854.6842904090881\n",
      "  time_this_iter_s: 23.62547540664673\n",
      "  time_total_s: 1854.6842904090881\n",
      "  timers:\n",
      "    learn_throughput: 1157.761\n",
      "    learn_time_ms: 1725.744\n",
      "    load_throughput: 60627.554\n",
      "    load_time_ms: 32.955\n",
      "    sample_throughput: 88.224\n",
      "    sample_time_ms: 22646.919\n",
      "    update_time_ms: 9.15\n",
      "  timestamp: 1636431368\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 137862\n",
      "  training_iteration: 69\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         1854.68</td><td style=\"text-align: right;\">137862</td><td style=\"text-align: right;\">  5.0068</td><td style=\"text-align: right;\">                7.87</td><td style=\"text-align: right;\">                1.57</td><td style=\"text-align: right;\">            114.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 139860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-16-31\n",
      "  done: false\n",
      "  episode_len_mean: 115.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.830000000000023\n",
      "  episode_reward_mean: 4.92420000000002\n",
      "  episode_reward_min: 1.570000000000012\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1292\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8789924144744874\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014879965594637617\n",
      "          policy_loss: -0.046302712726451103\n",
      "          total_loss: 0.32321352415851184\n",
      "          vf_explained_var: 0.8398255705833435\n",
      "          vf_loss: 0.38161017901840666\n",
      "    num_agent_steps_sampled: 139860\n",
      "    num_agent_steps_trained: 139860\n",
      "    num_steps_sampled: 139860\n",
      "    num_steps_trained: 139860\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03125\n",
      "    ram_util_percent: 29.893749999999997\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04457813824785898\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.930841932771294\n",
      "    mean_inference_ms: 2.5104648639402756\n",
      "    mean_raw_obs_processing_ms: 1.8021073246647978\n",
      "  time_since_restore: 1877.1953008174896\n",
      "  time_this_iter_s: 22.51101040840149\n",
      "  time_total_s: 1877.1953008174896\n",
      "  timers:\n",
      "    learn_throughput: 1156.354\n",
      "    learn_time_ms: 1727.845\n",
      "    load_throughput: 60591.609\n",
      "    load_time_ms: 32.975\n",
      "    sample_throughput: 89.481\n",
      "    sample_time_ms: 22328.793\n",
      "    update_time_ms: 9.113\n",
      "  timestamp: 1636431391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 139860\n",
      "  training_iteration: 70\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">          1877.2</td><td style=\"text-align: right;\">139860</td><td style=\"text-align: right;\">  4.9242</td><td style=\"text-align: right;\">                7.83</td><td style=\"text-align: right;\">                1.57</td><td style=\"text-align: right;\">            115.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 141858\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-16-55\n",
      "  done: false\n",
      "  episode_len_mean: 115.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.18000000000002\n",
      "  episode_reward_mean: 4.987100000000021\n",
      "  episode_reward_min: 1.570000000000012\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1309\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9164436311948867\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013615726263435993\n",
      "          policy_loss: -0.042864624889833586\n",
      "          total_loss: 0.31201879016700246\n",
      "          vf_explained_var: 0.8747044205665588\n",
      "          vf_loss: 0.36792077649207344\n",
      "    num_agent_steps_sampled: 141858\n",
      "    num_agent_steps_trained: 141858\n",
      "    num_steps_sampled: 141858\n",
      "    num_steps_trained: 141858\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.175\n",
      "    ram_util_percent: 29.83055555555556\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044566879298834204\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.884799856038693\n",
      "    mean_inference_ms: 2.5098044763002916\n",
      "    mean_raw_obs_processing_ms: 1.7859024838668547\n",
      "  time_since_restore: 1901.7260308265686\n",
      "  time_this_iter_s: 24.53073000907898\n",
      "  time_total_s: 1901.7260308265686\n",
      "  timers:\n",
      "    learn_throughput: 1155.305\n",
      "    learn_time_ms: 1729.413\n",
      "    load_throughput: 60348.481\n",
      "    load_time_ms: 33.108\n",
      "    sample_throughput: 89.636\n",
      "    sample_time_ms: 22290.159\n",
      "    update_time_ms: 8.815\n",
      "  timestamp: 1636431415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 141858\n",
      "  training_iteration: 71\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         1901.73</td><td style=\"text-align: right;\">141858</td><td style=\"text-align: right;\">  4.9871</td><td style=\"text-align: right;\">               10.18</td><td style=\"text-align: right;\">                1.57</td><td style=\"text-align: right;\">            115.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 143856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-17-18\n",
      "  done: false\n",
      "  episode_len_mean: 116.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.18000000000002\n",
      "  episode_reward_mean: 5.1078000000000205\n",
      "  episode_reward_min: 1.8000000000000123\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1326\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9106936789694287\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012145190117180875\n",
      "          policy_loss: -0.01825353933409566\n",
      "          total_loss: 0.3224677793504227\n",
      "          vf_explained_var: 0.8755363821983337\n",
      "          vf_loss: 0.3543629160949162\n",
      "    num_agent_steps_sampled: 143856\n",
      "    num_agent_steps_trained: 143856\n",
      "    num_steps_sampled: 143856\n",
      "    num_steps_trained: 143856\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.68124999999999\n",
      "    ram_util_percent: 29.815625\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044557689732989944\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.83393250786228\n",
      "    mean_inference_ms: 2.5090349734095043\n",
      "    mean_raw_obs_processing_ms: 1.7698401095283414\n",
      "  time_since_restore: 1924.4338533878326\n",
      "  time_this_iter_s: 22.707822561264038\n",
      "  time_total_s: 1924.4338533878326\n",
      "  timers:\n",
      "    learn_throughput: 1154.763\n",
      "    learn_time_ms: 1730.226\n",
      "    load_throughput: 60429.771\n",
      "    load_time_ms: 33.063\n",
      "    sample_throughput: 90.623\n",
      "    sample_time_ms: 22047.348\n",
      "    update_time_ms: 8.342\n",
      "  timestamp: 1636431438\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 143856\n",
      "  training_iteration: 72\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         1924.43</td><td style=\"text-align: right;\">143856</td><td style=\"text-align: right;\">  5.1078</td><td style=\"text-align: right;\">               10.18</td><td style=\"text-align: right;\">                 1.8</td><td style=\"text-align: right;\">            116.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 145854\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-17-42\n",
      "  done: false\n",
      "  episode_len_mean: 115.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.420000000000016\n",
      "  episode_reward_mean: 5.249400000000021\n",
      "  episode_reward_min: 1.8000000000000123\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1344\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.903351998896826\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01391000803420343\n",
      "          policy_loss: -0.04799706087935539\n",
      "          total_loss: 0.311358475569813\n",
      "          vf_explained_var: 0.8766356110572815\n",
      "          vf_loss: 0.37212955057621\n",
      "    num_agent_steps_sampled: 145854\n",
      "    num_agent_steps_trained: 145854\n",
      "    num_steps_sampled: 145854\n",
      "    num_steps_trained: 145854\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.32941176470588\n",
      "    ram_util_percent: 29.805882352941175\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04452995292214254\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.789249532818747\n",
      "    mean_inference_ms: 2.5080190770083597\n",
      "    mean_raw_obs_processing_ms: 1.7537408404285946\n",
      "  time_since_restore: 1948.2043137550354\n",
      "  time_this_iter_s: 23.77046036720276\n",
      "  time_total_s: 1948.2043137550354\n",
      "  timers:\n",
      "    learn_throughput: 1159.176\n",
      "    learn_time_ms: 1723.637\n",
      "    load_throughput: 60373.654\n",
      "    load_time_ms: 33.094\n",
      "    sample_throughput: 90.938\n",
      "    sample_time_ms: 21970.923\n",
      "    update_time_ms: 8.907\n",
      "  timestamp: 1636431462\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 145854\n",
      "  training_iteration: 73\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">          1948.2</td><td style=\"text-align: right;\">145854</td><td style=\"text-align: right;\">  5.2494</td><td style=\"text-align: right;\">               10.42</td><td style=\"text-align: right;\">                 1.8</td><td style=\"text-align: right;\">            115.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 147852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-18-05\n",
      "  done: false\n",
      "  episode_len_mean: 115.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.420000000000016\n",
      "  episode_reward_mean: 5.4279000000000215\n",
      "  episode_reward_min: 1.8000000000000123\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1362\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.96846315463384\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01326571381900922\n",
      "          policy_loss: -0.021381826858435357\n",
      "          total_loss: 0.2421733227159296\n",
      "          vf_explained_var: 0.9032809138298035\n",
      "          vf_loss: 0.277270209079697\n",
      "    num_agent_steps_sampled: 147852\n",
      "    num_agent_steps_trained: 147852\n",
      "    num_steps_sampled: 147852\n",
      "    num_steps_trained: 147852\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.29393939393938\n",
      "    ram_util_percent: 29.806060606060605\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044520076317911064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.738401909390678\n",
      "    mean_inference_ms: 2.5072100173878877\n",
      "    mean_raw_obs_processing_ms: 1.7381980528140073\n",
      "  time_since_restore: 1971.751273393631\n",
      "  time_this_iter_s: 23.54695963859558\n",
      "  time_total_s: 1971.751273393631\n",
      "  timers:\n",
      "    learn_throughput: 1159.288\n",
      "    learn_time_ms: 1723.471\n",
      "    load_throughput: 59468.976\n",
      "    load_time_ms: 33.597\n",
      "    sample_throughput: 91.49\n",
      "    sample_time_ms: 21838.388\n",
      "    update_time_ms: 8.953\n",
      "  timestamp: 1636431485\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 147852\n",
      "  training_iteration: 74\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         1971.75</td><td style=\"text-align: right;\">147852</td><td style=\"text-align: right;\">  5.4279</td><td style=\"text-align: right;\">               10.42</td><td style=\"text-align: right;\">                 1.8</td><td style=\"text-align: right;\">            115.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 149850\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-18-28\n",
      "  done: false\n",
      "  episode_len_mean: 116.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.420000000000016\n",
      "  episode_reward_mean: 5.70220000000002\n",
      "  episode_reward_min: 1.8000000000000123\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 1378\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8143053083192735\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.020695947257338723\n",
      "          policy_loss: -0.047476150663126084\n",
      "          total_loss: 0.47105011677458175\n",
      "          vf_explained_var: 0.8415629267692566\n",
      "          vf_loss: 0.5273561454245023\n",
      "    num_agent_steps_sampled: 149850\n",
      "    num_agent_steps_trained: 149850\n",
      "    num_steps_sampled: 149850\n",
      "    num_steps_trained: 149850\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.63636363636364\n",
      "    ram_util_percent: 29.8\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04453972600501124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.68942515010265\n",
      "    mean_inference_ms: 2.5071185515087664\n",
      "    mean_raw_obs_processing_ms: 1.724144091876231\n",
      "  time_since_restore: 1994.6397924423218\n",
      "  time_this_iter_s: 22.888519048690796\n",
      "  time_total_s: 1994.6397924423218\n",
      "  timers:\n",
      "    learn_throughput: 1159.387\n",
      "    learn_time_ms: 1723.324\n",
      "    load_throughput: 59175.57\n",
      "    load_time_ms: 33.764\n",
      "    sample_throughput: 91.764\n",
      "    sample_time_ms: 21773.132\n",
      "    update_time_ms: 8.202\n",
      "  timestamp: 1636431508\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 149850\n",
      "  training_iteration: 75\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         1994.64</td><td style=\"text-align: right;\">149850</td><td style=\"text-align: right;\">  5.7022</td><td style=\"text-align: right;\">               10.42</td><td style=\"text-align: right;\">                 1.8</td><td style=\"text-align: right;\">            116.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 151848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-18-51\n",
      "  done: false\n",
      "  episode_len_mean: 115.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.420000000000016\n",
      "  episode_reward_mean: 5.842300000000019\n",
      "  episode_reward_min: 1.8000000000000123\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1395\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9220567567007882\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01209161398060004\n",
      "          policy_loss: -0.027507350647023747\n",
      "          total_loss: 0.3808688119586025\n",
      "          vf_explained_var: 0.8774357438087463\n",
      "          vf_loss: 0.4194348907896451\n",
      "    num_agent_steps_sampled: 151848\n",
      "    num_agent_steps_trained: 151848\n",
      "    num_steps_sampled: 151848\n",
      "    num_steps_trained: 151848\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.56666666666668\n",
      "    ram_util_percent: 29.72121212121212\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0445487470302451\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.648714237409095\n",
      "    mean_inference_ms: 2.506771708691512\n",
      "    mean_raw_obs_processing_ms: 1.7097335538441498\n",
      "  time_since_restore: 2017.6138842105865\n",
      "  time_this_iter_s: 22.97409176826477\n",
      "  time_total_s: 2017.6138842105865\n",
      "  timers:\n",
      "    learn_throughput: 1158.982\n",
      "    learn_time_ms: 1723.926\n",
      "    load_throughput: 59793.962\n",
      "    load_time_ms: 33.415\n",
      "    sample_throughput: 92.294\n",
      "    sample_time_ms: 21648.193\n",
      "    update_time_ms: 7.837\n",
      "  timestamp: 1636431531\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 151848\n",
      "  training_iteration: 76\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         2017.61</td><td style=\"text-align: right;\">151848</td><td style=\"text-align: right;\">  5.8423</td><td style=\"text-align: right;\">               10.42</td><td style=\"text-align: right;\">                 1.8</td><td style=\"text-align: right;\">            115.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 153846\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-19-15\n",
      "  done: false\n",
      "  episode_len_mean: 114.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.420000000000016\n",
      "  episode_reward_mean: 5.8773000000000195\n",
      "  episode_reward_min: 2.0600000000000103\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1413\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8457779197465807\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009241003197188772\n",
      "          policy_loss: -0.03437241523393563\n",
      "          total_loss: 0.4119122295507363\n",
      "          vf_explained_var: 0.8619800209999084\n",
      "          vf_loss: 0.458504747847716\n",
      "    num_agent_steps_sampled: 153846\n",
      "    num_agent_steps_trained: 153846\n",
      "    num_steps_sampled: 153846\n",
      "    num_steps_trained: 153846\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0794117647059\n",
      "    ram_util_percent: 29.691176470588236\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044529925534356155\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.605456930624463\n",
      "    mean_inference_ms: 2.506060799339269\n",
      "    mean_raw_obs_processing_ms: 1.6953342120102397\n",
      "  time_since_restore: 2041.7030293941498\n",
      "  time_this_iter_s: 24.089145183563232\n",
      "  time_total_s: 2041.7030293941498\n",
      "  timers:\n",
      "    learn_throughput: 1158.727\n",
      "    learn_time_ms: 1724.305\n",
      "    load_throughput: 59996.616\n",
      "    load_time_ms: 33.302\n",
      "    sample_throughput: 92.112\n",
      "    sample_time_ms: 21691.037\n",
      "    update_time_ms: 7.613\n",
      "  timestamp: 1636431555\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 153846\n",
      "  training_iteration: 77\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">          2041.7</td><td style=\"text-align: right;\">153846</td><td style=\"text-align: right;\">  5.8773</td><td style=\"text-align: right;\">               10.42</td><td style=\"text-align: right;\">                2.06</td><td style=\"text-align: right;\">            114.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 155844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-20-11\n",
      "  done: false\n",
      "  episode_len_mean: 112.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.160000000000021\n",
      "  episode_reward_mean: 5.743700000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1434\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8532118621326628\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01175780376861744\n",
      "          policy_loss: -0.023775673976966314\n",
      "          total_loss: 0.5064218517392873\n",
      "          vf_explained_var: 0.8293305039405823\n",
      "          vf_loss: 0.540793121180364\n",
      "    num_agent_steps_sampled: 155844\n",
      "    num_agent_steps_trained: 155844\n",
      "    num_steps_sampled: 155844\n",
      "    num_steps_trained: 155844\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.84556962025317\n",
      "    ram_util_percent: 29.3632911392405\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04451355258961139\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.557548305671418\n",
      "    mean_inference_ms: 2.5053017108978968\n",
      "    mean_raw_obs_processing_ms: 1.7478658430684397\n",
      "  time_since_restore: 2096.9684834480286\n",
      "  time_this_iter_s: 55.265454053878784\n",
      "  time_total_s: 2096.9684834480286\n",
      "  timers:\n",
      "    learn_throughput: 1159.571\n",
      "    learn_time_ms: 1723.051\n",
      "    load_throughput: 60575.316\n",
      "    load_time_ms: 32.984\n",
      "    sample_throughput: 80.505\n",
      "    sample_time_ms: 24818.417\n",
      "    update_time_ms: 7.121\n",
      "  timestamp: 1636431611\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 155844\n",
      "  training_iteration: 78\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         2096.97</td><td style=\"text-align: right;\">155844</td><td style=\"text-align: right;\">  5.7437</td><td style=\"text-align: right;\">               10.16</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            112.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 157842\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-20-36\n",
      "  done: false\n",
      "  episode_len_mean: 110.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.160000000000021\n",
      "  episode_reward_mean: 5.72670000000002\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1452\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.76231594369525\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016832259765374013\n",
      "          policy_loss: -0.043876371599201644\n",
      "          total_loss: 0.3743671470099971\n",
      "          vf_explained_var: 0.8798216581344604\n",
      "          vf_loss: 0.42450490054630097\n",
      "    num_agent_steps_sampled: 157842\n",
      "    num_agent_steps_trained: 157842\n",
      "    num_steps_sampled: 157842\n",
      "    num_steps_trained: 157842\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.80833333333332\n",
      "    ram_util_percent: 29.199999999999996\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04448860814181006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.530744043730564\n",
      "    mean_inference_ms: 2.504400549229568\n",
      "    mean_raw_obs_processing_ms: 1.7930816410827368\n",
      "  time_since_restore: 2122.019744873047\n",
      "  time_this_iter_s: 25.05126142501831\n",
      "  time_total_s: 2122.019744873047\n",
      "  timers:\n",
      "    learn_throughput: 1157.969\n",
      "    learn_time_ms: 1725.435\n",
      "    load_throughput: 59555.149\n",
      "    load_time_ms: 33.549\n",
      "    sample_throughput: 80.056\n",
      "    sample_time_ms: 24957.467\n",
      "    update_time_ms: 7.812\n",
      "  timestamp: 1636431636\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 157842\n",
      "  training_iteration: 79\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         2122.02</td><td style=\"text-align: right;\">157842</td><td style=\"text-align: right;\">  5.7267</td><td style=\"text-align: right;\">               10.16</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            110.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 159840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-21-00\n",
      "  done: false\n",
      "  episode_len_mean: 110.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.160000000000021\n",
      "  episode_reward_mean: 5.669200000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1470\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7771896765345618\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011050993813192675\n",
      "          policy_loss: -0.06638943600867475\n",
      "          total_loss: 0.2971076707355678\n",
      "          vf_explained_var: 0.8742092847824097\n",
      "          vf_loss: 0.3738095837689581\n",
      "    num_agent_steps_sampled: 159840\n",
      "    num_agent_steps_trained: 159840\n",
      "    num_steps_sampled: 159840\n",
      "    num_steps_trained: 159840\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69117647058823\n",
      "    ram_util_percent: 29.673529411764704\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044485805071758734\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.503381184719128\n",
      "    mean_inference_ms: 2.5039211542414885\n",
      "    mean_raw_obs_processing_ms: 1.8375171471227454\n",
      "  time_since_restore: 2146.005624294281\n",
      "  time_this_iter_s: 23.98587942123413\n",
      "  time_total_s: 2146.005624294281\n",
      "  timers:\n",
      "    learn_throughput: 1157.687\n",
      "    learn_time_ms: 1725.856\n",
      "    load_throughput: 59686.854\n",
      "    load_time_ms: 33.475\n",
      "    sample_throughput: 79.59\n",
      "    sample_time_ms: 25103.603\n",
      "    update_time_ms: 8.862\n",
      "  timestamp: 1636431660\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 159840\n",
      "  training_iteration: 80\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2146.01</td><td style=\"text-align: right;\">159840</td><td style=\"text-align: right;\">  5.6692</td><td style=\"text-align: right;\">               10.16</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            110.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 161838\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-21-25\n",
      "  done: false\n",
      "  episode_len_mean: 107.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.080000000000014\n",
      "  episode_reward_mean: 5.5858000000000185\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1489\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8339229549680438\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009431450206601763\n",
      "          policy_loss: -0.07575519437946024\n",
      "          total_loss: 0.27123939231747674\n",
      "          vf_explained_var: 0.884414792060852\n",
      "          vf_loss: 0.35896758621647246\n",
      "    num_agent_steps_sampled: 161838\n",
      "    num_agent_steps_trained: 161838\n",
      "    num_steps_sampled: 161838\n",
      "    num_steps_trained: 161838\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.76756756756757\n",
      "    ram_util_percent: 30.002702702702706\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0444722617739377\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.49124439375441\n",
      "    mean_inference_ms: 2.503444230987554\n",
      "    mean_raw_obs_processing_ms: 1.8846634020500141\n",
      "  time_since_restore: 2171.4570372104645\n",
      "  time_this_iter_s: 25.45141291618347\n",
      "  time_total_s: 2171.4570372104645\n",
      "  timers:\n",
      "    learn_throughput: 1158.36\n",
      "    learn_time_ms: 1724.853\n",
      "    load_throughput: 59627.568\n",
      "    load_time_ms: 33.508\n",
      "    sample_throughput: 79.297\n",
      "    sample_time_ms: 25196.34\n",
      "    update_time_ms: 8.918\n",
      "  timestamp: 1636431685\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 161838\n",
      "  training_iteration: 81\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         2171.46</td><td style=\"text-align: right;\">161838</td><td style=\"text-align: right;\">  5.5858</td><td style=\"text-align: right;\">               10.08</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            107.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 163836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-21-49\n",
      "  done: false\n",
      "  episode_len_mean: 106.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.080000000000014\n",
      "  episode_reward_mean: 5.583100000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1507\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8141688290096465\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010941455899964508\n",
      "          policy_loss: -0.021816896008593694\n",
      "          total_loss: 0.2828358444518277\n",
      "          vf_explained_var: 0.8886467814445496\n",
      "          vf_loss: 0.31540894558032356\n",
      "    num_agent_steps_sampled: 163836\n",
      "    num_agent_steps_trained: 163836\n",
      "    num_steps_sampled: 163836\n",
      "    num_steps_trained: 163836\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.37058823529412\n",
      "    ram_util_percent: 30.202941176470585\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044445692245305694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.481202257479417\n",
      "    mean_inference_ms: 2.502546558415247\n",
      "    mean_raw_obs_processing_ms: 1.9294007055983635\n",
      "  time_since_restore: 2195.508911371231\n",
      "  time_this_iter_s: 24.0518741607666\n",
      "  time_total_s: 2195.508911371231\n",
      "  timers:\n",
      "    learn_throughput: 1159.684\n",
      "    learn_time_ms: 1722.883\n",
      "    load_throughput: 59489.999\n",
      "    load_time_ms: 33.585\n",
      "    sample_throughput: 78.87\n",
      "    sample_time_ms: 25332.795\n",
      "    update_time_ms: 8.975\n",
      "  timestamp: 1636431709\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 163836\n",
      "  training_iteration: 82\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         2195.51</td><td style=\"text-align: right;\">163836</td><td style=\"text-align: right;\">  5.5831</td><td style=\"text-align: right;\">               10.08</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             106.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 165834\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-22-12\n",
      "  done: false\n",
      "  episode_len_mean: 108.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.250000000000016\n",
      "  episode_reward_mean: 5.667900000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1524\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7876731089183262\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011638045805572973\n",
      "          policy_loss: -0.04608763637287276\n",
      "          total_loss: 0.3133229128750307\n",
      "          vf_explained_var: 0.8746377229690552\n",
      "          vf_loss: 0.36943159656865254\n",
      "    num_agent_steps_sampled: 165834\n",
      "    num_agent_steps_trained: 165834\n",
      "    num_steps_sampled: 165834\n",
      "    num_steps_trained: 165834\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.46249999999999\n",
      "    ram_util_percent: 30.28125\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04443956623740216\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.453730816394856\n",
      "    mean_inference_ms: 2.501886219905861\n",
      "    mean_raw_obs_processing_ms: 1.935155460926866\n",
      "  time_since_restore: 2218.032539844513\n",
      "  time_this_iter_s: 22.52362847328186\n",
      "  time_total_s: 2218.032539844513\n",
      "  timers:\n",
      "    learn_throughput: 1157.974\n",
      "    learn_time_ms: 1725.427\n",
      "    load_throughput: 59489.113\n",
      "    load_time_ms: 33.586\n",
      "    sample_throughput: 79.269\n",
      "    sample_time_ms: 25205.166\n",
      "    update_time_ms: 9.439\n",
      "  timestamp: 1636431732\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 165834\n",
      "  training_iteration: 83\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         2218.03</td><td style=\"text-align: right;\">165834</td><td style=\"text-align: right;\">  5.6679</td><td style=\"text-align: right;\">               10.25</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            108.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 167832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-22-35\n",
      "  done: false\n",
      "  episode_len_mean: 110.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.250000000000016\n",
      "  episode_reward_mean: 5.7283000000000195\n",
      "  episode_reward_min: 2.2500000000000204\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1543\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7229400089808873\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012435269757274575\n",
      "          policy_loss: -0.0392530134391217\n",
      "          total_loss: 0.3537826274388603\n",
      "          vf_explained_var: 0.8790363073348999\n",
      "          vf_loss: 0.4018712347462064\n",
      "    num_agent_steps_sampled: 167832\n",
      "    num_agent_steps_trained: 167832\n",
      "    num_steps_sampled: 167832\n",
      "    num_steps_trained: 167832\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16363636363636\n",
      "    ram_util_percent: 30.345454545454544\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044433223306680564\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.440034544004583\n",
      "    mean_inference_ms: 2.501509246847843\n",
      "    mean_raw_obs_processing_ms: 1.9191588436960756\n",
      "  time_since_restore: 2240.9777097702026\n",
      "  time_this_iter_s: 22.945169925689697\n",
      "  time_total_s: 2240.9777097702026\n",
      "  timers:\n",
      "    learn_throughput: 1158.755\n",
      "    learn_time_ms: 1724.264\n",
      "    load_throughput: 59179.039\n",
      "    load_time_ms: 33.762\n",
      "    sample_throughput: 79.458\n",
      "    sample_time_ms: 25145.474\n",
      "    update_time_ms: 10.132\n",
      "  timestamp: 1636431755\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 167832\n",
      "  training_iteration: 84\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         2240.98</td><td style=\"text-align: right;\">167832</td><td style=\"text-align: right;\">  5.7283</td><td style=\"text-align: right;\">               10.25</td><td style=\"text-align: right;\">                2.25</td><td style=\"text-align: right;\">            110.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 169830\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-22-58\n",
      "  done: false\n",
      "  episode_len_mean: 110.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.250000000000016\n",
      "  episode_reward_mean: 5.71720000000002\n",
      "  episode_reward_min: 1.8400000000000185\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1561\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8207836168152944\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012656994898510477\n",
      "          policy_loss: -0.012417852754394214\n",
      "          total_loss: 0.31548715606331823\n",
      "          vf_explained_var: 0.8949904441833496\n",
      "          vf_loss: 0.3375693725688117\n",
      "    num_agent_steps_sampled: 169830\n",
      "    num_agent_steps_trained: 169830\n",
      "    num_steps_sampled: 169830\n",
      "    num_steps_trained: 169830\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.42424242424242\n",
      "    ram_util_percent: 30.363636363636363\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04443296881044157\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.407609211005592\n",
      "    mean_inference_ms: 2.5010941569867042\n",
      "    mean_raw_obs_processing_ms: 1.904001097415441\n",
      "  time_since_restore: 2264.390828847885\n",
      "  time_this_iter_s: 23.413119077682495\n",
      "  time_total_s: 2264.390828847885\n",
      "  timers:\n",
      "    learn_throughput: 1159.077\n",
      "    learn_time_ms: 1723.785\n",
      "    load_throughput: 59205.713\n",
      "    load_time_ms: 33.747\n",
      "    sample_throughput: 79.29\n",
      "    sample_time_ms: 25198.497\n",
      "    update_time_ms: 10.094\n",
      "  timestamp: 1636431778\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 169830\n",
      "  training_iteration: 85\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         2264.39</td><td style=\"text-align: right;\">169830</td><td style=\"text-align: right;\">  5.7172</td><td style=\"text-align: right;\">               10.25</td><td style=\"text-align: right;\">                1.84</td><td style=\"text-align: right;\">            110.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 171828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-23-22\n",
      "  done: false\n",
      "  episode_len_mean: 111.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.250000000000016\n",
      "  episode_reward_mean: 5.73140000000002\n",
      "  episode_reward_min: 1.8400000000000185\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1579\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.790547373748961\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012573714175199063\n",
      "          policy_loss: -0.05332395927537055\n",
      "          total_loss: 0.3645513403717251\n",
      "          vf_explained_var: 0.8235441446304321\n",
      "          vf_loss: 0.42729351768891016\n",
      "    num_agent_steps_sampled: 171828\n",
      "    num_agent_steps_trained: 171828\n",
      "    num_steps_sampled: 171828\n",
      "    num_steps_trained: 171828\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99117647058824\n",
      "    ram_util_percent: 30.38823529411765\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044423716567618815\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.38133375368041\n",
      "    mean_inference_ms: 2.5004303627915485\n",
      "    mean_raw_obs_processing_ms: 1.8894506780693099\n",
      "  time_since_restore: 2287.736571073532\n",
      "  time_this_iter_s: 23.345742225646973\n",
      "  time_total_s: 2287.736571073532\n",
      "  timers:\n",
      "    learn_throughput: 1158.605\n",
      "    learn_time_ms: 1724.488\n",
      "    load_throughput: 58775.024\n",
      "    load_time_ms: 33.994\n",
      "    sample_throughput: 79.178\n",
      "    sample_time_ms: 25234.299\n",
      "    update_time_ms: 10.471\n",
      "  timestamp: 1636431802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 171828\n",
      "  training_iteration: 86\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         2287.74</td><td style=\"text-align: right;\">171828</td><td style=\"text-align: right;\">  5.7314</td><td style=\"text-align: right;\">               10.25</td><td style=\"text-align: right;\">                1.84</td><td style=\"text-align: right;\">            111.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 173826\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-23-45\n",
      "  done: false\n",
      "  episode_len_mean: 111.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.250000000000016\n",
      "  episode_reward_mean: 5.692600000000019\n",
      "  episode_reward_min: 1.8400000000000185\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1597\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.809579644884382\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010180890991772436\n",
      "          policy_loss: -0.05093351911221232\n",
      "          total_loss: 0.27228652675236975\n",
      "          vf_explained_var: 0.8795090317726135\n",
      "          vf_loss: 0.334443742391609\n",
      "    num_agent_steps_sampled: 173826\n",
      "    num_agent_steps_trained: 173826\n",
      "    num_steps_sampled: 173826\n",
      "    num_steps_trained: 173826\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69411764705882\n",
      "    ram_util_percent: 30.288235294117644\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0444301254346518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.354045120199807\n",
      "    mean_inference_ms: 2.5002101194177255\n",
      "    mean_raw_obs_processing_ms: 1.8748935665035829\n",
      "  time_since_restore: 2311.4013652801514\n",
      "  time_this_iter_s: 23.664794206619263\n",
      "  time_total_s: 2311.4013652801514\n",
      "  timers:\n",
      "    learn_throughput: 1158.7\n",
      "    learn_time_ms: 1724.346\n",
      "    load_throughput: 58632.29\n",
      "    load_time_ms: 34.077\n",
      "    sample_throughput: 79.314\n",
      "    sample_time_ms: 25191.166\n",
      "    update_time_ms: 11.053\n",
      "  timestamp: 1636431825\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 173826\n",
      "  training_iteration: 87\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">          2311.4</td><td style=\"text-align: right;\">173826</td><td style=\"text-align: right;\">  5.6926</td><td style=\"text-align: right;\">               10.25</td><td style=\"text-align: right;\">                1.84</td><td style=\"text-align: right;\">            111.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 175824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-24-09\n",
      "  done: false\n",
      "  episode_len_mean: 111.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.250000000000016\n",
      "  episode_reward_mean: 5.898100000000017\n",
      "  episode_reward_min: 1.8400000000000185\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1615\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6550624115126473\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0164534151201388\n",
      "          policy_loss: -0.041040054034619106\n",
      "          total_loss: 0.3958463570546536\n",
      "          vf_explained_var: 0.8585960865020752\n",
      "          vf_loss: 0.44233097760450274\n",
      "    num_agent_steps_sampled: 175824\n",
      "    num_agent_steps_trained: 175824\n",
      "    num_steps_sampled: 175824\n",
      "    num_steps_trained: 175824\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.23030303030303\n",
      "    ram_util_percent: 30.224242424242423\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04443869533510471\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.318396014801746\n",
      "    mean_inference_ms: 2.5000978513176677\n",
      "    mean_raw_obs_processing_ms: 1.8604584627485594\n",
      "  time_since_restore: 2335.069708108902\n",
      "  time_this_iter_s: 23.66834282875061\n",
      "  time_total_s: 2335.069708108902\n",
      "  timers:\n",
      "    learn_throughput: 1159.161\n",
      "    learn_time_ms: 1723.66\n",
      "    load_throughput: 58328.463\n",
      "    load_time_ms: 34.254\n",
      "    sample_throughput: 90.688\n",
      "    sample_time_ms: 22031.492\n",
      "    update_time_ms: 11.37\n",
      "  timestamp: 1636431849\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 175824\n",
      "  training_iteration: 88\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         2335.07</td><td style=\"text-align: right;\">175824</td><td style=\"text-align: right;\">  5.8981</td><td style=\"text-align: right;\">               10.25</td><td style=\"text-align: right;\">                1.84</td><td style=\"text-align: right;\">            111.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 177822\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-24-33\n",
      "  done: false\n",
      "  episode_len_mean: 109.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.090000000000016\n",
      "  episode_reward_mean: 5.977600000000019\n",
      "  episode_reward_min: 1.8400000000000185\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1633\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.618393365542094\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010625330954234086\n",
      "          policy_loss: -0.023578717027391706\n",
      "          total_loss: 0.3476364024338268\n",
      "          vf_explained_var: 0.8981428146362305\n",
      "          vf_loss: 0.3802269560595353\n",
      "    num_agent_steps_sampled: 177822\n",
      "    num_agent_steps_trained: 177822\n",
      "    num_steps_sampled: 177822\n",
      "    num_steps_trained: 177822\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.55428571428571\n",
      "    ram_util_percent: 30.234285714285708\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04443093699463903\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.305020191640132\n",
      "    mean_inference_ms: 2.499944626712402\n",
      "    mean_raw_obs_processing_ms: 1.8471751176442246\n",
      "  time_since_restore: 2359.146261692047\n",
      "  time_this_iter_s: 24.07655358314514\n",
      "  time_total_s: 2359.146261692047\n",
      "  timers:\n",
      "    learn_throughput: 1159.447\n",
      "    learn_time_ms: 1723.235\n",
      "    load_throughput: 58310.159\n",
      "    load_time_ms: 34.265\n",
      "    sample_throughput: 91.087\n",
      "    sample_time_ms: 21934.968\n",
      "    update_time_ms: 10.861\n",
      "  timestamp: 1636431873\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 177822\n",
      "  training_iteration: 89\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         2359.15</td><td style=\"text-align: right;\">177822</td><td style=\"text-align: right;\">  5.9776</td><td style=\"text-align: right;\">               10.09</td><td style=\"text-align: right;\">                1.84</td><td style=\"text-align: right;\">             109.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 179820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-24-57\n",
      "  done: false\n",
      "  episode_len_mean: 108.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.080000000000016\n",
      "  episode_reward_mean: 5.945200000000018\n",
      "  episode_reward_min: 1.8400000000000185\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1651\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.728463952314286\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011684818357698244\n",
      "          policy_loss: -0.0203794097616559\n",
      "          total_loss: 0.3776203070456783\n",
      "          vf_explained_var: 0.9000752568244934\n",
      "          vf_loss: 0.4073971002584412\n",
      "    num_agent_steps_sampled: 179820\n",
      "    num_agent_steps_trained: 179820\n",
      "    num_steps_sampled: 179820\n",
      "    num_steps_trained: 179820\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.42647058823529\n",
      "    ram_util_percent: 30.13235294117647\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04443772717973334\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.279006517317804\n",
      "    mean_inference_ms: 2.499960657912092\n",
      "    mean_raw_obs_processing_ms: 1.8336345704093282\n",
      "  time_since_restore: 2383.2205464839935\n",
      "  time_this_iter_s: 24.07428479194641\n",
      "  time_total_s: 2383.2205464839935\n",
      "  timers:\n",
      "    learn_throughput: 1162.47\n",
      "    learn_time_ms: 1718.753\n",
      "    load_throughput: 59349.071\n",
      "    load_time_ms: 33.665\n",
      "    sample_throughput: 91.029\n",
      "    sample_time_ms: 21948.995\n",
      "    update_time_ms: 10.448\n",
      "  timestamp: 1636431897\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 179820\n",
      "  training_iteration: 90\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         2383.22</td><td style=\"text-align: right;\">179820</td><td style=\"text-align: right;\">  5.9452</td><td style=\"text-align: right;\">               10.08</td><td style=\"text-align: right;\">                1.84</td><td style=\"text-align: right;\">            108.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 181818\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-25-21\n",
      "  done: false\n",
      "  episode_len_mean: 109.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.080000000000016\n",
      "  episode_reward_mean: 6.012500000000021\n",
      "  episode_reward_min: 2.460000000000017\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1669\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8342530948775155\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01351302294025476\n",
      "          policy_loss: -0.023620128667070753\n",
      "          total_loss: 0.2805711099523164\n",
      "          vf_explained_var: 0.8958092927932739\n",
      "          vf_loss: 0.31341247860164867\n",
      "    num_agent_steps_sampled: 181818\n",
      "    num_agent_steps_trained: 181818\n",
      "    num_steps_sampled: 181818\n",
      "    num_steps_trained: 181818\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.50606060606061\n",
      "    ram_util_percent: 30.12727272727273\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04442782953818572\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.26018417049824\n",
      "    mean_inference_ms: 2.4999396527792546\n",
      "    mean_raw_obs_processing_ms: 1.820665097678934\n",
      "  time_since_restore: 2406.471427679062\n",
      "  time_this_iter_s: 23.25088119506836\n",
      "  time_total_s: 2406.471427679062\n",
      "  timers:\n",
      "    learn_throughput: 1162.437\n",
      "    learn_time_ms: 1718.802\n",
      "    load_throughput: 59296.746\n",
      "    load_time_ms: 33.695\n",
      "    sample_throughput: 91.952\n",
      "    sample_time_ms: 21728.83\n",
      "    update_time_ms: 10.323\n",
      "  timestamp: 1636431921\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 181818\n",
      "  training_iteration: 91\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         2406.47</td><td style=\"text-align: right;\">181818</td><td style=\"text-align: right;\">  6.0125</td><td style=\"text-align: right;\">               10.08</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            109.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 183816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-25-45\n",
      "  done: false\n",
      "  episode_len_mean: 108.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.610000000000014\n",
      "  episode_reward_mean: 6.182900000000019\n",
      "  episode_reward_min: 2.460000000000017\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1688\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7722322015535263\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009297168857482876\n",
      "          policy_loss: -0.04463445186792385\n",
      "          total_loss: 0.23927153745400054\n",
      "          vf_explained_var: 0.9158617258071899\n",
      "          vf_loss: 0.29535272014992575\n",
      "    num_agent_steps_sampled: 183816\n",
      "    num_agent_steps_trained: 183816\n",
      "    num_steps_sampled: 183816\n",
      "    num_steps_trained: 183816\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.51111111111112\n",
      "    ram_util_percent: 30.158333333333328\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04441552891181637\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.25154377156894\n",
      "    mean_inference_ms: 2.4997760670365268\n",
      "    mean_raw_obs_processing_ms: 1.8076582577361853\n",
      "  time_since_restore: 2431.2630944252014\n",
      "  time_this_iter_s: 24.791666746139526\n",
      "  time_total_s: 2431.2630944252014\n",
      "  timers:\n",
      "    learn_throughput: 1161.592\n",
      "    learn_time_ms: 1720.054\n",
      "    load_throughput: 60028.118\n",
      "    load_time_ms: 33.284\n",
      "    sample_throughput: 91.645\n",
      "    sample_time_ms: 21801.427\n",
      "    update_time_ms: 10.825\n",
      "  timestamp: 1636431945\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 183816\n",
      "  training_iteration: 92\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         2431.26</td><td style=\"text-align: right;\">183816</td><td style=\"text-align: right;\">  6.1829</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            108.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 185814\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-26-11\n",
      "  done: false\n",
      "  episode_len_mean: 107.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.610000000000014\n",
      "  episode_reward_mean: 6.197600000000018\n",
      "  episode_reward_min: 2.780000000000019\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1708\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7738579846563793\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011221774417160458\n",
      "          policy_loss: -0.012827613843338831\n",
      "          total_loss: 0.29954378788936\n",
      "          vf_explained_var: 0.9023517370223999\n",
      "          vf_loss: 0.32253528322492325\n",
      "    num_agent_steps_sampled: 185814\n",
      "    num_agent_steps_trained: 185814\n",
      "    num_steps_sampled: 185814\n",
      "    num_steps_trained: 185814\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92499999999998\n",
      "    ram_util_percent: 30.194444444444443\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04443235930607102\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.24163743962847\n",
      "    mean_inference_ms: 2.4999471823616615\n",
      "    mean_raw_obs_processing_ms: 1.7943088185480094\n",
      "  time_since_restore: 2456.7279484272003\n",
      "  time_this_iter_s: 25.4648540019989\n",
      "  time_total_s: 2456.7279484272003\n",
      "  timers:\n",
      "    learn_throughput: 1162.122\n",
      "    learn_time_ms: 1719.269\n",
      "    load_throughput: 59724.884\n",
      "    load_time_ms: 33.453\n",
      "    sample_throughput: 90.423\n",
      "    sample_time_ms: 22096.08\n",
      "    update_time_ms: 10.931\n",
      "  timestamp: 1636431971\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 185814\n",
      "  training_iteration: 93\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         2456.73</td><td style=\"text-align: right;\">185814</td><td style=\"text-align: right;\">  6.1976</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">            107.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 187812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-26-36\n",
      "  done: false\n",
      "  episode_len_mean: 106.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.610000000000014\n",
      "  episode_reward_mean: 5.856700000000019\n",
      "  episode_reward_min: 2.3700000000000117\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1727\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9239513851347423\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007954350058284541\n",
      "          policy_loss: -0.05904413124635106\n",
      "          total_loss: 0.10086116284309399\n",
      "          vf_explained_var: 0.9403129816055298\n",
      "          vf_loss: 0.17377562036826497\n",
      "    num_agent_steps_sampled: 187812\n",
      "    num_agent_steps_trained: 187812\n",
      "    num_steps_sampled: 187812\n",
      "    num_steps_trained: 187812\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.48611111111113\n",
      "    ram_util_percent: 30.047222222222217\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04444975619947927\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.234931315365625\n",
      "    mean_inference_ms: 2.499925309733028\n",
      "    mean_raw_obs_processing_ms: 1.7821234797558785\n",
      "  time_since_restore: 2481.787768602371\n",
      "  time_this_iter_s: 25.0598201751709\n",
      "  time_total_s: 2481.787768602371\n",
      "  timers:\n",
      "    learn_throughput: 1162.091\n",
      "    learn_time_ms: 1719.315\n",
      "    load_throughput: 60001.256\n",
      "    load_time_ms: 33.299\n",
      "    sample_throughput: 89.563\n",
      "    sample_time_ms: 22308.326\n",
      "    update_time_ms: 10.026\n",
      "  timestamp: 1636431996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 187812\n",
      "  training_iteration: 94\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         2481.79</td><td style=\"text-align: right;\">187812</td><td style=\"text-align: right;\">  5.8567</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">                2.37</td><td style=\"text-align: right;\">            106.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 189810\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-27-01\n",
      "  done: false\n",
      "  episode_len_mean: 106.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.610000000000014\n",
      "  episode_reward_mean: 5.783400000000018\n",
      "  episode_reward_min: 2.32000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1746\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.8037513182276772\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012631335315922953\n",
      "          policy_loss: -0.03671515140505064\n",
      "          total_loss: 0.3294037643642653\n",
      "          vf_explained_var: 0.8837664723396301\n",
      "          vf_loss: 0.37563027633087975\n",
      "    num_agent_steps_sampled: 189810\n",
      "    num_agent_steps_trained: 189810\n",
      "    num_steps_sampled: 189810\n",
      "    num_steps_trained: 189810\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97428571428573\n",
      "    ram_util_percent: 30.071428571428573\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044460708944263135\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.227389915326167\n",
      "    mean_inference_ms: 2.4997624479321425\n",
      "    mean_raw_obs_processing_ms: 1.7703441605337804\n",
      "  time_since_restore: 2506.531119823456\n",
      "  time_this_iter_s: 24.743351221084595\n",
      "  time_total_s: 2506.531119823456\n",
      "  timers:\n",
      "    learn_throughput: 1158.088\n",
      "    learn_time_ms: 1725.257\n",
      "    load_throughput: 60789.925\n",
      "    load_time_ms: 32.867\n",
      "    sample_throughput: 89.053\n",
      "    sample_time_ms: 22436.004\n",
      "    update_time_ms: 10.038\n",
      "  timestamp: 1636432021\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 189810\n",
      "  training_iteration: 95\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         2506.53</td><td style=\"text-align: right;\">189810</td><td style=\"text-align: right;\">  5.7834</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">                2.32</td><td style=\"text-align: right;\">            106.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 191808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-27-27\n",
      "  done: false\n",
      "  episode_len_mean: 105.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.610000000000014\n",
      "  episode_reward_mean: 5.803300000000018\n",
      "  episode_reward_min: 2.32000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1764\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7013385659172422\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011701392153994931\n",
      "          policy_loss: -0.04947678102623849\n",
      "          total_loss: 0.3203045438886398\n",
      "          vf_explained_var: 0.8659259676933289\n",
      "          vf_loss: 0.3788962714019276\n",
      "    num_agent_steps_sampled: 191808\n",
      "    num_agent_steps_trained: 191808\n",
      "    num_steps_sampled: 191808\n",
      "    num_steps_trained: 191808\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.95135135135135\n",
      "    ram_util_percent: 30.04864864864864\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04447219600800129\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.228482357581225\n",
      "    mean_inference_ms: 2.4996049658731407\n",
      "    mean_raw_obs_processing_ms: 1.7595036187619575\n",
      "  time_since_restore: 2532.3790214061737\n",
      "  time_this_iter_s: 25.847901582717896\n",
      "  time_total_s: 2532.3790214061737\n",
      "  timers:\n",
      "    learn_throughput: 1160.238\n",
      "    learn_time_ms: 1722.06\n",
      "    load_throughput: 60958.577\n",
      "    load_time_ms: 32.776\n",
      "    sample_throughput: 88.058\n",
      "    sample_time_ms: 22689.641\n",
      "    update_time_ms: 9.983\n",
      "  timestamp: 1636432047\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 191808\n",
      "  training_iteration: 96\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         2532.38</td><td style=\"text-align: right;\">191808</td><td style=\"text-align: right;\">  5.8033</td><td style=\"text-align: right;\">               10.61</td><td style=\"text-align: right;\">                2.32</td><td style=\"text-align: right;\">             105.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 193806\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-28-22\n",
      "  done: false\n",
      "  episode_len_mean: 103.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000015\n",
      "  episode_reward_mean: 5.587500000000016\n",
      "  episode_reward_min: 1.94\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1784\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6817511496089754\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011838777440010504\n",
      "          policy_loss: -0.02391521182088625\n",
      "          total_loss: 0.3553296384002481\n",
      "          vf_explained_var: 0.8725080490112305\n",
      "          vf_loss: 0.38807118229922793\n",
      "    num_agent_steps_sampled: 193806\n",
      "    num_agent_steps_trained: 193806\n",
      "    num_steps_sampled: 193806\n",
      "    num_steps_trained: 193806\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.61265822784812\n",
      "    ram_util_percent: 29.906329113924066\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044507984833515514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.219717619940994\n",
      "    mean_inference_ms: 2.4996699851859834\n",
      "    mean_raw_obs_processing_ms: 1.7869892078930365\n",
      "  time_since_restore: 2587.492804288864\n",
      "  time_this_iter_s: 55.11378288269043\n",
      "  time_total_s: 2587.492804288864\n",
      "  timers:\n",
      "    learn_throughput: 1160.47\n",
      "    learn_time_ms: 1721.716\n",
      "    load_throughput: 61325.753\n",
      "    load_time_ms: 32.58\n",
      "    sample_throughput: 77.336\n",
      "    sample_time_ms: 25835.263\n",
      "    update_time_ms: 9.972\n",
      "  timestamp: 1636432102\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 193806\n",
      "  training_iteration: 97\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         2587.49</td><td style=\"text-align: right;\">193806</td><td style=\"text-align: right;\">  5.5875</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">                1.94</td><td style=\"text-align: right;\">            103.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 195804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-29-03\n",
      "  done: false\n",
      "  episode_len_mean: 102.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000015\n",
      "  episode_reward_mean: 5.584400000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 1805\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7376719491822379\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011118168041367447\n",
      "          policy_loss: -0.021664789886701674\n",
      "          total_loss: 0.3499283471455177\n",
      "          vf_explained_var: 0.8765549659729004\n",
      "          vf_loss: 0.3814650948558535\n",
      "    num_agent_steps_sampled: 195804\n",
      "    num_agent_steps_trained: 195804\n",
      "    num_steps_sampled: 195804\n",
      "    num_steps_trained: 195804\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.80677966101698\n",
      "    ram_util_percent: 29.87118644067796\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0445046048636865\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.207255876223943\n",
      "    mean_inference_ms: 2.499175805195826\n",
      "    mean_raw_obs_processing_ms: 1.829583055680648\n",
      "  time_since_restore: 2628.7055943012238\n",
      "  time_this_iter_s: 41.21279001235962\n",
      "  time_total_s: 2628.7055943012238\n",
      "  timers:\n",
      "    learn_throughput: 1160.365\n",
      "    learn_time_ms: 1721.871\n",
      "    load_throughput: 61585.66\n",
      "    load_time_ms: 32.443\n",
      "    sample_throughput: 72.419\n",
      "    sample_time_ms: 27589.283\n",
      "    update_time_ms: 10.588\n",
      "  timestamp: 1636432143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 195804\n",
      "  training_iteration: 98\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         2628.71</td><td style=\"text-align: right;\">195804</td><td style=\"text-align: right;\">  5.5844</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            102.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 197802\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-29-27\n",
      "  done: false\n",
      "  episode_len_mean: 102.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000015\n",
      "  episode_reward_mean: 5.677600000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1824\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7940905792372568\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010194597062131694\n",
      "          policy_loss: -0.04609637590391295\n",
      "          total_loss: 0.17223639070455518\n",
      "          vf_explained_var: 0.9272928833961487\n",
      "          vf_loss: 0.22939231927905765\n",
      "    num_agent_steps_sampled: 197802\n",
      "    num_agent_steps_trained: 197802\n",
      "    num_steps_sampled: 197802\n",
      "    num_steps_trained: 197802\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.27941176470588\n",
      "    ram_util_percent: 30.197058823529414\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04447604037682542\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.207798780906323\n",
      "    mean_inference_ms: 2.498412332960084\n",
      "    mean_raw_obs_processing_ms: 1.8682171977877309\n",
      "  time_since_restore: 2652.5833175182343\n",
      "  time_this_iter_s: 23.877723217010498\n",
      "  time_total_s: 2652.5833175182343\n",
      "  timers:\n",
      "    learn_throughput: 1161.054\n",
      "    learn_time_ms: 1720.85\n",
      "    load_throughput: 61328.805\n",
      "    load_time_ms: 32.578\n",
      "    sample_throughput: 72.47\n",
      "    sample_time_ms: 27570.094\n",
      "    update_time_ms: 10.384\n",
      "  timestamp: 1636432167\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 197802\n",
      "  training_iteration: 99\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         2652.58</td><td style=\"text-align: right;\">197802</td><td style=\"text-align: right;\">  5.6776</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            102.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 199800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-29-50\n",
      "  done: false\n",
      "  episode_len_mean: 103.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000015\n",
      "  episode_reward_mean: 5.663300000000017\n",
      "  episode_reward_min: -0.3199999999999992\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1842\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7253523701713198\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016400816417014116\n",
      "          policy_loss: -0.07047839359868141\n",
      "          total_loss: 0.316181759784619\n",
      "          vf_explained_var: 0.8961905241012573\n",
      "          vf_loss: 0.3928431253348078\n",
      "    num_agent_steps_sampled: 199800\n",
      "    num_agent_steps_trained: 199800\n",
      "    num_steps_sampled: 199800\n",
      "    num_steps_trained: 199800\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.78787878787878\n",
      "    ram_util_percent: 30.227272727272727\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04446992964158543\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.197254295598267\n",
      "    mean_inference_ms: 2.497901111756022\n",
      "    mean_raw_obs_processing_ms: 1.9042204374077139\n",
      "  time_since_restore: 2675.947850704193\n",
      "  time_this_iter_s: 23.364533185958862\n",
      "  time_total_s: 2675.947850704193\n",
      "  timers:\n",
      "    learn_throughput: 1160.334\n",
      "    learn_time_ms: 1721.919\n",
      "    load_throughput: 60151.087\n",
      "    load_time_ms: 33.216\n",
      "    sample_throughput: 72.66\n",
      "    sample_time_ms: 27497.856\n",
      "    update_time_ms: 9.925\n",
      "  timestamp: 1636432190\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 199800\n",
      "  training_iteration: 100\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         2675.95</td><td style=\"text-align: right;\">199800</td><td style=\"text-align: right;\">  5.6633</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">               -0.32</td><td style=\"text-align: right;\">            103.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 201798\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-30-14\n",
      "  done: false\n",
      "  episode_len_mean: 104.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.290000000000019\n",
      "  episode_reward_mean: 5.619200000000018\n",
      "  episode_reward_min: -0.3199999999999992\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1860\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7430792626880465\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01297571193250926\n",
      "          policy_loss: -0.023005290489111627\n",
      "          total_loss: 0.35065120698085855\n",
      "          vf_explained_var: 0.8785028457641602\n",
      "          vf_loss: 0.38232868689866295\n",
      "    num_agent_steps_sampled: 201798\n",
      "    num_agent_steps_trained: 201798\n",
      "    num_steps_sampled: 201798\n",
      "    num_steps_trained: 201798\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.12352941176471\n",
      "    ram_util_percent: 30.235294117647058\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044460717445291405\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.180699900081954\n",
      "    mean_inference_ms: 2.4973089820424144\n",
      "    mean_raw_obs_processing_ms: 1.939807380354183\n",
      "  time_since_restore: 2699.5276186466217\n",
      "  time_this_iter_s: 23.57976794242859\n",
      "  time_total_s: 2699.5276186466217\n",
      "  timers:\n",
      "    learn_throughput: 1159.558\n",
      "    learn_time_ms: 1723.07\n",
      "    load_throughput: 60208.781\n",
      "    load_time_ms: 33.185\n",
      "    sample_throughput: 72.576\n",
      "    sample_time_ms: 27529.819\n",
      "    update_time_ms: 10.059\n",
      "  timestamp: 1636432214\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 201798\n",
      "  training_iteration: 101\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         2699.53</td><td style=\"text-align: right;\">201798</td><td style=\"text-align: right;\">  5.6192</td><td style=\"text-align: right;\">               10.29</td><td style=\"text-align: right;\">               -0.32</td><td style=\"text-align: right;\">            104.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 203796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-30-36\n",
      "  done: false\n",
      "  episode_len_mean: 106.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.290000000000019\n",
      "  episode_reward_mean: 5.732700000000017\n",
      "  episode_reward_min: -0.3199999999999992\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1877\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.728829170408703\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011156885568682154\n",
      "          policy_loss: -0.0391074966107096\n",
      "          total_loss: 0.27326100822538135\n",
      "          vf_explained_var: 0.8933712840080261\n",
      "          vf_loss: 0.3221258989402226\n",
      "    num_agent_steps_sampled: 203796\n",
      "    num_agent_steps_trained: 203796\n",
      "    num_steps_sampled: 203796\n",
      "    num_steps_trained: 203796\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8225806451613\n",
      "    ram_util_percent: 30.238709677419358\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04440275357146124\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.173850813894536\n",
      "    mean_inference_ms: 2.4961286120229893\n",
      "    mean_raw_obs_processing_ms: 1.9525539432126187\n",
      "  time_since_restore: 2721.5414090156555\n",
      "  time_this_iter_s: 22.013790369033813\n",
      "  time_total_s: 2721.5414090156555\n",
      "  timers:\n",
      "    learn_throughput: 1159.24\n",
      "    learn_time_ms: 1723.544\n",
      "    load_throughput: 56433.062\n",
      "    load_time_ms: 35.405\n",
      "    sample_throughput: 73.32\n",
      "    sample_time_ms: 27250.287\n",
      "    update_time_ms: 9.142\n",
      "  timestamp: 1636432236\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 203796\n",
      "  training_iteration: 102\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         2721.54</td><td style=\"text-align: right;\">203796</td><td style=\"text-align: right;\">  5.7327</td><td style=\"text-align: right;\">               10.29</td><td style=\"text-align: right;\">               -0.32</td><td style=\"text-align: right;\">            106.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 205794\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-30-58\n",
      "  done: false\n",
      "  episode_len_mean: 110.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.910000000000018\n",
      "  episode_reward_mean: 5.74580000000002\n",
      "  episode_reward_min: -0.3199999999999992\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 1894\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7630434121404375\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013453700226606044\n",
      "          policy_loss: 0.004165806727749961\n",
      "          total_loss: 0.4004770782022249\n",
      "          vf_explained_var: 0.8434374332427979\n",
      "          vf_loss: 0.4048604586294719\n",
      "    num_agent_steps_sampled: 205794\n",
      "    num_agent_steps_trained: 205794\n",
      "    num_steps_sampled: 205794\n",
      "    num_steps_trained: 205794\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.97096774193548\n",
      "    ram_util_percent: 30.296774193548387\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04440679261577673\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.127189826533076\n",
      "    mean_inference_ms: 2.495825694548801\n",
      "    mean_raw_obs_processing_ms: 1.9400612391440257\n",
      "  time_since_restore: 2743.014368534088\n",
      "  time_this_iter_s: 21.472959518432617\n",
      "  time_total_s: 2743.014368534088\n",
      "  timers:\n",
      "    learn_throughput: 1158.957\n",
      "    learn_time_ms: 1723.964\n",
      "    load_throughput: 56902.387\n",
      "    load_time_ms: 35.113\n",
      "    sample_throughput: 74.408\n",
      "    sample_time_ms: 26851.917\n",
      "    update_time_ms: 8.445\n",
      "  timestamp: 1636432258\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 205794\n",
      "  training_iteration: 103\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         2743.01</td><td style=\"text-align: right;\">205794</td><td style=\"text-align: right;\">  5.7458</td><td style=\"text-align: right;\">                9.91</td><td style=\"text-align: right;\">               -0.32</td><td style=\"text-align: right;\">            110.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 207792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-31-21\n",
      "  done: false\n",
      "  episode_len_mean: 112.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.910000000000018\n",
      "  episode_reward_mean: 5.577400000000017\n",
      "  episode_reward_min: -0.3199999999999992\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1912\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7882861898058937\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011407056415554888\n",
      "          policy_loss: -0.062009920108885994\n",
      "          total_loss: 0.2823925139027692\n",
      "          vf_explained_var: 0.8782331347465515\n",
      "          vf_loss: 0.3545855290478184\n",
      "    num_agent_steps_sampled: 207792\n",
      "    num_agent_steps_trained: 207792\n",
      "    num_steps_sampled: 207792\n",
      "    num_steps_trained: 207792\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79090909090908\n",
      "    ram_util_percent: 30.25151515151515\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044416363733758804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.094666290932505\n",
      "    mean_inference_ms: 2.495579204555599\n",
      "    mean_raw_obs_processing_ms: 1.9269990147608747\n",
      "  time_since_restore: 2766.1458082199097\n",
      "  time_this_iter_s: 23.131439685821533\n",
      "  time_total_s: 2766.1458082199097\n",
      "  timers:\n",
      "    learn_throughput: 1158.398\n",
      "    learn_time_ms: 1724.795\n",
      "    load_throughput: 56790.675\n",
      "    load_time_ms: 35.182\n",
      "    sample_throughput: 74.95\n",
      "    sample_time_ms: 26657.672\n",
      "    update_time_ms: 8.903\n",
      "  timestamp: 1636432281\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 207792\n",
      "  training_iteration: 104\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         2766.15</td><td style=\"text-align: right;\">207792</td><td style=\"text-align: right;\">  5.5774</td><td style=\"text-align: right;\">                9.91</td><td style=\"text-align: right;\">               -0.32</td><td style=\"text-align: right;\">            112.23</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 209790\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-31-43\n",
      "  done: false\n",
      "  episode_len_mean: 113.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.030000000000028\n",
      "  episode_reward_mean: 5.714800000000017\n",
      "  episode_reward_min: -0.3199999999999992\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 1928\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6521770982515245\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012731875693231741\n",
      "          policy_loss: -0.001122830550940264\n",
      "          total_loss: 0.34422592981940225\n",
      "          vf_explained_var: 0.8875991106033325\n",
      "          vf_loss: 0.35327651500701907\n",
      "    num_agent_steps_sampled: 209790\n",
      "    num_agent_steps_trained: 209790\n",
      "    num_steps_sampled: 209790\n",
      "    num_steps_trained: 209790\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.646875\n",
      "    ram_util_percent: 30.21875\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04446217238241526\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.048787664562514\n",
      "    mean_inference_ms: 2.4958677834009517\n",
      "    mean_raw_obs_processing_ms: 1.914770077267497\n",
      "  time_since_restore: 2788.121433019638\n",
      "  time_this_iter_s: 21.975624799728394\n",
      "  time_total_s: 2788.121433019638\n",
      "  timers:\n",
      "    learn_throughput: 1163.298\n",
      "    learn_time_ms: 1717.53\n",
      "    load_throughput: 56148.874\n",
      "    load_time_ms: 35.584\n",
      "    sample_throughput: 75.717\n",
      "    sample_time_ms: 26387.674\n",
      "    update_time_ms: 8.817\n",
      "  timestamp: 1636432303\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 209790\n",
      "  training_iteration: 105\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         2788.12</td><td style=\"text-align: right;\">209790</td><td style=\"text-align: right;\">  5.7148</td><td style=\"text-align: right;\">               10.03</td><td style=\"text-align: right;\">               -0.32</td><td style=\"text-align: right;\">            113.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 211788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-32-07\n",
      "  done: false\n",
      "  episode_len_mean: 112.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.030000000000028\n",
      "  episode_reward_mean: 5.781800000000019\n",
      "  episode_reward_min: 1.2900000000000122\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 1948\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.692890629314241\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012378045697009647\n",
      "          policy_loss: -0.07928474176497687\n",
      "          total_loss: 0.20809661308746963\n",
      "          vf_explained_var: 0.8827019333839417\n",
      "          vf_loss: 0.2959550834127835\n",
      "    num_agent_steps_sampled: 211788\n",
      "    num_agent_steps_trained: 211788\n",
      "    num_steps_sampled: 211788\n",
      "    num_steps_trained: 211788\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16000000000001\n",
      "    ram_util_percent: 30.197142857142854\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04445161041683869\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.018004344269926\n",
      "    mean_inference_ms: 2.4953167905856635\n",
      "    mean_raw_obs_processing_ms: 1.9009206098166618\n",
      "  time_since_restore: 2812.6157052516937\n",
      "  time_this_iter_s: 24.494272232055664\n",
      "  time_total_s: 2812.6157052516937\n",
      "  timers:\n",
      "    learn_throughput: 1161.651\n",
      "    learn_time_ms: 1719.965\n",
      "    load_throughput: 56089.759\n",
      "    load_time_ms: 35.621\n",
      "    sample_throughput: 76.115\n",
      "    sample_time_ms: 26249.758\n",
      "    update_time_ms: 8.546\n",
      "  timestamp: 1636432327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 211788\n",
      "  training_iteration: 106\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         2812.62</td><td style=\"text-align: right;\">211788</td><td style=\"text-align: right;\">  5.7818</td><td style=\"text-align: right;\">               10.03</td><td style=\"text-align: right;\">                1.29</td><td style=\"text-align: right;\">            112.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 213786\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-32-31\n",
      "  done: false\n",
      "  episode_len_mean: 112.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.030000000000028\n",
      "  episode_reward_mean: 5.760900000000017\n",
      "  episode_reward_min: 1.0200000000000014\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 1966\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7568746555419195\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012606849456146105\n",
      "          policy_loss: -0.02122814515605569\n",
      "          total_loss: 0.39433583372405595\n",
      "          vf_explained_var: 0.8603055477142334\n",
      "          vf_loss: 0.42462310379459745\n",
      "    num_agent_steps_sampled: 213786\n",
      "    num_agent_steps_trained: 213786\n",
      "    num_steps_sampled: 213786\n",
      "    num_steps_trained: 213786\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.17058823529413\n",
      "    ram_util_percent: 30.185294117647064\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04445965829675081\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.987579971243793\n",
      "    mean_inference_ms: 2.495020409463497\n",
      "    mean_raw_obs_processing_ms: 1.8885102489383496\n",
      "  time_since_restore: 2836.46831202507\n",
      "  time_this_iter_s: 23.852606773376465\n",
      "  time_total_s: 2836.46831202507\n",
      "  timers:\n",
      "    learn_throughput: 1159.823\n",
      "    learn_time_ms: 1722.676\n",
      "    load_throughput: 55799.013\n",
      "    load_time_ms: 35.807\n",
      "    sample_throughput: 86.415\n",
      "    sample_time_ms: 23121.056\n",
      "    update_time_ms: 8.013\n",
      "  timestamp: 1636432351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 213786\n",
      "  training_iteration: 107\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         2836.47</td><td style=\"text-align: right;\">213786</td><td style=\"text-align: right;\">  5.7609</td><td style=\"text-align: right;\">               10.03</td><td style=\"text-align: right;\">                1.02</td><td style=\"text-align: right;\">            112.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 215784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-32-54\n",
      "  done: false\n",
      "  episode_len_mean: 110.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.240000000000018\n",
      "  episode_reward_mean: 5.832500000000019\n",
      "  episode_reward_min: 1.0200000000000014\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 1985\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7014189572561356\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012400831499261475\n",
      "          policy_loss: 0.001818045565769786\n",
      "          total_loss: 0.38311933176148505\n",
      "          vf_explained_var: 0.8984407782554626\n",
      "          vf_loss: 0.38994491483483995\n",
      "    num_agent_steps_sampled: 215784\n",
      "    num_agent_steps_trained: 215784\n",
      "    num_steps_sampled: 215784\n",
      "    num_steps_trained: 215784\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9125\n",
      "    ram_util_percent: 30.121875000000003\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044477937891806825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.961371236815836\n",
      "    mean_inference_ms: 2.4949065535564596\n",
      "    mean_raw_obs_processing_ms: 1.8760393266386257\n",
      "  time_since_restore: 2859.389333486557\n",
      "  time_this_iter_s: 22.921021461486816\n",
      "  time_total_s: 2859.389333486557\n",
      "  timers:\n",
      "    learn_throughput: 1159.542\n",
      "    learn_time_ms: 1723.093\n",
      "    load_throughput: 55544.748\n",
      "    load_time_ms: 35.971\n",
      "    sample_throughput: 93.842\n",
      "    sample_time_ms: 21291.118\n",
      "    update_time_ms: 8.131\n",
      "  timestamp: 1636432374\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 215784\n",
      "  training_iteration: 108\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         2859.39</td><td style=\"text-align: right;\">215784</td><td style=\"text-align: right;\">  5.8325</td><td style=\"text-align: right;\">               10.24</td><td style=\"text-align: right;\">                1.02</td><td style=\"text-align: right;\">            110.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 217782\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-33-17\n",
      "  done: false\n",
      "  episode_len_mean: 111.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.240000000000018\n",
      "  episode_reward_mean: 5.90920000000002\n",
      "  episode_reward_min: 1.0200000000000014\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2002\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6444898718879337\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011629702538667302\n",
      "          policy_loss: -0.03275430104917004\n",
      "          total_loss: 0.2729147124281597\n",
      "          vf_explained_var: 0.908051073551178\n",
      "          vf_loss: 0.3142638614489919\n",
      "    num_agent_steps_sampled: 217782\n",
      "    num_agent_steps_trained: 217782\n",
      "    num_steps_sampled: 217782\n",
      "    num_steps_trained: 217782\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9625\n",
      "    ram_util_percent: 30.137500000000003\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044474223443600615\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.945646585143706\n",
      "    mean_inference_ms: 2.494503439328444\n",
      "    mean_raw_obs_processing_ms: 1.8653884868209594\n",
      "  time_since_restore: 2881.82248711586\n",
      "  time_this_iter_s: 22.43315362930298\n",
      "  time_total_s: 2881.82248711586\n",
      "  timers:\n",
      "    learn_throughput: 1159.588\n",
      "    learn_time_ms: 1723.025\n",
      "    load_throughput: 55581.477\n",
      "    load_time_ms: 35.947\n",
      "    sample_throughput: 94.481\n",
      "    sample_time_ms: 21147.214\n",
      "    update_time_ms: 7.976\n",
      "  timestamp: 1636432397\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 217782\n",
      "  training_iteration: 109\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         2881.82</td><td style=\"text-align: right;\">217782</td><td style=\"text-align: right;\">  5.9092</td><td style=\"text-align: right;\">               10.24</td><td style=\"text-align: right;\">                1.02</td><td style=\"text-align: right;\">            111.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 219780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-33-40\n",
      "  done: false\n",
      "  episode_len_mean: 111.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.240000000000018\n",
      "  episode_reward_mean: 6.012400000000019\n",
      "  episode_reward_min: 1.0200000000000014\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2019\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7291771372159321\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01106114201029498\n",
      "          policy_loss: -0.031507366469928196\n",
      "          total_loss: 0.31450757966155096\n",
      "          vf_explained_var: 0.8851600885391235\n",
      "          vf_loss: 0.3558404469064304\n",
      "    num_agent_steps_sampled: 219780\n",
      "    num_agent_steps_trained: 219780\n",
      "    num_steps_sampled: 219780\n",
      "    num_steps_trained: 219780\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.10909090909091\n",
      "    ram_util_percent: 30.106060606060606\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04445370064056303\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.921975578673532\n",
      "    mean_inference_ms: 2.493993730941689\n",
      "    mean_raw_obs_processing_ms: 1.8545649214097761\n",
      "  time_since_restore: 2904.8650748729706\n",
      "  time_this_iter_s: 23.042587757110596\n",
      "  time_total_s: 2904.8650748729706\n",
      "  timers:\n",
      "    learn_throughput: 1158.826\n",
      "    learn_time_ms: 1724.159\n",
      "    load_throughput: 55555.242\n",
      "    load_time_ms: 35.964\n",
      "    sample_throughput: 94.63\n",
      "    sample_time_ms: 21113.734\n",
      "    update_time_ms: 8.158\n",
      "  timestamp: 1636432420\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 219780\n",
      "  training_iteration: 110\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         2904.87</td><td style=\"text-align: right;\">219780</td><td style=\"text-align: right;\">  6.0124</td><td style=\"text-align: right;\">               10.24</td><td style=\"text-align: right;\">                1.02</td><td style=\"text-align: right;\">            111.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 221778\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-34-03\n",
      "  done: false\n",
      "  episode_len_mean: 111.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.240000000000018\n",
      "  episode_reward_mean: 5.933600000000018\n",
      "  episode_reward_min: 1.0200000000000014\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2037\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6209150013469515\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01353330660090034\n",
      "          policy_loss: -0.03283551459511121\n",
      "          total_loss: 0.2539057708744492\n",
      "          vf_explained_var: 0.8830348253250122\n",
      "          vf_loss: 0.2938154512218067\n",
      "    num_agent_steps_sampled: 221778\n",
      "    num_agent_steps_trained: 221778\n",
      "    num_steps_sampled: 221778\n",
      "    num_steps_trained: 221778\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.41764705882352\n",
      "    ram_util_percent: 30.02058823529412\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04442501433147314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.908094653630425\n",
      "    mean_inference_ms: 2.493402321642405\n",
      "    mean_raw_obs_processing_ms: 1.8437386424747624\n",
      "  time_since_restore: 2928.2598764896393\n",
      "  time_this_iter_s: 23.3948016166687\n",
      "  time_total_s: 2928.2598764896393\n",
      "  timers:\n",
      "    learn_throughput: 1158.25\n",
      "    learn_time_ms: 1725.016\n",
      "    load_throughput: 55446.147\n",
      "    load_time_ms: 36.035\n",
      "    sample_throughput: 94.72\n",
      "    sample_time_ms: 21093.721\n",
      "    update_time_ms: 8.733\n",
      "  timestamp: 1636432443\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 221778\n",
      "  training_iteration: 111\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         2928.26</td><td style=\"text-align: right;\">221778</td><td style=\"text-align: right;\">  5.9336</td><td style=\"text-align: right;\">               10.24</td><td style=\"text-align: right;\">                1.02</td><td style=\"text-align: right;\">            111.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 223776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-34-27\n",
      "  done: false\n",
      "  episode_len_mean: 111.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.240000000000018\n",
      "  episode_reward_mean: 5.757500000000021\n",
      "  episode_reward_min: 1.0200000000000014\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2055\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.675027696859269\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009876724591046557\n",
      "          policy_loss: -0.023586970425787425\n",
      "          total_loss: 0.19875422290393285\n",
      "          vf_explained_var: 0.9104951620101929\n",
      "          vf_loss: 0.2324246804983843\n",
      "    num_agent_steps_sampled: 223776\n",
      "    num_agent_steps_trained: 223776\n",
      "    num_steps_sampled: 223776\n",
      "    num_steps_trained: 223776\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66176470588236\n",
      "    ram_util_percent: 30.085294117647063\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04443173625682386\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.881150153908393\n",
      "    mean_inference_ms: 2.493334295493031\n",
      "    mean_raw_obs_processing_ms: 1.8324432722096413\n",
      "  time_since_restore: 2952.5188252925873\n",
      "  time_this_iter_s: 24.258948802947998\n",
      "  time_total_s: 2952.5188252925873\n",
      "  timers:\n",
      "    learn_throughput: 1159.244\n",
      "    learn_time_ms: 1723.537\n",
      "    load_throughput: 58475.513\n",
      "    load_time_ms: 34.168\n",
      "    sample_throughput: 93.709\n",
      "    sample_time_ms: 21321.42\n",
      "    update_time_ms: 8.725\n",
      "  timestamp: 1636432467\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 223776\n",
      "  training_iteration: 112\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         2952.52</td><td style=\"text-align: right;\">223776</td><td style=\"text-align: right;\">  5.7575</td><td style=\"text-align: right;\">               10.24</td><td style=\"text-align: right;\">                1.02</td><td style=\"text-align: right;\">            111.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 225774\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-34-50\n",
      "  done: false\n",
      "  episode_len_mean: 112.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.75000000000002\n",
      "  episode_reward_mean: 5.829000000000019\n",
      "  episode_reward_min: 2.480000000000016\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2073\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7224042795953296\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011392139519817218\n",
      "          policy_loss: -0.006491103963482948\n",
      "          total_loss: 0.29376328775570504\n",
      "          vf_explained_var: 0.894023060798645\n",
      "          vf_loss: 0.3097887432291394\n",
      "    num_agent_steps_sampled: 225774\n",
      "    num_agent_steps_trained: 225774\n",
      "    num_steps_sampled: 225774\n",
      "    num_steps_trained: 225774\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.61515151515152\n",
      "    ram_util_percent: 30.054545454545455\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044409683480980865\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.856855969733036\n",
      "    mean_inference_ms: 2.492941156467643\n",
      "    mean_raw_obs_processing_ms: 1.8215440049977716\n",
      "  time_since_restore: 2975.232779979706\n",
      "  time_this_iter_s: 22.71395468711853\n",
      "  time_total_s: 2975.232779979706\n",
      "  timers:\n",
      "    learn_throughput: 1159.303\n",
      "    learn_time_ms: 1723.45\n",
      "    load_throughput: 58620.56\n",
      "    load_time_ms: 34.084\n",
      "    sample_throughput: 93.166\n",
      "    sample_time_ms: 21445.559\n",
      "    update_time_ms: 8.56\n",
      "  timestamp: 1636432490\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 225774\n",
      "  training_iteration: 113\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         2975.23</td><td style=\"text-align: right;\">225774</td><td style=\"text-align: right;\">   5.829</td><td style=\"text-align: right;\">                9.75</td><td style=\"text-align: right;\">                2.48</td><td style=\"text-align: right;\">            112.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 227772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-35-14\n",
      "  done: false\n",
      "  episode_len_mean: 113.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.760000000000026\n",
      "  episode_reward_mean: 5.713600000000021\n",
      "  episode_reward_min: 2.22000000000002\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2090\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7221164533070155\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011439039329343603\n",
      "          policy_loss: -0.029452141090517952\n",
      "          total_loss: 0.2688049755014834\n",
      "          vf_explained_var: 0.891615092754364\n",
      "          vf_loss: 0.30775693229266576\n",
      "    num_agent_steps_sampled: 227772\n",
      "    num_agent_steps_trained: 227772\n",
      "    num_steps_sampled: 227772\n",
      "    num_steps_trained: 227772\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73529411764707\n",
      "    ram_util_percent: 30.064705882352943\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04440149320776447\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.83605962809249\n",
      "    mean_inference_ms: 2.4928069262168906\n",
      "    mean_raw_obs_processing_ms: 1.8112018094126305\n",
      "  time_since_restore: 2998.8544323444366\n",
      "  time_this_iter_s: 23.621652364730835\n",
      "  time_total_s: 2998.8544323444366\n",
      "  timers:\n",
      "    learn_throughput: 1154.386\n",
      "    learn_time_ms: 1730.79\n",
      "    load_throughput: 58852.831\n",
      "    load_time_ms: 33.949\n",
      "    sample_throughput: 92.987\n",
      "    sample_time_ms: 21486.839\n",
      "    update_time_ms: 9.072\n",
      "  timestamp: 1636432514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 227772\n",
      "  training_iteration: 114\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         2998.85</td><td style=\"text-align: right;\">227772</td><td style=\"text-align: right;\">  5.7136</td><td style=\"text-align: right;\">                9.76</td><td style=\"text-align: right;\">                2.22</td><td style=\"text-align: right;\">            113.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 229770\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-35-38\n",
      "  done: false\n",
      "  episode_len_mean: 111.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.760000000000026\n",
      "  episode_reward_mean: 5.7153000000000205\n",
      "  episode_reward_min: 2.22000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2110\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6616338037309193\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015496224081533137\n",
      "          policy_loss: -0.02484620378485748\n",
      "          total_loss: 0.29866184985176436\n",
      "          vf_explained_var: 0.8944061398506165\n",
      "          vf_loss: 0.3296644404885315\n",
      "    num_agent_steps_sampled: 229770\n",
      "    num_agent_steps_trained: 229770\n",
      "    num_steps_sampled: 229770\n",
      "    num_steps_trained: 229770\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.3941176470588\n",
      "    ram_util_percent: 30.044117647058822\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04440677099163983\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.818490174600633\n",
      "    mean_inference_ms: 2.492813499421016\n",
      "    mean_raw_obs_processing_ms: 1.7996656759645975\n",
      "  time_since_restore: 3022.6626257896423\n",
      "  time_this_iter_s: 23.80819344520569\n",
      "  time_total_s: 3022.6626257896423\n",
      "  timers:\n",
      "    learn_throughput: 1153.253\n",
      "    learn_time_ms: 1732.491\n",
      "    load_throughput: 58929.269\n",
      "    load_time_ms: 33.905\n",
      "    sample_throughput: 92.21\n",
      "    sample_time_ms: 21667.845\n",
      "    update_time_ms: 9.853\n",
      "  timestamp: 1636432538\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 229770\n",
      "  training_iteration: 115\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         3022.66</td><td style=\"text-align: right;\">229770</td><td style=\"text-align: right;\">  5.7153</td><td style=\"text-align: right;\">                9.76</td><td style=\"text-align: right;\">                2.22</td><td style=\"text-align: right;\">            111.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 231768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-36-17\n",
      "  done: false\n",
      "  episode_len_mean: 110.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.840000000000025\n",
      "  episode_reward_mean: 5.629800000000021\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2126\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5931826018151782\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01073646343896984\n",
      "          policy_loss: -0.04325212715637116\n",
      "          total_loss: 0.1945485784760898\n",
      "          vf_explained_var: 0.9122964143753052\n",
      "          vf_loss: 0.2464854172652676\n",
      "    num_agent_steps_sampled: 231768\n",
      "    num_agent_steps_trained: 231768\n",
      "    num_steps_sampled: 231768\n",
      "    num_steps_trained: 231768\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.57142857142857\n",
      "    ram_util_percent: 30.025\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438711746772716\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.799190171882792\n",
      "    mean_inference_ms: 2.492477388115253\n",
      "    mean_raw_obs_processing_ms: 1.8040101465051641\n",
      "  time_since_restore: 3062.5233421325684\n",
      "  time_this_iter_s: 39.860716342926025\n",
      "  time_total_s: 3062.5233421325684\n",
      "  timers:\n",
      "    learn_throughput: 1154.244\n",
      "    learn_time_ms: 1731.003\n",
      "    load_throughput: 58847.872\n",
      "    load_time_ms: 33.952\n",
      "    sample_throughput: 86.098\n",
      "    sample_time_ms: 23206.094\n",
      "    update_time_ms: 9.895\n",
      "  timestamp: 1636432577\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 231768\n",
      "  training_iteration: 116\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         3062.52</td><td style=\"text-align: right;\">231768</td><td style=\"text-align: right;\">  5.6298</td><td style=\"text-align: right;\">                9.84</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            110.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 233766\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-36-55\n",
      "  done: false\n",
      "  episode_len_mean: 110.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.06000000000002\n",
      "  episode_reward_mean: 5.971700000000019\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2146\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7166362240200952\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010042062710551507\n",
      "          policy_loss: -0.030760999627056577\n",
      "          total_loss: 0.27014965017636616\n",
      "          vf_explained_var: 0.8949511647224426\n",
      "          vf_loss: 0.3112986220845154\n",
      "    num_agent_steps_sampled: 233766\n",
      "    num_agent_steps_trained: 233766\n",
      "    num_steps_sampled: 233766\n",
      "    num_steps_trained: 233766\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.87222222222223\n",
      "    ram_util_percent: 30.085185185185193\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044387250390955355\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.781937489178027\n",
      "    mean_inference_ms: 2.4923344054902814\n",
      "    mean_raw_obs_processing_ms: 1.824319221689459\n",
      "  time_since_restore: 3100.298580646515\n",
      "  time_this_iter_s: 37.77523851394653\n",
      "  time_total_s: 3100.298580646515\n",
      "  timers:\n",
      "    learn_throughput: 1155.569\n",
      "    learn_time_ms: 1729.018\n",
      "    load_throughput: 58962.148\n",
      "    load_time_ms: 33.886\n",
      "    sample_throughput: 81.217\n",
      "    sample_time_ms: 24600.662\n",
      "    update_time_ms: 9.746\n",
      "  timestamp: 1636432615\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 233766\n",
      "  training_iteration: 117\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">          3100.3</td><td style=\"text-align: right;\">233766</td><td style=\"text-align: right;\">  5.9717</td><td style=\"text-align: right;\">               12.06</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            110.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 235764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-37-35\n",
      "  done: false\n",
      "  episode_len_mean: 110.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.06000000000002\n",
      "  episode_reward_mean: 6.05940000000002\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2163\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.664086463337853\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011425042384829472\n",
      "          policy_loss: -0.05077826412660735\n",
      "          total_loss: 0.22980479655698652\n",
      "          vf_explained_var: 0.9253833293914795\n",
      "          vf_loss: 0.28951201825624423\n",
      "    num_agent_steps_sampled: 235764\n",
      "    num_agent_steps_trained: 235764\n",
      "    num_steps_sampled: 235764\n",
      "    num_steps_trained: 235764\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.49122807017544\n",
      "    ram_util_percent: 30.0578947368421\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438096740159318\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.753294309924215\n",
      "    mean_inference_ms: 2.492038686372008\n",
      "    mean_raw_obs_processing_ms: 1.8525960883484063\n",
      "  time_since_restore: 3139.822050333023\n",
      "  time_this_iter_s: 39.52346968650818\n",
      "  time_total_s: 3139.822050333023\n",
      "  timers:\n",
      "    learn_throughput: 1155.764\n",
      "    learn_time_ms: 1728.727\n",
      "    load_throughput: 59160.03\n",
      "    load_time_ms: 33.773\n",
      "    sample_throughput: 76.079\n",
      "    sample_time_ms: 26262.283\n",
      "    update_time_ms: 8.779\n",
      "  timestamp: 1636432655\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 235764\n",
      "  training_iteration: 118\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         3139.82</td><td style=\"text-align: right;\">235764</td><td style=\"text-align: right;\">  6.0594</td><td style=\"text-align: right;\">               12.06</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            110.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 237762\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-37-58\n",
      "  done: false\n",
      "  episode_len_mean: 110.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.06000000000002\n",
      "  episode_reward_mean: 6.10040000000002\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2180\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.664843033041273\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012739536686755197\n",
      "          policy_loss: -0.008857807091304234\n",
      "          total_loss: 0.27942252815479324\n",
      "          vf_explained_var: 0.9163947701454163\n",
      "          vf_loss: 0.2963295781896228\n",
      "    num_agent_steps_sampled: 237762\n",
      "    num_agent_steps_trained: 237762\n",
      "    num_steps_sampled: 237762\n",
      "    num_steps_trained: 237762\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.4235294117647\n",
      "    ram_util_percent: 30.099999999999994\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044371237162252226\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.73228802495854\n",
      "    mean_inference_ms: 2.491587985736889\n",
      "    mean_raw_obs_processing_ms: 1.8808439791674743\n",
      "  time_since_restore: 3163.4521486759186\n",
      "  time_this_iter_s: 23.630098342895508\n",
      "  time_total_s: 3163.4521486759186\n",
      "  timers:\n",
      "    learn_throughput: 1156.719\n",
      "    learn_time_ms: 1727.299\n",
      "    load_throughput: 59378.129\n",
      "    load_time_ms: 33.649\n",
      "    sample_throughput: 75.73\n",
      "    sample_time_ms: 26383.333\n",
      "    update_time_ms: 8.656\n",
      "  timestamp: 1636432678\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 237762\n",
      "  training_iteration: 119\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         3163.45</td><td style=\"text-align: right;\">237762</td><td style=\"text-align: right;\">  6.1004</td><td style=\"text-align: right;\">               12.06</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            110.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 239760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-38-22\n",
      "  done: false\n",
      "  episode_len_mean: 111.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.06000000000002\n",
      "  episode_reward_mean: 6.1445000000000185\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2198\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7542475768498011\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010883539351073406\n",
      "          policy_loss: -0.04308775858510108\n",
      "          total_loss: 0.2270581446942829\n",
      "          vf_explained_var: 0.9218264818191528\n",
      "          vf_loss: 0.2803419894760563\n",
      "    num_agent_steps_sampled: 239760\n",
      "    num_agent_steps_trained: 239760\n",
      "    num_steps_sampled: 239760\n",
      "    num_steps_trained: 239760\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.13333333333335\n",
      "    ram_util_percent: 30.245454545454546\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044347966067122234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.7084687583063\n",
      "    mean_inference_ms: 2.4910373259467895\n",
      "    mean_raw_obs_processing_ms: 1.910690757201282\n",
      "  time_since_restore: 3186.996908187866\n",
      "  time_this_iter_s: 23.544759511947632\n",
      "  time_total_s: 3186.996908187866\n",
      "  timers:\n",
      "    learn_throughput: 1157.071\n",
      "    learn_time_ms: 1726.774\n",
      "    load_throughput: 59550.197\n",
      "    load_time_ms: 33.552\n",
      "    sample_throughput: 75.583\n",
      "    sample_time_ms: 26434.575\n",
      "    update_time_ms: 8.566\n",
      "  timestamp: 1636432702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 239760\n",
      "  training_iteration: 120\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">            3187</td><td style=\"text-align: right;\">239760</td><td style=\"text-align: right;\">  6.1445</td><td style=\"text-align: right;\">               12.06</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            111.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 241758\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-38-48\n",
      "  done: false\n",
      "  episode_len_mean: 110.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.06000000000002\n",
      "  episode_reward_mean: 6.130700000000021\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2217\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6749953854651678\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009406338315851602\n",
      "          policy_loss: -0.023458876230177426\n",
      "          total_loss: 0.21934502690675714\n",
      "          vf_explained_var: 0.9306496977806091\n",
      "          vf_loss: 0.2532045790836925\n",
      "    num_agent_steps_sampled: 241758\n",
      "    num_agent_steps_trained: 241758\n",
      "    num_steps_sampled: 241758\n",
      "    num_steps_trained: 241758\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.98684210526315\n",
      "    ram_util_percent: 30.40263157894736\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443449670111957\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.696509685602813\n",
      "    mean_inference_ms: 2.4906608359705387\n",
      "    mean_raw_obs_processing_ms: 1.942161038832939\n",
      "  time_since_restore: 3213.2456152439117\n",
      "  time_this_iter_s: 26.248707056045532\n",
      "  time_total_s: 3213.2456152439117\n",
      "  timers:\n",
      "    learn_throughput: 1157.086\n",
      "    learn_time_ms: 1726.751\n",
      "    load_throughput: 59366.014\n",
      "    load_time_ms: 33.656\n",
      "    sample_throughput: 74.773\n",
      "    sample_time_ms: 26720.744\n",
      "    update_time_ms: 7.702\n",
      "  timestamp: 1636432728\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 241758\n",
      "  training_iteration: 121\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         3213.25</td><td style=\"text-align: right;\">241758</td><td style=\"text-align: right;\">  6.1307</td><td style=\"text-align: right;\">               12.06</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            110.23</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 243756\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-39-13\n",
      "  done: false\n",
      "  episode_len_mean: 110.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.470000000000018\n",
      "  episode_reward_mean: 6.202500000000019\n",
      "  episode_reward_min: 2.3900000000000197\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2236\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6748486445063637\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014342015661553409\n",
      "          policy_loss: -0.0882084376311728\n",
      "          total_loss: 0.3170673911459744\n",
      "          vf_explained_var: 0.8788401484489441\n",
      "          vf_loss: 0.412343450316361\n",
      "    num_agent_steps_sampled: 243756\n",
      "    num_agent_steps_trained: 243756\n",
      "    num_steps_sampled: 243756\n",
      "    num_steps_trained: 243756\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94285714285715\n",
      "    ram_util_percent: 30.582857142857147\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433881255905231\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.67768969435506\n",
      "    mean_inference_ms: 2.4904661778256307\n",
      "    mean_raw_obs_processing_ms: 1.9444968954405184\n",
      "  time_since_restore: 3237.777219772339\n",
      "  time_this_iter_s: 24.531604528427124\n",
      "  time_total_s: 3237.777219772339\n",
      "  timers:\n",
      "    learn_throughput: 1154.299\n",
      "    learn_time_ms: 1730.921\n",
      "    load_throughput: 59300.187\n",
      "    load_time_ms: 33.693\n",
      "    sample_throughput: 74.712\n",
      "    sample_time_ms: 26742.575\n",
      "    update_time_ms: 8.77\n",
      "  timestamp: 1636432753\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 243756\n",
      "  training_iteration: 122\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         3237.78</td><td style=\"text-align: right;\">243756</td><td style=\"text-align: right;\">  6.2025</td><td style=\"text-align: right;\">               10.47</td><td style=\"text-align: right;\">                2.39</td><td style=\"text-align: right;\">            110.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 245754\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-39-38\n",
      "  done: false\n",
      "  episode_len_mean: 110.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.110000000000019\n",
      "  episode_reward_mean: 6.194800000000019\n",
      "  episode_reward_min: 2.3900000000000197\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2255\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6480806708335876\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010607230673563735\n",
      "          policy_loss: 0.0034852534177757443\n",
      "          total_loss: 0.2740261688163238\n",
      "          vf_explained_var: 0.9274261593818665\n",
      "          vf_loss: 0.27986184191845714\n",
      "    num_agent_steps_sampled: 245754\n",
      "    num_agent_steps_trained: 245754\n",
      "    num_steps_sampled: 245754\n",
      "    num_steps_trained: 245754\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0\n",
      "    ram_util_percent: 30.597142857142853\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433216796781921\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.667457992941436\n",
      "    mean_inference_ms: 2.490306744386684\n",
      "    mean_raw_obs_processing_ms: 1.9402235364216665\n",
      "  time_since_restore: 3262.4448380470276\n",
      "  time_this_iter_s: 24.66761827468872\n",
      "  time_total_s: 3262.4448380470276\n",
      "  timers:\n",
      "    learn_throughput: 1153.702\n",
      "    learn_time_ms: 1731.816\n",
      "    load_throughput: 59025.523\n",
      "    load_time_ms: 33.85\n",
      "    sample_throughput: 74.174\n",
      "    sample_time_ms: 26936.781\n",
      "    update_time_ms: 8.909\n",
      "  timestamp: 1636432778\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 245754\n",
      "  training_iteration: 123\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         3262.44</td><td style=\"text-align: right;\">245754</td><td style=\"text-align: right;\">  6.1948</td><td style=\"text-align: right;\">               12.11</td><td style=\"text-align: right;\">                2.39</td><td style=\"text-align: right;\">            110.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 247752\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-40-01\n",
      "  done: false\n",
      "  episode_len_mean: 109.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.110000000000019\n",
      "  episode_reward_mean: 6.244700000000019\n",
      "  episode_reward_min: 2.5000000000000155\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2273\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6392156629335313\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012444946001918672\n",
      "          policy_loss: -0.027148270429599854\n",
      "          total_loss: 0.2324360757533993\n",
      "          vf_explained_var: 0.922684907913208\n",
      "          vf_loss: 0.2675761651425135\n",
      "    num_agent_steps_sampled: 247752\n",
      "    num_agent_steps_trained: 247752\n",
      "    num_steps_sampled: 247752\n",
      "    num_steps_trained: 247752\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0878787878788\n",
      "    ram_util_percent: 30.542424242424243\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433884623610803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.665893790481697\n",
      "    mean_inference_ms: 2.4902966628936274\n",
      "    mean_raw_obs_processing_ms: 1.9302328094965995\n",
      "  time_since_restore: 3285.5583317279816\n",
      "  time_this_iter_s: 23.11349368095398\n",
      "  time_total_s: 3285.5583317279816\n",
      "  timers:\n",
      "    learn_throughput: 1159.072\n",
      "    learn_time_ms: 1723.793\n",
      "    load_throughput: 58845.805\n",
      "    load_time_ms: 33.953\n",
      "    sample_throughput: 74.29\n",
      "    sample_time_ms: 26894.742\n",
      "    update_time_ms: 8.163\n",
      "  timestamp: 1636432801\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 247752\n",
      "  training_iteration: 124\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         3285.56</td><td style=\"text-align: right;\">247752</td><td style=\"text-align: right;\">  6.2447</td><td style=\"text-align: right;\">               12.11</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">            109.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 249750\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-40-26\n",
      "  done: false\n",
      "  episode_len_mean: 107.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.110000000000019\n",
      "  episode_reward_mean: 6.38100000000002\n",
      "  episode_reward_min: 2.5000000000000155\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2293\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6379004915555317\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009950138933594145\n",
      "          policy_loss: -0.08549079114482516\n",
      "          total_loss: 0.10611375980079174\n",
      "          vf_explained_var: 0.9546718001365662\n",
      "          vf_loss: 0.20126720991517816\n",
      "    num_agent_steps_sampled: 249750\n",
      "    num_agent_steps_trained: 249750\n",
      "    num_steps_sampled: 249750\n",
      "    num_steps_trained: 249750\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.28571428571429\n",
      "    ram_util_percent: 30.514285714285716\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433592469470565\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.658353429616092\n",
      "    mean_inference_ms: 2.4901569692731282\n",
      "    mean_raw_obs_processing_ms: 1.9194331528571649\n",
      "  time_since_restore: 3310.3522822856903\n",
      "  time_this_iter_s: 24.79395055770874\n",
      "  time_total_s: 3310.3522822856903\n",
      "  timers:\n",
      "    learn_throughput: 1159.455\n",
      "    learn_time_ms: 1723.223\n",
      "    load_throughput: 58789.208\n",
      "    load_time_ms: 33.986\n",
      "    sample_throughput: 74.016\n",
      "    sample_time_ms: 26994.28\n",
      "    update_time_ms: 7.755\n",
      "  timestamp: 1636432826\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 249750\n",
      "  training_iteration: 125\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         3310.35</td><td style=\"text-align: right;\">249750</td><td style=\"text-align: right;\">   6.381</td><td style=\"text-align: right;\">               12.11</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">            107.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 251748\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-40-50\n",
      "  done: false\n",
      "  episode_len_mean: 106.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.110000000000019\n",
      "  episode_reward_mean: 6.412800000000019\n",
      "  episode_reward_min: 2.5000000000000155\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2311\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6765209896223885\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009998970260913512\n",
      "          policy_loss: -0.08549230473027343\n",
      "          total_loss: 0.1390593481094887\n",
      "          vf_explained_var: 0.9431438446044922\n",
      "          vf_loss: 0.23456755688502676\n",
      "    num_agent_steps_sampled: 251748\n",
      "    num_agent_steps_trained: 251748\n",
      "    num_steps_sampled: 251748\n",
      "    num_steps_trained: 251748\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.26857142857143\n",
      "    ram_util_percent: 30.48\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433372531631619\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.65021845255007\n",
      "    mean_inference_ms: 2.4900305438836683\n",
      "    mean_raw_obs_processing_ms: 1.9098924647110715\n",
      "  time_since_restore: 3334.66543340683\n",
      "  time_this_iter_s: 24.313151121139526\n",
      "  time_total_s: 3334.66543340683\n",
      "  timers:\n",
      "    learn_throughput: 1160.41\n",
      "    learn_time_ms: 1721.806\n",
      "    load_throughput: 58625.03\n",
      "    load_time_ms: 34.081\n",
      "    sample_throughput: 78.536\n",
      "    sample_time_ms: 25440.62\n",
      "    update_time_ms: 8.024\n",
      "  timestamp: 1636432850\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 251748\n",
      "  training_iteration: 126\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         3334.67</td><td style=\"text-align: right;\">251748</td><td style=\"text-align: right;\">  6.4128</td><td style=\"text-align: right;\">               12.11</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">            106.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 253746\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-41-14\n",
      "  done: false\n",
      "  episode_len_mean: 106.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.110000000000019\n",
      "  episode_reward_mean: 6.56550000000002\n",
      "  episode_reward_min: 2.7100000000000173\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2330\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4835398106347948\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010618977751409174\n",
      "          policy_loss: -0.06201386382537229\n",
      "          total_loss: 0.17382174048217988\n",
      "          vf_explained_var: 0.9432286024093628\n",
      "          vf_loss: 0.24350319419588362\n",
      "    num_agent_steps_sampled: 253746\n",
      "    num_agent_steps_trained: 253746\n",
      "    num_steps_sampled: 253746\n",
      "    num_steps_trained: 253746\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.25588235294119\n",
      "    ram_util_percent: 30.41176470588235\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443150423480934\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.645962150153395\n",
      "    mean_inference_ms: 2.4895713091093734\n",
      "    mean_raw_obs_processing_ms: 1.900069478864168\n",
      "  time_since_restore: 3358.649320602417\n",
      "  time_this_iter_s: 23.983887195587158\n",
      "  time_total_s: 3358.649320602417\n",
      "  timers:\n",
      "    learn_throughput: 1159.648\n",
      "    learn_time_ms: 1722.936\n",
      "    load_throughput: 58646.651\n",
      "    load_time_ms: 34.068\n",
      "    sample_throughput: 83.043\n",
      "    sample_time_ms: 24059.825\n",
      "    update_time_ms: 8.391\n",
      "  timestamp: 1636432874\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 253746\n",
      "  training_iteration: 127\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         3358.65</td><td style=\"text-align: right;\">253746</td><td style=\"text-align: right;\">  6.5655</td><td style=\"text-align: right;\">               12.11</td><td style=\"text-align: right;\">                2.71</td><td style=\"text-align: right;\">             106.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 255744\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-41-39\n",
      "  done: false\n",
      "  episode_len_mean: 105.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.92000000000002\n",
      "  episode_reward_mean: 6.430900000000017\n",
      "  episode_reward_min: 2.7100000000000173\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2350\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6373967692965552\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008947799064855854\n",
      "          policy_loss: -0.0745153766657625\n",
      "          total_loss: 0.2046789320984057\n",
      "          vf_explained_var: 0.9397814273834229\n",
      "          vf_loss: 0.2895285107550167\n",
      "    num_agent_steps_sampled: 255744\n",
      "    num_agent_steps_trained: 255744\n",
      "    num_steps_sampled: 255744\n",
      "    num_steps_trained: 255744\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89166666666665\n",
      "    ram_util_percent: 30.422222222222224\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432829595913782\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.63237637084395\n",
      "    mean_inference_ms: 2.4895639712036903\n",
      "    mean_raw_obs_processing_ms: 1.8896681419818588\n",
      "  time_since_restore: 3383.440928220749\n",
      "  time_this_iter_s: 24.79160761833191\n",
      "  time_total_s: 3383.440928220749\n",
      "  timers:\n",
      "    learn_throughput: 1158.608\n",
      "    learn_time_ms: 1724.483\n",
      "    load_throughput: 58568.815\n",
      "    load_time_ms: 34.114\n",
      "    sample_throughput: 88.466\n",
      "    sample_time_ms: 22584.867\n",
      "    update_time_ms: 8.599\n",
      "  timestamp: 1636432899\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 255744\n",
      "  training_iteration: 128\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         3383.44</td><td style=\"text-align: right;\">255744</td><td style=\"text-align: right;\">  6.4309</td><td style=\"text-align: right;\">               11.92</td><td style=\"text-align: right;\">                2.71</td><td style=\"text-align: right;\">            105.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 257742\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-42-03\n",
      "  done: false\n",
      "  episode_len_mean: 105.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.92000000000002\n",
      "  episode_reward_mean: 6.593900000000019\n",
      "  episode_reward_min: 2.600000000000012\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2367\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5537732850937616\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01589510115273053\n",
      "          policy_loss: -0.017388560995459556\n",
      "          total_loss: 0.30454085355713256\n",
      "          vf_explained_var: 0.9311486482620239\n",
      "          vf_loss: 0.3267379535096032\n",
      "    num_agent_steps_sampled: 257742\n",
      "    num_agent_steps_trained: 257742\n",
      "    num_steps_sampled: 257742\n",
      "    num_steps_trained: 257742\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87058823529412\n",
      "    ram_util_percent: 30.394117647058827\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431921406961605\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.633218560401023\n",
      "    mean_inference_ms: 2.48903144371641\n",
      "    mean_raw_obs_processing_ms: 1.8813635642483422\n",
      "  time_since_restore: 3407.3073921203613\n",
      "  time_this_iter_s: 23.866463899612427\n",
      "  time_total_s: 3407.3073921203613\n",
      "  timers:\n",
      "    learn_throughput: 1156.72\n",
      "    learn_time_ms: 1727.298\n",
      "    load_throughput: 58666.317\n",
      "    load_time_ms: 34.057\n",
      "    sample_throughput: 88.383\n",
      "    sample_time_ms: 22606.055\n",
      "    update_time_ms: 8.646\n",
      "  timestamp: 1636432923\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 257742\n",
      "  training_iteration: 129\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         3407.31</td><td style=\"text-align: right;\">257742</td><td style=\"text-align: right;\">  6.5939</td><td style=\"text-align: right;\">               11.92</td><td style=\"text-align: right;\">                 2.6</td><td style=\"text-align: right;\">             105.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 259740\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-42-28\n",
      "  done: false\n",
      "  episode_len_mean: 104.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.92000000000002\n",
      "  episode_reward_mean: 6.571500000000018\n",
      "  episode_reward_min: 2.3700000000000183\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2388\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4099393827574593\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00960917253996912\n",
      "          policy_loss: -0.016588220931589605\n",
      "          total_loss: 0.2515775986991468\n",
      "          vf_explained_var: 0.9352595806121826\n",
      "          vf_loss: 0.27577902192161197\n",
      "    num_agent_steps_sampled: 259740\n",
      "    num_agent_steps_trained: 259740\n",
      "    num_steps_sampled: 259740\n",
      "    num_steps_trained: 259740\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92500000000001\n",
      "    ram_util_percent: 30.34722222222223\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435078295200432\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.624350613690453\n",
      "    mean_inference_ms: 2.4890983151842505\n",
      "    mean_raw_obs_processing_ms: 1.8709973014932115\n",
      "  time_since_restore: 3432.4605255126953\n",
      "  time_this_iter_s: 25.153133392333984\n",
      "  time_total_s: 3432.4605255126953\n",
      "  timers:\n",
      "    learn_throughput: 1156.476\n",
      "    learn_time_ms: 1727.663\n",
      "    load_throughput: 58502.456\n",
      "    load_time_ms: 34.152\n",
      "    sample_throughput: 87.764\n",
      "    sample_time_ms: 22765.687\n",
      "    update_time_ms: 9.238\n",
      "  timestamp: 1636432948\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259740\n",
      "  training_iteration: 130\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         3432.46</td><td style=\"text-align: right;\">259740</td><td style=\"text-align: right;\">  6.5715</td><td style=\"text-align: right;\">               11.92</td><td style=\"text-align: right;\">                2.37</td><td style=\"text-align: right;\">            104.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 261738\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-42-51\n",
      "  done: false\n",
      "  episode_len_mean: 105.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.020000000000024\n",
      "  episode_reward_mean: 6.719200000000018\n",
      "  episode_reward_min: 2.3700000000000183\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2406\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5791828933216276\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01178522383696789\n",
      "          policy_loss: -0.025503000625897023\n",
      "          total_loss: 0.2731506501280126\n",
      "          vf_explained_var: 0.9313633441925049\n",
      "          vf_loss: 0.3064904535810153\n",
      "    num_agent_steps_sampled: 261738\n",
      "    num_agent_steps_trained: 261738\n",
      "    num_steps_sampled: 261738\n",
      "    num_steps_trained: 261738\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.86060606060606\n",
      "    ram_util_percent: 30.345454545454544\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436050270759877\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.620731264360746\n",
      "    mean_inference_ms: 2.488917640039036\n",
      "    mean_raw_obs_processing_ms: 1.862402026179201\n",
      "  time_since_restore: 3455.416501522064\n",
      "  time_this_iter_s: 22.955976009368896\n",
      "  time_total_s: 3455.416501522064\n",
      "  timers:\n",
      "    learn_throughput: 1158.302\n",
      "    learn_time_ms: 1724.939\n",
      "    load_throughput: 58475.962\n",
      "    load_time_ms: 34.168\n",
      "    sample_throughput: 89.044\n",
      "    sample_time_ms: 22438.375\n",
      "    update_time_ms: 10.029\n",
      "  timestamp: 1636432971\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 261738\n",
      "  training_iteration: 131\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         3455.42</td><td style=\"text-align: right;\">261738</td><td style=\"text-align: right;\">  6.7192</td><td style=\"text-align: right;\">               12.02</td><td style=\"text-align: right;\">                2.37</td><td style=\"text-align: right;\">            105.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 263736\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-43-16\n",
      "  done: false\n",
      "  episode_len_mean: 105.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.020000000000024\n",
      "  episode_reward_mean: 6.5782000000000185\n",
      "  episode_reward_min: 2.3700000000000183\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2425\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6018564723786854\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010899292151580534\n",
      "          policy_loss: 0.0029793429055384227\n",
      "          total_loss: 0.2880108743373837\n",
      "          vf_explained_var: 0.9155308604240417\n",
      "          vf_loss: 0.29369307316484905\n",
      "    num_agent_steps_sampled: 263736\n",
      "    num_agent_steps_trained: 263736\n",
      "    num_steps_sampled: 263736\n",
      "    num_steps_trained: 263736\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69142857142856\n",
      "    ram_util_percent: 30.32285714285715\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044375084475294424\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.617340966039237\n",
      "    mean_inference_ms: 2.488791828060164\n",
      "    mean_raw_obs_processing_ms: 1.853520498285888\n",
      "  time_since_restore: 3480.195950984955\n",
      "  time_this_iter_s: 24.779449462890625\n",
      "  time_total_s: 3480.195950984955\n",
      "  timers:\n",
      "    learn_throughput: 1160.375\n",
      "    learn_time_ms: 1721.857\n",
      "    load_throughput: 58488.737\n",
      "    load_time_ms: 34.16\n",
      "    sample_throughput: 88.929\n",
      "    sample_time_ms: 22467.395\n",
      "    update_time_ms: 8.999\n",
      "  timestamp: 1636432996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 263736\n",
      "  training_iteration: 132\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">          3480.2</td><td style=\"text-align: right;\">263736</td><td style=\"text-align: right;\">  6.5782</td><td style=\"text-align: right;\">               12.02</td><td style=\"text-align: right;\">                2.37</td><td style=\"text-align: right;\">            105.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 265734\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-43-41\n",
      "  done: false\n",
      "  episode_len_mean: 105.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.020000000000024\n",
      "  episode_reward_mean: 6.502800000000018\n",
      "  episode_reward_min: 2.3700000000000183\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2443\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6483252763748169\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010565248027606475\n",
      "          policy_loss: -0.043630164302885535\n",
      "          total_loss: 0.11233030696887346\n",
      "          vf_explained_var: 0.9452325105667114\n",
      "          vf_loss: 0.16531217843294144\n",
      "    num_agent_steps_sampled: 265734\n",
      "    num_agent_steps_trained: 265734\n",
      "    num_steps_sampled: 265734\n",
      "    num_steps_trained: 265734\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.83055555555555\n",
      "    ram_util_percent: 30.288888888888884\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437161177085183\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.619312611060646\n",
      "    mean_inference_ms: 2.4883651027235305\n",
      "    mean_raw_obs_processing_ms: 1.8452039993543279\n",
      "  time_since_restore: 3505.181384563446\n",
      "  time_this_iter_s: 24.98543357849121\n",
      "  time_total_s: 3505.181384563446\n",
      "  timers:\n",
      "    learn_throughput: 1158.697\n",
      "    learn_time_ms: 1724.351\n",
      "    load_throughput: 58409.121\n",
      "    load_time_ms: 34.207\n",
      "    sample_throughput: 88.812\n",
      "    sample_time_ms: 22496.916\n",
      "    update_time_ms: 8.674\n",
      "  timestamp: 1636433021\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 265734\n",
      "  training_iteration: 133\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         3505.18</td><td style=\"text-align: right;\">265734</td><td style=\"text-align: right;\">  6.5028</td><td style=\"text-align: right;\">               12.02</td><td style=\"text-align: right;\">                2.37</td><td style=\"text-align: right;\">             105.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 267732\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-44-05\n",
      "  done: false\n",
      "  episode_len_mean: 105.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.850000000000025\n",
      "  episode_reward_mean: 6.583200000000018\n",
      "  episode_reward_min: 2.3700000000000183\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2461\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6074210774330866\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010317705012833064\n",
      "          policy_loss: -0.09176220712030218\n",
      "          total_loss: 0.1535129691562837\n",
      "          vf_explained_var: 0.9475312829017639\n",
      "          vf_loss: 0.25438493562950976\n",
      "    num_agent_steps_sampled: 267732\n",
      "    num_agent_steps_trained: 267732\n",
      "    num_steps_sampled: 267732\n",
      "    num_steps_trained: 267732\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.49428571428572\n",
      "    ram_util_percent: 30.23142857142857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04440261510353293\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.61534571488841\n",
      "    mean_inference_ms: 2.4884364686363587\n",
      "    mean_raw_obs_processing_ms: 1.8365429423077533\n",
      "  time_since_restore: 3530.014575481415\n",
      "  time_this_iter_s: 24.83319091796875\n",
      "  time_total_s: 3530.014575481415\n",
      "  timers:\n",
      "    learn_throughput: 1158.636\n",
      "    learn_time_ms: 1724.442\n",
      "    load_throughput: 58239.405\n",
      "    load_time_ms: 34.307\n",
      "    sample_throughput: 88.14\n",
      "    sample_time_ms: 22668.578\n",
      "    update_time_ms: 8.837\n",
      "  timestamp: 1636433045\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 267732\n",
      "  training_iteration: 134\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         3530.01</td><td style=\"text-align: right;\">267732</td><td style=\"text-align: right;\">  6.5832</td><td style=\"text-align: right;\">               13.85</td><td style=\"text-align: right;\">                2.37</td><td style=\"text-align: right;\">            105.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 269730\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-44-44\n",
      "  done: false\n",
      "  episode_len_mean: 105.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.850000000000025\n",
      "  episode_reward_mean: 6.487300000000021\n",
      "  episode_reward_min: -0.02\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 2482\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.528582811923254\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009340113123118117\n",
      "          policy_loss: -0.05049288045792352\n",
      "          total_loss: 0.2294970211883386\n",
      "          vf_explained_var: 0.92828369140625\n",
      "          vf_loss: 0.28897115236946513\n",
      "    num_agent_steps_sampled: 269730\n",
      "    num_agent_steps_trained: 269730\n",
      "    num_steps_sampled: 269730\n",
      "    num_steps_trained: 269730\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.97272727272724\n",
      "    ram_util_percent: 30.241818181818182\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04440127756447576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.60644514665859\n",
      "    mean_inference_ms: 2.4882356927850235\n",
      "    mean_raw_obs_processing_ms: 1.8391915348331815\n",
      "  time_since_restore: 3568.4410486221313\n",
      "  time_this_iter_s: 38.42647314071655\n",
      "  time_total_s: 3568.4410486221313\n",
      "  timers:\n",
      "    learn_throughput: 1156.892\n",
      "    learn_time_ms: 1727.041\n",
      "    load_throughput: 58149.368\n",
      "    load_time_ms: 34.36\n",
      "    sample_throughput: 83.15\n",
      "    sample_time_ms: 24028.956\n",
      "    update_time_ms: 8.894\n",
      "  timestamp: 1636433084\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 269730\n",
      "  training_iteration: 135\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         3568.44</td><td style=\"text-align: right;\">269730</td><td style=\"text-align: right;\">  6.4873</td><td style=\"text-align: right;\">               13.85</td><td style=\"text-align: right;\">               -0.02</td><td style=\"text-align: right;\">            105.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 271728\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-45-08\n",
      "  done: false\n",
      "  episode_len_mean: 107.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.850000000000025\n",
      "  episode_reward_mean: 6.4623000000000195\n",
      "  episode_reward_min: -0.02\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2498\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6327531638599577\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011978759255282842\n",
      "          policy_loss: -0.0366647193474429\n",
      "          total_loss: 0.24241475103689092\n",
      "          vf_explained_var: 0.9360076785087585\n",
      "          vf_loss: 0.2873213379865601\n",
      "    num_agent_steps_sampled: 271728\n",
      "    num_agent_steps_trained: 271728\n",
      "    num_steps_sampled: 271728\n",
      "    num_steps_trained: 271728\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.51764705882354\n",
      "    ram_util_percent: 30.155882352941177\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044392544241846806\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.597062712823316\n",
      "    mean_inference_ms: 2.4878597356576715\n",
      "    mean_raw_obs_processing_ms: 1.8422121104257478\n",
      "  time_since_restore: 3592.1495735645294\n",
      "  time_this_iter_s: 23.70852494239807\n",
      "  time_total_s: 3592.1495735645294\n",
      "  timers:\n",
      "    learn_throughput: 1155.976\n",
      "    learn_time_ms: 1728.41\n",
      "    load_throughput: 58239.526\n",
      "    load_time_ms: 34.307\n",
      "    sample_throughput: 83.365\n",
      "    sample_time_ms: 23966.861\n",
      "    update_time_ms: 9.282\n",
      "  timestamp: 1636433108\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 271728\n",
      "  training_iteration: 136\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         3592.15</td><td style=\"text-align: right;\">271728</td><td style=\"text-align: right;\">  6.4623</td><td style=\"text-align: right;\">               13.85</td><td style=\"text-align: right;\">               -0.02</td><td style=\"text-align: right;\">            107.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 273726\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-45-47\n",
      "  done: false\n",
      "  episode_len_mean: 107.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.850000000000025\n",
      "  episode_reward_mean: 6.319900000000019\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2517\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.589680898757208\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013997469003016995\n",
      "          policy_loss: -0.004236967400425957\n",
      "          total_loss: 0.44798554962589626\n",
      "          vf_explained_var: 0.8553228378295898\n",
      "          vf_loss: 0.4586710341629528\n",
      "    num_agent_steps_sampled: 273726\n",
      "    num_agent_steps_trained: 273726\n",
      "    num_steps_sampled: 273726\n",
      "    num_steps_trained: 273726\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.76428571428572\n",
      "    ram_util_percent: 30.03392857142857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0444082689655098\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.582992041440704\n",
      "    mean_inference_ms: 2.487721679510132\n",
      "    mean_raw_obs_processing_ms: 1.8673784344580782\n",
      "  time_since_restore: 3631.309573173523\n",
      "  time_this_iter_s: 39.15999960899353\n",
      "  time_total_s: 3631.309573173523\n",
      "  timers:\n",
      "    learn_throughput: 1154.896\n",
      "    learn_time_ms: 1730.026\n",
      "    load_throughput: 58160.95\n",
      "    load_time_ms: 34.353\n",
      "    sample_throughput: 78.406\n",
      "    sample_time_ms: 25482.743\n",
      "    update_time_ms: 9.598\n",
      "  timestamp: 1636433147\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 273726\n",
      "  training_iteration: 137\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         3631.31</td><td style=\"text-align: right;\">273726</td><td style=\"text-align: right;\">  6.3199</td><td style=\"text-align: right;\">               13.85</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            107.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 275724\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-46-11\n",
      "  done: false\n",
      "  episode_len_mean: 109.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.850000000000025\n",
      "  episode_reward_mean: 6.455400000000019\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2535\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5464099668321156\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010788390242636564\n",
      "          policy_loss: -0.060076482735929033\n",
      "          total_loss: 0.17985419176873707\n",
      "          vf_explained_var: 0.9418133497238159\n",
      "          vf_loss: 0.24811261086946443\n",
      "    num_agent_steps_sampled: 275724\n",
      "    num_agent_steps_trained: 275724\n",
      "    num_steps_sampled: 275724\n",
      "    num_steps_trained: 275724\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.24117647058824\n",
      "    ram_util_percent: 30.03529411764706\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044395920898254476\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.560315079822402\n",
      "    mean_inference_ms: 2.4873113418083537\n",
      "    mean_raw_obs_processing_ms: 1.8907900004989997\n",
      "  time_since_restore: 3655.1637873649597\n",
      "  time_this_iter_s: 23.854214191436768\n",
      "  time_total_s: 3655.1637873649597\n",
      "  timers:\n",
      "    learn_throughput: 1154.798\n",
      "    learn_time_ms: 1730.172\n",
      "    load_throughput: 58376.001\n",
      "    load_time_ms: 34.226\n",
      "    sample_throughput: 78.696\n",
      "    sample_time_ms: 25388.981\n",
      "    update_time_ms: 9.44\n",
      "  timestamp: 1636433171\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 275724\n",
      "  training_iteration: 138\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         3655.16</td><td style=\"text-align: right;\">275724</td><td style=\"text-align: right;\">  6.4554</td><td style=\"text-align: right;\">               13.85</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            109.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 277722\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-46-35\n",
      "  done: false\n",
      "  episode_len_mean: 109.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.950000000000026\n",
      "  episode_reward_mean: 6.2481000000000195\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2553\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6186148524284363\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011772751394535673\n",
      "          policy_loss: 0.03913448364252136\n",
      "          total_loss: 0.26707003827073744\n",
      "          vf_explained_var: 0.9092108011245728\n",
      "          vf_loss: 0.23617509738320397\n",
      "    num_agent_steps_sampled: 277722\n",
      "    num_agent_steps_trained: 277722\n",
      "    num_steps_sampled: 277722\n",
      "    num_steps_trained: 277722\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.35588235294118\n",
      "    ram_util_percent: 30.09411764705882\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439716288073769\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.53744099112859\n",
      "    mean_inference_ms: 2.4871032261169783\n",
      "    mean_raw_obs_processing_ms: 1.9141669732634974\n",
      "  time_since_restore: 3679.171999692917\n",
      "  time_this_iter_s: 24.008212327957153\n",
      "  time_total_s: 3679.171999692917\n",
      "  timers:\n",
      "    learn_throughput: 1154.867\n",
      "    learn_time_ms: 1730.069\n",
      "    load_throughput: 58207.084\n",
      "    load_time_ms: 34.326\n",
      "    sample_throughput: 78.652\n",
      "    sample_time_ms: 25403.044\n",
      "    update_time_ms: 9.259\n",
      "  timestamp: 1636433195\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 277722\n",
      "  training_iteration: 139\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         3679.17</td><td style=\"text-align: right;\">277722</td><td style=\"text-align: right;\">  6.2481</td><td style=\"text-align: right;\">               11.95</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             109.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 279720\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-46-58\n",
      "  done: false\n",
      "  episode_len_mean: 111.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.18000000000002\n",
      "  episode_reward_mean: 6.35570000000002\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2571\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5328132816723414\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012836415671089606\n",
      "          policy_loss: -0.0632634325396447\n",
      "          total_loss: 0.21266306408104443\n",
      "          vf_explained_var: 0.9207316040992737\n",
      "          vf_loss: 0.2825900483699072\n",
      "    num_agent_steps_sampled: 279720\n",
      "    num_agent_steps_trained: 279720\n",
      "    num_steps_sampled: 279720\n",
      "    num_steps_trained: 279720\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96969696969698\n",
      "    ram_util_percent: 30.321212121212117\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437688944282299\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.516438828776355\n",
      "    mean_inference_ms: 2.486625653468961\n",
      "    mean_raw_obs_processing_ms: 1.9375427975470756\n",
      "  time_since_restore: 3702.1016454696655\n",
      "  time_this_iter_s: 22.929645776748657\n",
      "  time_total_s: 3702.1016454696655\n",
      "  timers:\n",
      "    learn_throughput: 1155.475\n",
      "    learn_time_ms: 1729.158\n",
      "    load_throughput: 58111.061\n",
      "    load_time_ms: 34.382\n",
      "    sample_throughput: 79.342\n",
      "    sample_time_ms: 25182.108\n",
      "    update_time_ms: 8.823\n",
      "  timestamp: 1636433218\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 279720\n",
      "  training_iteration: 140\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">          3702.1</td><td style=\"text-align: right;\">279720</td><td style=\"text-align: right;\">  6.3557</td><td style=\"text-align: right;\">               12.18</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            111.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 281718\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-47-20\n",
      "  done: false\n",
      "  episode_len_mean: 112.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.18000000000002\n",
      "  episode_reward_mean: 6.37900000000002\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2589\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4666664418720063\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010579766571073568\n",
      "          policy_loss: -0.00625536832071486\n",
      "          total_loss: 0.2483145378175236\n",
      "          vf_explained_var: 0.9307595491409302\n",
      "          vf_loss: 0.2620952281923521\n",
      "    num_agent_steps_sampled: 281718\n",
      "    num_agent_steps_trained: 281718\n",
      "    num_steps_sampled: 281718\n",
      "    num_steps_trained: 281718\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.759375\n",
      "    ram_util_percent: 30.48125\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438540577731637\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.49103936391375\n",
      "    mean_inference_ms: 2.4867128379802548\n",
      "    mean_raw_obs_processing_ms: 1.9479325797398734\n",
      "  time_since_restore: 3724.3101711273193\n",
      "  time_this_iter_s: 22.20852565765381\n",
      "  time_total_s: 3724.3101711273193\n",
      "  timers:\n",
      "    learn_throughput: 1155.88\n",
      "    learn_time_ms: 1728.554\n",
      "    load_throughput: 59294.69\n",
      "    load_time_ms: 33.696\n",
      "    sample_throughput: 79.573\n",
      "    sample_time_ms: 25109.064\n",
      "    update_time_ms: 8.404\n",
      "  timestamp: 1636433240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 281718\n",
      "  training_iteration: 141\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         3724.31</td><td style=\"text-align: right;\">281718</td><td style=\"text-align: right;\">   6.379</td><td style=\"text-align: right;\">               12.18</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            112.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 283716\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-47-43\n",
      "  done: false\n",
      "  episode_len_mean: 112.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.18000000000002\n",
      "  episode_reward_mean: 6.545200000000022\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2605\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.561122113182431\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010635985263736556\n",
      "          policy_loss: -0.016357763963086264\n",
      "          total_loss: 0.19892723732406184\n",
      "          vf_explained_var: 0.9422924518585205\n",
      "          vf_loss: 0.2237169314353239\n",
      "    num_agent_steps_sampled: 283716\n",
      "    num_agent_steps_trained: 283716\n",
      "    num_steps_sampled: 283716\n",
      "    num_steps_trained: 283716\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.17575757575759\n",
      "    ram_util_percent: 30.581818181818182\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434735004028928\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.46661390534362\n",
      "    mean_inference_ms: 2.4862964688158393\n",
      "    mean_raw_obs_processing_ms: 1.9446317995044722\n",
      "  time_since_restore: 3747.6845054626465\n",
      "  time_this_iter_s: 23.37433433532715\n",
      "  time_total_s: 3747.6845054626465\n",
      "  timers:\n",
      "    learn_throughput: 1154.555\n",
      "    learn_time_ms: 1730.536\n",
      "    load_throughput: 59338.271\n",
      "    load_time_ms: 33.671\n",
      "    sample_throughput: 80.026\n",
      "    sample_time_ms: 24966.741\n",
      "    update_time_ms: 8.197\n",
      "  timestamp: 1636433263\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 283716\n",
      "  training_iteration: 142\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         3747.68</td><td style=\"text-align: right;\">283716</td><td style=\"text-align: right;\">  6.5452</td><td style=\"text-align: right;\">               12.18</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            112.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 285714\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-48-08\n",
      "  done: false\n",
      "  episode_len_mean: 111.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.18000000000002\n",
      "  episode_reward_mean: 6.853200000000019\n",
      "  episode_reward_min: 2.780000000000011\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2624\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5376857485089983\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009116775474520087\n",
      "          policy_loss: -0.03998335867765404\n",
      "          total_loss: 0.2044400823435613\n",
      "          vf_explained_var: 0.9428350329399109\n",
      "          vf_loss: 0.2536464748638017\n",
      "    num_agent_steps_sampled: 285714\n",
      "    num_agent_steps_trained: 285714\n",
      "    num_steps_sampled: 285714\n",
      "    num_steps_trained: 285714\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.05555555555554\n",
      "    ram_util_percent: 30.59444444444445\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044356001183537414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.451991118393966\n",
      "    mean_inference_ms: 2.486364888127862\n",
      "    mean_raw_obs_processing_ms: 1.9348454328063702\n",
      "  time_since_restore: 3772.5540804862976\n",
      "  time_this_iter_s: 24.869575023651123\n",
      "  time_total_s: 3772.5540804862976\n",
      "  timers:\n",
      "    learn_throughput: 1157.324\n",
      "    learn_time_ms: 1726.397\n",
      "    load_throughput: 59552.99\n",
      "    load_time_ms: 33.55\n",
      "    sample_throughput: 80.049\n",
      "    sample_time_ms: 24959.628\n",
      "    update_time_ms: 8.176\n",
      "  timestamp: 1636433288\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 285714\n",
      "  training_iteration: 143\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         3772.55</td><td style=\"text-align: right;\">285714</td><td style=\"text-align: right;\">  6.8532</td><td style=\"text-align: right;\">               12.18</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">            111.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 287712\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-48-32\n",
      "  done: false\n",
      "  episode_len_mean: 110.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.18000000000002\n",
      "  episode_reward_mean: 7.136500000000019\n",
      "  episode_reward_min: 2.780000000000011\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2643\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5004728754361472\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011435189022505492\n",
      "          policy_loss: -0.020788481352584702\n",
      "          total_loss: 0.2656368977079789\n",
      "          vf_explained_var: 0.9391801953315735\n",
      "          vf_loss: 0.293711357599213\n",
      "    num_agent_steps_sampled: 287712\n",
      "    num_agent_steps_trained: 287712\n",
      "    num_steps_sampled: 287712\n",
      "    num_steps_trained: 287712\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87941176470588\n",
      "    ram_util_percent: 30.573529411764707\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044342528957889746\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.442963903134295\n",
      "    mean_inference_ms: 2.48612793209291\n",
      "    mean_raw_obs_processing_ms: 1.92542094319923\n",
      "  time_since_restore: 3796.3193259239197\n",
      "  time_this_iter_s: 23.76524543762207\n",
      "  time_total_s: 3796.3193259239197\n",
      "  timers:\n",
      "    learn_throughput: 1157.235\n",
      "    learn_time_ms: 1726.529\n",
      "    load_throughput: 59673.127\n",
      "    load_time_ms: 33.482\n",
      "    sample_throughput: 80.394\n",
      "    sample_time_ms: 24852.536\n",
      "    update_time_ms: 8.418\n",
      "  timestamp: 1636433312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 287712\n",
      "  training_iteration: 144\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         3796.32</td><td style=\"text-align: right;\">287712</td><td style=\"text-align: right;\">  7.1365</td><td style=\"text-align: right;\">               12.18</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">            110.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 289710\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-48-55\n",
      "  done: false\n",
      "  episode_len_mean: 112.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.18000000000002\n",
      "  episode_reward_mean: 7.26650000000002\n",
      "  episode_reward_min: 2.780000000000011\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2660\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.532057000909533\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016194177552740364\n",
      "          policy_loss: -0.02426821037772156\n",
      "          total_loss: 0.4228643010592177\n",
      "          vf_explained_var: 0.8915917277336121\n",
      "          vf_loss: 0.45152201194848335\n",
      "    num_agent_steps_sampled: 289710\n",
      "    num_agent_steps_trained: 289710\n",
      "    num_steps_sampled: 289710\n",
      "    num_steps_trained: 289710\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33437500000001\n",
      "    ram_util_percent: 30.58125\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433946599595821\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.42916310733849\n",
      "    mean_inference_ms: 2.4859948532677496\n",
      "    mean_raw_obs_processing_ms: 1.91701911696323\n",
      "  time_since_restore: 3818.995410680771\n",
      "  time_this_iter_s: 22.676084756851196\n",
      "  time_total_s: 3818.995410680771\n",
      "  timers:\n",
      "    learn_throughput: 1158.791\n",
      "    learn_time_ms: 1724.21\n",
      "    load_throughput: 59716.457\n",
      "    load_time_ms: 33.458\n",
      "    sample_throughput: 85.826\n",
      "    sample_time_ms: 23279.711\n",
      "    update_time_ms: 8.895\n",
      "  timestamp: 1636433335\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 289710\n",
      "  training_iteration: 145\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">            3819</td><td style=\"text-align: right;\">289710</td><td style=\"text-align: right;\">  7.2665</td><td style=\"text-align: right;\">               12.18</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">            112.23</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 291708\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-49-19\n",
      "  done: false\n",
      "  episode_len_mean: 113.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.040000000000022\n",
      "  episode_reward_mean: 7.25010000000002\n",
      "  episode_reward_min: 2.780000000000011\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2676\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.521150419257936\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013698381829426847\n",
      "          policy_loss: -0.05067432356022653\n",
      "          total_loss: 0.3352051391621076\n",
      "          vf_explained_var: 0.8979358673095703\n",
      "          vf_loss: 0.3918445561613355\n",
      "    num_agent_steps_sampled: 291708\n",
      "    num_agent_steps_trained: 291708\n",
      "    num_steps_sampled: 291708\n",
      "    num_steps_trained: 291708\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.81428571428572\n",
      "    ram_util_percent: 30.514285714285716\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433414749215656\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.41657884663211\n",
      "    mean_inference_ms: 2.485850650436023\n",
      "    mean_raw_obs_processing_ms: 1.9090015506114246\n",
      "  time_since_restore: 3843.573599100113\n",
      "  time_this_iter_s: 24.57818841934204\n",
      "  time_total_s: 3843.573599100113\n",
      "  timers:\n",
      "    learn_throughput: 1157.424\n",
      "    learn_time_ms: 1726.247\n",
      "    load_throughput: 59875.218\n",
      "    load_time_ms: 33.369\n",
      "    sample_throughput: 85.511\n",
      "    sample_time_ms: 23365.364\n",
      "    update_time_ms: 8.217\n",
      "  timestamp: 1636433359\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 291708\n",
      "  training_iteration: 146\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         3843.57</td><td style=\"text-align: right;\">291708</td><td style=\"text-align: right;\">  7.2501</td><td style=\"text-align: right;\">               12.04</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">            113.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 293706\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-49-44\n",
      "  done: false\n",
      "  episode_len_mean: 111.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.040000000000022\n",
      "  episode_reward_mean: 7.236800000000019\n",
      "  episode_reward_min: 2.780000000000011\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2695\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5512729099818638\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010245937050272274\n",
      "          policy_loss: 0.0067382377971495905\n",
      "          total_loss: 0.3661775347732362\n",
      "          vf_explained_var: 0.8908097147941589\n",
      "          vf_loss: 0.3680360197311356\n",
      "    num_agent_steps_sampled: 293706\n",
      "    num_agent_steps_trained: 293706\n",
      "    num_steps_sampled: 293706\n",
      "    num_steps_trained: 293706\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84857142857145\n",
      "    ram_util_percent: 30.502857142857142\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434176153389714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.406345243245145\n",
      "    mean_inference_ms: 2.485802395192627\n",
      "    mean_raw_obs_processing_ms: 1.8997297034008855\n",
      "  time_since_restore: 3868.024299144745\n",
      "  time_this_iter_s: 24.450700044631958\n",
      "  time_total_s: 3868.024299144745\n",
      "  timers:\n",
      "    learn_throughput: 1158.975\n",
      "    learn_time_ms: 1723.937\n",
      "    load_throughput: 59642.633\n",
      "    load_time_ms: 33.5\n",
      "    sample_throughput: 91.246\n",
      "    sample_time_ms: 21896.894\n",
      "    update_time_ms: 7.668\n",
      "  timestamp: 1636433384\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 293706\n",
      "  training_iteration: 147\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         3868.02</td><td style=\"text-align: right;\">293706</td><td style=\"text-align: right;\">  7.2368</td><td style=\"text-align: right;\">               12.04</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">            111.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 295704\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-50-07\n",
      "  done: false\n",
      "  episode_len_mean: 112.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.20000000000002\n",
      "  episode_reward_mean: 7.098500000000021\n",
      "  episode_reward_min: 2.4600000000000177\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2713\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5850680657795497\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008900745059193176\n",
      "          policy_loss: -0.023339697452528136\n",
      "          total_loss: 0.2256933876446315\n",
      "          vf_explained_var: 0.9494208693504333\n",
      "          vf_loss: 0.25887576472901164\n",
      "    num_agent_steps_sampled: 295704\n",
      "    num_agent_steps_trained: 295704\n",
      "    num_steps_sampled: 295704\n",
      "    num_steps_trained: 295704\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97878787878787\n",
      "    ram_util_percent: 30.493939393939396\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433669045278233\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.400860214343815\n",
      "    mean_inference_ms: 2.485502249550214\n",
      "    mean_raw_obs_processing_ms: 1.8913298475649345\n",
      "  time_since_restore: 3891.107882976532\n",
      "  time_this_iter_s: 23.08358383178711\n",
      "  time_total_s: 3891.107882976532\n",
      "  timers:\n",
      "    learn_throughput: 1159.809\n",
      "    learn_time_ms: 1722.698\n",
      "    load_throughput: 59622.689\n",
      "    load_time_ms: 33.511\n",
      "    sample_throughput: 91.562\n",
      "    sample_time_ms: 21821.258\n",
      "    update_time_ms: 7.566\n",
      "  timestamp: 1636433407\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 295704\n",
      "  training_iteration: 148\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         3891.11</td><td style=\"text-align: right;\">295704</td><td style=\"text-align: right;\">  7.0985</td><td style=\"text-align: right;\">                12.2</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            112.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 297702\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-50-31\n",
      "  done: false\n",
      "  episode_len_mean: 113.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.440000000000026\n",
      "  episode_reward_mean: 7.14150000000002\n",
      "  episode_reward_min: 2.4600000000000177\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2730\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.516264678183056\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010684777631725198\n",
      "          policy_loss: -0.031145275561582475\n",
      "          total_loss: 0.1359033298279558\n",
      "          vf_explained_var: 0.9624699354171753\n",
      "          vf_loss: 0.17499902755731628\n",
      "    num_agent_steps_sampled: 297702\n",
      "    num_agent_steps_trained: 297702\n",
      "    num_steps_sampled: 297702\n",
      "    num_steps_trained: 297702\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.02058823529413\n",
      "    ram_util_percent: 30.46470588235294\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443236544429995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.389164949530706\n",
      "    mean_inference_ms: 2.4851002829789515\n",
      "    mean_raw_obs_processing_ms: 1.8831486090640146\n",
      "  time_since_restore: 3915.1467237472534\n",
      "  time_this_iter_s: 24.038840770721436\n",
      "  time_total_s: 3915.1467237472534\n",
      "  timers:\n",
      "    learn_throughput: 1160.192\n",
      "    learn_time_ms: 1722.129\n",
      "    load_throughput: 60246.569\n",
      "    load_time_ms: 33.164\n",
      "    sample_throughput: 91.547\n",
      "    sample_time_ms: 21824.866\n",
      "    update_time_ms: 8.243\n",
      "  timestamp: 1636433431\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 297702\n",
      "  training_iteration: 149\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         3915.15</td><td style=\"text-align: right;\">297702</td><td style=\"text-align: right;\">  7.1415</td><td style=\"text-align: right;\">               13.44</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            113.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 299700\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-50-54\n",
      "  done: false\n",
      "  episode_len_mean: 113.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.440000000000026\n",
      "  episode_reward_mean: 6.934200000000021\n",
      "  episode_reward_min: 2.4600000000000177\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2747\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4821203169368562\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.018334382429543643\n",
      "          policy_loss: 0.006048522321950822\n",
      "          total_loss: 0.4832700554902355\n",
      "          vf_explained_var: 0.8905865550041199\n",
      "          vf_loss: 0.479667027897778\n",
      "    num_agent_steps_sampled: 299700\n",
      "    num_agent_steps_trained: 299700\n",
      "    num_steps_sampled: 299700\n",
      "    num_steps_trained: 299700\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.75\n",
      "    ram_util_percent: 30.440625\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044361233782773055\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.364348866550067\n",
      "    mean_inference_ms: 2.4854741723656195\n",
      "    mean_raw_obs_processing_ms: 1.8747369018623579\n",
      "  time_since_restore: 3937.5921432971954\n",
      "  time_this_iter_s: 22.445419549942017\n",
      "  time_total_s: 3937.5921432971954\n",
      "  timers:\n",
      "    learn_throughput: 1159.63\n",
      "    learn_time_ms: 1722.963\n",
      "    load_throughput: 60343.266\n",
      "    load_time_ms: 33.111\n",
      "    sample_throughput: 91.755\n",
      "    sample_time_ms: 21775.282\n",
      "    update_time_ms: 8.537\n",
      "  timestamp: 1636433454\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 299700\n",
      "  training_iteration: 150\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         3937.59</td><td style=\"text-align: right;\">299700</td><td style=\"text-align: right;\">  6.9342</td><td style=\"text-align: right;\">               13.44</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            113.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 301698\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-51-17\n",
      "  done: false\n",
      "  episode_len_mean: 113.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.440000000000026\n",
      "  episode_reward_mean: 6.9538000000000215\n",
      "  episode_reward_min: 2.4600000000000177\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2764\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6322251546950568\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010891701158161425\n",
      "          policy_loss: 0.0019428902793498265\n",
      "          total_loss: 0.2993443801999092\n",
      "          vf_explained_var: 0.9232727289199829\n",
      "          vf_loss: 0.30637184569523446\n",
      "    num_agent_steps_sampled: 301698\n",
      "    num_agent_steps_trained: 301698\n",
      "    num_steps_sampled: 301698\n",
      "    num_steps_trained: 301698\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.40882352941175\n",
      "    ram_util_percent: 30.41176470588235\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435422990348266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.355541037855584\n",
      "    mean_inference_ms: 2.4851580641710393\n",
      "    mean_raw_obs_processing_ms: 1.86669693350641\n",
      "  time_since_restore: 3961.219009399414\n",
      "  time_this_iter_s: 23.626866102218628\n",
      "  time_total_s: 3961.219009399414\n",
      "  timers:\n",
      "    learn_throughput: 1159.417\n",
      "    learn_time_ms: 1723.279\n",
      "    load_throughput: 59897.258\n",
      "    load_time_ms: 33.357\n",
      "    sample_throughput: 91.164\n",
      "    sample_time_ms: 21916.627\n",
      "    update_time_ms: 8.445\n",
      "  timestamp: 1636433477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 301698\n",
      "  training_iteration: 151\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         3961.22</td><td style=\"text-align: right;\">301698</td><td style=\"text-align: right;\">  6.9538</td><td style=\"text-align: right;\">               13.44</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            113.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 303696\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-51-42\n",
      "  done: false\n",
      "  episode_len_mean: 113.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.440000000000026\n",
      "  episode_reward_mean: 7.052800000000018\n",
      "  episode_reward_min: 2.4600000000000177\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2784\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5269176046053567\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008633343899449166\n",
      "          policy_loss: -0.010893575563317253\n",
      "          total_loss: 0.18465427277343613\n",
      "          vf_explained_var: 0.9481016397476196\n",
      "          vf_loss: 0.2049895176930087\n",
      "    num_agent_steps_sampled: 303696\n",
      "    num_agent_steps_trained: 303696\n",
      "    num_steps_sampled: 303696\n",
      "    num_steps_trained: 303696\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94857142857146\n",
      "    ram_util_percent: 30.39428571428571\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434200178104154\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.34158447874536\n",
      "    mean_inference_ms: 2.484769802759156\n",
      "    mean_raw_obs_processing_ms: 1.8576068940128443\n",
      "  time_since_restore: 3985.602072238922\n",
      "  time_this_iter_s: 24.383062839508057\n",
      "  time_total_s: 3985.602072238922\n",
      "  timers:\n",
      "    learn_throughput: 1160.256\n",
      "    learn_time_ms: 1722.034\n",
      "    load_throughput: 59848.237\n",
      "    load_time_ms: 33.384\n",
      "    sample_throughput: 90.742\n",
      "    sample_time_ms: 22018.401\n",
      "    update_time_ms: 8.811\n",
      "  timestamp: 1636433502\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 303696\n",
      "  training_iteration: 152\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">          3985.6</td><td style=\"text-align: right;\">303696</td><td style=\"text-align: right;\">  7.0528</td><td style=\"text-align: right;\">               13.44</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            113.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 305694\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-52-05\n",
      "  done: false\n",
      "  episode_len_mean: 113.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.440000000000026\n",
      "  episode_reward_mean: 7.1113000000000195\n",
      "  episode_reward_min: -1.1200000000000008\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2801\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4868015300659907\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.020830810458364987\n",
      "          policy_loss: 0.016539094508403823\n",
      "          total_loss: 0.3756082451081879\n",
      "          vf_explained_var: 0.938480794429779\n",
      "          vf_loss: 0.3598763670949709\n",
      "    num_agent_steps_sampled: 305694\n",
      "    num_agent_steps_trained: 305694\n",
      "    num_steps_sampled: 305694\n",
      "    num_steps_trained: 305694\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.81818181818181\n",
      "    ram_util_percent: 30.36060606060606\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433042825565666\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.328808119110153\n",
      "    mean_inference_ms: 2.4844251960802506\n",
      "    mean_raw_obs_processing_ms: 1.8498759305747416\n",
      "  time_since_restore: 4008.826730489731\n",
      "  time_this_iter_s: 23.224658250808716\n",
      "  time_total_s: 4008.826730489731\n",
      "  timers:\n",
      "    learn_throughput: 1158.873\n",
      "    learn_time_ms: 1724.089\n",
      "    load_throughput: 59439.618\n",
      "    load_time_ms: 33.614\n",
      "    sample_throughput: 91.437\n",
      "    sample_time_ms: 21851.211\n",
      "    update_time_ms: 9.226\n",
      "  timestamp: 1636433525\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 305694\n",
      "  training_iteration: 153\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         4008.83</td><td style=\"text-align: right;\">305694</td><td style=\"text-align: right;\">  7.1113</td><td style=\"text-align: right;\">               13.44</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">            113.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 307692\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-52-28\n",
      "  done: false\n",
      "  episode_len_mean: 112.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.010000000000023\n",
      "  episode_reward_mean: 7.21200000000002\n",
      "  episode_reward_min: -1.1200000000000008\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2818\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5523657764707293\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006987610134272464\n",
      "          policy_loss: -0.05021489777025722\n",
      "          total_loss: 0.18390590433208714\n",
      "          vf_explained_var: 0.9327701926231384\n",
      "          vf_loss: 0.24256950308169636\n",
      "    num_agent_steps_sampled: 307692\n",
      "    num_agent_steps_trained: 307692\n",
      "    num_steps_sampled: 307692\n",
      "    num_steps_trained: 307692\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8125\n",
      "    ram_util_percent: 30.321875\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044343945575728086\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.315433930775956\n",
      "    mean_inference_ms: 2.484463692445397\n",
      "    mean_raw_obs_processing_ms: 1.8421839838710223\n",
      "  time_since_restore: 4031.516199827194\n",
      "  time_this_iter_s: 22.68946933746338\n",
      "  time_total_s: 4031.516199827194\n",
      "  timers:\n",
      "    learn_throughput: 1160.36\n",
      "    learn_time_ms: 1721.879\n",
      "    load_throughput: 59348.819\n",
      "    load_time_ms: 33.665\n",
      "    sample_throughput: 91.881\n",
      "    sample_time_ms: 21745.543\n",
      "    update_time_ms: 9.487\n",
      "  timestamp: 1636433548\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 307692\n",
      "  training_iteration: 154\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         4031.52</td><td style=\"text-align: right;\">307692</td><td style=\"text-align: right;\">   7.212</td><td style=\"text-align: right;\">               14.01</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">            112.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 309690\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-52-51\n",
      "  done: false\n",
      "  episode_len_mean: 113.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.010000000000023\n",
      "  episode_reward_mean: 7.0423000000000195\n",
      "  episode_reward_min: -1.1200000000000008\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2835\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.503391959553673\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009029799883548325\n",
      "          policy_loss: -0.001989179015869186\n",
      "          total_loss: 0.18925794881014596\n",
      "          vf_explained_var: 0.9331493377685547\n",
      "          vf_loss: 0.19713837486647423\n",
      "    num_agent_steps_sampled: 309690\n",
      "    num_agent_steps_trained: 309690\n",
      "    num_steps_sampled: 309690\n",
      "    num_steps_trained: 309690\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.83823529411765\n",
      "    ram_util_percent: 30.308823529411764\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044365704346245295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.29736841023867\n",
      "    mean_inference_ms: 2.4846204900383864\n",
      "    mean_raw_obs_processing_ms: 1.8345552578396178\n",
      "  time_since_restore: 4054.991424560547\n",
      "  time_this_iter_s: 23.47522473335266\n",
      "  time_total_s: 4054.991424560547\n",
      "  timers:\n",
      "    learn_throughput: 1160.862\n",
      "    learn_time_ms: 1721.134\n",
      "    load_throughput: 56664.837\n",
      "    load_time_ms: 35.26\n",
      "    sample_throughput: 91.55\n",
      "    sample_time_ms: 21824.21\n",
      "    update_time_ms: 9.417\n",
      "  timestamp: 1636433571\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 309690\n",
      "  training_iteration: 155\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         4054.99</td><td style=\"text-align: right;\">309690</td><td style=\"text-align: right;\">  7.0423</td><td style=\"text-align: right;\">               14.01</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">            113.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 311688\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-53-40\n",
      "  done: false\n",
      "  episode_len_mean: 111.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.010000000000023\n",
      "  episode_reward_mean: 7.1597000000000195\n",
      "  episode_reward_min: -1.1200000000000008\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 2855\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4992290275437492\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01137758487694388\n",
      "          policy_loss: -0.03889257393422581\n",
      "          total_loss: 0.4662999544647478\n",
      "          vf_explained_var: 0.8952781558036804\n",
      "          vf_loss: 0.5086650129230249\n",
      "    num_agent_steps_sampled: 311688\n",
      "    num_agent_steps_trained: 311688\n",
      "    num_steps_sampled: 311688\n",
      "    num_steps_trained: 311688\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.95714285714286\n",
      "    ram_util_percent: 30.238571428571426\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434200385029607\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.288497975920595\n",
      "    mean_inference_ms: 2.483906462917611\n",
      "    mean_raw_obs_processing_ms: 1.8476879022942194\n",
      "  time_since_restore: 4103.7452480793\n",
      "  time_this_iter_s: 48.75382351875305\n",
      "  time_total_s: 4103.7452480793\n",
      "  timers:\n",
      "    learn_throughput: 1161.091\n",
      "    learn_time_ms: 1720.796\n",
      "    load_throughput: 56463.1\n",
      "    load_time_ms: 35.386\n",
      "    sample_throughput: 82.422\n",
      "    sample_time_ms: 24241.169\n",
      "    update_time_ms: 10.147\n",
      "  timestamp: 1636433620\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 311688\n",
      "  training_iteration: 156\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         4103.75</td><td style=\"text-align: right;\">311688</td><td style=\"text-align: right;\">  7.1597</td><td style=\"text-align: right;\">               14.01</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">            111.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 313686\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-54-17\n",
      "  done: false\n",
      "  episode_len_mean: 110.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.010000000000023\n",
      "  episode_reward_mean: 6.96670000000002\n",
      "  episode_reward_min: -1.1200000000000008\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2873\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4784684430985224\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01256172972020859\n",
      "          policy_loss: 0.00024830973928882964\n",
      "          total_loss: 0.3917773618229798\n",
      "          vf_explained_var: 0.9027294516563416\n",
      "          vf_loss: 0.3935949812332789\n",
      "    num_agent_steps_sampled: 313686\n",
      "    num_agent_steps_trained: 313686\n",
      "    num_steps_sampled: 313686\n",
      "    num_steps_trained: 313686\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.02830188679248\n",
      "    ram_util_percent: 30.14528301886793\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044345186213213116\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.265737974982713\n",
      "    mean_inference_ms: 2.4836890490475816\n",
      "    mean_raw_obs_processing_ms: 1.8673243536977184\n",
      "  time_since_restore: 4140.784156084061\n",
      "  time_this_iter_s: 37.03890800476074\n",
      "  time_total_s: 4140.784156084061\n",
      "  timers:\n",
      "    learn_throughput: 1159.236\n",
      "    learn_time_ms: 1723.549\n",
      "    load_throughput: 56581.853\n",
      "    load_time_ms: 35.312\n",
      "    sample_throughput: 78.361\n",
      "    sample_time_ms: 25497.472\n",
      "    update_time_ms: 10.43\n",
      "  timestamp: 1636433657\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 313686\n",
      "  training_iteration: 157\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         4140.78</td><td style=\"text-align: right;\">313686</td><td style=\"text-align: right;\">  6.9667</td><td style=\"text-align: right;\">               14.01</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">            110.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 315684\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-54-41\n",
      "  done: false\n",
      "  episode_len_mean: 110.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.010000000000023\n",
      "  episode_reward_mean: 7.101600000000019\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2892\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5275228250594366\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00897992144954299\n",
      "          policy_loss: -0.07447296176992711\n",
      "          total_loss: 0.133515510424262\n",
      "          vf_explained_var: 0.9504634141921997\n",
      "          vf_loss: 0.21417153030633926\n",
      "    num_agent_steps_sampled: 315684\n",
      "    num_agent_steps_trained: 315684\n",
      "    num_steps_sampled: 315684\n",
      "    num_steps_trained: 315684\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.28787878787877\n",
      "    ram_util_percent: 30.345454545454544\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437420296417805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.245809227815183\n",
      "    mean_inference_ms: 2.4836641829495063\n",
      "    mean_raw_obs_processing_ms: 1.8880810110500121\n",
      "  time_since_restore: 4164.369576692581\n",
      "  time_this_iter_s: 23.585420608520508\n",
      "  time_total_s: 4164.369576692581\n",
      "  timers:\n",
      "    learn_throughput: 1158.983\n",
      "    learn_time_ms: 1723.925\n",
      "    load_throughput: 56442.526\n",
      "    load_time_ms: 35.399\n",
      "    sample_throughput: 78.21\n",
      "    sample_time_ms: 25546.462\n",
      "    update_time_ms: 11.307\n",
      "  timestamp: 1636433681\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 315684\n",
      "  training_iteration: 158\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         4164.37</td><td style=\"text-align: right;\">315684</td><td style=\"text-align: right;\">  7.1016</td><td style=\"text-align: right;\">               14.01</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             110.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 317682\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-55-03\n",
      "  done: false\n",
      "  episode_len_mean: 111.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.010000000000023\n",
      "  episode_reward_mean: 7.0770000000000195\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 16\n",
      "  episodes_total: 2908\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4483274618784587\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009985652372088942\n",
      "          policy_loss: -0.03115958110207603\n",
      "          total_loss: 0.35482489093251174\n",
      "          vf_explained_var: 0.895455002784729\n",
      "          vf_loss: 0.39035727374610446\n",
      "    num_agent_steps_sampled: 317682\n",
      "    num_agent_steps_trained: 317682\n",
      "    num_steps_sampled: 317682\n",
      "    num_steps_trained: 317682\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.20625000000001\n",
      "    ram_util_percent: 30.43125\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044362589115361145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.226030651964685\n",
      "    mean_inference_ms: 2.483175623567998\n",
      "    mean_raw_obs_processing_ms: 1.9054487325192448\n",
      "  time_since_restore: 4186.296464920044\n",
      "  time_this_iter_s: 21.92688822746277\n",
      "  time_total_s: 4186.296464920044\n",
      "  timers:\n",
      "    learn_throughput: 1159.496\n",
      "    learn_time_ms: 1723.163\n",
      "    load_throughput: 55943.28\n",
      "    load_time_ms: 35.715\n",
      "    sample_throughput: 78.859\n",
      "    sample_time_ms: 25336.225\n",
      "    update_time_ms: 10.857\n",
      "  timestamp: 1636433703\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 317682\n",
      "  training_iteration: 159\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">          4186.3</td><td style=\"text-align: right;\">317682</td><td style=\"text-align: right;\">   7.077</td><td style=\"text-align: right;\">               14.01</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            111.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 319680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-55-26\n",
      "  done: false\n",
      "  episode_len_mean: 111.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000019\n",
      "  episode_reward_mean: 6.98970000000002\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2926\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4380874179658436\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00802669545776622\n",
      "          policy_loss: -0.0060116816489469435\n",
      "          total_loss: 0.25200925370057425\n",
      "          vf_explained_var: 0.947057843208313\n",
      "          vf_loss: 0.26427478141018323\n",
      "    num_agent_steps_sampled: 319680\n",
      "    num_agent_steps_trained: 319680\n",
      "    num_steps_sampled: 319680\n",
      "    num_steps_trained: 319680\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.32058823529412\n",
      "    ram_util_percent: 30.523529411764706\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437944396347555\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.201195260533723\n",
      "    mean_inference_ms: 2.4831286007709115\n",
      "    mean_raw_obs_processing_ms: 1.9248177146317011\n",
      "  time_since_restore: 4210.107128381729\n",
      "  time_this_iter_s: 23.81066346168518\n",
      "  time_total_s: 4210.107128381729\n",
      "  timers:\n",
      "    learn_throughput: 1159.224\n",
      "    learn_time_ms: 1723.567\n",
      "    load_throughput: 56020.73\n",
      "    load_time_ms: 35.665\n",
      "    sample_throughput: 78.435\n",
      "    sample_time_ms: 25473.222\n",
      "    update_time_ms: 10.109\n",
      "  timestamp: 1636433726\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319680\n",
      "  training_iteration: 160\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         4210.11</td><td style=\"text-align: right;\">319680</td><td style=\"text-align: right;\">  6.9897</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            111.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 321678\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-55-50\n",
      "  done: false\n",
      "  episode_len_mean: 110.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000019\n",
      "  episode_reward_mean: 6.933100000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2945\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.560276704742795\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01072091653046831\n",
      "          policy_loss: -0.01980140448680946\n",
      "          total_loss: 0.2967786318489483\n",
      "          vf_explained_var: 0.9236714839935303\n",
      "          vf_loss: 0.32132787108421323\n",
      "    num_agent_steps_sampled: 321678\n",
      "    num_agent_steps_trained: 321678\n",
      "    num_steps_sampled: 321678\n",
      "    num_steps_trained: 321678\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99705882352941\n",
      "    ram_util_percent: 30.558823529411764\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044370864893928184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.188463351751196\n",
      "    mean_inference_ms: 2.4826640093289045\n",
      "    mean_raw_obs_processing_ms: 1.9394326225039231\n",
      "  time_since_restore: 4234.158757209778\n",
      "  time_this_iter_s: 24.051628828048706\n",
      "  time_total_s: 4234.158757209778\n",
      "  timers:\n",
      "    learn_throughput: 1158.733\n",
      "    learn_time_ms: 1724.297\n",
      "    load_throughput: 55178.363\n",
      "    load_time_ms: 36.21\n",
      "    sample_throughput: 78.309\n",
      "    sample_time_ms: 25514.292\n",
      "    update_time_ms: 10.433\n",
      "  timestamp: 1636433750\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 321678\n",
      "  training_iteration: 161\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">         4234.16</td><td style=\"text-align: right;\">321678</td><td style=\"text-align: right;\">  6.9331</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            110.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 323676\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-56-14\n",
      "  done: false\n",
      "  episode_len_mean: 112.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000019\n",
      "  episode_reward_mean: 7.123500000000022\n",
      "  episode_reward_min: 2.5700000000000127\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 2962\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5153870446341378\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00833727192801034\n",
      "          policy_loss: -0.00889404687498297\n",
      "          total_loss: 0.24538212862043154\n",
      "          vf_explained_var: 0.9269796013832092\n",
      "          vf_loss: 0.2609885555292879\n",
      "    num_agent_steps_sampled: 323676\n",
      "    num_agent_steps_trained: 323676\n",
      "    num_steps_sampled: 323676\n",
      "    num_steps_trained: 323676\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73939393939395\n",
      "    ram_util_percent: 30.62424242424243\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434908532106213\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.17008947254064\n",
      "    mean_inference_ms: 2.482275137930897\n",
      "    mean_raw_obs_processing_ms: 1.9316618939503138\n",
      "  time_since_restore: 4257.680923461914\n",
      "  time_this_iter_s: 23.52216625213623\n",
      "  time_total_s: 4257.680923461914\n",
      "  timers:\n",
      "    learn_throughput: 1158.15\n",
      "    learn_time_ms: 1725.165\n",
      "    load_throughput: 55060.14\n",
      "    load_time_ms: 36.288\n",
      "    sample_throughput: 78.577\n",
      "    sample_time_ms: 25427.196\n",
      "    update_time_ms: 10.477\n",
      "  timestamp: 1636433774\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 323676\n",
      "  training_iteration: 162\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">         4257.68</td><td style=\"text-align: right;\">323676</td><td style=\"text-align: right;\">  7.1235</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                2.57</td><td style=\"text-align: right;\">             112.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 325674\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-56-38\n",
      "  done: false\n",
      "  episode_len_mean: 112.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000019\n",
      "  episode_reward_mean: 7.37010000000002\n",
      "  episode_reward_min: 2.5700000000000127\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 2980\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5539642033122836\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008979231877874255\n",
      "          policy_loss: -0.04722694231285935\n",
      "          total_loss: 0.18591425248554774\n",
      "          vf_explained_var: 0.9536747336387634\n",
      "          vf_loss: 0.23958936447188967\n",
      "    num_agent_steps_sampled: 325674\n",
      "    num_agent_steps_trained: 325674\n",
      "    num_steps_sampled: 325674\n",
      "    num_steps_trained: 325674\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.67647058823529\n",
      "    ram_util_percent: 30.63823529411765\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443297973901114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.161976751801795\n",
      "    mean_inference_ms: 2.481869140717198\n",
      "    mean_raw_obs_processing_ms: 1.9236674242714764\n",
      "  time_since_restore: 4281.187202215195\n",
      "  time_this_iter_s: 23.50627875328064\n",
      "  time_total_s: 4281.187202215195\n",
      "  timers:\n",
      "    learn_throughput: 1160.003\n",
      "    learn_time_ms: 1722.409\n",
      "    load_throughput: 55303.444\n",
      "    load_time_ms: 36.128\n",
      "    sample_throughput: 78.483\n",
      "    sample_time_ms: 25457.744\n",
      "    update_time_ms: 11.058\n",
      "  timestamp: 1636433798\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 325674\n",
      "  training_iteration: 163\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         4281.19</td><td style=\"text-align: right;\">325674</td><td style=\"text-align: right;\">  7.3701</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                2.57</td><td style=\"text-align: right;\">            112.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 327672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-57-02\n",
      "  done: false\n",
      "  episode_len_mean: 110.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000019\n",
      "  episode_reward_mean: 7.13680000000002\n",
      "  episode_reward_min: 2.5700000000000127\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 2999\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4830062661852155\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008812424608373642\n",
      "          policy_loss: -0.025478823926477205\n",
      "          total_loss: 0.30625487989967776\n",
      "          vf_explained_var: 0.9288211464881897\n",
      "          vf_loss: 0.337641187508901\n",
      "    num_agent_steps_sampled: 327672\n",
      "    num_agent_steps_trained: 327672\n",
      "    num_steps_sampled: 327672\n",
      "    num_steps_trained: 327672\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00571428571428\n",
      "    ram_util_percent: 30.614285714285714\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433845341799156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.153046020613992\n",
      "    mean_inference_ms: 2.4818758529071325\n",
      "    mean_raw_obs_processing_ms: 1.9153096849788964\n",
      "  time_since_restore: 4305.436215639114\n",
      "  time_this_iter_s: 24.249013423919678\n",
      "  time_total_s: 4305.436215639114\n",
      "  timers:\n",
      "    learn_throughput: 1158.948\n",
      "    learn_time_ms: 1723.978\n",
      "    load_throughput: 55340.622\n",
      "    load_time_ms: 36.104\n",
      "    sample_throughput: 78.007\n",
      "    sample_time_ms: 25613.217\n",
      "    update_time_ms: 9.886\n",
      "  timestamp: 1636433822\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 327672\n",
      "  training_iteration: 164\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         4305.44</td><td style=\"text-align: right;\">327672</td><td style=\"text-align: right;\">  7.1368</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                2.57</td><td style=\"text-align: right;\">            110.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 329670\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-57-26\n",
      "  done: false\n",
      "  episode_len_mean: 111.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000019\n",
      "  episode_reward_mean: 7.269100000000019\n",
      "  episode_reward_min: 2.5700000000000127\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3017\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5446481324377515\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010163063325630007\n",
      "          policy_loss: 0.0061526678679954434\n",
      "          total_loss: 0.2924919461210569\n",
      "          vf_explained_var: 0.9194092750549316\n",
      "          vf_loss: 0.29149565739291056\n",
      "    num_agent_steps_sampled: 329670\n",
      "    num_agent_steps_trained: 329670\n",
      "    num_steps_sampled: 329670\n",
      "    num_steps_trained: 329670\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92571428571429\n",
      "    ram_util_percent: 30.64857142857143\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044335556359039234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.146647745284525\n",
      "    mean_inference_ms: 2.4817854345017984\n",
      "    mean_raw_obs_processing_ms: 1.9077326704036304\n",
      "  time_since_restore: 4329.990116357803\n",
      "  time_this_iter_s: 24.553900718688965\n",
      "  time_total_s: 4329.990116357803\n",
      "  timers:\n",
      "    learn_throughput: 1158.117\n",
      "    learn_time_ms: 1725.215\n",
      "    load_throughput: 51725.471\n",
      "    load_time_ms: 38.627\n",
      "    sample_throughput: 77.688\n",
      "    sample_time_ms: 25718.339\n",
      "    update_time_ms: 9.169\n",
      "  timestamp: 1636433846\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 329670\n",
      "  training_iteration: 165\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         4329.99</td><td style=\"text-align: right;\">329670</td><td style=\"text-align: right;\">  7.2691</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                2.57</td><td style=\"text-align: right;\">             111.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 331668\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-57-51\n",
      "  done: false\n",
      "  episode_len_mean: 108.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.770000000000026\n",
      "  episode_reward_mean: 7.061700000000019\n",
      "  episode_reward_min: 2.580000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3037\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4848793012755257\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006816112331619117\n",
      "          policy_loss: -0.02886978542166097\n",
      "          total_loss: 0.1523721597246116\n",
      "          vf_explained_var: 0.9439454078674316\n",
      "          vf_loss: 0.18918942418836412\n",
      "    num_agent_steps_sampled: 331668\n",
      "    num_agent_steps_trained: 331668\n",
      "    num_steps_sampled: 331668\n",
      "    num_steps_trained: 331668\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.57428571428571\n",
      "    ram_util_percent: 30.545714285714283\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431874585028075\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.151823339655902\n",
      "    mean_inference_ms: 2.481453559603752\n",
      "    mean_raw_obs_processing_ms: 1.899860958838696\n",
      "  time_since_restore: 4354.813766479492\n",
      "  time_this_iter_s: 24.823650121688843\n",
      "  time_total_s: 4354.813766479492\n",
      "  timers:\n",
      "    learn_throughput: 1158.771\n",
      "    learn_time_ms: 1724.24\n",
      "    load_throughput: 51747.669\n",
      "    load_time_ms: 38.61\n",
      "    sample_throughput: 85.652\n",
      "    sample_time_ms: 23327.006\n",
      "    update_time_ms: 8.55\n",
      "  timestamp: 1636433871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 331668\n",
      "  training_iteration: 166\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         4354.81</td><td style=\"text-align: right;\">331668</td><td style=\"text-align: right;\">  7.0617</td><td style=\"text-align: right;\">               13.77</td><td style=\"text-align: right;\">                2.58</td><td style=\"text-align: right;\">            108.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 333666\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-58-15\n",
      "  done: false\n",
      "  episode_len_mean: 108.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.770000000000026\n",
      "  episode_reward_mean: 7.056100000000018\n",
      "  episode_reward_min: 2.580000000000016\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3055\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5227211515108745\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01371973551438755\n",
      "          policy_loss: -0.04439199907439095\n",
      "          total_loss: 0.2742430556033339\n",
      "          vf_explained_var: 0.9174363613128662\n",
      "          vf_loss: 0.3199710307376725\n",
      "    num_agent_steps_sampled: 333666\n",
      "    num_agent_steps_trained: 333666\n",
      "    num_steps_sampled: 333666\n",
      "    num_steps_trained: 333666\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.50882352941179\n",
      "    ram_util_percent: 30.52058823529412\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044338412416157\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.149796024215615\n",
      "    mean_inference_ms: 2.481792913453637\n",
      "    mean_raw_obs_processing_ms: 1.892644893089267\n",
      "  time_since_restore: 4378.515930652618\n",
      "  time_this_iter_s: 23.70216417312622\n",
      "  time_total_s: 4378.515930652618\n",
      "  timers:\n",
      "    learn_throughput: 1161.305\n",
      "    learn_time_ms: 1720.478\n",
      "    load_throughput: 52052.701\n",
      "    load_time_ms: 38.384\n",
      "    sample_throughput: 90.83\n",
      "    sample_time_ms: 21997.084\n",
      "    update_time_ms: 8.424\n",
      "  timestamp: 1636433895\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 333666\n",
      "  training_iteration: 167\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         4378.52</td><td style=\"text-align: right;\">333666</td><td style=\"text-align: right;\">  7.0561</td><td style=\"text-align: right;\">               13.77</td><td style=\"text-align: right;\">                2.58</td><td style=\"text-align: right;\">            108.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 335664\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-58-39\n",
      "  done: false\n",
      "  episode_len_mean: 107.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.770000000000026\n",
      "  episode_reward_mean: 7.008500000000018\n",
      "  episode_reward_min: 2.580000000000016\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3073\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.527630649294172\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00906033604000723\n",
      "          policy_loss: -0.04191875177479926\n",
      "          total_loss: 0.2486942297025096\n",
      "          vf_explained_var: 0.926408052444458\n",
      "          vf_loss: 0.2967156959431512\n",
      "    num_agent_steps_sampled: 335664\n",
      "    num_agent_steps_trained: 335664\n",
      "    num_steps_sampled: 335664\n",
      "    num_steps_trained: 335664\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08823529411767\n",
      "    ram_util_percent: 30.491176470588236\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434113173006791\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.144872829990344\n",
      "    mean_inference_ms: 2.481868567099688\n",
      "    mean_raw_obs_processing_ms: 1.8855455103288778\n",
      "  time_since_restore: 4402.594111919403\n",
      "  time_this_iter_s: 24.078181266784668\n",
      "  time_total_s: 4402.594111919403\n",
      "  timers:\n",
      "    learn_throughput: 1161.486\n",
      "    learn_time_ms: 1720.211\n",
      "    load_throughput: 52010.413\n",
      "    load_time_ms: 38.415\n",
      "    sample_throughput: 90.626\n",
      "    sample_time_ms: 22046.744\n",
      "    update_time_ms: 8.192\n",
      "  timestamp: 1636433919\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 335664\n",
      "  training_iteration: 168\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         4402.59</td><td style=\"text-align: right;\">335664</td><td style=\"text-align: right;\">  7.0085</td><td style=\"text-align: right;\">               13.77</td><td style=\"text-align: right;\">                2.58</td><td style=\"text-align: right;\">             107.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 337662\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-59-02\n",
      "  done: false\n",
      "  episode_len_mean: 109.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.770000000000026\n",
      "  episode_reward_mean: 7.15430000000002\n",
      "  episode_reward_min: 2.580000000000016\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 3090\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5108513877505347\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010209219546631567\n",
      "          policy_loss: -0.010912171396471205\n",
      "          total_loss: 0.31317483192043644\n",
      "          vf_explained_var: 0.9356394410133362\n",
      "          vf_loss: 0.3288586798168364\n",
      "    num_agent_steps_sampled: 337662\n",
      "    num_agent_steps_trained: 337662\n",
      "    num_steps_sampled: 337662\n",
      "    num_steps_trained: 337662\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94545454545455\n",
      "    ram_util_percent: 30.527272727272727\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432653267617287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.14167689808265\n",
      "    mean_inference_ms: 2.481667100506859\n",
      "    mean_raw_obs_processing_ms: 1.8788938109964834\n",
      "  time_since_restore: 4425.411336660385\n",
      "  time_this_iter_s: 22.817224740982056\n",
      "  time_total_s: 4425.411336660385\n",
      "  timers:\n",
      "    learn_throughput: 1161.555\n",
      "    learn_time_ms: 1720.107\n",
      "    load_throughput: 51820.499\n",
      "    load_time_ms: 38.556\n",
      "    sample_throughput: 90.264\n",
      "    sample_time_ms: 22135.162\n",
      "    update_time_ms: 8.763\n",
      "  timestamp: 1636433942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 337662\n",
      "  training_iteration: 169\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         4425.41</td><td style=\"text-align: right;\">337662</td><td style=\"text-align: right;\">  7.1543</td><td style=\"text-align: right;\">               13.77</td><td style=\"text-align: right;\">                2.58</td><td style=\"text-align: right;\">            109.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 339660\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-59-25\n",
      "  done: false\n",
      "  episode_len_mean: 109.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000022\n",
      "  episode_reward_mean: 7.28420000000002\n",
      "  episode_reward_min: 2.750000000000016\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3108\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4412285691215878\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011049054365065982\n",
      "          policy_loss: -0.015850448076214108\n",
      "          total_loss: 0.2870869188613835\n",
      "          vf_explained_var: 0.9216423630714417\n",
      "          vf_loss: 0.30616248512551897\n",
      "    num_agent_steps_sampled: 339660\n",
      "    num_agent_steps_trained: 339660\n",
      "    num_steps_sampled: 339660\n",
      "    num_steps_trained: 339660\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88787878787879\n",
      "    ram_util_percent: 30.457575757575757\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044315165900312016\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.13664768723187\n",
      "    mean_inference_ms: 2.4814452756251986\n",
      "    mean_raw_obs_processing_ms: 1.8717631471029779\n",
      "  time_since_restore: 4448.582200288773\n",
      "  time_this_iter_s: 23.17086362838745\n",
      "  time_total_s: 4448.582200288773\n",
      "  timers:\n",
      "    learn_throughput: 1160.067\n",
      "    learn_time_ms: 1722.315\n",
      "    load_throughput: 51872.848\n",
      "    load_time_ms: 38.517\n",
      "    sample_throughput: 90.535\n",
      "    sample_time_ms: 22068.754\n",
      "    update_time_ms: 8.761\n",
      "  timestamp: 1636433965\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 339660\n",
      "  training_iteration: 170\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">         4448.58</td><td style=\"text-align: right;\">339660</td><td style=\"text-align: right;\">  7.2842</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                2.75</td><td style=\"text-align: right;\">            109.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 341658\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_04-59-48\n",
      "  done: false\n",
      "  episode_len_mean: 110.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000022\n",
      "  episode_reward_mean: 7.1848000000000205\n",
      "  episode_reward_min: 2.8900000000000143\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3126\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.407319652466547\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008419253438297417\n",
      "          policy_loss: 0.0035014226855266664\n",
      "          total_loss: 0.2503793896619408\n",
      "          vf_explained_var: 0.9241684675216675\n",
      "          vf_loss: 0.2524266710593587\n",
      "    num_agent_steps_sampled: 341658\n",
      "    num_agent_steps_trained: 341658\n",
      "    num_steps_sampled: 341658\n",
      "    num_steps_trained: 341658\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97575757575758\n",
      "    ram_util_percent: 30.4\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044317578222942036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.130111969846443\n",
      "    mean_inference_ms: 2.4814450519322278\n",
      "    mean_raw_obs_processing_ms: 1.8646671652404188\n",
      "  time_since_restore: 4471.747227668762\n",
      "  time_this_iter_s: 23.165027379989624\n",
      "  time_total_s: 4471.747227668762\n",
      "  timers:\n",
      "    learn_throughput: 1158.798\n",
      "    learn_time_ms: 1724.2\n",
      "    load_throughput: 52267.72\n",
      "    load_time_ms: 38.226\n",
      "    sample_throughput: 90.906\n",
      "    sample_time_ms: 21978.747\n",
      "    update_time_ms: 8.402\n",
      "  timestamp: 1636433988\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 341658\n",
      "  training_iteration: 171\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         4471.75</td><td style=\"text-align: right;\">341658</td><td style=\"text-align: right;\">  7.1848</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                2.89</td><td style=\"text-align: right;\">            110.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 343656\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-00-12\n",
      "  done: false\n",
      "  episode_len_mean: 110.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000022\n",
      "  episode_reward_mean: 7.470200000000019\n",
      "  episode_reward_min: 2.8900000000000143\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3145\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.50254507178352\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009285916016637778\n",
      "          policy_loss: -0.04316062756947109\n",
      "          total_loss: 0.17022601803321213\n",
      "          vf_explained_var: 0.9531794786453247\n",
      "          vf_loss: 0.2190101063499848\n",
      "    num_agent_steps_sampled: 343656\n",
      "    num_agent_steps_trained: 343656\n",
      "    num_steps_sampled: 343656\n",
      "    num_steps_trained: 343656\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.93823529411763\n",
      "    ram_util_percent: 30.405882352941177\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044308929359888866\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.121993135646118\n",
      "    mean_inference_ms: 2.4812621266467403\n",
      "    mean_raw_obs_processing_ms: 1.8571329930678289\n",
      "  time_since_restore: 4495.5453317165375\n",
      "  time_this_iter_s: 23.79810404777527\n",
      "  time_total_s: 4495.5453317165375\n",
      "  timers:\n",
      "    learn_throughput: 1159.212\n",
      "    learn_time_ms: 1723.584\n",
      "    load_throughput: 52234.587\n",
      "    load_time_ms: 38.251\n",
      "    sample_throughput: 90.789\n",
      "    sample_time_ms: 22007.051\n",
      "    update_time_ms: 8.164\n",
      "  timestamp: 1636434012\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 343656\n",
      "  training_iteration: 172\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         4495.55</td><td style=\"text-align: right;\">343656</td><td style=\"text-align: right;\">  7.4702</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                2.89</td><td style=\"text-align: right;\">            110.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 345654\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-00-36\n",
      "  done: false\n",
      "  episode_len_mean: 111.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000022\n",
      "  episode_reward_mean: 7.69900000000002\n",
      "  episode_reward_min: 4.10000000000002\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 3162\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4639772137006124\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011131358878777236\n",
      "          policy_loss: -0.03741113165659564\n",
      "          total_loss: 0.31295572115729253\n",
      "          vf_explained_var: 0.9374841451644897\n",
      "          vf_loss: 0.3537361231588182\n",
      "    num_agent_steps_sampled: 345654\n",
      "    num_agent_steps_trained: 345654\n",
      "    num_steps_sampled: 345654\n",
      "    num_steps_trained: 345654\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.43235294117648\n",
      "    ram_util_percent: 30.41764705882353\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443196614923623\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.110144551584526\n",
      "    mean_inference_ms: 2.481334396262911\n",
      "    mean_raw_obs_processing_ms: 1.850447561418294\n",
      "  time_since_restore: 4518.966579675674\n",
      "  time_this_iter_s: 23.421247959136963\n",
      "  time_total_s: 4518.966579675674\n",
      "  timers:\n",
      "    learn_throughput: 1158.709\n",
      "    learn_time_ms: 1724.332\n",
      "    load_throughput: 51930.258\n",
      "    load_time_ms: 38.475\n",
      "    sample_throughput: 90.827\n",
      "    sample_time_ms: 21997.808\n",
      "    update_time_ms: 8.055\n",
      "  timestamp: 1636434036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 345654\n",
      "  training_iteration: 173\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         4518.97</td><td style=\"text-align: right;\">345654</td><td style=\"text-align: right;\">   7.699</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                 4.1</td><td style=\"text-align: right;\">            111.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 347652\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-00-59\n",
      "  done: false\n",
      "  episode_len_mean: 110.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000022\n",
      "  episode_reward_mean: 7.67480000000002\n",
      "  episode_reward_min: 4.210000000000019\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3181\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4948701529275803\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008655602540593187\n",
      "          policy_loss: -0.051333104446530345\n",
      "          total_loss: 0.1618297178298235\n",
      "          vf_explained_var: 0.9540862441062927\n",
      "          vf_loss: 0.21934772685524964\n",
      "    num_agent_steps_sampled: 347652\n",
      "    num_agent_steps_trained: 347652\n",
      "    num_steps_sampled: 347652\n",
      "    num_steps_trained: 347652\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.32727272727271\n",
      "    ram_util_percent: 30.381818181818183\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432850058678712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.10936392433794\n",
      "    mean_inference_ms: 2.481203401177015\n",
      "    mean_raw_obs_processing_ms: 1.8432903502285043\n",
      "  time_since_restore: 4542.178665876389\n",
      "  time_this_iter_s: 23.21208620071411\n",
      "  time_total_s: 4542.178665876389\n",
      "  timers:\n",
      "    learn_throughput: 1158.03\n",
      "    learn_time_ms: 1725.344\n",
      "    load_throughput: 51561.379\n",
      "    load_time_ms: 38.75\n",
      "    sample_throughput: 91.268\n",
      "    sample_time_ms: 21891.619\n",
      "    update_time_ms: 9.15\n",
      "  timestamp: 1636434059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 347652\n",
      "  training_iteration: 174\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">         4542.18</td><td style=\"text-align: right;\">347652</td><td style=\"text-align: right;\">  7.6748</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">                4.21</td><td style=\"text-align: right;\">            110.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 349650\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-01-39\n",
      "  done: false\n",
      "  episode_len_mean: 109.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.880000000000022\n",
      "  episode_reward_mean: 7.54760000000002\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3200\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4751422479039147\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010673448871619896\n",
      "          policy_loss: -0.022728771538961502\n",
      "          total_loss: 0.2758964895137719\n",
      "          vf_explained_var: 0.9342378973960876\n",
      "          vf_loss: 0.3025698150197665\n",
      "    num_agent_steps_sampled: 349650\n",
      "    num_agent_steps_trained: 349650\n",
      "    num_steps_sampled: 349650\n",
      "    num_steps_trained: 349650\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.84912280701754\n",
      "    ram_util_percent: 30.40526315789474\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432523063418938\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.106058772762175\n",
      "    mean_inference_ms: 2.4810342495151803\n",
      "    mean_raw_obs_processing_ms: 1.846609419838243\n",
      "  time_since_restore: 4582.190861701965\n",
      "  time_this_iter_s: 40.01219582557678\n",
      "  time_total_s: 4582.190861701965\n",
      "  timers:\n",
      "    learn_throughput: 1158.245\n",
      "    learn_time_ms: 1725.023\n",
      "    load_throughput: 57700.863\n",
      "    load_time_ms: 34.627\n",
      "    sample_throughput: 85.232\n",
      "    sample_time_ms: 23441.981\n",
      "    update_time_ms: 9.044\n",
      "  timestamp: 1636434099\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 349650\n",
      "  training_iteration: 175\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         4582.19</td><td style=\"text-align: right;\">349650</td><td style=\"text-align: right;\">  7.5476</td><td style=\"text-align: right;\">               13.88</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            109.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 351648\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-02-34\n",
      "  done: false\n",
      "  episode_len_mean: 105.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.870000000000022\n",
      "  episode_reward_mean: 7.47150000000002\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3221\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3819775206702096\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00796979460140831\n",
      "          policy_loss: -0.023330905785163242\n",
      "          total_loss: 0.2574172794375391\n",
      "          vf_explained_var: 0.9411168694496155\n",
      "          vf_loss: 0.2864985390788033\n",
      "    num_agent_steps_sampled: 351648\n",
      "    num_agent_steps_trained: 351648\n",
      "    num_steps_sampled: 351648\n",
      "    num_steps_trained: 351648\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.1897435897436\n",
      "    ram_util_percent: 30.128205128205128\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443563448421594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.09424081678003\n",
      "    mean_inference_ms: 2.4813189853437887\n",
      "    mean_raw_obs_processing_ms: 1.8692409914388042\n",
      "  time_since_restore: 4636.83053445816\n",
      "  time_this_iter_s: 54.63967275619507\n",
      "  time_total_s: 4636.83053445816\n",
      "  timers:\n",
      "    learn_throughput: 1157.462\n",
      "    learn_time_ms: 1726.19\n",
      "    load_throughput: 57946.917\n",
      "    load_time_ms: 34.48\n",
      "    sample_throughput: 75.618\n",
      "    sample_time_ms: 26422.315\n",
      "    update_time_ms: 9.094\n",
      "  timestamp: 1636434154\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 351648\n",
      "  training_iteration: 176\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         4636.83</td><td style=\"text-align: right;\">351648</td><td style=\"text-align: right;\">  7.4715</td><td style=\"text-align: right;\">               13.87</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             105.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 353646\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-02-58\n",
      "  done: false\n",
      "  episode_len_mean: 104.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.870000000000022\n",
      "  episode_reward_mean: 7.280300000000018\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3240\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.561210712932405\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007439239030980529\n",
      "          policy_loss: -0.04079155897100766\n",
      "          total_loss: 0.16585679323900313\n",
      "          vf_explained_var: 0.9266918897628784\n",
      "          vf_loss: 0.2147282313732874\n",
      "    num_agent_steps_sampled: 353646\n",
      "    num_agent_steps_trained: 353646\n",
      "    num_steps_sampled: 353646\n",
      "    num_steps_trained: 353646\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84857142857142\n",
      "    ram_util_percent: 30.000000000000007\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044373721629348835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.084375862886144\n",
      "    mean_inference_ms: 2.4814637849341947\n",
      "    mean_raw_obs_processing_ms: 1.8898676740236515\n",
      "  time_since_restore: 4661.61331152916\n",
      "  time_this_iter_s: 24.782777070999146\n",
      "  time_total_s: 4661.61331152916\n",
      "  timers:\n",
      "    learn_throughput: 1156.322\n",
      "    learn_time_ms: 1727.892\n",
      "    load_throughput: 57745.831\n",
      "    load_time_ms: 34.6\n",
      "    sample_throughput: 75.318\n",
      "    sample_time_ms: 26527.618\n",
      "    update_time_ms: 10.361\n",
      "  timestamp: 1636434178\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 353646\n",
      "  training_iteration: 177\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         4661.61</td><td style=\"text-align: right;\">353646</td><td style=\"text-align: right;\">  7.2803</td><td style=\"text-align: right;\">               13.87</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             104.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 355644\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-03-24\n",
      "  done: false\n",
      "  episode_len_mean: 103.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.320000000000023\n",
      "  episode_reward_mean: 6.9813000000000205\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3259\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5265572144871666\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009694122747173258\n",
      "          policy_loss: -0.04366251028009823\n",
      "          total_loss: 0.26212661145698457\n",
      "          vf_explained_var: 0.9328399896621704\n",
      "          vf_loss: 0.31123939284256524\n",
      "    num_agent_steps_sampled: 355644\n",
      "    num_agent_steps_trained: 355644\n",
      "    num_steps_sampled: 355644\n",
      "    num_steps_trained: 355644\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.52499999999999\n",
      "    ram_util_percent: 30.194444444444443\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044369347269882946\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.080618184588534\n",
      "    mean_inference_ms: 2.4813558828796793\n",
      "    mean_raw_obs_processing_ms: 1.9104716606153522\n",
      "  time_since_restore: 4686.713737010956\n",
      "  time_this_iter_s: 25.100425481796265\n",
      "  time_total_s: 4686.713737010956\n",
      "  timers:\n",
      "    learn_throughput: 1156.668\n",
      "    learn_time_ms: 1727.376\n",
      "    load_throughput: 57842.965\n",
      "    load_time_ms: 34.542\n",
      "    sample_throughput: 75.026\n",
      "    sample_time_ms: 26630.688\n",
      "    update_time_ms: 10.057\n",
      "  timestamp: 1636434204\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 355644\n",
      "  training_iteration: 178\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   178</td><td style=\"text-align: right;\">         4686.71</td><td style=\"text-align: right;\">355644</td><td style=\"text-align: right;\">  6.9813</td><td style=\"text-align: right;\">               13.32</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            103.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 357642\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-03-47\n",
      "  done: false\n",
      "  episode_len_mean: 102.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.560000000000024\n",
      "  episode_reward_mean: 6.983100000000019\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3278\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.644693198090508\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010254308397025355\n",
      "          policy_loss: -0.05535655392422562\n",
      "          total_loss: 0.16120240599626587\n",
      "          vf_explained_var: 0.9433718919754028\n",
      "          vf_loss: 0.2226234035300357\n",
      "    num_agent_steps_sampled: 357642\n",
      "    num_agent_steps_trained: 357642\n",
      "    num_steps_sampled: 357642\n",
      "    num_steps_trained: 357642\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0764705882353\n",
      "    ram_util_percent: 30.32058823529412\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438425882719683\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.07441728980694\n",
      "    mean_inference_ms: 2.481607585009968\n",
      "    mean_raw_obs_processing_ms: 1.9310273501770485\n",
      "  time_since_restore: 4710.3098130226135\n",
      "  time_this_iter_s: 23.596076011657715\n",
      "  time_total_s: 4710.3098130226135\n",
      "  timers:\n",
      "    learn_throughput: 1154.884\n",
      "    learn_time_ms: 1730.044\n",
      "    load_throughput: 58041.312\n",
      "    load_time_ms: 34.424\n",
      "    sample_throughput: 74.814\n",
      "    sample_time_ms: 26706.067\n",
      "    update_time_ms: 10.102\n",
      "  timestamp: 1636434227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 357642\n",
      "  training_iteration: 179\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         4710.31</td><td style=\"text-align: right;\">357642</td><td style=\"text-align: right;\">  6.9831</td><td style=\"text-align: right;\">               13.56</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            102.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 359640\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-04-11\n",
      "  done: false\n",
      "  episode_len_mean: 101.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.560000000000024\n",
      "  episode_reward_mean: 7.017300000000018\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3297\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4137522952897208\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0138743821772424\n",
      "          policy_loss: 0.0044541473189989725\n",
      "          total_loss: 0.43096484139206864\n",
      "          vf_explained_var: 0.937518298625946\n",
      "          vf_loss: 0.42660040459817367\n",
      "    num_agent_steps_sampled: 359640\n",
      "    num_agent_steps_trained: 359640\n",
      "    num_steps_sampled: 359640\n",
      "    num_steps_trained: 359640\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.4970588235294\n",
      "    ram_util_percent: 30.529411764705884\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044383168572137845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.069014236841884\n",
      "    mean_inference_ms: 2.481678740493419\n",
      "    mean_raw_obs_processing_ms: 1.945551266023719\n",
      "  time_since_restore: 4734.028446674347\n",
      "  time_this_iter_s: 23.7186336517334\n",
      "  time_total_s: 4734.028446674347\n",
      "  timers:\n",
      "    learn_throughput: 1157.746\n",
      "    learn_time_ms: 1725.768\n",
      "    load_throughput: 58054.782\n",
      "    load_time_ms: 34.416\n",
      "    sample_throughput: 74.651\n",
      "    sample_time_ms: 26764.58\n",
      "    update_time_ms: 10.921\n",
      "  timestamp: 1636434251\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 359640\n",
      "  training_iteration: 180\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   180</td><td style=\"text-align: right;\">         4734.03</td><td style=\"text-align: right;\">359640</td><td style=\"text-align: right;\">  7.0173</td><td style=\"text-align: right;\">               13.56</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            101.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 361638\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-04-34\n",
      "  done: false\n",
      "  episode_len_mean: 105.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.560000000000024\n",
      "  episode_reward_mean: 7.268400000000018\n",
      "  episode_reward_min: 2.620000000000012\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3315\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.490531077271416\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008414433181799958\n",
      "          policy_loss: -0.031655286926598775\n",
      "          total_loss: 0.1698241106101445\n",
      "          vf_explained_var: 0.9622381329536438\n",
      "          vf_loss: 0.20786509327590466\n",
      "    num_agent_steps_sampled: 361638\n",
      "    num_agent_steps_trained: 361638\n",
      "    num_steps_sampled: 361638\n",
      "    num_steps_trained: 361638\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16060606060606\n",
      "    ram_util_percent: 30.636363636363637\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044337776221781346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.078335287978643\n",
      "    mean_inference_ms: 2.48108027299698\n",
      "    mean_raw_obs_processing_ms: 1.9392119087153707\n",
      "  time_since_restore: 4757.179409503937\n",
      "  time_this_iter_s: 23.150962829589844\n",
      "  time_total_s: 4757.179409503937\n",
      "  timers:\n",
      "    learn_throughput: 1158.884\n",
      "    learn_time_ms: 1724.073\n",
      "    load_throughput: 57900.595\n",
      "    load_time_ms: 34.507\n",
      "    sample_throughput: 74.65\n",
      "    sample_time_ms: 26764.996\n",
      "    update_time_ms: 10.665\n",
      "  timestamp: 1636434274\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 361638\n",
      "  training_iteration: 181\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         4757.18</td><td style=\"text-align: right;\">361638</td><td style=\"text-align: right;\">  7.2684</td><td style=\"text-align: right;\">               13.56</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">            105.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 363636\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-04-58\n",
      "  done: false\n",
      "  episode_len_mean: 107.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.560000000000024\n",
      "  episode_reward_mean: 7.348900000000019\n",
      "  episode_reward_min: 2.620000000000012\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3333\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5405912490118117\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007383843216025653\n",
      "          policy_loss: -0.054246283446749054\n",
      "          total_loss: 0.1251230173345123\n",
      "          vf_explained_var: 0.9547563791275024\n",
      "          vf_loss: 0.18729907150069872\n",
      "    num_agent_steps_sampled: 363636\n",
      "    num_agent_steps_trained: 363636\n",
      "    num_steps_sampled: 363636\n",
      "    num_steps_trained: 363636\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94999999999999\n",
      "    ram_util_percent: 30.738235294117644\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044323822110034376\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.075863160868657\n",
      "    mean_inference_ms: 2.4809643404382684\n",
      "    mean_raw_obs_processing_ms: 1.932410989464874\n",
      "  time_since_restore: 4780.748529672623\n",
      "  time_this_iter_s: 23.569120168685913\n",
      "  time_total_s: 4780.748529672623\n",
      "  timers:\n",
      "    learn_throughput: 1159.509\n",
      "    learn_time_ms: 1723.143\n",
      "    load_throughput: 58025.398\n",
      "    load_time_ms: 34.433\n",
      "    sample_throughput: 74.712\n",
      "    sample_time_ms: 26742.708\n",
      "    update_time_ms: 11.27\n",
      "  timestamp: 1636434298\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 363636\n",
      "  training_iteration: 182\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         4780.75</td><td style=\"text-align: right;\">363636</td><td style=\"text-align: right;\">  7.3489</td><td style=\"text-align: right;\">               13.56</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">            107.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 365634\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-05-22\n",
      "  done: false\n",
      "  episode_len_mean: 107.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.670000000000021\n",
      "  episode_reward_mean: 7.3952000000000195\n",
      "  episode_reward_min: 2.8700000000000156\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3352\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4788837608836947\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010346902620208133\n",
      "          policy_loss: -0.0031489738396235875\n",
      "          total_loss: 0.27389230953662524\n",
      "          vf_explained_var: 0.9517612457275391\n",
      "          vf_loss: 0.281353884154842\n",
      "    num_agent_steps_sampled: 365634\n",
      "    num_agent_steps_trained: 365634\n",
      "    num_steps_sampled: 365634\n",
      "    num_steps_trained: 365634\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.50294117647059\n",
      "    ram_util_percent: 30.71176470588235\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432140924331996\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.071994350404886\n",
      "    mean_inference_ms: 2.481012432880962\n",
      "    mean_raw_obs_processing_ms: 1.9253174184212805\n",
      "  time_since_restore: 4805.1699459552765\n",
      "  time_this_iter_s: 24.42141628265381\n",
      "  time_total_s: 4805.1699459552765\n",
      "  timers:\n",
      "    learn_throughput: 1158.912\n",
      "    learn_time_ms: 1724.031\n",
      "    load_throughput: 58389.098\n",
      "    load_time_ms: 34.219\n",
      "    sample_throughput: 74.433\n",
      "    sample_time_ms: 26842.841\n",
      "    update_time_ms: 10.299\n",
      "  timestamp: 1636434322\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 365634\n",
      "  training_iteration: 183\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">         4805.17</td><td style=\"text-align: right;\">365634</td><td style=\"text-align: right;\">  7.3952</td><td style=\"text-align: right;\">               13.67</td><td style=\"text-align: right;\">                2.87</td><td style=\"text-align: right;\">            107.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 367632\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-05-46\n",
      "  done: false\n",
      "  episode_len_mean: 107.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.300000000000022\n",
      "  episode_reward_mean: 7.7824000000000195\n",
      "  episode_reward_min: 3.0800000000000107\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3370\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3881896098454793\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009454664274370406\n",
      "          policy_loss: -0.05250021446318853\n",
      "          total_loss: 0.16303338388069755\n",
      "          vf_explained_var: 0.9614067673683167\n",
      "          vf_loss: 0.21984264330849762\n",
      "    num_agent_steps_sampled: 367632\n",
      "    num_agent_steps_trained: 367632\n",
      "    num_steps_sampled: 367632\n",
      "    num_steps_trained: 367632\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.09117647058824\n",
      "    ram_util_percent: 30.7235294117647\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431222972585735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.064677709119987\n",
      "    mean_inference_ms: 2.480973419183417\n",
      "    mean_raw_obs_processing_ms: 1.9184374706472271\n",
      "  time_since_restore: 4828.535466909409\n",
      "  time_this_iter_s: 23.36552095413208\n",
      "  time_total_s: 4828.535466909409\n",
      "  timers:\n",
      "    learn_throughput: 1159.219\n",
      "    learn_time_ms: 1723.575\n",
      "    load_throughput: 58942.947\n",
      "    load_time_ms: 33.897\n",
      "    sample_throughput: 74.387\n",
      "    sample_time_ms: 26859.687\n",
      "    update_time_ms: 9.743\n",
      "  timestamp: 1636434346\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 367632\n",
      "  training_iteration: 184\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   184</td><td style=\"text-align: right;\">         4828.54</td><td style=\"text-align: right;\">367632</td><td style=\"text-align: right;\">  7.7824</td><td style=\"text-align: right;\">                14.3</td><td style=\"text-align: right;\">                3.08</td><td style=\"text-align: right;\">            107.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 369630\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-06-09\n",
      "  done: false\n",
      "  episode_len_mean: 108.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.300000000000022\n",
      "  episode_reward_mean: 7.701000000000019\n",
      "  episode_reward_min: 0.8000000000000129\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3388\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5431685708817982\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015591636628147812\n",
      "          policy_loss: -0.029219376650594528\n",
      "          total_loss: 0.39642133289682013\n",
      "          vf_explained_var: 0.9426615238189697\n",
      "          vf_loss: 0.4252858643375692\n",
      "    num_agent_steps_sampled: 369630\n",
      "    num_agent_steps_trained: 369630\n",
      "    num_steps_sampled: 369630\n",
      "    num_steps_trained: 369630\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89090909090908\n",
      "    ram_util_percent: 30.654545454545456\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431044960111878\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.060541735903602\n",
      "    mean_inference_ms: 2.4809619238191196\n",
      "    mean_raw_obs_processing_ms: 1.9117786849552758\n",
      "  time_since_restore: 4852.089279413223\n",
      "  time_this_iter_s: 23.553812503814697\n",
      "  time_total_s: 4852.089279413223\n",
      "  timers:\n",
      "    learn_throughput: 1159.35\n",
      "    learn_time_ms: 1723.379\n",
      "    load_throughput: 58946.264\n",
      "    load_time_ms: 33.895\n",
      "    sample_throughput: 79.242\n",
      "    sample_time_ms: 25213.858\n",
      "    update_time_ms: 9.856\n",
      "  timestamp: 1636434369\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 369630\n",
      "  training_iteration: 185\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         4852.09</td><td style=\"text-align: right;\">369630</td><td style=\"text-align: right;\">   7.701</td><td style=\"text-align: right;\">                14.3</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            108.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 371628\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-06-32\n",
      "  done: false\n",
      "  episode_len_mean: 110.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.300000000000022\n",
      "  episode_reward_mean: 7.821500000000022\n",
      "  episode_reward_min: 0.8000000000000129\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3406\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4291210237003509\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012594820834648576\n",
      "          policy_loss: -0.011834280476683662\n",
      "          total_loss: 0.5139242080705506\n",
      "          vf_explained_var: 0.8984050750732422\n",
      "          vf_loss: 0.5272974401712418\n",
      "    num_agent_steps_sampled: 371628\n",
      "    num_agent_steps_trained: 371628\n",
      "    num_steps_sampled: 371628\n",
      "    num_steps_trained: 371628\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.49705882352943\n",
      "    ram_util_percent: 30.655882352941177\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430804440688091\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.054394165103602\n",
      "    mean_inference_ms: 2.4809127905788944\n",
      "    mean_raw_obs_processing_ms: 1.9051032101345229\n",
      "  time_since_restore: 4875.319079875946\n",
      "  time_this_iter_s: 23.22980046272278\n",
      "  time_total_s: 4875.319079875946\n",
      "  timers:\n",
      "    learn_throughput: 1159.943\n",
      "    learn_time_ms: 1722.498\n",
      "    load_throughput: 58744.454\n",
      "    load_time_ms: 34.012\n",
      "    sample_throughput: 90.515\n",
      "    sample_time_ms: 22073.68\n",
      "    update_time_ms: 9.935\n",
      "  timestamp: 1636434392\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 371628\n",
      "  training_iteration: 186\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         4875.32</td><td style=\"text-align: right;\">371628</td><td style=\"text-align: right;\">  7.8215</td><td style=\"text-align: right;\">                14.3</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            110.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 373626\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-06-56\n",
      "  done: false\n",
      "  episode_len_mean: 109.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.320000000000022\n",
      "  episode_reward_mean: 7.872200000000018\n",
      "  episode_reward_min: 0.8000000000000129\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3424\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4985514544305347\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00878010784502944\n",
      "          policy_loss: -0.00995117619278885\n",
      "          total_loss: 0.1907026415069898\n",
      "          vf_explained_var: 0.9580772519111633\n",
      "          vf_loss: 0.2067494703545457\n",
      "    num_agent_steps_sampled: 373626\n",
      "    num_agent_steps_trained: 373626\n",
      "    num_steps_sampled: 373626\n",
      "    num_steps_trained: 373626\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94242424242424\n",
      "    ram_util_percent: 30.660606060606064\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429735105160793\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.051051772454326\n",
      "    mean_inference_ms: 2.480727077008191\n",
      "    mean_raw_obs_processing_ms: 1.8985915521812557\n",
      "  time_since_restore: 4898.535497665405\n",
      "  time_this_iter_s: 23.21641778945923\n",
      "  time_total_s: 4898.535497665405\n",
      "  timers:\n",
      "    learn_throughput: 1160.989\n",
      "    learn_time_ms: 1720.947\n",
      "    load_throughput: 58780.755\n",
      "    load_time_ms: 33.991\n",
      "    sample_throughput: 91.151\n",
      "    sample_time_ms: 21919.739\n",
      "    update_time_ms: 8.699\n",
      "  timestamp: 1636434416\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 373626\n",
      "  training_iteration: 187\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         4898.54</td><td style=\"text-align: right;\">373626</td><td style=\"text-align: right;\">  7.8722</td><td style=\"text-align: right;\">               14.32</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            109.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 375624\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-07-20\n",
      "  done: false\n",
      "  episode_len_mean: 108.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.320000000000022\n",
      "  episode_reward_mean: 7.971400000000018\n",
      "  episode_reward_min: 0.8000000000000129\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3443\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4574941873550415\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006794669701181007\n",
      "          policy_loss: 0.002602244523309526\n",
      "          total_loss: 0.14632243911425272\n",
      "          vf_explained_var: 0.9688791632652283\n",
      "          vf_loss: 0.15141553250806672\n",
      "    num_agent_steps_sampled: 375624\n",
      "    num_agent_steps_trained: 375624\n",
      "    num_steps_sampled: 375624\n",
      "    num_steps_trained: 375624\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9057142857143\n",
      "    ram_util_percent: 30.614285714285714\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044293863282914216\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.045490488371144\n",
      "    mean_inference_ms: 2.480663651980403\n",
      "    mean_raw_obs_processing_ms: 1.891673017557691\n",
      "  time_since_restore: 4923.094648599625\n",
      "  time_this_iter_s: 24.55915093421936\n",
      "  time_total_s: 4923.094648599625\n",
      "  timers:\n",
      "    learn_throughput: 1159.672\n",
      "    learn_time_ms: 1722.9\n",
      "    load_throughput: 58862.669\n",
      "    load_time_ms: 33.943\n",
      "    sample_throughput: 91.388\n",
      "    sample_time_ms: 21862.925\n",
      "    update_time_ms: 9.469\n",
      "  timestamp: 1636434440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 375624\n",
      "  training_iteration: 188\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">         4923.09</td><td style=\"text-align: right;\">375624</td><td style=\"text-align: right;\">  7.9714</td><td style=\"text-align: right;\">               14.32</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            108.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 377622\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-07-45\n",
      "  done: false\n",
      "  episode_len_mean: 108.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.320000000000022\n",
      "  episode_reward_mean: 7.774000000000018\n",
      "  episode_reward_min: 0.8000000000000129\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3462\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4978817542394003\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008419868293012996\n",
      "          policy_loss: -0.06657345988565967\n",
      "          total_loss: 0.13721758062463432\n",
      "          vf_explained_var: 0.9521040320396423\n",
      "          vf_loss: 0.21024474242613428\n",
      "    num_agent_steps_sampled: 377622\n",
      "    num_agent_steps_trained: 377622\n",
      "    num_steps_sampled: 377622\n",
      "    num_steps_trained: 377622\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.76666666666665\n",
      "    ram_util_percent: 30.58888888888889\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430293716174563\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.04057981879272\n",
      "    mean_inference_ms: 2.4807233252913985\n",
      "    mean_raw_obs_processing_ms: 1.8848437359656105\n",
      "  time_since_restore: 4948.006369113922\n",
      "  time_this_iter_s: 24.911720514297485\n",
      "  time_total_s: 4948.006369113922\n",
      "  timers:\n",
      "    learn_throughput: 1161.257\n",
      "    learn_time_ms: 1720.549\n",
      "    load_throughput: 58937.517\n",
      "    load_time_ms: 33.9\n",
      "    sample_throughput: 90.831\n",
      "    sample_time_ms: 21996.906\n",
      "    update_time_ms: 9.286\n",
      "  timestamp: 1636434465\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 377622\n",
      "  training_iteration: 189\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">         4948.01</td><td style=\"text-align: right;\">377622</td><td style=\"text-align: right;\">   7.774</td><td style=\"text-align: right;\">               14.32</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            108.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 379620\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-08-11\n",
      "  done: false\n",
      "  episode_len_mean: 107.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.440000000000015\n",
      "  episode_reward_mean: 7.720400000000019\n",
      "  episode_reward_min: 2.6400000000000197\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3482\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5071627946127029\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009698442327594746\n",
      "          policy_loss: -0.04198970865635645\n",
      "          total_loss: 0.21220657122099684\n",
      "          vf_explained_var: 0.9494422674179077\n",
      "          vf_loss: 0.25944823266140055\n",
      "    num_agent_steps_sampled: 379620\n",
      "    num_agent_steps_trained: 379620\n",
      "    num_steps_sampled: 379620\n",
      "    num_steps_trained: 379620\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95\n",
      "    ram_util_percent: 30.566666666666663\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431005513071978\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.037871753639603\n",
      "    mean_inference_ms: 2.480735209445076\n",
      "    mean_raw_obs_processing_ms: 1.8778629486957286\n",
      "  time_since_restore: 4973.663081645966\n",
      "  time_this_iter_s: 25.656712532043457\n",
      "  time_total_s: 4973.663081645966\n",
      "  timers:\n",
      "    learn_throughput: 1160.782\n",
      "    learn_time_ms: 1721.253\n",
      "    load_throughput: 59064.337\n",
      "    load_time_ms: 33.828\n",
      "    sample_throughput: 90.038\n",
      "    sample_time_ms: 22190.52\n",
      "    update_time_ms: 8.638\n",
      "  timestamp: 1636434491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 379620\n",
      "  training_iteration: 190\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   190</td><td style=\"text-align: right;\">         4973.66</td><td style=\"text-align: right;\">379620</td><td style=\"text-align: right;\">  7.7204</td><td style=\"text-align: right;\">               14.44</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">            107.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 381618\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-08-36\n",
      "  done: false\n",
      "  episode_len_mean: 105.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.440000000000015\n",
      "  episode_reward_mean: 7.315600000000021\n",
      "  episode_reward_min: 0.44000000000000616\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3502\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3981157177970522\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009246021249142394\n",
      "          policy_loss: -0.049427501112222674\n",
      "          total_loss: 0.2586672355509585\n",
      "          vf_explained_var: 0.9462928175926208\n",
      "          vf_loss: 0.312714298140435\n",
      "    num_agent_steps_sampled: 381618\n",
      "    num_agent_steps_trained: 381618\n",
      "    num_steps_sampled: 381618\n",
      "    num_steps_trained: 381618\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9638888888889\n",
      "    ram_util_percent: 30.602777777777778\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431142631383718\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.036247876415477\n",
      "    mean_inference_ms: 2.4807672813149604\n",
      "    mean_raw_obs_processing_ms: 1.8710255915900549\n",
      "  time_since_restore: 4998.510509490967\n",
      "  time_this_iter_s: 24.84742784500122\n",
      "  time_total_s: 4998.510509490967\n",
      "  timers:\n",
      "    learn_throughput: 1159.975\n",
      "    learn_time_ms: 1722.45\n",
      "    load_throughput: 58823.459\n",
      "    load_time_ms: 33.966\n",
      "    sample_throughput: 89.361\n",
      "    sample_time_ms: 22358.754\n",
      "    update_time_ms: 8.642\n",
      "  timestamp: 1636434516\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 381618\n",
      "  training_iteration: 191\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">         4998.51</td><td style=\"text-align: right;\">381618</td><td style=\"text-align: right;\">  7.3156</td><td style=\"text-align: right;\">               14.44</td><td style=\"text-align: right;\">                0.44</td><td style=\"text-align: right;\">            105.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 383616\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-09-02\n",
      "  done: false\n",
      "  episode_len_mean: 103.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.440000000000015\n",
      "  episode_reward_mean: 7.174700000000018\n",
      "  episode_reward_min: 0.44000000000000616\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3521\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5181001816477095\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009817984707436885\n",
      "          policy_loss: -0.02197928269881578\n",
      "          total_loss: 0.20478002237422124\n",
      "          vf_explained_var: 0.9446086883544922\n",
      "          vf_loss: 0.23199959580032598\n",
      "    num_agent_steps_sampled: 383616\n",
      "    num_agent_steps_trained: 383616\n",
      "    num_steps_sampled: 383616\n",
      "    num_steps_trained: 383616\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.19459459459459\n",
      "    ram_util_percent: 30.56756756756757\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431237935250678\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.03849982120783\n",
      "    mean_inference_ms: 2.480829094803609\n",
      "    mean_raw_obs_processing_ms: 1.8647567893036612\n",
      "  time_since_restore: 5024.527580738068\n",
      "  time_this_iter_s: 26.01707124710083\n",
      "  time_total_s: 5024.527580738068\n",
      "  timers:\n",
      "    learn_throughput: 1152.813\n",
      "    learn_time_ms: 1733.152\n",
      "    load_throughput: 58726.217\n",
      "    load_time_ms: 34.022\n",
      "    sample_throughput: 88.443\n",
      "    sample_time_ms: 22590.717\n",
      "    update_time_ms: 10.304\n",
      "  timestamp: 1636434542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 383616\n",
      "  training_iteration: 192\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">         5024.53</td><td style=\"text-align: right;\">383616</td><td style=\"text-align: right;\">  7.1747</td><td style=\"text-align: right;\">               14.44</td><td style=\"text-align: right;\">                0.44</td><td style=\"text-align: right;\">            103.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 385614\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-09-28\n",
      "  done: false\n",
      "  episode_len_mean: 102.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.440000000000015\n",
      "  episode_reward_mean: 7.1518000000000175\n",
      "  episode_reward_min: 0.44000000000000616\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3541\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4524286457470486\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01159645894296505\n",
      "          policy_loss: -0.01326497235291061\n",
      "          total_loss: 0.3697890547680713\n",
      "          vf_explained_var: 0.9362902641296387\n",
      "          vf_loss: 0.3858368979323478\n",
      "    num_agent_steps_sampled: 385614\n",
      "    num_agent_steps_trained: 385614\n",
      "    num_steps_sampled: 385614\n",
      "    num_steps_trained: 385614\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.4054054054054\n",
      "    ram_util_percent: 30.586486486486482\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443262325135228\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.0426690352486\n",
      "    mean_inference_ms: 2.4810553095944816\n",
      "    mean_raw_obs_processing_ms: 1.8584226037781537\n",
      "  time_since_restore: 5050.325778245926\n",
      "  time_this_iter_s: 25.798197507858276\n",
      "  time_total_s: 5050.325778245926\n",
      "  timers:\n",
      "    learn_throughput: 1152.666\n",
      "    learn_time_ms: 1733.373\n",
      "    load_throughput: 58808.475\n",
      "    load_time_ms: 33.975\n",
      "    sample_throughput: 87.912\n",
      "    sample_time_ms: 22727.37\n",
      "    update_time_ms: 11.21\n",
      "  timestamp: 1636434568\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 385614\n",
      "  training_iteration: 193\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">         5050.33</td><td style=\"text-align: right;\">385614</td><td style=\"text-align: right;\">  7.1518</td><td style=\"text-align: right;\">               14.44</td><td style=\"text-align: right;\">                0.44</td><td style=\"text-align: right;\">            102.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 387612\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-10-08\n",
      "  done: false\n",
      "  episode_len_mean: 100.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.440000000000015\n",
      "  episode_reward_mean: 6.937800000000018\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3562\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4396630661828178\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011529806138920492\n",
      "          policy_loss: 0.015038310133275532\n",
      "          total_loss: 0.344733297097541\n",
      "          vf_explained_var: 0.9212178587913513\n",
      "          vf_loss: 0.3324176903459288\n",
      "    num_agent_steps_sampled: 387612\n",
      "    num_agent_steps_trained: 387612\n",
      "    num_steps_sampled: 387612\n",
      "    num_steps_trained: 387612\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.85789473684211\n",
      "    ram_util_percent: 30.417543859649125\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044320847786294665\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.04667789826623\n",
      "    mean_inference_ms: 2.4809736881818294\n",
      "    mean_raw_obs_processing_ms: 1.8709724859671641\n",
      "  time_since_restore: 5090.558335065842\n",
      "  time_this_iter_s: 40.23255681991577\n",
      "  time_total_s: 5090.558335065842\n",
      "  timers:\n",
      "    learn_throughput: 1150.442\n",
      "    learn_time_ms: 1736.724\n",
      "    load_throughput: 58719.715\n",
      "    load_time_ms: 34.026\n",
      "    sample_throughput: 81.849\n",
      "    sample_time_ms: 24410.911\n",
      "    update_time_ms: 11.009\n",
      "  timestamp: 1636434608\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 387612\n",
      "  training_iteration: 194\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   194</td><td style=\"text-align: right;\">         5090.56</td><td style=\"text-align: right;\">387612</td><td style=\"text-align: right;\">  6.9378</td><td style=\"text-align: right;\">               14.44</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">            100.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 389610\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-10-51\n",
      "  done: false\n",
      "  episode_len_mean: 99.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.86000000000002\n",
      "  episode_reward_mean: 6.704700000000018\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3582\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5597428719202677\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010701868429274286\n",
      "          policy_loss: -0.01674347875994586\n",
      "          total_loss: 0.4094330354460648\n",
      "          vf_explained_var: 0.8870644569396973\n",
      "          vf_loss: 0.4309382993550528\n",
      "    num_agent_steps_sampled: 389610\n",
      "    num_agent_steps_trained: 389610\n",
      "    num_steps_sampled: 389610\n",
      "    num_steps_trained: 389610\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.69516129032257\n",
      "    ram_util_percent: 30.11290322580645\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044334597802553936\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.05235120348525\n",
      "    mean_inference_ms: 2.48110193259303\n",
      "    mean_raw_obs_processing_ms: 1.891147444108979\n",
      "  time_since_restore: 5133.653025388718\n",
      "  time_this_iter_s: 43.09469032287598\n",
      "  time_total_s: 5133.653025388718\n",
      "  timers:\n",
      "    learn_throughput: 1148.98\n",
      "    learn_time_ms: 1738.934\n",
      "    load_throughput: 58608.548\n",
      "    load_time_ms: 34.091\n",
      "    sample_throughput: 75.791\n",
      "    sample_time_ms: 26362.018\n",
      "    update_time_ms: 11.835\n",
      "  timestamp: 1636434651\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 389610\n",
      "  training_iteration: 195\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">         5133.65</td><td style=\"text-align: right;\">389610</td><td style=\"text-align: right;\">  6.7047</td><td style=\"text-align: right;\">               13.86</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             99.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 391608\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-11-17\n",
      "  done: false\n",
      "  episode_len_mean: 98.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.130000000000022\n",
      "  episode_reward_mean: 6.572100000000017\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3602\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4875768638792493\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00904314124000431\n",
      "          policy_loss: -0.011762634469639687\n",
      "          total_loss: 0.3115492763441233\n",
      "          vf_explained_var: 0.9198101162910461\n",
      "          vf_loss: 0.32903149802060355\n",
      "    num_agent_steps_sampled: 391608\n",
      "    num_agent_steps_trained: 391608\n",
      "    num_steps_sampled: 391608\n",
      "    num_steps_trained: 391608\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9945945945946\n",
      "    ram_util_percent: 30.31891891891891\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435399985416126\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.058010819130374\n",
      "    mean_inference_ms: 2.481246526968519\n",
      "    mean_raw_obs_processing_ms: 1.911101503158422\n",
      "  time_since_restore: 5159.486442565918\n",
      "  time_this_iter_s: 25.833417177200317\n",
      "  time_total_s: 5159.486442565918\n",
      "  timers:\n",
      "    learn_throughput: 1141.772\n",
      "    learn_time_ms: 1749.912\n",
      "    load_throughput: 58732.72\n",
      "    load_time_ms: 34.019\n",
      "    sample_throughput: 75.082\n",
      "    sample_time_ms: 26611.08\n",
      "    update_time_ms: 12.205\n",
      "  timestamp: 1636434677\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 391608\n",
      "  training_iteration: 196\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   196</td><td style=\"text-align: right;\">         5159.49</td><td style=\"text-align: right;\">391608</td><td style=\"text-align: right;\">  6.5721</td><td style=\"text-align: right;\">               14.13</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             98.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 393606\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-11-43\n",
      "  done: false\n",
      "  episode_len_mean: 99.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.130000000000022\n",
      "  episode_reward_mean: 6.631200000000018\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3622\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4622323689006624\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008477210689013186\n",
      "          policy_loss: -0.07716036994187604\n",
      "          total_loss: 0.17015582559009393\n",
      "          vf_explained_var: 0.9367955327033997\n",
      "          vf_loss: 0.2533553443849087\n",
      "    num_agent_steps_sampled: 393606\n",
      "    num_agent_steps_trained: 393606\n",
      "    num_steps_sampled: 393606\n",
      "    num_steps_trained: 393606\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79729729729729\n",
      "    ram_util_percent: 30.508108108108114\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436763503620174\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.061296769980455\n",
      "    mean_inference_ms: 2.4813600052100324\n",
      "    mean_raw_obs_processing_ms: 1.9308298855683321\n",
      "  time_since_restore: 5185.4241325855255\n",
      "  time_this_iter_s: 25.937690019607544\n",
      "  time_total_s: 5185.4241325855255\n",
      "  timers:\n",
      "    learn_throughput: 1140.964\n",
      "    learn_time_ms: 1751.151\n",
      "    load_throughput: 58940.584\n",
      "    load_time_ms: 33.899\n",
      "    sample_throughput: 74.325\n",
      "    sample_time_ms: 26881.852\n",
      "    update_time_ms: 12.244\n",
      "  timestamp: 1636434703\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 393606\n",
      "  training_iteration: 197\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">         5185.42</td><td style=\"text-align: right;\">393606</td><td style=\"text-align: right;\">  6.6312</td><td style=\"text-align: right;\">               14.13</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             99.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 395604\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-12-08\n",
      "  done: false\n",
      "  episode_len_mean: 99.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.160000000000018\n",
      "  episode_reward_mean: 6.643000000000018\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3642\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.425427964755467\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012499702162665091\n",
      "          policy_loss: -0.05903983749449253\n",
      "          total_loss: 0.30324050133072195\n",
      "          vf_explained_var: 0.9188843369483948\n",
      "          vf_loss: 0.36387867026385806\n",
      "    num_agent_steps_sampled: 395604\n",
      "    num_agent_steps_trained: 395604\n",
      "    num_steps_sampled: 395604\n",
      "    num_steps_trained: 395604\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.31944444444444\n",
      "    ram_util_percent: 30.547222222222217\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435377774612781\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.069060726618126\n",
      "    mean_inference_ms: 2.4810841223370472\n",
      "    mean_raw_obs_processing_ms: 1.9505404864548086\n",
      "  time_since_restore: 5210.908817529678\n",
      "  time_this_iter_s: 25.484684944152832\n",
      "  time_total_s: 5210.908817529678\n",
      "  timers:\n",
      "    learn_throughput: 1141.435\n",
      "    learn_time_ms: 1750.427\n",
      "    load_throughput: 58947.757\n",
      "    load_time_ms: 33.894\n",
      "    sample_throughput: 74.066\n",
      "    sample_time_ms: 26975.997\n",
      "    update_time_ms: 11.241\n",
      "  timestamp: 1636434728\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 395604\n",
      "  training_iteration: 198\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   198</td><td style=\"text-align: right;\">         5210.91</td><td style=\"text-align: right;\">395604</td><td style=\"text-align: right;\">   6.643</td><td style=\"text-align: right;\">               14.16</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             99.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 397602\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-12-34\n",
      "  done: false\n",
      "  episode_len_mean: 99.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.300000000000018\n",
      "  episode_reward_mean: 6.796000000000018\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3661\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3239491133462815\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.022372992231369692\n",
      "          policy_loss: -0.010094381771272138\n",
      "          total_loss: 0.4969385171131719\n",
      "          vf_explained_var: 0.9236415028572083\n",
      "          vf_loss: 0.49761973108564106\n",
      "    num_agent_steps_sampled: 397602\n",
      "    num_agent_steps_trained: 397602\n",
      "    num_steps_sampled: 397602\n",
      "    num_steps_trained: 397602\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.43611111111112\n",
      "    ram_util_percent: 30.60833333333333\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437982507190228\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.074132939222185\n",
      "    mean_inference_ms: 2.4814060690215847\n",
      "    mean_raw_obs_processing_ms: 1.951459716285491\n",
      "  time_since_restore: 5236.25044131279\n",
      "  time_this_iter_s: 25.341623783111572\n",
      "  time_total_s: 5236.25044131279\n",
      "  timers:\n",
      "    learn_throughput: 1141.279\n",
      "    learn_time_ms: 1750.667\n",
      "    load_throughput: 58905.948\n",
      "    load_time_ms: 33.918\n",
      "    sample_throughput: 73.947\n",
      "    sample_time_ms: 27019.32\n",
      "    update_time_ms: 10.733\n",
      "  timestamp: 1636434754\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 397602\n",
      "  training_iteration: 199\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">         5236.25</td><td style=\"text-align: right;\">397602</td><td style=\"text-align: right;\">   6.796</td><td style=\"text-align: right;\">                14.3</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             99.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 399600\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-12-59\n",
      "  done: false\n",
      "  episode_len_mean: 101.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.300000000000018\n",
      "  episode_reward_mean: 7.2150000000000185\n",
      "  episode_reward_min: 0.9000000000000155\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3680\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5102348367373148\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005987592978732724\n",
      "          policy_loss: 0.004316509124778566\n",
      "          total_loss: 0.19796461682944072\n",
      "          vf_explained_var: 0.9547319412231445\n",
      "          vf_loss: 0.19965679860186009\n",
      "    num_agent_steps_sampled: 399600\n",
      "    num_agent_steps_trained: 399600\n",
      "    num_steps_sampled: 399600\n",
      "    num_steps_trained: 399600\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96944444444446\n",
      "    ram_util_percent: 30.769444444444453\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434460398012877\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.085818545565058\n",
      "    mean_inference_ms: 2.4808714262171496\n",
      "    mean_raw_obs_processing_ms: 1.9452650217950458\n",
      "  time_since_restore: 5261.0468719005585\n",
      "  time_this_iter_s: 24.796430587768555\n",
      "  time_total_s: 5261.0468719005585\n",
      "  timers:\n",
      "    learn_throughput: 1140.736\n",
      "    learn_time_ms: 1751.501\n",
      "    load_throughput: 58663.483\n",
      "    load_time_ms: 34.059\n",
      "    sample_throughput: 74.186\n",
      "    sample_time_ms: 26932.482\n",
      "    update_time_ms: 10.713\n",
      "  timestamp: 1636434779\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 399600\n",
      "  training_iteration: 200\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">         5261.05</td><td style=\"text-align: right;\">399600</td><td style=\"text-align: right;\">   7.215</td><td style=\"text-align: right;\">                14.3</td><td style=\"text-align: right;\">                 0.9</td><td style=\"text-align: right;\">            101.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 401598\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-13-24\n",
      "  done: false\n",
      "  episode_len_mean: 102.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.300000000000018\n",
      "  episode_reward_mean: 7.38390000000002\n",
      "  episode_reward_min: 0.9000000000000155\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3701\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4527187194143023\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007611540033007009\n",
      "          policy_loss: -0.019299078626292092\n",
      "          total_loss: 0.33173711603241307\n",
      "          vf_explained_var: 0.94244384765625\n",
      "          vf_loss: 0.3540033568228994\n",
      "    num_agent_steps_sampled: 401598\n",
      "    num_agent_steps_trained: 401598\n",
      "    num_steps_sampled: 401598\n",
      "    num_steps_trained: 401598\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.65555555555555\n",
      "    ram_util_percent: 30.77777777777777\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434285474650023\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.08953369693843\n",
      "    mean_inference_ms: 2.480958536412169\n",
      "    mean_raw_obs_processing_ms: 1.9383308282204712\n",
      "  time_since_restore: 5286.232569694519\n",
      "  time_this_iter_s: 25.18569779396057\n",
      "  time_total_s: 5286.232569694519\n",
      "  timers:\n",
      "    learn_throughput: 1141.446\n",
      "    learn_time_ms: 1750.411\n",
      "    load_throughput: 59130.351\n",
      "    load_time_ms: 33.79\n",
      "    sample_throughput: 74.09\n",
      "    sample_time_ms: 26967.24\n",
      "    update_time_ms: 11.268\n",
      "  timestamp: 1636434804\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 401598\n",
      "  training_iteration: 201\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         5286.23</td><td style=\"text-align: right;\">401598</td><td style=\"text-align: right;\">  7.3839</td><td style=\"text-align: right;\">                14.3</td><td style=\"text-align: right;\">                 0.9</td><td style=\"text-align: right;\">            102.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 403596\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-13-50\n",
      "  done: false\n",
      "  episode_len_mean: 101.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.300000000000018\n",
      "  episode_reward_mean: 7.545600000000018\n",
      "  episode_reward_min: 0.9000000000000155\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3721\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4078906030881972\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0082239185134488\n",
      "          policy_loss: -0.02033132401605447\n",
      "          total_loss: 0.24854694319268067\n",
      "          vf_explained_var: 0.9358932971954346\n",
      "          vf_loss: 0.2704670977024805\n",
      "    num_agent_steps_sampled: 403596\n",
      "    num_agent_steps_trained: 403596\n",
      "    num_steps_sampled: 403596\n",
      "    num_steps_trained: 403596\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03333333333336\n",
      "    ram_util_percent: 30.71111111111111\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431803985243677\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.09798913117278\n",
      "    mean_inference_ms: 2.4806346351842574\n",
      "    mean_raw_obs_processing_ms: 1.932034231035372\n",
      "  time_since_restore: 5311.99951672554\n",
      "  time_this_iter_s: 25.766947031021118\n",
      "  time_total_s: 5311.99951672554\n",
      "  timers:\n",
      "    learn_throughput: 1147.641\n",
      "    learn_time_ms: 1740.963\n",
      "    load_throughput: 59255.573\n",
      "    load_time_ms: 33.718\n",
      "    sample_throughput: 74.127\n",
      "    sample_time_ms: 26953.747\n",
      "    update_time_ms: 9.355\n",
      "  timestamp: 1636434830\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 403596\n",
      "  training_iteration: 202\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   202</td><td style=\"text-align: right;\">            5312</td><td style=\"text-align: right;\">403596</td><td style=\"text-align: right;\">  7.5456</td><td style=\"text-align: right;\">                14.3</td><td style=\"text-align: right;\">                 0.9</td><td style=\"text-align: right;\">            101.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 405594\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-14-15\n",
      "  done: false\n",
      "  episode_len_mean: 100.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.300000000000018\n",
      "  episode_reward_mean: 7.471700000000018\n",
      "  episode_reward_min: 0.9000000000000155\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3740\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3676210454532078\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013777990252600172\n",
      "          policy_loss: 0.007458950135679472\n",
      "          total_loss: 0.3488426962601287\n",
      "          vf_explained_var: 0.9389707446098328\n",
      "          vf_loss: 0.33413463603882565\n",
      "    num_agent_steps_sampled: 405594\n",
      "    num_agent_steps_trained: 405594\n",
      "    num_steps_sampled: 405594\n",
      "    num_steps_trained: 405594\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08648648648649\n",
      "    ram_util_percent: 30.71621621621621\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044318984479274334\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.105592632155666\n",
      "    mean_inference_ms: 2.480574536982715\n",
      "    mean_raw_obs_processing_ms: 1.9264331148428788\n",
      "  time_since_restore: 5337.648384094238\n",
      "  time_this_iter_s: 25.64886736869812\n",
      "  time_total_s: 5337.648384094238\n",
      "  timers:\n",
      "    learn_throughput: 1147.585\n",
      "    learn_time_ms: 1741.047\n",
      "    load_throughput: 59262.864\n",
      "    load_time_ms: 33.714\n",
      "    sample_throughput: 74.168\n",
      "    sample_time_ms: 26938.922\n",
      "    update_time_ms: 9.041\n",
      "  timestamp: 1636434855\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 405594\n",
      "  training_iteration: 203\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   203</td><td style=\"text-align: right;\">         5337.65</td><td style=\"text-align: right;\">405594</td><td style=\"text-align: right;\">  7.4717</td><td style=\"text-align: right;\">                14.3</td><td style=\"text-align: right;\">                 0.9</td><td style=\"text-align: right;\">            100.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 407592\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-14-40\n",
      "  done: false\n",
      "  episode_len_mean: 100.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.250000000000018\n",
      "  episode_reward_mean: 7.387900000000017\n",
      "  episode_reward_min: 0.9000000000000155\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3760\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3782679901236579\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013068721813960129\n",
      "          policy_loss: 0.005265944424484457\n",
      "          total_loss: 0.3531583031905549\n",
      "          vf_explained_var: 0.9376431703567505\n",
      "          vf_loss: 0.34182691708916707\n",
      "    num_agent_steps_sampled: 407592\n",
      "    num_agent_steps_trained: 407592\n",
      "    num_steps_sampled: 407592\n",
      "    num_steps_trained: 407592\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.35714285714286\n",
      "    ram_util_percent: 30.608571428571427\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429659084453629\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.11148515034466\n",
      "    mean_inference_ms: 2.480344785989512\n",
      "    mean_raw_obs_processing_ms: 1.9200960255990704\n",
      "  time_since_restore: 5362.375477075577\n",
      "  time_this_iter_s: 24.7270929813385\n",
      "  time_total_s: 5362.375477075577\n",
      "  timers:\n",
      "    learn_throughput: 1149.063\n",
      "    learn_time_ms: 1738.807\n",
      "    load_throughput: 59488.986\n",
      "    load_time_ms: 33.586\n",
      "    sample_throughput: 78.689\n",
      "    sample_time_ms: 25391.074\n",
      "    update_time_ms: 8.719\n",
      "  timestamp: 1636434880\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 407592\n",
      "  training_iteration: 204\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">         5362.38</td><td style=\"text-align: right;\">407592</td><td style=\"text-align: right;\">  7.3879</td><td style=\"text-align: right;\">               14.25</td><td style=\"text-align: right;\">                 0.9</td><td style=\"text-align: right;\">            100.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 409590\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-15-05\n",
      "  done: false\n",
      "  episode_len_mean: 100.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.250000000000018\n",
      "  episode_reward_mean: 7.559800000000017\n",
      "  episode_reward_min: 0.9899999999999991\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3779\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3832927953629266\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009311567854551344\n",
      "          policy_loss: -0.03272637747937725\n",
      "          total_loss: 0.3228616366517686\n",
      "          vf_explained_var: 0.9489102959632874\n",
      "          vf_loss: 0.35527899815213115\n",
      "    num_agent_steps_sampled: 409590\n",
      "    num_agent_steps_trained: 409590\n",
      "    num_steps_sampled: 409590\n",
      "    num_steps_trained: 409590\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.71111111111111\n",
      "    ram_util_percent: 30.61944444444445\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428960596076477\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.11659916006556\n",
      "    mean_inference_ms: 2.4802786854187158\n",
      "    mean_raw_obs_processing_ms: 1.9143462365351234\n",
      "  time_since_restore: 5387.482350349426\n",
      "  time_this_iter_s: 25.106873273849487\n",
      "  time_total_s: 5387.482350349426\n",
      "  timers:\n",
      "    learn_throughput: 1149.946\n",
      "    learn_time_ms: 1737.473\n",
      "    load_throughput: 59589.069\n",
      "    load_time_ms: 33.53\n",
      "    sample_throughput: 84.681\n",
      "    sample_time_ms: 23594.497\n",
      "    update_time_ms: 7.922\n",
      "  timestamp: 1636434905\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 409590\n",
      "  training_iteration: 205\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   205</td><td style=\"text-align: right;\">         5387.48</td><td style=\"text-align: right;\">409590</td><td style=\"text-align: right;\">  7.5598</td><td style=\"text-align: right;\">               14.25</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">            100.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 411588\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-15-31\n",
      "  done: false\n",
      "  episode_len_mean: 100.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.29000000000002\n",
      "  episode_reward_mean: 7.737100000000019\n",
      "  episode_reward_min: 0.9899999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3799\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3698470467612858\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005793916313106651\n",
      "          policy_loss: -0.0210768841561817\n",
      "          total_loss: 0.2192581245675683\n",
      "          vf_explained_var: 0.9524614810943604\n",
      "          vf_loss: 0.245233967261655\n",
      "    num_agent_steps_sampled: 411588\n",
      "    num_agent_steps_trained: 411588\n",
      "    num_steps_sampled: 411588\n",
      "    num_steps_trained: 411588\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.52972972972972\n",
      "    ram_util_percent: 30.537837837837834\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426823897181235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.124720328686582\n",
      "    mean_inference_ms: 2.479929638199083\n",
      "    mean_raw_obs_processing_ms: 1.9083364411600336\n",
      "  time_since_restore: 5412.868365526199\n",
      "  time_this_iter_s: 25.38601517677307\n",
      "  time_total_s: 5412.868365526199\n",
      "  timers:\n",
      "    learn_throughput: 1156.74\n",
      "    learn_time_ms: 1727.267\n",
      "    load_throughput: 59455.517\n",
      "    load_time_ms: 33.605\n",
      "    sample_throughput: 84.803\n",
      "    sample_time_ms: 23560.44\n",
      "    update_time_ms: 7.482\n",
      "  timestamp: 1636434931\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 411588\n",
      "  training_iteration: 206\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   206</td><td style=\"text-align: right;\">         5412.87</td><td style=\"text-align: right;\">411588</td><td style=\"text-align: right;\">  7.7371</td><td style=\"text-align: right;\">               14.29</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">            100.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 413586\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-15-54\n",
      "  done: false\n",
      "  episode_len_mean: 102.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.29000000000002\n",
      "  episode_reward_mean: 7.67710000000002\n",
      "  episode_reward_min: 0.9899999999999991\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3817\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4270921559560867\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009653939559028716\n",
      "          policy_loss: -0.034379507468215054\n",
      "          total_loss: 0.3482711355601038\n",
      "          vf_explained_var: 0.932550311088562\n",
      "          vf_loss: 0.3822596435745557\n",
      "    num_agent_steps_sampled: 413586\n",
      "    num_agent_steps_trained: 413586\n",
      "    num_steps_sampled: 413586\n",
      "    num_steps_trained: 413586\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.58181818181818\n",
      "    ram_util_percent: 30.536363636363635\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426031167462708\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.13023548929209\n",
      "    mean_inference_ms: 2.4797334515535217\n",
      "    mean_raw_obs_processing_ms: 1.903006371901712\n",
      "  time_since_restore: 5436.564793586731\n",
      "  time_this_iter_s: 23.696428060531616\n",
      "  time_total_s: 5436.564793586731\n",
      "  timers:\n",
      "    learn_throughput: 1157.883\n",
      "    learn_time_ms: 1725.563\n",
      "    load_throughput: 59118.379\n",
      "    load_time_ms: 33.797\n",
      "    sample_throughput: 85.612\n",
      "    sample_time_ms: 23337.841\n",
      "    update_time_ms: 7.683\n",
      "  timestamp: 1636434954\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 413586\n",
      "  training_iteration: 207\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   207</td><td style=\"text-align: right;\">         5436.56</td><td style=\"text-align: right;\">413586</td><td style=\"text-align: right;\">  7.6771</td><td style=\"text-align: right;\">               14.29</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">            102.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 415584\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-16-19\n",
      "  done: false\n",
      "  episode_len_mean: 103.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.29000000000002\n",
      "  episode_reward_mean: 7.983200000000019\n",
      "  episode_reward_min: 0.9899999999999991\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3836\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3765817000752403\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009518058929156427\n",
      "          policy_loss: -0.04651528251845212\n",
      "          total_loss: 0.2736314704730397\n",
      "          vf_explained_var: 0.939660370349884\n",
      "          vf_loss: 0.31945701787869135\n",
      "    num_agent_steps_sampled: 415584\n",
      "    num_agent_steps_trained: 415584\n",
      "    num_steps_sampled: 415584\n",
      "    num_steps_trained: 415584\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.40555555555555\n",
      "    ram_util_percent: 30.522222222222222\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044247759947617406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.133464887703802\n",
      "    mean_inference_ms: 2.479531481362995\n",
      "    mean_raw_obs_processing_ms: 1.8970412573530562\n",
      "  time_since_restore: 5461.500623464584\n",
      "  time_this_iter_s: 24.935829877853394\n",
      "  time_total_s: 5461.500623464584\n",
      "  timers:\n",
      "    learn_throughput: 1158.596\n",
      "    learn_time_ms: 1724.5\n",
      "    load_throughput: 59139.99\n",
      "    load_time_ms: 33.784\n",
      "    sample_throughput: 85.811\n",
      "    sample_time_ms: 23283.798\n",
      "    update_time_ms: 8.266\n",
      "  timestamp: 1636434979\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 415584\n",
      "  training_iteration: 208\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">          5461.5</td><td style=\"text-align: right;\">415584</td><td style=\"text-align: right;\">  7.9832</td><td style=\"text-align: right;\">               14.29</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">            103.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 417582\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-16-44\n",
      "  done: false\n",
      "  episode_len_mean: 104.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.29000000000002\n",
      "  episode_reward_mean: 8.000100000000018\n",
      "  episode_reward_min: 0.9899999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3856\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3685457490739368\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013238719124394734\n",
      "          policy_loss: -0.0432831039563531\n",
      "          total_loss: 0.3477289775652545\n",
      "          vf_explained_var: 0.932616651058197\n",
      "          vf_loss: 0.38459123681698526\n",
      "    num_agent_steps_sampled: 417582\n",
      "    num_agent_steps_trained: 417582\n",
      "    num_steps_sampled: 417582\n",
      "    num_steps_trained: 417582\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.19722222222221\n",
      "    ram_util_percent: 30.522222222222215\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426175245197795\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.13443316217592\n",
      "    mean_inference_ms: 2.479608131735176\n",
      "    mean_raw_obs_processing_ms: 1.8911434896160062\n",
      "  time_since_restore: 5486.5932903289795\n",
      "  time_this_iter_s: 25.09266686439514\n",
      "  time_total_s: 5486.5932903289795\n",
      "  timers:\n",
      "    learn_throughput: 1156.684\n",
      "    learn_time_ms: 1727.351\n",
      "    load_throughput: 59175.278\n",
      "    load_time_ms: 33.764\n",
      "    sample_throughput: 85.914\n",
      "    sample_time_ms: 23255.686\n",
      "    update_time_ms: 8.741\n",
      "  timestamp: 1636435004\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 417582\n",
      "  training_iteration: 209\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   209</td><td style=\"text-align: right;\">         5486.59</td><td style=\"text-align: right;\">417582</td><td style=\"text-align: right;\">  8.0001</td><td style=\"text-align: right;\">               14.29</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">            104.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 419580\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-17-09\n",
      "  done: false\n",
      "  episode_len_mean: 105.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.29000000000002\n",
      "  episode_reward_mean: 8.25540000000002\n",
      "  episode_reward_min: 2.360000000000018\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3875\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3125086369968595\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00920022130048425\n",
      "          policy_loss: -0.024417151714719476\n",
      "          total_loss: 0.3695090220708932\n",
      "          vf_explained_var: 0.9234254360198975\n",
      "          vf_loss: 0.39307842212063926\n",
      "    num_agent_steps_sampled: 419580\n",
      "    num_agent_steps_trained: 419580\n",
      "    num_steps_sampled: 419580\n",
      "    num_steps_trained: 419580\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79117647058823\n",
      "    ram_util_percent: 30.467647058823527\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428169717471772\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.13182736708542\n",
      "    mean_inference_ms: 2.479776132717439\n",
      "    mean_raw_obs_processing_ms: 1.8854536032021951\n",
      "  time_since_restore: 5510.872336149216\n",
      "  time_this_iter_s: 24.279045820236206\n",
      "  time_total_s: 5510.872336149216\n",
      "  timers:\n",
      "    learn_throughput: 1157.403\n",
      "    learn_time_ms: 1726.279\n",
      "    load_throughput: 59162.995\n",
      "    load_time_ms: 33.771\n",
      "    sample_throughput: 86.104\n",
      "    sample_time_ms: 23204.519\n",
      "    update_time_ms: 9.168\n",
      "  timestamp: 1636435029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 419580\n",
      "  training_iteration: 210\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   210</td><td style=\"text-align: right;\">         5510.87</td><td style=\"text-align: right;\">419580</td><td style=\"text-align: right;\">  8.2554</td><td style=\"text-align: right;\">               14.29</td><td style=\"text-align: right;\">                2.36</td><td style=\"text-align: right;\">            105.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 421578\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-17-33\n",
      "  done: false\n",
      "  episode_len_mean: 105.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.29000000000002\n",
      "  episode_reward_mean: 8.238200000000019\n",
      "  episode_reward_min: 2.360000000000018\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 3893\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3969667377926054\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006333611800124395\n",
      "          policy_loss: 0.007289713940450124\n",
      "          total_loss: 0.2970615019046125\n",
      "          vf_explained_var: 0.950057864189148\n",
      "          vf_loss: 0.2941222839057446\n",
      "    num_agent_steps_sampled: 421578\n",
      "    num_agent_steps_trained: 421578\n",
      "    num_steps_sampled: 421578\n",
      "    num_steps_trained: 421578\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.01428571428572\n",
      "    ram_util_percent: 30.537142857142857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428197110584871\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.135356599103975\n",
      "    mean_inference_ms: 2.4795782528213097\n",
      "    mean_raw_obs_processing_ms: 1.880302151185382\n",
      "  time_since_restore: 5535.327670574188\n",
      "  time_this_iter_s: 24.455334424972534\n",
      "  time_total_s: 5535.327670574188\n",
      "  timers:\n",
      "    learn_throughput: 1156.833\n",
      "    learn_time_ms: 1727.129\n",
      "    load_throughput: 58937.102\n",
      "    load_time_ms: 33.901\n",
      "    sample_throughput: 86.378\n",
      "    sample_time_ms: 23131.015\n",
      "    update_time_ms: 8.538\n",
      "  timestamp: 1636435053\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 421578\n",
      "  training_iteration: 211\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   211</td><td style=\"text-align: right;\">         5535.33</td><td style=\"text-align: right;\">421578</td><td style=\"text-align: right;\">  8.2382</td><td style=\"text-align: right;\">               14.29</td><td style=\"text-align: right;\">                2.36</td><td style=\"text-align: right;\">            105.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 423576\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-18-11\n",
      "  done: false\n",
      "  episode_len_mean: 106.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.010000000000021\n",
      "  episode_reward_mean: 8.165900000000018\n",
      "  episode_reward_min: 2.360000000000018\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3912\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.279895788147336\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006571204258004715\n",
      "          policy_loss: 0.03372973388149625\n",
      "          total_loss: 0.26866457521516296\n",
      "          vf_explained_var: 0.9428728222846985\n",
      "          vf_loss: 0.23775378107315018\n",
      "    num_agent_steps_sampled: 423576\n",
      "    num_agent_steps_trained: 423576\n",
      "    num_steps_sampled: 423576\n",
      "    num_steps_trained: 423576\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.92545454545454\n",
      "    ram_util_percent: 30.4709090909091\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429175246857462\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.131372456984153\n",
      "    mean_inference_ms: 2.479612552151235\n",
      "    mean_raw_obs_processing_ms: 1.8815236586806645\n",
      "  time_since_restore: 5573.230924129486\n",
      "  time_this_iter_s: 37.90325355529785\n",
      "  time_total_s: 5573.230924129486\n",
      "  timers:\n",
      "    learn_throughput: 1156.992\n",
      "    learn_time_ms: 1726.891\n",
      "    load_throughput: 58816.771\n",
      "    load_time_ms: 33.97\n",
      "    sample_throughput: 82.071\n",
      "    sample_time_ms: 24344.826\n",
      "    update_time_ms: 8.556\n",
      "  timestamp: 1636435091\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 423576\n",
      "  training_iteration: 212\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">         5573.23</td><td style=\"text-align: right;\">423576</td><td style=\"text-align: right;\">  8.1659</td><td style=\"text-align: right;\">               14.01</td><td style=\"text-align: right;\">                2.36</td><td style=\"text-align: right;\">            106.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 425574\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-18-51\n",
      "  done: false\n",
      "  episode_len_mean: 102.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.010000000000021\n",
      "  episode_reward_mean: 7.749200000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 3933\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3846381136349268\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010730145900681755\n",
      "          policy_loss: -0.023783747319664275\n",
      "          total_loss: 0.48954094457661823\n",
      "          vf_explained_var: 0.9076771140098572\n",
      "          vf_loss: 0.5108746661848965\n",
      "    num_agent_steps_sampled: 425574\n",
      "    num_agent_steps_trained: 425574\n",
      "    num_steps_sampled: 425574\n",
      "    num_steps_trained: 425574\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.54385964912281\n",
      "    ram_util_percent: 30.249122807017542\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044304571169305994\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.124435352136324\n",
      "    mean_inference_ms: 2.4796872743818823\n",
      "    mean_raw_obs_processing_ms: 1.899870886648413\n",
      "  time_since_restore: 5613.481152534485\n",
      "  time_this_iter_s: 40.25022840499878\n",
      "  time_total_s: 5613.481152534485\n",
      "  timers:\n",
      "    learn_throughput: 1158.391\n",
      "    learn_time_ms: 1724.806\n",
      "    load_throughput: 58774.695\n",
      "    load_time_ms: 33.994\n",
      "    sample_throughput: 77.419\n",
      "    sample_time_ms: 25807.672\n",
      "    update_time_ms: 8.005\n",
      "  timestamp: 1636435131\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 425574\n",
      "  training_iteration: 213\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   213</td><td style=\"text-align: right;\">         5613.48</td><td style=\"text-align: right;\">425574</td><td style=\"text-align: right;\">  7.7492</td><td style=\"text-align: right;\">               14.01</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            102.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 427572\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-19-19\n",
      "  done: false\n",
      "  episode_len_mean: 101.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.010000000000021\n",
      "  episode_reward_mean: 7.886900000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3953\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3264337051482427\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008819304717652654\n",
      "          policy_loss: -0.036309508979320525\n",
      "          total_loss: 0.27472333056142645\n",
      "          vf_explained_var: 0.9517669677734375\n",
      "          vf_loss: 0.310902858986741\n",
      "    num_agent_steps_sampled: 427572\n",
      "    num_agent_steps_trained: 427572\n",
      "    num_steps_sampled: 427572\n",
      "    num_steps_trained: 427572\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1975\n",
      "    ram_util_percent: 29.935000000000002\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429746532529334\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.127551131198786\n",
      "    mean_inference_ms: 2.4793371042787733\n",
      "    mean_raw_obs_processing_ms: 1.9175766830690868\n",
      "  time_since_restore: 5641.240750312805\n",
      "  time_this_iter_s: 27.759597778320312\n",
      "  time_total_s: 5641.240750312805\n",
      "  timers:\n",
      "    learn_throughput: 1159.515\n",
      "    learn_time_ms: 1723.134\n",
      "    load_throughput: 59479.739\n",
      "    load_time_ms: 33.591\n",
      "    sample_throughput: 76.516\n",
      "    sample_time_ms: 26112.284\n",
      "    update_time_ms: 8.528\n",
      "  timestamp: 1636435159\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 427572\n",
      "  training_iteration: 214\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   214</td><td style=\"text-align: right;\">         5641.24</td><td style=\"text-align: right;\">427572</td><td style=\"text-align: right;\">  7.8869</td><td style=\"text-align: right;\">               14.01</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            101.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 429570\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-19-44\n",
      "  done: false\n",
      "  episode_len_mean: 101.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.87000000000002\n",
      "  episode_reward_mean: 7.677000000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 3973\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.363589328243619\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006669223330982463\n",
      "          policy_loss: -0.03294741103336925\n",
      "          total_loss: 0.21575901185472807\n",
      "          vf_explained_var: 0.9427846074104309\n",
      "          vf_loss: 0.252213433633248\n",
      "    num_agent_steps_sampled: 429570\n",
      "    num_agent_steps_trained: 429570\n",
      "    num_steps_sampled: 429570\n",
      "    num_steps_trained: 429570\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04857142857142\n",
      "    ram_util_percent: 30.26857142857143\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429942096960628\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.13040906332139\n",
      "    mean_inference_ms: 2.479164191502814\n",
      "    mean_raw_obs_processing_ms: 1.9353300709633867\n",
      "  time_since_restore: 5666.300874948502\n",
      "  time_this_iter_s: 25.06012463569641\n",
      "  time_total_s: 5666.300874948502\n",
      "  timers:\n",
      "    learn_throughput: 1160.017\n",
      "    learn_time_ms: 1722.388\n",
      "    load_throughput: 59299.096\n",
      "    load_time_ms: 33.694\n",
      "    sample_throughput: 76.531\n",
      "    sample_time_ms: 26107.173\n",
      "    update_time_ms: 9.371\n",
      "  timestamp: 1636435184\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 429570\n",
      "  training_iteration: 215\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   215</td><td style=\"text-align: right;\">          5666.3</td><td style=\"text-align: right;\">429570</td><td style=\"text-align: right;\">   7.677</td><td style=\"text-align: right;\">               13.87</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            101.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 431568\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-20-10\n",
      "  done: false\n",
      "  episode_len_mean: 101.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.87000000000002\n",
      "  episode_reward_mean: 7.617200000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 3992\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4217577270099095\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0053954993923701665\n",
      "          policy_loss: -0.042992914219697316\n",
      "          total_loss: 0.2115221241045566\n",
      "          vf_explained_var: 0.9416049122810364\n",
      "          vf_loss: 0.26053820294993263\n",
      "    num_agent_steps_sampled: 431568\n",
      "    num_agent_steps_trained: 431568\n",
      "    num_steps_sampled: 431568\n",
      "    num_steps_trained: 431568\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11891891891892\n",
      "    ram_util_percent: 30.47027027027026\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044304718060381026\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.131536336578918\n",
      "    mean_inference_ms: 2.479113267476877\n",
      "    mean_raw_obs_processing_ms: 1.9520301255477972\n",
      "  time_since_restore: 5692.082402944565\n",
      "  time_this_iter_s: 25.781527996063232\n",
      "  time_total_s: 5692.082402944565\n",
      "  timers:\n",
      "    learn_throughput: 1160.361\n",
      "    learn_time_ms: 1721.878\n",
      "    load_throughput: 59482.779\n",
      "    load_time_ms: 33.59\n",
      "    sample_throughput: 76.412\n",
      "    sample_time_ms: 26147.728\n",
      "    update_time_ms: 9.049\n",
      "  timestamp: 1636435210\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 431568\n",
      "  training_iteration: 216\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   216</td><td style=\"text-align: right;\">         5692.08</td><td style=\"text-align: right;\">431568</td><td style=\"text-align: right;\">  7.6172</td><td style=\"text-align: right;\">               13.87</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            101.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 433566\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-20-36\n",
      "  done: false\n",
      "  episode_len_mean: 99.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.87000000000002\n",
      "  episode_reward_mean: 7.339900000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4011\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000005\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4008613251504445\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.004759025168157276\n",
      "          policy_loss: 0.007995230926289445\n",
      "          total_loss: 0.1412312498582261\n",
      "          vf_explained_var: 0.9699461460113525\n",
      "          vf_loss: 0.14001686026652654\n",
      "    num_agent_steps_sampled: 433566\n",
      "    num_agent_steps_trained: 433566\n",
      "    num_steps_sampled: 433566\n",
      "    num_steps_trained: 433566\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.81891891891892\n",
      "    ram_util_percent: 30.591891891891887\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430515863452856\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.138820390671626\n",
      "    mean_inference_ms: 2.4789493789536188\n",
      "    mean_raw_obs_processing_ms: 1.9630173303011194\n",
      "  time_since_restore: 5718.082285642624\n",
      "  time_this_iter_s: 25.999882698059082\n",
      "  time_total_s: 5718.082285642624\n",
      "  timers:\n",
      "    learn_throughput: 1159.405\n",
      "    learn_time_ms: 1723.298\n",
      "    load_throughput: 59513.616\n",
      "    load_time_ms: 33.572\n",
      "    sample_throughput: 75.749\n",
      "    sample_time_ms: 26376.757\n",
      "    update_time_ms: 9.051\n",
      "  timestamp: 1636435236\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 433566\n",
      "  training_iteration: 217\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   217</td><td style=\"text-align: right;\">         5718.08</td><td style=\"text-align: right;\">433566</td><td style=\"text-align: right;\">  7.3399</td><td style=\"text-align: right;\">               13.87</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 435564\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 101.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.060000000000025\n",
      "  episode_reward_mean: 7.501900000000018\n",
      "  episode_reward_min: 1.0600000000000116\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4031\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3988518652461823\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006671857338335012\n",
      "          policy_loss: -0.06684733685993013\n",
      "          total_loss: 0.07227654113833393\n",
      "          vf_explained_var: 0.9704297780990601\n",
      "          vf_loss: 0.14804595437433038\n",
      "    num_agent_steps_sampled: 435564\n",
      "    num_agent_steps_trained: 435564\n",
      "    num_steps_sampled: 435564\n",
      "    num_steps_trained: 435564\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.60000000000002\n",
      "    ram_util_percent: 30.718918918918927\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431201111497107\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.150232280641557\n",
      "    mean_inference_ms: 2.4789059191691534\n",
      "    mean_raw_obs_processing_ms: 1.9574474223394762\n",
      "  time_since_restore: 5743.556685209274\n",
      "  time_this_iter_s: 25.47439956665039\n",
      "  time_total_s: 5743.556685209274\n",
      "  timers:\n",
      "    learn_throughput: 1158.63\n",
      "    learn_time_ms: 1724.451\n",
      "    load_throughput: 59525.03\n",
      "    load_time_ms: 33.566\n",
      "    sample_throughput: 75.596\n",
      "    sample_time_ms: 26430.097\n",
      "    update_time_ms: 8.205\n",
      "  timestamp: 1636435262\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 435564\n",
      "  training_iteration: 218\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   218</td><td style=\"text-align: right;\">         5743.56</td><td style=\"text-align: right;\">435564</td><td style=\"text-align: right;\">  7.5019</td><td style=\"text-align: right;\">               14.06</td><td style=\"text-align: right;\">                1.06</td><td style=\"text-align: right;\">             101.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 437562\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 102.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.060000000000025\n",
      "  episode_reward_mean: 7.679200000000019\n",
      "  episode_reward_min: 1.0600000000000116\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4051\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4211179710569837\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011467997502750411\n",
      "          policy_loss: -0.028505914534131687\n",
      "          total_loss: 0.34765895830378646\n",
      "          vf_explained_var: 0.9252415895462036\n",
      "          vf_loss: 0.38166753961926414\n",
      "    num_agent_steps_sampled: 437562\n",
      "    num_agent_steps_trained: 437562\n",
      "    num_steps_sampled: 437562\n",
      "    num_steps_trained: 437562\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.93888888888891\n",
      "    ram_util_percent: 30.80277777777778\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432143451607619\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.155901380887062\n",
      "    mean_inference_ms: 2.4789953793146324\n",
      "    mean_raw_obs_processing_ms: 1.9517207927052453\n",
      "  time_since_restore: 5768.676232337952\n",
      "  time_this_iter_s: 25.119547128677368\n",
      "  time_total_s: 5768.676232337952\n",
      "  timers:\n",
      "    learn_throughput: 1160.849\n",
      "    learn_time_ms: 1721.154\n",
      "    load_throughput: 59443.624\n",
      "    load_time_ms: 33.612\n",
      "    sample_throughput: 75.578\n",
      "    sample_time_ms: 26436.425\n",
      "    update_time_ms: 7.772\n",
      "  timestamp: 1636435287\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 437562\n",
      "  training_iteration: 219\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   219</td><td style=\"text-align: right;\">         5768.68</td><td style=\"text-align: right;\">437562</td><td style=\"text-align: right;\">  7.6792</td><td style=\"text-align: right;\">               14.06</td><td style=\"text-align: right;\">                1.06</td><td style=\"text-align: right;\">            102.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 439560\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-21-54\n",
      "  done: false\n",
      "  episode_len_mean: 101.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000018\n",
      "  episode_reward_mean: 7.552200000000019\n",
      "  episode_reward_min: 2.8600000000000136\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4071\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4013859953199115\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00898741161028637\n",
      "          policy_loss: -0.029470389008167244\n",
      "          total_loss: 0.22108642886437121\n",
      "          vf_explained_var: 0.9500879049301147\n",
      "          vf_loss: 0.2577458624683675\n",
      "    num_agent_steps_sampled: 439560\n",
      "    num_agent_steps_trained: 439560\n",
      "    num_steps_sampled: 439560\n",
      "    num_steps_trained: 439560\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9\n",
      "    ram_util_percent: 30.994736842105254\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443280484018106\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.161440602822886\n",
      "    mean_inference_ms: 2.4791203777603474\n",
      "    mean_raw_obs_processing_ms: 1.9458259629157624\n",
      "  time_since_restore: 5795.536376714706\n",
      "  time_this_iter_s: 26.86014437675476\n",
      "  time_total_s: 5795.536376714706\n",
      "  timers:\n",
      "    learn_throughput: 1160.485\n",
      "    learn_time_ms: 1721.694\n",
      "    load_throughput: 59012.097\n",
      "    load_time_ms: 33.857\n",
      "    sample_throughput: 74.848\n",
      "    sample_time_ms: 26694.032\n",
      "    update_time_ms: 7.6\n",
      "  timestamp: 1636435314\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 439560\n",
      "  training_iteration: 220\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   220</td><td style=\"text-align: right;\">         5795.54</td><td style=\"text-align: right;\">439560</td><td style=\"text-align: right;\">  7.5522</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">            101.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 441558\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-22-20\n",
      "  done: false\n",
      "  episode_len_mean: 101.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000018\n",
      "  episode_reward_mean: 7.3808000000000185\n",
      "  episode_reward_min: 2.8600000000000136\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4091\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3310432121867226\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008510455512899855\n",
      "          policy_loss: -0.06406320906465962\n",
      "          total_loss: 0.1616503149891893\n",
      "          vf_explained_var: 0.9555668234825134\n",
      "          vf_loss: 0.2325613283330486\n",
      "    num_agent_steps_sampled: 441558\n",
      "    num_agent_steps_trained: 441558\n",
      "    num_steps_sampled: 441558\n",
      "    num_steps_trained: 441558\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.4972972972973\n",
      "    ram_util_percent: 30.967567567567567\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434149566588591\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.16898632851533\n",
      "    mean_inference_ms: 2.4792344821189523\n",
      "    mean_raw_obs_processing_ms: 1.9402561713251019\n",
      "  time_since_restore: 5821.30760383606\n",
      "  time_this_iter_s: 25.77122712135315\n",
      "  time_total_s: 5821.30760383606\n",
      "  timers:\n",
      "    learn_throughput: 1160.688\n",
      "    learn_time_ms: 1721.393\n",
      "    load_throughput: 59118.462\n",
      "    load_time_ms: 33.797\n",
      "    sample_throughput: 74.481\n",
      "    sample_time_ms: 26825.51\n",
      "    update_time_ms: 7.822\n",
      "  timestamp: 1636435340\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 441558\n",
      "  training_iteration: 221\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   221</td><td style=\"text-align: right;\">         5821.31</td><td style=\"text-align: right;\">441558</td><td style=\"text-align: right;\">  7.3808</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">            101.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 443556\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-22-46\n",
      "  done: false\n",
      "  episode_len_mean: 100.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000018\n",
      "  episode_reward_mean: 7.762300000000018\n",
      "  episode_reward_min: 2.8600000000000136\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4111\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2999965304420107\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011542003710446896\n",
      "          policy_loss: -0.03394757021395933\n",
      "          total_loss: 0.22280513987477338\n",
      "          vf_explained_var: 0.957452654838562\n",
      "          vf_loss: 0.26098796867188956\n",
      "    num_agent_steps_sampled: 443556\n",
      "    num_agent_steps_trained: 443556\n",
      "    num_steps_sampled: 443556\n",
      "    num_steps_trained: 443556\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.37368421052633\n",
      "    ram_util_percent: 30.913157894736845\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434906004568649\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.177806544675843\n",
      "    mean_inference_ms: 2.4792324403511343\n",
      "    mean_raw_obs_processing_ms: 1.9347317285781753\n",
      "  time_since_restore: 5848.1012971401215\n",
      "  time_this_iter_s: 26.79369330406189\n",
      "  time_total_s: 5848.1012971401215\n",
      "  timers:\n",
      "    learn_throughput: 1161.27\n",
      "    learn_time_ms: 1720.531\n",
      "    load_throughput: 59115.46\n",
      "    load_time_ms: 33.798\n",
      "    sample_throughput: 77.696\n",
      "    sample_time_ms: 25715.561\n",
      "    update_time_ms: 7.95\n",
      "  timestamp: 1636435366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 443556\n",
      "  training_iteration: 222\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   222</td><td style=\"text-align: right;\">          5848.1</td><td style=\"text-align: right;\">443556</td><td style=\"text-align: right;\">  7.7623</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">            100.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 445554\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-23-11\n",
      "  done: false\n",
      "  episode_len_mean: 101.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000018\n",
      "  episode_reward_mean: 7.94830000000002\n",
      "  episode_reward_min: 2.8600000000000136\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4130\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3809923438798815\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0104900175239971\n",
      "          policy_loss: -0.04855030890376795\n",
      "          total_loss: 0.1591664365359715\n",
      "          vf_explained_var: 0.9651190638542175\n",
      "          vf_loss: 0.2135608088402521\n",
      "    num_agent_steps_sampled: 445554\n",
      "    num_agent_steps_trained: 445554\n",
      "    num_steps_sampled: 445554\n",
      "    num_steps_trained: 445554\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1542857142857\n",
      "    ram_util_percent: 30.86571428571429\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044344103640549755\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.18639414246916\n",
      "    mean_inference_ms: 2.47907322127203\n",
      "    mean_raw_obs_processing_ms: 1.9294529747514837\n",
      "  time_since_restore: 5872.744430780411\n",
      "  time_this_iter_s: 24.643133640289307\n",
      "  time_total_s: 5872.744430780411\n",
      "  timers:\n",
      "    learn_throughput: 1160.026\n",
      "    learn_time_ms: 1722.376\n",
      "    load_throughput: 59123.509\n",
      "    load_time_ms: 33.794\n",
      "    sample_throughput: 82.723\n",
      "    sample_time_ms: 24152.801\n",
      "    update_time_ms: 8.002\n",
      "  timestamp: 1636435391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 445554\n",
      "  training_iteration: 223\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   223</td><td style=\"text-align: right;\">         5872.74</td><td style=\"text-align: right;\">445554</td><td style=\"text-align: right;\">  7.9483</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">             101.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 447552\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-23-36\n",
      "  done: false\n",
      "  episode_len_mean: 100.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000018\n",
      "  episode_reward_mean: 7.8831000000000175\n",
      "  episode_reward_min: 2.7200000000000135\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4149\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3554069388480414\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010892526932659179\n",
      "          policy_loss: -0.03421865934949546\n",
      "          total_loss: 0.17430946570155875\n",
      "          vf_explained_var: 0.9611020088195801\n",
      "          vf_loss: 0.21381068415939808\n",
      "    num_agent_steps_sampled: 447552\n",
      "    num_agent_steps_trained: 447552\n",
      "    num_steps_sampled: 447552\n",
      "    num_steps_trained: 447552\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.90540540540539\n",
      "    ram_util_percent: 30.827027027027032\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044352182018886216\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.195026253368695\n",
      "    mean_inference_ms: 2.4790642595609302\n",
      "    mean_raw_obs_processing_ms: 1.9243020442548675\n",
      "  time_since_restore: 5898.124879360199\n",
      "  time_this_iter_s: 25.380448579788208\n",
      "  time_total_s: 5898.124879360199\n",
      "  timers:\n",
      "    learn_throughput: 1158.317\n",
      "    learn_time_ms: 1724.916\n",
      "    load_throughput: 58369.292\n",
      "    load_time_ms: 34.23\n",
      "    sample_throughput: 83.555\n",
      "    sample_time_ms: 23912.521\n",
      "    update_time_ms: 7.51\n",
      "  timestamp: 1636435416\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 447552\n",
      "  training_iteration: 224\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   224</td><td style=\"text-align: right;\">         5898.12</td><td style=\"text-align: right;\">447552</td><td style=\"text-align: right;\">  7.8831</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                2.72</td><td style=\"text-align: right;\">            100.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 449550\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-24-01\n",
      "  done: false\n",
      "  episode_len_mean: 102.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.15000000000002\n",
      "  episode_reward_mean: 8.196200000000019\n",
      "  episode_reward_min: 2.4300000000000144\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4168\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3528809819902692\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009393985504883243\n",
      "          policy_loss: -0.04868191122299149\n",
      "          total_loss: 0.2139478820243052\n",
      "          vf_explained_var: 0.9576193690299988\n",
      "          vf_loss: 0.26902504655576887\n",
      "    num_agent_steps_sampled: 449550\n",
      "    num_agent_steps_trained: 449550\n",
      "    num_steps_sampled: 449550\n",
      "    num_steps_trained: 449550\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.29142857142858\n",
      "    ram_util_percent: 30.817142857142862\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433590272583541\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.206271022520212\n",
      "    mean_inference_ms: 2.4786559694168595\n",
      "    mean_raw_obs_processing_ms: 1.9192336819324447\n",
      "  time_since_restore: 5923.191254615784\n",
      "  time_this_iter_s: 25.066375255584717\n",
      "  time_total_s: 5923.191254615784\n",
      "  timers:\n",
      "    learn_throughput: 1156.847\n",
      "    learn_time_ms: 1727.108\n",
      "    load_throughput: 58519.491\n",
      "    load_time_ms: 34.142\n",
      "    sample_throughput: 83.559\n",
      "    sample_time_ms: 23911.353\n",
      "    update_time_ms: 7.277\n",
      "  timestamp: 1636435441\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 449550\n",
      "  training_iteration: 225\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   225</td><td style=\"text-align: right;\">         5923.19</td><td style=\"text-align: right;\">449550</td><td style=\"text-align: right;\">  8.1962</td><td style=\"text-align: right;\">               14.15</td><td style=\"text-align: right;\">                2.43</td><td style=\"text-align: right;\">            102.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 451548\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-24-27\n",
      "  done: false\n",
      "  episode_len_mean: 103.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.15000000000002\n",
      "  episode_reward_mean: 8.352500000000019\n",
      "  episode_reward_min: 2.4300000000000144\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4187\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4676977316538493\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008135077515432885\n",
      "          policy_loss: -0.03464491812600976\n",
      "          total_loss: 0.11237639269481102\n",
      "          vf_explained_var: 0.9695637226104736\n",
      "          vf_loss: 0.1555207148903892\n",
      "    num_agent_steps_sampled: 451548\n",
      "    num_agent_steps_trained: 451548\n",
      "    num_steps_sampled: 451548\n",
      "    num_steps_trained: 451548\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99189189189188\n",
      "    ram_util_percent: 30.80540540540541\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443419330033414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.211753051540107\n",
      "    mean_inference_ms: 2.478615983397157\n",
      "    mean_raw_obs_processing_ms: 1.914077253663115\n",
      "  time_since_restore: 5949.132332324982\n",
      "  time_this_iter_s: 25.941077709197998\n",
      "  time_total_s: 5949.132332324982\n",
      "  timers:\n",
      "    learn_throughput: 1155.927\n",
      "    learn_time_ms: 1728.482\n",
      "    load_throughput: 58315.231\n",
      "    load_time_ms: 34.262\n",
      "    sample_throughput: 83.509\n",
      "    sample_time_ms: 23925.591\n",
      "    update_time_ms: 7.398\n",
      "  timestamp: 1636435467\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 451548\n",
      "  training_iteration: 226\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   226</td><td style=\"text-align: right;\">         5949.13</td><td style=\"text-align: right;\">451548</td><td style=\"text-align: right;\">  8.3525</td><td style=\"text-align: right;\">               14.15</td><td style=\"text-align: right;\">                2.43</td><td style=\"text-align: right;\">             103.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 453546\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-24-53\n",
      "  done: false\n",
      "  episode_len_mean: 104.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000018\n",
      "  episode_reward_mean: 8.526500000000022\n",
      "  episode_reward_min: 2.4300000000000144\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4206\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.351211146513621\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00979814997300227\n",
      "          policy_loss: -0.06926338140453611\n",
      "          total_loss: 0.10444963284369026\n",
      "          vf_explained_var: 0.977556049823761\n",
      "          vf_loss: 0.17978465450661524\n",
      "    num_agent_steps_sampled: 453546\n",
      "    num_agent_steps_trained: 453546\n",
      "    num_steps_sampled: 453546\n",
      "    num_steps_trained: 453546\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.53611111111111\n",
      "    ram_util_percent: 30.78055555555556\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434286737619017\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.214765101505808\n",
      "    mean_inference_ms: 2.4785810873296796\n",
      "    mean_raw_obs_processing_ms: 1.908873070524308\n",
      "  time_since_restore: 5974.134365320206\n",
      "  time_this_iter_s: 25.002032995224\n",
      "  time_total_s: 5974.134365320206\n",
      "  timers:\n",
      "    learn_throughput: 1156.773\n",
      "    learn_time_ms: 1727.219\n",
      "    load_throughput: 58362.341\n",
      "    load_time_ms: 34.234\n",
      "    sample_throughput: 83.853\n",
      "    sample_time_ms: 23827.473\n",
      "    update_time_ms: 6.7\n",
      "  timestamp: 1636435493\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 453546\n",
      "  training_iteration: 227\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   227</td><td style=\"text-align: right;\">         5974.13</td><td style=\"text-align: right;\">453546</td><td style=\"text-align: right;\">  8.5265</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                2.43</td><td style=\"text-align: right;\">            104.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 455544\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-25-19\n",
      "  done: false\n",
      "  episode_len_mean: 103.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000018\n",
      "  episode_reward_mean: 8.457800000000018\n",
      "  episode_reward_min: 2.4300000000000144\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4226\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3006198201860701\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01665013260297835\n",
      "          policy_loss: -0.015487157216384297\n",
      "          total_loss: 0.33184134440407864\n",
      "          vf_explained_var: 0.9566037058830261\n",
      "          vf_loss: 0.34769100417338666\n",
      "    num_agent_steps_sampled: 455544\n",
      "    num_agent_steps_trained: 455544\n",
      "    num_steps_sampled: 455544\n",
      "    num_steps_trained: 455544\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79210526315788\n",
      "    ram_util_percent: 30.718421052631573\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437736907041418\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.21676725026513\n",
      "    mean_inference_ms: 2.4789258422501574\n",
      "    mean_raw_obs_processing_ms: 1.9035245983106475\n",
      "  time_since_restore: 6000.969350814819\n",
      "  time_this_iter_s: 26.834985494613647\n",
      "  time_total_s: 6000.969350814819\n",
      "  timers:\n",
      "    learn_throughput: 1156.677\n",
      "    learn_time_ms: 1727.363\n",
      "    load_throughput: 58408.632\n",
      "    load_time_ms: 34.207\n",
      "    sample_throughput: 83.38\n",
      "    sample_time_ms: 23962.638\n",
      "    update_time_ms: 7.446\n",
      "  timestamp: 1636435519\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 455544\n",
      "  training_iteration: 228\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   228</td><td style=\"text-align: right;\">         6000.97</td><td style=\"text-align: right;\">455544</td><td style=\"text-align: right;\">  8.4578</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                2.43</td><td style=\"text-align: right;\">            103.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 457542\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-25-45\n",
      "  done: false\n",
      "  episode_len_mean: 104.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000018\n",
      "  episode_reward_mean: 8.63120000000002\n",
      "  episode_reward_min: 2.4300000000000144\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4245\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3141901578222002\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009688630643943688\n",
      "          policy_loss: -0.05011291099446161\n",
      "          total_loss: 0.20088039039678518\n",
      "          vf_explained_var: 0.9535611271858215\n",
      "          vf_loss: 0.25677789907370296\n",
      "    num_agent_steps_sampled: 457542\n",
      "    num_agent_steps_trained: 457542\n",
      "    num_steps_sampled: 457542\n",
      "    num_steps_trained: 457542\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96944444444442\n",
      "    ram_util_percent: 30.71111111111111\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436133519912345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.222991070381408\n",
      "    mean_inference_ms: 2.4786686085376437\n",
      "    mean_raw_obs_processing_ms: 1.8983573075117266\n",
      "  time_since_restore: 6026.142954111099\n",
      "  time_this_iter_s: 25.173603296279907\n",
      "  time_total_s: 6026.142954111099\n",
      "  timers:\n",
      "    learn_throughput: 1155.007\n",
      "    learn_time_ms: 1729.859\n",
      "    load_throughput: 58519.614\n",
      "    load_time_ms: 34.142\n",
      "    sample_throughput: 83.374\n",
      "    sample_time_ms: 23964.411\n",
      "    update_time_ms: 8.618\n",
      "  timestamp: 1636435545\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 457542\n",
      "  training_iteration: 229\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   229</td><td style=\"text-align: right;\">         6026.14</td><td style=\"text-align: right;\">457542</td><td style=\"text-align: right;\">  8.6312</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                2.43</td><td style=\"text-align: right;\">            104.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 459540\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-26-26\n",
      "  done: false\n",
      "  episode_len_mean: 103.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000018\n",
      "  episode_reward_mean: 8.563000000000018\n",
      "  episode_reward_min: 2.440000000000018\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4264\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3263503687722342\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009352126929851518\n",
      "          policy_loss: -0.05917033907913026\n",
      "          total_loss: 0.17250109161472038\n",
      "          vf_explained_var: 0.9540281891822815\n",
      "          vf_loss: 0.2378331607651143\n",
      "    num_agent_steps_sampled: 459540\n",
      "    num_agent_steps_trained: 459540\n",
      "    num_steps_sampled: 459540\n",
      "    num_steps_trained: 459540\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.82499999999999\n",
      "    ram_util_percent: 30.71\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044380928005407695\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.22499106596289\n",
      "    mean_inference_ms: 2.4788743933856257\n",
      "    mean_raw_obs_processing_ms: 1.899778632303406\n",
      "  time_since_restore: 6067.694560289383\n",
      "  time_this_iter_s: 41.55160617828369\n",
      "  time_total_s: 6067.694560289383\n",
      "  timers:\n",
      "    learn_throughput: 1154.671\n",
      "    learn_time_ms: 1730.363\n",
      "    load_throughput: 58911.953\n",
      "    load_time_ms: 33.915\n",
      "    sample_throughput: 78.558\n",
      "    sample_time_ms: 25433.533\n",
      "    update_time_ms: 8.455\n",
      "  timestamp: 1636435586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 459540\n",
      "  training_iteration: 230\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   230</td><td style=\"text-align: right;\">         6067.69</td><td style=\"text-align: right;\">459540</td><td style=\"text-align: right;\">   8.563</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                2.44</td><td style=\"text-align: right;\">            103.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 461538\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-27-09\n",
      "  done: false\n",
      "  episode_len_mean: 100.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000018\n",
      "  episode_reward_mean: 8.229700000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4286\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3592003436315627\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012356585775938\n",
      "          policy_loss: -0.049167872805680544\n",
      "          total_loss: 0.40760595943956146\n",
      "          vf_explained_var: 0.919855535030365\n",
      "          vf_loss: 0.46098254975818453\n",
      "    num_agent_steps_sampled: 461538\n",
      "    num_agent_steps_trained: 461538\n",
      "    num_steps_sampled: 461538\n",
      "    num_steps_trained: 461538\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.88032786885248\n",
      "    ram_util_percent: 30.521311475409835\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439706419453781\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.225082981958003\n",
      "    mean_inference_ms: 2.478991608459105\n",
      "    mean_raw_obs_processing_ms: 1.9174025889668749\n",
      "  time_since_restore: 6110.701063156128\n",
      "  time_this_iter_s: 43.006502866744995\n",
      "  time_total_s: 6110.701063156128\n",
      "  timers:\n",
      "    learn_throughput: 1155.147\n",
      "    learn_time_ms: 1729.65\n",
      "    load_throughput: 58508.869\n",
      "    load_time_ms: 34.149\n",
      "    sample_throughput: 73.57\n",
      "    sample_time_ms: 27157.677\n",
      "    update_time_ms: 8.562\n",
      "  timestamp: 1636435629\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 461538\n",
      "  training_iteration: 231\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   231</td><td style=\"text-align: right;\">          6110.7</td><td style=\"text-align: right;\">461538</td><td style=\"text-align: right;\">  8.2297</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            100.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 463536\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-27-38\n",
      "  done: false\n",
      "  episode_len_mean: 99.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.410000000000021\n",
      "  episode_reward_mean: 8.125700000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4307\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2686856627464294\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015850250019343794\n",
      "          policy_loss: -0.05636326008964153\n",
      "          total_loss: 0.30983055036160206\n",
      "          vf_explained_var: 0.9516558051109314\n",
      "          vf_loss: 0.36684438660740853\n",
      "    num_agent_steps_sampled: 463536\n",
      "    num_agent_steps_trained: 463536\n",
      "    num_steps_sampled: 463536\n",
      "    num_steps_trained: 463536\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.43902439024392\n",
      "    ram_util_percent: 30.451219512195117\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044400334644973956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.233760301621643\n",
      "    mean_inference_ms: 2.4789572997319476\n",
      "    mean_raw_obs_processing_ms: 1.9346482026518468\n",
      "  time_since_restore: 6139.071572065353\n",
      "  time_this_iter_s: 28.370508909225464\n",
      "  time_total_s: 6139.071572065353\n",
      "  timers:\n",
      "    learn_throughput: 1153.015\n",
      "    learn_time_ms: 1732.848\n",
      "    load_throughput: 58753.638\n",
      "    load_time_ms: 34.006\n",
      "    sample_throughput: 73.153\n",
      "    sample_time_ms: 27312.614\n",
      "    update_time_ms: 8.219\n",
      "  timestamp: 1636435658\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 463536\n",
      "  training_iteration: 232\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   232</td><td style=\"text-align: right;\">         6139.07</td><td style=\"text-align: right;\">463536</td><td style=\"text-align: right;\">  8.1257</td><td style=\"text-align: right;\">               14.41</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 465534\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-28-04\n",
      "  done: false\n",
      "  episode_len_mean: 99.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.410000000000021\n",
      "  episode_reward_mean: 8.02190000000002\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4328\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3933838418551854\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009699553575118163\n",
      "          policy_loss: -0.04722070926356883\n",
      "          total_loss: 0.13555949183979205\n",
      "          vf_explained_var: 0.9670247435569763\n",
      "          vf_loss: 0.18934843884337516\n",
      "    num_agent_steps_sampled: 465534\n",
      "    num_agent_steps_trained: 465534\n",
      "    num_steps_sampled: 465534\n",
      "    num_steps_trained: 465534\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1972972972973\n",
      "    ram_util_percent: 30.618918918918922\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436991312537005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.244096167257513\n",
      "    mean_inference_ms: 2.478527625963284\n",
      "    mean_raw_obs_processing_ms: 1.9518112458407393\n",
      "  time_since_restore: 6165.282580375671\n",
      "  time_this_iter_s: 26.211008310317993\n",
      "  time_total_s: 6165.282580375671\n",
      "  timers:\n",
      "    learn_throughput: 1151.958\n",
      "    learn_time_ms: 1734.438\n",
      "    load_throughput: 58768.265\n",
      "    load_time_ms: 33.998\n",
      "    sample_throughput: 72.739\n",
      "    sample_time_ms: 27467.92\n",
      "    update_time_ms: 8.104\n",
      "  timestamp: 1636435684\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 465534\n",
      "  training_iteration: 233\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   233</td><td style=\"text-align: right;\">         6165.28</td><td style=\"text-align: right;\">465534</td><td style=\"text-align: right;\">  8.0219</td><td style=\"text-align: right;\">               14.41</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 467532\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-28-30\n",
      "  done: false\n",
      "  episode_len_mean: 97.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 8.042900000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4347\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2354919439270382\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00958693695588597\n",
      "          policy_loss: -0.07151896481712659\n",
      "          total_loss: 0.21608107717086872\n",
      "          vf_explained_var: 0.9574047327041626\n",
      "          vf_loss: 0.2926748777429263\n",
      "    num_agent_steps_sampled: 467532\n",
      "    num_agent_steps_trained: 467532\n",
      "    num_steps_sampled: 467532\n",
      "    num_steps_trained: 467532\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95263157894738\n",
      "    ram_util_percent: 30.734210526315803\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044386486972195785\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.25150049197777\n",
      "    mean_inference_ms: 2.478746897527694\n",
      "    mean_raw_obs_processing_ms: 1.9674990289382612\n",
      "  time_since_restore: 6191.580119132996\n",
      "  time_this_iter_s: 26.29753875732422\n",
      "  time_total_s: 6191.580119132996\n",
      "  timers:\n",
      "    learn_throughput: 1150.91\n",
      "    learn_time_ms: 1736.018\n",
      "    load_throughput: 58434.82\n",
      "    load_time_ms: 34.192\n",
      "    sample_throughput: 72.502\n",
      "    sample_time_ms: 27557.732\n",
      "    update_time_ms: 8.18\n",
      "  timestamp: 1636435710\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 467532\n",
      "  training_iteration: 234\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   234</td><td style=\"text-align: right;\">         6191.58</td><td style=\"text-align: right;\">467532</td><td style=\"text-align: right;\">  8.0429</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 469530\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-28-57\n",
      "  done: false\n",
      "  episode_len_mean: 96.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 8.303500000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4368\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2760256057693844\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011520639400016451\n",
      "          policy_loss: -0.016176851146987508\n",
      "          total_loss: 0.3967879970070152\n",
      "          vf_explained_var: 0.937372088432312\n",
      "          vf_loss: 0.41697662061169033\n",
      "    num_agent_steps_sampled: 469530\n",
      "    num_agent_steps_trained: 469530\n",
      "    num_steps_sampled: 469530\n",
      "    num_steps_trained: 469530\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.75\n",
      "    ram_util_percent: 30.823684210526327\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044355361623176055\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.264646176245552\n",
      "    mean_inference_ms: 2.478343497992483\n",
      "    mean_raw_obs_processing_ms: 1.9739396729402505\n",
      "  time_since_restore: 6218.83738899231\n",
      "  time_this_iter_s: 27.257269859313965\n",
      "  time_total_s: 6218.83738899231\n",
      "  timers:\n",
      "    learn_throughput: 1153.34\n",
      "    learn_time_ms: 1732.359\n",
      "    load_throughput: 58357.952\n",
      "    load_time_ms: 34.237\n",
      "    sample_throughput: 71.919\n",
      "    sample_time_ms: 27781.311\n",
      "    update_time_ms: 7.425\n",
      "  timestamp: 1636435737\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 469530\n",
      "  training_iteration: 235\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   235</td><td style=\"text-align: right;\">         6218.84</td><td style=\"text-align: right;\">469530</td><td style=\"text-align: right;\">  8.3035</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 471528\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-29-24\n",
      "  done: false\n",
      "  episode_len_mean: 99.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 8.516900000000017\n",
      "  episode_reward_min: 2.860000000000012\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4387\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2308317896865664\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009751157006611938\n",
      "          policy_loss: 0.025088711827993392\n",
      "          total_loss: 0.30013408321177676\n",
      "          vf_explained_var: 0.9545026421546936\n",
      "          vf_loss: 0.2799489070971807\n",
      "    num_agent_steps_sampled: 471528\n",
      "    num_agent_steps_trained: 471528\n",
      "    num_steps_sampled: 471528\n",
      "    num_steps_trained: 471528\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.98684210526316\n",
      "    ram_util_percent: 30.98947368421053\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439502356798178\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.27412181676202\n",
      "    mean_inference_ms: 2.478899603201541\n",
      "    mean_raw_obs_processing_ms: 1.969226191794568\n",
      "  time_since_restore: 6245.185316085815\n",
      "  time_this_iter_s: 26.34792709350586\n",
      "  time_total_s: 6245.185316085815\n",
      "  timers:\n",
      "    learn_throughput: 1153.068\n",
      "    learn_time_ms: 1732.769\n",
      "    load_throughput: 58370.431\n",
      "    load_time_ms: 34.23\n",
      "    sample_throughput: 71.815\n",
      "    sample_time_ms: 27821.488\n",
      "    update_time_ms: 7.754\n",
      "  timestamp: 1636435764\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 471528\n",
      "  training_iteration: 236\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">         6245.19</td><td style=\"text-align: right;\">471528</td><td style=\"text-align: right;\">  8.5169</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">             99.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 473526\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-29-50\n",
      "  done: false\n",
      "  episode_len_mean: 100.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 8.486100000000018\n",
      "  episode_reward_min: 2.6200000000000148\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4406\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3644591620990207\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011453841727778948\n",
      "          policy_loss: 0.0027792493103160746\n",
      "          total_loss: 0.36577665216865995\n",
      "          vf_explained_var: 0.9412453174591064\n",
      "          vf_loss: 0.36794423350975625\n",
      "    num_agent_steps_sampled: 473526\n",
      "    num_agent_steps_trained: 473526\n",
      "    num_steps_sampled: 473526\n",
      "    num_steps_trained: 473526\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.36578947368423\n",
      "    ram_util_percent: 31.026315789473678\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04440200790127657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.281843130728284\n",
      "    mean_inference_ms: 2.4790090818839117\n",
      "    mean_raw_obs_processing_ms: 1.9642909480233237\n",
      "  time_since_restore: 6271.6529405117035\n",
      "  time_this_iter_s: 26.46762442588806\n",
      "  time_total_s: 6271.6529405117035\n",
      "  timers:\n",
      "    learn_throughput: 1149.557\n",
      "    learn_time_ms: 1738.061\n",
      "    load_throughput: 58465.355\n",
      "    load_time_ms: 34.174\n",
      "    sample_throughput: 71.452\n",
      "    sample_time_ms: 27962.818\n",
      "    update_time_ms: 7.956\n",
      "  timestamp: 1636435790\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 473526\n",
      "  training_iteration: 237\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   237</td><td style=\"text-align: right;\">         6271.65</td><td style=\"text-align: right;\">473526</td><td style=\"text-align: right;\">  8.4861</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">            100.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 475524\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-30-16\n",
      "  done: false\n",
      "  episode_len_mean: 101.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 8.373700000000019\n",
      "  episode_reward_min: 2.6200000000000148\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4425\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3319811520122347\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008053056215299718\n",
      "          policy_loss: 0.009628250565202463\n",
      "          total_loss: 0.21215450898522423\n",
      "          vf_explained_var: 0.9438986778259277\n",
      "          vf_loss: 0.20973078127773034\n",
      "    num_agent_steps_sampled: 475524\n",
      "    num_agent_steps_trained: 475524\n",
      "    num_steps_sampled: 475524\n",
      "    num_steps_trained: 475524\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.28378378378379\n",
      "    ram_util_percent: 30.929729729729733\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044375766566193804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.291224542695122\n",
      "    mean_inference_ms: 2.4786668349746526\n",
      "    mean_raw_obs_processing_ms: 1.9592706753443985\n",
      "  time_since_restore: 6297.498660564423\n",
      "  time_this_iter_s: 25.845720052719116\n",
      "  time_total_s: 6297.498660564423\n",
      "  timers:\n",
      "    learn_throughput: 1150.011\n",
      "    learn_time_ms: 1737.375\n",
      "    load_throughput: 58287.69\n",
      "    load_time_ms: 34.278\n",
      "    sample_throughput: 71.703\n",
      "    sample_time_ms: 27864.903\n",
      "    update_time_ms: 7.65\n",
      "  timestamp: 1636435816\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 475524\n",
      "  training_iteration: 238\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   238</td><td style=\"text-align: right;\">          6297.5</td><td style=\"text-align: right;\">475524</td><td style=\"text-align: right;\">  8.3737</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">             101.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 477522\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-30-45\n",
      "  done: false\n",
      "  episode_len_mean: 100.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.330000000000021\n",
      "  episode_reward_mean: 7.998700000000018\n",
      "  episode_reward_min: 2.6200000000000148\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4447\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3772950984182812\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00991306893869359\n",
      "          policy_loss: -0.048162706107610746\n",
      "          total_loss: 0.21196600819627445\n",
      "          vf_explained_var: 0.9439867734909058\n",
      "          vf_loss: 0.26637392668496995\n",
      "    num_agent_steps_sampled: 477522\n",
      "    num_agent_steps_trained: 477522\n",
      "    num_steps_sampled: 477522\n",
      "    num_steps_trained: 477522\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5625\n",
      "    ram_util_percent: 30.8975\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044385848164961016\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.296365347631507\n",
      "    mean_inference_ms: 2.478760655897679\n",
      "    mean_raw_obs_processing_ms: 1.953208851081174\n",
      "  time_since_restore: 6325.78614282608\n",
      "  time_this_iter_s: 28.287482261657715\n",
      "  time_total_s: 6325.78614282608\n",
      "  timers:\n",
      "    learn_throughput: 1150.985\n",
      "    learn_time_ms: 1735.905\n",
      "    load_throughput: 58228.479\n",
      "    load_time_ms: 34.313\n",
      "    sample_throughput: 70.908\n",
      "    sample_time_ms: 28177.184\n",
      "    update_time_ms: 7.907\n",
      "  timestamp: 1636435845\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 477522\n",
      "  training_iteration: 239\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   239</td><td style=\"text-align: right;\">         6325.79</td><td style=\"text-align: right;\">477522</td><td style=\"text-align: right;\">  7.9987</td><td style=\"text-align: right;\">               14.33</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">            100.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 479520\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-31-11\n",
      "  done: false\n",
      "  episode_len_mean: 99.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.420000000000016\n",
      "  episode_reward_mean: 7.960100000000019\n",
      "  episode_reward_min: 2.6200000000000148\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4467\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2658016125361125\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013379538338512494\n",
      "          policy_loss: -0.010859778195264794\n",
      "          total_loss: 0.31417925847428185\n",
      "          vf_explained_var: 0.9488290548324585\n",
      "          vf_loss: 0.3275369665097623\n",
      "    num_agent_steps_sampled: 479520\n",
      "    num_agent_steps_trained: 479520\n",
      "    num_steps_sampled: 479520\n",
      "    num_steps_trained: 479520\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.10000000000001\n",
      "    ram_util_percent: 30.87105263157895\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438760701982638\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.30370261033374\n",
      "    mean_inference_ms: 2.4787679432622385\n",
      "    mean_raw_obs_processing_ms: 1.9479634373937058\n",
      "  time_since_restore: 6352.563603878021\n",
      "  time_this_iter_s: 26.777461051940918\n",
      "  time_total_s: 6352.563603878021\n",
      "  timers:\n",
      "    learn_throughput: 1148.805\n",
      "    learn_time_ms: 1739.199\n",
      "    load_throughput: 58318.274\n",
      "    load_time_ms: 34.26\n",
      "    sample_throughput: 74.844\n",
      "    sample_time_ms: 26695.583\n",
      "    update_time_ms: 8.64\n",
      "  timestamp: 1636435871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 479520\n",
      "  training_iteration: 240\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   240</td><td style=\"text-align: right;\">         6352.56</td><td style=\"text-align: right;\">479520</td><td style=\"text-align: right;\">  7.9601</td><td style=\"text-align: right;\">               14.42</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">             99.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 481518\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-31-38\n",
      "  done: false\n",
      "  episode_len_mean: 99.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.420000000000016\n",
      "  episode_reward_mean: 7.691000000000018\n",
      "  episode_reward_min: 2.6200000000000148\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4488\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.37551178250994\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00965331928396451\n",
      "          policy_loss: 0.009095325285480136\n",
      "          total_loss: 0.19875272406886021\n",
      "          vf_explained_var: 0.9524602293968201\n",
      "          vf_loss: 0.19608202887078127\n",
      "    num_agent_steps_sampled: 481518\n",
      "    num_agent_steps_trained: 481518\n",
      "    num_steps_sampled: 481518\n",
      "    num_steps_trained: 481518\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.2552631578947\n",
      "    ram_util_percent: 30.81315789473685\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437687695983849\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.310600417686402\n",
      "    mean_inference_ms: 2.4786123536293014\n",
      "    mean_raw_obs_processing_ms: 1.9424682309918533\n",
      "  time_since_restore: 6379.182383298874\n",
      "  time_this_iter_s: 26.61877942085266\n",
      "  time_total_s: 6379.182383298874\n",
      "  timers:\n",
      "    learn_throughput: 1146.42\n",
      "    learn_time_ms: 1742.816\n",
      "    load_throughput: 58678.065\n",
      "    load_time_ms: 34.05\n",
      "    sample_throughput: 79.752\n",
      "    sample_time_ms: 25052.684\n",
      "    update_time_ms: 9.065\n",
      "  timestamp: 1636435898\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 481518\n",
      "  training_iteration: 241\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   241</td><td style=\"text-align: right;\">         6379.18</td><td style=\"text-align: right;\">481518</td><td style=\"text-align: right;\">   7.691</td><td style=\"text-align: right;\">               14.42</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">             99.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 483516\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-32-05\n",
      "  done: false\n",
      "  episode_len_mean: 97.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 7.548400000000018\n",
      "  episode_reward_min: 2.740000000000012\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4509\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.312893313453311\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007684405106716694\n",
      "          policy_loss: 0.009810957587545827\n",
      "          total_loss: 0.30030811338552404\n",
      "          vf_explained_var: 0.9391478300094604\n",
      "          vf_loss: 0.29779074631986163\n",
      "    num_agent_steps_sampled: 483516\n",
      "    num_agent_steps_trained: 483516\n",
      "    num_steps_sampled: 483516\n",
      "    num_steps_trained: 483516\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.56500000000001\n",
      "    ram_util_percent: 30.847500000000004\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434658303597698\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.320525208002927\n",
      "    mean_inference_ms: 2.4782153764596386\n",
      "    mean_raw_obs_processing_ms: 1.937213032399992\n",
      "  time_since_restore: 6406.619569540024\n",
      "  time_this_iter_s: 27.437186241149902\n",
      "  time_total_s: 6406.619569540024\n",
      "  timers:\n",
      "    learn_throughput: 1148.107\n",
      "    learn_time_ms: 1740.255\n",
      "    load_throughput: 58819.578\n",
      "    load_time_ms: 33.968\n",
      "    sample_throughput: 80.042\n",
      "    sample_time_ms: 24961.837\n",
      "    update_time_ms: 9.097\n",
      "  timestamp: 1636435925\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 483516\n",
      "  training_iteration: 242\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   242</td><td style=\"text-align: right;\">         6406.62</td><td style=\"text-align: right;\">483516</td><td style=\"text-align: right;\">  7.5484</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">                2.74</td><td style=\"text-align: right;\">             97.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 485514\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-32-31\n",
      "  done: false\n",
      "  episode_len_mean: 97.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 7.735400000000016\n",
      "  episode_reward_min: 2.740000000000012\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 4527\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2564848911194575\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009025790051514977\n",
      "          policy_loss: 0.001582207495257968\n",
      "          total_loss: 0.2862723180403312\n",
      "          vf_explained_var: 0.9429119229316711\n",
      "          vf_loss: 0.2904009947819369\n",
      "    num_agent_steps_sampled: 485514\n",
      "    num_agent_steps_trained: 485514\n",
      "    num_steps_sampled: 485514\n",
      "    num_steps_trained: 485514\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9138888888889\n",
      "    ram_util_percent: 30.83333333333334\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436327373324048\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.328752455475723\n",
      "    mean_inference_ms: 2.4784258224013045\n",
      "    mean_raw_obs_processing_ms: 1.9328903865272276\n",
      "  time_since_restore: 6432.031325101852\n",
      "  time_this_iter_s: 25.411755561828613\n",
      "  time_total_s: 6432.031325101852\n",
      "  timers:\n",
      "    learn_throughput: 1147.865\n",
      "    learn_time_ms: 1740.623\n",
      "    load_throughput: 58935.071\n",
      "    load_time_ms: 33.902\n",
      "    sample_throughput: 80.301\n",
      "    sample_time_ms: 24881.442\n",
      "    update_time_ms: 9.336\n",
      "  timestamp: 1636435951\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 485514\n",
      "  training_iteration: 243\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   243</td><td style=\"text-align: right;\">         6432.03</td><td style=\"text-align: right;\">485514</td><td style=\"text-align: right;\">  7.7354</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">                2.74</td><td style=\"text-align: right;\">             97.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 487512\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-32-57\n",
      "  done: false\n",
      "  episode_len_mean: 99.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 7.7810000000000175\n",
      "  episode_reward_min: 2.740000000000012\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4547\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3137178290457951\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008841396312447418\n",
      "          policy_loss: -0.04527643659994716\n",
      "          total_loss: 0.1583502245490395\n",
      "          vf_explained_var: 0.9626331329345703\n",
      "          vf_loss: 0.21004990247033892\n",
      "    num_agent_steps_sampled: 487512\n",
      "    num_agent_steps_trained: 487512\n",
      "    num_steps_sampled: 487512\n",
      "    num_steps_trained: 487512\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.17368421052633\n",
      "    ram_util_percent: 30.823684210526327\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044393795367505796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.336302721145795\n",
      "    mean_inference_ms: 2.4788154278618153\n",
      "    mean_raw_obs_processing_ms: 1.928015020750668\n",
      "  time_since_restore: 6458.601571798325\n",
      "  time_this_iter_s: 26.570246696472168\n",
      "  time_total_s: 6458.601571798325\n",
      "  timers:\n",
      "    learn_throughput: 1150.076\n",
      "    learn_time_ms: 1737.277\n",
      "    load_throughput: 59223.663\n",
      "    load_time_ms: 33.737\n",
      "    sample_throughput: 80.202\n",
      "    sample_time_ms: 24912.093\n",
      "    update_time_ms: 9.714\n",
      "  timestamp: 1636435977\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 487512\n",
      "  training_iteration: 244\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   244</td><td style=\"text-align: right;\">          6458.6</td><td style=\"text-align: right;\">487512</td><td style=\"text-align: right;\">   7.781</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">                2.74</td><td style=\"text-align: right;\">              99.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 489510\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-33-25\n",
      "  done: false\n",
      "  episode_len_mean: 98.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 7.393600000000018\n",
      "  episode_reward_min: 0.8200000000000152\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4569\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3937116656984603\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009347614638301773\n",
      "          policy_loss: -0.055021413805938904\n",
      "          total_loss: 0.1711573252010913\n",
      "          vf_explained_var: 0.9621946811676025\n",
      "          vf_loss: 0.23301751115137623\n",
      "    num_agent_steps_sampled: 489510\n",
      "    num_agent_steps_trained: 489510\n",
      "    num_steps_sampled: 489510\n",
      "    num_steps_trained: 489510\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9075\n",
      "    ram_util_percent: 30.764999999999997\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044359732201930485\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.346770783670205\n",
      "    mean_inference_ms: 2.4783432356867765\n",
      "    mean_raw_obs_processing_ms: 1.9226375952329229\n",
      "  time_since_restore: 6486.503692865372\n",
      "  time_this_iter_s: 27.90212106704712\n",
      "  time_total_s: 6486.503692865372\n",
      "  timers:\n",
      "    learn_throughput: 1148.438\n",
      "    learn_time_ms: 1739.755\n",
      "    load_throughput: 59762.279\n",
      "    load_time_ms: 33.432\n",
      "    sample_throughput: 80.006\n",
      "    sample_time_ms: 24973.03\n",
      "    update_time_ms: 11.042\n",
      "  timestamp: 1636436005\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 489510\n",
      "  training_iteration: 245\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   245</td><td style=\"text-align: right;\">          6486.5</td><td style=\"text-align: right;\">489510</td><td style=\"text-align: right;\">  7.3936</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">                0.82</td><td style=\"text-align: right;\">             98.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 491508\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-33-52\n",
      "  done: false\n",
      "  episode_len_mean: 97.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 7.398300000000018\n",
      "  episode_reward_min: 0.8200000000000152\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4590\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2729229927062988\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010360523726161601\n",
      "          policy_loss: -0.004364546920572009\n",
      "          total_loss: 0.17923080499860503\n",
      "          vf_explained_var: 0.9619610905647278\n",
      "          vf_loss: 0.1884570631952513\n",
      "    num_agent_steps_sampled: 491508\n",
      "    num_agent_steps_trained: 491508\n",
      "    num_steps_sampled: 491508\n",
      "    num_steps_trained: 491508\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.01315789473684\n",
      "    ram_util_percent: 30.707894736842103\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435487120596199\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.358724761194054\n",
      "    mean_inference_ms: 2.4782897547029368\n",
      "    mean_raw_obs_processing_ms: 1.9176975941355732\n",
      "  time_since_restore: 6513.0931141376495\n",
      "  time_this_iter_s: 26.589421272277832\n",
      "  time_total_s: 6513.0931141376495\n",
      "  timers:\n",
      "    learn_throughput: 1148.599\n",
      "    learn_time_ms: 1739.51\n",
      "    load_throughput: 59817.479\n",
      "    load_time_ms: 33.402\n",
      "    sample_throughput: 79.929\n",
      "    sample_time_ms: 24997.266\n",
      "    update_time_ms: 11.027\n",
      "  timestamp: 1636436032\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 491508\n",
      "  training_iteration: 246\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   246</td><td style=\"text-align: right;\">         6513.09</td><td style=\"text-align: right;\">491508</td><td style=\"text-align: right;\">  7.3983</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">                0.82</td><td style=\"text-align: right;\">             97.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 493506\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-34-19\n",
      "  done: false\n",
      "  episode_len_mean: 97.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.350000000000017\n",
      "  episode_reward_mean: 7.425900000000018\n",
      "  episode_reward_min: -1.0700000000000007\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4611\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.7593750000000002\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2776444889250256\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.020915391505506174\n",
      "          policy_loss: -0.0066758146243436\n",
      "          total_loss: 0.34747019834550363\n",
      "          vf_explained_var: 0.9442264437675476\n",
      "          vf_loss: 0.35103983144674983\n",
      "    num_agent_steps_sampled: 493506\n",
      "    num_agent_steps_trained: 493506\n",
      "    num_steps_sampled: 493506\n",
      "    num_steps_trained: 493506\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.29210526315791\n",
      "    ram_util_percent: 30.707894736842103\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044345815377776175\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.37349331000547\n",
      "    mean_inference_ms: 2.4781962425299433\n",
      "    mean_raw_obs_processing_ms: 1.912916006546937\n",
      "  time_since_restore: 6540.045221328735\n",
      "  time_this_iter_s: 26.952107191085815\n",
      "  time_total_s: 6540.045221328735\n",
      "  timers:\n",
      "    learn_throughput: 1152.099\n",
      "    learn_time_ms: 1734.226\n",
      "    load_throughput: 59385.619\n",
      "    load_time_ms: 33.645\n",
      "    sample_throughput: 79.759\n",
      "    sample_time_ms: 25050.597\n",
      "    update_time_ms: 11.245\n",
      "  timestamp: 1636436059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 493506\n",
      "  training_iteration: 247\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   247</td><td style=\"text-align: right;\">         6540.05</td><td style=\"text-align: right;\">493506</td><td style=\"text-align: right;\">  7.4259</td><td style=\"text-align: right;\">               14.35</td><td style=\"text-align: right;\">               -1.07</td><td style=\"text-align: right;\">              97.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 495504\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-35-19\n",
      "  done: false\n",
      "  episode_len_mean: 96.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.350000000000017\n",
      "  episode_reward_mean: 7.584200000000018\n",
      "  episode_reward_min: -1.0700000000000007\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4631\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.33108183826719\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009604145509124404\n",
      "          policy_loss: -0.01356557971310048\n",
      "          total_loss: 0.40398013322126297\n",
      "          vf_explained_var: 0.9354663491249084\n",
      "          vf_loss: 0.4199168104146208\n",
      "    num_agent_steps_sampled: 495504\n",
      "    num_agent_steps_trained: 495504\n",
      "    num_steps_sampled: 495504\n",
      "    num_steps_trained: 495504\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.7313953488372\n",
      "    ram_util_percent: 30.650000000000002\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434136731235956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.387164309420605\n",
      "    mean_inference_ms: 2.4781879069455037\n",
      "    mean_raw_obs_processing_ms: 1.9228609017532212\n",
      "  time_since_restore: 6600.121666431427\n",
      "  time_this_iter_s: 60.07644510269165\n",
      "  time_total_s: 6600.121666431427\n",
      "  timers:\n",
      "    learn_throughput: 1152.732\n",
      "    learn_time_ms: 1733.274\n",
      "    load_throughput: 59287.643\n",
      "    load_time_ms: 33.7\n",
      "    sample_throughput: 70.168\n",
      "    sample_time_ms: 28474.351\n",
      "    update_time_ms: 11.295\n",
      "  timestamp: 1636436119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 495504\n",
      "  training_iteration: 248\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   248</td><td style=\"text-align: right;\">         6600.12</td><td style=\"text-align: right;\">495504</td><td style=\"text-align: right;\">  7.5842</td><td style=\"text-align: right;\">               14.35</td><td style=\"text-align: right;\">               -1.07</td><td style=\"text-align: right;\">             96.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 497502\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-36-00\n",
      "  done: false\n",
      "  episode_len_mean: 94.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.350000000000017\n",
      "  episode_reward_mean: 7.723400000000015\n",
      "  episode_reward_min: -1.0700000000000007\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4653\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2140114602588472\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008542830660395724\n",
      "          policy_loss: -0.0033088675744476774\n",
      "          total_loss: 0.3579194348128069\n",
      "          vf_explained_var: 0.9497753381729126\n",
      "          vf_loss: 0.3636375988168376\n",
      "    num_agent_steps_sampled: 497502\n",
      "    num_agent_steps_trained: 497502\n",
      "    num_steps_sampled: 497502\n",
      "    num_steps_trained: 497502\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.58965517241379\n",
      "    ram_util_percent: 30.53620689655173\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430892651527439\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.39788258051721\n",
      "    mean_inference_ms: 2.4777530696282883\n",
      "    mean_raw_obs_processing_ms: 1.9400556461081544\n",
      "  time_since_restore: 6640.924626350403\n",
      "  time_this_iter_s: 40.80295991897583\n",
      "  time_total_s: 6640.924626350403\n",
      "  timers:\n",
      "    learn_throughput: 1152.959\n",
      "    learn_time_ms: 1732.933\n",
      "    load_throughput: 59588.476\n",
      "    load_time_ms: 33.53\n",
      "    sample_throughput: 67.21\n",
      "    sample_time_ms: 29727.601\n",
      "    update_time_ms: 10.207\n",
      "  timestamp: 1636436160\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 497502\n",
      "  training_iteration: 249\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   249</td><td style=\"text-align: right;\">         6640.92</td><td style=\"text-align: right;\">497502</td><td style=\"text-align: right;\">  7.7234</td><td style=\"text-align: right;\">               14.35</td><td style=\"text-align: right;\">               -1.07</td><td style=\"text-align: right;\">             94.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 499500\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-36-27\n",
      "  done: false\n",
      "  episode_len_mean: 95.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.350000000000017\n",
      "  episode_reward_mean: 7.8888000000000185\n",
      "  episode_reward_min: -1.0700000000000007\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4673\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.311941799663362\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00860439114827798\n",
      "          policy_loss: -0.041674323344514486\n",
      "          total_loss: 0.2176923674353886\n",
      "          vf_explained_var: 0.9414052367210388\n",
      "          vf_loss: 0.26268517490298976\n",
      "    num_agent_steps_sampled: 499500\n",
      "    num_agent_steps_trained: 499500\n",
      "    num_steps_sampled: 499500\n",
      "    num_steps_trained: 499500\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6025641025641\n",
      "    ram_util_percent: 30.676923076923085\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431684277182127\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.41003800246278\n",
      "    mean_inference_ms: 2.477864565529133\n",
      "    mean_raw_obs_processing_ms: 1.9558651227841586\n",
      "  time_since_restore: 6667.856699705124\n",
      "  time_this_iter_s: 26.93207335472107\n",
      "  time_total_s: 6667.856699705124\n",
      "  timers:\n",
      "    learn_throughput: 1154.833\n",
      "    learn_time_ms: 1730.12\n",
      "    load_throughput: 59634.781\n",
      "    load_time_ms: 33.504\n",
      "    sample_throughput: 67.168\n",
      "    sample_time_ms: 29746.438\n",
      "    update_time_ms: 9.309\n",
      "  timestamp: 1636436187\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 499500\n",
      "  training_iteration: 250\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         6667.86</td><td style=\"text-align: right;\">499500</td><td style=\"text-align: right;\">  7.8888</td><td style=\"text-align: right;\">               14.35</td><td style=\"text-align: right;\">               -1.07</td><td style=\"text-align: right;\">             95.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 501498\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-36-54\n",
      "  done: false\n",
      "  episode_len_mean: 94.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 7.931400000000018\n",
      "  episode_reward_min: -1.0700000000000007\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4695\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2077162348088764\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005623817787767563\n",
      "          policy_loss: -0.00265394299335423\n",
      "          total_loss: 0.10341258696502163\n",
      "          vf_explained_var: 0.980728268623352\n",
      "          vf_loss: 0.11173781035911469\n",
      "    num_agent_steps_sampled: 501498\n",
      "    num_agent_steps_trained: 501498\n",
      "    num_steps_sampled: 501498\n",
      "    num_steps_trained: 501498\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.86153846153847\n",
      "    ram_util_percent: 30.7871794871795\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044312603950414496\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.420844755337956\n",
      "    mean_inference_ms: 2.47780996095977\n",
      "    mean_raw_obs_processing_ms: 1.9730911485075218\n",
      "  time_since_restore: 6695.292699337006\n",
      "  time_this_iter_s: 27.435999631881714\n",
      "  time_total_s: 6695.292699337006\n",
      "  timers:\n",
      "    learn_throughput: 1156.617\n",
      "    learn_time_ms: 1727.451\n",
      "    load_throughput: 59668.453\n",
      "    load_time_ms: 33.485\n",
      "    sample_throughput: 66.978\n",
      "    sample_time_ms: 29830.726\n",
      "    update_time_ms: 9.508\n",
      "  timestamp: 1636436214\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 501498\n",
      "  training_iteration: 251\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   251</td><td style=\"text-align: right;\">         6695.29</td><td style=\"text-align: right;\">501498</td><td style=\"text-align: right;\">  7.9314</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">               -1.07</td><td style=\"text-align: right;\">             94.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 503496\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-37-22\n",
      "  done: false\n",
      "  episode_len_mean: 94.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 7.763700000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4717\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.251056679089864\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007320908418704739\n",
      "          policy_loss: -0.008171699018705458\n",
      "          total_loss: 0.16244939815785203\n",
      "          vf_explained_var: 0.969085693359375\n",
      "          vf_loss: 0.17479269160401253\n",
      "    num_agent_steps_sampled: 503496\n",
      "    num_agent_steps_trained: 503496\n",
      "    num_steps_sampled: 503496\n",
      "    num_steps_trained: 503496\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.74358974358977\n",
      "    ram_util_percent: 30.848717948717947\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431471739992951\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.42810766934027\n",
      "    mean_inference_ms: 2.477806600815386\n",
      "    mean_raw_obs_processing_ms: 1.9841257448472072\n",
      "  time_since_restore: 6722.496386289597\n",
      "  time_this_iter_s: 27.203686952590942\n",
      "  time_total_s: 6722.496386289597\n",
      "  timers:\n",
      "    learn_throughput: 1155.752\n",
      "    learn_time_ms: 1728.745\n",
      "    load_throughput: 59556.08\n",
      "    load_time_ms: 33.548\n",
      "    sample_throughput: 67.034\n",
      "    sample_time_ms: 29805.741\n",
      "    update_time_ms: 9.896\n",
      "  timestamp: 1636436242\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 503496\n",
      "  training_iteration: 252\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   252</td><td style=\"text-align: right;\">          6722.5</td><td style=\"text-align: right;\">503496</td><td style=\"text-align: right;\">  7.7637</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             94.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 505494\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-37-47\n",
      "  done: false\n",
      "  episode_len_mean: 94.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 7.985400000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4737\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2165753336179823\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007134970254718691\n",
      "          policy_loss: -0.032475466538398036\n",
      "          total_loss: 0.13743812241369768\n",
      "          vf_explained_var: 0.9659351706504822\n",
      "          vf_loss: 0.1739521651750519\n",
      "    num_agent_steps_sampled: 505494\n",
      "    num_agent_steps_trained: 505494\n",
      "    num_steps_sampled: 505494\n",
      "    num_steps_trained: 505494\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.12777777777777\n",
      "    ram_util_percent: 30.90555555555555\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428335125518597\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.432694651481466\n",
      "    mean_inference_ms: 2.477376448649376\n",
      "    mean_raw_obs_processing_ms: 1.9851984559517752\n",
      "  time_since_restore: 6747.874066114426\n",
      "  time_this_iter_s: 25.3776798248291\n",
      "  time_total_s: 6747.874066114426\n",
      "  timers:\n",
      "    learn_throughput: 1157.604\n",
      "    learn_time_ms: 1725.979\n",
      "    load_throughput: 59145.291\n",
      "    load_time_ms: 33.781\n",
      "    sample_throughput: 67.037\n",
      "    sample_time_ms: 29804.353\n",
      "    update_time_ms: 10.558\n",
      "  timestamp: 1636436267\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 505494\n",
      "  training_iteration: 253\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   253</td><td style=\"text-align: right;\">         6747.87</td><td style=\"text-align: right;\">505494</td><td style=\"text-align: right;\">  7.9854</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             94.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 507492\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-38-14\n",
      "  done: false\n",
      "  episode_len_mean: 95.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 8.019000000000018\n",
      "  episode_reward_min: 3.0500000000000096\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4759\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2346183328401474\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00752468204720029\n",
      "          policy_loss: -0.03313832682158266\n",
      "          total_loss: 0.1409393805389603\n",
      "          vf_explained_var: 0.9743592143058777\n",
      "          vf_loss: 0.17785280675050757\n",
      "    num_agent_steps_sampled: 507492\n",
      "    num_agent_steps_trained: 507492\n",
      "    num_steps_sampled: 507492\n",
      "    num_steps_trained: 507492\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77179487179487\n",
      "    ram_util_percent: 30.882051282051286\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427536233378472\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.4460580223832\n",
      "    mean_inference_ms: 2.4773083263280693\n",
      "    mean_raw_obs_processing_ms: 1.9803390215679268\n",
      "  time_since_restore: 6774.8617441654205\n",
      "  time_this_iter_s: 26.987678050994873\n",
      "  time_total_s: 6774.8617441654205\n",
      "  timers:\n",
      "    learn_throughput: 1157.349\n",
      "    learn_time_ms: 1726.36\n",
      "    load_throughput: 59003.621\n",
      "    load_time_ms: 33.862\n",
      "    sample_throughput: 66.944\n",
      "    sample_time_ms: 29845.857\n",
      "    update_time_ms: 10.133\n",
      "  timestamp: 1636436294\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 507492\n",
      "  training_iteration: 254\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   254</td><td style=\"text-align: right;\">         6774.86</td><td style=\"text-align: right;\">507492</td><td style=\"text-align: right;\">   8.019</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">                3.05</td><td style=\"text-align: right;\">             95.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 509490\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-38-41\n",
      "  done: false\n",
      "  episode_len_mean: 95.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 8.355600000000017\n",
      "  episode_reward_min: 2.960000000000012\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4779\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.201776615210942\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006221061078942059\n",
      "          policy_loss: -0.08169364711003645\n",
      "          total_loss: 0.08963065230775447\n",
      "          vf_explained_var: 0.9699196815490723\n",
      "          vf_loss: 0.1762558882435163\n",
      "    num_agent_steps_sampled: 509490\n",
      "    num_agent_steps_trained: 509490\n",
      "    num_steps_sampled: 509490\n",
      "    num_steps_trained: 509490\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28157894736842\n",
      "    ram_util_percent: 30.889473684210525\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044288192064164074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.458063287025798\n",
      "    mean_inference_ms: 2.4774820455418642\n",
      "    mean_raw_obs_processing_ms: 1.97594716500522\n",
      "  time_since_restore: 6801.496251344681\n",
      "  time_this_iter_s: 26.634507179260254\n",
      "  time_total_s: 6801.496251344681\n",
      "  timers:\n",
      "    learn_throughput: 1157.528\n",
      "    learn_time_ms: 1726.093\n",
      "    load_throughput: 58529.587\n",
      "    load_time_ms: 34.137\n",
      "    sample_throughput: 67.228\n",
      "    sample_time_ms: 29719.787\n",
      "    update_time_ms: 9.43\n",
      "  timestamp: 1636436321\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 509490\n",
      "  training_iteration: 255\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   255</td><td style=\"text-align: right;\">          6801.5</td><td style=\"text-align: right;\">509490</td><td style=\"text-align: right;\">  8.3556</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">                2.96</td><td style=\"text-align: right;\">             95.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 511488\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-39-08\n",
      "  done: false\n",
      "  episode_len_mean: 94.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 8.233800000000016\n",
      "  episode_reward_min: 2.960000000000012\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 4801\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2335888431185769\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006932484711453042\n",
      "          policy_loss: -0.01858941933938435\n",
      "          total_loss: 0.1478499635167065\n",
      "          vf_explained_var: 0.9678481221199036\n",
      "          vf_loss: 0.17087873734888576\n",
      "    num_agent_steps_sampled: 511488\n",
      "    num_agent_steps_trained: 511488\n",
      "    num_steps_sampled: 511488\n",
      "    num_steps_trained: 511488\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0076923076923\n",
      "    ram_util_percent: 30.81794871794873\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428046416969954\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.467047253551044\n",
      "    mean_inference_ms: 2.477369117460355\n",
      "    mean_raw_obs_processing_ms: 1.9707440236671452\n",
      "  time_since_restore: 6829.187838554382\n",
      "  time_this_iter_s: 27.691587209701538\n",
      "  time_total_s: 6829.187838554382\n",
      "  timers:\n",
      "    learn_throughput: 1159.173\n",
      "    learn_time_ms: 1723.643\n",
      "    load_throughput: 58638.895\n",
      "    load_time_ms: 34.073\n",
      "    sample_throughput: 66.975\n",
      "    sample_time_ms: 29832.131\n",
      "    update_time_ms: 9.694\n",
      "  timestamp: 1636436348\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 511488\n",
      "  training_iteration: 256\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   256</td><td style=\"text-align: right;\">         6829.19</td><td style=\"text-align: right;\">511488</td><td style=\"text-align: right;\">  8.2338</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                2.96</td><td style=\"text-align: right;\">             94.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 513486\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-39-37\n",
      "  done: false\n",
      "  episode_len_mean: 93.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 8.080200000000017\n",
      "  episode_reward_min: 2.8500000000000143\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 4824\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2373416378384545\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.019195758289658988\n",
      "          policy_loss: -0.014337755650991485\n",
      "          total_loss: 0.28287019289231724\n",
      "          vf_explained_var: 0.9582188129425049\n",
      "          vf_loss: 0.2877161942511087\n",
      "    num_agent_steps_sampled: 513486\n",
      "    num_agent_steps_trained: 513486\n",
      "    num_steps_sampled: 513486\n",
      "    num_steps_trained: 513486\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.4609756097561\n",
      "    ram_util_percent: 30.800000000000004\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044283236705271095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.48270424989839\n",
      "    mean_inference_ms: 2.477406076681188\n",
      "    mean_raw_obs_processing_ms: 1.9655701731829422\n",
      "  time_since_restore: 6857.584426164627\n",
      "  time_this_iter_s: 28.39658761024475\n",
      "  time_total_s: 6857.584426164627\n",
      "  timers:\n",
      "    learn_throughput: 1158.627\n",
      "    learn_time_ms: 1724.455\n",
      "    load_throughput: 59095.367\n",
      "    load_time_ms: 33.81\n",
      "    sample_throughput: 66.653\n",
      "    sample_time_ms: 29976.07\n",
      "    update_time_ms: 9.525\n",
      "  timestamp: 1636436377\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 513486\n",
      "  training_iteration: 257\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   257</td><td style=\"text-align: right;\">         6857.58</td><td style=\"text-align: right;\">513486</td><td style=\"text-align: right;\">  8.0802</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                2.85</td><td style=\"text-align: right;\">             93.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 515484\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-40-03\n",
      "  done: false\n",
      "  episode_len_mean: 93.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 8.231100000000017\n",
      "  episode_reward_min: 2.8500000000000143\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4843\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2586334120659601\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007954361681670854\n",
      "          policy_loss: -0.005713183211073989\n",
      "          total_loss: 0.3259807447548069\n",
      "          vf_explained_var: 0.9583756327629089\n",
      "          vf_loss: 0.3352197439897628\n",
      "    num_agent_steps_sampled: 515484\n",
      "    num_agent_steps_trained: 515484\n",
      "    num_steps_sampled: 515484\n",
      "    num_steps_trained: 515484\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79166666666669\n",
      "    ram_util_percent: 30.741666666666674\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429506514984803\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.492411915110182\n",
      "    mean_inference_ms: 2.4774938313236494\n",
      "    mean_raw_obs_processing_ms: 1.9611570641668317\n",
      "  time_since_restore: 6883.220112800598\n",
      "  time_this_iter_s: 25.63568663597107\n",
      "  time_total_s: 6883.220112800598\n",
      "  timers:\n",
      "    learn_throughput: 1157.895\n",
      "    learn_time_ms: 1725.546\n",
      "    load_throughput: 59359.917\n",
      "    load_time_ms: 33.659\n",
      "    sample_throughput: 75.306\n",
      "    sample_time_ms: 26531.604\n",
      "    update_time_ms: 9.104\n",
      "  timestamp: 1636436403\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 515484\n",
      "  training_iteration: 258\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   258</td><td style=\"text-align: right;\">         6883.22</td><td style=\"text-align: right;\">515484</td><td style=\"text-align: right;\">  8.2311</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                2.85</td><td style=\"text-align: right;\">             93.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 517482\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-40-29\n",
      "  done: false\n",
      "  episode_len_mean: 94.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000013\n",
      "  episode_reward_mean: 8.605000000000016\n",
      "  episode_reward_min: 2.8500000000000143\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4864\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.373492029167357\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008365407876478981\n",
      "          policy_loss: -0.04934698183621679\n",
      "          total_loss: 0.24034727627322788\n",
      "          vf_explained_var: 0.9655841588973999\n",
      "          vf_loss: 0.2939004565988268\n",
      "    num_agent_steps_sampled: 517482\n",
      "    num_agent_steps_trained: 517482\n",
      "    num_steps_sampled: 517482\n",
      "    num_steps_trained: 517482\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.17368421052632\n",
      "    ram_util_percent: 30.718421052631577\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044315326229349396\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.505192814479198\n",
      "    mean_inference_ms: 2.4777524578808876\n",
      "    mean_raw_obs_processing_ms: 1.9563557401493465\n",
      "  time_since_restore: 6909.500493049622\n",
      "  time_this_iter_s: 26.280380249023438\n",
      "  time_total_s: 6909.500493049622\n",
      "  timers:\n",
      "    learn_throughput: 1157.687\n",
      "    learn_time_ms: 1725.855\n",
      "    load_throughput: 59067.917\n",
      "    load_time_ms: 33.825\n",
      "    sample_throughput: 79.668\n",
      "    sample_time_ms: 25079.223\n",
      "    update_time_ms: 8.832\n",
      "  timestamp: 1636436429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 517482\n",
      "  training_iteration: 259\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   259</td><td style=\"text-align: right;\">          6909.5</td><td style=\"text-align: right;\">517482</td><td style=\"text-align: right;\">   8.605</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                2.85</td><td style=\"text-align: right;\">             94.47</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 519480\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-40-54\n",
      "  done: false\n",
      "  episode_len_mean: 96.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000013\n",
      "  episode_reward_mean: 8.509900000000018\n",
      "  episode_reward_min: 2.8500000000000143\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4883\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.299329476129441\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006351050073293135\n",
      "          policy_loss: -0.03644714254353728\n",
      "          total_loss: 0.13621217376064687\n",
      "          vf_explained_var: 0.9675778150558472\n",
      "          vf_loss: 0.17841836822529633\n",
      "    num_agent_steps_sampled: 519480\n",
      "    num_agent_steps_trained: 519480\n",
      "    num_steps_sampled: 519480\n",
      "    num_steps_trained: 519480\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00571428571428\n",
      "    ram_util_percent: 30.720000000000002\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044317998906684156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.514473045715675\n",
      "    mean_inference_ms: 2.477790123677724\n",
      "    mean_raw_obs_processing_ms: 1.9520196852641982\n",
      "  time_since_restore: 6934.207098007202\n",
      "  time_this_iter_s: 24.706604957580566\n",
      "  time_total_s: 6934.207098007202\n",
      "  timers:\n",
      "    learn_throughput: 1156.12\n",
      "    learn_time_ms: 1728.194\n",
      "    load_throughput: 59102.16\n",
      "    load_time_ms: 33.806\n",
      "    sample_throughput: 80.39\n",
      "    sample_time_ms: 24853.99\n",
      "    update_time_ms: 9.435\n",
      "  timestamp: 1636436454\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 519480\n",
      "  training_iteration: 260\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   260</td><td style=\"text-align: right;\">         6934.21</td><td style=\"text-align: right;\">519480</td><td style=\"text-align: right;\">  8.5099</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                2.85</td><td style=\"text-align: right;\">             96.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 521478\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-41-20\n",
      "  done: false\n",
      "  episode_len_mean: 97.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000013\n",
      "  episode_reward_mean: 8.605200000000018\n",
      "  episode_reward_min: 2.7700000000000164\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4902\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3557736362729753\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007730716328668638\n",
      "          policy_loss: -0.027694498002529145\n",
      "          total_loss: 0.18549496272490137\n",
      "          vf_explained_var: 0.9542096853256226\n",
      "          vf_loss: 0.21794142715987705\n",
      "    num_agent_steps_sampled: 521478\n",
      "    num_agent_steps_trained: 521478\n",
      "    num_steps_sampled: 521478\n",
      "    num_steps_trained: 521478\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00270270270269\n",
      "    ram_util_percent: 30.71351351351351\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436119830696393\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.527276908368613\n",
      "    mean_inference_ms: 2.47834151008501\n",
      "    mean_raw_obs_processing_ms: 1.947873880626303\n",
      "  time_since_restore: 6960.296229362488\n",
      "  time_this_iter_s: 26.089131355285645\n",
      "  time_total_s: 6960.296229362488\n",
      "  timers:\n",
      "    learn_throughput: 1155.901\n",
      "    learn_time_ms: 1728.522\n",
      "    load_throughput: 59029.68\n",
      "    load_time_ms: 33.847\n",
      "    sample_throughput: 80.827\n",
      "    sample_time_ms: 24719.42\n",
      "    update_time_ms: 8.971\n",
      "  timestamp: 1636436480\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 521478\n",
      "  training_iteration: 261\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   261</td><td style=\"text-align: right;\">          6960.3</td><td style=\"text-align: right;\">521478</td><td style=\"text-align: right;\">  8.6052</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                2.77</td><td style=\"text-align: right;\">             97.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 523476\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-41-45\n",
      "  done: false\n",
      "  episode_len_mean: 100.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000013\n",
      "  episode_reward_mean: 8.576700000000018\n",
      "  episode_reward_min: 2.7700000000000164\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 4922\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.324438708736783\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008908318070929917\n",
      "          policy_loss: -0.01383466592856816\n",
      "          total_loss: 0.16599574435413594\n",
      "          vf_explained_var: 0.9656252264976501\n",
      "          vf_loss: 0.18292766273731276\n",
      "    num_agent_steps_sampled: 523476\n",
      "    num_agent_steps_trained: 523476\n",
      "    num_steps_sampled: 523476\n",
      "    num_steps_trained: 523476\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.55405405405405\n",
      "    ram_util_percent: 30.670270270270276\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435427653013502\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.53713498207645\n",
      "    mean_inference_ms: 2.4781899430026315\n",
      "    mean_raw_obs_processing_ms: 1.9434146817459756\n",
      "  time_since_restore: 6985.723395586014\n",
      "  time_this_iter_s: 25.427166223526\n",
      "  time_total_s: 6985.723395586014\n",
      "  timers:\n",
      "    learn_throughput: 1154.808\n",
      "    learn_time_ms: 1730.157\n",
      "    load_throughput: 58899.034\n",
      "    load_time_ms: 33.922\n",
      "    sample_throughput: 81.418\n",
      "    sample_time_ms: 24540.057\n",
      "    update_time_ms: 9.02\n",
      "  timestamp: 1636436505\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 523476\n",
      "  training_iteration: 262\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   262</td><td style=\"text-align: right;\">         6985.72</td><td style=\"text-align: right;\">523476</td><td style=\"text-align: right;\">  8.5767</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                2.77</td><td style=\"text-align: right;\">            100.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 525474\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-42-09\n",
      "  done: false\n",
      "  episode_len_mean: 103.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000013\n",
      "  episode_reward_mean: 8.603100000000017\n",
      "  episode_reward_min: 2.7700000000000164\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 4940\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.321945485614595\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008017259450419575\n",
      "          policy_loss: -0.005612489439192272\n",
      "          total_loss: 0.22193031405054386\n",
      "          vf_explained_var: 0.9655771851539612\n",
      "          vf_loss: 0.2316300978263219\n",
      "    num_agent_steps_sampled: 525474\n",
      "    num_agent_steps_trained: 525474\n",
      "    num_steps_sampled: 525474\n",
      "    num_steps_trained: 525474\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.47575757575757\n",
      "    ram_util_percent: 30.603030303030305\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434859024214575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.54198058071183\n",
      "    mean_inference_ms: 2.478117719704348\n",
      "    mean_raw_obs_processing_ms: 1.9391949550845213\n",
      "  time_since_restore: 7009.071944236755\n",
      "  time_this_iter_s: 23.348548650741577\n",
      "  time_total_s: 7009.071944236755\n",
      "  timers:\n",
      "    learn_throughput: 1153.296\n",
      "    learn_time_ms: 1732.425\n",
      "    load_throughput: 59233.961\n",
      "    load_time_ms: 33.731\n",
      "    sample_throughput: 82.103\n",
      "    sample_time_ms: 24335.432\n",
      "    update_time_ms: 8.589\n",
      "  timestamp: 1636436529\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 525474\n",
      "  training_iteration: 263\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   263</td><td style=\"text-align: right;\">         7009.07</td><td style=\"text-align: right;\">525474</td><td style=\"text-align: right;\">  8.6031</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                2.77</td><td style=\"text-align: right;\">            103.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 527472\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-42-32\n",
      "  done: false\n",
      "  episode_len_mean: 104.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000013\n",
      "  episode_reward_mean: 8.329900000000016\n",
      "  episode_reward_min: 2.7700000000000164\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 4958\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3492082556088765\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010520564679460283\n",
      "          policy_loss: -0.05564891525677272\n",
      "          total_loss: 0.14799309248725573\n",
      "          vf_explained_var: 0.9732953906059265\n",
      "          vf_loss: 0.20515050900479156\n",
      "    num_agent_steps_sampled: 527472\n",
      "    num_agent_steps_trained: 527472\n",
      "    num_steps_sampled: 527472\n",
      "    num_steps_trained: 527472\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8558823529412\n",
      "    ram_util_percent: 30.573529411764707\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431376897797566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.542499483740567\n",
      "    mean_inference_ms: 2.4776453844150508\n",
      "    mean_raw_obs_processing_ms: 1.9347591260585317\n",
      "  time_since_restore: 7032.954124689102\n",
      "  time_this_iter_s: 23.8821804523468\n",
      "  time_total_s: 7032.954124689102\n",
      "  timers:\n",
      "    learn_throughput: 1152.688\n",
      "    learn_time_ms: 1733.34\n",
      "    load_throughput: 59198.269\n",
      "    load_time_ms: 33.751\n",
      "    sample_throughput: 83.168\n",
      "    sample_time_ms: 24023.538\n",
      "    update_time_ms: 8.736\n",
      "  timestamp: 1636436552\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 527472\n",
      "  training_iteration: 264\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   264</td><td style=\"text-align: right;\">         7032.95</td><td style=\"text-align: right;\">527472</td><td style=\"text-align: right;\">  8.3299</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                2.77</td><td style=\"text-align: right;\">               104</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 529470\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-43-15\n",
      "  done: false\n",
      "  episode_len_mean: 103.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.310000000000022\n",
      "  episode_reward_mean: 8.216000000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 4979\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3025842519033524\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00853161910509345\n",
      "          policy_loss: -0.05781550221145153\n",
      "          total_loss: 0.1147523604156006\n",
      "          vf_explained_var: 0.9687603116035461\n",
      "          vf_loss: 0.17587565659057527\n",
      "    num_agent_steps_sampled: 529470\n",
      "    num_agent_steps_trained: 529470\n",
      "    num_steps_sampled: 529470\n",
      "    num_steps_trained: 529470\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.05166666666668\n",
      "    ram_util_percent: 30.613333333333333\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432597441833295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.541573282267105\n",
      "    mean_inference_ms: 2.477833847817377\n",
      "    mean_raw_obs_processing_ms: 1.9376053476359851\n",
      "  time_since_restore: 7075.063140869141\n",
      "  time_this_iter_s: 42.10901618003845\n",
      "  time_total_s: 7075.063140869141\n",
      "  timers:\n",
      "    learn_throughput: 1152.39\n",
      "    learn_time_ms: 1733.788\n",
      "    load_throughput: 59224.793\n",
      "    load_time_ms: 33.736\n",
      "    sample_throughput: 78.137\n",
      "    sample_time_ms: 25570.559\n",
      "    update_time_ms: 8.723\n",
      "  timestamp: 1636436595\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 529470\n",
      "  training_iteration: 265\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   265</td><td style=\"text-align: right;\">         7075.06</td><td style=\"text-align: right;\">529470</td><td style=\"text-align: right;\">   8.216</td><td style=\"text-align: right;\">               14.31</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            103.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 531468\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-43-55\n",
      "  done: false\n",
      "  episode_len_mean: 104.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.310000000000022\n",
      "  episode_reward_mean: 8.318200000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 4998\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3395912686983744\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009621254110589176\n",
      "          policy_loss: 0.020819386742299512\n",
      "          total_loss: 0.28603471790750823\n",
      "          vf_explained_var: 0.9493226408958435\n",
      "          vf_loss: 0.26765203186798664\n",
      "    num_agent_steps_sampled: 531468\n",
      "    num_agent_steps_trained: 531468\n",
      "    num_steps_sampled: 531468\n",
      "    num_steps_trained: 531468\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.8271186440678\n",
      "    ram_util_percent: 30.662711864406774\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443088706261278\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.53813497673494\n",
      "    mean_inference_ms: 2.4775804687790592\n",
      "    mean_raw_obs_processing_ms: 1.9458009626761135\n",
      "  time_since_restore: 7115.805493354797\n",
      "  time_this_iter_s: 40.74235248565674\n",
      "  time_total_s: 7115.805493354797\n",
      "  timers:\n",
      "    learn_throughput: 1151.928\n",
      "    learn_time_ms: 1734.483\n",
      "    load_throughput: 59032.175\n",
      "    load_time_ms: 33.846\n",
      "    sample_throughput: 74.342\n",
      "    sample_time_ms: 26875.952\n",
      "    update_time_ms: 7.877\n",
      "  timestamp: 1636436635\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 531468\n",
      "  training_iteration: 266\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   266</td><td style=\"text-align: right;\">         7115.81</td><td style=\"text-align: right;\">531468</td><td style=\"text-align: right;\">  8.3182</td><td style=\"text-align: right;\">               14.31</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            104.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 533466\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-44-35\n",
      "  done: false\n",
      "  episode_len_mean: 102.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.310000000000018\n",
      "  episode_reward_mean: 8.461300000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5019\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2704605409077236\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010875084105203594\n",
      "          policy_loss: -0.017934736738070136\n",
      "          total_loss: 0.38608248851128985\n",
      "          vf_explained_var: 0.9519562721252441\n",
      "          vf_loss: 0.404334428489563\n",
      "    num_agent_steps_sampled: 533466\n",
      "    num_agent_steps_trained: 533466\n",
      "    num_steps_sampled: 533466\n",
      "    num_steps_trained: 533466\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.71428571428571\n",
      "    ram_util_percent: 30.710714285714285\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044317720768216766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.528078157356067\n",
      "    mean_inference_ms: 2.477627872879194\n",
      "    mean_raw_obs_processing_ms: 1.9609357610662388\n",
      "  time_since_restore: 7155.322213411331\n",
      "  time_this_iter_s: 39.51672005653381\n",
      "  time_total_s: 7155.322213411331\n",
      "  timers:\n",
      "    learn_throughput: 1152.877\n",
      "    learn_time_ms: 1733.055\n",
      "    load_throughput: 58708.978\n",
      "    load_time_ms: 34.032\n",
      "    sample_throughput: 71.386\n",
      "    sample_time_ms: 27988.577\n",
      "    update_time_ms: 8.562\n",
      "  timestamp: 1636436675\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 533466\n",
      "  training_iteration: 267\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   267</td><td style=\"text-align: right;\">         7155.32</td><td style=\"text-align: right;\">533466</td><td style=\"text-align: right;\">  8.4613</td><td style=\"text-align: right;\">               14.31</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            102.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 535464\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-45-01\n",
      "  done: false\n",
      "  episode_len_mean: 101.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.400000000000018\n",
      "  episode_reward_mean: 8.462300000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5039\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3651482593445552\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006430833085327575\n",
      "          policy_loss: -0.007309464312025479\n",
      "          total_loss: 0.20353894270956516\n",
      "          vf_explained_var: 0.9703661203384399\n",
      "          vf_loss: 0.21717477096688179\n",
      "    num_agent_steps_sampled: 535464\n",
      "    num_agent_steps_trained: 535464\n",
      "    num_steps_sampled: 535464\n",
      "    num_steps_trained: 535464\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.24864864864865\n",
      "    ram_util_percent: 30.783783783783797\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433240657781689\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.52497712396527\n",
      "    mean_inference_ms: 2.477827369677704\n",
      "    mean_raw_obs_processing_ms: 1.975661768716074\n",
      "  time_since_restore: 7181.53148317337\n",
      "  time_this_iter_s: 26.209269762039185\n",
      "  time_total_s: 7181.53148317337\n",
      "  timers:\n",
      "    learn_throughput: 1153.348\n",
      "    learn_time_ms: 1732.347\n",
      "    load_throughput: 58679.051\n",
      "    load_time_ms: 34.05\n",
      "    sample_throughput: 71.24\n",
      "    sample_time_ms: 28045.897\n",
      "    update_time_ms: 9.219\n",
      "  timestamp: 1636436701\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 535464\n",
      "  training_iteration: 268\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   268</td><td style=\"text-align: right;\">         7181.53</td><td style=\"text-align: right;\">535464</td><td style=\"text-align: right;\">  8.4623</td><td style=\"text-align: right;\">                14.4</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            101.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 537462\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-45-27\n",
      "  done: false\n",
      "  episode_len_mean: 98.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.400000000000018\n",
      "  episode_reward_mean: 8.168900000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5060\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3584645225888208\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007142646302112576\n",
      "          policy_loss: -0.03843040363419624\n",
      "          total_loss: 0.10290088256200154\n",
      "          vf_explained_var: 0.9797604084014893\n",
      "          vf_loss: 0.14678001428643864\n",
      "    num_agent_steps_sampled: 537462\n",
      "    num_agent_steps_trained: 537462\n",
      "    num_steps_sampled: 537462\n",
      "    num_steps_trained: 537462\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.55135135135134\n",
      "    ram_util_percent: 30.794594594594596\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433177560758765\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.5241297291265\n",
      "    mean_inference_ms: 2.4778059443462417\n",
      "    mean_raw_obs_processing_ms: 1.9913796257240832\n",
      "  time_since_restore: 7206.952778100967\n",
      "  time_this_iter_s: 25.421294927597046\n",
      "  time_total_s: 7206.952778100967\n",
      "  timers:\n",
      "    learn_throughput: 1152.671\n",
      "    learn_time_ms: 1733.365\n",
      "    load_throughput: 58710.048\n",
      "    load_time_ms: 34.032\n",
      "    sample_throughput: 71.463\n",
      "    sample_time_ms: 27958.609\n",
      "    update_time_ms: 9.626\n",
      "  timestamp: 1636436727\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 537462\n",
      "  training_iteration: 269\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   269</td><td style=\"text-align: right;\">         7206.95</td><td style=\"text-align: right;\">537462</td><td style=\"text-align: right;\">  8.1689</td><td style=\"text-align: right;\">                14.4</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 539460\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-45-52\n",
      "  done: false\n",
      "  episode_len_mean: 98.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.400000000000018\n",
      "  episode_reward_mean: 8.186700000000016\n",
      "  episode_reward_min: 1.95\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5080\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3942857146263123\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005780420998891385\n",
      "          policy_loss: -0.01349797465261959\n",
      "          total_loss: 0.10105707145162991\n",
      "          vf_explained_var: 0.9682961702346802\n",
      "          vf_loss: 0.12191364176216579\n",
      "    num_agent_steps_sampled: 539460\n",
      "    num_agent_steps_trained: 539460\n",
      "    num_steps_sampled: 539460\n",
      "    num_steps_trained: 539460\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.50833333333334\n",
      "    ram_util_percent: 30.80277777777778\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044346094201102734\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.52313664404089\n",
      "    mean_inference_ms: 2.4778783717409913\n",
      "    mean_raw_obs_processing_ms: 1.9971120882900164\n",
      "  time_since_restore: 7232.608781576157\n",
      "  time_this_iter_s: 25.65600347518921\n",
      "  time_total_s: 7232.608781576157\n",
      "  timers:\n",
      "    learn_throughput: 1155.383\n",
      "    learn_time_ms: 1729.297\n",
      "    load_throughput: 58615.025\n",
      "    load_time_ms: 34.087\n",
      "    sample_throughput: 71.211\n",
      "    sample_time_ms: 28057.386\n",
      "    update_time_ms: 9.953\n",
      "  timestamp: 1636436752\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 539460\n",
      "  training_iteration: 270\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   270</td><td style=\"text-align: right;\">         7232.61</td><td style=\"text-align: right;\">539460</td><td style=\"text-align: right;\">  8.1867</td><td style=\"text-align: right;\">                14.4</td><td style=\"text-align: right;\">                1.95</td><td style=\"text-align: right;\">             98.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 541458\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-46-18\n",
      "  done: false\n",
      "  episode_len_mean: 98.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.270400000000016\n",
      "  episode_reward_min: 1.95\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5100\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.347712444691431\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015028907867282917\n",
      "          policy_loss: -0.010271177157050088\n",
      "          total_loss: 0.34183271162300594\n",
      "          vf_explained_var: 0.9537121057510376\n",
      "          vf_loss: 0.34846214710601736\n",
      "    num_agent_steps_sampled: 541458\n",
      "    num_agent_steps_trained: 541458\n",
      "    num_steps_sampled: 541458\n",
      "    num_steps_trained: 541458\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.17027027027028\n",
      "    ram_util_percent: 30.864864864864863\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434177818338545\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.523793310682077\n",
      "    mean_inference_ms: 2.477684517601464\n",
      "    mean_raw_obs_processing_ms: 1.9980816124093213\n",
      "  time_since_restore: 7258.222207546234\n",
      "  time_this_iter_s: 25.613425970077515\n",
      "  time_total_s: 7258.222207546234\n",
      "  timers:\n",
      "    learn_throughput: 1156.256\n",
      "    learn_time_ms: 1727.991\n",
      "    load_throughput: 58768.018\n",
      "    load_time_ms: 33.998\n",
      "    sample_throughput: 71.328\n",
      "    sample_time_ms: 28011.307\n",
      "    update_time_ms: 9.857\n",
      "  timestamp: 1636436778\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 541458\n",
      "  training_iteration: 271\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   271</td><td style=\"text-align: right;\">         7258.22</td><td style=\"text-align: right;\">541458</td><td style=\"text-align: right;\">  8.2704</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                1.95</td><td style=\"text-align: right;\">             98.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 543456\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-46-44\n",
      "  done: false\n",
      "  episode_len_mean: 99.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.010500000000018\n",
      "  episode_reward_min: 0.9899999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5120\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2576406410762242\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009921416431400197\n",
      "          policy_loss: -0.0199783354110661\n",
      "          total_loss: 0.29823336022950353\n",
      "          vf_explained_var: 0.9479418992996216\n",
      "          vf_loss: 0.3194869902162325\n",
      "    num_agent_steps_sampled: 543456\n",
      "    num_agent_steps_trained: 543456\n",
      "    num_steps_sampled: 543456\n",
      "    num_steps_trained: 543456\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.62972972972973\n",
      "    ram_util_percent: 30.927027027027027\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434206807422871\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.530674981018848\n",
      "    mean_inference_ms: 2.477615968913645\n",
      "    mean_raw_obs_processing_ms: 1.9935117943305594\n",
      "  time_since_restore: 7283.832172632217\n",
      "  time_this_iter_s: 25.609965085983276\n",
      "  time_total_s: 7283.832172632217\n",
      "  timers:\n",
      "    learn_throughput: 1158.996\n",
      "    learn_time_ms: 1723.907\n",
      "    load_throughput: 58762.248\n",
      "    load_time_ms: 34.001\n",
      "    sample_throughput: 71.27\n",
      "    sample_time_ms: 28034.297\n",
      "    update_time_ms: 9.097\n",
      "  timestamp: 1636436804\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 543456\n",
      "  training_iteration: 272\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   272</td><td style=\"text-align: right;\">         7283.83</td><td style=\"text-align: right;\">543456</td><td style=\"text-align: right;\">  8.0105</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">             99.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 545454\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-47-10\n",
      "  done: false\n",
      "  episode_len_mean: 98.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 7.618400000000019\n",
      "  episode_reward_min: 0.750000000000011\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5140\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3046373038064867\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00891628440367432\n",
      "          policy_loss: -0.03617771707829975\n",
      "          total_loss: 0.24372044259770995\n",
      "          vf_explained_var: 0.9601364731788635\n",
      "          vf_loss: 0.2827883302101067\n",
      "    num_agent_steps_sampled: 545454\n",
      "    num_agent_steps_trained: 545454\n",
      "    num_steps_sampled: 545454\n",
      "    num_steps_trained: 545454\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.47631578947369\n",
      "    ram_util_percent: 30.905263157894744\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434907015963715\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.5352223760203\n",
      "    mean_inference_ms: 2.477550634428643\n",
      "    mean_raw_obs_processing_ms: 1.9888029971099046\n",
      "  time_since_restore: 7310.446521759033\n",
      "  time_this_iter_s: 26.614349126815796\n",
      "  time_total_s: 7310.446521759033\n",
      "  timers:\n",
      "    learn_throughput: 1160.031\n",
      "    learn_time_ms: 1722.368\n",
      "    load_throughput: 58824.987\n",
      "    load_time_ms: 33.965\n",
      "    sample_throughput: 70.444\n",
      "    sample_time_ms: 28362.961\n",
      "    update_time_ms: 8.665\n",
      "  timestamp: 1636436830\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 545454\n",
      "  training_iteration: 273\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   273</td><td style=\"text-align: right;\">         7310.45</td><td style=\"text-align: right;\">545454</td><td style=\"text-align: right;\">  7.6184</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                0.75</td><td style=\"text-align: right;\">             98.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 547452\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-47-36\n",
      "  done: false\n",
      "  episode_len_mean: 98.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 7.915400000000017\n",
      "  episode_reward_min: 0.750000000000011\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5160\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2391177753607432\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009635923838705382\n",
      "          policy_loss: -0.017765809169837405\n",
      "          total_loss: 0.3322959656782803\n",
      "          vf_explained_var: 0.9504468441009521\n",
      "          vf_loss: 0.3514770308775561\n",
      "    num_agent_steps_sampled: 547452\n",
      "    num_agent_steps_trained: 547452\n",
      "    num_steps_sampled: 547452\n",
      "    num_steps_trained: 547452\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.61351351351352\n",
      "    ram_util_percent: 30.84054054054055\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443723775405136\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.53903369125187\n",
      "    mean_inference_ms: 2.4776683993602715\n",
      "    mean_raw_obs_processing_ms: 1.9839914478595768\n",
      "  time_since_restore: 7336.325189828873\n",
      "  time_this_iter_s: 25.878668069839478\n",
      "  time_total_s: 7336.325189828873\n",
      "  timers:\n",
      "    learn_throughput: 1161.219\n",
      "    learn_time_ms: 1720.606\n",
      "    load_throughput: 58870.071\n",
      "    load_time_ms: 33.939\n",
      "    sample_throughput: 69.948\n",
      "    sample_time_ms: 28564.209\n",
      "    update_time_ms: 9.041\n",
      "  timestamp: 1636436856\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 547452\n",
      "  training_iteration: 274\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   274</td><td style=\"text-align: right;\">         7336.33</td><td style=\"text-align: right;\">547452</td><td style=\"text-align: right;\">  7.9154</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                0.75</td><td style=\"text-align: right;\">             98.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 549450\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-48-02\n",
      "  done: false\n",
      "  episode_len_mean: 99.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 7.8851000000000155\n",
      "  episode_reward_min: 0.750000000000011\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5181\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.350164298784165\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007067239702283499\n",
      "          policy_loss: -0.018595119388330552\n",
      "          total_loss: 0.11966773572688301\n",
      "          vf_explained_var: 0.9665877819061279\n",
      "          vf_loss: 0.1437144709307523\n",
      "    num_agent_steps_sampled: 549450\n",
      "    num_agent_steps_trained: 549450\n",
      "    num_steps_sampled: 549450\n",
      "    num_steps_trained: 549450\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.90555555555557\n",
      "    ram_util_percent: 30.797222222222224\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437210092961155\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.54330077411755\n",
      "    mean_inference_ms: 2.477525618163905\n",
      "    mean_raw_obs_processing_ms: 1.9791182418460773\n",
      "  time_since_restore: 7361.869917154312\n",
      "  time_this_iter_s: 25.544727325439453\n",
      "  time_total_s: 7361.869917154312\n",
      "  timers:\n",
      "    learn_throughput: 1161.474\n",
      "    learn_time_ms: 1720.228\n",
      "    load_throughput: 58920.361\n",
      "    load_time_ms: 33.91\n",
      "    sample_throughput: 74.251\n",
      "    sample_time_ms: 26908.791\n",
      "    update_time_ms: 8.431\n",
      "  timestamp: 1636436882\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 549450\n",
      "  training_iteration: 275\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   275</td><td style=\"text-align: right;\">         7361.87</td><td style=\"text-align: right;\">549450</td><td style=\"text-align: right;\">  7.8851</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                0.75</td><td style=\"text-align: right;\">             99.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 551448\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-48-27\n",
      "  done: false\n",
      "  episode_len_mean: 99.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.390000000000018\n",
      "  episode_reward_mean: 8.064300000000019\n",
      "  episode_reward_min: 0.750000000000011\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 5200\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2418187334423973\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007271343476332519\n",
      "          policy_loss: -0.04159718286246061\n",
      "          total_loss: 0.12758217748431933\n",
      "          vf_explained_var: 0.9800394773483276\n",
      "          vf_loss: 0.17331503409714927\n",
      "    num_agent_steps_sampled: 551448\n",
      "    num_agent_steps_trained: 551448\n",
      "    num_steps_sampled: 551448\n",
      "    num_steps_trained: 551448\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.54166666666669\n",
      "    ram_util_percent: 30.811111111111114\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438203526689912\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.54893416583772\n",
      "    mean_inference_ms: 2.4775894570561765\n",
      "    mean_raw_obs_processing_ms: 1.9748445189996442\n",
      "  time_since_restore: 7386.70213675499\n",
      "  time_this_iter_s: 24.83221960067749\n",
      "  time_total_s: 7386.70213675499\n",
      "  timers:\n",
      "    learn_throughput: 1161.107\n",
      "    learn_time_ms: 1720.772\n",
      "    load_throughput: 59024.442\n",
      "    load_time_ms: 33.85\n",
      "    sample_throughput: 78.921\n",
      "    sample_time_ms: 25316.519\n",
      "    update_time_ms: 9.133\n",
      "  timestamp: 1636436907\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 551448\n",
      "  training_iteration: 276\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   276</td><td style=\"text-align: right;\">          7386.7</td><td style=\"text-align: right;\">551448</td><td style=\"text-align: right;\">  8.0643</td><td style=\"text-align: right;\">               14.39</td><td style=\"text-align: right;\">                0.75</td><td style=\"text-align: right;\">             99.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 553446\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-48-53\n",
      "  done: false\n",
      "  episode_len_mean: 99.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.390000000000018\n",
      "  episode_reward_mean: 8.184400000000018\n",
      "  episode_reward_min: 0.750000000000011\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5220\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2648623880885896\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007004350442294734\n",
      "          policy_loss: 0.020572803249316558\n",
      "          total_loss: 0.20460542722472122\n",
      "          vf_explained_var: 0.9666376113891602\n",
      "          vf_loss: 0.18870285398193767\n",
      "    num_agent_steps_sampled: 553446\n",
      "    num_agent_steps_trained: 553446\n",
      "    num_steps_sampled: 553446\n",
      "    num_steps_trained: 553446\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87297297297297\n",
      "    ram_util_percent: 30.808108108108115\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439767857558996\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.55205012550804\n",
      "    mean_inference_ms: 2.4777412610737413\n",
      "    mean_raw_obs_processing_ms: 1.9702246926410505\n",
      "  time_since_restore: 7412.9163546562195\n",
      "  time_this_iter_s: 26.21421790122986\n",
      "  time_total_s: 7412.9163546562195\n",
      "  timers:\n",
      "    learn_throughput: 1159.449\n",
      "    learn_time_ms: 1723.233\n",
      "    load_throughput: 59186.186\n",
      "    load_time_ms: 33.758\n",
      "    sample_throughput: 83.303\n",
      "    sample_time_ms: 23984.641\n",
      "    update_time_ms: 8.264\n",
      "  timestamp: 1636436933\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 553446\n",
      "  training_iteration: 277\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   277</td><td style=\"text-align: right;\">         7412.92</td><td style=\"text-align: right;\">553446</td><td style=\"text-align: right;\">  8.1844</td><td style=\"text-align: right;\">               14.39</td><td style=\"text-align: right;\">                0.75</td><td style=\"text-align: right;\">             99.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 555444\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-49-18\n",
      "  done: false\n",
      "  episode_len_mean: 100.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.390000000000018\n",
      "  episode_reward_mean: 8.190000000000019\n",
      "  episode_reward_min: 2.6400000000000152\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5241\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2365763235659826\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010255690231559225\n",
      "          policy_loss: -0.008064306527376174\n",
      "          total_loss: 0.4085118901073223\n",
      "          vf_explained_var: 0.9545692205429077\n",
      "          vf_loss: 0.4172600850108124\n",
      "    num_agent_steps_sampled: 555444\n",
      "    num_agent_steps_trained: 555444\n",
      "    num_steps_sampled: 555444\n",
      "    num_steps_trained: 555444\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.22285714285715\n",
      "    ram_util_percent: 30.771428571428572\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439044031984246\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.553248557389132\n",
      "    mean_inference_ms: 2.4775349666878297\n",
      "    mean_raw_obs_processing_ms: 1.9653813116778907\n",
      "  time_since_restore: 7437.738845586777\n",
      "  time_this_iter_s: 24.82249093055725\n",
      "  time_total_s: 7437.738845586777\n",
      "  timers:\n",
      "    learn_throughput: 1158.409\n",
      "    learn_time_ms: 1724.779\n",
      "    load_throughput: 59146.209\n",
      "    load_time_ms: 33.781\n",
      "    sample_throughput: 83.792\n",
      "    sample_time_ms: 23844.894\n",
      "    update_time_ms: 7.851\n",
      "  timestamp: 1636436958\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 555444\n",
      "  training_iteration: 278\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   278</td><td style=\"text-align: right;\">         7437.74</td><td style=\"text-align: right;\">555444</td><td style=\"text-align: right;\">    8.19</td><td style=\"text-align: right;\">               14.39</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">            100.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 557442\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-49-44\n",
      "  done: false\n",
      "  episode_len_mean: 99.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.390000000000018\n",
      "  episode_reward_mean: 8.512600000000019\n",
      "  episode_reward_min: 2.6400000000000152\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5261\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0999234900588082\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011027628630790787\n",
      "          policy_loss: -0.025527179644753536\n",
      "          total_loss: 0.30209433294477916\n",
      "          vf_explained_var: 0.9548017382621765\n",
      "          vf_loss: 0.32605958964143483\n",
      "    num_agent_steps_sampled: 557442\n",
      "    num_agent_steps_trained: 557442\n",
      "    num_steps_sampled: 557442\n",
      "    num_steps_trained: 557442\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8921052631579\n",
      "    ram_util_percent: 30.74210526315789\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044378098870834555\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.55793102402996\n",
      "    mean_inference_ms: 2.4772945485190085\n",
      "    mean_raw_obs_processing_ms: 1.9609719660914526\n",
      "  time_since_restore: 7464.1726334095\n",
      "  time_this_iter_s: 26.43378782272339\n",
      "  time_total_s: 7464.1726334095\n",
      "  timers:\n",
      "    learn_throughput: 1158.804\n",
      "    learn_time_ms: 1724.192\n",
      "    load_throughput: 59175.737\n",
      "    load_time_ms: 33.764\n",
      "    sample_throughput: 83.437\n",
      "    sample_time_ms: 23946.289\n",
      "    update_time_ms: 8.066\n",
      "  timestamp: 1636436984\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 557442\n",
      "  training_iteration: 279\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   279</td><td style=\"text-align: right;\">         7464.17</td><td style=\"text-align: right;\">557442</td><td style=\"text-align: right;\">  8.5126</td><td style=\"text-align: right;\">               14.39</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">             99.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 559440\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-50-09\n",
      "  done: false\n",
      "  episode_len_mean: 100.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.390000000000018\n",
      "  episode_reward_mean: 8.69430000000002\n",
      "  episode_reward_min: 2.4400000000000204\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5281\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3159865657488505\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008408852002224338\n",
      "          policy_loss: -0.0075203320100193935\n",
      "          total_loss: 0.1485539138760595\n",
      "          vf_explained_var: 0.9663788080215454\n",
      "          vf_loss: 0.15965590115104403\n",
      "    num_agent_steps_sampled: 559440\n",
      "    num_agent_steps_trained: 559440\n",
      "    num_steps_sampled: 559440\n",
      "    num_steps_trained: 559440\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96285714285713\n",
      "    ram_util_percent: 30.717142857142854\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044396921580166\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.559978188993355\n",
      "    mean_inference_ms: 2.4775233048602168\n",
      "    mean_raw_obs_processing_ms: 1.9564578128524064\n",
      "  time_since_restore: 7488.724806547165\n",
      "  time_this_iter_s: 24.552173137664795\n",
      "  time_total_s: 7488.724806547165\n",
      "  timers:\n",
      "    learn_throughput: 1159.083\n",
      "    learn_time_ms: 1723.777\n",
      "    load_throughput: 59034.379\n",
      "    load_time_ms: 33.845\n",
      "    sample_throughput: 83.822\n",
      "    sample_time_ms: 23836.13\n",
      "    update_time_ms: 8.377\n",
      "  timestamp: 1636437009\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 559440\n",
      "  training_iteration: 280\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   280</td><td style=\"text-align: right;\">         7488.72</td><td style=\"text-align: right;\">559440</td><td style=\"text-align: right;\">  8.6943</td><td style=\"text-align: right;\">               14.39</td><td style=\"text-align: right;\">                2.44</td><td style=\"text-align: right;\">            100.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 561438\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-50-37\n",
      "  done: false\n",
      "  episode_len_mean: 99.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.090000000000021\n",
      "  episode_reward_mean: 8.101600000000017\n",
      "  episode_reward_min: 2.4400000000000204\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5301\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3142689880870637\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008144936499045942\n",
      "          policy_loss: -0.03095206847148282\n",
      "          total_loss: 0.10969426667406446\n",
      "          vf_explained_var: 0.9645714163780212\n",
      "          vf_loss: 0.14451143317634152\n",
      "    num_agent_steps_sampled: 561438\n",
      "    num_agent_steps_trained: 561438\n",
      "    num_steps_sampled: 561438\n",
      "    num_steps_trained: 561438\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.35365853658537\n",
      "    ram_util_percent: 30.70731707317073\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438879911387895\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.56406567771208\n",
      "    mean_inference_ms: 2.4773528539068255\n",
      "    mean_raw_obs_processing_ms: 1.9519113066984952\n",
      "  time_since_restore: 7517.3164138793945\n",
      "  time_this_iter_s: 28.591607332229614\n",
      "  time_total_s: 7517.3164138793945\n",
      "  timers:\n",
      "    learn_throughput: 1159.08\n",
      "    learn_time_ms: 1723.78\n",
      "    load_throughput: 58893.281\n",
      "    load_time_ms: 33.926\n",
      "    sample_throughput: 82.788\n",
      "    sample_time_ms: 24134.06\n",
      "    update_time_ms: 8.246\n",
      "  timestamp: 1636437037\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 561438\n",
      "  training_iteration: 281\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   281</td><td style=\"text-align: right;\">         7517.32</td><td style=\"text-align: right;\">561438</td><td style=\"text-align: right;\">  8.1016</td><td style=\"text-align: right;\">               14.09</td><td style=\"text-align: right;\">                2.44</td><td style=\"text-align: right;\">              99.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 563436\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-51-03\n",
      "  done: false\n",
      "  episode_len_mean: 98.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.090000000000021\n",
      "  episode_reward_mean: 8.15710000000002\n",
      "  episode_reward_min: 2.4400000000000204\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5322\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2801825103305635\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005386191184887459\n",
      "          policy_loss: -0.01700172344488757\n",
      "          total_loss: 0.0879565677649918\n",
      "          vf_explained_var: 0.9803221225738525\n",
      "          vf_loss: 0.11162490782638392\n",
      "    num_agent_steps_sampled: 563436\n",
      "    num_agent_steps_trained: 563436\n",
      "    num_steps_sampled: 563436\n",
      "    num_steps_trained: 563436\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28648648648647\n",
      "    ram_util_percent: 30.68108108108109\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437841595224415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.571486850036536\n",
      "    mean_inference_ms: 2.4771194861657815\n",
      "    mean_raw_obs_processing_ms: 1.9474190099740076\n",
      "  time_since_restore: 7543.080327272415\n",
      "  time_this_iter_s: 25.76391339302063\n",
      "  time_total_s: 7543.080327272415\n",
      "  timers:\n",
      "    learn_throughput: 1158.567\n",
      "    learn_time_ms: 1724.544\n",
      "    load_throughput: 58971.65\n",
      "    load_time_ms: 33.881\n",
      "    sample_throughput: 82.738\n",
      "    sample_time_ms: 24148.549\n",
      "    update_time_ms: 8.529\n",
      "  timestamp: 1636437063\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 563436\n",
      "  training_iteration: 282\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   282</td><td style=\"text-align: right;\">         7543.08</td><td style=\"text-align: right;\">563436</td><td style=\"text-align: right;\">  8.1571</td><td style=\"text-align: right;\">               14.09</td><td style=\"text-align: right;\">                2.44</td><td style=\"text-align: right;\">             98.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 565434\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-51-46\n",
      "  done: false\n",
      "  episode_len_mean: 96.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 8.147300000000019\n",
      "  episode_reward_min: -0.02\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5343\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2712002424966722\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011082124757426056\n",
      "          policy_loss: -0.00986209340570938\n",
      "          total_loss: 0.44716332590296154\n",
      "          vf_explained_var: 0.9388816952705383\n",
      "          vf_loss: 0.45711418890527317\n",
      "    num_agent_steps_sampled: 565434\n",
      "    num_agent_steps_trained: 565434\n",
      "    num_steps_sampled: 565434\n",
      "    num_steps_trained: 565434\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.81967213114754\n",
      "    ram_util_percent: 30.642622950819668\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443721222836462\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.581360115346477\n",
      "    mean_inference_ms: 2.4769768767031177\n",
      "    mean_raw_obs_processing_ms: 1.9501867710066556\n",
      "  time_since_restore: 7585.791330575943\n",
      "  time_this_iter_s: 42.71100330352783\n",
      "  time_total_s: 7585.791330575943\n",
      "  timers:\n",
      "    learn_throughput: 1158.105\n",
      "    learn_time_ms: 1725.232\n",
      "    load_throughput: 58902.305\n",
      "    load_time_ms: 33.921\n",
      "    sample_throughput: 77.571\n",
      "    sample_time_ms: 25756.924\n",
      "    update_time_ms: 9.014\n",
      "  timestamp: 1636437106\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 565434\n",
      "  training_iteration: 283\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   283</td><td style=\"text-align: right;\">         7585.79</td><td style=\"text-align: right;\">565434</td><td style=\"text-align: right;\">  8.1473</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">               -0.02</td><td style=\"text-align: right;\">             96.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 567432\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-52-40\n",
      "  done: false\n",
      "  episode_len_mean: 96.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 7.970800000000017\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 5365\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.200730836391449\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007979547035886709\n",
      "          policy_loss: -0.06569960417137259\n",
      "          total_loss: 0.25469672373895136\n",
      "          vf_explained_var: 0.9527625441551208\n",
      "          vf_loss: 0.32331443244502656\n",
      "    num_agent_steps_sampled: 567432\n",
      "    num_agent_steps_trained: 567432\n",
      "    num_steps_sampled: 567432\n",
      "    num_steps_trained: 567432\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.06493506493507\n",
      "    ram_util_percent: 30.67532467532469\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044369679010336026\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.586656480514257\n",
      "    mean_inference_ms: 2.476811401900385\n",
      "    mean_raw_obs_processing_ms: 1.9646126323133566\n",
      "  time_since_restore: 7640.0421624183655\n",
      "  time_this_iter_s: 54.250831842422485\n",
      "  time_total_s: 7640.0421624183655\n",
      "  timers:\n",
      "    learn_throughput: 1157.247\n",
      "    learn_time_ms: 1726.511\n",
      "    load_throughput: 58967.168\n",
      "    load_time_ms: 33.883\n",
      "    sample_throughput: 69.877\n",
      "    sample_time_ms: 28593.187\n",
      "    update_time_ms: 8.832\n",
      "  timestamp: 1636437160\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 567432\n",
      "  training_iteration: 284\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   284</td><td style=\"text-align: right;\">         7640.04</td><td style=\"text-align: right;\">567432</td><td style=\"text-align: right;\">  7.9708</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             96.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 569430\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-53-09\n",
      "  done: false\n",
      "  episode_len_mean: 94.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 8.477400000000015\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5386\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1853216279120673\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00768616612941481\n",
      "          policy_loss: -0.03188261107674667\n",
      "          total_loss: 0.20324600296361106\n",
      "          vf_explained_var: 0.9723497033119202\n",
      "          vf_loss: 0.23822680825278872\n",
      "    num_agent_steps_sampled: 569430\n",
      "    num_agent_steps_trained: 569430\n",
      "    num_steps_sampled: 569430\n",
      "    num_steps_trained: 569430\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59268292682927\n",
      "    ram_util_percent: 30.626829268292685\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443509865088296\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.59472287980995\n",
      "    mean_inference_ms: 2.4764226870874935\n",
      "    mean_raw_obs_processing_ms: 1.978490497776615\n",
      "  time_since_restore: 7668.786413669586\n",
      "  time_this_iter_s: 28.744251251220703\n",
      "  time_total_s: 7668.786413669586\n",
      "  timers:\n",
      "    learn_throughput: 1158.416\n",
      "    learn_time_ms: 1724.769\n",
      "    load_throughput: 59125.303\n",
      "    load_time_ms: 33.793\n",
      "    sample_throughput: 69.102\n",
      "    sample_time_ms: 28913.594\n",
      "    update_time_ms: 9.938\n",
      "  timestamp: 1636437189\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 569430\n",
      "  training_iteration: 285\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   285</td><td style=\"text-align: right;\">         7668.79</td><td style=\"text-align: right;\">569430</td><td style=\"text-align: right;\">  8.4774</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             94.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 571428\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-53-35\n",
      "  done: false\n",
      "  episode_len_mean: 93.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 8.644100000000018\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5407\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2244437546957108\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006295582002255846\n",
      "          policy_loss: -0.016915357059666087\n",
      "          total_loss: 0.15630102512382327\n",
      "          vf_explained_var: 0.9623178839683533\n",
      "          vf_loss: 0.17828975616111642\n",
      "    num_agent_steps_sampled: 571428\n",
      "    num_agent_steps_trained: 571428\n",
      "    num_steps_sampled: 571428\n",
      "    num_steps_trained: 571428\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1837837837838\n",
      "    ram_util_percent: 30.886486486486486\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434927978682625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.60081262432251\n",
      "    mean_inference_ms: 2.476287851136253\n",
      "    mean_raw_obs_processing_ms: 1.9923909468996657\n",
      "  time_since_restore: 7694.228875637054\n",
      "  time_this_iter_s: 25.44246196746826\n",
      "  time_total_s: 7694.228875637054\n",
      "  timers:\n",
      "    learn_throughput: 1158.171\n",
      "    learn_time_ms: 1725.134\n",
      "    load_throughput: 59219.018\n",
      "    load_time_ms: 33.739\n",
      "    sample_throughput: 68.959\n",
      "    sample_time_ms: 28973.748\n",
      "    update_time_ms: 10.406\n",
      "  timestamp: 1636437215\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 571428\n",
      "  training_iteration: 286\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   286</td><td style=\"text-align: right;\">         7694.23</td><td style=\"text-align: right;\">571428</td><td style=\"text-align: right;\">  8.6441</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             93.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 573426\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-54-01\n",
      "  done: false\n",
      "  episode_len_mean: 94.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 8.629200000000017\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5428\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2593601851236254\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008324126597476661\n",
      "          policy_loss: -0.05808073553434085\n",
      "          total_loss: 0.12334849494509399\n",
      "          vf_explained_var: 0.9697974920272827\n",
      "          vf_loss: 0.18454112944503626\n",
      "    num_agent_steps_sampled: 573426\n",
      "    num_agent_steps_trained: 573426\n",
      "    num_steps_sampled: 573426\n",
      "    num_steps_trained: 573426\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96216216216216\n",
      "    ram_util_percent: 30.91621621621622\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044342864724086814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.606106533499155\n",
      "    mean_inference_ms: 2.4761864064880426\n",
      "    mean_raw_obs_processing_ms: 2.0062715816350187\n",
      "  time_since_restore: 7720.51816534996\n",
      "  time_this_iter_s: 26.289289712905884\n",
      "  time_total_s: 7720.51816534996\n",
      "  timers:\n",
      "    learn_throughput: 1159.31\n",
      "    learn_time_ms: 1723.439\n",
      "    load_throughput: 59320.42\n",
      "    load_time_ms: 33.681\n",
      "    sample_throughput: 68.939\n",
      "    sample_time_ms: 28981.994\n",
      "    update_time_ms: 11.237\n",
      "  timestamp: 1636437241\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 573426\n",
      "  training_iteration: 287\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   287</td><td style=\"text-align: right;\">         7720.52</td><td style=\"text-align: right;\">573426</td><td style=\"text-align: right;\">  8.6292</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             94.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 575424\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-54-26\n",
      "  done: false\n",
      "  episode_len_mean: 96.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 8.761100000000017\n",
      "  episode_reward_min: 2.9900000000000158\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 5447\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.398820716426486\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008269730288295273\n",
      "          policy_loss: -0.038262570117201126\n",
      "          total_loss: 0.10276588225471121\n",
      "          vf_explained_var: 0.9749879240989685\n",
      "          vf_loss: 0.1455969183572701\n",
      "    num_agent_steps_sampled: 575424\n",
      "    num_agent_steps_trained: 575424\n",
      "    num_steps_sampled: 575424\n",
      "    num_steps_trained: 575424\n",
      "  iterations_since_restore: 288\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03783783783786\n",
      "    ram_util_percent: 30.96756756756756\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044359436768704456\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.608133132374125\n",
      "    mean_inference_ms: 2.4764383641671945\n",
      "    mean_raw_obs_processing_ms: 2.008160647259035\n",
      "  time_since_restore: 7745.929525136948\n",
      "  time_this_iter_s: 25.411359786987305\n",
      "  time_total_s: 7745.929525136948\n",
      "  timers:\n",
      "    learn_throughput: 1159.438\n",
      "    learn_time_ms: 1723.248\n",
      "    load_throughput: 59167.465\n",
      "    load_time_ms: 33.769\n",
      "    sample_throughput: 68.8\n",
      "    sample_time_ms: 29040.808\n",
      "    update_time_ms: 11.141\n",
      "  timestamp: 1636437266\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 575424\n",
      "  training_iteration: 288\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   288</td><td style=\"text-align: right;\">         7745.93</td><td style=\"text-align: right;\">575424</td><td style=\"text-align: right;\">  8.7611</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">                2.99</td><td style=\"text-align: right;\">             96.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 577422\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-54-52\n",
      "  done: false\n",
      "  episode_len_mean: 96.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 8.691500000000017\n",
      "  episode_reward_min: 2.7800000000000162\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5468\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.284337324187869\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007858622106661519\n",
      "          policy_loss: -0.021171922910781134\n",
      "          total_loss: 0.18869891886909804\n",
      "          vf_explained_var: 0.9696707129478455\n",
      "          vf_loss: 0.2137627525698571\n",
      "    num_agent_steps_sampled: 577422\n",
      "    num_agent_steps_trained: 577422\n",
      "    num_steps_sampled: 577422\n",
      "    num_steps_trained: 577422\n",
      "  iterations_since_restore: 289\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.47297297297295\n",
      "    ram_util_percent: 30.999999999999993\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435289122568717\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.615149166678272\n",
      "    mean_inference_ms: 2.4764433997098068\n",
      "    mean_raw_obs_processing_ms: 2.003664765194424\n",
      "  time_since_restore: 7772.0734651088715\n",
      "  time_this_iter_s: 26.143939971923828\n",
      "  time_total_s: 7772.0734651088715\n",
      "  timers:\n",
      "    learn_throughput: 1160.402\n",
      "    learn_time_ms: 1721.817\n",
      "    load_throughput: 59247.446\n",
      "    load_time_ms: 33.723\n",
      "    sample_throughput: 68.862\n",
      "    sample_time_ms: 29014.353\n",
      "    update_time_ms: 10.3\n",
      "  timestamp: 1636437292\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 577422\n",
      "  training_iteration: 289\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   289</td><td style=\"text-align: right;\">         7772.07</td><td style=\"text-align: right;\">577422</td><td style=\"text-align: right;\">  8.6915</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">             96.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 579420\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-55-19\n",
      "  done: false\n",
      "  episode_len_mean: 97.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 8.399200000000018\n",
      "  episode_reward_min: 2.7800000000000162\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5489\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4058173565637497\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006272578808726675\n",
      "          policy_loss: -0.09782600601514181\n",
      "          total_loss: 0.09140950141563302\n",
      "          vf_explained_var: 0.9693292379379272\n",
      "          vf_loss: 0.19614882192441396\n",
      "    num_agent_steps_sampled: 579420\n",
      "    num_agent_steps_trained: 579420\n",
      "    num_steps_sampled: 579420\n",
      "    num_steps_trained: 579420\n",
      "  iterations_since_restore: 290\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.25263157894737\n",
      "    ram_util_percent: 30.968421052631577\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434644364381999\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.62156899523351\n",
      "    mean_inference_ms: 2.4764726660660923\n",
      "    mean_raw_obs_processing_ms: 1.9992264050294453\n",
      "  time_since_restore: 7798.422553777695\n",
      "  time_this_iter_s: 26.349088668823242\n",
      "  time_total_s: 7798.422553777695\n",
      "  timers:\n",
      "    learn_throughput: 1159.012\n",
      "    learn_time_ms: 1723.882\n",
      "    load_throughput: 59509.981\n",
      "    load_time_ms: 33.574\n",
      "    sample_throughput: 68.441\n",
      "    sample_time_ms: 29193.189\n",
      "    update_time_ms: 9.07\n",
      "  timestamp: 1636437319\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 579420\n",
      "  training_iteration: 290\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   290</td><td style=\"text-align: right;\">         7798.42</td><td style=\"text-align: right;\">579420</td><td style=\"text-align: right;\">  8.3992</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">              97.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 581418\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-55-44\n",
      "  done: false\n",
      "  episode_len_mean: 97.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 8.489000000000019\n",
      "  episode_reward_min: 2.7800000000000162\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5509\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2882004976272583\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010453058933121895\n",
      "          policy_loss: -0.015470736207706587\n",
      "          total_loss: 0.299636415338942\n",
      "          vf_explained_var: 0.9508455395698547\n",
      "          vf_loss: 0.31608246728068307\n",
      "    num_agent_steps_sampled: 581418\n",
      "    num_agent_steps_trained: 581418\n",
      "    num_steps_sampled: 581418\n",
      "    num_steps_trained: 581418\n",
      "  iterations_since_restore: 291\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.10000000000001\n",
      "    ram_util_percent: 30.938888888888886\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044358892938433654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.627076930349844\n",
      "    mean_inference_ms: 2.4767539291262968\n",
      "    mean_raw_obs_processing_ms: 1.9948848412801612\n",
      "  time_since_restore: 7823.848005056381\n",
      "  time_this_iter_s: 25.425451278686523\n",
      "  time_total_s: 7823.848005056381\n",
      "  timers:\n",
      "    learn_throughput: 1158.701\n",
      "    learn_time_ms: 1724.345\n",
      "    load_throughput: 59541.524\n",
      "    load_time_ms: 33.556\n",
      "    sample_throughput: 69.191\n",
      "    sample_time_ms: 28876.493\n",
      "    update_time_ms: 8.923\n",
      "  timestamp: 1636437344\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 581418\n",
      "  training_iteration: 291\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   291</td><td style=\"text-align: right;\">         7823.85</td><td style=\"text-align: right;\">581418</td><td style=\"text-align: right;\">   8.489</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">             97.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 583416\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-56-11\n",
      "  done: false\n",
      "  episode_len_mean: 97.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 8.244600000000018\n",
      "  episode_reward_min: 2.640000000000016\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5530\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4601934603282383\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006969860651864826\n",
      "          policy_loss: -0.055094072648457115\n",
      "          total_loss: 0.08236929935713609\n",
      "          vf_explained_var: 0.9693991541862488\n",
      "          vf_loss: 0.14412620106623286\n",
      "    num_agent_steps_sampled: 583416\n",
      "    num_agent_steps_trained: 583416\n",
      "    num_steps_sampled: 583416\n",
      "    num_steps_trained: 583416\n",
      "  iterations_since_restore: 292\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0153846153846\n",
      "    ram_util_percent: 30.90512820512821\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435545539579477\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.634308132841937\n",
      "    mean_inference_ms: 2.476775148786736\n",
      "    mean_raw_obs_processing_ms: 1.9904520817486138\n",
      "  time_since_restore: 7850.916263103485\n",
      "  time_this_iter_s: 27.068258047103882\n",
      "  time_total_s: 7850.916263103485\n",
      "  timers:\n",
      "    learn_throughput: 1159.522\n",
      "    learn_time_ms: 1723.123\n",
      "    load_throughput: 59617.854\n",
      "    load_time_ms: 33.513\n",
      "    sample_throughput: 68.877\n",
      "    sample_time_ms: 29008.253\n",
      "    update_time_ms: 8.871\n",
      "  timestamp: 1636437371\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 583416\n",
      "  training_iteration: 292\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   292</td><td style=\"text-align: right;\">         7850.92</td><td style=\"text-align: right;\">583416</td><td style=\"text-align: right;\">  8.2446</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">             97.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 585414\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-56-37\n",
      "  done: false\n",
      "  episode_len_mean: 98.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000018\n",
      "  episode_reward_mean: 8.396200000000018\n",
      "  episode_reward_min: 2.640000000000016\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 5549\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3631144756362552\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007622601017845728\n",
      "          policy_loss: -0.0448221544247298\n",
      "          total_loss: 0.08301185704767704\n",
      "          vf_explained_var: 0.984360933303833\n",
      "          vf_loss: 0.13278253690472672\n",
      "    num_agent_steps_sampled: 585414\n",
      "    num_agent_steps_trained: 585414\n",
      "    num_steps_sampled: 585414\n",
      "    num_steps_trained: 585414\n",
      "  iterations_since_restore: 293\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66666666666667\n",
      "    ram_util_percent: 30.81944444444445\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044363770149886655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.642104291268662\n",
      "    mean_inference_ms: 2.476962933600592\n",
      "    mean_raw_obs_processing_ms: 1.9864927345793382\n",
      "  time_since_restore: 7876.462915182114\n",
      "  time_this_iter_s: 25.54665207862854\n",
      "  time_total_s: 7876.462915182114\n",
      "  timers:\n",
      "    learn_throughput: 1159.961\n",
      "    learn_time_ms: 1722.472\n",
      "    load_throughput: 59581.613\n",
      "    load_time_ms: 33.534\n",
      "    sample_throughput: 73.208\n",
      "    sample_time_ms: 27292.09\n",
      "    update_time_ms: 9.087\n",
      "  timestamp: 1636437397\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 585414\n",
      "  training_iteration: 293\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   293</td><td style=\"text-align: right;\">         7876.46</td><td style=\"text-align: right;\">585414</td><td style=\"text-align: right;\">  8.3962</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">             98.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 587412\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-57-04\n",
      "  done: false\n",
      "  episode_len_mean: 96.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.530000000000015\n",
      "  episode_reward_mean: 8.378700000000018\n",
      "  episode_reward_min: 2.640000000000016\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 5571\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.320798261676516\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00956619961356803\n",
      "          policy_loss: 0.018620175921491216\n",
      "          total_loss: 0.2608728279049198\n",
      "          vf_explained_var: 0.9676933884620667\n",
      "          vf_loss: 0.24456413500010968\n",
      "    num_agent_steps_sampled: 587412\n",
      "    num_agent_steps_trained: 587412\n",
      "    num_steps_sampled: 587412\n",
      "    num_steps_trained: 587412\n",
      "  iterations_since_restore: 294\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.05384615384617\n",
      "    ram_util_percent: 30.80256410256411\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044354333295583095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.64948323098215\n",
      "    mean_inference_ms: 2.4768338897741415\n",
      "    mean_raw_obs_processing_ms: 1.9819088975732841\n",
      "  time_since_restore: 7903.632083654404\n",
      "  time_this_iter_s: 27.16916847229004\n",
      "  time_total_s: 7903.632083654404\n",
      "  timers:\n",
      "    learn_throughput: 1161.427\n",
      "    learn_time_ms: 1720.297\n",
      "    load_throughput: 59581.443\n",
      "    load_time_ms: 33.534\n",
      "    sample_throughput: 81.266\n",
      "    sample_time_ms: 24586.006\n",
      "    update_time_ms: 9.262\n",
      "  timestamp: 1636437424\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 587412\n",
      "  training_iteration: 294\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   294</td><td style=\"text-align: right;\">         7903.63</td><td style=\"text-align: right;\">587412</td><td style=\"text-align: right;\">  8.3787</td><td style=\"text-align: right;\">               14.53</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">             96.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 589410\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-57-29\n",
      "  done: false\n",
      "  episode_len_mean: 97.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.530000000000015\n",
      "  episode_reward_mean: 8.138100000000017\n",
      "  episode_reward_min: 2.640000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5591\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.347116460118975\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00766590816080926\n",
      "          policy_loss: -0.039752814377702415\n",
      "          total_loss: 0.10631605736201717\n",
      "          vf_explained_var: 0.9587530493736267\n",
      "          vf_loss: 0.15080808764767079\n",
      "    num_agent_steps_sampled: 589410\n",
      "    num_agent_steps_trained: 589410\n",
      "    num_steps_sampled: 589410\n",
      "    num_steps_trained: 589410\n",
      "  iterations_since_restore: 295\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.12777777777778\n",
      "    ram_util_percent: 30.80555555555556\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436241943807075\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.65756382806534\n",
      "    mean_inference_ms: 2.477002105890496\n",
      "    mean_raw_obs_processing_ms: 1.9777292004996514\n",
      "  time_since_restore: 7928.93256020546\n",
      "  time_this_iter_s: 25.300476551055908\n",
      "  time_total_s: 7928.93256020546\n",
      "  timers:\n",
      "    learn_throughput: 1161.034\n",
      "    learn_time_ms: 1720.879\n",
      "    load_throughput: 59449.527\n",
      "    load_time_ms: 33.608\n",
      "    sample_throughput: 82.418\n",
      "    sample_time_ms: 24242.351\n",
      "    update_time_ms: 8.423\n",
      "  timestamp: 1636437449\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 589410\n",
      "  training_iteration: 295\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   295</td><td style=\"text-align: right;\">         7928.93</td><td style=\"text-align: right;\">589410</td><td style=\"text-align: right;\">  8.1381</td><td style=\"text-align: right;\">               14.53</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">             97.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 591408\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 96.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.530000000000015\n",
      "  episode_reward_mean: 7.9895000000000165\n",
      "  episode_reward_min: 2.640000000000016\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 5613\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3583972964968\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011875553118216314\n",
      "          policy_loss: -0.0069321321234816595\n",
      "          total_loss: 0.24213541585597254\n",
      "          vf_explained_var: 0.96843421459198\n",
      "          vf_loss: 0.24912452500845705\n",
      "    num_agent_steps_sampled: 591408\n",
      "    num_agent_steps_trained: 591408\n",
      "    num_steps_sampled: 591408\n",
      "    num_steps_trained: 591408\n",
      "  iterations_since_restore: 296\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66410256410256\n",
      "    ram_util_percent: 30.725641025641025\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044334167456827445\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.66551574381976\n",
      "    mean_inference_ms: 2.4765899005322414\n",
      "    mean_raw_obs_processing_ms: 1.9732937937397492\n",
      "  time_since_restore: 7956.357219457626\n",
      "  time_this_iter_s: 27.424659252166748\n",
      "  time_total_s: 7956.357219457626\n",
      "  timers:\n",
      "    learn_throughput: 1161.417\n",
      "    learn_time_ms: 1720.313\n",
      "    load_throughput: 59473.956\n",
      "    load_time_ms: 33.595\n",
      "    sample_throughput: 81.746\n",
      "    sample_time_ms: 24441.486\n",
      "    update_time_ms: 7.916\n",
      "  timestamp: 1636437477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 591408\n",
      "  training_iteration: 296\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   296</td><td style=\"text-align: right;\">         7956.36</td><td style=\"text-align: right;\">591408</td><td style=\"text-align: right;\">  7.9895</td><td style=\"text-align: right;\">               14.53</td><td style=\"text-align: right;\">                2.64</td><td style=\"text-align: right;\">             96.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 593406\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-58-23\n",
      "  done: false\n",
      "  episode_len_mean: 96.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.530000000000015\n",
      "  episode_reward_mean: 8.081100000000017\n",
      "  episode_reward_min: 2.550000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5633\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3109973527136303\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008568122291453185\n",
      "          policy_loss: -0.03191277918716272\n",
      "          total_loss: 0.17020867733018738\n",
      "          vf_explained_var: 0.96840500831604\n",
      "          vf_loss: 0.20547180211260205\n",
      "    num_agent_steps_sampled: 593406\n",
      "    num_agent_steps_trained: 593406\n",
      "    num_steps_sampled: 593406\n",
      "    num_steps_trained: 593406\n",
      "  iterations_since_restore: 297\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.62631578947367\n",
      "    ram_util_percent: 30.74473684210526\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434190699498521\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.674446605864524\n",
      "    mean_inference_ms: 2.4767476755721805\n",
      "    mean_raw_obs_processing_ms: 1.9692612146567767\n",
      "  time_since_restore: 7982.786813497543\n",
      "  time_this_iter_s: 26.429594039916992\n",
      "  time_total_s: 7982.786813497543\n",
      "  timers:\n",
      "    learn_throughput: 1158.626\n",
      "    learn_time_ms: 1724.456\n",
      "    load_throughput: 59605.853\n",
      "    load_time_ms: 33.52\n",
      "    sample_throughput: 81.712\n",
      "    sample_time_ms: 24451.599\n",
      "    update_time_ms: 7.813\n",
      "  timestamp: 1636437503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 593406\n",
      "  training_iteration: 297\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   297</td><td style=\"text-align: right;\">         7982.79</td><td style=\"text-align: right;\">593406</td><td style=\"text-align: right;\">  8.0811</td><td style=\"text-align: right;\">               14.53</td><td style=\"text-align: right;\">                2.55</td><td style=\"text-align: right;\">             96.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 595404\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-58-49\n",
      "  done: false\n",
      "  episode_len_mean: 96.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000018\n",
      "  episode_reward_mean: 7.970100000000018\n",
      "  episode_reward_min: 2.550000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5653\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1316296529202234\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006088562164106394\n",
      "          policy_loss: 0.0002647356085834049\n",
      "          total_loss: 0.16325493825688248\n",
      "          vf_explained_var: 0.969072699546814\n",
      "          vf_loss: 0.16737124589937075\n",
      "    num_agent_steps_sampled: 595404\n",
      "    num_agent_steps_trained: 595404\n",
      "    num_steps_sampled: 595404\n",
      "    num_steps_trained: 595404\n",
      "  iterations_since_restore: 298\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66111111111111\n",
      "    ram_util_percent: 30.71111111111111\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432245787229865\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.68182107614159\n",
      "    mean_inference_ms: 2.4765018598378834\n",
      "    mean_raw_obs_processing_ms: 1.9653512608930344\n",
      "  time_since_restore: 8008.056195735931\n",
      "  time_this_iter_s: 25.26938223838806\n",
      "  time_total_s: 8008.056195735931\n",
      "  timers:\n",
      "    learn_throughput: 1158.917\n",
      "    learn_time_ms: 1724.024\n",
      "    load_throughput: 59616.2\n",
      "    load_time_ms: 33.514\n",
      "    sample_throughput: 81.758\n",
      "    sample_time_ms: 24437.904\n",
      "    update_time_ms: 8.092\n",
      "  timestamp: 1636437529\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 595404\n",
      "  training_iteration: 298\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   298</td><td style=\"text-align: right;\">         8008.06</td><td style=\"text-align: right;\">595404</td><td style=\"text-align: right;\">  7.9701</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                2.55</td><td style=\"text-align: right;\">             96.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 597402\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-59-15\n",
      "  done: false\n",
      "  episode_len_mean: 97.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.490000000000016\n",
      "  episode_reward_mean: 7.673000000000018\n",
      "  episode_reward_min: 2.550000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5673\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.365710855665661\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006701762839933385\n",
      "          policy_loss: 0.0031870343678054355\n",
      "          total_loss: 0.13052367867813225\n",
      "          vf_explained_var: 0.9728474020957947\n",
      "          vf_loss: 0.13336002649295897\n",
      "    num_agent_steps_sampled: 597402\n",
      "    num_agent_steps_trained: 597402\n",
      "    num_steps_sampled: 597402\n",
      "    num_steps_trained: 597402\n",
      "  iterations_since_restore: 299\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.7236842105263\n",
      "    ram_util_percent: 30.655263157894744\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433730592613123\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.690700021288887\n",
      "    mean_inference_ms: 2.4768085593329374\n",
      "    mean_raw_obs_processing_ms: 1.9613086019099968\n",
      "  time_since_restore: 8034.499713897705\n",
      "  time_this_iter_s: 26.44351816177368\n",
      "  time_total_s: 8034.499713897705\n",
      "  timers:\n",
      "    learn_throughput: 1157.929\n",
      "    learn_time_ms: 1725.495\n",
      "    load_throughput: 59455.306\n",
      "    load_time_ms: 33.605\n",
      "    sample_throughput: 81.664\n",
      "    sample_time_ms: 24466.134\n",
      "    update_time_ms: 8.189\n",
      "  timestamp: 1636437555\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 597402\n",
      "  training_iteration: 299\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   299</td><td style=\"text-align: right;\">          8034.5</td><td style=\"text-align: right;\">597402</td><td style=\"text-align: right;\">   7.673</td><td style=\"text-align: right;\">               14.49</td><td style=\"text-align: right;\">                2.55</td><td style=\"text-align: right;\">             97.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 599400\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_05-59-56\n",
      "  done: false\n",
      "  episode_len_mean: 96.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.490000000000016\n",
      "  episode_reward_mean: 7.885200000000018\n",
      "  episode_reward_min: -0.9300000000000004\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 5695\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3499255855878194\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010289448945707238\n",
      "          policy_loss: -0.0030843831953548248\n",
      "          total_loss: 0.2606536429818897\n",
      "          vf_explained_var: 0.9488939642906189\n",
      "          vf_loss: 0.2655169583324875\n",
      "    num_agent_steps_sampled: 599400\n",
      "    num_agent_steps_trained: 599400\n",
      "    num_steps_sampled: 599400\n",
      "    num_steps_trained: 599400\n",
      "  iterations_since_restore: 300\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.46491228070175\n",
      "    ram_util_percent: 30.599999999999998\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044308770104885174\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.695259307493888\n",
      "    mean_inference_ms: 2.4763628365366195\n",
      "    mean_raw_obs_processing_ms: 1.9637386470888873\n",
      "  time_since_restore: 8074.901599884033\n",
      "  time_this_iter_s: 40.401885986328125\n",
      "  time_total_s: 8074.901599884033\n",
      "  timers:\n",
      "    learn_throughput: 1155.17\n",
      "    learn_time_ms: 1729.616\n",
      "    load_throughput: 59371.524\n",
      "    load_time_ms: 33.652\n",
      "    sample_throughput: 77.242\n",
      "    sample_time_ms: 25866.923\n",
      "    update_time_ms: 8.623\n",
      "  timestamp: 1636437596\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 599400\n",
      "  training_iteration: 300\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   300</td><td style=\"text-align: right;\">          8074.9</td><td style=\"text-align: right;\">599400</td><td style=\"text-align: right;\">  7.8852</td><td style=\"text-align: right;\">               14.49</td><td style=\"text-align: right;\">               -0.93</td><td style=\"text-align: right;\">             96.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 601398\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-00-50\n",
      "  done: false\n",
      "  episode_len_mean: 94.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 7.721000000000016\n",
      "  episode_reward_min: -0.9300000000000004\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 5718\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2433589322226388\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011807381576731554\n",
      "          policy_loss: -0.026393378854152702\n",
      "          total_loss: 0.29181354292890144\n",
      "          vf_explained_var: 0.9526144862174988\n",
      "          vf_loss: 0.3171911659694853\n",
      "    num_agent_steps_sampled: 601398\n",
      "    num_agent_steps_trained: 601398\n",
      "    num_steps_sampled: 601398\n",
      "    num_steps_trained: 601398\n",
      "  iterations_since_restore: 301\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.33333333333334\n",
      "    ram_util_percent: 30.37051282051281\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044304672346597566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.69793733258247\n",
      "    mean_inference_ms: 2.476268029875438\n",
      "    mean_raw_obs_processing_ms: 1.9780346028481648\n",
      "  time_since_restore: 8128.915739536285\n",
      "  time_this_iter_s: 54.0141396522522\n",
      "  time_total_s: 8128.915739536285\n",
      "  timers:\n",
      "    learn_throughput: 1155.018\n",
      "    learn_time_ms: 1729.844\n",
      "    load_throughput: 59530.611\n",
      "    load_time_ms: 33.563\n",
      "    sample_throughput: 69.555\n",
      "    sample_time_ms: 28725.289\n",
      "    update_time_ms: 8.759\n",
      "  timestamp: 1636437650\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 601398\n",
      "  training_iteration: 301\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   301</td><td style=\"text-align: right;\">         8128.92</td><td style=\"text-align: right;\">601398</td><td style=\"text-align: right;\">   7.721</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">               -0.93</td><td style=\"text-align: right;\">             94.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 603396\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-01-16\n",
      "  done: false\n",
      "  episode_len_mean: 94.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 8.119200000000015\n",
      "  episode_reward_min: -0.9300000000000004\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5738\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2416561035882858\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010914254311238034\n",
      "          policy_loss: -0.0915341990334647\n",
      "          total_loss: 0.13482485819785367\n",
      "          vf_explained_var: 0.9675099849700928\n",
      "          vf_loss: 0.2263436009841306\n",
      "    num_agent_steps_sampled: 603396\n",
      "    num_agent_steps_trained: 603396\n",
      "    num_steps_sampled: 603396\n",
      "    num_steps_trained: 603396\n",
      "  iterations_since_restore: 302\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.39999999999998\n",
      "    ram_util_percent: 30.108108108108116\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044290543414485094\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.698986709926327\n",
      "    mean_inference_ms: 2.476010243708488\n",
      "    mean_raw_obs_processing_ms: 1.990456737774349\n",
      "  time_since_restore: 8155.477116346359\n",
      "  time_this_iter_s: 26.561376810073853\n",
      "  time_total_s: 8155.477116346359\n",
      "  timers:\n",
      "    learn_throughput: 1155.227\n",
      "    learn_time_ms: 1729.53\n",
      "    load_throughput: 59432.621\n",
      "    load_time_ms: 33.618\n",
      "    sample_throughput: 69.678\n",
      "    sample_time_ms: 28674.71\n",
      "    update_time_ms: 9.098\n",
      "  timestamp: 1636437676\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 603396\n",
      "  training_iteration: 302\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   302</td><td style=\"text-align: right;\">         8155.48</td><td style=\"text-align: right;\">603396</td><td style=\"text-align: right;\">  8.1192</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">               -0.93</td><td style=\"text-align: right;\">             94.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 605394\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-01-42\n",
      "  done: false\n",
      "  episode_len_mean: 95.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.480000000000015\n",
      "  episode_reward_mean: 8.529000000000016\n",
      "  episode_reward_min: -0.9300000000000004\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 5757\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2639827762331282\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00971011580614214\n",
      "          policy_loss: -0.022461367664592606\n",
      "          total_loss: 0.2427133953287488\n",
      "          vf_explained_var: 0.9648404121398926\n",
      "          vf_loss: 0.26675416016507714\n",
      "    num_agent_steps_sampled: 605394\n",
      "    num_agent_steps_trained: 605394\n",
      "    num_steps_sampled: 605394\n",
      "    num_steps_trained: 605394\n",
      "  iterations_since_restore: 303\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95945945945945\n",
      "    ram_util_percent: 30.527027027027028\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429419038095659\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.699492039656462\n",
      "    mean_inference_ms: 2.475977225102724\n",
      "    mean_raw_obs_processing_ms: 2.0020857850320213\n",
      "  time_since_restore: 8181.323287963867\n",
      "  time_this_iter_s: 25.846171617507935\n",
      "  time_total_s: 8181.323287963867\n",
      "  timers:\n",
      "    learn_throughput: 1155.563\n",
      "    learn_time_ms: 1729.027\n",
      "    load_throughput: 59568.526\n",
      "    load_time_ms: 33.541\n",
      "    sample_throughput: 69.604\n",
      "    sample_time_ms: 28705.445\n",
      "    update_time_ms: 9.095\n",
      "  timestamp: 1636437702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 605394\n",
      "  training_iteration: 303\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   303</td><td style=\"text-align: right;\">         8181.32</td><td style=\"text-align: right;\">605394</td><td style=\"text-align: right;\">   8.529</td><td style=\"text-align: right;\">               14.48</td><td style=\"text-align: right;\">               -0.93</td><td style=\"text-align: right;\">              95.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 607392\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-02-08\n",
      "  done: false\n",
      "  episode_len_mean: 94.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 8.798900000000017\n",
      "  episode_reward_min: -0.9300000000000004\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5778\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2405522485574088\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007136468112908061\n",
      "          policy_loss: -0.029144861762012753\n",
      "          total_loss: 0.15495562636781307\n",
      "          vf_explained_var: 0.9704666137695312\n",
      "          vf_loss: 0.18837712758353778\n",
      "    num_agent_steps_sampled: 607392\n",
      "    num_agent_steps_trained: 607392\n",
      "    num_steps_sampled: 607392\n",
      "    num_steps_trained: 607392\n",
      "  iterations_since_restore: 304\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88648648648648\n",
      "    ram_util_percent: 30.802702702702703\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044280966764703604\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.700386395015375\n",
      "    mean_inference_ms: 2.4757075062390554\n",
      "    mean_raw_obs_processing_ms: 2.0150639566416455\n",
      "  time_since_restore: 8207.057776212692\n",
      "  time_this_iter_s: 25.734488248825073\n",
      "  time_total_s: 8207.057776212692\n",
      "  timers:\n",
      "    learn_throughput: 1154.521\n",
      "    learn_time_ms: 1730.587\n",
      "    load_throughput: 59625.489\n",
      "    load_time_ms: 33.509\n",
      "    sample_throughput: 69.959\n",
      "    sample_time_ms: 28559.74\n",
      "    update_time_ms: 9.57\n",
      "  timestamp: 1636437728\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 607392\n",
      "  training_iteration: 304\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   304</td><td style=\"text-align: right;\">         8207.06</td><td style=\"text-align: right;\">607392</td><td style=\"text-align: right;\">  8.7989</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">               -0.93</td><td style=\"text-align: right;\">             94.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 609390\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-02-33\n",
      "  done: false\n",
      "  episode_len_mean: 97.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 8.894300000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5798\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3346087847437178\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00763379862246083\n",
      "          policy_loss: -0.03561401014171896\n",
      "          total_loss: 0.1433802787569307\n",
      "          vf_explained_var: 0.9805277585983276\n",
      "          vf_loss: 0.18364500069015083\n",
      "    num_agent_steps_sampled: 609390\n",
      "    num_agent_steps_trained: 609390\n",
      "    num_steps_sampled: 609390\n",
      "    num_steps_trained: 609390\n",
      "  iterations_since_restore: 305\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.76666666666667\n",
      "    ram_util_percent: 30.955555555555552\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429613362107214\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.702906808281288\n",
      "    mean_inference_ms: 2.475887660042987\n",
      "    mean_raw_obs_processing_ms: 2.018162549324294\n",
      "  time_since_restore: 8231.928277730942\n",
      "  time_this_iter_s: 24.87050151824951\n",
      "  time_total_s: 8231.928277730942\n",
      "  timers:\n",
      "    learn_throughput: 1154.553\n",
      "    learn_time_ms: 1730.541\n",
      "    load_throughput: 59578.436\n",
      "    load_time_ms: 33.536\n",
      "    sample_throughput: 70.066\n",
      "    sample_time_ms: 28516.05\n",
      "    update_time_ms: 9.872\n",
      "  timestamp: 1636437753\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 609390\n",
      "  training_iteration: 305\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   305</td><td style=\"text-align: right;\">         8231.93</td><td style=\"text-align: right;\">609390</td><td style=\"text-align: right;\">  8.8943</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             97.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 611388\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-02-59\n",
      "  done: false\n",
      "  episode_len_mean: 99.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 9.138600000000018\n",
      "  episode_reward_min: 2.4700000000000197\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5818\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3177657615570795\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006817041483881586\n",
      "          policy_loss: -0.030266658411849112\n",
      "          total_loss: 0.10329165637847923\n",
      "          vf_explained_var: 0.9756495952606201\n",
      "          vf_loss: 0.13897093694124904\n",
      "    num_agent_steps_sampled: 611388\n",
      "    num_agent_steps_trained: 611388\n",
      "    num_steps_sampled: 611388\n",
      "    num_steps_trained: 611388\n",
      "  iterations_since_restore: 306\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.76111111111112\n",
      "    ram_util_percent: 30.999999999999993\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431483265373595\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.709943970318637\n",
      "    mean_inference_ms: 2.4761868203713533\n",
      "    mean_raw_obs_processing_ms: 2.0139218306379765\n",
      "  time_since_restore: 8257.646613836288\n",
      "  time_this_iter_s: 25.71833610534668\n",
      "  time_total_s: 8257.646613836288\n",
      "  timers:\n",
      "    learn_throughput: 1154.607\n",
      "    learn_time_ms: 1730.459\n",
      "    load_throughput: 59519.872\n",
      "    load_time_ms: 33.569\n",
      "    sample_throughput: 70.488\n",
      "    sample_time_ms: 28345.281\n",
      "    update_time_ms: 10.261\n",
      "  timestamp: 1636437779\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 611388\n",
      "  training_iteration: 306\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   306</td><td style=\"text-align: right;\">         8257.65</td><td style=\"text-align: right;\">611388</td><td style=\"text-align: right;\">  9.1386</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                2.47</td><td style=\"text-align: right;\">             99.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 613386\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-03-22\n",
      "  done: false\n",
      "  episode_len_mean: 101.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 8.985200000000019\n",
      "  episode_reward_min: 2.3000000000000274\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 5836\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.297631938116891\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007042905657675309\n",
      "          policy_loss: -0.009263151422852561\n",
      "          total_loss: 0.12301412625681786\n",
      "          vf_explained_var: 0.9844309687614441\n",
      "          vf_loss: 0.13723128670383067\n",
      "    num_agent_steps_sampled: 613386\n",
      "    num_agent_steps_trained: 613386\n",
      "    num_steps_sampled: 613386\n",
      "    num_steps_trained: 613386\n",
      "  iterations_since_restore: 307\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66060606060607\n",
      "    ram_util_percent: 31.03333333333333\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430733918794957\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.712654403717643\n",
      "    mean_inference_ms: 2.476102186287646\n",
      "    mean_raw_obs_processing_ms: 2.010222177518003\n",
      "  time_since_restore: 8280.690771341324\n",
      "  time_this_iter_s: 23.0441575050354\n",
      "  time_total_s: 8280.690771341324\n",
      "  timers:\n",
      "    learn_throughput: 1157.03\n",
      "    learn_time_ms: 1726.835\n",
      "    load_throughput: 59115.918\n",
      "    load_time_ms: 33.798\n",
      "    sample_throughput: 71.33\n",
      "    sample_time_ms: 28010.64\n",
      "    update_time_ms: 10.037\n",
      "  timestamp: 1636437802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 613386\n",
      "  training_iteration: 307\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   307</td><td style=\"text-align: right;\">         8280.69</td><td style=\"text-align: right;\">613386</td><td style=\"text-align: right;\">  8.9852</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                 2.3</td><td style=\"text-align: right;\">            101.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 615384\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-03-47\n",
      "  done: false\n",
      "  episode_len_mean: 101.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 8.937000000000019\n",
      "  episode_reward_min: 2.3000000000000274\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5856\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3245651114554633\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0095174603263617\n",
      "          policy_loss: -0.031058060980978467\n",
      "          total_loss: 0.18529041942563795\n",
      "          vf_explained_var: 0.9763503074645996\n",
      "          vf_loss: 0.21875314648662295\n",
      "    num_agent_steps_sampled: 615384\n",
      "    num_agent_steps_trained: 615384\n",
      "    num_steps_sampled: 615384\n",
      "    num_steps_trained: 615384\n",
      "  iterations_since_restore: 308\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.63783783783785\n",
      "    ram_util_percent: 31.067567567567572\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431919379312408\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.71557384921854\n",
      "    mean_inference_ms: 2.4762793630704185\n",
      "    mean_raw_obs_processing_ms: 2.00591805178352\n",
      "  time_since_restore: 8306.109172344208\n",
      "  time_this_iter_s: 25.41840100288391\n",
      "  time_total_s: 8306.109172344208\n",
      "  timers:\n",
      "    learn_throughput: 1156.823\n",
      "    learn_time_ms: 1727.144\n",
      "    load_throughput: 59460.79\n",
      "    load_time_ms: 33.602\n",
      "    sample_throughput: 71.292\n",
      "    sample_time_ms: 28025.42\n",
      "    update_time_ms: 10.001\n",
      "  timestamp: 1636437827\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 615384\n",
      "  training_iteration: 308\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   308</td><td style=\"text-align: right;\">         8306.11</td><td style=\"text-align: right;\">615384</td><td style=\"text-align: right;\">   8.937</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                 2.3</td><td style=\"text-align: right;\">             101.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 617382\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-04-12\n",
      "  done: false\n",
      "  episode_len_mean: 101.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 8.699500000000018\n",
      "  episode_reward_min: 2.3000000000000274\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 5877\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2807923873265585\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008340895499492499\n",
      "          policy_loss: -0.08425914081079619\n",
      "          total_loss: 0.1894460071366103\n",
      "          vf_explained_var: 0.9541444778442383\n",
      "          vf_loss: 0.2770122707244896\n",
      "    num_agent_steps_sampled: 617382\n",
      "    num_agent_steps_trained: 617382\n",
      "    num_steps_sampled: 617382\n",
      "    num_steps_trained: 617382\n",
      "  iterations_since_restore: 309\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1888888888889\n",
      "    ram_util_percent: 31.036111111111104\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431334194382036\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.715469446685926\n",
      "    mean_inference_ms: 2.4761257254418108\n",
      "    mean_raw_obs_processing_ms: 2.0014879598584723\n",
      "  time_since_restore: 8331.265494346619\n",
      "  time_this_iter_s: 25.15632200241089\n",
      "  time_total_s: 8331.265494346619\n",
      "  timers:\n",
      "    learn_throughput: 1157.486\n",
      "    learn_time_ms: 1726.155\n",
      "    load_throughput: 59339.237\n",
      "    load_time_ms: 33.671\n",
      "    sample_throughput: 71.621\n",
      "    sample_time_ms: 27897.026\n",
      "    update_time_ms: 10.612\n",
      "  timestamp: 1636437852\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 617382\n",
      "  training_iteration: 309\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   309</td><td style=\"text-align: right;\">         8331.27</td><td style=\"text-align: right;\">617382</td><td style=\"text-align: right;\">  8.6995</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                 2.3</td><td style=\"text-align: right;\">            101.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 619380\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-04-36\n",
      "  done: false\n",
      "  episode_len_mean: 102.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 8.406500000000019\n",
      "  episode_reward_min: 2.3000000000000274\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 5895\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3129312906946455\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011068693406404598\n",
      "          policy_loss: -0.0019634832051538286\n",
      "          total_loss: 0.33462216612838563\n",
      "          vf_explained_var: 0.9485781788825989\n",
      "          vf_loss: 0.3371070343646265\n",
      "    num_agent_steps_sampled: 619380\n",
      "    num_agent_steps_trained: 619380\n",
      "    num_steps_sampled: 619380\n",
      "    num_steps_trained: 619380\n",
      "  iterations_since_restore: 310\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08529411764705\n",
      "    ram_util_percent: 30.955882352941178\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443168187660484\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.71847752762415\n",
      "    mean_inference_ms: 2.476221977356207\n",
      "    mean_raw_obs_processing_ms: 1.997796645151662\n",
      "  time_since_restore: 8355.413782596588\n",
      "  time_this_iter_s: 24.148288249969482\n",
      "  time_total_s: 8355.413782596588\n",
      "  timers:\n",
      "    learn_throughput: 1158.193\n",
      "    learn_time_ms: 1725.101\n",
      "    load_throughput: 59346.759\n",
      "    load_time_ms: 33.667\n",
      "    sample_throughput: 76.048\n",
      "    sample_time_ms: 26272.818\n",
      "    update_time_ms: 10.223\n",
      "  timestamp: 1636437876\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 619380\n",
      "  training_iteration: 310\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   310</td><td style=\"text-align: right;\">         8355.41</td><td style=\"text-align: right;\">619380</td><td style=\"text-align: right;\">  8.4065</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">                 2.3</td><td style=\"text-align: right;\">             102.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 621378\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-05-02\n",
      "  done: false\n",
      "  episode_len_mean: 103.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000015\n",
      "  episode_reward_mean: 8.539700000000018\n",
      "  episode_reward_min: 2.1400000000000223\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5915\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2634616936956133\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00757920542650492\n",
      "          policy_loss: -0.040289596654474735\n",
      "          total_loss: 0.1518294477037021\n",
      "          vf_explained_var: 0.9709740281105042\n",
      "          vf_loss: 0.19612046827872595\n",
      "    num_agent_steps_sampled: 621378\n",
      "    num_agent_steps_trained: 621378\n",
      "    num_steps_sampled: 621378\n",
      "    num_steps_trained: 621378\n",
      "  iterations_since_restore: 311\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.56666666666666\n",
      "    ram_util_percent: 30.90277777777778\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044317874428273105\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.71774409734883\n",
      "    mean_inference_ms: 2.476225403306383\n",
      "    mean_raw_obs_processing_ms: 1.9934321727256359\n",
      "  time_since_restore: 8380.848399877548\n",
      "  time_this_iter_s: 25.434617280960083\n",
      "  time_total_s: 8380.848399877548\n",
      "  timers:\n",
      "    learn_throughput: 1158.673\n",
      "    learn_time_ms: 1724.387\n",
      "    load_throughput: 59260.685\n",
      "    load_time_ms: 33.715\n",
      "    sample_throughput: 85.327\n",
      "    sample_time_ms: 23415.934\n",
      "    update_time_ms: 10.042\n",
      "  timestamp: 1636437902\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 621378\n",
      "  training_iteration: 311\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   311</td><td style=\"text-align: right;\">         8380.85</td><td style=\"text-align: right;\">621378</td><td style=\"text-align: right;\">  8.5397</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                2.14</td><td style=\"text-align: right;\">            103.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 623376\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-05-26\n",
      "  done: false\n",
      "  episode_len_mean: 101.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000015\n",
      "  episode_reward_mean: 8.309300000000018\n",
      "  episode_reward_min: 2.1400000000000223\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5935\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3202674984931946\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009725692704796968\n",
      "          policy_loss: -0.025309374786558606\n",
      "          total_loss: 0.1677281198535292\n",
      "          vf_explained_var: 0.9688036441802979\n",
      "          vf_loss: 0.1951619993363108\n",
      "    num_agent_steps_sampled: 623376\n",
      "    num_agent_steps_trained: 623376\n",
      "    num_steps_sampled: 623376\n",
      "    num_steps_trained: 623376\n",
      "  iterations_since_restore: 312\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.74857142857142\n",
      "    ram_util_percent: 30.89428571428571\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432775556172114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.716219181638692\n",
      "    mean_inference_ms: 2.4762797139556283\n",
      "    mean_raw_obs_processing_ms: 1.9889725781781313\n",
      "  time_since_restore: 8405.217938184738\n",
      "  time_this_iter_s: 24.36953830718994\n",
      "  time_total_s: 8405.217938184738\n",
      "  timers:\n",
      "    learn_throughput: 1156.783\n",
      "    learn_time_ms: 1727.204\n",
      "    load_throughput: 59186.019\n",
      "    load_time_ms: 33.758\n",
      "    sample_throughput: 86.145\n",
      "    sample_time_ms: 23193.554\n",
      "    update_time_ms: 10.163\n",
      "  timestamp: 1636437926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 623376\n",
      "  training_iteration: 312\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   312</td><td style=\"text-align: right;\">         8405.22</td><td style=\"text-align: right;\">623376</td><td style=\"text-align: right;\">  8.3093</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                2.14</td><td style=\"text-align: right;\">             101.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 625374\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-05-52\n",
      "  done: false\n",
      "  episode_len_mean: 101.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000015\n",
      "  episode_reward_mean: 7.861100000000017\n",
      "  episode_reward_min: 2.1400000000000223\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 5954\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3729094715345473\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0071089508887110095\n",
      "          policy_loss: 0.004474679735444841\n",
      "          total_loss: 0.1752691260405949\n",
      "          vf_explained_var: 0.9453265070915222\n",
      "          vf_loss: 0.17642600092859495\n",
      "    num_agent_steps_sampled: 625374\n",
      "    num_agent_steps_trained: 625374\n",
      "    num_steps_sampled: 625374\n",
      "    num_steps_trained: 625374\n",
      "  iterations_since_restore: 313\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84444444444445\n",
      "    ram_util_percent: 30.875000000000007\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443180906982672\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.714537208759303\n",
      "    mean_inference_ms: 2.4761097321486845\n",
      "    mean_raw_obs_processing_ms: 1.9849426492522746\n",
      "  time_since_restore: 8430.537791013718\n",
      "  time_this_iter_s: 25.319852828979492\n",
      "  time_total_s: 8430.537791013718\n",
      "  timers:\n",
      "    learn_throughput: 1156.561\n",
      "    learn_time_ms: 1727.535\n",
      "    load_throughput: 58862.628\n",
      "    load_time_ms: 33.943\n",
      "    sample_throughput: 86.341\n",
      "    sample_time_ms: 23140.739\n",
      "    update_time_ms: 9.786\n",
      "  timestamp: 1636437952\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 625374\n",
      "  training_iteration: 313\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   313</td><td style=\"text-align: right;\">         8430.54</td><td style=\"text-align: right;\">625374</td><td style=\"text-align: right;\">  7.8611</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                2.14</td><td style=\"text-align: right;\">            101.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 627372\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-06-16\n",
      "  done: false\n",
      "  episode_len_mean: 103.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000015\n",
      "  episode_reward_mean: 7.791300000000017\n",
      "  episode_reward_min: 1.9200000000000135\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 5972\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2368049241247632\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016238027077817182\n",
      "          policy_loss: -0.027221323922276497\n",
      "          total_loss: 0.34872675289710364\n",
      "          vf_explained_var: 0.922298014163971\n",
      "          vf_loss: 0.3698199959737914\n",
      "    num_agent_steps_sampled: 627372\n",
      "    num_agent_steps_trained: 627372\n",
      "    num_steps_sampled: 627372\n",
      "    num_steps_trained: 627372\n",
      "  iterations_since_restore: 314\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.79999999999998\n",
      "    ram_util_percent: 30.825714285714287\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430304303836625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.71680514478727\n",
      "    mean_inference_ms: 2.475979438439835\n",
      "    mean_raw_obs_processing_ms: 1.9813684877830133\n",
      "  time_since_restore: 8454.696291446686\n",
      "  time_this_iter_s: 24.15850043296814\n",
      "  time_total_s: 8454.696291446686\n",
      "  timers:\n",
      "    learn_throughput: 1156.452\n",
      "    learn_time_ms: 1727.698\n",
      "    load_throughput: 58742.271\n",
      "    load_time_ms: 34.013\n",
      "    sample_throughput: 86.932\n",
      "    sample_time_ms: 22983.527\n",
      "    update_time_ms: 9.188\n",
      "  timestamp: 1636437976\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 627372\n",
      "  training_iteration: 314\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   314</td><td style=\"text-align: right;\">          8454.7</td><td style=\"text-align: right;\">627372</td><td style=\"text-align: right;\">  7.7913</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                1.92</td><td style=\"text-align: right;\">            103.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 629370\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-06-41\n",
      "  done: false\n",
      "  episode_len_mean: 103.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.560000000000015\n",
      "  episode_reward_mean: 7.8888000000000185\n",
      "  episode_reward_min: 1.9200000000000135\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 5992\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2347448865572612\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007781012677058421\n",
      "          policy_loss: -0.038177728227206637\n",
      "          total_loss: 0.207445010596088\n",
      "          vf_explained_var: 0.9378317594528198\n",
      "          vf_loss: 0.24910712795598167\n",
      "    num_agent_steps_sampled: 629370\n",
      "    num_agent_steps_trained: 629370\n",
      "    num_steps_sampled: 629370\n",
      "    num_steps_trained: 629370\n",
      "  iterations_since_restore: 315\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.15833333333335\n",
      "    ram_util_percent: 30.79166666666667\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431213143633096\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.714415770689165\n",
      "    mean_inference_ms: 2.476059156238293\n",
      "    mean_raw_obs_processing_ms: 1.9768745943280432\n",
      "  time_since_restore: 8480.19708609581\n",
      "  time_this_iter_s: 25.500794649124146\n",
      "  time_total_s: 8480.19708609581\n",
      "  timers:\n",
      "    learn_throughput: 1156.558\n",
      "    learn_time_ms: 1727.54\n",
      "    load_throughput: 58699.808\n",
      "    load_time_ms: 34.038\n",
      "    sample_throughput: 86.694\n",
      "    sample_time_ms: 23046.564\n",
      "    update_time_ms: 9.572\n",
      "  timestamp: 1636438001\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 629370\n",
      "  training_iteration: 315\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   315</td><td style=\"text-align: right;\">          8480.2</td><td style=\"text-align: right;\">629370</td><td style=\"text-align: right;\">  7.8888</td><td style=\"text-align: right;\">               14.56</td><td style=\"text-align: right;\">                1.92</td><td style=\"text-align: right;\">            103.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 631368\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-07-07\n",
      "  done: false\n",
      "  episode_len_mean: 103.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 7.673000000000019\n",
      "  episode_reward_min: 1.9200000000000135\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6012\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2657837510108947\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009025867258374613\n",
      "          policy_loss: -0.03296610970227491\n",
      "          total_loss: 0.16502917748654172\n",
      "          vf_explained_var: 0.9621362686157227\n",
      "          vf_loss: 0.2003720967187768\n",
      "    num_agent_steps_sampled: 631368\n",
      "    num_agent_steps_trained: 631368\n",
      "    num_steps_sampled: 631368\n",
      "    num_steps_trained: 631368\n",
      "  iterations_since_restore: 316\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.375\n",
      "    ram_util_percent: 30.691666666666663\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044304083434253363\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.712977609292786\n",
      "    mean_inference_ms: 2.4759136737884786\n",
      "    mean_raw_obs_processing_ms: 1.9726575236942194\n",
      "  time_since_restore: 8505.24926686287\n",
      "  time_this_iter_s: 25.052180767059326\n",
      "  time_total_s: 8505.24926686287\n",
      "  timers:\n",
      "    learn_throughput: 1157.841\n",
      "    learn_time_ms: 1725.625\n",
      "    load_throughput: 58826.308\n",
      "    load_time_ms: 33.964\n",
      "    sample_throughput: 86.938\n",
      "    sample_time_ms: 22981.886\n",
      "    update_time_ms: 9.503\n",
      "  timestamp: 1636438027\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 631368\n",
      "  training_iteration: 316\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   316</td><td style=\"text-align: right;\">         8505.25</td><td style=\"text-align: right;\">631368</td><td style=\"text-align: right;\">   7.673</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">                1.92</td><td style=\"text-align: right;\">            103.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 633366\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-07-32\n",
      "  done: false\n",
      "  episode_len_mean: 102.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 7.593700000000018\n",
      "  episode_reward_min: 1.9200000000000135\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 6031\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4326064387957256\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010196276658626545\n",
      "          policy_loss: -0.001278564085563024\n",
      "          total_loss: 0.09863783796096132\n",
      "          vf_explained_var: 0.9837288856506348\n",
      "          vf_loss: 0.10262826727259727\n",
      "    num_agent_steps_sampled: 633366\n",
      "    num_agent_steps_trained: 633366\n",
      "    num_steps_sampled: 633366\n",
      "    num_steps_trained: 633366\n",
      "  iterations_since_restore: 317\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6361111111111\n",
      "    ram_util_percent: 30.72222222222222\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443050164731752\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.712559538565202\n",
      "    mean_inference_ms: 2.475936007340276\n",
      "    mean_raw_obs_processing_ms: 1.9686856498239838\n",
      "  time_since_restore: 8530.400489807129\n",
      "  time_this_iter_s: 25.151222944259644\n",
      "  time_total_s: 8530.400489807129\n",
      "  timers:\n",
      "    learn_throughput: 1157.642\n",
      "    learn_time_ms: 1725.922\n",
      "    load_throughput: 58810.208\n",
      "    load_time_ms: 33.974\n",
      "    sample_throughput: 86.152\n",
      "    sample_time_ms: 23191.682\n",
      "    update_time_ms: 9.96\n",
      "  timestamp: 1636438052\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 633366\n",
      "  training_iteration: 317\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   317</td><td style=\"text-align: right;\">          8530.4</td><td style=\"text-align: right;\">633366</td><td style=\"text-align: right;\">  7.5937</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">                1.92</td><td style=\"text-align: right;\">            102.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 635364\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-08-12\n",
      "  done: false\n",
      "  episode_len_mean: 103.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 7.692200000000018\n",
      "  episode_reward_min: -0.02\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6051\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3352373265084767\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005868270707514852\n",
      "          policy_loss: -0.029777866424549194\n",
      "          total_loss: 0.14744337428183782\n",
      "          vf_explained_var: 0.9707704186439514\n",
      "          vf_loss: 0.18388928433968907\n",
      "    num_agent_steps_sampled: 635364\n",
      "    num_agent_steps_trained: 635364\n",
      "    num_steps_sampled: 635364\n",
      "    num_steps_trained: 635364\n",
      "  iterations_since_restore: 318\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.7122807017544\n",
      "    ram_util_percent: 30.682456140350876\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044309772294449774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.71425999468438\n",
      "    mean_inference_ms: 2.4760304433148086\n",
      "    mean_raw_obs_processing_ms: 1.970889068752023\n",
      "  time_since_restore: 8570.415243148804\n",
      "  time_this_iter_s: 40.014753341674805\n",
      "  time_total_s: 8570.415243148804\n",
      "  timers:\n",
      "    learn_throughput: 1156.72\n",
      "    learn_time_ms: 1727.298\n",
      "    load_throughput: 58528.033\n",
      "    load_time_ms: 34.137\n",
      "    sample_throughput: 81.054\n",
      "    sample_time_ms: 24650.152\n",
      "    update_time_ms: 9.5\n",
      "  timestamp: 1636438092\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 635364\n",
      "  training_iteration: 318\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   318</td><td style=\"text-align: right;\">         8570.42</td><td style=\"text-align: right;\">635364</td><td style=\"text-align: right;\">  7.6922</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.02</td><td style=\"text-align: right;\">            103.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 637362\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-08-53\n",
      "  done: false\n",
      "  episode_len_mean: 99.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 7.804200000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 6073\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2549826301279523\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008143174336559528\n",
      "          policy_loss: 0.0024234875060972715\n",
      "          total_loss: 0.2853721315662066\n",
      "          vf_explained_var: 0.9639819860458374\n",
      "          vf_loss: 0.28622288292362574\n",
      "    num_agent_steps_sampled: 637362\n",
      "    num_agent_steps_trained: 637362\n",
      "    num_steps_sampled: 637362\n",
      "    num_steps_trained: 637362\n",
      "  iterations_since_restore: 319\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.79999999999998\n",
      "    ram_util_percent: 30.7542372881356\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434447006892791\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.70774478293379\n",
      "    mean_inference_ms: 2.4763418890180153\n",
      "    mean_raw_obs_processing_ms: 1.9834876286078094\n",
      "  time_since_restore: 8611.830386161804\n",
      "  time_this_iter_s: 41.41514301300049\n",
      "  time_total_s: 8611.830386161804\n",
      "  timers:\n",
      "    learn_throughput: 1156.632\n",
      "    learn_time_ms: 1727.429\n",
      "    load_throughput: 58577.208\n",
      "    load_time_ms: 34.109\n",
      "    sample_throughput: 76.039\n",
      "    sample_time_ms: 26276.02\n",
      "    update_time_ms: 9.285\n",
      "  timestamp: 1636438133\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 637362\n",
      "  training_iteration: 319\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   319</td><td style=\"text-align: right;\">         8611.83</td><td style=\"text-align: right;\">637362</td><td style=\"text-align: right;\">  7.8042</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 639360\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-09-20\n",
      "  done: false\n",
      "  episode_len_mean: 98.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 7.5996000000000175\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6093\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3610617461658658\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005413807772278378\n",
      "          policy_loss: 0.0006613577760401226\n",
      "          total_loss: 0.08950198745975892\n",
      "          vf_explained_var: 0.9809530973434448\n",
      "          vf_loss: 0.09628458220866465\n",
      "    num_agent_steps_sampled: 639360\n",
      "    num_agent_steps_trained: 639360\n",
      "    num_steps_sampled: 639360\n",
      "    num_steps_trained: 639360\n",
      "  iterations_since_restore: 320\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.52307692307693\n",
      "    ram_util_percent: 30.561538461538458\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044335191179911\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.706159770664406\n",
      "    mean_inference_ms: 2.4761728971416352\n",
      "    mean_raw_obs_processing_ms: 1.9953924084454275\n",
      "  time_since_restore: 8638.820274353027\n",
      "  time_this_iter_s: 26.989888191223145\n",
      "  time_total_s: 8638.820274353027\n",
      "  timers:\n",
      "    learn_throughput: 1159.241\n",
      "    learn_time_ms: 1723.541\n",
      "    load_throughput: 58517.979\n",
      "    load_time_ms: 34.143\n",
      "    sample_throughput: 75.218\n",
      "    sample_time_ms: 26562.962\n",
      "    update_time_ms: 10.659\n",
      "  timestamp: 1636438160\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 639360\n",
      "  training_iteration: 320\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   320</td><td style=\"text-align: right;\">         8638.82</td><td style=\"text-align: right;\">639360</td><td style=\"text-align: right;\">  7.5996</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 641358\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-09-46\n",
      "  done: false\n",
      "  episode_len_mean: 98.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 7.586300000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6114\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.1390624999999996\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3224298783711024\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.004952700170160624\n",
      "          policy_loss: -0.09212660439135063\n",
      "          total_loss: 0.04889947387079398\n",
      "          vf_explained_var: 0.9721863269805908\n",
      "          vf_loss: 0.1486089398463567\n",
      "    num_agent_steps_sampled: 641358\n",
      "    num_agent_steps_trained: 641358\n",
      "    num_steps_sampled: 641358\n",
      "    num_steps_trained: 641358\n",
      "  iterations_since_restore: 321\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8162162162162\n",
      "    ram_util_percent: 30.737837837837848\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433968402309736\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.706173213689826\n",
      "    mean_inference_ms: 2.4761492857195533\n",
      "    mean_raw_obs_processing_ms: 2.0079134467554445\n",
      "  time_since_restore: 8664.626159191132\n",
      "  time_this_iter_s: 25.805884838104248\n",
      "  time_total_s: 8664.626159191132\n",
      "  timers:\n",
      "    learn_throughput: 1158.683\n",
      "    learn_time_ms: 1724.371\n",
      "    load_throughput: 58477.921\n",
      "    load_time_ms: 34.167\n",
      "    sample_throughput: 75.117\n",
      "    sample_time_ms: 26598.556\n",
      "    update_time_ms: 11.345\n",
      "  timestamp: 1636438186\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 641358\n",
      "  training_iteration: 321\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   321</td><td style=\"text-align: right;\">         8664.63</td><td style=\"text-align: right;\">641358</td><td style=\"text-align: right;\">  7.5863</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 643356\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-10-12\n",
      "  done: false\n",
      "  episode_len_mean: 97.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 7.643600000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 6133\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3385417904172625\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008653353120958399\n",
      "          policy_loss: -0.07999962340330793\n",
      "          total_loss: 0.019447026953899434\n",
      "          vf_explained_var: 0.9820808172225952\n",
      "          vf_loss: 0.10790371565769116\n",
      "    num_agent_steps_sampled: 643356\n",
      "    num_agent_steps_trained: 643356\n",
      "    num_steps_sampled: 643356\n",
      "    num_steps_trained: 643356\n",
      "  iterations_since_restore: 322\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94444444444444\n",
      "    ram_util_percent: 30.80555555555556\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044336154153894754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.70870449373491\n",
      "    mean_inference_ms: 2.4760336584917413\n",
      "    mean_raw_obs_processing_ms: 2.0193618283342203\n",
      "  time_since_restore: 8690.199691534042\n",
      "  time_this_iter_s: 25.573532342910767\n",
      "  time_total_s: 8690.199691534042\n",
      "  timers:\n",
      "    learn_throughput: 1159.491\n",
      "    learn_time_ms: 1723.169\n",
      "    load_throughput: 58572.541\n",
      "    load_time_ms: 34.112\n",
      "    sample_throughput: 74.773\n",
      "    sample_time_ms: 26720.818\n",
      "    update_time_ms: 10.799\n",
      "  timestamp: 1636438212\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 643356\n",
      "  training_iteration: 322\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   322</td><td style=\"text-align: right;\">          8690.2</td><td style=\"text-align: right;\">643356</td><td style=\"text-align: right;\">  7.6436</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 645354\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-10-36\n",
      "  done: false\n",
      "  episode_len_mean: 98.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 7.725700000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6154\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3415324733370826\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013769056187539545\n",
      "          policy_loss: -0.02720396516046354\n",
      "          total_loss: 0.22429359061199994\n",
      "          vf_explained_var: 0.9631147384643555\n",
      "          vf_loss: 0.25707097065945467\n",
      "    num_agent_steps_sampled: 645354\n",
      "    num_agent_steps_trained: 645354\n",
      "    num_steps_sampled: 645354\n",
      "    num_steps_trained: 645354\n",
      "  iterations_since_restore: 323\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.56285714285715\n",
      "    ram_util_percent: 30.914285714285715\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433868407952711\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.707071623002268\n",
      "    mean_inference_ms: 2.4759326603429046\n",
      "    mean_raw_obs_processing_ms: 2.0231221099064105\n",
      "  time_since_restore: 8714.651478290558\n",
      "  time_this_iter_s: 24.451786756515503\n",
      "  time_total_s: 8714.651478290558\n",
      "  timers:\n",
      "    learn_throughput: 1159.086\n",
      "    learn_time_ms: 1723.772\n",
      "    load_throughput: 58724.447\n",
      "    load_time_ms: 34.023\n",
      "    sample_throughput: 75.021\n",
      "    sample_time_ms: 26632.681\n",
      "    update_time_ms: 11.503\n",
      "  timestamp: 1636438236\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 645354\n",
      "  training_iteration: 323\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   323</td><td style=\"text-align: right;\">         8714.65</td><td style=\"text-align: right;\">645354</td><td style=\"text-align: right;\">  7.7257</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 647352\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-11-02\n",
      "  done: false\n",
      "  episode_len_mean: 99.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 7.700700000000017\n",
      "  episode_reward_min: 2.730000000000017\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 6173\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3631918804986136\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01143959940595484\n",
      "          policy_loss: -0.045070055801244006\n",
      "          total_loss: 0.15435975872068888\n",
      "          vf_explained_var: 0.9603191614151001\n",
      "          vf_loss: 0.2065465254088243\n",
      "    num_agent_steps_sampled: 647352\n",
      "    num_agent_steps_trained: 647352\n",
      "    num_steps_sampled: 647352\n",
      "    num_steps_trained: 647352\n",
      "  iterations_since_restore: 324\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.22162162162162\n",
      "    ram_util_percent: 31.032432432432426\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434349036519665\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.71339379577639\n",
      "    mean_inference_ms: 2.4760528108910638\n",
      "    mean_raw_obs_processing_ms: 2.0194029164572296\n",
      "  time_since_restore: 8740.23630142212\n",
      "  time_this_iter_s: 25.58482313156128\n",
      "  time_total_s: 8740.23630142212\n",
      "  timers:\n",
      "    learn_throughput: 1157.742\n",
      "    learn_time_ms: 1725.773\n",
      "    load_throughput: 58716.3\n",
      "    load_time_ms: 34.028\n",
      "    sample_throughput: 74.626\n",
      "    sample_time_ms: 26773.432\n",
      "    update_time_ms: 11.144\n",
      "  timestamp: 1636438262\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 647352\n",
      "  training_iteration: 324\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   324</td><td style=\"text-align: right;\">         8740.24</td><td style=\"text-align: right;\">647352</td><td style=\"text-align: right;\">  7.7007</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">             99.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 649350\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-11-27\n",
      "  done: false\n",
      "  episode_len_mean: 99.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 8.005800000000018\n",
      "  episode_reward_min: 2.730000000000017\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6193\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3936658484595164\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007582191297501996\n",
      "          policy_loss: -0.10740059362280936\n",
      "          total_loss: -0.03816273029716242\n",
      "          vf_explained_var: 0.9791226387023926\n",
      "          vf_loss: 0.07885622497470605\n",
      "    num_agent_steps_sampled: 649350\n",
      "    num_agent_steps_trained: 649350\n",
      "    num_steps_sampled: 649350\n",
      "    num_steps_trained: 649350\n",
      "  iterations_since_restore: 325\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96571428571428\n",
      "    ram_util_percent: 31.00857142857143\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436630526542491\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.714763466010698\n",
      "    mean_inference_ms: 2.4762954622013638\n",
      "    mean_raw_obs_processing_ms: 2.015271594605839\n",
      "  time_since_restore: 8765.075381040573\n",
      "  time_this_iter_s: 24.83907961845398\n",
      "  time_total_s: 8765.075381040573\n",
      "  timers:\n",
      "    learn_throughput: 1158.218\n",
      "    learn_time_ms: 1725.064\n",
      "    load_throughput: 58818.34\n",
      "    load_time_ms: 33.969\n",
      "    sample_throughput: 74.807\n",
      "    sample_time_ms: 26708.567\n",
      "    update_time_ms: 10.41\n",
      "  timestamp: 1636438287\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 649350\n",
      "  training_iteration: 325\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   325</td><td style=\"text-align: right;\">         8765.08</td><td style=\"text-align: right;\">649350</td><td style=\"text-align: right;\">  8.0058</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">             99.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 651348\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-11-53\n",
      "  done: false\n",
      "  episode_len_mean: 98.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 7.953700000000018\n",
      "  episode_reward_min: 2.730000000000017\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6214\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.142639585619881\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015675833456691993\n",
      "          policy_loss: -0.024350583517835252\n",
      "          total_loss: 0.21015512840378853\n",
      "          vf_explained_var: 0.9639255404472351\n",
      "          vf_loss: 0.2370042291070734\n",
      "    num_agent_steps_sampled: 651348\n",
      "    num_agent_steps_trained: 651348\n",
      "    num_steps_sampled: 651348\n",
      "    num_steps_trained: 651348\n",
      "  iterations_since_restore: 326\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97631578947369\n",
      "    ram_util_percent: 31.034210526315782\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044353783192523144\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.7183429240785\n",
      "    mean_inference_ms: 2.476069588614078\n",
      "    mean_raw_obs_processing_ms: 2.0112182229877327\n",
      "  time_since_restore: 8791.40548658371\n",
      "  time_this_iter_s: 26.330105543136597\n",
      "  time_total_s: 8791.40548658371\n",
      "  timers:\n",
      "    learn_throughput: 1156.974\n",
      "    learn_time_ms: 1726.918\n",
      "    load_throughput: 58687.476\n",
      "    load_time_ms: 34.045\n",
      "    sample_throughput: 74.455\n",
      "    sample_time_ms: 26834.987\n",
      "    update_time_ms: 9.938\n",
      "  timestamp: 1636438313\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 651348\n",
      "  training_iteration: 326\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   326</td><td style=\"text-align: right;\">         8791.41</td><td style=\"text-align: right;\">651348</td><td style=\"text-align: right;\">  7.9537</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">             98.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 653346\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-12-19\n",
      "  done: false\n",
      "  episode_len_mean: 98.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 7.843700000000018\n",
      "  episode_reward_min: 2.730000000000017\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6235\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.348704231353033\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014119688553355624\n",
      "          policy_loss: 0.030383043328211422\n",
      "          total_loss: 0.3220374312384852\n",
      "          vf_explained_var: 0.9455980658531189\n",
      "          vf_loss: 0.2970998193359091\n",
      "    num_agent_steps_sampled: 653346\n",
      "    num_agent_steps_trained: 653346\n",
      "    num_steps_sampled: 653346\n",
      "    num_steps_trained: 653346\n",
      "  iterations_since_restore: 327\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.50540540540541\n",
      "    ram_util_percent: 31.048648648648648\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044349031326292684\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.72058599011377\n",
      "    mean_inference_ms: 2.475947055199284\n",
      "    mean_raw_obs_processing_ms: 2.0071467102606424\n",
      "  time_since_restore: 8817.48848247528\n",
      "  time_this_iter_s: 26.082995891571045\n",
      "  time_total_s: 8817.48848247528\n",
      "  timers:\n",
      "    learn_throughput: 1157.072\n",
      "    learn_time_ms: 1726.773\n",
      "    load_throughput: 58757.51\n",
      "    load_time_ms: 34.004\n",
      "    sample_throughput: 74.197\n",
      "    sample_time_ms: 26928.441\n",
      "    update_time_ms: 9.693\n",
      "  timestamp: 1636438339\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 653346\n",
      "  training_iteration: 327\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   327</td><td style=\"text-align: right;\">         8817.49</td><td style=\"text-align: right;\">653346</td><td style=\"text-align: right;\">  7.8437</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">             98.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 655344\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-12-44\n",
      "  done: false\n",
      "  episode_len_mean: 98.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000015\n",
      "  episode_reward_mean: 7.743700000000017\n",
      "  episode_reward_min: 2.7300000000000133\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6255\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3869074588730221\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01067370691544567\n",
      "          policy_loss: -0.04809710421555099\n",
      "          total_loss: 0.12638575141983374\n",
      "          vf_explained_var: 0.9640377163887024\n",
      "          vf_loss: 0.1822729203850031\n",
      "    num_agent_steps_sampled: 655344\n",
      "    num_agent_steps_trained: 655344\n",
      "    num_steps_sampled: 655344\n",
      "    num_steps_trained: 655344\n",
      "  iterations_since_restore: 328\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04722222222223\n",
      "    ram_util_percent: 31.022222222222215\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436790941461721\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.724071932838196\n",
      "    mean_inference_ms: 2.4761973976922347\n",
      "    mean_raw_obs_processing_ms: 2.003109465463545\n",
      "  time_since_restore: 8842.75202012062\n",
      "  time_this_iter_s: 25.263537645339966\n",
      "  time_total_s: 8842.75202012062\n",
      "  timers:\n",
      "    learn_throughput: 1158.404\n",
      "    learn_time_ms: 1724.787\n",
      "    load_throughput: 58931.673\n",
      "    load_time_ms: 33.904\n",
      "    sample_throughput: 78.495\n",
      "    sample_time_ms: 25453.963\n",
      "    update_time_ms: 10.722\n",
      "  timestamp: 1636438364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 655344\n",
      "  training_iteration: 328\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   328</td><td style=\"text-align: right;\">         8842.75</td><td style=\"text-align: right;\">655344</td><td style=\"text-align: right;\">  7.7437</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">             98.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 657342\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-13-12\n",
      "  done: false\n",
      "  episode_len_mean: 98.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000014\n",
      "  episode_reward_mean: 7.616800000000017\n",
      "  episode_reward_min: 2.6300000000000114\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6275\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.346135629074914\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011249463457396709\n",
      "          policy_loss: -0.060158145693796024\n",
      "          total_loss: 0.12156166911479972\n",
      "          vf_explained_var: 0.9698509573936462\n",
      "          vf_loss: 0.18877424938338144\n",
      "    num_agent_steps_sampled: 657342\n",
      "    num_agent_steps_trained: 657342\n",
      "    num_steps_sampled: 657342\n",
      "    num_steps_trained: 657342\n",
      "  iterations_since_restore: 329\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.63333333333335\n",
      "    ram_util_percent: 31.010256410256407\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435935471223632\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.728048117744017\n",
      "    mean_inference_ms: 2.4760293195001317\n",
      "    mean_raw_obs_processing_ms: 1.9992476823822531\n",
      "  time_since_restore: 8869.864436626434\n",
      "  time_this_iter_s: 27.1124165058136\n",
      "  time_total_s: 8869.864436626434\n",
      "  timers:\n",
      "    learn_throughput: 1158.514\n",
      "    learn_time_ms: 1724.623\n",
      "    load_throughput: 58902.595\n",
      "    load_time_ms: 33.92\n",
      "    sample_throughput: 83.167\n",
      "    sample_time_ms: 24023.967\n",
      "    update_time_ms: 10.739\n",
      "  timestamp: 1636438392\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 657342\n",
      "  training_iteration: 329\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   329</td><td style=\"text-align: right;\">         8869.86</td><td style=\"text-align: right;\">657342</td><td style=\"text-align: right;\">  7.6168</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">                2.63</td><td style=\"text-align: right;\">              98.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 659340\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-13-39\n",
      "  done: false\n",
      "  episode_len_mean: 97.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.460000000000017\n",
      "  episode_reward_mean: 7.712700000000016\n",
      "  episode_reward_min: 2.6300000000000114\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6295\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2800861568677993\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009757849133289594\n",
      "          policy_loss: -0.042126618698239325\n",
      "          total_loss: 0.06994981784373522\n",
      "          vf_explained_var: 0.9764447808265686\n",
      "          vf_loss: 0.11931989901654777\n",
      "    num_agent_steps_sampled: 659340\n",
      "    num_agent_steps_trained: 659340\n",
      "    num_steps_sampled: 659340\n",
      "    num_steps_trained: 659340\n",
      "  iterations_since_restore: 330\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.64358974358974\n",
      "    ram_util_percent: 30.938461538461535\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435765921264465\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.73384205484154\n",
      "    mean_inference_ms: 2.4760195198688\n",
      "    mean_raw_obs_processing_ms: 1.9954226886582374\n",
      "  time_since_restore: 8897.333862781525\n",
      "  time_this_iter_s: 27.469426155090332\n",
      "  time_total_s: 8897.333862781525\n",
      "  timers:\n",
      "    learn_throughput: 1159.121\n",
      "    learn_time_ms: 1723.72\n",
      "    load_throughput: 59047.191\n",
      "    load_time_ms: 33.837\n",
      "    sample_throughput: 82.996\n",
      "    sample_time_ms: 24073.507\n",
      "    update_time_ms: 10.174\n",
      "  timestamp: 1636438419\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 659340\n",
      "  training_iteration: 330\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   330</td><td style=\"text-align: right;\">         8897.33</td><td style=\"text-align: right;\">659340</td><td style=\"text-align: right;\">  7.7127</td><td style=\"text-align: right;\">               14.46</td><td style=\"text-align: right;\">                2.63</td><td style=\"text-align: right;\">             97.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 661338\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-14-06\n",
      "  done: false\n",
      "  episode_len_mean: 97.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 7.880500000000017\n",
      "  episode_reward_min: 2.6300000000000114\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 6317\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2520311798368182\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01736684528752612\n",
      "          policy_loss: 0.003613087676820301\n",
      "          total_loss: 0.47367068093624853\n",
      "          vf_explained_var: 0.9368197321891785\n",
      "          vf_loss: 0.47268694206362677\n",
      "    num_agent_steps_sampled: 661338\n",
      "    num_agent_steps_trained: 661338\n",
      "    num_steps_sampled: 661338\n",
      "    num_steps_trained: 661338\n",
      "  iterations_since_restore: 331\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97948717948718\n",
      "    ram_util_percent: 30.925641025641028\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437093589286313\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.740486921049513\n",
      "    mean_inference_ms: 2.476252542010381\n",
      "    mean_raw_obs_processing_ms: 1.9911947872449218\n",
      "  time_since_restore: 8924.488260269165\n",
      "  time_this_iter_s: 27.15439748764038\n",
      "  time_total_s: 8924.488260269165\n",
      "  timers:\n",
      "    learn_throughput: 1159.364\n",
      "    learn_time_ms: 1723.359\n",
      "    load_throughput: 59158.025\n",
      "    load_time_ms: 33.774\n",
      "    sample_throughput: 82.532\n",
      "    sample_time_ms: 24208.819\n",
      "    update_time_ms: 10.287\n",
      "  timestamp: 1636438446\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 661338\n",
      "  training_iteration: 331\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   331</td><td style=\"text-align: right;\">         8924.49</td><td style=\"text-align: right;\">661338</td><td style=\"text-align: right;\">  7.8805</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                2.63</td><td style=\"text-align: right;\">              97.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 663336\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-14-33\n",
      "  done: false\n",
      "  episode_len_mean: 96.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000015\n",
      "  episode_reward_mean: 8.322700000000017\n",
      "  episode_reward_min: 2.6300000000000114\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6338\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2939374512150175\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013703074350247186\n",
      "          policy_loss: -0.020903648586855048\n",
      "          total_loss: 0.17679476927788484\n",
      "          vf_explained_var: 0.9675490856170654\n",
      "          vf_loss: 0.20283346481266476\n",
      "    num_agent_steps_sampled: 663336\n",
      "    num_agent_steps_trained: 663336\n",
      "    num_steps_sampled: 663336\n",
      "    num_steps_trained: 663336\n",
      "  iterations_since_restore: 332\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.31315789473685\n",
      "    ram_util_percent: 30.900000000000002\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435942272042286\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.750168285673453\n",
      "    mean_inference_ms: 2.476160633650526\n",
      "    mean_raw_obs_processing_ms: 1.9874351031546693\n",
      "  time_since_restore: 8951.24833369255\n",
      "  time_this_iter_s: 26.76007342338562\n",
      "  time_total_s: 8951.24833369255\n",
      "  timers:\n",
      "    learn_throughput: 1158.745\n",
      "    learn_time_ms: 1724.279\n",
      "    load_throughput: 59160.531\n",
      "    load_time_ms: 33.773\n",
      "    sample_throughput: 82.132\n",
      "    sample_time_ms: 24326.689\n",
      "    update_time_ms: 10.154\n",
      "  timestamp: 1636438473\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 663336\n",
      "  training_iteration: 332\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   332</td><td style=\"text-align: right;\">         8951.25</td><td style=\"text-align: right;\">663336</td><td style=\"text-align: right;\">  8.3227</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">                2.63</td><td style=\"text-align: right;\">             96.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 665334\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-14-59\n",
      "  done: false\n",
      "  episode_len_mean: 95.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000015\n",
      "  episode_reward_mean: 8.360300000000018\n",
      "  episode_reward_min: 1.0099999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6358\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.5695312499999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3070197990962438\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.020040837735135732\n",
      "          policy_loss: 0.005487218960410073\n",
      "          total_loss: 0.29247251625749326\n",
      "          vf_explained_var: 0.9591438174247742\n",
      "          vf_loss: 0.2886416089499281\n",
      "    num_agent_steps_sampled: 665334\n",
      "    num_agent_steps_trained: 665334\n",
      "    num_steps_sampled: 665334\n",
      "    num_steps_trained: 665334\n",
      "  iterations_since_restore: 333\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0945945945946\n",
      "    ram_util_percent: 30.889189189189192\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443597632850799\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.758026537220232\n",
      "    mean_inference_ms: 2.4761562247249267\n",
      "    mean_raw_obs_processing_ms: 1.9837979287061582\n",
      "  time_since_restore: 8977.247005939484\n",
      "  time_this_iter_s: 25.998672246932983\n",
      "  time_total_s: 8977.247005939484\n",
      "  timers:\n",
      "    learn_throughput: 1156.52\n",
      "    learn_time_ms: 1727.597\n",
      "    load_throughput: 58711.035\n",
      "    load_time_ms: 34.031\n",
      "    sample_throughput: 81.622\n",
      "    sample_time_ms: 24478.657\n",
      "    update_time_ms: 9.509\n",
      "  timestamp: 1636438499\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 665334\n",
      "  training_iteration: 333\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   333</td><td style=\"text-align: right;\">         8977.25</td><td style=\"text-align: right;\">665334</td><td style=\"text-align: right;\">  8.3603</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">                1.01</td><td style=\"text-align: right;\">             95.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 667332\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-15-25\n",
      "  done: false\n",
      "  episode_len_mean: 96.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000015\n",
      "  episode_reward_mean: 8.66310000000002\n",
      "  episode_reward_min: 1.0099999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6378\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2859246674038114\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00832389184816152\n",
      "          policy_loss: 0.03352791920659088\n",
      "          total_loss: 0.2329613973963119\n",
      "          vf_explained_var: 0.9737922549247742\n",
      "          vf_loss: 0.2051816510125285\n",
      "    num_agent_steps_sampled: 667332\n",
      "    num_agent_steps_trained: 667332\n",
      "    num_steps_sampled: 667332\n",
      "    num_steps_trained: 667332\n",
      "  iterations_since_restore: 334\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.98108108108106\n",
      "    ram_util_percent: 30.84594594594595\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436152899807562\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.764723472908127\n",
      "    mean_inference_ms: 2.4761144021067794\n",
      "    mean_raw_obs_processing_ms: 1.9801653316339172\n",
      "  time_since_restore: 9002.820136070251\n",
      "  time_this_iter_s: 25.573130130767822\n",
      "  time_total_s: 9002.820136070251\n",
      "  timers:\n",
      "    learn_throughput: 1158.44\n",
      "    learn_time_ms: 1724.733\n",
      "    load_throughput: 58940.128\n",
      "    load_time_ms: 33.899\n",
      "    sample_throughput: 81.616\n",
      "    sample_time_ms: 24480.361\n",
      "    update_time_ms: 10.187\n",
      "  timestamp: 1636438525\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 667332\n",
      "  training_iteration: 334\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   334</td><td style=\"text-align: right;\">         9002.82</td><td style=\"text-align: right;\">667332</td><td style=\"text-align: right;\">  8.6631</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">                1.01</td><td style=\"text-align: right;\">             96.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 669330\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-16-03\n",
      "  done: false\n",
      "  episode_len_mean: 96.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000015\n",
      "  episode_reward_mean: 8.74550000000002\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6399\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3163059626306806\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008025077558790086\n",
      "          policy_loss: -0.028611994880650724\n",
      "          total_loss: 0.42639863810368944\n",
      "          vf_explained_var: 0.9101011753082275\n",
      "          vf_loss: 0.46131789185816335\n",
      "    num_agent_steps_sampled: 669330\n",
      "    num_agent_steps_trained: 669330\n",
      "    num_steps_sampled: 669330\n",
      "    num_steps_trained: 669330\n",
      "  iterations_since_restore: 335\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.56296296296296\n",
      "    ram_util_percent: 30.796296296296298\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044344356806204015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.77000607476376\n",
      "    mean_inference_ms: 2.475807176288167\n",
      "    mean_raw_obs_processing_ms: 1.9814063621429796\n",
      "  time_since_restore: 9040.849599838257\n",
      "  time_this_iter_s: 38.02946376800537\n",
      "  time_total_s: 9040.849599838257\n",
      "  timers:\n",
      "    learn_throughput: 1157.929\n",
      "    learn_time_ms: 1725.495\n",
      "    load_throughput: 59011.598\n",
      "    load_time_ms: 33.858\n",
      "    sample_throughput: 77.446\n",
      "    sample_time_ms: 25798.742\n",
      "    update_time_ms: 10.038\n",
      "  timestamp: 1636438563\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 669330\n",
      "  training_iteration: 335\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   335</td><td style=\"text-align: right;\">         9040.85</td><td style=\"text-align: right;\">669330</td><td style=\"text-align: right;\">  8.7455</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 671328\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-16-30\n",
      "  done: false\n",
      "  episode_len_mean: 97.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000015\n",
      "  episode_reward_mean: 8.697000000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6420\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.267643279688699\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007584892236445302\n",
      "          policy_loss: -0.054662521183490756\n",
      "          total_loss: 0.1688628750365405\n",
      "          vf_explained_var: 0.9721618890762329\n",
      "          vf_loss: 0.22972208112478257\n",
      "    num_agent_steps_sampled: 671328\n",
      "    num_agent_steps_trained: 671328\n",
      "    num_steps_sampled: 671328\n",
      "    num_steps_trained: 671328\n",
      "  iterations_since_restore: 336\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08684210526314\n",
      "    ram_util_percent: 30.55263157894737\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434971530799478\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.774187488282834\n",
      "    mean_inference_ms: 2.4757423479819836\n",
      "    mean_raw_obs_processing_ms: 1.9824836810641557\n",
      "  time_since_restore: 9067.713001966476\n",
      "  time_this_iter_s: 26.863402128219604\n",
      "  time_total_s: 9067.713001966476\n",
      "  timers:\n",
      "    learn_throughput: 1158.883\n",
      "    learn_time_ms: 1724.074\n",
      "    load_throughput: 58227.751\n",
      "    load_time_ms: 34.314\n",
      "    sample_throughput: 77.285\n",
      "    sample_time_ms: 25852.507\n",
      "    update_time_ms: 10.453\n",
      "  timestamp: 1636438590\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 671328\n",
      "  training_iteration: 336\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   336</td><td style=\"text-align: right;\">         9067.71</td><td style=\"text-align: right;\">671328</td><td style=\"text-align: right;\">   8.697</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 673326\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-17-12\n",
      "  done: false\n",
      "  episode_len_mean: 97.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 8.398500000000018\n",
      "  episode_reward_min: -1.400000000000001\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6441\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4582096213386173\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008916506841736845\n",
      "          policy_loss: -0.038348451522844176\n",
      "          total_loss: 0.4431554554473786\n",
      "          vf_explained_var: 0.9052816033363342\n",
      "          vf_loss: 0.4884686584273974\n",
      "    num_agent_steps_sampled: 673326\n",
      "    num_agent_steps_trained: 673326\n",
      "    num_steps_sampled: 673326\n",
      "    num_steps_trained: 673326\n",
      "  iterations_since_restore: 337\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.7672131147541\n",
      "    ram_util_percent: 30.54098360655738\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437738493539747\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.773826067369146\n",
      "    mean_inference_ms: 2.4759806159244833\n",
      "    mean_raw_obs_processing_ms: 1.9939237411717219\n",
      "  time_since_restore: 9110.122290849686\n",
      "  time_this_iter_s: 42.40928888320923\n",
      "  time_total_s: 9110.122290849686\n",
      "  timers:\n",
      "    learn_throughput: 1159.223\n",
      "    learn_time_ms: 1723.568\n",
      "    load_throughput: 58516.59\n",
      "    load_time_ms: 34.144\n",
      "    sample_throughput: 72.691\n",
      "    sample_time_ms: 27486.327\n",
      "    update_time_ms: 10.251\n",
      "  timestamp: 1636438632\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 673326\n",
      "  training_iteration: 337\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   337</td><td style=\"text-align: right;\">         9110.12</td><td style=\"text-align: right;\">673326</td><td style=\"text-align: right;\">  8.3985</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">             97.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 675324\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-17-39\n",
      "  done: false\n",
      "  episode_len_mean: 96.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 8.225200000000015\n",
      "  episode_reward_min: -1.400000000000001\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6462\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4992447484107245\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009995201436470532\n",
      "          policy_loss: -0.02190162954585893\n",
      "          total_loss: 0.15992314967193774\n",
      "          vf_explained_var: 0.9650133848190308\n",
      "          vf_loss: 0.18827835616788693\n",
      "    num_agent_steps_sampled: 675324\n",
      "    num_agent_steps_trained: 675324\n",
      "    num_steps_sampled: 675324\n",
      "    num_steps_trained: 675324\n",
      "  iterations_since_restore: 338\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.55526315789474\n",
      "    ram_util_percent: 30.61842105263157\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436146744983585\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.77712871862601\n",
      "    mean_inference_ms: 2.475660074370319\n",
      "    mean_raw_obs_processing_ms: 2.0056862093287156\n",
      "  time_since_restore: 9136.560245752335\n",
      "  time_this_iter_s: 26.437954902648926\n",
      "  time_total_s: 9136.560245752335\n",
      "  timers:\n",
      "    learn_throughput: 1159.284\n",
      "    learn_time_ms: 1723.477\n",
      "    load_throughput: 58703.632\n",
      "    load_time_ms: 34.035\n",
      "    sample_throughput: 72.379\n",
      "    sample_time_ms: 27604.835\n",
      "    update_time_ms: 9.86\n",
      "  timestamp: 1636438659\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 675324\n",
      "  training_iteration: 338\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   338</td><td style=\"text-align: right;\">         9136.56</td><td style=\"text-align: right;\">675324</td><td style=\"text-align: right;\">  8.2252</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">             96.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 677322\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-18-05\n",
      "  done: false\n",
      "  episode_len_mean: 95.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.490000000000016\n",
      "  episode_reward_mean: 8.031700000000017\n",
      "  episode_reward_min: -1.400000000000001\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6483\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2876351946876163\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008551069493795652\n",
      "          policy_loss: -0.03761723641128767\n",
      "          total_loss: 0.10026918985836562\n",
      "          vf_explained_var: 0.978560745716095\n",
      "          vf_loss: 0.14345762470648402\n",
      "    num_agent_steps_sampled: 677322\n",
      "    num_agent_steps_trained: 677322\n",
      "    num_steps_sampled: 677322\n",
      "    num_steps_trained: 677322\n",
      "  iterations_since_restore: 339\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94054054054054\n",
      "    ram_util_percent: 30.74324324324325\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436258899201553\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.780295215816427\n",
      "    mean_inference_ms: 2.4755828847282095\n",
      "    mean_raw_obs_processing_ms: 2.0173185431277734\n",
      "  time_since_restore: 9162.946864366531\n",
      "  time_this_iter_s: 26.386618614196777\n",
      "  time_total_s: 9162.946864366531\n",
      "  timers:\n",
      "    learn_throughput: 1159.064\n",
      "    learn_time_ms: 1723.805\n",
      "    load_throughput: 58684.434\n",
      "    load_time_ms: 34.047\n",
      "    sample_throughput: 72.57\n",
      "    sample_time_ms: 27531.918\n",
      "    update_time_ms: 9.813\n",
      "  timestamp: 1636438685\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 677322\n",
      "  training_iteration: 339\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   339</td><td style=\"text-align: right;\">         9162.95</td><td style=\"text-align: right;\">677322</td><td style=\"text-align: right;\">  8.0317</td><td style=\"text-align: right;\">               14.49</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">             95.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 679320\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-18-30\n",
      "  done: false\n",
      "  episode_len_mean: 96.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.490000000000016\n",
      "  episode_reward_mean: 7.819400000000017\n",
      "  episode_reward_min: -1.400000000000001\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6503\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4567826662744794\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009651758796773552\n",
      "          policy_loss: -0.006705844473271143\n",
      "          total_loss: 0.14574650143761012\n",
      "          vf_explained_var: 0.9760978817939758\n",
      "          vf_loss: 0.15877470155911785\n",
      "    num_agent_steps_sampled: 679320\n",
      "    num_agent_steps_trained: 679320\n",
      "    num_steps_sampled: 679320\n",
      "    num_steps_trained: 679320\n",
      "  iterations_since_restore: 340\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.05277777777778\n",
      "    ram_util_percent: 30.922222222222224\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044365532324531165\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.78425464426999\n",
      "    mean_inference_ms: 2.4755565017939163\n",
      "    mean_raw_obs_processing_ms: 2.02345465760861\n",
      "  time_since_restore: 9187.719095468521\n",
      "  time_this_iter_s: 24.772231101989746\n",
      "  time_total_s: 9187.719095468521\n",
      "  timers:\n",
      "    learn_throughput: 1157.5\n",
      "    learn_time_ms: 1726.134\n",
      "    load_throughput: 58846.136\n",
      "    load_time_ms: 33.953\n",
      "    sample_throughput: 73.293\n",
      "    sample_time_ms: 27260.505\n",
      "    update_time_ms: 8.972\n",
      "  timestamp: 1636438710\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 679320\n",
      "  training_iteration: 340\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   340</td><td style=\"text-align: right;\">         9187.72</td><td style=\"text-align: right;\">679320</td><td style=\"text-align: right;\">  7.8194</td><td style=\"text-align: right;\">               14.49</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">             96.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 681318\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-18-54\n",
      "  done: false\n",
      "  episode_len_mean: 97.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.490000000000016\n",
      "  episode_reward_mean: 7.8043000000000164\n",
      "  episode_reward_min: -1.400000000000001\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 6522\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.329045041402181\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00938554731904157\n",
      "          policy_loss: -0.011068250274374372\n",
      "          total_loss: 0.23782867406982752\n",
      "          vf_explained_var: 0.960331916809082\n",
      "          vf_loss: 0.2541693310297671\n",
      "    num_agent_steps_sampled: 681318\n",
      "    num_agent_steps_trained: 681318\n",
      "    num_steps_sampled: 681318\n",
      "    num_steps_trained: 681318\n",
      "  iterations_since_restore: 341\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.31142857142856\n",
      "    ram_util_percent: 31.011428571428574\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438237025441012\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.785280597776108\n",
      "    mean_inference_ms: 2.4757631052822444\n",
      "    mean_raw_obs_processing_ms: 2.027376511427613\n",
      "  time_since_restore: 9212.291705608368\n",
      "  time_this_iter_s: 24.5726101398468\n",
      "  time_total_s: 9212.291705608368\n",
      "  timers:\n",
      "    learn_throughput: 1157.722\n",
      "    learn_time_ms: 1725.802\n",
      "    load_throughput: 58817.349\n",
      "    load_time_ms: 33.97\n",
      "    sample_throughput: 73.993\n",
      "    sample_time_ms: 27002.666\n",
      "    update_time_ms: 8.588\n",
      "  timestamp: 1636438734\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 681318\n",
      "  training_iteration: 341\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   341</td><td style=\"text-align: right;\">         9212.29</td><td style=\"text-align: right;\">681318</td><td style=\"text-align: right;\">  7.8043</td><td style=\"text-align: right;\">               14.49</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">             97.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 683316\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-19-19\n",
      "  done: false\n",
      "  episode_len_mean: 98.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.570000000000016\n",
      "  episode_reward_mean: 8.110500000000018\n",
      "  episode_reward_min: 2.1500000000000155\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 6541\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3142667134602866\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009233032199972869\n",
      "          policy_loss: -0.09156874189419406\n",
      "          total_loss: 0.07713589748101575\n",
      "          vf_explained_var: 0.9787451028823853\n",
      "          vf_loss: 0.1739595557962145\n",
      "    num_agent_steps_sampled: 683316\n",
      "    num_agent_steps_trained: 683316\n",
      "    num_steps_sampled: 683316\n",
      "    num_steps_trained: 683316\n",
      "  iterations_since_restore: 342\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.23055555555555\n",
      "    ram_util_percent: 31.09444444444445\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439367887143094\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.788872280807336\n",
      "    mean_inference_ms: 2.4758962977964383\n",
      "    mean_raw_obs_processing_ms: 2.023628766887688\n",
      "  time_since_restore: 9237.341723442078\n",
      "  time_this_iter_s: 25.050017833709717\n",
      "  time_total_s: 9237.341723442078\n",
      "  timers:\n",
      "    learn_throughput: 1158.382\n",
      "    learn_time_ms: 1724.82\n",
      "    load_throughput: 58803.853\n",
      "    load_time_ms: 33.977\n",
      "    sample_throughput: 74.464\n",
      "    sample_time_ms: 26831.871\n",
      "    update_time_ms: 9.299\n",
      "  timestamp: 1636438759\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 683316\n",
      "  training_iteration: 342\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   342</td><td style=\"text-align: right;\">         9237.34</td><td style=\"text-align: right;\">683316</td><td style=\"text-align: right;\">  8.1105</td><td style=\"text-align: right;\">               14.57</td><td style=\"text-align: right;\">                2.15</td><td style=\"text-align: right;\">                98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 685314\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-19-45\n",
      "  done: false\n",
      "  episode_len_mean: 98.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.570000000000016\n",
      "  episode_reward_mean: 8.330300000000019\n",
      "  episode_reward_min: 2.1500000000000155\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 6563\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.354618962038131\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008178868044154868\n",
      "          policy_loss: 0.0027668381198531107\n",
      "          total_loss: 0.15038413265276523\n",
      "          vf_explained_var: 0.9754685759544373\n",
      "          vf_loss: 0.15417630253803163\n",
      "    num_agent_steps_sampled: 685314\n",
      "    num_agent_steps_trained: 685314\n",
      "    num_steps_sampled: 685314\n",
      "    num_steps_trained: 685314\n",
      "  iterations_since_restore: 343\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8722222222222\n",
      "    ram_util_percent: 31.08333333333334\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439436288862387\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.79060167602467\n",
      "    mean_inference_ms: 2.475900529193124\n",
      "    mean_raw_obs_processing_ms: 2.0194472461874655\n",
      "  time_since_restore: 9263.016947746277\n",
      "  time_this_iter_s: 25.67522430419922\n",
      "  time_total_s: 9263.016947746277\n",
      "  timers:\n",
      "    learn_throughput: 1161.4\n",
      "    learn_time_ms: 1720.338\n",
      "    load_throughput: 59232.035\n",
      "    load_time_ms: 33.732\n",
      "    sample_throughput: 74.54\n",
      "    sample_time_ms: 26804.288\n",
      "    update_time_ms: 9.174\n",
      "  timestamp: 1636438785\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 685314\n",
      "  training_iteration: 343\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   343</td><td style=\"text-align: right;\">         9263.02</td><td style=\"text-align: right;\">685314</td><td style=\"text-align: right;\">  8.3303</td><td style=\"text-align: right;\">               14.57</td><td style=\"text-align: right;\">                2.15</td><td style=\"text-align: right;\">             98.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 687312\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-20-11\n",
      "  done: false\n",
      "  episode_len_mean: 99.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.570000000000016\n",
      "  episode_reward_mean: 8.169500000000017\n",
      "  episode_reward_min: 2.1500000000000155\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6583\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3509451650437854\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008142356727243658\n",
      "          policy_loss: -0.03412926202373845\n",
      "          total_loss: 0.11646484450570174\n",
      "          vf_explained_var: 0.9765812754631042\n",
      "          vf_loss: 0.15714756842880023\n",
      "    num_agent_steps_sampled: 687312\n",
      "    num_agent_steps_trained: 687312\n",
      "    num_steps_sampled: 687312\n",
      "    num_steps_trained: 687312\n",
      "  iterations_since_restore: 344\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88378378378378\n",
      "    ram_util_percent: 31.137837837837843\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439416105332917\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.791832888679846\n",
      "    mean_inference_ms: 2.47593942206963\n",
      "    mean_raw_obs_processing_ms: 2.0156207420665937\n",
      "  time_since_restore: 9288.335778474808\n",
      "  time_this_iter_s: 25.318830728530884\n",
      "  time_total_s: 9288.335778474808\n",
      "  timers:\n",
      "    learn_throughput: 1161.589\n",
      "    learn_time_ms: 1720.058\n",
      "    load_throughput: 59109.33\n",
      "    load_time_ms: 33.802\n",
      "    sample_throughput: 74.612\n",
      "    sample_time_ms: 26778.388\n",
      "    update_time_ms: 9.41\n",
      "  timestamp: 1636438811\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 687312\n",
      "  training_iteration: 344\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   344</td><td style=\"text-align: right;\">         9288.34</td><td style=\"text-align: right;\">687312</td><td style=\"text-align: right;\">  8.1695</td><td style=\"text-align: right;\">               14.57</td><td style=\"text-align: right;\">                2.15</td><td style=\"text-align: right;\">             99.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 689310\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-20-35\n",
      "  done: false\n",
      "  episode_len_mean: 101.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.570000000000016\n",
      "  episode_reward_mean: 8.671000000000015\n",
      "  episode_reward_min: 2.1500000000000155\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 6602\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2994666207404364\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011465647870236462\n",
      "          policy_loss: -0.05158957028761506\n",
      "          total_loss: 0.07864000403455325\n",
      "          vf_explained_var: 0.9851568937301636\n",
      "          vf_loss: 0.13342917466624862\n",
      "    num_agent_steps_sampled: 689310\n",
      "    num_agent_steps_trained: 689310\n",
      "    num_steps_sampled: 689310\n",
      "    num_steps_trained: 689310\n",
      "  iterations_since_restore: 345\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96470588235293\n",
      "    ram_util_percent: 31.108823529411765\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439306218118018\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.79196479056675\n",
      "    mean_inference_ms: 2.475951133753144\n",
      "    mean_raw_obs_processing_ms: 2.0119551457022506\n",
      "  time_since_restore: 9312.546773672104\n",
      "  time_this_iter_s: 24.210995197296143\n",
      "  time_total_s: 9312.546773672104\n",
      "  timers:\n",
      "    learn_throughput: 1161.209\n",
      "    learn_time_ms: 1720.62\n",
      "    load_throughput: 58767.276\n",
      "    load_time_ms: 33.999\n",
      "    sample_throughput: 78.675\n",
      "    sample_time_ms: 25395.631\n",
      "    update_time_ms: 9.519\n",
      "  timestamp: 1636438835\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 689310\n",
      "  training_iteration: 345\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   345</td><td style=\"text-align: right;\">         9312.55</td><td style=\"text-align: right;\">689310</td><td style=\"text-align: right;\">   8.671</td><td style=\"text-align: right;\">               14.57</td><td style=\"text-align: right;\">                2.15</td><td style=\"text-align: right;\">            101.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 691308\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-20-59\n",
      "  done: false\n",
      "  episode_len_mean: 101.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.570000000000016\n",
      "  episode_reward_mean: 8.453900000000019\n",
      "  episode_reward_min: 2.500000000000015\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 6620\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4190960543496267\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006798547805403946\n",
      "          policy_loss: -0.04554038853162811\n",
      "          total_loss: 0.052021701806890114\n",
      "          vf_explained_var: 0.9827831387519836\n",
      "          vf_loss: 0.1059450728552682\n",
      "    num_agent_steps_sampled: 691308\n",
      "    num_agent_steps_trained: 691308\n",
      "    num_steps_sampled: 691308\n",
      "    num_steps_trained: 691308\n",
      "  iterations_since_restore: 346\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.38529411764705\n",
      "    ram_util_percent: 31.114705882352943\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044383913961429516\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.793591311820155\n",
      "    mean_inference_ms: 2.475874417090344\n",
      "    mean_raw_obs_processing_ms: 2.008484459533919\n",
      "  time_since_restore: 9336.558116912842\n",
      "  time_this_iter_s: 24.011343240737915\n",
      "  time_total_s: 9336.558116912842\n",
      "  timers:\n",
      "    learn_throughput: 1160.535\n",
      "    learn_time_ms: 1721.62\n",
      "    load_throughput: 59586.824\n",
      "    load_time_ms: 33.531\n",
      "    sample_throughput: 79.569\n",
      "    sample_time_ms: 25110.439\n",
      "    update_time_ms: 8.95\n",
      "  timestamp: 1636438859\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 691308\n",
      "  training_iteration: 346\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   346</td><td style=\"text-align: right;\">         9336.56</td><td style=\"text-align: right;\">691308</td><td style=\"text-align: right;\">  8.4539</td><td style=\"text-align: right;\">               14.57</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">            101.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 693306\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-21-24\n",
      "  done: false\n",
      "  episode_len_mean: 101.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 8.266900000000017\n",
      "  episode_reward_min: 2.500000000000015\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6641\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4049781078384036\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009915467807996134\n",
      "          policy_loss: -0.04787975576307092\n",
      "          total_loss: 0.03697026124046672\n",
      "          vf_explained_var: 0.9799949526786804\n",
      "          vf_loss: 0.09042904631545147\n",
      "    num_agent_steps_sampled: 693306\n",
      "    num_agent_steps_trained: 693306\n",
      "    num_steps_sampled: 693306\n",
      "    num_steps_trained: 693306\n",
      "  iterations_since_restore: 347\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.27027027027027\n",
      "    ram_util_percent: 31.097297297297295\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443860905200832\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.79214196944102\n",
      "    mean_inference_ms: 2.475942164442088\n",
      "    mean_raw_obs_processing_ms: 2.0043858739870073\n",
      "  time_since_restore: 9361.80112195015\n",
      "  time_this_iter_s: 25.24300503730774\n",
      "  time_total_s: 9361.80112195015\n",
      "  timers:\n",
      "    learn_throughput: 1161.247\n",
      "    learn_time_ms: 1720.564\n",
      "    load_throughput: 59448.389\n",
      "    load_time_ms: 33.609\n",
      "    sample_throughput: 85.402\n",
      "    sample_time_ms: 23395.29\n",
      "    update_time_ms: 8.401\n",
      "  timestamp: 1636438884\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 693306\n",
      "  training_iteration: 347\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   347</td><td style=\"text-align: right;\">          9361.8</td><td style=\"text-align: right;\">693306</td><td style=\"text-align: right;\">  8.2669</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">            101.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 695304\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-21-50\n",
      "  done: false\n",
      "  episode_len_mean: 101.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 8.556700000000017\n",
      "  episode_reward_min: 2.870000000000022\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6661\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3062041467144376\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009532601016797903\n",
      "          policy_loss: -0.026228107201556366\n",
      "          total_loss: 0.26253174540719815\n",
      "          vf_explained_var: 0.9521899819374084\n",
      "          vf_loss: 0.2936782259848856\n",
      "    num_agent_steps_sampled: 695304\n",
      "    num_agent_steps_trained: 695304\n",
      "    num_steps_sampled: 695304\n",
      "    num_steps_trained: 695304\n",
      "  iterations_since_restore: 348\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1722222222222\n",
      "    ram_util_percent: 31.083333333333332\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436184495651814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.794715733875464\n",
      "    mean_inference_ms: 2.475625586354825\n",
      "    mean_raw_obs_processing_ms: 2.000671489546016\n",
      "  time_since_restore: 9387.683686256409\n",
      "  time_this_iter_s: 25.882564306259155\n",
      "  time_total_s: 9387.683686256409\n",
      "  timers:\n",
      "    learn_throughput: 1161.842\n",
      "    learn_time_ms: 1719.684\n",
      "    load_throughput: 58924.214\n",
      "    load_time_ms: 33.908\n",
      "    sample_throughput: 85.601\n",
      "    sample_time_ms: 23340.721\n",
      "    update_time_ms: 7.998\n",
      "  timestamp: 1636438910\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 695304\n",
      "  training_iteration: 348\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   348</td><td style=\"text-align: right;\">         9387.68</td><td style=\"text-align: right;\">695304</td><td style=\"text-align: right;\">  8.5567</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                2.87</td><td style=\"text-align: right;\">            101.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 697302\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-22-15\n",
      "  done: false\n",
      "  episode_len_mean: 102.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 8.534900000000016\n",
      "  episode_reward_min: 2.870000000000022\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 6679\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4574476117179507\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010030906100699882\n",
      "          policy_loss: -0.05369256685177485\n",
      "          total_loss: 0.1406198683638303\n",
      "          vf_explained_var: 0.9678728580474854\n",
      "          vf_loss: 0.20031754042775857\n",
      "    num_agent_steps_sampled: 697302\n",
      "    num_agent_steps_trained: 697302\n",
      "    num_steps_sampled: 697302\n",
      "    num_steps_trained: 697302\n",
      "  iterations_since_restore: 349\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.875\n",
      "    ram_util_percent: 31.033333333333328\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044355880681634485\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.79595520359568\n",
      "    mean_inference_ms: 2.475526476703278\n",
      "    mean_raw_obs_processing_ms: 1.9972089495615057\n",
      "  time_since_restore: 9412.43535208702\n",
      "  time_this_iter_s: 24.751665830612183\n",
      "  time_total_s: 9412.43535208702\n",
      "  timers:\n",
      "    learn_throughput: 1161.662\n",
      "    learn_time_ms: 1719.949\n",
      "    load_throughput: 58995.189\n",
      "    load_time_ms: 33.867\n",
      "    sample_throughput: 86.205\n",
      "    sample_time_ms: 23177.371\n",
      "    update_time_ms: 7.604\n",
      "  timestamp: 1636438935\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 697302\n",
      "  training_iteration: 349\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   349</td><td style=\"text-align: right;\">         9412.44</td><td style=\"text-align: right;\">697302</td><td style=\"text-align: right;\">  8.5349</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                2.87</td><td style=\"text-align: right;\">            102.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 699300\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-22-40\n",
      "  done: false\n",
      "  episode_len_mean: 102.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 8.074800000000018\n",
      "  episode_reward_min: 2.460000000000018\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6700\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.32734597495624\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013927905287505772\n",
      "          policy_loss: -0.019712889411797125\n",
      "          total_loss: 0.1565983062476984\n",
      "          vf_explained_var: 0.9604735374450684\n",
      "          vf_loss: 0.1776860883725541\n",
      "    num_agent_steps_sampled: 699300\n",
      "    num_agent_steps_trained: 699300\n",
      "    num_steps_sampled: 699300\n",
      "    num_steps_trained: 699300\n",
      "  iterations_since_restore: 350\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.10857142857145\n",
      "    ram_util_percent: 30.98285714285714\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044374828113516805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.795281548634648\n",
      "    mean_inference_ms: 2.4757344976283755\n",
      "    mean_raw_obs_processing_ms: 1.9930544520975277\n",
      "  time_since_restore: 9437.292286634445\n",
      "  time_this_iter_s: 24.856934547424316\n",
      "  time_total_s: 9437.292286634445\n",
      "  timers:\n",
      "    learn_throughput: 1159.091\n",
      "    learn_time_ms: 1723.765\n",
      "    load_throughput: 58617.198\n",
      "    load_time_ms: 34.086\n",
      "    sample_throughput: 86.193\n",
      "    sample_time_ms: 23180.646\n",
      "    update_time_ms: 8.684\n",
      "  timestamp: 1636438960\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 699300\n",
      "  training_iteration: 350\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   350</td><td style=\"text-align: right;\">         9437.29</td><td style=\"text-align: right;\">699300</td><td style=\"text-align: right;\">  8.0748</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            102.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 701298\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-23-06\n",
      "  done: false\n",
      "  episode_len_mean: 100.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 8.055200000000017\n",
      "  episode_reward_min: 2.460000000000018\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 6719\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.337004580384209\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010735919646094992\n",
      "          policy_loss: -0.04699248554451125\n",
      "          total_loss: 0.2308222077432133\n",
      "          vf_explained_var: 0.9638420939445496\n",
      "          vf_loss: 0.28201307594066577\n",
      "    num_agent_steps_sampled: 701298\n",
      "    num_agent_steps_trained: 701298\n",
      "    num_steps_sampled: 701298\n",
      "    num_steps_trained: 701298\n",
      "  iterations_since_restore: 351\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.39999999999999\n",
      "    ram_util_percent: 31.017948717948702\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439310421548358\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.79594177268788\n",
      "    mean_inference_ms: 2.4759425995243607\n",
      "    mean_raw_obs_processing_ms: 1.9893872884357133\n",
      "  time_since_restore: 9464.052873373032\n",
      "  time_this_iter_s: 26.760586738586426\n",
      "  time_total_s: 9464.052873373032\n",
      "  timers:\n",
      "    learn_throughput: 1158.354\n",
      "    learn_time_ms: 1724.861\n",
      "    load_throughput: 58489.471\n",
      "    load_time_ms: 34.16\n",
      "    sample_throughput: 85.39\n",
      "    sample_time_ms: 23398.546\n",
      "    update_time_ms: 8.445\n",
      "  timestamp: 1636438986\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 701298\n",
      "  training_iteration: 351\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   351</td><td style=\"text-align: right;\">         9464.05</td><td style=\"text-align: right;\">701298</td><td style=\"text-align: right;\">  8.0552</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            100.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 703296\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-23-32\n",
      "  done: false\n",
      "  episode_len_mean: 101.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 8.269300000000017\n",
      "  episode_reward_min: 2.460000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6739\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.346977965037028\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010482162533732839\n",
      "          policy_loss: -0.03136878064168351\n",
      "          total_loss: 0.17050512651247637\n",
      "          vf_explained_var: 0.9763215780258179\n",
      "          vf_loss: 0.2063888054163683\n",
      "    num_agent_steps_sampled: 703296\n",
      "    num_agent_steps_trained: 703296\n",
      "    num_steps_sampled: 703296\n",
      "    num_steps_trained: 703296\n",
      "  iterations_since_restore: 352\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.075\n",
      "    ram_util_percent: 30.99166666666666\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044389340008895904\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.798839133719444\n",
      "    mean_inference_ms: 2.4758379321000104\n",
      "    mean_raw_obs_processing_ms: 1.9857012988855478\n",
      "  time_since_restore: 9489.223828077316\n",
      "  time_this_iter_s: 25.170954704284668\n",
      "  time_total_s: 9489.223828077316\n",
      "  timers:\n",
      "    learn_throughput: 1158.829\n",
      "    learn_time_ms: 1724.154\n",
      "    load_throughput: 58306.507\n",
      "    load_time_ms: 34.267\n",
      "    sample_throughput: 85.343\n",
      "    sample_time_ms: 23411.276\n",
      "    update_time_ms: 8.064\n",
      "  timestamp: 1636439012\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 703296\n",
      "  training_iteration: 352\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   352</td><td style=\"text-align: right;\">         9489.22</td><td style=\"text-align: right;\">703296</td><td style=\"text-align: right;\">  8.2693</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            101.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 705294\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-24-15\n",
      "  done: false\n",
      "  episode_len_mean: 99.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 8.156000000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6760\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2697730694498335\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009346902147312002\n",
      "          policy_loss: -0.0017446626864728474\n",
      "          total_loss: 0.24181658284117777\n",
      "          vf_explained_var: 0.9631671905517578\n",
      "          vf_loss: 0.24827394473056\n",
      "    num_agent_steps_sampled: 705294\n",
      "    num_agent_steps_trained: 705294\n",
      "    num_steps_sampled: 705294\n",
      "    num_steps_trained: 705294\n",
      "  iterations_since_restore: 353\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.36774193548386\n",
      "    ram_util_percent: 30.91129032258064\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044390038643775005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.80124398823899\n",
      "    mean_inference_ms: 2.4758314963857555\n",
      "    mean_raw_obs_processing_ms: 1.9873930773578978\n",
      "  time_since_restore: 9532.773388147354\n",
      "  time_this_iter_s: 43.54956007003784\n",
      "  time_total_s: 9532.773388147354\n",
      "  timers:\n",
      "    learn_throughput: 1157.945\n",
      "    learn_time_ms: 1725.471\n",
      "    load_throughput: 58411.645\n",
      "    load_time_ms: 34.206\n",
      "    sample_throughput: 79.293\n",
      "    sample_time_ms: 25197.535\n",
      "    update_time_ms: 7.787\n",
      "  timestamp: 1636439055\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 705294\n",
      "  training_iteration: 353\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   353</td><td style=\"text-align: right;\">         9532.77</td><td style=\"text-align: right;\">705294</td><td style=\"text-align: right;\">   8.156</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">              99.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 707292\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-24-58\n",
      "  done: false\n",
      "  episode_len_mean: 98.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.440000000000015\n",
      "  episode_reward_mean: 8.250100000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6781\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3371250163941157\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01784258970269047\n",
      "          policy_loss: -0.03203862416779711\n",
      "          total_loss: 0.21281654173951772\n",
      "          vf_explained_var: 0.9655543565750122\n",
      "          vf_loss: 0.24298355091540585\n",
      "    num_agent_steps_sampled: 707292\n",
      "    num_agent_steps_trained: 707292\n",
      "    num_steps_sampled: 707292\n",
      "    num_steps_trained: 707292\n",
      "  iterations_since_restore: 354\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.39500000000001\n",
      "    ram_util_percent: 30.988333333333333\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044380324210071063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.8038145250908\n",
      "    mean_inference_ms: 2.475632368140627\n",
      "    mean_raw_obs_processing_ms: 1.9936431629185756\n",
      "  time_since_restore: 9575.322590351105\n",
      "  time_this_iter_s: 42.54920220375061\n",
      "  time_total_s: 9575.322590351105\n",
      "  timers:\n",
      "    learn_throughput: 1158.003\n",
      "    learn_time_ms: 1725.384\n",
      "    load_throughput: 58362.91\n",
      "    load_time_ms: 34.234\n",
      "    sample_throughput: 74.214\n",
      "    sample_time_ms: 26922.008\n",
      "    update_time_ms: 6.913\n",
      "  timestamp: 1636439098\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 707292\n",
      "  training_iteration: 354\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   354</td><td style=\"text-align: right;\">         9575.32</td><td style=\"text-align: right;\">707292</td><td style=\"text-align: right;\">  8.2501</td><td style=\"text-align: right;\">               14.44</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             98.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 709290\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-25-39\n",
      "  done: false\n",
      "  episode_len_mean: 97.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.440000000000015\n",
      "  episode_reward_mean: 8.341400000000016\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6802\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3619236162730626\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008310188970941147\n",
      "          policy_loss: -0.005224102673431237\n",
      "          total_loss: 0.18890051015076184\n",
      "          vf_explained_var: 0.9629426002502441\n",
      "          vf_loss: 0.20064447798899243\n",
      "    num_agent_steps_sampled: 709290\n",
      "    num_agent_steps_trained: 709290\n",
      "    num_steps_sampled: 709290\n",
      "    num_steps_trained: 709290\n",
      "  iterations_since_restore: 355\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.78103448275863\n",
      "    ram_util_percent: 30.782758620689652\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436975194854804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.8065905237475\n",
      "    mean_inference_ms: 2.475408691026869\n",
      "    mean_raw_obs_processing_ms: 2.0045723446699024\n",
      "  time_since_restore: 9615.999799251556\n",
      "  time_this_iter_s: 40.67720890045166\n",
      "  time_total_s: 9615.999799251556\n",
      "  timers:\n",
      "    learn_throughput: 1157.689\n",
      "    learn_time_ms: 1725.852\n",
      "    load_throughput: 58525.295\n",
      "    load_time_ms: 34.139\n",
      "    sample_throughput: 69.94\n",
      "    sample_time_ms: 28567.426\n",
      "    update_time_ms: 7.855\n",
      "  timestamp: 1636439139\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 709290\n",
      "  training_iteration: 355\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   355</td><td style=\"text-align: right;\">            9616</td><td style=\"text-align: right;\">709290</td><td style=\"text-align: right;\">  8.3414</td><td style=\"text-align: right;\">               14.44</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">              97.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 711288\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-26-04\n",
      "  done: false\n",
      "  episode_len_mean: 97.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.440000000000015\n",
      "  episode_reward_mean: 8.316600000000017\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6822\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3677930034342267\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009286569215419394\n",
      "          policy_loss: -0.028524173476866314\n",
      "          total_loss: 0.12277876654905932\n",
      "          vf_explained_var: 0.9665505290031433\n",
      "          vf_loss: 0.15704738458707218\n",
      "    num_agent_steps_sampled: 711288\n",
      "    num_agent_steps_trained: 711288\n",
      "    num_steps_sampled: 711288\n",
      "    num_steps_trained: 711288\n",
      "  iterations_since_restore: 356\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.17837837837837\n",
      "    ram_util_percent: 30.797297297297302\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435183502539825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.811349574305083\n",
      "    mean_inference_ms: 2.47512819988433\n",
      "    mean_raw_obs_processing_ms: 2.0151317569843075\n",
      "  time_since_restore: 9641.398814439774\n",
      "  time_this_iter_s: 25.399015188217163\n",
      "  time_total_s: 9641.398814439774\n",
      "  timers:\n",
      "    learn_throughput: 1158.509\n",
      "    learn_time_ms: 1724.631\n",
      "    load_throughput: 58477.676\n",
      "    load_time_ms: 34.167\n",
      "    sample_throughput: 69.599\n",
      "    sample_time_ms: 28707.348\n",
      "    update_time_ms: 7.971\n",
      "  timestamp: 1636439164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 711288\n",
      "  training_iteration: 356\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   356</td><td style=\"text-align: right;\">          9641.4</td><td style=\"text-align: right;\">711288</td><td style=\"text-align: right;\">  8.3166</td><td style=\"text-align: right;\">               14.44</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             97.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 713286\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-26-30\n",
      "  done: false\n",
      "  episode_len_mean: 96.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.066200000000016\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6842\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2359523426918757\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007878049486402463\n",
      "          policy_loss: -0.00923981439499628\n",
      "          total_loss: 0.1809174850228287\n",
      "          vf_explained_var: 0.9630292057991028\n",
      "          vf_loss: 0.1957866301848775\n",
      "    num_agent_steps_sampled: 713286\n",
      "    num_agent_steps_trained: 713286\n",
      "    num_steps_sampled: 713286\n",
      "    num_steps_trained: 713286\n",
      "  iterations_since_restore: 357\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.35675675675675\n",
      "    ram_util_percent: 30.889189189189185\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435664496391476\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.81342356631808\n",
      "    mean_inference_ms: 2.4751437405315797\n",
      "    mean_raw_obs_processing_ms: 2.025522353974668\n",
      "  time_since_restore: 9667.221780061722\n",
      "  time_this_iter_s: 25.822965621948242\n",
      "  time_total_s: 9667.221780061722\n",
      "  timers:\n",
      "    learn_throughput: 1158.188\n",
      "    learn_time_ms: 1725.109\n",
      "    load_throughput: 58514.343\n",
      "    load_time_ms: 34.145\n",
      "    sample_throughput: 69.462\n",
      "    sample_time_ms: 28763.973\n",
      "    update_time_ms: 8.943\n",
      "  timestamp: 1636439190\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 713286\n",
      "  training_iteration: 357\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   357</td><td style=\"text-align: right;\">         9667.22</td><td style=\"text-align: right;\">713286</td><td style=\"text-align: right;\">  8.0662</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             96.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 715284\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-26-56\n",
      "  done: false\n",
      "  episode_len_mean: 98.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.090100000000017\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6862\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3860928938502357\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011287990489453158\n",
      "          policy_loss: -0.03670581402700572\n",
      "          total_loss: 0.14409142802691177\n",
      "          vf_explained_var: 0.9641470909118652\n",
      "          vf_loss: 0.18501487372531777\n",
      "    num_agent_steps_sampled: 715284\n",
      "    num_agent_steps_trained: 715284\n",
      "    num_steps_sampled: 715284\n",
      "    num_steps_trained: 715284\n",
      "  iterations_since_restore: 358\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.24722222222222\n",
      "    ram_util_percent: 31.016666666666676\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437772062437956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.81375792379986\n",
      "    mean_inference_ms: 2.4753727574198887\n",
      "    mean_raw_obs_processing_ms: 2.0287427839165355\n",
      "  time_since_restore: 9692.881446838379\n",
      "  time_this_iter_s: 25.659666776657104\n",
      "  time_total_s: 9692.881446838379\n",
      "  timers:\n",
      "    learn_throughput: 1146.914\n",
      "    learn_time_ms: 1742.066\n",
      "    load_throughput: 57697.406\n",
      "    load_time_ms: 34.629\n",
      "    sample_throughput: 69.558\n",
      "    sample_time_ms: 28724.071\n",
      "    update_time_ms: 8.918\n",
      "  timestamp: 1636439216\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 715284\n",
      "  training_iteration: 358\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   358</td><td style=\"text-align: right;\">         9692.88</td><td style=\"text-align: right;\">715284</td><td style=\"text-align: right;\">  8.0901</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             98.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 717282\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-27-21\n",
      "  done: false\n",
      "  episode_len_mean: 99.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.278200000000018\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6882\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.328961078609739\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011027151366115937\n",
      "          policy_loss: -0.05499471787895475\n",
      "          total_loss: 0.17742119946827492\n",
      "          vf_explained_var: 0.9680435061454773\n",
      "          vf_loss: 0.23628506447587694\n",
      "    num_agent_steps_sampled: 717282\n",
      "    num_agent_steps_trained: 717282\n",
      "    num_steps_sampled: 717282\n",
      "    num_steps_trained: 717282\n",
      "  iterations_since_restore: 359\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88648648648649\n",
      "    ram_util_percent: 31.237837837837837\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437427292686435\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.815864957043477\n",
      "    mean_inference_ms: 2.4753506099452482\n",
      "    mean_raw_obs_processing_ms: 2.0298262330075043\n",
      "  time_since_restore: 9718.541988372803\n",
      "  time_this_iter_s: 25.660541534423828\n",
      "  time_total_s: 9718.541988372803\n",
      "  timers:\n",
      "    learn_throughput: 1145.838\n",
      "    learn_time_ms: 1743.703\n",
      "    load_throughput: 57963.029\n",
      "    load_time_ms: 34.47\n",
      "    sample_throughput: 69.343\n",
      "    sample_time_ms: 28813.112\n",
      "    update_time_ms: 9.539\n",
      "  timestamp: 1636439241\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 717282\n",
      "  training_iteration: 359\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   359</td><td style=\"text-align: right;\">         9718.54</td><td style=\"text-align: right;\">717282</td><td style=\"text-align: right;\">  8.2782</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             99.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 719280\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-27-47\n",
      "  done: false\n",
      "  episode_len_mean: 100.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.32690000000002\n",
      "  episode_reward_min: 3.180000000000012\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6903\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.291761006627764\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008530267990291968\n",
      "          policy_loss: -0.03657809683964366\n",
      "          total_loss: 0.12853096462786198\n",
      "          vf_explained_var: 0.9688601493835449\n",
      "          vf_loss: 0.17073928830879076\n",
      "    num_agent_steps_sampled: 719280\n",
      "    num_agent_steps_trained: 719280\n",
      "    num_steps_sampled: 719280\n",
      "    num_steps_trained: 719280\n",
      "  iterations_since_restore: 360\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.82162162162163\n",
      "    ram_util_percent: 31.01351351351351\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438146883661553\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.819596817987232\n",
      "    mean_inference_ms: 2.475529221504406\n",
      "    mean_raw_obs_processing_ms: 2.026068616772876\n",
      "  time_since_restore: 9744.747784137726\n",
      "  time_this_iter_s: 26.205795764923096\n",
      "  time_total_s: 9744.747784137726\n",
      "  timers:\n",
      "    learn_throughput: 1149.314\n",
      "    learn_time_ms: 1738.428\n",
      "    load_throughput: 58129.039\n",
      "    load_time_ms: 34.372\n",
      "    sample_throughput: 69.005\n",
      "    sample_time_ms: 28954.377\n",
      "    update_time_ms: 8.839\n",
      "  timestamp: 1636439267\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 719280\n",
      "  training_iteration: 360\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   360</td><td style=\"text-align: right;\">         9744.75</td><td style=\"text-align: right;\">719280</td><td style=\"text-align: right;\">  8.3269</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                3.18</td><td style=\"text-align: right;\">            100.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 721278\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-28-13\n",
      "  done: false\n",
      "  episode_len_mean: 99.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.152400000000018\n",
      "  episode_reward_min: 2.9300000000000126\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6923\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2901059462910607\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01479557778523747\n",
      "          policy_loss: -0.08897989401150318\n",
      "          total_loss: 0.17826444576716138\n",
      "          vf_explained_var: 0.948409914970398\n",
      "          vf_loss: 0.2675055825994128\n",
      "    num_agent_steps_sampled: 721278\n",
      "    num_agent_steps_trained: 721278\n",
      "    num_steps_sampled: 721278\n",
      "    num_steps_trained: 721278\n",
      "  iterations_since_restore: 361\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.81666666666666\n",
      "    ram_util_percent: 30.938888888888883\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437012841110008\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.820672752915232\n",
      "    mean_inference_ms: 2.4753792809827244\n",
      "    mean_raw_obs_processing_ms: 2.022470050803388\n",
      "  time_since_restore: 9769.973987102509\n",
      "  time_this_iter_s: 25.226202964782715\n",
      "  time_total_s: 9769.973987102509\n",
      "  timers:\n",
      "    learn_throughput: 1150.246\n",
      "    learn_time_ms: 1737.02\n",
      "    load_throughput: 58144.849\n",
      "    load_time_ms: 34.362\n",
      "    sample_throughput: 69.369\n",
      "    sample_time_ms: 28802.528\n",
      "    update_time_ms: 8.842\n",
      "  timestamp: 1636439293\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 721278\n",
      "  training_iteration: 361\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   361</td><td style=\"text-align: right;\">         9769.97</td><td style=\"text-align: right;\">721278</td><td style=\"text-align: right;\">  8.1524</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                2.93</td><td style=\"text-align: right;\">              99.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 723276\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-28-38\n",
      "  done: false\n",
      "  episode_len_mean: 99.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 8.20260000000002\n",
      "  episode_reward_min: 2.9300000000000126\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 6943\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2371899071193877\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010208327613809774\n",
      "          policy_loss: -0.017023710760154895\n",
      "          total_loss: 0.14966552932524965\n",
      "          vf_explained_var: 0.967486560344696\n",
      "          vf_loss: 0.17034019602551348\n",
      "    num_agent_steps_sampled: 723276\n",
      "    num_agent_steps_trained: 723276\n",
      "    num_steps_sampled: 723276\n",
      "    num_steps_trained: 723276\n",
      "  iterations_since_restore: 362\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.90810810810812\n",
      "    ram_util_percent: 30.894594594594597\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437005972250364\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.822788026210038\n",
      "    mean_inference_ms: 2.475391231912254\n",
      "    mean_raw_obs_processing_ms: 2.018910913266923\n",
      "  time_since_restore: 9795.36503648758\n",
      "  time_this_iter_s: 25.3910493850708\n",
      "  time_total_s: 9795.36503648758\n",
      "  timers:\n",
      "    learn_throughput: 1150.126\n",
      "    learn_time_ms: 1737.201\n",
      "    load_throughput: 58309.915\n",
      "    load_time_ms: 34.265\n",
      "    sample_throughput: 69.317\n",
      "    sample_time_ms: 28824.294\n",
      "    update_time_ms: 9.295\n",
      "  timestamp: 1636439318\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 723276\n",
      "  training_iteration: 362\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   362</td><td style=\"text-align: right;\">         9795.37</td><td style=\"text-align: right;\">723276</td><td style=\"text-align: right;\">  8.2026</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">                2.93</td><td style=\"text-align: right;\">              99.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 725274\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-29-03\n",
      "  done: false\n",
      "  episode_len_mean: 100.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000016\n",
      "  episode_reward_mean: 8.53080000000002\n",
      "  episode_reward_min: 2.9300000000000126\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 6962\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2974622039567856\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006823510482732974\n",
      "          policy_loss: -0.08477870128339245\n",
      "          total_loss: 0.020725552320835137\n",
      "          vf_explained_var: 0.980401337146759\n",
      "          vf_loss: 0.11264957068931489\n",
      "    num_agent_steps_sampled: 725274\n",
      "    num_agent_steps_trained: 725274\n",
      "    num_steps_sampled: 725274\n",
      "    num_steps_trained: 725274\n",
      "  iterations_since_restore: 363\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69714285714288\n",
      "    ram_util_percent: 30.83714285714286\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437892552623314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.825430160975774\n",
      "    mean_inference_ms: 2.475570946427877\n",
      "    mean_raw_obs_processing_ms: 2.015512907752152\n",
      "  time_since_restore: 9819.82947063446\n",
      "  time_this_iter_s: 24.464434146881104\n",
      "  time_total_s: 9819.82947063446\n",
      "  timers:\n",
      "    learn_throughput: 1151.006\n",
      "    learn_time_ms: 1735.872\n",
      "    load_throughput: 58279.624\n",
      "    load_time_ms: 34.283\n",
      "    sample_throughput: 74.228\n",
      "    sample_time_ms: 26917.029\n",
      "    update_time_ms: 9.69\n",
      "  timestamp: 1636439343\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 725274\n",
      "  training_iteration: 363\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   363</td><td style=\"text-align: right;\">         9819.83</td><td style=\"text-align: right;\">725274</td><td style=\"text-align: right;\">  8.5308</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">                2.93</td><td style=\"text-align: right;\">            100.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 727272\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 98.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.267500000000018\n",
      "  episode_reward_min: 2.9300000000000126\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 6983\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2643950519107636\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010030350485640674\n",
      "          policy_loss: -0.018617000413082896\n",
      "          total_loss: 0.24203304335297574\n",
      "          vf_explained_var: 0.9600182175636292\n",
      "          vf_loss: 0.26472509636410646\n",
      "    num_agent_steps_sampled: 727272\n",
      "    num_agent_steps_trained: 727272\n",
      "    num_steps_sampled: 727272\n",
      "    num_steps_trained: 727272\n",
      "  iterations_since_restore: 364\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.13783783783784\n",
      "    ram_util_percent: 30.756756756756758\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437994750797799\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.82767331142574\n",
      "    mean_inference_ms: 2.475569794894605\n",
      "    mean_raw_obs_processing_ms: 2.0117996772337032\n",
      "  time_since_restore: 9846.104308366776\n",
      "  time_this_iter_s: 26.274837732315063\n",
      "  time_total_s: 9846.104308366776\n",
      "  timers:\n",
      "    learn_throughput: 1150.821\n",
      "    learn_time_ms: 1736.152\n",
      "    load_throughput: 58279.583\n",
      "    load_time_ms: 34.283\n",
      "    sample_throughput: 79.007\n",
      "    sample_time_ms: 25289.054\n",
      "    update_time_ms: 9.612\n",
      "  timestamp: 1636439369\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 727272\n",
      "  training_iteration: 364\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   364</td><td style=\"text-align: right;\">          9846.1</td><td style=\"text-align: right;\">727272</td><td style=\"text-align: right;\">  8.2675</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                2.93</td><td style=\"text-align: right;\">             98.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 729270\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-29-55\n",
      "  done: false\n",
      "  episode_len_mean: 98.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.553000000000019\n",
      "  episode_reward_min: 2.220000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7003\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2952426933106922\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010176033108699207\n",
      "          policy_loss: -0.043855467438697816\n",
      "          total_loss: 0.3257447286730721\n",
      "          vf_explained_var: 0.9450478553771973\n",
      "          vf_loss: 0.37385926966865857\n",
      "    num_agent_steps_sampled: 729270\n",
      "    num_agent_steps_trained: 729270\n",
      "    num_steps_sampled: 729270\n",
      "    num_steps_trained: 729270\n",
      "  iterations_since_restore: 365\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77027027027027\n",
      "    ram_util_percent: 30.72972972972973\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438062956810335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.82968918445964\n",
      "    mean_inference_ms: 2.4755510590406216\n",
      "    mean_raw_obs_processing_ms: 2.0082485480749495\n",
      "  time_since_restore: 9871.723978281021\n",
      "  time_this_iter_s: 25.619669914245605\n",
      "  time_total_s: 9871.723978281021\n",
      "  timers:\n",
      "    learn_throughput: 1151.879\n",
      "    learn_time_ms: 1734.558\n",
      "    load_throughput: 58329.924\n",
      "    load_time_ms: 34.253\n",
      "    sample_throughput: 84.0\n",
      "    sample_time_ms: 23785.597\n",
      "    update_time_ms: 8.801\n",
      "  timestamp: 1636439395\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 729270\n",
      "  training_iteration: 365\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   365</td><td style=\"text-align: right;\">         9871.72</td><td style=\"text-align: right;\">729270</td><td style=\"text-align: right;\">   8.553</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                2.22</td><td style=\"text-align: right;\">             98.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 731268\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-30-21\n",
      "  done: false\n",
      "  episode_len_mean: 97.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.581600000000016\n",
      "  episode_reward_min: 2.220000000000018\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 7026\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3253761745634534\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013130620354748011\n",
      "          policy_loss: 0.004039045955453601\n",
      "          total_loss: 0.1399556239623399\n",
      "          vf_explained_var: 0.9790974259376526\n",
      "          vf_loss: 0.13795289239801822\n",
      "    num_agent_steps_sampled: 731268\n",
      "    num_agent_steps_trained: 731268\n",
      "    num_steps_sampled: 731268\n",
      "    num_steps_trained: 731268\n",
      "  iterations_since_restore: 366\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.17297297297297\n",
      "    ram_util_percent: 30.699999999999996\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436572245465143\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.83336018340867\n",
      "    mean_inference_ms: 2.4752932478286978\n",
      "    mean_raw_obs_processing_ms: 2.0043753492081544\n",
      "  time_since_restore: 9897.835479021072\n",
      "  time_this_iter_s: 26.11150074005127\n",
      "  time_total_s: 9897.835479021072\n",
      "  timers:\n",
      "    learn_throughput: 1150.48\n",
      "    learn_time_ms: 1736.666\n",
      "    load_throughput: 58261.796\n",
      "    load_time_ms: 34.293\n",
      "    sample_throughput: 83.76\n",
      "    sample_time_ms: 23853.809\n",
      "    update_time_ms: 9.682\n",
      "  timestamp: 1636439421\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 731268\n",
      "  training_iteration: 366\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   366</td><td style=\"text-align: right;\">         9897.84</td><td style=\"text-align: right;\">731268</td><td style=\"text-align: right;\">  8.5816</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                2.22</td><td style=\"text-align: right;\">             97.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 733266\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-30-46\n",
      "  done: false\n",
      "  episode_len_mean: 97.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.971200000000017\n",
      "  episode_reward_min: 2.220000000000018\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 7045\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2074101709184193\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009544988508930013\n",
      "          policy_loss: 0.015125659019464539\n",
      "          total_loss: 0.4125593081604512\n",
      "          vf_explained_var: 0.9650599956512451\n",
      "          vf_loss: 0.4013534915411756\n",
      "    num_agent_steps_sampled: 733266\n",
      "    num_agent_steps_trained: 733266\n",
      "    num_steps_sampled: 733266\n",
      "    num_steps_trained: 733266\n",
      "  iterations_since_restore: 367\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.31944444444446\n",
      "    ram_util_percent: 30.708333333333332\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443662843499836\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.835980768449303\n",
      "    mean_inference_ms: 2.4752943926972155\n",
      "    mean_raw_obs_processing_ms: 2.001119930504743\n",
      "  time_since_restore: 9923.189410448074\n",
      "  time_this_iter_s: 25.353931427001953\n",
      "  time_total_s: 9923.189410448074\n",
      "  timers:\n",
      "    learn_throughput: 1150.704\n",
      "    learn_time_ms: 1736.329\n",
      "    load_throughput: 58562.881\n",
      "    load_time_ms: 34.117\n",
      "    sample_throughput: 83.923\n",
      "    sample_time_ms: 23807.579\n",
      "    update_time_ms: 9.399\n",
      "  timestamp: 1636439446\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 733266\n",
      "  training_iteration: 367\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   367</td><td style=\"text-align: right;\">         9923.19</td><td style=\"text-align: right;\">733266</td><td style=\"text-align: right;\">  8.9712</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                2.22</td><td style=\"text-align: right;\">             97.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 735264\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-31-12\n",
      "  done: false\n",
      "  episode_len_mean: 96.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.672000000000018\n",
      "  episode_reward_min: 0.9499999999999991\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7066\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1629855544794174\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009398041416845944\n",
      "          policy_loss: 0.0019703096044915063\n",
      "          total_loss: 0.23039308423619895\n",
      "          vf_explained_var: 0.9616162776947021\n",
      "          vf_loss: 0.23202391367937839\n",
      "    num_agent_steps_sampled: 735264\n",
      "    num_agent_steps_trained: 735264\n",
      "    num_steps_sampled: 735264\n",
      "    num_steps_trained: 735264\n",
      "  iterations_since_restore: 368\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59459459459458\n",
      "    ram_util_percent: 30.629729729729736\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044342822181418884\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.838730531181717\n",
      "    mean_inference_ms: 2.4749086760062364\n",
      "    mean_raw_obs_processing_ms: 1.9976667136624235\n",
      "  time_since_restore: 9948.618468046188\n",
      "  time_this_iter_s: 25.429057598114014\n",
      "  time_total_s: 9948.618468046188\n",
      "  timers:\n",
      "    learn_throughput: 1162.108\n",
      "    learn_time_ms: 1719.289\n",
      "    load_throughput: 59900.769\n",
      "    load_time_ms: 33.355\n",
      "    sample_throughput: 83.942\n",
      "    sample_time_ms: 23802.249\n",
      "    update_time_ms: 9.311\n",
      "  timestamp: 1636439472\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 735264\n",
      "  training_iteration: 368\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   368</td><td style=\"text-align: right;\">         9948.62</td><td style=\"text-align: right;\">735264</td><td style=\"text-align: right;\">   8.672</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                0.95</td><td style=\"text-align: right;\">              96.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 737262\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-31-38\n",
      "  done: false\n",
      "  episode_len_mean: 97.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.526600000000016\n",
      "  episode_reward_min: 0.9499999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7086\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1902918023722513\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007772684363107012\n",
      "          policy_loss: -0.026767023298002426\n",
      "          total_loss: 0.1372812455276116\n",
      "          vf_explained_var: 0.9693616628646851\n",
      "          vf_loss: 0.16931100714774358\n",
      "    num_agent_steps_sampled: 737262\n",
      "    num_agent_steps_trained: 737262\n",
      "    num_steps_sampled: 737262\n",
      "    num_steps_trained: 737262\n",
      "  iterations_since_restore: 369\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.45675675675676\n",
      "    ram_util_percent: 30.632432432432434\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443527888225643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.842694905515703\n",
      "    mean_inference_ms: 2.4750747473467776\n",
      "    mean_raw_obs_processing_ms: 1.9943340756504637\n",
      "  time_since_restore: 9974.792044401169\n",
      "  time_this_iter_s: 26.17357635498047\n",
      "  time_total_s: 9974.792044401169\n",
      "  timers:\n",
      "    learn_throughput: 1162.777\n",
      "    learn_time_ms: 1718.3\n",
      "    load_throughput: 59590.934\n",
      "    load_time_ms: 33.529\n",
      "    sample_throughput: 83.759\n",
      "    sample_time_ms: 23854.28\n",
      "    update_time_ms: 9.309\n",
      "  timestamp: 1636439498\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 737262\n",
      "  training_iteration: 369\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   369</td><td style=\"text-align: right;\">         9974.79</td><td style=\"text-align: right;\">737262</td><td style=\"text-align: right;\">  8.5266</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">                0.95</td><td style=\"text-align: right;\">             97.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 739260\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-32-20\n",
      "  done: false\n",
      "  episode_len_mean: 96.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.520000000000016\n",
      "  episode_reward_mean: 8.352400000000017\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7107\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2993781401997522\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00752958114513356\n",
      "          policy_loss: -0.02869471942207643\n",
      "          total_loss: 0.10600502146851448\n",
      "          vf_explained_var: 0.9753931164741516\n",
      "          vf_loss: 0.14126102392162596\n",
      "    num_agent_steps_sampled: 739260\n",
      "    num_agent_steps_trained: 739260\n",
      "    num_steps_sampled: 739260\n",
      "    num_steps_trained: 739260\n",
      "  iterations_since_restore: 370\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.90491803278687\n",
      "    ram_util_percent: 30.614754098360645\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433903785055177\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.845901295213906\n",
      "    mean_inference_ms: 2.4748732755527736\n",
      "    mean_raw_obs_processing_ms: 1.996369396223119\n",
      "  time_since_restore: 10017.360853672028\n",
      "  time_this_iter_s: 42.568809270858765\n",
      "  time_total_s: 10017.360853672028\n",
      "  timers:\n",
      "    learn_throughput: 1163.739\n",
      "    learn_time_ms: 1716.88\n",
      "    load_throughput: 59549.097\n",
      "    load_time_ms: 33.552\n",
      "    sample_throughput: 78.378\n",
      "    sample_time_ms: 25491.969\n",
      "    update_time_ms: 8.973\n",
      "  timestamp: 1636439540\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 739260\n",
      "  training_iteration: 370\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   370</td><td style=\"text-align: right;\">         10017.4</td><td style=\"text-align: right;\">739260</td><td style=\"text-align: right;\">  8.3524</td><td style=\"text-align: right;\">               14.52</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">             96.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 741258\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-32-47\n",
      "  done: false\n",
      "  episode_len_mean: 97.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.530000000000017\n",
      "  episode_reward_mean: 8.313100000000016\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7128\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3266222766467504\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007844395427312481\n",
      "          policy_loss: -0.020123177110439254\n",
      "          total_loss: 0.0974256938412076\n",
      "          vf_explained_var: 0.9860268831253052\n",
      "          vf_loss: 0.12411364994588353\n",
      "    num_agent_steps_sampled: 741258\n",
      "    num_agent_steps_trained: 741258\n",
      "    num_steps_sampled: 741258\n",
      "    num_steps_trained: 741258\n",
      "  iterations_since_restore: 371\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.02368421052631\n",
      "    ram_util_percent: 30.64736842105263\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435623686551622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.848753679161923\n",
      "    mean_inference_ms: 2.4751174701557868\n",
      "    mean_raw_obs_processing_ms: 1.9975688372444314\n",
      "  time_since_restore: 10044.391867637634\n",
      "  time_this_iter_s: 27.03101396560669\n",
      "  time_total_s: 10044.391867637634\n",
      "  timers:\n",
      "    learn_throughput: 1163.072\n",
      "    learn_time_ms: 1717.864\n",
      "    load_throughput: 59563.869\n",
      "    load_time_ms: 33.544\n",
      "    sample_throughput: 77.829\n",
      "    sample_time_ms: 25671.708\n",
      "    update_time_ms: 8.87\n",
      "  timestamp: 1636439567\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 741258\n",
      "  training_iteration: 371\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   371</td><td style=\"text-align: right;\">         10044.4</td><td style=\"text-align: right;\">741258</td><td style=\"text-align: right;\">  8.3131</td><td style=\"text-align: right;\">               14.53</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">             97.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 743256\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-33-33\n",
      "  done: false\n",
      "  episode_len_mean: 93.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.428600000000015\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 7151\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2411462244533358\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0061553175053889065\n",
      "          policy_loss: -0.008885186218789646\n",
      "          total_loss: 0.4369311896263666\n",
      "          vf_explained_var: 0.9654485583305359\n",
      "          vf_loss: 0.4529693682367603\n",
      "    num_agent_steps_sampled: 743256\n",
      "    num_agent_steps_trained: 743256\n",
      "    num_steps_sampled: 743256\n",
      "    num_steps_trained: 743256\n",
      "  iterations_since_restore: 372\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.39538461538461\n",
      "    ram_util_percent: 30.746153846153845\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443379282598441\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.852448918851234\n",
      "    mean_inference_ms: 2.4747984964322667\n",
      "    mean_raw_obs_processing_ms: 2.0095576495771463\n",
      "  time_since_restore: 10089.586032629013\n",
      "  time_this_iter_s: 45.194164991378784\n",
      "  time_total_s: 10089.586032629013\n",
      "  timers:\n",
      "    learn_throughput: 1161.405\n",
      "    learn_time_ms: 1720.33\n",
      "    load_throughput: 59521.055\n",
      "    load_time_ms: 33.568\n",
      "    sample_throughput: 72.261\n",
      "    sample_time_ms: 27649.961\n",
      "    update_time_ms: 8.43\n",
      "  timestamp: 1636439613\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 743256\n",
      "  training_iteration: 372\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   372</td><td style=\"text-align: right;\">         10089.6</td><td style=\"text-align: right;\">743256</td><td style=\"text-align: right;\">  8.4286</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             93.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 745254\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-33-59\n",
      "  done: false\n",
      "  episode_len_mean: 93.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.453300000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7172\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.8542968749999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2583233958198912\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.004938840548784555\n",
      "          policy_loss: -0.11705142227666719\n",
      "          total_loss: -0.02958332992025784\n",
      "          vf_explained_var: 0.9874986410140991\n",
      "          vf_loss: 0.09583209030152787\n",
      "    num_agent_steps_sampled: 745254\n",
      "    num_agent_steps_trained: 745254\n",
      "    num_steps_sampled: 745254\n",
      "    num_steps_trained: 745254\n",
      "  iterations_since_restore: 373\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.33421052631579\n",
      "    ram_util_percent: 30.792105263157897\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433874721512412\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.85893650090294\n",
      "    mean_inference_ms: 2.4748028517940104\n",
      "    mean_raw_obs_processing_ms: 2.0205387851265844\n",
      "  time_since_restore: 10116.105591773987\n",
      "  time_this_iter_s: 26.519559144973755\n",
      "  time_total_s: 10116.105591773987\n",
      "  timers:\n",
      "    learn_throughput: 1160.661\n",
      "    learn_time_ms: 1721.433\n",
      "    load_throughput: 59528.539\n",
      "    load_time_ms: 33.564\n",
      "    sample_throughput: 71.73\n",
      "    sample_time_ms: 27854.599\n",
      "    update_time_ms: 8.252\n",
      "  timestamp: 1636439639\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 745254\n",
      "  training_iteration: 373\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   373</td><td style=\"text-align: right;\">         10116.1</td><td style=\"text-align: right;\">745254</td><td style=\"text-align: right;\">  8.4533</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             93.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 747252\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-34-26\n",
      "  done: false\n",
      "  episode_len_mean: 92.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.829700000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 7194\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4271484374999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2108529601778304\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01017530420786566\n",
      "          policy_loss: -0.012853812665811606\n",
      "          total_loss: 0.06091678997590428\n",
      "          vf_explained_var: 0.9900934100151062\n",
      "          vf_loss: 0.08153276729974009\n",
      "    num_agent_steps_sampled: 747252\n",
      "    num_agent_steps_trained: 747252\n",
      "    num_steps_sampled: 747252\n",
      "    num_steps_trained: 747252\n",
      "  iterations_since_restore: 374\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.61282051282053\n",
      "    ram_util_percent: 30.835897435897433\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433267502159378\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.869504128394578\n",
      "    mean_inference_ms: 2.4747402076297984\n",
      "    mean_raw_obs_processing_ms: 2.032152226512628\n",
      "  time_since_restore: 10143.265274524689\n",
      "  time_this_iter_s: 27.159682750701904\n",
      "  time_total_s: 10143.265274524689\n",
      "  timers:\n",
      "    learn_throughput: 1161.44\n",
      "    learn_time_ms: 1720.279\n",
      "    load_throughput: 59723.905\n",
      "    load_time_ms: 33.454\n",
      "    sample_throughput: 71.5\n",
      "    sample_time_ms: 27944.067\n",
      "    update_time_ms: 8.578\n",
      "  timestamp: 1636439666\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 747252\n",
      "  training_iteration: 374\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   374</td><td style=\"text-align: right;\">         10143.3</td><td style=\"text-align: right;\">747252</td><td style=\"text-align: right;\">  8.8297</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             92.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 749250\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-34-51\n",
      "  done: false\n",
      "  episode_len_mean: 92.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.748100000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7214\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4271484374999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.313187038898468\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009939969089122798\n",
      "          policy_loss: -0.03514497179892801\n",
      "          total_loss: 0.05038605035238323\n",
      "          vf_explained_var: 0.9836385250091553\n",
      "          vf_loss: 0.09441705057840971\n",
      "    num_agent_steps_sampled: 749250\n",
      "    num_agent_steps_trained: 749250\n",
      "    num_steps_sampled: 749250\n",
      "    num_steps_trained: 749250\n",
      "  iterations_since_restore: 375\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.46571428571428\n",
      "    ram_util_percent: 30.95142857142857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434673169699877\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.873462699145175\n",
      "    mean_inference_ms: 2.4748817697619714\n",
      "    mean_raw_obs_processing_ms: 2.037012127133934\n",
      "  time_since_restore: 10168.088609457016\n",
      "  time_this_iter_s: 24.82333493232727\n",
      "  time_total_s: 10168.088609457016\n",
      "  timers:\n",
      "    learn_throughput: 1161.661\n",
      "    learn_time_ms: 1719.95\n",
      "    load_throughput: 59723.564\n",
      "    load_time_ms: 33.454\n",
      "    sample_throughput: 71.703\n",
      "    sample_time_ms: 27864.989\n",
      "    update_time_ms: 8.674\n",
      "  timestamp: 1636439691\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 749250\n",
      "  training_iteration: 375\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   375</td><td style=\"text-align: right;\">         10168.1</td><td style=\"text-align: right;\">749250</td><td style=\"text-align: right;\">  8.7481</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             92.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 751248\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-35-18\n",
      "  done: false\n",
      "  episode_len_mean: 94.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.691100000000016\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7235\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4271484374999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1845461079052517\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01603909516719592\n",
      "          policy_loss: -0.06314484592349756\n",
      "          total_loss: 0.10886140570399307\n",
      "          vf_explained_var: 0.973111093044281\n",
      "          vf_loss: 0.17700063674932434\n",
      "    num_agent_steps_sampled: 751248\n",
      "    num_agent_steps_trained: 751248\n",
      "    num_steps_sampled: 751248\n",
      "    num_steps_trained: 751248\n",
      "  iterations_since_restore: 376\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.22894736842103\n",
      "    ram_util_percent: 31.036842105263162\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434915088811771\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.87977699534307\n",
      "    mean_inference_ms: 2.474888177199934\n",
      "    mean_raw_obs_processing_ms: 2.0383464904481357\n",
      "  time_since_restore: 10195.005973100662\n",
      "  time_this_iter_s: 26.91736364364624\n",
      "  time_total_s: 10195.005973100662\n",
      "  timers:\n",
      "    learn_throughput: 1162.605\n",
      "    learn_time_ms: 1718.555\n",
      "    load_throughput: 60040.934\n",
      "    load_time_ms: 33.277\n",
      "    sample_throughput: 71.489\n",
      "    sample_time_ms: 27948.326\n",
      "    update_time_ms: 7.595\n",
      "  timestamp: 1636439718\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 751248\n",
      "  training_iteration: 376\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   376</td><td style=\"text-align: right;\">           10195</td><td style=\"text-align: right;\">751248</td><td style=\"text-align: right;\">  8.6911</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             94.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 753246\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-35-45\n",
      "  done: false\n",
      "  episode_len_mean: 95.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000013\n",
      "  episode_reward_mean: 8.592100000000018\n",
      "  episode_reward_min: 2.3700000000000268\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7256\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4271484374999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2728246978351048\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016430138143281765\n",
      "          policy_loss: -0.016388282960369472\n",
      "          total_loss: 0.1488633566136871\n",
      "          vf_explained_var: 0.9764269590377808\n",
      "          vf_loss: 0.17096178020749772\n",
      "    num_agent_steps_sampled: 753246\n",
      "    num_agent_steps_trained: 753246\n",
      "    num_steps_sampled: 753246\n",
      "    num_steps_trained: 753246\n",
      "  iterations_since_restore: 377\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77948717948719\n",
      "    ram_util_percent: 31.092307692307696\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435372824331271\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.888878034963227\n",
      "    mean_inference_ms: 2.474981320983515\n",
      "    mean_raw_obs_processing_ms: 2.0349302348254397\n",
      "  time_since_restore: 10221.810379266739\n",
      "  time_this_iter_s: 26.80440616607666\n",
      "  time_total_s: 10221.810379266739\n",
      "  timers:\n",
      "    learn_throughput: 1161.342\n",
      "    learn_time_ms: 1720.424\n",
      "    load_throughput: 59600.173\n",
      "    load_time_ms: 33.523\n",
      "    sample_throughput: 71.124\n",
      "    sample_time_ms: 28091.896\n",
      "    update_time_ms: 6.934\n",
      "  timestamp: 1636439745\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 753246\n",
      "  training_iteration: 377\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   377</td><td style=\"text-align: right;\">         10221.8</td><td style=\"text-align: right;\">753246</td><td style=\"text-align: right;\">  8.5921</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">                2.37</td><td style=\"text-align: right;\">             95.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 755244\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-36-11\n",
      "  done: false\n",
      "  episode_len_mean: 95.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000015\n",
      "  episode_reward_mean: 8.475100000000017\n",
      "  episode_reward_min: 3.080000000000012\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7277\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4271484374999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2089885791142783\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015958141571848904\n",
      "          policy_loss: -0.004467076488903591\n",
      "          total_loss: 0.14268618862898577\n",
      "          vf_explained_var: 0.9773911237716675\n",
      "          vf_loss: 0.1524266545616445\n",
      "    num_agent_steps_sampled: 755244\n",
      "    num_agent_steps_trained: 755244\n",
      "    num_steps_sampled: 755244\n",
      "    num_steps_trained: 755244\n",
      "  iterations_since_restore: 378\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.61944444444445\n",
      "    ram_util_percent: 31.072222222222226\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435566098845719\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.894268228360016\n",
      "    mean_inference_ms: 2.474958629944884\n",
      "    mean_raw_obs_processing_ms: 2.031472137102398\n",
      "  time_since_restore: 10247.328494548798\n",
      "  time_this_iter_s: 25.518115282058716\n",
      "  time_total_s: 10247.328494548798\n",
      "  timers:\n",
      "    learn_throughput: 1161.488\n",
      "    learn_time_ms: 1720.207\n",
      "    load_throughput: 60427.593\n",
      "    load_time_ms: 33.064\n",
      "    sample_throughput: 71.099\n",
      "    sample_time_ms: 28101.474\n",
      "    update_time_ms: 7.341\n",
      "  timestamp: 1636439771\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 755244\n",
      "  training_iteration: 378\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   378</td><td style=\"text-align: right;\">         10247.3</td><td style=\"text-align: right;\">755244</td><td style=\"text-align: right;\">  8.4751</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">                3.08</td><td style=\"text-align: right;\">             95.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 757242\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-36-37\n",
      "  done: false\n",
      "  episode_len_mean: 97.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.500000000000016\n",
      "  episode_reward_mean: 7.897100000000016\n",
      "  episode_reward_min: 2.8000000000000127\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7297\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4271484374999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.343240771974836\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010232922892055374\n",
      "          policy_loss: -0.0460873024449462\n",
      "          total_loss: 0.044809870599281224\n",
      "          vf_explained_var: 0.9791662096977234\n",
      "          vf_loss: 0.09995860395332178\n",
      "    num_agent_steps_sampled: 757242\n",
      "    num_agent_steps_trained: 757242\n",
      "    num_steps_sampled: 757242\n",
      "    num_steps_trained: 757242\n",
      "  iterations_since_restore: 379\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.35135135135135\n",
      "    ram_util_percent: 31.11621621621621\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438869802223461\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.89672283880383\n",
      "    mean_inference_ms: 2.4753597924123985\n",
      "    mean_raw_obs_processing_ms: 2.028017837884044\n",
      "  time_since_restore: 10273.283207654953\n",
      "  time_this_iter_s: 25.954713106155396\n",
      "  time_total_s: 10273.283207654953\n",
      "  timers:\n",
      "    learn_throughput: 1162.245\n",
      "    learn_time_ms: 1719.087\n",
      "    load_throughput: 60893.641\n",
      "    load_time_ms: 32.811\n",
      "    sample_throughput: 71.152\n",
      "    sample_time_ms: 28080.822\n",
      "    update_time_ms: 7.215\n",
      "  timestamp: 1636439797\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 757242\n",
      "  training_iteration: 379\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   379</td><td style=\"text-align: right;\">         10273.3</td><td style=\"text-align: right;\">757242</td><td style=\"text-align: right;\">  7.8971</td><td style=\"text-align: right;\">                14.5</td><td style=\"text-align: right;\">                 2.8</td><td style=\"text-align: right;\">             97.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 759240\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-37-03\n",
      "  done: false\n",
      "  episode_len_mean: 96.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 8.432100000000018\n",
      "  episode_reward_min: 2.8000000000000127\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7317\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4271484374999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2302439831552052\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01065207100434588\n",
      "          policy_loss: -0.02228027344903066\n",
      "          total_loss: 0.09408361245656298\n",
      "          vf_explained_var: 0.984835684299469\n",
      "          vf_loss: 0.12411631076108842\n",
      "    num_agent_steps_sampled: 759240\n",
      "    num_agent_steps_trained: 759240\n",
      "    num_steps_sampled: 759240\n",
      "    num_steps_trained: 759240\n",
      "  iterations_since_restore: 380\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.7078947368421\n",
      "    ram_util_percent: 31.042105263157886\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044381790586282416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.902545201928923\n",
      "    mean_inference_ms: 2.4752447395126684\n",
      "    mean_raw_obs_processing_ms: 2.0247133789239515\n",
      "  time_since_restore: 10299.79520893097\n",
      "  time_this_iter_s: 26.512001276016235\n",
      "  time_total_s: 10299.79520893097\n",
      "  timers:\n",
      "    learn_throughput: 1161.163\n",
      "    learn_time_ms: 1720.689\n",
      "    load_throughput: 60612.206\n",
      "    load_time_ms: 32.964\n",
      "    sample_throughput: 75.472\n",
      "    sample_time_ms: 26473.319\n",
      "    update_time_ms: 7.338\n",
      "  timestamp: 1636439823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 759240\n",
      "  training_iteration: 380\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   380</td><td style=\"text-align: right;\">         10299.8</td><td style=\"text-align: right;\">759240</td><td style=\"text-align: right;\">  8.4321</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">                 2.8</td><td style=\"text-align: right;\">             96.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 761238\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-37-28\n",
      "  done: false\n",
      "  episode_len_mean: 98.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.178200000000016\n",
      "  episode_reward_min: 2.0500000000000282\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7337\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4271484374999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.247103609641393\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.02158451739597879\n",
      "          policy_loss: 0.015039046498991194\n",
      "          total_loss: 0.372407153907365\n",
      "          vf_explained_var: 0.947981595993042\n",
      "          vf_loss: 0.360619346602332\n",
      "    num_agent_steps_sampled: 761238\n",
      "    num_agent_steps_trained: 761238\n",
      "    num_steps_sampled: 761238\n",
      "    num_steps_trained: 761238\n",
      "  iterations_since_restore: 381\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.43428571428572\n",
      "    ram_util_percent: 31.0\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438030416364489\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.9050222485865\n",
      "    mean_inference_ms: 2.4751877321511824\n",
      "    mean_raw_obs_processing_ms: 2.0213327934547576\n",
      "  time_since_restore: 10324.280314445496\n",
      "  time_this_iter_s: 24.485105514526367\n",
      "  time_total_s: 10324.280314445496\n",
      "  timers:\n",
      "    learn_throughput: 1161.364\n",
      "    learn_time_ms: 1720.391\n",
      "    load_throughput: 60623.914\n",
      "    load_time_ms: 32.957\n",
      "    sample_throughput: 76.205\n",
      "    sample_time_ms: 26218.718\n",
      "    update_time_ms: 7.529\n",
      "  timestamp: 1636439848\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 761238\n",
      "  training_iteration: 381\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   381</td><td style=\"text-align: right;\">         10324.3</td><td style=\"text-align: right;\">761238</td><td style=\"text-align: right;\">  8.1782</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.05</td><td style=\"text-align: right;\">             98.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 763236\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-37-54\n",
      "  done: false\n",
      "  episode_len_mean: 98.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.025700000000016\n",
      "  episode_reward_min: 2.0500000000000282\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7358\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3079442552157812\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009959911795440278\n",
      "          policy_loss: 0.021510059528407597\n",
      "          total_loss: 0.1925450126862242\n",
      "          vf_explained_var: 0.9657893776893616\n",
      "          vf_loss: 0.1777328557379189\n",
      "    num_agent_steps_sampled: 763236\n",
      "    num_agent_steps_trained: 763236\n",
      "    num_steps_sampled: 763236\n",
      "    num_steps_trained: 763236\n",
      "  iterations_since_restore: 382\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.07837837837837\n",
      "    ram_util_percent: 30.951351351351352\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437863370495401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.907066413557303\n",
      "    mean_inference_ms: 2.475116170200354\n",
      "    mean_raw_obs_processing_ms: 2.017796313312276\n",
      "  time_since_restore: 10350.349255800247\n",
      "  time_this_iter_s: 26.068941354751587\n",
      "  time_total_s: 10350.349255800247\n",
      "  timers:\n",
      "    learn_throughput: 1163.015\n",
      "    learn_time_ms: 1717.949\n",
      "    load_throughput: 60652.39\n",
      "    load_time_ms: 32.942\n",
      "    sample_throughput: 82.193\n",
      "    sample_time_ms: 24308.603\n",
      "    update_time_ms: 7.606\n",
      "  timestamp: 1636439874\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 763236\n",
      "  training_iteration: 382\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   382</td><td style=\"text-align: right;\">         10350.3</td><td style=\"text-align: right;\">763236</td><td style=\"text-align: right;\">  8.0257</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.05</td><td style=\"text-align: right;\">             98.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 765234\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-38-20\n",
      "  done: false\n",
      "  episode_len_mean: 98.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.146400000000018\n",
      "  episode_reward_min: 2.0500000000000282\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7378\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1413159228506542\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01347899965224408\n",
      "          policy_loss: -0.0030371525457927157\n",
      "          total_loss: 0.30970134571017255\n",
      "          vf_explained_var: 0.9570305943489075\n",
      "          vf_loss: 0.31551535981042045\n",
      "    num_agent_steps_sampled: 765234\n",
      "    num_agent_steps_trained: 765234\n",
      "    num_steps_sampled: 765234\n",
      "    num_steps_trained: 765234\n",
      "  iterations_since_restore: 383\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9657894736842\n",
      "    ram_util_percent: 30.923684210526318\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044385833522214195\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.910330748920305\n",
      "    mean_inference_ms: 2.475181858079814\n",
      "    mean_raw_obs_processing_ms: 2.014410654060727\n",
      "  time_since_restore: 10376.832093954086\n",
      "  time_this_iter_s: 26.48283815383911\n",
      "  time_total_s: 10376.832093954086\n",
      "  timers:\n",
      "    learn_throughput: 1163.172\n",
      "    learn_time_ms: 1717.717\n",
      "    load_throughput: 60626.37\n",
      "    load_time_ms: 32.956\n",
      "    sample_throughput: 82.204\n",
      "    sample_time_ms: 24305.343\n",
      "    update_time_ms: 7.375\n",
      "  timestamp: 1636439900\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 765234\n",
      "  training_iteration: 383\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   383</td><td style=\"text-align: right;\">         10376.8</td><td style=\"text-align: right;\">765234</td><td style=\"text-align: right;\">  8.1464</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.05</td><td style=\"text-align: right;\">                98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 767232\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-38-46\n",
      "  done: false\n",
      "  episode_len_mean: 97.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.638800000000018\n",
      "  episode_reward_min: 2.0500000000000282\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7399\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1261167375814347\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013508707634771204\n",
      "          policy_loss: -0.0075963673669667475\n",
      "          total_loss: 0.1979995292744466\n",
      "          vf_explained_var: 0.9682111740112305\n",
      "          vf_loss: 0.20820172909824622\n",
      "    num_agent_steps_sampled: 767232\n",
      "    num_agent_steps_trained: 767232\n",
      "    num_steps_sampled: 767232\n",
      "    num_steps_trained: 767232\n",
      "  iterations_since_restore: 384\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.05135135135136\n",
      "    ram_util_percent: 30.902702702702705\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436798332224301\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.91417807509858\n",
      "    mean_inference_ms: 2.4748725755084737\n",
      "    mean_raw_obs_processing_ms: 2.0109585542008173\n",
      "  time_since_restore: 10402.876550912857\n",
      "  time_this_iter_s: 26.044456958770752\n",
      "  time_total_s: 10402.876550912857\n",
      "  timers:\n",
      "    learn_throughput: 1162.439\n",
      "    learn_time_ms: 1718.799\n",
      "    load_throughput: 60342.788\n",
      "    load_time_ms: 33.111\n",
      "    sample_throughput: 82.589\n",
      "    sample_time_ms: 24192.128\n",
      "    update_time_ms: 7.969\n",
      "  timestamp: 1636439926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 767232\n",
      "  training_iteration: 384\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   384</td><td style=\"text-align: right;\">         10402.9</td><td style=\"text-align: right;\">767232</td><td style=\"text-align: right;\">  8.6388</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.05</td><td style=\"text-align: right;\">             97.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 769230\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-39-13\n",
      "  done: false\n",
      "  episode_len_mean: 96.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.500100000000018\n",
      "  episode_reward_min: 2.0500000000000282\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7420\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1682595244475773\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009503856077193288\n",
      "          policy_loss: -0.06489030032285623\n",
      "          total_loss: 0.16573498440640314\n",
      "          vf_explained_var: 0.9663606286048889\n",
      "          vf_loss: 0.23621854453924157\n",
      "    num_agent_steps_sampled: 769230\n",
      "    num_agent_steps_trained: 769230\n",
      "    num_steps_sampled: 769230\n",
      "    num_steps_trained: 769230\n",
      "  iterations_since_restore: 385\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.02631578947368\n",
      "    ram_util_percent: 30.910526315789472\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435862021305452\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.917323672735055\n",
      "    mean_inference_ms: 2.474644027281002\n",
      "    mean_raw_obs_processing_ms: 2.007533084985387\n",
      "  time_since_restore: 10429.202153205872\n",
      "  time_this_iter_s: 26.325602293014526\n",
      "  time_total_s: 10429.202153205872\n",
      "  timers:\n",
      "    learn_throughput: 1162.679\n",
      "    learn_time_ms: 1718.445\n",
      "    load_throughput: 60004.306\n",
      "    load_time_ms: 33.298\n",
      "    sample_throughput: 82.077\n",
      "    sample_time_ms: 24342.848\n",
      "    update_time_ms: 7.62\n",
      "  timestamp: 1636439953\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 769230\n",
      "  training_iteration: 385\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   385</td><td style=\"text-align: right;\">         10429.2</td><td style=\"text-align: right;\">769230</td><td style=\"text-align: right;\">  8.5001</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.05</td><td style=\"text-align: right;\">             96.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 771228\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-39-39\n",
      "  done: false\n",
      "  episode_len_mean: 95.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 8.353600000000018\n",
      "  episode_reward_min: 3.0100000000000158\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7440\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3737439655122303\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017195603583422932\n",
      "          policy_loss: -0.02254209919344811\n",
      "          total_loss: 0.2659698437012377\n",
      "          vf_explained_var: 0.9427317380905151\n",
      "          vf_loss: 0.2912317724454971\n",
      "    num_agent_steps_sampled: 771228\n",
      "    num_agent_steps_trained: 771228\n",
      "    num_steps_sampled: 771228\n",
      "    num_steps_trained: 771228\n",
      "  iterations_since_restore: 386\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.56052631578946\n",
      "    ram_util_percent: 30.850000000000012\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436723441634264\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.92381641207636\n",
      "    mean_inference_ms: 2.4747425761264146\n",
      "    mean_raw_obs_processing_ms: 2.0043223986419725\n",
      "  time_since_restore: 10455.533269405365\n",
      "  time_this_iter_s: 26.331116199493408\n",
      "  time_total_s: 10455.533269405365\n",
      "  timers:\n",
      "    learn_throughput: 1162.433\n",
      "    learn_time_ms: 1718.809\n",
      "    load_throughput: 59792.81\n",
      "    load_time_ms: 33.415\n",
      "    sample_throughput: 82.281\n",
      "    sample_time_ms: 24282.664\n",
      "    update_time_ms: 8.453\n",
      "  timestamp: 1636439979\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 771228\n",
      "  training_iteration: 386\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   386</td><td style=\"text-align: right;\">         10455.5</td><td style=\"text-align: right;\">771228</td><td style=\"text-align: right;\">  8.3536</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                3.01</td><td style=\"text-align: right;\">             95.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 773226\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-40-05\n",
      "  done: false\n",
      "  episode_len_mean: 95.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 8.340600000000016\n",
      "  episode_reward_min: 2.9000000000000123\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7461\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2918707858948482\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009366963359914713\n",
      "          policy_loss: -0.03605158574701775\n",
      "          total_loss: 0.053647973585785144\n",
      "          vf_explained_var: 0.9769076108932495\n",
      "          vf_loss: 0.09661664266494058\n",
      "    num_agent_steps_sampled: 773226\n",
      "    num_agent_steps_trained: 773226\n",
      "    num_steps_sampled: 773226\n",
      "    num_steps_trained: 773226\n",
      "  iterations_since_restore: 387\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16756756756756\n",
      "    ram_util_percent: 30.810810810810818\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436764007838029\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.92997884434014\n",
      "    mean_inference_ms: 2.474713319022496\n",
      "    mean_raw_obs_processing_ms: 2.000947615616007\n",
      "  time_since_restore: 10481.817754745483\n",
      "  time_this_iter_s: 26.284485340118408\n",
      "  time_total_s: 10481.817754745483\n",
      "  timers:\n",
      "    learn_throughput: 1163.608\n",
      "    learn_time_ms: 1717.073\n",
      "    load_throughput: 59512.264\n",
      "    load_time_ms: 33.573\n",
      "    sample_throughput: 82.454\n",
      "    sample_time_ms: 24231.834\n",
      "    update_time_ms: 9.107\n",
      "  timestamp: 1636440005\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 773226\n",
      "  training_iteration: 387\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   387</td><td style=\"text-align: right;\">         10481.8</td><td style=\"text-align: right;\">773226</td><td style=\"text-align: right;\">  8.3406</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                 2.9</td><td style=\"text-align: right;\">             95.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 775224\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-40-45\n",
      "  done: false\n",
      "  episode_len_mean: 95.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 8.025900000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 7483\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2752223304339818\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010097018698131125\n",
      "          policy_loss: -0.07199646268217337\n",
      "          total_loss: 0.18523427038231777\n",
      "          vf_explained_var: 0.9641606211662292\n",
      "          vf_loss: 0.2635135681412759\n",
      "    num_agent_steps_sampled: 775224\n",
      "    num_agent_steps_trained: 775224\n",
      "    num_steps_sampled: 775224\n",
      "    num_steps_trained: 775224\n",
      "  iterations_since_restore: 388\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.81428571428572\n",
      "    ram_util_percent: 30.758928571428573\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433088562723647\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.93264741972\n",
      "    mean_inference_ms: 2.4741160651088716\n",
      "    mean_raw_obs_processing_ms: 2.002537543598007\n",
      "  time_since_restore: 10520.98385977745\n",
      "  time_this_iter_s: 39.16610503196716\n",
      "  time_total_s: 10520.98385977745\n",
      "  timers:\n",
      "    learn_throughput: 1161.08\n",
      "    learn_time_ms: 1720.812\n",
      "    load_throughput: 58462.908\n",
      "    load_time_ms: 34.176\n",
      "    sample_throughput: 78.072\n",
      "    sample_time_ms: 25591.712\n",
      "    update_time_ms: 9.774\n",
      "  timestamp: 1636440045\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 775224\n",
      "  training_iteration: 388\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   388</td><td style=\"text-align: right;\">           10521</td><td style=\"text-align: right;\">775224</td><td style=\"text-align: right;\">  8.0259</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             95.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 777222\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-41-42\n",
      "  done: false\n",
      "  episode_len_mean: 92.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 7.804200000000016\n",
      "  episode_reward_min: -0.7400000000000007\n",
      "  episodes_this_iter: 24\n",
      "  episodes_total: 7507\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2135515814735776\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017605658452186434\n",
      "          policy_loss: 0.0004860818031288329\n",
      "          total_loss: 0.636663262390842\n",
      "          vf_explained_var: 0.8875007033348083\n",
      "          vf_loss: 0.6370323502946468\n",
      "    num_agent_steps_sampled: 777222\n",
      "    num_agent_steps_trained: 777222\n",
      "    num_steps_sampled: 777222\n",
      "    num_steps_trained: 777222\n",
      "  iterations_since_restore: 389\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.58048780487805\n",
      "    ram_util_percent: 30.64390243902439\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044327941034351274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.93643294144641\n",
      "    mean_inference_ms: 2.4740138911746765\n",
      "    mean_raw_obs_processing_ms: 2.014283356489504\n",
      "  time_since_restore: 10578.59189581871\n",
      "  time_this_iter_s: 57.608036041259766\n",
      "  time_total_s: 10578.59189581871\n",
      "  timers:\n",
      "    learn_throughput: 1160.589\n",
      "    learn_time_ms: 1721.54\n",
      "    load_throughput: 57926.93\n",
      "    load_time_ms: 34.492\n",
      "    sample_throughput: 69.48\n",
      "    sample_time_ms: 28756.366\n",
      "    update_time_ms: 9.532\n",
      "  timestamp: 1636440102\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 777222\n",
      "  training_iteration: 389\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   389</td><td style=\"text-align: right;\">         10578.6</td><td style=\"text-align: right;\">777222</td><td style=\"text-align: right;\">  7.8042</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.74</td><td style=\"text-align: right;\">             92.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 779220\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-42-09\n",
      "  done: false\n",
      "  episode_len_mean: 92.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000016\n",
      "  episode_reward_mean: 8.072700000000015\n",
      "  episode_reward_min: -0.7400000000000007\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7528\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2448708406516484\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008672441200102212\n",
      "          policy_loss: -0.05684287461141745\n",
      "          total_loss: 0.04345277500826688\n",
      "          vf_explained_var: 0.9839825630187988\n",
      "          vf_loss: 0.10718772831772055\n",
      "    num_agent_steps_sampled: 779220\n",
      "    num_agent_steps_trained: 779220\n",
      "    num_steps_sampled: 779220\n",
      "    num_steps_trained: 779220\n",
      "  iterations_since_restore: 390\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.91315789473684\n",
      "    ram_util_percent: 30.671052631578952\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432460731093775\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.939962213143925\n",
      "    mean_inference_ms: 2.4739305606522164\n",
      "    mean_raw_obs_processing_ms: 2.0246233410674623\n",
      "  time_since_restore: 10605.084838151932\n",
      "  time_this_iter_s: 26.492942333221436\n",
      "  time_total_s: 10605.084838151932\n",
      "  timers:\n",
      "    learn_throughput: 1160.511\n",
      "    learn_time_ms: 1721.655\n",
      "    load_throughput: 58209.995\n",
      "    load_time_ms: 34.324\n",
      "    sample_throughput: 69.484\n",
      "    sample_time_ms: 28755.015\n",
      "    update_time_ms: 9.31\n",
      "  timestamp: 1636440129\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 779220\n",
      "  training_iteration: 390\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   390</td><td style=\"text-align: right;\">         10605.1</td><td style=\"text-align: right;\">779220</td><td style=\"text-align: right;\">  8.0727</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">               -0.74</td><td style=\"text-align: right;\">             92.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 781218\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-42-35\n",
      "  done: false\n",
      "  episode_len_mean: 92.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.028500000000015\n",
      "  episode_reward_min: -0.7400000000000007\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7548\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3503769318262735\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00726591211437631\n",
      "          policy_loss: -0.02518760391644069\n",
      "          total_loss: 0.0494277438326251\n",
      "          vf_explained_var: 0.9833489060401917\n",
      "          vf_loss: 0.08346368397275607\n",
      "    num_agent_steps_sampled: 781218\n",
      "    num_agent_steps_trained: 781218\n",
      "    num_steps_sampled: 781218\n",
      "    num_steps_trained: 781218\n",
      "  iterations_since_restore: 391\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.23243243243243\n",
      "    ram_util_percent: 30.897297297297293\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432086273452352\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.943069346097563\n",
      "    mean_inference_ms: 2.473864450481762\n",
      "    mean_raw_obs_processing_ms: 2.0344462167590907\n",
      "  time_since_restore: 10631.102082967758\n",
      "  time_this_iter_s: 26.017244815826416\n",
      "  time_total_s: 10631.102082967758\n",
      "  timers:\n",
      "    learn_throughput: 1160.661\n",
      "    learn_time_ms: 1721.433\n",
      "    load_throughput: 58199.848\n",
      "    load_time_ms: 34.33\n",
      "    sample_throughput: 69.116\n",
      "    sample_time_ms: 28907.954\n",
      "    update_time_ms: 9.682\n",
      "  timestamp: 1636440155\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 781218\n",
      "  training_iteration: 391\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   391</td><td style=\"text-align: right;\">         10631.1</td><td style=\"text-align: right;\">781218</td><td style=\"text-align: right;\">  8.0285</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -0.74</td><td style=\"text-align: right;\">             92.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 783216\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-43-01\n",
      "  done: false\n",
      "  episode_len_mean: 92.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.114500000000016\n",
      "  episode_reward_min: -0.7400000000000007\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7569\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3146726148469108\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010011920091866947\n",
      "          policy_loss: -0.06417558599440824\n",
      "          total_loss: 0.09789513211165156\n",
      "          vf_explained_var: 0.9764108061790466\n",
      "          vf_loss: 0.1688025795278095\n",
      "    num_agent_steps_sampled: 783216\n",
      "    num_agent_steps_trained: 783216\n",
      "    num_steps_sampled: 783216\n",
      "    num_steps_trained: 783216\n",
      "  iterations_since_restore: 392\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.56315789473685\n",
      "    ram_util_percent: 31.036842105263162\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432619283120096\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.947581503521068\n",
      "    mean_inference_ms: 2.4739284653977838\n",
      "    mean_raw_obs_processing_ms: 2.044792790175303\n",
      "  time_since_restore: 10657.211933135986\n",
      "  time_this_iter_s: 26.10985016822815\n",
      "  time_total_s: 10657.211933135986\n",
      "  timers:\n",
      "    learn_throughput: 1161.282\n",
      "    learn_time_ms: 1720.512\n",
      "    load_throughput: 58364.821\n",
      "    load_time_ms: 34.233\n",
      "    sample_throughput: 69.104\n",
      "    sample_time_ms: 28913.035\n",
      "    update_time_ms: 9.854\n",
      "  timestamp: 1636440181\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 783216\n",
      "  training_iteration: 392\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   392</td><td style=\"text-align: right;\">         10657.2</td><td style=\"text-align: right;\">783216</td><td style=\"text-align: right;\">  8.1145</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -0.74</td><td style=\"text-align: right;\">             92.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 785214\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-43-27\n",
      "  done: false\n",
      "  episode_len_mean: 94.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.243800000000016\n",
      "  episode_reward_min: -0.7400000000000007\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7589\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2181054938407172\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009479325970725807\n",
      "          policy_loss: -0.05786646178790501\n",
      "          total_loss: 0.04466936026832887\n",
      "          vf_explained_var: 0.9811521768569946\n",
      "          vf_loss: 0.10864325924998237\n",
      "    num_agent_steps_sampled: 785214\n",
      "    num_agent_steps_trained: 785214\n",
      "    num_steps_sampled: 785214\n",
      "    num_steps_trained: 785214\n",
      "  iterations_since_restore: 393\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.19166666666666\n",
      "    ram_util_percent: 31.105555555555554\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433039340487116\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.949707781499583\n",
      "    mean_inference_ms: 2.4739618272711095\n",
      "    mean_raw_obs_processing_ms: 2.0457090848063526\n",
      "  time_since_restore: 10682.956405878067\n",
      "  time_this_iter_s: 25.74447274208069\n",
      "  time_total_s: 10682.956405878067\n",
      "  timers:\n",
      "    learn_throughput: 1160.764\n",
      "    learn_time_ms: 1721.28\n",
      "    load_throughput: 58140.008\n",
      "    load_time_ms: 34.365\n",
      "    sample_throughput: 69.284\n",
      "    sample_time_ms: 28837.84\n",
      "    update_time_ms: 9.845\n",
      "  timestamp: 1636440207\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 785214\n",
      "  training_iteration: 393\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   393</td><td style=\"text-align: right;\">           10683</td><td style=\"text-align: right;\">785214</td><td style=\"text-align: right;\">  8.2438</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -0.74</td><td style=\"text-align: right;\">             94.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 787212\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-43-54\n",
      "  done: false\n",
      "  episode_len_mean: 95.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.462300000000017\n",
      "  episode_reward_min: 2.330000000000018\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 7612\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2461446529343014\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010156137724948928\n",
      "          policy_loss: -0.03961278657828059\n",
      "          total_loss: 0.0742620383699735\n",
      "          vf_explained_var: 0.9844581484794617\n",
      "          vf_loss: 0.11982900395634628\n",
      "    num_agent_steps_sampled: 787212\n",
      "    num_agent_steps_trained: 787212\n",
      "    num_steps_sampled: 787212\n",
      "    num_steps_trained: 787212\n",
      "  iterations_since_restore: 394\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16666666666667\n",
      "    ram_util_percent: 31.16153846153845\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432572252536511\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.955153760376096\n",
      "    mean_inference_ms: 2.4739527836203354\n",
      "    mean_raw_obs_processing_ms: 2.0420614807274755\n",
      "  time_since_restore: 10710.215410232544\n",
      "  time_this_iter_s: 27.25900435447693\n",
      "  time_total_s: 10710.215410232544\n",
      "  timers:\n",
      "    learn_throughput: 1159.945\n",
      "    learn_time_ms: 1722.496\n",
      "    load_throughput: 58263.902\n",
      "    load_time_ms: 34.292\n",
      "    sample_throughput: 68.996\n",
      "    sample_time_ms: 28958.145\n",
      "    update_time_ms: 9.757\n",
      "  timestamp: 1636440234\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 787212\n",
      "  training_iteration: 394\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   394</td><td style=\"text-align: right;\">         10710.2</td><td style=\"text-align: right;\">787212</td><td style=\"text-align: right;\">  8.4623</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.33</td><td style=\"text-align: right;\">             95.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 789210\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-44-20\n",
      "  done: false\n",
      "  episode_len_mean: 96.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.294900000000018\n",
      "  episode_reward_min: 2.330000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7632\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2496220577330817\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008829641443044878\n",
      "          policy_loss: -0.04183430994550387\n",
      "          total_loss: 0.09868319304216476\n",
      "          vf_explained_var: 0.9777666330337524\n",
      "          vf_loss: 0.14735637406508129\n",
      "    num_agent_steps_sampled: 789210\n",
      "    num_agent_steps_trained: 789210\n",
      "    num_steps_sampled: 789210\n",
      "    num_steps_trained: 789210\n",
      "  iterations_since_restore: 395\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.26578947368424\n",
      "    ram_util_percent: 31.213157894736838\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433093260392907\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.960059473450546\n",
      "    mean_inference_ms: 2.4740843117802953\n",
      "    mean_raw_obs_processing_ms: 2.038822957098934\n",
      "  time_since_restore: 10736.391790151596\n",
      "  time_this_iter_s: 26.176379919052124\n",
      "  time_total_s: 10736.391790151596\n",
      "  timers:\n",
      "    learn_throughput: 1160.217\n",
      "    learn_time_ms: 1722.091\n",
      "    load_throughput: 58609.818\n",
      "    load_time_ms: 34.09\n",
      "    sample_throughput: 69.033\n",
      "    sample_time_ms: 28942.775\n",
      "    update_time_ms: 10.742\n",
      "  timestamp: 1636440260\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 789210\n",
      "  training_iteration: 395\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   395</td><td style=\"text-align: right;\">         10736.4</td><td style=\"text-align: right;\">789210</td><td style=\"text-align: right;\">  8.2949</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.33</td><td style=\"text-align: right;\">             96.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 791208\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-44-46\n",
      "  done: false\n",
      "  episode_len_mean: 96.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.136200000000017\n",
      "  episode_reward_min: 2.330000000000018\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7653\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2133542083558582\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010805565424032252\n",
      "          policy_loss: 0.0008126323599190939\n",
      "          total_loss: 0.12000093409525496\n",
      "          vf_explained_var: 0.9755093455314636\n",
      "          vf_loss: 0.12439847209801276\n",
      "    num_agent_steps_sampled: 791208\n",
      "    num_agent_steps_trained: 791208\n",
      "    num_steps_sampled: 791208\n",
      "    num_steps_trained: 791208\n",
      "  iterations_since_restore: 396\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.15945945945946\n",
      "    ram_util_percent: 31.22972972972973\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430849139394391\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.96212878087843\n",
      "    mean_inference_ms: 2.473718714046572\n",
      "    mean_raw_obs_processing_ms: 2.0355835548808345\n",
      "  time_since_restore: 10762.561497926712\n",
      "  time_this_iter_s: 26.169707775115967\n",
      "  time_total_s: 10762.561497926712\n",
      "  timers:\n",
      "    learn_throughput: 1161.063\n",
      "    learn_time_ms: 1720.836\n",
      "    load_throughput: 58493.431\n",
      "    load_time_ms: 34.158\n",
      "    sample_throughput: 69.067\n",
      "    sample_time_ms: 28928.434\n",
      "    update_time_ms: 10.49\n",
      "  timestamp: 1636440286\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 791208\n",
      "  training_iteration: 396\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   396</td><td style=\"text-align: right;\">         10762.6</td><td style=\"text-align: right;\">791208</td><td style=\"text-align: right;\">  8.1362</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.33</td><td style=\"text-align: right;\">             96.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 793206\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-45-13\n",
      "  done: false\n",
      "  episode_len_mean: 95.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.190200000000015\n",
      "  episode_reward_min: 3.2100000000000106\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7673\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2578070328349158\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00980991599676613\n",
      "          policy_loss: 0.015582263239082836\n",
      "          total_loss: 0.12055804723252853\n",
      "          vf_explained_var: 0.9836856126785278\n",
      "          vf_loss: 0.11126841730659916\n",
      "    num_agent_steps_sampled: 793206\n",
      "    num_agent_steps_trained: 793206\n",
      "    num_steps_sampled: 793206\n",
      "    num_steps_trained: 793206\n",
      "  iterations_since_restore: 397\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.16842105263157\n",
      "    ram_util_percent: 31.234210526315785\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431322590184819\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.966627376527775\n",
      "    mean_inference_ms: 2.473865916630014\n",
      "    mean_raw_obs_processing_ms: 2.0323671534195955\n",
      "  time_since_restore: 10788.898158311844\n",
      "  time_this_iter_s: 26.336660385131836\n",
      "  time_total_s: 10788.898158311844\n",
      "  timers:\n",
      "    learn_throughput: 1160.579\n",
      "    learn_time_ms: 1721.554\n",
      "    load_throughput: 58813.551\n",
      "    load_time_ms: 33.972\n",
      "    sample_throughput: 69.056\n",
      "    sample_time_ms: 28932.856\n",
      "    update_time_ms: 10.359\n",
      "  timestamp: 1636440313\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 793206\n",
      "  training_iteration: 397\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   397</td><td style=\"text-align: right;\">         10788.9</td><td style=\"text-align: right;\">793206</td><td style=\"text-align: right;\">  8.1902</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                3.21</td><td style=\"text-align: right;\">             95.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 795204\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-45-38\n",
      "  done: false\n",
      "  episode_len_mean: 95.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 7.900000000000017\n",
      "  episode_reward_min: 2.730000000000016\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7694\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.280493706748599\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01705740267387792\n",
      "          policy_loss: -0.07840974405407905\n",
      "          total_loss: 0.1563767411258249\n",
      "          vf_explained_var: 0.9467495679855347\n",
      "          vf_loss: 0.23666235502986682\n",
      "    num_agent_steps_sampled: 795204\n",
      "    num_agent_steps_trained: 795204\n",
      "    num_steps_sampled: 795204\n",
      "    num_steps_trained: 795204\n",
      "  iterations_since_restore: 398\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.49722222222222\n",
      "    ram_util_percent: 31.125000000000007\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430909855581508\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.970218107711798\n",
      "    mean_inference_ms: 2.4738319320299436\n",
      "    mean_raw_obs_processing_ms: 2.029077719540495\n",
      "  time_since_restore: 10814.5055372715\n",
      "  time_this_iter_s: 25.60737895965576\n",
      "  time_total_s: 10814.5055372715\n",
      "  timers:\n",
      "    learn_throughput: 1161.979\n",
      "    learn_time_ms: 1719.481\n",
      "    load_throughput: 58915.183\n",
      "    load_time_ms: 33.913\n",
      "    sample_throughput: 72.444\n",
      "    sample_time_ms: 27579.843\n",
      "    update_time_ms: 9.238\n",
      "  timestamp: 1636440338\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 795204\n",
      "  training_iteration: 398\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   398</td><td style=\"text-align: right;\">         10814.5</td><td style=\"text-align: right;\">795204</td><td style=\"text-align: right;\">     7.9</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">             95.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 797202\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-46-04\n",
      "  done: false\n",
      "  episode_len_mean: 97.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.202300000000019\n",
      "  episode_reward_min: 2.730000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7714\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2619742631912232\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01052953031928588\n",
      "          policy_loss: -0.008666105195879936\n",
      "          total_loss: 0.17466096923287425\n",
      "          vf_explained_var: 0.9751268029212952\n",
      "          vf_loss: 0.1892003051581837\n",
      "    num_agent_steps_sampled: 797202\n",
      "    num_agent_steps_trained: 797202\n",
      "    num_steps_sampled: 797202\n",
      "    num_steps_trained: 797202\n",
      "  iterations_since_restore: 399\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.33513513513515\n",
      "    ram_util_percent: 31.110810810810815\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431501691369483\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.974054527807088\n",
      "    mean_inference_ms: 2.4739408215822785\n",
      "    mean_raw_obs_processing_ms: 2.025828432135736\n",
      "  time_since_restore: 10840.429582595825\n",
      "  time_this_iter_s: 25.92404532432556\n",
      "  time_total_s: 10840.429582595825\n",
      "  timers:\n",
      "    learn_throughput: 1162.629\n",
      "    learn_time_ms: 1718.518\n",
      "    load_throughput: 59108.705\n",
      "    load_time_ms: 33.802\n",
      "    sample_throughput: 81.845\n",
      "    sample_time_ms: 24412.004\n",
      "    update_time_ms: 9.752\n",
      "  timestamp: 1636440364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 797202\n",
      "  training_iteration: 399\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   399</td><td style=\"text-align: right;\">         10840.4</td><td style=\"text-align: right;\">797202</td><td style=\"text-align: right;\">  8.2023</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">              97.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 799200\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-46-29\n",
      "  done: false\n",
      "  episode_len_mean: 98.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.387100000000016\n",
      "  episode_reward_min: 2.730000000000016\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 7733\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.215387877963838\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01218902167666937\n",
      "          policy_loss: -0.031694786365897884\n",
      "          total_loss: 0.047141453570553236\n",
      "          vf_explained_var: 0.9869619011878967\n",
      "          vf_loss: 0.08318033588251897\n",
      "    num_agent_steps_sampled: 799200\n",
      "    num_agent_steps_trained: 799200\n",
      "    num_steps_sampled: 799200\n",
      "    num_steps_trained: 799200\n",
      "  iterations_since_restore: 400\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.82777777777778\n",
      "    ram_util_percent: 31.125\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432857959058322\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.975515795671512\n",
      "    mean_inference_ms: 2.4741515093410746\n",
      "    mean_raw_obs_processing_ms: 2.0226831854527423\n",
      "  time_since_restore: 10865.288223028183\n",
      "  time_this_iter_s: 24.858640432357788\n",
      "  time_total_s: 10865.288223028183\n",
      "  timers:\n",
      "    learn_throughput: 1163.282\n",
      "    learn_time_ms: 1717.554\n",
      "    load_throughput: 59125.303\n",
      "    load_time_ms: 33.793\n",
      "    sample_throughput: 82.395\n",
      "    sample_time_ms: 24249.179\n",
      "    update_time_ms: 10.043\n",
      "  timestamp: 1636440389\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 799200\n",
      "  training_iteration: 400\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   400</td><td style=\"text-align: right;\">         10865.3</td><td style=\"text-align: right;\">799200</td><td style=\"text-align: right;\">  8.3871</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">              98.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 801198\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-46-54\n",
      "  done: false\n",
      "  episode_len_mean: 99.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.476900000000018\n",
      "  episode_reward_min: 2.730000000000016\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 7752\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2580809258279346\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.018079000780740786\n",
      "          policy_loss: -0.01963418908417225\n",
      "          total_loss: 0.16433963357870068\n",
      "          vf_explained_var: 0.9764898419380188\n",
      "          vf_loss: 0.18497100733220578\n",
      "    num_agent_steps_sampled: 801198\n",
      "    num_agent_steps_trained: 801198\n",
      "    num_steps_sampled: 801198\n",
      "    num_steps_trained: 801198\n",
      "  iterations_since_restore: 401\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.63055555555553\n",
      "    ram_util_percent: 31.049999999999994\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432894120566539\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.979334404419422\n",
      "    mean_inference_ms: 2.4742268376685943\n",
      "    mean_raw_obs_processing_ms: 2.0195154801798214\n",
      "  time_since_restore: 10890.465309858322\n",
      "  time_this_iter_s: 25.17708683013916\n",
      "  time_total_s: 10890.465309858322\n",
      "  timers:\n",
      "    learn_throughput: 1163.932\n",
      "    learn_time_ms: 1716.595\n",
      "    load_throughput: 59114.167\n",
      "    load_time_ms: 33.799\n",
      "    sample_throughput: 82.677\n",
      "    sample_time_ms: 24166.35\n",
      "    update_time_ms: 9.876\n",
      "  timestamp: 1636440414\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 801198\n",
      "  training_iteration: 401\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   401</td><td style=\"text-align: right;\">         10890.5</td><td style=\"text-align: right;\">801198</td><td style=\"text-align: right;\">  8.4769</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">             99.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 803196\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-47-20\n",
      "  done: false\n",
      "  episode_len_mean: 100.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000016\n",
      "  episode_reward_mean: 8.479600000000017\n",
      "  episode_reward_min: 2.730000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7772\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2938916688873654\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009681411585500975\n",
      "          policy_loss: -0.04585397346388726\n",
      "          total_loss: 0.04602900356763885\n",
      "          vf_explained_var: 0.9816805124282837\n",
      "          vf_loss: 0.0986187950264485\n",
      "    num_agent_steps_sampled: 803196\n",
      "    num_agent_steps_trained: 803196\n",
      "    num_steps_sampled: 803196\n",
      "    num_steps_trained: 803196\n",
      "  iterations_since_restore: 402\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.56285714285714\n",
      "    ram_util_percent: 31.025714285714287\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433454237579939\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.97873463002541\n",
      "    mean_inference_ms: 2.4742872353119414\n",
      "    mean_raw_obs_processing_ms: 2.016195517905656\n",
      "  time_since_restore: 10915.513823747635\n",
      "  time_this_iter_s: 25.048513889312744\n",
      "  time_total_s: 10915.513823747635\n",
      "  timers:\n",
      "    learn_throughput: 1163.254\n",
      "    learn_time_ms: 1717.595\n",
      "    load_throughput: 58843.781\n",
      "    load_time_ms: 33.954\n",
      "    sample_throughput: 83.046\n",
      "    sample_time_ms: 24059.036\n",
      "    update_time_ms: 9.793\n",
      "  timestamp: 1636440440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 803196\n",
      "  training_iteration: 402\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   402</td><td style=\"text-align: right;\">         10915.5</td><td style=\"text-align: right;\">803196</td><td style=\"text-align: right;\">  8.4796</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">                2.73</td><td style=\"text-align: right;\">            100.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 805194\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-47-44\n",
      "  done: false\n",
      "  episode_len_mean: 101.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000016\n",
      "  episode_reward_mean: 8.455600000000018\n",
      "  episode_reward_min: 3.010000000000013\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7792\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3185978787285941\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011115792638237264\n",
      "          policy_loss: -0.041504238882944695\n",
      "          total_loss: 0.05638243383949711\n",
      "          vf_explained_var: 0.9778459668159485\n",
      "          vf_loss: 0.10395050944671744\n",
      "    num_agent_steps_sampled: 805194\n",
      "    num_agent_steps_trained: 805194\n",
      "    num_steps_sampled: 805194\n",
      "    num_steps_trained: 805194\n",
      "  iterations_since_restore: 403\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.61666666666665\n",
      "    ram_util_percent: 31.12777777777778\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431826695479621\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.97992985518218\n",
      "    mean_inference_ms: 2.474014238393993\n",
      "    mean_raw_obs_processing_ms: 2.0129544750570427\n",
      "  time_since_restore: 10940.33886051178\n",
      "  time_this_iter_s: 24.825036764144897\n",
      "  time_total_s: 10940.33886051178\n",
      "  timers:\n",
      "    learn_throughput: 1164.985\n",
      "    learn_time_ms: 1715.044\n",
      "    load_throughput: 59006.695\n",
      "    load_time_ms: 33.861\n",
      "    sample_throughput: 83.356\n",
      "    sample_time_ms: 23969.457\n",
      "    update_time_ms: 10.331\n",
      "  timestamp: 1636440464\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 805194\n",
      "  training_iteration: 403\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   403</td><td style=\"text-align: right;\">         10940.3</td><td style=\"text-align: right;\">805194</td><td style=\"text-align: right;\">  8.4556</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">                3.01</td><td style=\"text-align: right;\">            101.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 807192\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-48-09\n",
      "  done: false\n",
      "  episode_len_mean: 101.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.411100000000017\n",
      "  episode_reward_min: 2.740000000000014\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7812\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2801753242810567\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012990378853131038\n",
      "          policy_loss: -0.025966522700729824\n",
      "          total_loss: 0.13356261902621813\n",
      "          vf_explained_var: 0.9745162129402161\n",
      "          vf_loss: 0.1640076658378045\n",
      "    num_agent_steps_sampled: 807192\n",
      "    num_agent_steps_trained: 807192\n",
      "    num_steps_sampled: 807192\n",
      "    num_steps_trained: 807192\n",
      "  iterations_since_restore: 404\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.98333333333335\n",
      "    ram_util_percent: 31.116666666666667\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044331220767043274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.980662105756018\n",
      "    mean_inference_ms: 2.4741409246098582\n",
      "    mean_raw_obs_processing_ms: 2.009604921291676\n",
      "  time_since_restore: 10965.314470767975\n",
      "  time_this_iter_s: 24.97561025619507\n",
      "  time_total_s: 10965.314470767975\n",
      "  timers:\n",
      "    learn_throughput: 1165.861\n",
      "    learn_time_ms: 1713.755\n",
      "    load_throughput: 59094.033\n",
      "    load_time_ms: 33.811\n",
      "    sample_throughput: 84.151\n",
      "    sample_time_ms: 23743.147\n",
      "    update_time_ms: 9.443\n",
      "  timestamp: 1636440489\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 807192\n",
      "  training_iteration: 404\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   404</td><td style=\"text-align: right;\">         10965.3</td><td style=\"text-align: right;\">807192</td><td style=\"text-align: right;\">  8.4111</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">                2.74</td><td style=\"text-align: right;\">            101.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 809190\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-48-50\n",
      "  done: false\n",
      "  episode_len_mean: 100.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.279000000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7832\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.280193333398728\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01349773338481632\n",
      "          policy_loss: 0.000969470664858818\n",
      "          total_loss: 0.4693957239433768\n",
      "          vf_explained_var: 0.9432649612426758\n",
      "          vf_loss: 0.47257987654634886\n",
      "    num_agent_steps_sampled: 809190\n",
      "    num_agent_steps_trained: 809190\n",
      "    num_steps_sampled: 809190\n",
      "    num_steps_trained: 809190\n",
      "  iterations_since_restore: 405\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.26666666666667\n",
      "    ram_util_percent: 31.057894736842105\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432580885530423\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.97937426502829\n",
      "    mean_inference_ms: 2.473934941871995\n",
      "    mean_raw_obs_processing_ms: 2.010711438517827\n",
      "  time_since_restore: 11005.84244465828\n",
      "  time_this_iter_s: 40.527973890304565\n",
      "  time_total_s: 11005.84244465828\n",
      "  timers:\n",
      "    learn_throughput: 1165.693\n",
      "    learn_time_ms: 1714.001\n",
      "    load_throughput: 59002.416\n",
      "    load_time_ms: 33.863\n",
      "    sample_throughput: 79.354\n",
      "    sample_time_ms: 25178.198\n",
      "    update_time_ms: 9.345\n",
      "  timestamp: 1636440530\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 809190\n",
      "  training_iteration: 405\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   405</td><td style=\"text-align: right;\">         11005.8</td><td style=\"text-align: right;\">809190</td><td style=\"text-align: right;\">   8.279</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            100.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 811188\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-49-33\n",
      "  done: false\n",
      "  episode_len_mean: 98.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.384100000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 7854\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.228617787361145\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01376866967884405\n",
      "          policy_loss: -0.018561021770749773\n",
      "          total_loss: 0.1489789008384659\n",
      "          vf_explained_var: 0.9749252796173096\n",
      "          vf_loss: 0.17100420218138468\n",
      "    num_agent_steps_sampled: 811188\n",
      "    num_agent_steps_trained: 811188\n",
      "    num_steps_sampled: 811188\n",
      "    num_steps_trained: 811188\n",
      "  iterations_since_restore: 406\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.95901639344262\n",
      "    ram_util_percent: 30.901639344262303\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433953183804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.977655704515495\n",
      "    mean_inference_ms: 2.4739624478330238\n",
      "    mean_raw_obs_processing_ms: 2.0211514802732604\n",
      "  time_since_restore: 11048.50744009018\n",
      "  time_this_iter_s: 42.664995431900024\n",
      "  time_total_s: 11048.50744009018\n",
      "  timers:\n",
      "    learn_throughput: 1165.474\n",
      "    learn_time_ms: 1714.324\n",
      "    load_throughput: 59207.428\n",
      "    load_time_ms: 33.746\n",
      "    sample_throughput: 74.477\n",
      "    sample_time_ms: 26826.999\n",
      "    update_time_ms: 9.8\n",
      "  timestamp: 1636440573\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 811188\n",
      "  training_iteration: 406\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   406</td><td style=\"text-align: right;\">         11048.5</td><td style=\"text-align: right;\">811188</td><td style=\"text-align: right;\">  8.3841</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 813186\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-49-59\n",
      "  done: false\n",
      "  episode_len_mean: 99.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.539100000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 7873\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.299733733563196\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011082374084094604\n",
      "          policy_loss: -0.04705457086009639\n",
      "          total_loss: 0.108003790703203\n",
      "          vf_explained_var: 0.9779105186462402\n",
      "          vf_loss: 0.16095497044069426\n",
      "    num_agent_steps_sampled: 813186\n",
      "    num_agent_steps_trained: 813186\n",
      "    num_steps_sampled: 813186\n",
      "    num_steps_trained: 813186\n",
      "  iterations_since_restore: 407\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.78157894736842\n",
      "    ram_util_percent: 30.84736842105264\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435336985826712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.97928271694752\n",
      "    mean_inference_ms: 2.4740891661985063\n",
      "    mean_raw_obs_processing_ms: 2.0301303721986828\n",
      "  time_since_restore: 11074.495085954666\n",
      "  time_this_iter_s: 25.987645864486694\n",
      "  time_total_s: 11074.495085954666\n",
      "  timers:\n",
      "    learn_throughput: 1164.619\n",
      "    learn_time_ms: 1715.582\n",
      "    load_throughput: 59017.541\n",
      "    load_time_ms: 33.854\n",
      "    sample_throughput: 74.577\n",
      "    sample_time_ms: 26791.126\n",
      "    update_time_ms: 9.583\n",
      "  timestamp: 1636440599\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 813186\n",
      "  training_iteration: 407\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   407</td><td style=\"text-align: right;\">         11074.5</td><td style=\"text-align: right;\">813186</td><td style=\"text-align: right;\">  8.5391</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 815184\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-50-25\n",
      "  done: false\n",
      "  episode_len_mean: 98.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.935200000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 7894\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2366269117309934\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007872224169970618\n",
      "          policy_loss: -0.09762081010710626\n",
      "          total_loss: -0.017524908917645615\n",
      "          vf_explained_var: 0.9901213049888611\n",
      "          vf_loss: 0.0874182596714014\n",
      "    num_agent_steps_sampled: 815184\n",
      "    num_agent_steps_trained: 815184\n",
      "    num_steps_sampled: 815184\n",
      "    num_steps_trained: 815184\n",
      "  iterations_since_restore: 408\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.62162162162163\n",
      "    ram_util_percent: 31.132432432432427\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044339874342841756\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.981514779756058\n",
      "    mean_inference_ms: 2.473827620372246\n",
      "    mean_raw_obs_processing_ms: 2.0402018458589324\n",
      "  time_since_restore: 11100.6640355587\n",
      "  time_this_iter_s: 26.168949604034424\n",
      "  time_total_s: 11100.6640355587\n",
      "  timers:\n",
      "    learn_throughput: 1164.323\n",
      "    learn_time_ms: 1716.019\n",
      "    load_throughput: 58902.595\n",
      "    load_time_ms: 33.92\n",
      "    sample_throughput: 74.423\n",
      "    sample_time_ms: 26846.655\n",
      "    update_time_ms: 10.026\n",
      "  timestamp: 1636440625\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 815184\n",
      "  training_iteration: 408\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   408</td><td style=\"text-align: right;\">         11100.7</td><td style=\"text-align: right;\">815184</td><td style=\"text-align: right;\">  8.9352</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 817182\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-50-50\n",
      "  done: false\n",
      "  episode_len_mean: 98.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.935400000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7914\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2799547428176516\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009670664596072078\n",
      "          policy_loss: -0.017977344147151426\n",
      "          total_loss: 0.12504560759379751\n",
      "          vf_explained_var: 0.9803187251091003\n",
      "          vf_loss: 0.14962628560052033\n",
      "    num_agent_steps_sampled: 817182\n",
      "    num_agent_steps_trained: 817182\n",
      "    num_steps_sampled: 817182\n",
      "    num_steps_trained: 817182\n",
      "  iterations_since_restore: 409\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.98857142857142\n",
      "    ram_util_percent: 31.197142857142854\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044331743492716846\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.981994782204666\n",
      "    mean_inference_ms: 2.4736592657325884\n",
      "    mean_raw_obs_processing_ms: 2.0497702081117826\n",
      "  time_since_restore: 11125.277481555939\n",
      "  time_this_iter_s: 24.61344599723816\n",
      "  time_total_s: 11125.277481555939\n",
      "  timers:\n",
      "    learn_throughput: 1163.115\n",
      "    learn_time_ms: 1717.802\n",
      "    load_throughput: 59265.169\n",
      "    load_time_ms: 33.713\n",
      "    sample_throughput: 74.792\n",
      "    sample_time_ms: 26714.193\n",
      "    update_time_ms: 9.953\n",
      "  timestamp: 1636440650\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 817182\n",
      "  training_iteration: 409\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   409</td><td style=\"text-align: right;\">         11125.3</td><td style=\"text-align: right;\">817182</td><td style=\"text-align: right;\">  8.9354</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 819180\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-51-16\n",
      "  done: false\n",
      "  episode_len_mean: 98.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.673500000000017\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 7934\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.38279067221142\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008670273432954503\n",
      "          policy_loss: -0.05139267877453849\n",
      "          total_loss: 0.019913162610360555\n",
      "          vf_explained_var: 0.9834539294242859\n",
      "          vf_loss: 0.07957850828589429\n",
      "    num_agent_steps_sampled: 819180\n",
      "    num_agent_steps_trained: 819180\n",
      "    num_steps_sampled: 819180\n",
      "    num_steps_trained: 819180\n",
      "  iterations_since_restore: 410\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.35405405405405\n",
      "    ram_util_percent: 31.227027027027024\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434199967444085\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.984287457807987\n",
      "    mean_inference_ms: 2.473805341884154\n",
      "    mean_raw_obs_processing_ms: 2.0536008416835325\n",
      "  time_since_restore: 11151.334786653519\n",
      "  time_this_iter_s: 26.057305097579956\n",
      "  time_total_s: 11151.334786653519\n",
      "  timers:\n",
      "    learn_throughput: 1162.469\n",
      "    learn_time_ms: 1718.756\n",
      "    load_throughput: 59125.637\n",
      "    load_time_ms: 33.792\n",
      "    sample_throughput: 74.462\n",
      "    sample_time_ms: 26832.36\n",
      "    update_time_ms: 10.437\n",
      "  timestamp: 1636440676\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 819180\n",
      "  training_iteration: 410\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   410</td><td style=\"text-align: right;\">         11151.3</td><td style=\"text-align: right;\">819180</td><td style=\"text-align: right;\">  8.6735</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             98.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 821178\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-51-40\n",
      "  done: false\n",
      "  episode_len_mean: 101.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.664400000000018\n",
      "  episode_reward_min: 2.8000000000000154\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 7952\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2979766039621263\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011813193432445619\n",
      "          policy_loss: -0.0272248621852625\n",
      "          total_loss: 0.0611528115169633\n",
      "          vf_explained_var: 0.9824846386909485\n",
      "          vf_loss: 0.09378845755543028\n",
      "    num_agent_steps_sampled: 821178\n",
      "    num_agent_steps_trained: 821178\n",
      "    num_steps_sampled: 821178\n",
      "    num_steps_trained: 821178\n",
      "  iterations_since_restore: 411\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9235294117647\n",
      "    ram_util_percent: 31.235294117647058\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433334718550189\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.986281058750603\n",
      "    mean_inference_ms: 2.473705460410359\n",
      "    mean_raw_obs_processing_ms: 2.050647304496976\n",
      "  time_since_restore: 11175.140543937683\n",
      "  time_this_iter_s: 23.80575728416443\n",
      "  time_total_s: 11175.140543937683\n",
      "  timers:\n",
      "    learn_throughput: 1162.185\n",
      "    learn_time_ms: 1719.176\n",
      "    load_throughput: 59137.778\n",
      "    load_time_ms: 33.786\n",
      "    sample_throughput: 74.844\n",
      "    sample_time_ms: 26695.499\n",
      "    update_time_ms: 9.808\n",
      "  timestamp: 1636440700\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 821178\n",
      "  training_iteration: 411\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   411</td><td style=\"text-align: right;\">         11175.1</td><td style=\"text-align: right;\">821178</td><td style=\"text-align: right;\">  8.6644</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">                 2.8</td><td style=\"text-align: right;\">            101.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 823176\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-52-03\n",
      "  done: false\n",
      "  episode_len_mean: 101.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.506600000000018\n",
      "  episode_reward_min: 2.920000000000017\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 7971\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4076535065968832\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010901037887165578\n",
      "          policy_loss: -0.027600756252095814\n",
      "          total_loss: 0.12173567596113398\n",
      "          vf_explained_var: 0.9529616832733154\n",
      "          vf_loss: 0.15642842641543775\n",
      "    num_agent_steps_sampled: 823176\n",
      "    num_agent_steps_trained: 823176\n",
      "    num_steps_sampled: 823176\n",
      "    num_steps_trained: 823176\n",
      "  iterations_since_restore: 412\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.31470588235294\n",
      "    ram_util_percent: 31.235294117647058\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433132763114708\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.98536104733132\n",
      "    mean_inference_ms: 2.473671335061358\n",
      "    mean_raw_obs_processing_ms: 2.0474654745170353\n",
      "  time_since_restore: 11198.747519493103\n",
      "  time_this_iter_s: 23.606975555419922\n",
      "  time_total_s: 11198.747519493103\n",
      "  timers:\n",
      "    learn_throughput: 1161.911\n",
      "    learn_time_ms: 1719.58\n",
      "    load_throughput: 59372.281\n",
      "    load_time_ms: 33.652\n",
      "    sample_throughput: 75.252\n",
      "    sample_time_ms: 26550.731\n",
      "    update_time_ms: 9.948\n",
      "  timestamp: 1636440723\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 823176\n",
      "  training_iteration: 412\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   412</td><td style=\"text-align: right;\">         11198.7</td><td style=\"text-align: right;\">823176</td><td style=\"text-align: right;\">  8.5066</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">                2.92</td><td style=\"text-align: right;\">            101.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 825174\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-52-28\n",
      "  done: false\n",
      "  episode_len_mean: 102.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.323900000000018\n",
      "  episode_reward_min: 2.480000000000018\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 7989\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2638321785699753\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008400330113862878\n",
      "          policy_loss: -0.007002430972421453\n",
      "          total_loss: 0.07941056350689558\n",
      "          vf_explained_var: 0.9797884821891785\n",
      "          vf_loss: 0.09366903441647688\n",
      "    num_agent_steps_sampled: 825174\n",
      "    num_agent_steps_trained: 825174\n",
      "    num_steps_sampled: 825174\n",
      "    num_steps_trained: 825174\n",
      "  iterations_since_restore: 413\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.76857142857145\n",
      "    ram_util_percent: 31.27142857142858\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431144758658151\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.985004200688564\n",
      "    mean_inference_ms: 2.473383940258835\n",
      "    mean_raw_obs_processing_ms: 2.044496734601375\n",
      "  time_since_restore: 11223.437396287918\n",
      "  time_this_iter_s: 24.689876794815063\n",
      "  time_total_s: 11223.437396287918\n",
      "  timers:\n",
      "    learn_throughput: 1162.15\n",
      "    learn_time_ms: 1719.227\n",
      "    load_throughput: 59454.589\n",
      "    load_time_ms: 33.605\n",
      "    sample_throughput: 75.29\n",
      "    sample_time_ms: 26537.35\n",
      "    update_time_ms: 10.339\n",
      "  timestamp: 1636440748\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 825174\n",
      "  training_iteration: 413\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   413</td><td style=\"text-align: right;\">         11223.4</td><td style=\"text-align: right;\">825174</td><td style=\"text-align: right;\">  8.3239</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">                2.48</td><td style=\"text-align: right;\">            102.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 827172\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-52-52\n",
      "  done: false\n",
      "  episode_len_mean: 104.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.610000000000015\n",
      "  episode_reward_mean: 8.14640000000002\n",
      "  episode_reward_min: 2.480000000000018\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8010\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1841094468321118\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015791900808864816\n",
      "          policy_loss: 0.01256749461449328\n",
      "          total_loss: 0.24537519751826212\n",
      "          vf_explained_var: 0.9734530448913574\n",
      "          vf_loss: 0.23453056964845884\n",
      "    num_agent_steps_sampled: 827172\n",
      "    num_agent_steps_trained: 827172\n",
      "    num_steps_sampled: 827172\n",
      "    num_steps_trained: 827172\n",
      "  iterations_since_restore: 414\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.34571428571428\n",
      "    ram_util_percent: 31.325714285714287\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432400318140942\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.981753853396995\n",
      "    mean_inference_ms: 2.4735890997846055\n",
      "    mean_raw_obs_processing_ms: 2.040828452196808\n",
      "  time_since_restore: 11247.996111392975\n",
      "  time_this_iter_s: 24.558715105056763\n",
      "  time_total_s: 11247.996111392975\n",
      "  timers:\n",
      "    learn_throughput: 1161.938\n",
      "    learn_time_ms: 1719.541\n",
      "    load_throughput: 59351.467\n",
      "    load_time_ms: 33.664\n",
      "    sample_throughput: 75.411\n",
      "    sample_time_ms: 26494.95\n",
      "    update_time_ms: 10.834\n",
      "  timestamp: 1636440772\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 827172\n",
      "  training_iteration: 414\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   414</td><td style=\"text-align: right;\">           11248</td><td style=\"text-align: right;\">827172</td><td style=\"text-align: right;\">  8.1464</td><td style=\"text-align: right;\">               14.61</td><td style=\"text-align: right;\">                2.48</td><td style=\"text-align: right;\">            104.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 829170\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-53-17\n",
      "  done: false\n",
      "  episode_len_mean: 104.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.610000000000015\n",
      "  episode_reward_mean: 8.626200000000019\n",
      "  episode_reward_min: 2.480000000000018\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 8028\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3123393881888616\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012713521346719723\n",
      "          policy_loss: -0.03468669963379701\n",
      "          total_loss: 0.19047703651622647\n",
      "          vf_explained_var: 0.9542067646980286\n",
      "          vf_loss: 0.23014128963862146\n",
      "    num_agent_steps_sampled: 829170\n",
      "    num_agent_steps_trained: 829170\n",
      "    num_steps_sampled: 829170\n",
      "    num_steps_trained: 829170\n",
      "  iterations_since_restore: 415\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99999999999999\n",
      "    ram_util_percent: 31.34285714285715\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430313591020134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.980357127873454\n",
      "    mean_inference_ms: 2.473323020501687\n",
      "    mean_raw_obs_processing_ms: 2.0378321646470225\n",
      "  time_since_restore: 11272.025898456573\n",
      "  time_this_iter_s: 24.029787063598633\n",
      "  time_total_s: 11272.025898456573\n",
      "  timers:\n",
      "    learn_throughput: 1160.604\n",
      "    learn_time_ms: 1721.518\n",
      "    load_throughput: 59261.691\n",
      "    load_time_ms: 33.715\n",
      "    sample_throughput: 80.426\n",
      "    sample_time_ms: 24842.823\n",
      "    update_time_ms: 10.797\n",
      "  timestamp: 1636440797\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 829170\n",
      "  training_iteration: 415\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   415</td><td style=\"text-align: right;\">           11272</td><td style=\"text-align: right;\">829170</td><td style=\"text-align: right;\">  8.6262</td><td style=\"text-align: right;\">               14.61</td><td style=\"text-align: right;\">                2.48</td><td style=\"text-align: right;\">            104.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 831168\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-53-41\n",
      "  done: false\n",
      "  episode_len_mean: 104.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.610000000000015\n",
      "  episode_reward_mean: 8.299500000000021\n",
      "  episode_reward_min: 2.480000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8048\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.368442367939722\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011503087752780632\n",
      "          policy_loss: -0.016977501997635477\n",
      "          total_loss: 0.0576338257817995\n",
      "          vf_explained_var: 0.9809182286262512\n",
      "          vf_loss: 0.08092546328192665\n",
      "    num_agent_steps_sampled: 831168\n",
      "    num_agent_steps_trained: 831168\n",
      "    num_steps_sampled: 831168\n",
      "    num_steps_trained: 831168\n",
      "  iterations_since_restore: 416\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.67428571428572\n",
      "    ram_util_percent: 31.237142857142857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430663773188756\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.976133487690067\n",
      "    mean_inference_ms: 2.4734023084437537\n",
      "    mean_raw_obs_processing_ms: 2.0343937442027396\n",
      "  time_since_restore: 11296.485966444016\n",
      "  time_this_iter_s: 24.460067987442017\n",
      "  time_total_s: 11296.485966444016\n",
      "  timers:\n",
      "    learn_throughput: 1159.584\n",
      "    learn_time_ms: 1723.032\n",
      "    load_throughput: 58950.908\n",
      "    load_time_ms: 33.893\n",
      "    sample_throughput: 86.788\n",
      "    sample_time_ms: 23021.537\n",
      "    update_time_ms: 9.753\n",
      "  timestamp: 1636440821\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 831168\n",
      "  training_iteration: 416\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   416</td><td style=\"text-align: right;\">         11296.5</td><td style=\"text-align: right;\">831168</td><td style=\"text-align: right;\">  8.2995</td><td style=\"text-align: right;\">               14.61</td><td style=\"text-align: right;\">                2.48</td><td style=\"text-align: right;\">             104.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 833166\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-54-05\n",
      "  done: false\n",
      "  episode_len_mean: 105.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.610000000000015\n",
      "  episode_reward_mean: 8.61700000000002\n",
      "  episode_reward_min: 2.480000000000018\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 8066\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2639183895928519\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010495470195156516\n",
      "          policy_loss: -0.03882918863424233\n",
      "          total_loss: 0.08171698105122362\n",
      "          vf_explained_var: 0.9788516759872437\n",
      "          vf_loss: 0.12646066573049342\n",
      "    num_agent_steps_sampled: 833166\n",
      "    num_agent_steps_trained: 833166\n",
      "    num_steps_sampled: 833166\n",
      "    num_steps_trained: 833166\n",
      "  iterations_since_restore: 417\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.17352941176469\n",
      "    ram_util_percent: 31.2235294117647\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428713683042984\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.974601087906805\n",
      "    mean_inference_ms: 2.473148427789696\n",
      "    mean_raw_obs_processing_ms: 2.031411414432826\n",
      "  time_since_restore: 11320.666223049164\n",
      "  time_this_iter_s: 24.180256605148315\n",
      "  time_total_s: 11320.666223049164\n",
      "  timers:\n",
      "    learn_throughput: 1159.75\n",
      "    learn_time_ms: 1722.785\n",
      "    load_throughput: 59193.376\n",
      "    load_time_ms: 33.754\n",
      "    sample_throughput: 87.473\n",
      "    sample_time_ms: 22841.231\n",
      "    update_time_ms: 9.701\n",
      "  timestamp: 1636440845\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 833166\n",
      "  training_iteration: 417\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   417</td><td style=\"text-align: right;\">         11320.7</td><td style=\"text-align: right;\">833166</td><td style=\"text-align: right;\">   8.617</td><td style=\"text-align: right;\">               14.61</td><td style=\"text-align: right;\">                2.48</td><td style=\"text-align: right;\">            105.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 835164\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-54-31\n",
      "  done: false\n",
      "  episode_len_mean: 104.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.610000000000015\n",
      "  episode_reward_mean: 8.706300000000018\n",
      "  episode_reward_min: 2.690000000000021\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8087\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3064576552027747\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010793478106858686\n",
      "          policy_loss: -0.0004863884122598739\n",
      "          total_loss: 0.11826232217607044\n",
      "          vf_explained_var: 0.9777764678001404\n",
      "          vf_loss: 0.1248976606875658\n",
      "    num_agent_steps_sampled: 835164\n",
      "    num_agent_steps_trained: 835164\n",
      "    num_steps_sampled: 835164\n",
      "    num_steps_trained: 835164\n",
      "  iterations_since_restore: 418\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.37027027027028\n",
      "    ram_util_percent: 31.22432432432432\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044318887185400745\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.970167409822388\n",
      "    mean_inference_ms: 2.4736358415513506\n",
      "    mean_raw_obs_processing_ms: 2.0277573827984456\n",
      "  time_since_restore: 11346.231523275375\n",
      "  time_this_iter_s: 25.565300226211548\n",
      "  time_total_s: 11346.231523275375\n",
      "  timers:\n",
      "    learn_throughput: 1161.216\n",
      "    learn_time_ms: 1720.61\n",
      "    load_throughput: 58629.172\n",
      "    load_time_ms: 34.079\n",
      "    sample_throughput: 87.698\n",
      "    sample_time_ms: 22782.84\n",
      "    update_time_ms: 9.563\n",
      "  timestamp: 1636440871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 835164\n",
      "  training_iteration: 418\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   418</td><td style=\"text-align: right;\">         11346.2</td><td style=\"text-align: right;\">835164</td><td style=\"text-align: right;\">  8.7063</td><td style=\"text-align: right;\">               14.61</td><td style=\"text-align: right;\">                2.69</td><td style=\"text-align: right;\">            104.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 837162\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-54-55\n",
      "  done: false\n",
      "  episode_len_mean: 105.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000016\n",
      "  episode_reward_mean: 8.56260000000002\n",
      "  episode_reward_min: 2.690000000000021\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 8104\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2993343551953633\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013266224586929505\n",
      "          policy_loss: -0.055401390480498476\n",
      "          total_loss: 0.07014920947452387\n",
      "          vf_explained_var: 0.9744377732276917\n",
      "          vf_loss: 0.13004397341892832\n",
      "    num_agent_steps_sampled: 837162\n",
      "    num_agent_steps_trained: 837162\n",
      "    num_steps_sampled: 837162\n",
      "    num_steps_trained: 837162\n",
      "  iterations_since_restore: 419\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.01764705882353\n",
      "    ram_util_percent: 31.226470588235294\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428636947010363\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.972098114257978\n",
      "    mean_inference_ms: 2.4731996723663214\n",
      "    mean_raw_obs_processing_ms: 2.0249982098119723\n",
      "  time_since_restore: 11370.176524162292\n",
      "  time_this_iter_s: 23.945000886917114\n",
      "  time_total_s: 11370.176524162292\n",
      "  timers:\n",
      "    learn_throughput: 1161.288\n",
      "    learn_time_ms: 1720.503\n",
      "    load_throughput: 58273.504\n",
      "    load_time_ms: 34.287\n",
      "    sample_throughput: 87.957\n",
      "    sample_time_ms: 22715.748\n",
      "    update_time_ms: 9.825\n",
      "  timestamp: 1636440895\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 837162\n",
      "  training_iteration: 419\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   419</td><td style=\"text-align: right;\">         11370.2</td><td style=\"text-align: right;\">837162</td><td style=\"text-align: right;\">  8.5626</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">                2.69</td><td style=\"text-align: right;\">            105.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 839160\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-55-17\n",
      "  done: false\n",
      "  episode_len_mean: 106.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000016\n",
      "  episode_reward_mean: 8.182000000000022\n",
      "  episode_reward_min: 2.690000000000021\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 8122\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3534541856674922\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011876924432008383\n",
      "          policy_loss: -0.031938826275013744\n",
      "          total_loss: 0.09033903788243021\n",
      "          vf_explained_var: 0.9702147841453552\n",
      "          vf_loss: 0.12820259167679718\n",
      "    num_agent_steps_sampled: 839160\n",
      "    num_agent_steps_trained: 839160\n",
      "    num_steps_sampled: 839160\n",
      "    num_steps_trained: 839160\n",
      "  iterations_since_restore: 420\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.18749999999999\n",
      "    ram_util_percent: 31.118750000000002\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044285580510435504\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.96875543896671\n",
      "    mean_inference_ms: 2.473181767509084\n",
      "    mean_raw_obs_processing_ms: 2.0218952393252025\n",
      "  time_since_restore: 11392.799294948578\n",
      "  time_this_iter_s: 22.6227707862854\n",
      "  time_total_s: 11392.799294948578\n",
      "  timers:\n",
      "    learn_throughput: 1160.725\n",
      "    learn_time_ms: 1721.338\n",
      "    load_throughput: 58479.431\n",
      "    load_time_ms: 34.166\n",
      "    sample_throughput: 89.308\n",
      "    sample_time_ms: 22372.017\n",
      "    update_time_ms: 9.494\n",
      "  timestamp: 1636440917\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 839160\n",
      "  training_iteration: 420\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   420</td><td style=\"text-align: right;\">         11392.8</td><td style=\"text-align: right;\">839160</td><td style=\"text-align: right;\">   8.182</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">                2.69</td><td style=\"text-align: right;\">            106.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 841158\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 105.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.368400000000019\n",
      "  episode_reward_min: 2.690000000000021\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8142\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3343083319209872\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011040620727712813\n",
      "          policy_loss: 0.013219636394864037\n",
      "          total_loss: 0.1218098952568003\n",
      "          vf_explained_var: 0.9804270267486572\n",
      "          vf_loss: 0.11485936721520765\n",
      "    num_agent_steps_sampled: 841158\n",
      "    num_agent_steps_trained: 841158\n",
      "    num_steps_sampled: 841158\n",
      "    num_steps_trained: 841158\n",
      "  iterations_since_restore: 421\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.17297297297297\n",
      "    ram_util_percent: 31.116216216216216\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428395007065309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.966176717428162\n",
      "    mean_inference_ms: 2.473159490495428\n",
      "    mean_raw_obs_processing_ms: 2.018502387469658\n",
      "  time_since_restore: 11418.50495481491\n",
      "  time_this_iter_s: 25.705659866333008\n",
      "  time_total_s: 11418.50495481491\n",
      "  timers:\n",
      "    learn_throughput: 1161.438\n",
      "    learn_time_ms: 1720.281\n",
      "    load_throughput: 58585.767\n",
      "    load_time_ms: 34.104\n",
      "    sample_throughput: 88.553\n",
      "    sample_time_ms: 22562.825\n",
      "    update_time_ms: 9.453\n",
      "  timestamp: 1636440943\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 841158\n",
      "  training_iteration: 421\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   421</td><td style=\"text-align: right;\">         11418.5</td><td style=\"text-align: right;\">841158</td><td style=\"text-align: right;\">  8.3684</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">                2.69</td><td style=\"text-align: right;\">            105.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 843156\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-56-08\n",
      "  done: false\n",
      "  episode_len_mean: 103.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.524100000000018\n",
      "  episode_reward_min: 2.690000000000021\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8162\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2740879626501174\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013632453036077902\n",
      "          policy_loss: -0.033308087129678046\n",
      "          total_loss: 0.13723059195492948\n",
      "          vf_explained_var: 0.9765623807907104\n",
      "          vf_loss: 0.17454493624113854\n",
      "    num_agent_steps_sampled: 843156\n",
      "    num_agent_steps_trained: 843156\n",
      "    num_steps_sampled: 843156\n",
      "    num_steps_trained: 843156\n",
      "  iterations_since_restore: 422\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9777777777778\n",
      "    ram_util_percent: 31.09444444444445\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430743741541528\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.96208806377157\n",
      "    mean_inference_ms: 2.4734819780449304\n",
      "    mean_raw_obs_processing_ms: 2.015084862161185\n",
      "  time_since_restore: 11443.578517198563\n",
      "  time_this_iter_s: 25.073562383651733\n",
      "  time_total_s: 11443.578517198563\n",
      "  timers:\n",
      "    learn_throughput: 1162.329\n",
      "    learn_time_ms: 1718.963\n",
      "    load_throughput: 58519.696\n",
      "    load_time_ms: 34.142\n",
      "    sample_throughput: 87.973\n",
      "    sample_time_ms: 22711.457\n",
      "    update_time_ms: 8.989\n",
      "  timestamp: 1636440968\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 843156\n",
      "  training_iteration: 422\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   422</td><td style=\"text-align: right;\">         11443.6</td><td style=\"text-align: right;\">843156</td><td style=\"text-align: right;\">  8.5241</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">                2.69</td><td style=\"text-align: right;\">            103.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 845154\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-56-51\n",
      "  done: false\n",
      "  episode_len_mean: 102.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.881300000000019\n",
      "  episode_reward_min: 3.5100000000000224\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8183\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2350294056392852\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009248174845749387\n",
      "          policy_loss: -0.05160268202778839\n",
      "          total_loss: 0.028123614192008973\n",
      "          vf_explained_var: 0.9883455038070679\n",
      "          vf_loss: 0.08615107635656992\n",
      "    num_agent_steps_sampled: 845154\n",
      "    num_agent_steps_trained: 845154\n",
      "    num_steps_sampled: 845154\n",
      "    num_steps_trained: 845154\n",
      "  iterations_since_restore: 423\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.35666666666667\n",
      "    ram_util_percent: 30.98\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428948326426738\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.962366969351542\n",
      "    mean_inference_ms: 2.4731983911993503\n",
      "    mean_raw_obs_processing_ms: 2.0162625626074386\n",
      "  time_since_restore: 11486.128916978836\n",
      "  time_this_iter_s: 42.55039978027344\n",
      "  time_total_s: 11486.128916978836\n",
      "  timers:\n",
      "    learn_throughput: 1159.715\n",
      "    learn_time_ms: 1722.836\n",
      "    load_throughput: 58463.642\n",
      "    load_time_ms: 34.175\n",
      "    sample_throughput: 81.573\n",
      "    sample_time_ms: 24493.314\n",
      "    update_time_ms: 9.234\n",
      "  timestamp: 1636441011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 845154\n",
      "  training_iteration: 423\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   423</td><td style=\"text-align: right;\">         11486.1</td><td style=\"text-align: right;\">845154</td><td style=\"text-align: right;\">  8.8813</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">                3.51</td><td style=\"text-align: right;\">            102.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 847152\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-57-16\n",
      "  done: false\n",
      "  episode_len_mean: 101.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.934400000000018\n",
      "  episode_reward_min: 4.130000000000017\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8203\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2445553038801467\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017085167369654628\n",
      "          policy_loss: -0.03744042838613192\n",
      "          total_loss: 0.18421849005279087\n",
      "          vf_explained_var: 0.971994161605835\n",
      "          vf_loss: 0.22315761744976043\n",
      "    num_agent_steps_sampled: 847152\n",
      "    num_agent_steps_trained: 847152\n",
      "    num_steps_sampled: 847152\n",
      "    num_steps_trained: 847152\n",
      "  iterations_since_restore: 424\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.52702702702702\n",
      "    ram_util_percent: 31.01081081081082\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443297810941967\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.958485941666453\n",
      "    mean_inference_ms: 2.473753667658508\n",
      "    mean_raw_obs_processing_ms: 2.016320143736654\n",
      "  time_since_restore: 11511.467716217041\n",
      "  time_this_iter_s: 25.338799238204956\n",
      "  time_total_s: 11511.467716217041\n",
      "  timers:\n",
      "    learn_throughput: 1160.082\n",
      "    learn_time_ms: 1722.291\n",
      "    load_throughput: 58831.016\n",
      "    load_time_ms: 33.962\n",
      "    sample_throughput: 81.311\n",
      "    sample_time_ms: 24572.362\n",
      "    update_time_ms: 9.209\n",
      "  timestamp: 1636441036\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 847152\n",
      "  training_iteration: 424\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   424</td><td style=\"text-align: right;\">         11511.5</td><td style=\"text-align: right;\">847152</td><td style=\"text-align: right;\">  8.9344</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">                4.13</td><td style=\"text-align: right;\">            101.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 849150\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 100.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.929700000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 8222\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3041784746306284\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013029803489814877\n",
      "          policy_loss: -0.01962471501458259\n",
      "          total_loss: 0.2063611042951899\n",
      "          vf_explained_var: 0.9402035474777222\n",
      "          vf_loss: 0.23067911137782393\n",
      "    num_agent_steps_sampled: 849150\n",
      "    num_agent_steps_trained: 849150\n",
      "    num_steps_sampled: 849150\n",
      "    num_steps_trained: 849150\n",
      "  iterations_since_restore: 425\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.15614035087718\n",
      "    ram_util_percent: 30.922807017543857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044346131902448696\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.957570663779528\n",
      "    mean_inference_ms: 2.473943242887291\n",
      "    mean_raw_obs_processing_ms: 2.02420247850791\n",
      "  time_since_restore: 11551.805431604385\n",
      "  time_this_iter_s: 40.33771538734436\n",
      "  time_total_s: 11551.805431604385\n",
      "  timers:\n",
      "    learn_throughput: 1157.992\n",
      "    learn_time_ms: 1725.4\n",
      "    load_throughput: 59287.937\n",
      "    load_time_ms: 33.7\n",
      "    sample_throughput: 76.256\n",
      "    sample_time_ms: 26201.08\n",
      "    update_time_ms: 8.533\n",
      "  timestamp: 1636441077\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 849150\n",
      "  training_iteration: 425\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   425</td><td style=\"text-align: right;\">         11551.8</td><td style=\"text-align: right;\">849150</td><td style=\"text-align: right;\">  8.9297</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            100.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 851148\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-58-26\n",
      "  done: false\n",
      "  episode_len_mean: 100.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 8.824600000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 8241\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2948133724076407\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011209170393913379\n",
      "          policy_loss: -0.06652404630468005\n",
      "          total_loss: 0.13513188254797742\n",
      "          vf_explained_var: 0.9644115567207336\n",
      "          vf_loss: 0.20742209135066894\n",
      "    num_agent_steps_sampled: 851148\n",
      "    num_agent_steps_trained: 851148\n",
      "    num_steps_sampled: 851148\n",
      "    num_steps_trained: 851148\n",
      "  iterations_since_restore: 426\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.47380952380954\n",
      "    ram_util_percent: 30.69285714285715\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435508539819619\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.95882610916609\n",
      "    mean_inference_ms: 2.474042173161329\n",
      "    mean_raw_obs_processing_ms: 2.0320953546891785\n",
      "  time_since_restore: 11581.137467861176\n",
      "  time_this_iter_s: 29.33203625679016\n",
      "  time_total_s: 11581.137467861176\n",
      "  timers:\n",
      "    learn_throughput: 1158.442\n",
      "    learn_time_ms: 1724.731\n",
      "    load_throughput: 59483.328\n",
      "    load_time_ms: 33.589\n",
      "    sample_throughput: 74.861\n",
      "    sample_time_ms: 26689.443\n",
      "    update_time_ms: 8.34\n",
      "  timestamp: 1636441106\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 851148\n",
      "  training_iteration: 426\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   426</td><td style=\"text-align: right;\">         11581.1</td><td style=\"text-align: right;\">851148</td><td style=\"text-align: right;\">  8.8246</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             100.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 853146\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-58-51\n",
      "  done: false\n",
      "  episode_len_mean: 100.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.377700000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8261\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.257682112285069\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010802077875397623\n",
      "          policy_loss: -0.018697171702626206\n",
      "          total_loss: 0.1384780718634526\n",
      "          vf_explained_var: 0.9639459252357483\n",
      "          vf_loss: 0.16283092981293087\n",
      "    num_agent_steps_sampled: 853146\n",
      "    num_agent_steps_trained: 853146\n",
      "    num_steps_sampled: 853146\n",
      "    num_steps_trained: 853146\n",
      "  iterations_since_restore: 427\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88571428571427\n",
      "    ram_util_percent: 30.92285714285714\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433811425002908\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.96025824332501\n",
      "    mean_inference_ms: 2.4737384461853855\n",
      "    mean_raw_obs_processing_ms: 2.0404376753744184\n",
      "  time_since_restore: 11605.714494228363\n",
      "  time_this_iter_s: 24.5770263671875\n",
      "  time_total_s: 11605.714494228363\n",
      "  timers:\n",
      "    learn_throughput: 1158.866\n",
      "    learn_time_ms: 1724.099\n",
      "    load_throughput: 59170.515\n",
      "    load_time_ms: 33.767\n",
      "    sample_throughput: 74.748\n",
      "    sample_time_ms: 26729.939\n",
      "    update_time_ms: 8.184\n",
      "  timestamp: 1636441131\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 853146\n",
      "  training_iteration: 427\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   427</td><td style=\"text-align: right;\">         11605.7</td><td style=\"text-align: right;\">853146</td><td style=\"text-align: right;\">  8.3777</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            100.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 855144\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-59-17\n",
      "  done: false\n",
      "  episode_len_mean: 100.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 7.935800000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8282\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2540054168019976\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016466703702715062\n",
      "          policy_loss: -0.05314311259204433\n",
      "          total_loss: 0.43246833106414195\n",
      "          vf_explained_var: 0.9183961153030396\n",
      "          vf_loss: 0.48760090778980936\n",
      "    num_agent_steps_sampled: 855144\n",
      "    num_agent_steps_trained: 855144\n",
      "    num_steps_sampled: 855144\n",
      "    num_steps_trained: 855144\n",
      "  iterations_since_restore: 428\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89736842105263\n",
      "    ram_util_percent: 31.10789473684211\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435510511475377\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.959267335671026\n",
      "    mean_inference_ms: 2.473926074004626\n",
      "    mean_raw_obs_processing_ms: 2.045106288717893\n",
      "  time_since_restore: 11632.14903831482\n",
      "  time_this_iter_s: 26.4345440864563\n",
      "  time_total_s: 11632.14903831482\n",
      "  timers:\n",
      "    learn_throughput: 1157.71\n",
      "    learn_time_ms: 1725.821\n",
      "    load_throughput: 59746.515\n",
      "    load_time_ms: 33.441\n",
      "    sample_throughput: 74.51\n",
      "    sample_time_ms: 26815.363\n",
      "    update_time_ms: 8.235\n",
      "  timestamp: 1636441157\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 855144\n",
      "  training_iteration: 428\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   428</td><td style=\"text-align: right;\">         11632.1</td><td style=\"text-align: right;\">855144</td><td style=\"text-align: right;\">  7.9358</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            100.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 857142\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_06-59-42\n",
      "  done: false\n",
      "  episode_len_mean: 100.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 7.644000000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8302\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3736466498602005\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012046689950730402\n",
      "          policy_loss: -0.0406065560167744\n",
      "          total_loss: 0.14135994128882884\n",
      "          vf_explained_var: 0.9644603729248047\n",
      "          vf_loss: 0.1879843771457672\n",
      "    num_agent_steps_sampled: 857142\n",
      "    num_agent_steps_trained: 857142\n",
      "    num_steps_sampled: 857142\n",
      "    num_steps_trained: 857142\n",
      "  iterations_since_restore: 429\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.60833333333333\n",
      "    ram_util_percent: 31.19722222222222\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433761450807028\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.95869239415559\n",
      "    mean_inference_ms: 2.4735505483773017\n",
      "    mean_raw_obs_processing_ms: 2.0500857865413264\n",
      "  time_since_restore: 11657.418368339539\n",
      "  time_this_iter_s: 25.26933002471924\n",
      "  time_total_s: 11657.418368339539\n",
      "  timers:\n",
      "    learn_throughput: 1159.113\n",
      "    learn_time_ms: 1723.731\n",
      "    load_throughput: 59623.665\n",
      "    load_time_ms: 33.51\n",
      "    sample_throughput: 74.136\n",
      "    sample_time_ms: 26950.411\n",
      "    update_time_ms: 7.647\n",
      "  timestamp: 1636441182\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 857142\n",
      "  training_iteration: 429\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   429</td><td style=\"text-align: right;\">         11657.4</td><td style=\"text-align: right;\">857142</td><td style=\"text-align: right;\">   7.644</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            100.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 859140\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-00-08\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 7.895300000000017\n",
      "  episode_reward_min: 2.660000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8322\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3226481630688622\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010547889684290842\n",
      "          policy_loss: -0.0341452664562634\n",
      "          total_loss: 0.13722724876410905\n",
      "          vf_explained_var: 0.9684545397758484\n",
      "          vf_loss: 0.17784072620173294\n",
      "    num_agent_steps_sampled: 859140\n",
      "    num_agent_steps_trained: 859140\n",
      "    num_steps_sampled: 859140\n",
      "    num_steps_trained: 859140\n",
      "  iterations_since_restore: 430\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.51666666666667\n",
      "    ram_util_percent: 31.188888888888886\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433776708480083\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.960500328577726\n",
      "    mean_inference_ms: 2.4735270723323772\n",
      "    mean_raw_obs_processing_ms: 2.0469098106868544\n",
      "  time_since_restore: 11682.774816036224\n",
      "  time_this_iter_s: 25.35644769668579\n",
      "  time_total_s: 11682.774816036224\n",
      "  timers:\n",
      "    learn_throughput: 1159.637\n",
      "    learn_time_ms: 1722.954\n",
      "    load_throughput: 59478.093\n",
      "    load_time_ms: 33.592\n",
      "    sample_throughput: 73.389\n",
      "    sample_time_ms: 27224.627\n",
      "    update_time_ms: 7.549\n",
      "  timestamp: 1636441208\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 859140\n",
      "  training_iteration: 430\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   430</td><td style=\"text-align: right;\">         11682.8</td><td style=\"text-align: right;\">859140</td><td style=\"text-align: right;\">  7.8953</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.66</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 861138\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-00-32\n",
      "  done: false\n",
      "  episode_len_mean: 99.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.275300000000017\n",
      "  episode_reward_min: 2.660000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8342\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2728734731674194\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01261414682110077\n",
      "          policy_loss: -0.037955029770022346\n",
      "          total_loss: 0.17698948079099258\n",
      "          vf_explained_var: 0.9669911861419678\n",
      "          vf_loss: 0.21959107763000896\n",
      "    num_agent_steps_sampled: 861138\n",
      "    num_agent_steps_trained: 861138\n",
      "    num_steps_sampled: 861138\n",
      "    num_steps_trained: 861138\n",
      "  iterations_since_restore: 431\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.05714285714285\n",
      "    ram_util_percent: 31.228571428571428\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044329787070305236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.96066042240415\n",
      "    mean_inference_ms: 2.473347533315473\n",
      "    mean_raw_obs_processing_ms: 2.043844161759768\n",
      "  time_since_restore: 11707.019337892532\n",
      "  time_this_iter_s: 24.244521856307983\n",
      "  time_total_s: 11707.019337892532\n",
      "  timers:\n",
      "    learn_throughput: 1159.428\n",
      "    learn_time_ms: 1723.263\n",
      "    load_throughput: 59336.632\n",
      "    load_time_ms: 33.672\n",
      "    sample_throughput: 73.788\n",
      "    sample_time_ms: 27077.493\n",
      "    update_time_ms: 8.275\n",
      "  timestamp: 1636441232\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 861138\n",
      "  training_iteration: 431\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   431</td><td style=\"text-align: right;\">           11707</td><td style=\"text-align: right;\">861138</td><td style=\"text-align: right;\">  8.2753</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.66</td><td style=\"text-align: right;\">             99.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 863136\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-00-58\n",
      "  done: false\n",
      "  episode_len_mean: 99.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.713000000000017\n",
      "  episode_reward_min: 2.660000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8362\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2432118787651971\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01322413916937298\n",
      "          policy_loss: -0.02172368899697349\n",
      "          total_loss: 0.17028282664804942\n",
      "          vf_explained_var: 0.9657986164093018\n",
      "          vf_loss: 0.19596562818402335\n",
      "    num_agent_steps_sampled: 863136\n",
      "    num_agent_steps_trained: 863136\n",
      "    num_steps_sampled: 863136\n",
      "    num_steps_trained: 863136\n",
      "  iterations_since_restore: 432\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6\n",
      "    ram_util_percent: 31.23783783783783\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044347313541340236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.960365807337293\n",
      "    mean_inference_ms: 2.473571453897942\n",
      "    mean_raw_obs_processing_ms: 2.0407367650238255\n",
      "  time_since_restore: 11733.069669008255\n",
      "  time_this_iter_s: 26.050331115722656\n",
      "  time_total_s: 11733.069669008255\n",
      "  timers:\n",
      "    learn_throughput: 1158.947\n",
      "    learn_time_ms: 1723.978\n",
      "    load_throughput: 59099.201\n",
      "    load_time_ms: 33.808\n",
      "    sample_throughput: 73.526\n",
      "    sample_time_ms: 27174.21\n",
      "    update_time_ms: 8.359\n",
      "  timestamp: 1636441258\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 863136\n",
      "  training_iteration: 432\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   432</td><td style=\"text-align: right;\">         11733.1</td><td style=\"text-align: right;\">863136</td><td style=\"text-align: right;\">   8.713</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.66</td><td style=\"text-align: right;\">             99.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 865134\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-01-22\n",
      "  done: false\n",
      "  episode_len_mean: 100.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.923800000000018\n",
      "  episode_reward_min: 2.660000000000018\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 8381\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2472948196388427\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01186958005634111\n",
      "          policy_loss: -0.03293538978766827\n",
      "          total_loss: 0.15816703220563275\n",
      "          vf_explained_var: 0.9772840142250061\n",
      "          vf_loss: 0.19597026198392822\n",
      "    num_agent_steps_sampled: 865134\n",
      "    num_agent_steps_trained: 865134\n",
      "    num_steps_sampled: 865134\n",
      "    num_steps_trained: 865134\n",
      "  iterations_since_restore: 433\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87352941176471\n",
      "    ram_util_percent: 31.208823529411763\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435722972593428\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.96075488797731\n",
      "    mean_inference_ms: 2.473711940079862\n",
      "    mean_raw_obs_processing_ms: 2.037752186748426\n",
      "  time_since_restore: 11757.03838801384\n",
      "  time_this_iter_s: 23.968719005584717\n",
      "  time_total_s: 11757.03838801384\n",
      "  timers:\n",
      "    learn_throughput: 1160.097\n",
      "    learn_time_ms: 1722.27\n",
      "    load_throughput: 58585.767\n",
      "    load_time_ms: 34.104\n",
      "    sample_throughput: 78.917\n",
      "    sample_time_ms: 25317.694\n",
      "    update_time_ms: 8.009\n",
      "  timestamp: 1636441282\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 865134\n",
      "  training_iteration: 433\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   433</td><td style=\"text-align: right;\">           11757</td><td style=\"text-align: right;\">865134</td><td style=\"text-align: right;\">  8.9238</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                2.66</td><td style=\"text-align: right;\">            100.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 867132\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-01-45\n",
      "  done: false\n",
      "  episode_len_mean: 102.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 8.895800000000019\n",
      "  episode_reward_min: 4.060000000000022\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 8399\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3193609498796008\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010917068920198609\n",
      "          policy_loss: -0.08016903385342587\n",
      "          total_loss: 0.11310852020978927\n",
      "          vf_explained_var: 0.9539571404457092\n",
      "          vf_loss: 0.1994763530613411\n",
      "    num_agent_steps_sampled: 867132\n",
      "    num_agent_steps_trained: 867132\n",
      "    num_steps_sampled: 867132\n",
      "    num_steps_trained: 867132\n",
      "  iterations_since_restore: 434\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.34545454545454\n",
      "    ram_util_percent: 31.203030303030303\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434232923896206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.96201156918105\n",
      "    mean_inference_ms: 2.4735332784260833\n",
      "    mean_raw_obs_processing_ms: 2.0349084198725724\n",
      "  time_since_restore: 11780.074578762054\n",
      "  time_this_iter_s: 23.03619074821472\n",
      "  time_total_s: 11780.074578762054\n",
      "  timers:\n",
      "    learn_throughput: 1160.049\n",
      "    learn_time_ms: 1722.341\n",
      "    load_throughput: 58174.233\n",
      "    load_time_ms: 34.345\n",
      "    sample_throughput: 79.642\n",
      "    sample_time_ms: 25087.188\n",
      "    update_time_ms: 7.711\n",
      "  timestamp: 1636441305\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 867132\n",
      "  training_iteration: 434\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   434</td><td style=\"text-align: right;\">         11780.1</td><td style=\"text-align: right;\">867132</td><td style=\"text-align: right;\">  8.8958</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">                4.06</td><td style=\"text-align: right;\">            102.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 869130\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-02-11\n",
      "  done: false\n",
      "  episode_len_mean: 102.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 8.788700000000018\n",
      "  episode_reward_min: 4.060000000000022\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8420\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3628725863638378\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010978983998114498\n",
      "          policy_loss: -0.04050708803392592\n",
      "          total_loss: 0.06939573369565465\n",
      "          vf_explained_var: 0.9782428741455078\n",
      "          vf_loss: 0.11649706262562956\n",
      "    num_agent_steps_sampled: 869130\n",
      "    num_agent_steps_trained: 869130\n",
      "    num_steps_sampled: 869130\n",
      "    num_steps_trained: 869130\n",
      "  iterations_since_restore: 435\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03783783783783\n",
      "    ram_util_percent: 31.12162162162162\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435095423092364\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.958991170491437\n",
      "    mean_inference_ms: 2.473599083456963\n",
      "    mean_raw_obs_processing_ms: 2.0315575109858672\n",
      "  time_since_restore: 11806.095048904419\n",
      "  time_this_iter_s: 26.020470142364502\n",
      "  time_total_s: 11806.095048904419\n",
      "  timers:\n",
      "    learn_throughput: 1162.156\n",
      "    learn_time_ms: 1719.218\n",
      "    load_throughput: 58153.201\n",
      "    load_time_ms: 34.358\n",
      "    sample_throughput: 84.451\n",
      "    sample_time_ms: 23658.73\n",
      "    update_time_ms: 7.742\n",
      "  timestamp: 1636441331\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 869130\n",
      "  training_iteration: 435\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   435</td><td style=\"text-align: right;\">         11806.1</td><td style=\"text-align: right;\">869130</td><td style=\"text-align: right;\">  8.7887</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">                4.06</td><td style=\"text-align: right;\">            102.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 871128\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-02-35\n",
      "  done: false\n",
      "  episode_len_mean: 103.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 8.683600000000018\n",
      "  episode_reward_min: 1.9100000000000172\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 8438\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.280241117307118\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010514067952974307\n",
      "          policy_loss: -0.062193199335819196\n",
      "          total_loss: 0.12816350899991535\n",
      "          vf_explained_var: 0.9486806988716125\n",
      "          vf_loss: 0.1964225145322936\n",
      "    num_agent_steps_sampled: 871128\n",
      "    num_agent_steps_trained: 871128\n",
      "    num_steps_sampled: 871128\n",
      "    num_steps_trained: 871128\n",
      "  iterations_since_restore: 436\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.93428571428572\n",
      "    ram_util_percent: 31.137142857142862\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432947919931651\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.959956983392377\n",
      "    mean_inference_ms: 2.4732416378789757\n",
      "    mean_raw_obs_processing_ms: 2.0287365053276485\n",
      "  time_since_restore: 11830.219289779663\n",
      "  time_this_iter_s: 24.12424087524414\n",
      "  time_total_s: 11830.219289779663\n",
      "  timers:\n",
      "    learn_throughput: 1162.931\n",
      "    learn_time_ms: 1718.073\n",
      "    load_throughput: 58026.764\n",
      "    load_time_ms: 34.432\n",
      "    sample_throughput: 86.349\n",
      "    sample_time_ms: 23138.551\n",
      "    update_time_ms: 8.102\n",
      "  timestamp: 1636441355\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 871128\n",
      "  training_iteration: 436\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   436</td><td style=\"text-align: right;\">         11830.2</td><td style=\"text-align: right;\">871128</td><td style=\"text-align: right;\">  8.6836</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">                1.91</td><td style=\"text-align: right;\">            103.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 873126\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-03-00\n",
      "  done: false\n",
      "  episode_len_mean: 103.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 8.572100000000018\n",
      "  episode_reward_min: 1.9100000000000172\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8458\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2579022861662366\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012505312282379338\n",
      "          policy_loss: -0.0541421020314807\n",
      "          total_loss: 0.12715768556864487\n",
      "          vf_explained_var: 0.9772593975067139\n",
      "          vf_loss: 0.18586637393704483\n",
      "    num_agent_steps_sampled: 873126\n",
      "    num_agent_steps_trained: 873126\n",
      "    num_steps_sampled: 873126\n",
      "    num_steps_trained: 873126\n",
      "  iterations_since_restore: 437\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28857142857144\n",
      "    ram_util_percent: 31.091428571428573\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432930180836236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.959929176794986\n",
      "    mean_inference_ms: 2.4731112476680464\n",
      "    mean_raw_obs_processing_ms: 2.025500517463702\n",
      "  time_since_restore: 11854.949487686157\n",
      "  time_this_iter_s: 24.73019790649414\n",
      "  time_total_s: 11854.949487686157\n",
      "  timers:\n",
      "    learn_throughput: 1163.468\n",
      "    learn_time_ms: 1717.279\n",
      "    load_throughput: 58273.383\n",
      "    load_time_ms: 34.287\n",
      "    sample_throughput: 86.291\n",
      "    sample_time_ms: 23154.12\n",
      "    update_time_ms: 8.431\n",
      "  timestamp: 1636441380\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 873126\n",
      "  training_iteration: 437\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   437</td><td style=\"text-align: right;\">         11854.9</td><td style=\"text-align: right;\">873126</td><td style=\"text-align: right;\">  8.5721</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">                1.91</td><td style=\"text-align: right;\">            103.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 875124\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-03-26\n",
      "  done: false\n",
      "  episode_len_mean: 102.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 8.45800000000002\n",
      "  episode_reward_min: 1.9100000000000172\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8479\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.209130319811049\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015486884591652754\n",
      "          policy_loss: -0.027459038368293217\n",
      "          total_loss: 0.1132349994477062\n",
      "          vf_explained_var: 0.9722762107849121\n",
      "          vf_loss: 0.14286253989807196\n",
      "    num_agent_steps_sampled: 875124\n",
      "    num_agent_steps_trained: 875124\n",
      "    num_steps_sampled: 875124\n",
      "    num_steps_trained: 875124\n",
      "  iterations_since_restore: 438\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88918918918918\n",
      "    ram_util_percent: 31.091891891891894\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434349724297599\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.95834976406575\n",
      "    mean_inference_ms: 2.4731463386948285\n",
      "    mean_raw_obs_processing_ms: 2.022159741695838\n",
      "  time_since_restore: 11880.748415231705\n",
      "  time_this_iter_s: 25.798927545547485\n",
      "  time_total_s: 11880.748415231705\n",
      "  timers:\n",
      "    learn_throughput: 1163.493\n",
      "    learn_time_ms: 1717.243\n",
      "    load_throughput: 58248.068\n",
      "    load_time_ms: 34.302\n",
      "    sample_throughput: 86.529\n",
      "    sample_time_ms: 23090.392\n",
      "    update_time_ms: 8.658\n",
      "  timestamp: 1636441406\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 875124\n",
      "  training_iteration: 438\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   438</td><td style=\"text-align: right;\">         11880.7</td><td style=\"text-align: right;\">875124</td><td style=\"text-align: right;\">   8.458</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">                1.91</td><td style=\"text-align: right;\">            102.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 877122\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-03-52\n",
      "  done: false\n",
      "  episode_len_mean: 99.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.56180000000002\n",
      "  episode_reward_min: 1.9100000000000172\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8499\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2996448017302014\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014067974747396976\n",
      "          policy_loss: -0.012072014081336202\n",
      "          total_loss: 0.16946706748789264\n",
      "          vf_explained_var: 0.9550136923789978\n",
      "          vf_loss: 0.18552186029652754\n",
      "    num_agent_steps_sampled: 877122\n",
      "    num_agent_steps_trained: 877122\n",
      "    num_steps_sampled: 877122\n",
      "    num_steps_trained: 877122\n",
      "  iterations_since_restore: 439\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.71578947368421\n",
      "    ram_util_percent: 31.047368421052617\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436648171657552\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.959859378608016\n",
      "    mean_inference_ms: 2.4733496934825148\n",
      "    mean_raw_obs_processing_ms: 2.019039977995065\n",
      "  time_since_restore: 11907.028630495071\n",
      "  time_this_iter_s: 26.2802152633667\n",
      "  time_total_s: 11907.028630495071\n",
      "  timers:\n",
      "    learn_throughput: 1163.37\n",
      "    learn_time_ms: 1717.424\n",
      "    load_throughput: 58486.777\n",
      "    load_time_ms: 34.162\n",
      "    sample_throughput: 86.154\n",
      "    sample_time_ms: 23190.987\n",
      "    update_time_ms: 9.039\n",
      "  timestamp: 1636441432\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 877122\n",
      "  training_iteration: 439\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   439</td><td style=\"text-align: right;\">           11907</td><td style=\"text-align: right;\">877122</td><td style=\"text-align: right;\">  8.5618</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                1.91</td><td style=\"text-align: right;\">             99.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 879120\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-04-17\n",
      "  done: false\n",
      "  episode_len_mean: 101.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.487000000000018\n",
      "  episode_reward_min: 1.9100000000000172\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 8518\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.335055118515378\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009097738649791227\n",
      "          policy_loss: -0.02138244781110968\n",
      "          total_loss: 0.10030796584628877\n",
      "          vf_explained_var: 0.9583998918533325\n",
      "          vf_loss: 0.1292118385522848\n",
      "    num_agent_steps_sampled: 879120\n",
      "    num_agent_steps_trained: 879120\n",
      "    num_steps_sampled: 879120\n",
      "    num_steps_trained: 879120\n",
      "  iterations_since_restore: 440\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.64571428571429\n",
      "    ram_util_percent: 31.02285714285714\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044353354345629814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.961519917679496\n",
      "    mean_inference_ms: 2.4730836219806718\n",
      "    mean_raw_obs_processing_ms: 2.0161939978416568\n",
      "  time_since_restore: 11931.645488262177\n",
      "  time_this_iter_s: 24.616857767105103\n",
      "  time_total_s: 11931.645488262177\n",
      "  timers:\n",
      "    learn_throughput: 1163.571\n",
      "    learn_time_ms: 1717.128\n",
      "    load_throughput: 58288.744\n",
      "    load_time_ms: 34.278\n",
      "    sample_throughput: 86.428\n",
      "    sample_time_ms: 23117.446\n",
      "    update_time_ms: 8.868\n",
      "  timestamp: 1636441457\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 879120\n",
      "  training_iteration: 440\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   440</td><td style=\"text-align: right;\">         11931.6</td><td style=\"text-align: right;\">879120</td><td style=\"text-align: right;\">   8.487</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                1.91</td><td style=\"text-align: right;\">            101.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 881118\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-04-58\n",
      "  done: false\n",
      "  episode_len_mean: 99.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.430100000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8539\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2362203822249458\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011674692229468915\n",
      "          policy_loss: -0.040860469373209134\n",
      "          total_loss: 0.17876223039236808\n",
      "          vf_explained_var: 0.972020149230957\n",
      "          vf_loss: 0.22450466022959778\n",
      "    num_agent_steps_sampled: 881118\n",
      "    num_agent_steps_trained: 881118\n",
      "    num_steps_sampled: 881118\n",
      "    num_steps_trained: 881118\n",
      "  iterations_since_restore: 441\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.91724137931035\n",
      "    ram_util_percent: 31.027586206896554\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434553156720197\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.961483781103126\n",
      "    mean_inference_ms: 2.4728787315954817\n",
      "    mean_raw_obs_processing_ms: 2.0175361598573405\n",
      "  time_since_restore: 11972.513668298721\n",
      "  time_this_iter_s: 40.8681800365448\n",
      "  time_total_s: 11972.513668298721\n",
      "  timers:\n",
      "    learn_throughput: 1162.945\n",
      "    learn_time_ms: 1718.053\n",
      "    load_throughput: 58342.797\n",
      "    load_time_ms: 34.246\n",
      "    sample_throughput: 80.631\n",
      "    sample_time_ms: 24779.645\n",
      "    update_time_ms: 8.511\n",
      "  timestamp: 1636441498\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 881118\n",
      "  training_iteration: 441\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   441</td><td style=\"text-align: right;\">         11972.5</td><td style=\"text-align: right;\">881118</td><td style=\"text-align: right;\">  8.4301</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 883116\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-05-25\n",
      "  done: false\n",
      "  episode_len_mean: 98.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.316100000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8560\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2324049745287213\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010695129676119632\n",
      "          policy_loss: -0.015739337479074796\n",
      "          total_loss: 0.10940273389929817\n",
      "          vf_explained_var: 0.9821810126304626\n",
      "          vf_loss: 0.13061351225312268\n",
      "    num_agent_steps_sampled: 883116\n",
      "    num_agent_steps_trained: 883116\n",
      "    num_steps_sampled: 883116\n",
      "    num_steps_trained: 883116\n",
      "  iterations_since_restore: 442\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.52307692307693\n",
      "    ram_util_percent: 31.02564102564102\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044332842882223805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.962333828631703\n",
      "    mean_inference_ms: 2.472692696867687\n",
      "    mean_raw_obs_processing_ms: 2.0184709202303255\n",
      "  time_since_restore: 11999.934382200241\n",
      "  time_this_iter_s: 27.420713901519775\n",
      "  time_total_s: 11999.934382200241\n",
      "  timers:\n",
      "    learn_throughput: 1163.028\n",
      "    learn_time_ms: 1717.93\n",
      "    load_throughput: 58395.242\n",
      "    load_time_ms: 34.215\n",
      "    sample_throughput: 80.186\n",
      "    sample_time_ms: 24917.104\n",
      "    update_time_ms: 8.281\n",
      "  timestamp: 1636441525\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 883116\n",
      "  training_iteration: 442\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   442</td><td style=\"text-align: right;\">         11999.9</td><td style=\"text-align: right;\">883116</td><td style=\"text-align: right;\">  8.3161</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 885114\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-06-07\n",
      "  done: false\n",
      "  episode_len_mean: 97.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.195400000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 8582\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2602667956125169\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00945308154882432\n",
      "          policy_loss: -0.013000062906316348\n",
      "          total_loss: 0.30182505347544236\n",
      "          vf_explained_var: 0.8919237852096558\n",
      "          vf_loss: 0.321370984152669\n",
      "    num_agent_steps_sampled: 885114\n",
      "    num_agent_steps_trained: 885114\n",
      "    num_steps_sampled: 885114\n",
      "    num_steps_trained: 885114\n",
      "  iterations_since_restore: 443\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.4813559322034\n",
      "    ram_util_percent: 30.84237288135594\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044329130137569873\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.9629691534871\n",
      "    mean_inference_ms: 2.472639369818459\n",
      "    mean_raw_obs_processing_ms: 2.027534570401695\n",
      "  time_since_restore: 12041.370864868164\n",
      "  time_this_iter_s: 41.436482667922974\n",
      "  time_total_s: 12041.370864868164\n",
      "  timers:\n",
      "    learn_throughput: 1163.39\n",
      "    learn_time_ms: 1717.395\n",
      "    load_throughput: 58976.506\n",
      "    load_time_ms: 33.878\n",
      "    sample_throughput: 74.93\n",
      "    sample_time_ms: 26664.821\n",
      "    update_time_ms: 8.22\n",
      "  timestamp: 1636441567\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 885114\n",
      "  training_iteration: 443\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   443</td><td style=\"text-align: right;\">         12041.4</td><td style=\"text-align: right;\">885114</td><td style=\"text-align: right;\">  8.1954</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 887112\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-06-31\n",
      "  done: false\n",
      "  episode_len_mean: 98.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.047600000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 8600\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.25073219197137\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011852083198262477\n",
      "          policy_loss: -0.030283064856415704\n",
      "          total_loss: 0.15210716026790794\n",
      "          vf_explained_var: 0.9653869867324829\n",
      "          vf_loss: 0.18730364626362211\n",
      "    num_agent_steps_sampled: 887112\n",
      "    num_agent_steps_trained: 887112\n",
      "    num_steps_sampled: 887112\n",
      "    num_steps_trained: 887112\n",
      "  iterations_since_restore: 444\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.17777777777776\n",
      "    ram_util_percent: 30.997222222222224\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044344024433284376\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.96180115616621\n",
      "    mean_inference_ms: 2.4728213893755573\n",
      "    mean_raw_obs_processing_ms: 2.0348511628171746\n",
      "  time_since_restore: 12066.005715608597\n",
      "  time_this_iter_s: 24.63485074043274\n",
      "  time_total_s: 12066.005715608597\n",
      "  timers:\n",
      "    learn_throughput: 1163.25\n",
      "    learn_time_ms: 1717.602\n",
      "    load_throughput: 58956.673\n",
      "    load_time_ms: 33.889\n",
      "    sample_throughput: 74.485\n",
      "    sample_time_ms: 26824.015\n",
      "    update_time_ms: 8.613\n",
      "  timestamp: 1636441591\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 887112\n",
      "  training_iteration: 444\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   444</td><td style=\"text-align: right;\">           12066</td><td style=\"text-align: right;\">887112</td><td style=\"text-align: right;\">  8.0476</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 889110\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-06-56\n",
      "  done: false\n",
      "  episode_len_mean: 98.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.141400000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8620\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2191545333181109\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017001822656031423\n",
      "          policy_loss: -0.04956815723507177\n",
      "          total_loss: 0.3064838155305811\n",
      "          vf_explained_var: 0.9333509206771851\n",
      "          vf_loss: 0.3573500674217939\n",
      "    num_agent_steps_sampled: 889110\n",
      "    num_agent_steps_trained: 889110\n",
      "    num_steps_sampled: 889110\n",
      "    num_steps_trained: 889110\n",
      "  iterations_since_restore: 445\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.51428571428573\n",
      "    ram_util_percent: 31.15714285714286\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044343568951540055\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.962004312705194\n",
      "    mean_inference_ms: 2.4727432979852004\n",
      "    mean_raw_obs_processing_ms: 2.0430041713435156\n",
      "  time_since_restore: 12090.817424297333\n",
      "  time_this_iter_s: 24.811708688735962\n",
      "  time_total_s: 12090.817424297333\n",
      "  timers:\n",
      "    learn_throughput: 1163.378\n",
      "    learn_time_ms: 1717.412\n",
      "    load_throughput: 58562.635\n",
      "    load_time_ms: 34.117\n",
      "    sample_throughput: 74.824\n",
      "    sample_time_ms: 26702.526\n",
      "    update_time_ms: 9.022\n",
      "  timestamp: 1636441616\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 889110\n",
      "  training_iteration: 445\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   445</td><td style=\"text-align: right;\">         12090.8</td><td style=\"text-align: right;\">889110</td><td style=\"text-align: right;\">  8.1414</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 891108\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-07-23\n",
      "  done: false\n",
      "  episode_len_mean: 97.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 8.011400000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8640\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.258411929720924\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012834079867406607\n",
      "          policy_loss: -0.030112307926728612\n",
      "          total_loss: 0.17415040818353494\n",
      "          vf_explained_var: 0.9662184715270996\n",
      "          vf_loss: 0.2086237496208577\n",
      "    num_agent_steps_sampled: 891108\n",
      "    num_agent_steps_trained: 891108\n",
      "    num_steps_sampled: 891108\n",
      "    num_steps_trained: 891108\n",
      "  iterations_since_restore: 446\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.2\n",
      "    ram_util_percent: 31.20263157894737\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044376291468863245\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.96200843848837\n",
      "    mean_inference_ms: 2.4731910944915665\n",
      "    mean_raw_obs_processing_ms: 2.046583455521676\n",
      "  time_since_restore: 12117.61560845375\n",
      "  time_this_iter_s: 26.798184156417847\n",
      "  time_total_s: 12117.61560845375\n",
      "  timers:\n",
      "    learn_throughput: 1162.786\n",
      "    learn_time_ms: 1718.287\n",
      "    load_throughput: 58400.939\n",
      "    load_time_ms: 34.212\n",
      "    sample_throughput: 74.086\n",
      "    sample_time_ms: 26968.73\n",
      "    update_time_ms: 9.082\n",
      "  timestamp: 1636441643\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 891108\n",
      "  training_iteration: 446\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   446</td><td style=\"text-align: right;\">         12117.6</td><td style=\"text-align: right;\">891108</td><td style=\"text-align: right;\">  8.0114</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 893106\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-07-49\n",
      "  done: false\n",
      "  episode_len_mean: 98.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 7.559000000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8661\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2923941822279068\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013779358388477686\n",
      "          policy_loss: -0.04053081256293115\n",
      "          total_loss: 0.25402345159756284\n",
      "          vf_explained_var: 0.9576393961906433\n",
      "          vf_loss: 0.29864945761149836\n",
      "    num_agent_steps_sampled: 893106\n",
      "    num_agent_steps_trained: 893106\n",
      "    num_steps_sampled: 893106\n",
      "    num_steps_trained: 893106\n",
      "  iterations_since_restore: 447\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.02368421052631\n",
      "    ram_util_percent: 31.294736842105277\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044377137307632604\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.963254140664603\n",
      "    mean_inference_ms: 2.473157569779426\n",
      "    mean_raw_obs_processing_ms: 2.050594528997121\n",
      "  time_since_restore: 12143.811592817307\n",
      "  time_this_iter_s: 26.195984363555908\n",
      "  time_total_s: 12143.811592817307\n",
      "  timers:\n",
      "    learn_throughput: 1162.007\n",
      "    learn_time_ms: 1719.438\n",
      "    load_throughput: 58384.257\n",
      "    load_time_ms: 34.222\n",
      "    sample_throughput: 73.689\n",
      "    sample_time_ms: 27113.943\n",
      "    update_time_ms: 9.465\n",
      "  timestamp: 1636441669\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 893106\n",
      "  training_iteration: 447\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   447</td><td style=\"text-align: right;\">         12143.8</td><td style=\"text-align: right;\">893106</td><td style=\"text-align: right;\">   7.559</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 895104\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-08-15\n",
      "  done: false\n",
      "  episode_len_mean: 98.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 7.878600000000017\n",
      "  episode_reward_min: 1.340000000000003\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8682\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.189447611002695\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008051635497841606\n",
      "          policy_loss: -0.09900842423417738\n",
      "          total_loss: 0.02175944031083158\n",
      "          vf_explained_var: 0.9813254475593567\n",
      "          vf_loss: 0.12750347659346603\n",
      "    num_agent_steps_sampled: 895104\n",
      "    num_agent_steps_trained: 895104\n",
      "    num_steps_sampled: 895104\n",
      "    num_steps_trained: 895104\n",
      "  iterations_since_restore: 448\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.16486486486485\n",
      "    ram_util_percent: 31.343243243243244\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437273867128358\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.966223939326966\n",
      "    mean_inference_ms: 2.4730647299012714\n",
      "    mean_raw_obs_processing_ms: 2.0473961407585364\n",
      "  time_since_restore: 12169.936654090881\n",
      "  time_this_iter_s: 26.12506127357483\n",
      "  time_total_s: 12169.936654090881\n",
      "  timers:\n",
      "    learn_throughput: 1163.001\n",
      "    learn_time_ms: 1717.97\n",
      "    load_throughput: 58698.163\n",
      "    load_time_ms: 34.039\n",
      "    sample_throughput: 73.595\n",
      "    sample_time_ms: 27148.51\n",
      "    update_time_ms: 8.831\n",
      "  timestamp: 1636441695\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 895104\n",
      "  training_iteration: 448\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   448</td><td style=\"text-align: right;\">         12169.9</td><td style=\"text-align: right;\">895104</td><td style=\"text-align: right;\">  7.8786</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">                1.34</td><td style=\"text-align: right;\">             98.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 897102\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-08-42\n",
      "  done: false\n",
      "  episode_len_mean: 96.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 7.723600000000017\n",
      "  episode_reward_min: 1.340000000000003\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8703\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2226425403640384\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011748772417506291\n",
      "          policy_loss: -0.04146283818852334\n",
      "          total_loss: 0.12973320086797077\n",
      "          vf_explained_var: 0.9691489338874817\n",
      "          vf_loss: 0.17589475996792317\n",
      "    num_agent_steps_sampled: 897102\n",
      "    num_agent_steps_trained: 897102\n",
      "    num_steps_sampled: 897102\n",
      "    num_steps_trained: 897102\n",
      "  iterations_since_restore: 449\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14210526315789\n",
      "    ram_util_percent: 31.373684210526317\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044345180885343415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.969671991114787\n",
      "    mean_inference_ms: 2.472668046955478\n",
      "    mean_raw_obs_processing_ms: 2.044421488143568\n",
      "  time_since_restore: 12196.295602321625\n",
      "  time_this_iter_s: 26.358948230743408\n",
      "  time_total_s: 12196.295602321625\n",
      "  timers:\n",
      "    learn_throughput: 1162.47\n",
      "    learn_time_ms: 1718.755\n",
      "    load_throughput: 58573.81\n",
      "    load_time_ms: 34.111\n",
      "    sample_throughput: 73.575\n",
      "    sample_time_ms: 27156.103\n",
      "    update_time_ms: 8.168\n",
      "  timestamp: 1636441722\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 897102\n",
      "  training_iteration: 449\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   449</td><td style=\"text-align: right;\">         12196.3</td><td style=\"text-align: right;\">897102</td><td style=\"text-align: right;\">  7.7236</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">                1.34</td><td style=\"text-align: right;\">             96.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 899100\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-09-09\n",
      "  done: false\n",
      "  episode_len_mean: 95.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 7.790100000000017\n",
      "  episode_reward_min: 1.340000000000003\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 8725\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0954819866589138\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013786336502156903\n",
      "          policy_loss: -0.010771489852950686\n",
      "          total_loss: 0.23824832937014953\n",
      "          vf_explained_var: 0.9678673148155212\n",
      "          vf_loss: 0.2511414216742629\n",
      "    num_agent_steps_sampled: 899100\n",
      "    num_agent_steps_trained: 899100\n",
      "    num_steps_sampled: 899100\n",
      "    num_steps_trained: 899100\n",
      "  iterations_since_restore: 450\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14999999999999\n",
      "    ram_util_percent: 31.389473684210532\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443123208804715\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.974958872697368\n",
      "    mean_inference_ms: 2.472167213959466\n",
      "    mean_raw_obs_processing_ms: 2.0414007723421888\n",
      "  time_since_restore: 12223.403314590454\n",
      "  time_this_iter_s: 27.107712268829346\n",
      "  time_total_s: 12223.403314590454\n",
      "  timers:\n",
      "    learn_throughput: 1162.426\n",
      "    learn_time_ms: 1718.818\n",
      "    load_throughput: 58753.308\n",
      "    load_time_ms: 34.007\n",
      "    sample_throughput: 72.905\n",
      "    sample_time_ms: 27405.494\n",
      "    update_time_ms: 7.908\n",
      "  timestamp: 1636441749\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 899100\n",
      "  training_iteration: 450\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   450</td><td style=\"text-align: right;\">         12223.4</td><td style=\"text-align: right;\">899100</td><td style=\"text-align: right;\">  7.7901</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                1.34</td><td style=\"text-align: right;\">             95.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 901098\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-09-36\n",
      "  done: false\n",
      "  episode_len_mean: 96.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000015\n",
      "  episode_reward_mean: 7.811300000000017\n",
      "  episode_reward_min: 1.0000000000000109\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8745\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3095058106240771\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009932000174637296\n",
      "          policy_loss: -0.06973158429775919\n",
      "          total_loss: 0.1346161619360958\n",
      "          vf_explained_var: 0.965749979019165\n",
      "          vf_loss: 0.21107914749355544\n",
      "    num_agent_steps_sampled: 901098\n",
      "    num_agent_steps_trained: 901098\n",
      "    num_steps_sampled: 901098\n",
      "    num_steps_trained: 901098\n",
      "  iterations_since_restore: 451\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.44871794871794\n",
      "    ram_util_percent: 31.392307692307696\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044297490936568734\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.979374577513745\n",
      "    mean_inference_ms: 2.471900633767363\n",
      "    mean_raw_obs_processing_ms: 2.0386381768101534\n",
      "  time_since_restore: 12250.214777708054\n",
      "  time_this_iter_s: 26.811463117599487\n",
      "  time_total_s: 12250.214777708054\n",
      "  timers:\n",
      "    learn_throughput: 1162.313\n",
      "    learn_time_ms: 1718.986\n",
      "    load_throughput: 58652.069\n",
      "    load_time_ms: 34.065\n",
      "    sample_throughput: 76.85\n",
      "    sample_time_ms: 25998.602\n",
      "    update_time_ms: 8.745\n",
      "  timestamp: 1636441776\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 901098\n",
      "  training_iteration: 451\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   451</td><td style=\"text-align: right;\">         12250.2</td><td style=\"text-align: right;\">901098</td><td style=\"text-align: right;\">  7.8113</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">             96.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 903096\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-10-00\n",
      "  done: false\n",
      "  episode_len_mean: 95.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.045200000000017\n",
      "  episode_reward_min: 1.0000000000000109\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8766\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2735247294108072\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008436537963763886\n",
      "          policy_loss: -0.03036355244971457\n",
      "          total_loss: 0.1281750268701996\n",
      "          vf_explained_var: 0.9606048464775085\n",
      "          vf_loss: 0.16586834607379777\n",
      "    num_agent_steps_sampled: 903096\n",
      "    num_agent_steps_trained: 903096\n",
      "    num_steps_sampled: 903096\n",
      "    num_steps_trained: 903096\n",
      "  iterations_since_restore: 452\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.53142857142856\n",
      "    ram_util_percent: 31.31428571428572\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044298797645677526\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.982848087113815\n",
      "    mean_inference_ms: 2.4718678926817197\n",
      "    mean_raw_obs_processing_ms: 2.0357213307716897\n",
      "  time_since_restore: 12274.677839040756\n",
      "  time_this_iter_s: 24.463061332702637\n",
      "  time_total_s: 12274.677839040756\n",
      "  timers:\n",
      "    learn_throughput: 1163.01\n",
      "    learn_time_ms: 1717.955\n",
      "    load_throughput: 58569.389\n",
      "    load_time_ms: 34.113\n",
      "    sample_throughput: 77.732\n",
      "    sample_time_ms: 25703.857\n",
      "    update_time_ms: 8.64\n",
      "  timestamp: 1636441800\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 903096\n",
      "  training_iteration: 452\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   452</td><td style=\"text-align: right;\">         12274.7</td><td style=\"text-align: right;\">903096</td><td style=\"text-align: right;\">  8.0452</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">             95.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 905094\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-10-26\n",
      "  done: false\n",
      "  episode_len_mean: 95.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 7.837700000000017\n",
      "  episode_reward_min: 1.0000000000000109\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8786\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.233112573055994\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009657329804593691\n",
      "          policy_loss: -0.01062761577112334\n",
      "          total_loss: 0.14197863481406656\n",
      "          vf_explained_var: 0.9655855894088745\n",
      "          vf_loss: 0.1587497065109866\n",
      "    num_agent_steps_sampled: 905094\n",
      "    num_agent_steps_trained: 905094\n",
      "    num_steps_sampled: 905094\n",
      "    num_steps_trained: 905094\n",
      "  iterations_since_restore: 453\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.22972972972973\n",
      "    ram_util_percent: 31.324324324324337\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432421181707858\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.98450101684093\n",
      "    mean_inference_ms: 2.4721824119692046\n",
      "    mean_raw_obs_processing_ms: 2.0329232135387767\n",
      "  time_since_restore: 12300.4847509861\n",
      "  time_this_iter_s: 25.806911945343018\n",
      "  time_total_s: 12300.4847509861\n",
      "  timers:\n",
      "    learn_throughput: 1163.404\n",
      "    learn_time_ms: 1717.374\n",
      "    load_throughput: 58682.051\n",
      "    load_time_ms: 34.048\n",
      "    sample_throughput: 82.758\n",
      "    sample_time_ms: 24142.583\n",
      "    update_time_ms: 7.88\n",
      "  timestamp: 1636441826\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 905094\n",
      "  training_iteration: 453\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   453</td><td style=\"text-align: right;\">         12300.5</td><td style=\"text-align: right;\">905094</td><td style=\"text-align: right;\">  7.8377</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">             95.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 907092\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-10-52\n",
      "  done: false\n",
      "  episode_len_mean: 96.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.331500000000016\n",
      "  episode_reward_min: 1.0000000000000109\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8807\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.242469839255015\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01234919041399996\n",
      "          policy_loss: -0.010385881949748313\n",
      "          total_loss: 0.21443969499142396\n",
      "          vf_explained_var: 0.9695245623588562\n",
      "          vf_loss: 0.22933786949586302\n",
      "    num_agent_steps_sampled: 907092\n",
      "    num_agent_steps_trained: 907092\n",
      "    num_steps_sampled: 907092\n",
      "    num_steps_trained: 907092\n",
      "  iterations_since_restore: 454\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33611111111111\n",
      "    ram_util_percent: 31.286111111111115\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432654877392109\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.988220141579113\n",
      "    mean_inference_ms: 2.47215243338556\n",
      "    mean_raw_obs_processing_ms: 2.03002659853224\n",
      "  time_since_restore: 12326.288447856903\n",
      "  time_this_iter_s: 25.803696870803833\n",
      "  time_total_s: 12326.288447856903\n",
      "  timers:\n",
      "    learn_throughput: 1162.81\n",
      "    learn_time_ms: 1718.251\n",
      "    load_throughput: 58745.195\n",
      "    load_time_ms: 34.011\n",
      "    sample_throughput: 82.362\n",
      "    sample_time_ms: 24258.771\n",
      "    update_time_ms: 7.754\n",
      "  timestamp: 1636441852\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 907092\n",
      "  training_iteration: 454\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   454</td><td style=\"text-align: right;\">         12326.3</td><td style=\"text-align: right;\">907092</td><td style=\"text-align: right;\">  8.3315</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">             96.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 909090\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-11-18\n",
      "  done: false\n",
      "  episode_len_mean: 97.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.257900000000017\n",
      "  episode_reward_min: 1.0000000000000109\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8827\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1929037255900248\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01242976166139767\n",
      "          policy_loss: -0.04095038979181222\n",
      "          total_loss: 0.16738361674139188\n",
      "          vf_explained_var: 0.9690564870834351\n",
      "          vf_loss: 0.21229901475210985\n",
      "    num_agent_steps_sampled: 909090\n",
      "    num_agent_steps_trained: 909090\n",
      "    num_steps_sampled: 909090\n",
      "    num_steps_trained: 909090\n",
      "  iterations_since_restore: 455\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.52972972972972\n",
      "    ram_util_percent: 31.286486486486478\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044345976258887844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.990642280496278\n",
      "    mean_inference_ms: 2.472357787550196\n",
      "    mean_raw_obs_processing_ms: 2.0271797531613123\n",
      "  time_since_restore: 12352.120249032974\n",
      "  time_this_iter_s: 25.831801176071167\n",
      "  time_total_s: 12352.120249032974\n",
      "  timers:\n",
      "    learn_throughput: 1163.296\n",
      "    learn_time_ms: 1717.533\n",
      "    load_throughput: 58893.281\n",
      "    load_time_ms: 33.926\n",
      "    sample_throughput: 82.012\n",
      "    sample_time_ms: 24362.321\n",
      "    update_time_ms: 7.224\n",
      "  timestamp: 1636441878\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 909090\n",
      "  training_iteration: 455\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   455</td><td style=\"text-align: right;\">         12352.1</td><td style=\"text-align: right;\">909090</td><td style=\"text-align: right;\">  8.2579</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">             97.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 911088\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-11-44\n",
      "  done: false\n",
      "  episode_len_mean: 98.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.287900000000016\n",
      "  episode_reward_min: 2.750000000000013\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8847\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3321716399419876\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012262827680587843\n",
      "          policy_loss: -0.0029142489213319052\n",
      "          total_loss: 0.24688736148001184\n",
      "          vf_explained_var: 0.9389634132385254\n",
      "          vf_loss: 0.2552662567013786\n",
      "    num_agent_steps_sampled: 911088\n",
      "    num_agent_steps_trained: 911088\n",
      "    num_steps_sampled: 911088\n",
      "    num_steps_trained: 911088\n",
      "  iterations_since_restore: 456\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.38378378378378\n",
      "    ram_util_percent: 31.21891891891891\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435677001922962\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.993789476365436\n",
      "    mean_inference_ms: 2.47246995159955\n",
      "    mean_raw_obs_processing_ms: 2.024347120489087\n",
      "  time_since_restore: 12377.828369617462\n",
      "  time_this_iter_s: 25.708120584487915\n",
      "  time_total_s: 12377.828369617462\n",
      "  timers:\n",
      "    learn_throughput: 1163.976\n",
      "    learn_time_ms: 1716.53\n",
      "    load_throughput: 59034.67\n",
      "    load_time_ms: 33.845\n",
      "    sample_throughput: 82.376\n",
      "    sample_time_ms: 24254.763\n",
      "    update_time_ms: 7.077\n",
      "  timestamp: 1636441904\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 911088\n",
      "  training_iteration: 456\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   456</td><td style=\"text-align: right;\">         12377.8</td><td style=\"text-align: right;\">911088</td><td style=\"text-align: right;\">  8.2879</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.75</td><td style=\"text-align: right;\">             98.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 913086\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-12-11\n",
      "  done: false\n",
      "  episode_len_mean: 97.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.986300000000018\n",
      "  episode_reward_min: 2.750000000000013\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8868\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1542237826756068\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009669094596819201\n",
      "          policy_loss: -0.06771869118369761\n",
      "          total_loss: 0.07198279750134264\n",
      "          vf_explained_var: 0.987320601940155\n",
      "          vf_loss: 0.14504851996898652\n",
      "    num_agent_steps_sampled: 913086\n",
      "    num_agent_steps_trained: 913086\n",
      "    num_steps_sampled: 913086\n",
      "    num_steps_trained: 913086\n",
      "  iterations_since_restore: 457\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.01794871794871\n",
      "    ram_util_percent: 31.18717948717948\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435699893679837\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.997632913698936\n",
      "    mean_inference_ms: 2.4724115917627767\n",
      "    mean_raw_obs_processing_ms: 2.0214235495110793\n",
      "  time_since_restore: 12405.41803264618\n",
      "  time_this_iter_s: 27.58966302871704\n",
      "  time_total_s: 12405.41803264618\n",
      "  timers:\n",
      "    learn_throughput: 1164.525\n",
      "    learn_time_ms: 1715.721\n",
      "    load_throughput: 59093.2\n",
      "    load_time_ms: 33.811\n",
      "    sample_throughput: 81.899\n",
      "    sample_time_ms: 24395.887\n",
      "    update_time_ms: 6.216\n",
      "  timestamp: 1636441931\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 913086\n",
      "  training_iteration: 457\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   457</td><td style=\"text-align: right;\">         12405.4</td><td style=\"text-align: right;\">913086</td><td style=\"text-align: right;\">  8.9863</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.75</td><td style=\"text-align: right;\">             97.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 915084\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-12-52\n",
      "  done: false\n",
      "  episode_len_mean: 97.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 9.066400000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8889\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1409431812309083\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011817471667703312\n",
      "          policy_loss: -0.02840615374346574\n",
      "          total_loss: 0.5257141021035966\n",
      "          vf_explained_var: 0.9262957572937012\n",
      "          vf_loss: 0.5579579664482957\n",
      "    num_agent_steps_sampled: 915084\n",
      "    num_agent_steps_trained: 915084\n",
      "    num_steps_sampled: 915084\n",
      "    num_steps_trained: 915084\n",
      "  iterations_since_restore: 458\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.64310344827588\n",
      "    ram_util_percent: 31.175862068965515\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044323137095025944\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.001950563626316\n",
      "    mean_inference_ms: 2.4718282091151194\n",
      "    mean_raw_obs_processing_ms: 2.022812948237611\n",
      "  time_since_restore: 12445.89973449707\n",
      "  time_this_iter_s: 40.48170185089111\n",
      "  time_total_s: 12445.89973449707\n",
      "  timers:\n",
      "    learn_throughput: 1165.394\n",
      "    learn_time_ms: 1714.442\n",
      "    load_throughput: 58673.012\n",
      "    load_time_ms: 34.053\n",
      "    sample_throughput: 77.347\n",
      "    sample_time_ms: 25831.498\n",
      "    update_time_ms: 7.375\n",
      "  timestamp: 1636441972\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 915084\n",
      "  training_iteration: 458\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   458</td><td style=\"text-align: right;\">         12445.9</td><td style=\"text-align: right;\">915084</td><td style=\"text-align: right;\">  9.0664</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 917082\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-13-19\n",
      "  done: false\n",
      "  episode_len_mean: 97.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.67000000000001\n",
      "  episode_reward_mean: 8.796900000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8909\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3255358057362692\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011966232898247456\n",
      "          policy_loss: -0.03807369208052045\n",
      "          total_loss: 0.1103227440179104\n",
      "          vf_explained_var: 0.955522894859314\n",
      "          vf_loss: 0.15398475600495226\n",
      "    num_agent_steps_sampled: 917082\n",
      "    num_agent_steps_trained: 917082\n",
      "    num_steps_sampled: 917082\n",
      "    num_steps_trained: 917082\n",
      "  iterations_since_restore: 459\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72820512820512\n",
      "    ram_util_percent: 30.97948717948718\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432331448091327\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.004529677597507\n",
      "    mean_inference_ms: 2.4717411687222692\n",
      "    mean_raw_obs_processing_ms: 2.023761238736094\n",
      "  time_since_restore: 12473.04769873619\n",
      "  time_this_iter_s: 27.147964239120483\n",
      "  time_total_s: 12473.04769873619\n",
      "  timers:\n",
      "    learn_throughput: 1165.208\n",
      "    learn_time_ms: 1714.715\n",
      "    load_throughput: 58455.241\n",
      "    load_time_ms: 34.18\n",
      "    sample_throughput: 77.113\n",
      "    sample_time_ms: 25909.986\n",
      "    update_time_ms: 7.288\n",
      "  timestamp: 1636441999\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 917082\n",
      "  training_iteration: 459\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   459</td><td style=\"text-align: right;\">           12473</td><td style=\"text-align: right;\">917082</td><td style=\"text-align: right;\">  8.7969</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 919080\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-13-59\n",
      "  done: false\n",
      "  episode_len_mean: 97.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.67000000000001\n",
      "  episode_reward_mean: 8.123100000000019\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8929\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3447149628684634\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008826543381165291\n",
      "          policy_loss: 0.013551090187614872\n",
      "          total_loss: 0.287034742995387\n",
      "          vf_explained_var: 0.912917971611023\n",
      "          vf_loss: 0.28127543768357666\n",
      "    num_agent_steps_sampled: 919080\n",
      "    num_agent_steps_trained: 919080\n",
      "    num_steps_sampled: 919080\n",
      "    num_steps_trained: 919080\n",
      "  iterations_since_restore: 460\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.34385964912282\n",
      "    ram_util_percent: 31.100000000000005\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433671825473556\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00448742168879\n",
      "    mean_inference_ms: 2.47188282841142\n",
      "    mean_raw_obs_processing_ms: 2.0318269523543284\n",
      "  time_since_restore: 12512.976260662079\n",
      "  time_this_iter_s: 39.92856192588806\n",
      "  time_total_s: 12512.976260662079\n",
      "  timers:\n",
      "    learn_throughput: 1164.608\n",
      "    learn_time_ms: 1715.599\n",
      "    load_throughput: 58417.671\n",
      "    load_time_ms: 34.202\n",
      "    sample_throughput: 73.481\n",
      "    sample_time_ms: 27190.86\n",
      "    update_time_ms: 7.426\n",
      "  timestamp: 1636442039\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 919080\n",
      "  training_iteration: 460\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   460</td><td style=\"text-align: right;\">           12513</td><td style=\"text-align: right;\">919080</td><td style=\"text-align: right;\">  8.1231</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             97.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 921078\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-14-25\n",
      "  done: false\n",
      "  episode_len_mean: 97.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.67000000000001\n",
      "  episode_reward_mean: 8.343400000000017\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 8950\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3190397063891093\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012610478178374837\n",
      "          policy_loss: -0.028489207981952598\n",
      "          total_loss: 0.14717779255339078\n",
      "          vf_explained_var: 0.9626034498214722\n",
      "          vf_loss: 0.18077757902266015\n",
      "    num_agent_steps_sampled: 921078\n",
      "    num_agent_steps_trained: 921078\n",
      "    num_steps_sampled: 921078\n",
      "    num_steps_trained: 921078\n",
      "  iterations_since_restore: 461\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97297297297297\n",
      "    ram_util_percent: 30.875675675675666\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432390284785054\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.004934168562194\n",
      "    mean_inference_ms: 2.4716163402776905\n",
      "    mean_raw_obs_processing_ms: 2.0403606058862995\n",
      "  time_since_restore: 12539.004997968674\n",
      "  time_this_iter_s: 26.02873730659485\n",
      "  time_total_s: 12539.004997968674\n",
      "  timers:\n",
      "    learn_throughput: 1165.345\n",
      "    learn_time_ms: 1714.513\n",
      "    load_throughput: 58537.927\n",
      "    load_time_ms: 34.132\n",
      "    sample_throughput: 73.687\n",
      "    sample_time_ms: 27114.823\n",
      "    update_time_ms: 6.316\n",
      "  timestamp: 1636442065\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 921078\n",
      "  training_iteration: 461\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   461</td><td style=\"text-align: right;\">           12539</td><td style=\"text-align: right;\">921078</td><td style=\"text-align: right;\">  8.3434</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             97.47</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 923076\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-14-52\n",
      "  done: false\n",
      "  episode_len_mean: 97.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000014\n",
      "  episode_reward_mean: 8.00140000000002\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 8970\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2617481793676104\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00897554847556113\n",
      "          policy_loss: -0.06021280709121909\n",
      "          total_loss: 0.006057911038043953\n",
      "          vf_explained_var: 0.988594651222229\n",
      "          vf_loss: 0.07313736375155193\n",
      "    num_agent_steps_sampled: 923076\n",
      "    num_agent_steps_trained: 923076\n",
      "    num_steps_sampled: 923076\n",
      "    num_steps_trained: 923076\n",
      "  iterations_since_restore: 462\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.21282051282053\n",
      "    ram_util_percent: 31.161538461538456\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044330937462544504\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.006528946957502\n",
      "    mean_inference_ms: 2.471682712708422\n",
      "    mean_raw_obs_processing_ms: 2.04839979674352\n",
      "  time_since_restore: 12566.174775123596\n",
      "  time_this_iter_s: 27.169777154922485\n",
      "  time_total_s: 12566.174775123596\n",
      "  timers:\n",
      "    learn_throughput: 1164.468\n",
      "    learn_time_ms: 1715.805\n",
      "    load_throughput: 58721.896\n",
      "    load_time_ms: 34.025\n",
      "    sample_throughput: 72.962\n",
      "    sample_time_ms: 27384.152\n",
      "    update_time_ms: 6.701\n",
      "  timestamp: 1636442092\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 923076\n",
      "  training_iteration: 462\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   462</td><td style=\"text-align: right;\">         12566.2</td><td style=\"text-align: right;\">923076</td><td style=\"text-align: right;\">  8.0014</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             97.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 925074\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-15-17\n",
      "  done: false\n",
      "  episode_len_mean: 99.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000014\n",
      "  episode_reward_mean: 8.05450000000002\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 8988\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2770709225109644\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010126714107506984\n",
      "          policy_loss: -0.017261506847682455\n",
      "          total_loss: 0.1444048038195996\n",
      "          vf_explained_var: 0.9744623303413391\n",
      "          vf_loss: 0.16794860595393749\n",
      "    num_agent_steps_sampled: 925074\n",
      "    num_agent_steps_trained: 925074\n",
      "    num_steps_sampled: 925074\n",
      "    num_steps_trained: 925074\n",
      "  iterations_since_restore: 463\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95833333333334\n",
      "    ram_util_percent: 31.208333333333332\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435569404660491\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00751837638349\n",
      "    mean_inference_ms: 2.4720222783312478\n",
      "    mean_raw_obs_processing_ms: 2.0517894599870248\n",
      "  time_since_restore: 12591.3573346138\n",
      "  time_this_iter_s: 25.182559490203857\n",
      "  time_total_s: 12591.3573346138\n",
      "  timers:\n",
      "    learn_throughput: 1163.627\n",
      "    learn_time_ms: 1717.044\n",
      "    load_throughput: 58640.906\n",
      "    load_time_ms: 34.072\n",
      "    sample_throughput: 73.135\n",
      "    sample_time_ms: 27319.453\n",
      "    update_time_ms: 7.569\n",
      "  timestamp: 1636442117\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 925074\n",
      "  training_iteration: 463\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   463</td><td style=\"text-align: right;\">         12591.4</td><td style=\"text-align: right;\">925074</td><td style=\"text-align: right;\">  8.0545</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             99.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 927072\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-15-41\n",
      "  done: false\n",
      "  episode_len_mean: 100.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000014\n",
      "  episode_reward_mean: 8.08140000000002\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9008\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.255234682559967\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01315531231788806\n",
      "          policy_loss: -0.03766564682480835\n",
      "          total_loss: 0.12477800510823726\n",
      "          vf_explained_var: 0.9676408171653748\n",
      "          vf_loss: 0.16656709135997863\n",
      "    num_agent_steps_sampled: 927072\n",
      "    num_agent_steps_trained: 927072\n",
      "    num_steps_sampled: 927072\n",
      "    num_steps_trained: 927072\n",
      "  iterations_since_restore: 464\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.47058823529412\n",
      "    ram_util_percent: 31.261764705882356\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436968574757264\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00668507302383\n",
      "    mean_inference_ms: 2.4721993094642896\n",
      "    mean_raw_obs_processing_ms: 2.0559456060183443\n",
      "  time_since_restore: 12615.205412864685\n",
      "  time_this_iter_s: 23.84807825088501\n",
      "  time_total_s: 12615.205412864685\n",
      "  timers:\n",
      "    learn_throughput: 1163.786\n",
      "    learn_time_ms: 1716.811\n",
      "    load_throughput: 58718.44\n",
      "    load_time_ms: 34.027\n",
      "    sample_throughput: 73.662\n",
      "    sample_time_ms: 27123.997\n",
      "    update_time_ms: 7.57\n",
      "  timestamp: 1636442141\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 927072\n",
      "  training_iteration: 464\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   464</td><td style=\"text-align: right;\">         12615.2</td><td style=\"text-align: right;\">927072</td><td style=\"text-align: right;\">  8.0814</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">            100.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 929070\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-16-06\n",
      "  done: false\n",
      "  episode_len_mean: 103.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000014\n",
      "  episode_reward_mean: 8.46550000000002\n",
      "  episode_reward_min: 4.1100000000000225\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9027\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.295387533732823\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011666184378022184\n",
      "          policy_loss: -0.0024640338051886788\n",
      "          total_loss: 0.10952537093488943\n",
      "          vf_explained_var: 0.9803905487060547\n",
      "          vf_loss: 0.11746849126759029\n",
      "    num_agent_steps_sampled: 929070\n",
      "    num_agent_steps_trained: 929070\n",
      "    num_steps_sampled: 929070\n",
      "    num_steps_trained: 929070\n",
      "  iterations_since_restore: 465\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.57142857142857\n",
      "    ram_util_percent: 31.32285714285715\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434751400647092\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00947953475692\n",
      "    mean_inference_ms: 2.4718215508291665\n",
      "    mean_raw_obs_processing_ms: 2.05309551203347\n",
      "  time_since_restore: 12639.899296045303\n",
      "  time_this_iter_s: 24.693883180618286\n",
      "  time_total_s: 12639.899296045303\n",
      "  timers:\n",
      "    learn_throughput: 1164.219\n",
      "    learn_time_ms: 1716.172\n",
      "    load_throughput: 58626.465\n",
      "    load_time_ms: 34.08\n",
      "    sample_throughput: 73.971\n",
      "    sample_time_ms: 27010.588\n",
      "    update_time_ms: 7.662\n",
      "  timestamp: 1636442166\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 929070\n",
      "  training_iteration: 465\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   465</td><td style=\"text-align: right;\">         12639.9</td><td style=\"text-align: right;\">929070</td><td style=\"text-align: right;\">  8.4655</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                4.11</td><td style=\"text-align: right;\">            103.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 931068\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-16-32\n",
      "  done: false\n",
      "  episode_len_mean: 102.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000014\n",
      "  episode_reward_mean: 8.631200000000018\n",
      "  episode_reward_min: 3.960000000000021\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9046\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.184913606870742\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012098058136312836\n",
      "          policy_loss: -0.04493875837042218\n",
      "          total_loss: 0.1273964810406878\n",
      "          vf_explained_var: 0.9781928658485413\n",
      "          vf_loss: 0.17643287533095905\n",
      "    num_agent_steps_sampled: 931068\n",
      "    num_agent_steps_trained: 931068\n",
      "    num_steps_sampled: 931068\n",
      "    num_steps_trained: 931068\n",
      "  iterations_since_restore: 466\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87894736842104\n",
      "    ram_util_percent: 31.307894736842112\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434359257385733\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.011564766089396\n",
      "    mean_inference_ms: 2.4716962840542234\n",
      "    mean_raw_obs_processing_ms: 2.0502247804016966\n",
      "  time_since_restore: 12666.167398929596\n",
      "  time_this_iter_s: 26.268102884292603\n",
      "  time_total_s: 12666.167398929596\n",
      "  timers:\n",
      "    learn_throughput: 1164.28\n",
      "    learn_time_ms: 1716.083\n",
      "    load_throughput: 58776.797\n",
      "    load_time_ms: 33.993\n",
      "    sample_throughput: 73.818\n",
      "    sample_time_ms: 27066.462\n",
      "    update_time_ms: 7.602\n",
      "  timestamp: 1636442192\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 931068\n",
      "  training_iteration: 466\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   466</td><td style=\"text-align: right;\">         12666.2</td><td style=\"text-align: right;\">931068</td><td style=\"text-align: right;\">  8.6312</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                3.96</td><td style=\"text-align: right;\">            102.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 933066\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-16-56\n",
      "  done: false\n",
      "  episode_len_mean: 104.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000012\n",
      "  episode_reward_mean: 8.442500000000019\n",
      "  episode_reward_min: 3.960000000000021\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 9064\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.293748902706873\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010728953984694927\n",
      "          policy_loss: -0.01751706124771209\n",
      "          total_loss: 0.16602977097389243\n",
      "          vf_explained_var: 0.9764853119850159\n",
      "          vf_loss: 0.18961003940729868\n",
      "    num_agent_steps_sampled: 933066\n",
      "    num_agent_steps_trained: 933066\n",
      "    num_steps_sampled: 933066\n",
      "    num_steps_trained: 933066\n",
      "  iterations_since_restore: 467\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04117647058824\n",
      "    ram_util_percent: 31.341176470588234\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432929709992127\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.011648430526098\n",
      "    mean_inference_ms: 2.4713963287280154\n",
      "    mean_raw_obs_processing_ms: 2.0474055763807173\n",
      "  time_since_restore: 12690.259310483932\n",
      "  time_this_iter_s: 24.091911554336548\n",
      "  time_total_s: 12690.259310483932\n",
      "  timers:\n",
      "    learn_throughput: 1163.918\n",
      "    learn_time_ms: 1716.615\n",
      "    load_throughput: 58827.712\n",
      "    load_time_ms: 33.964\n",
      "    sample_throughput: 74.787\n",
      "    sample_time_ms: 26715.95\n",
      "    update_time_ms: 7.788\n",
      "  timestamp: 1636442216\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 933066\n",
      "  training_iteration: 467\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   467</td><td style=\"text-align: right;\">         12690.3</td><td style=\"text-align: right;\">933066</td><td style=\"text-align: right;\">  8.4425</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                3.96</td><td style=\"text-align: right;\">            104.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 935064\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-17-22\n",
      "  done: false\n",
      "  episode_len_mean: 104.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.503900000000021\n",
      "  episode_reward_min: 3.2900000000000222\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 9085\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2748760484513781\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017025997933517157\n",
      "          policy_loss: -0.044306996358292446\n",
      "          total_loss: 0.23208422313133875\n",
      "          vf_explained_var: 0.9490517973899841\n",
      "          vf_loss: 0.27823103527937615\n",
      "    num_agent_steps_sampled: 935064\n",
      "    num_agent_steps_trained: 935064\n",
      "    num_steps_sampled: 935064\n",
      "    num_steps_trained: 935064\n",
      "  iterations_since_restore: 468\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9945945945946\n",
      "    ram_util_percent: 31.275675675675682\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044363310707863264\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.0085322983647\n",
      "    mean_inference_ms: 2.4718344250481925\n",
      "    mean_raw_obs_processing_ms: 2.044168916556017\n",
      "  time_since_restore: 12716.154153347015\n",
      "  time_this_iter_s: 25.894842863082886\n",
      "  time_total_s: 12716.154153347015\n",
      "  timers:\n",
      "    learn_throughput: 1163.299\n",
      "    learn_time_ms: 1717.53\n",
      "    load_throughput: 59111.915\n",
      "    load_time_ms: 33.8\n",
      "    sample_throughput: 79.107\n",
      "    sample_time_ms: 25256.816\n",
      "    update_time_ms: 7.68\n",
      "  timestamp: 1636442242\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 935064\n",
      "  training_iteration: 468\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   468</td><td style=\"text-align: right;\">         12716.2</td><td style=\"text-align: right;\">935064</td><td style=\"text-align: right;\">  8.5039</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                3.29</td><td style=\"text-align: right;\">             104.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 937062\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-17-46\n",
      "  done: false\n",
      "  episode_len_mean: 105.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.496200000000018\n",
      "  episode_reward_min: 0.7999999999999989\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 9103\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.306771733647301\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012928852535175936\n",
      "          policy_loss: -0.022624168615965615\n",
      "          total_loss: 0.1215094483856644\n",
      "          vf_explained_var: 0.9746482968330383\n",
      "          vf_loss: 0.1489175253858169\n",
      "    num_agent_steps_sampled: 937062\n",
      "    num_agent_steps_trained: 937062\n",
      "    num_steps_sampled: 937062\n",
      "    num_steps_trained: 937062\n",
      "  iterations_since_restore: 469\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14411764705883\n",
      "    ram_util_percent: 31.3264705882353\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434399097936988\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.008981770691552\n",
      "    mean_inference_ms: 2.4714448628012935\n",
      "    mean_raw_obs_processing_ms: 2.0414205820879046\n",
      "  time_since_restore: 12739.649025201797\n",
      "  time_this_iter_s: 23.494871854782104\n",
      "  time_total_s: 12739.649025201797\n",
      "  timers:\n",
      "    learn_throughput: 1164.761\n",
      "    learn_time_ms: 1715.374\n",
      "    load_throughput: 59239.865\n",
      "    load_time_ms: 33.727\n",
      "    sample_throughput: 80.262\n",
      "    sample_time_ms: 24893.46\n",
      "    update_time_ms: 8.066\n",
      "  timestamp: 1636442266\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 937062\n",
      "  training_iteration: 469\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   469</td><td style=\"text-align: right;\">         12739.6</td><td style=\"text-align: right;\">937062</td><td style=\"text-align: right;\">  8.4962</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            105.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 939060\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-18-12\n",
      "  done: false\n",
      "  episode_len_mean: 102.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.638900000000017\n",
      "  episode_reward_min: 0.7999999999999989\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9122\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6407226562500001\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2337208444163912\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.023130605179263342\n",
      "          policy_loss: -0.013160150178841182\n",
      "          total_loss: 0.4235162635444708\n",
      "          vf_explained_var: 0.9579694271087646\n",
      "          vf_loss: 0.4341933187984285\n",
      "    num_agent_steps_sampled: 939060\n",
      "    num_agent_steps_trained: 939060\n",
      "    num_steps_sampled: 939060\n",
      "    num_steps_trained: 939060\n",
      "  iterations_since_restore: 470\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.45277777777777\n",
      "    ram_util_percent: 31.26388888888889\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044352306411650985\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.007178642795306\n",
      "    mean_inference_ms: 2.471485649927131\n",
      "    mean_raw_obs_processing_ms: 2.0385165596848607\n",
      "  time_since_restore: 12765.38381767273\n",
      "  time_this_iter_s: 25.734792470932007\n",
      "  time_total_s: 12765.38381767273\n",
      "  timers:\n",
      "    learn_throughput: 1165.269\n",
      "    learn_time_ms: 1714.625\n",
      "    load_throughput: 59415.681\n",
      "    load_time_ms: 33.627\n",
      "    sample_throughput: 85.114\n",
      "    sample_time_ms: 23474.484\n",
      "    update_time_ms: 8.385\n",
      "  timestamp: 1636442292\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 939060\n",
      "  training_iteration: 470\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   470</td><td style=\"text-align: right;\">         12765.4</td><td style=\"text-align: right;\">939060</td><td style=\"text-align: right;\">  8.6389</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            102.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 941058\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-18-36\n",
      "  done: false\n",
      "  episode_len_mean: 106.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.41360000000002\n",
      "  episode_reward_min: 0.7999999999999989\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9142\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3123626249177116\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008421987907587799\n",
      "          policy_loss: -0.056277229716735225\n",
      "          total_loss: 0.15107922720767203\n",
      "          vf_explained_var: 0.9607823491096497\n",
      "          vf_loss: 0.21238584614225797\n",
      "    num_agent_steps_sampled: 941058\n",
      "    num_agent_steps_trained: 941058\n",
      "    num_steps_sampled: 941058\n",
      "    num_steps_trained: 941058\n",
      "  iterations_since_restore: 471\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.64857142857142\n",
      "    ram_util_percent: 31.225714285714282\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435960126319717\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.0042047500199\n",
      "    mean_inference_ms: 2.471526675623812\n",
      "    mean_raw_obs_processing_ms: 2.035493110812573\n",
      "  time_since_restore: 12789.44810795784\n",
      "  time_this_iter_s: 24.064290285110474\n",
      "  time_total_s: 12789.44810795784\n",
      "  timers:\n",
      "    learn_throughput: 1165.66\n",
      "    learn_time_ms: 1714.05\n",
      "    load_throughput: 59180.961\n",
      "    load_time_ms: 33.761\n",
      "    sample_throughput: 85.832\n",
      "    sample_time_ms: 23277.987\n",
      "    update_time_ms: 8.87\n",
      "  timestamp: 1636442316\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 941058\n",
      "  training_iteration: 471\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   471</td><td style=\"text-align: right;\">         12789.4</td><td style=\"text-align: right;\">941058</td><td style=\"text-align: right;\">  8.4136</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            106.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 943056\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-19-01\n",
      "  done: false\n",
      "  episode_len_mean: 105.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.50520000000002\n",
      "  episode_reward_min: 0.7999999999999989\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 9160\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2973893256414504\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007818773524150764\n",
      "          policy_loss: -0.004457949474453926\n",
      "          total_loss: 0.13601180472899052\n",
      "          vf_explained_var: 0.9762645959854126\n",
      "          vf_loss: 0.14592915120578948\n",
      "    num_agent_steps_sampled: 943056\n",
      "    num_agent_steps_trained: 943056\n",
      "    num_steps_sampled: 943056\n",
      "    num_steps_trained: 943056\n",
      "  iterations_since_restore: 472\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.09714285714286\n",
      "    ram_util_percent: 31.228571428571428\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436064133024411\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00297732441547\n",
      "    mean_inference_ms: 2.4714946463708225\n",
      "    mean_raw_obs_processing_ms: 2.0327988179695047\n",
      "  time_since_restore: 12814.252233028412\n",
      "  time_this_iter_s: 24.8041250705719\n",
      "  time_total_s: 12814.252233028412\n",
      "  timers:\n",
      "    learn_throughput: 1166.027\n",
      "    learn_time_ms: 1713.512\n",
      "    load_throughput: 59363.996\n",
      "    load_time_ms: 33.657\n",
      "    sample_throughput: 86.714\n",
      "    sample_time_ms: 23041.291\n",
      "    update_time_ms: 9.17\n",
      "  timestamp: 1636442341\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 943056\n",
      "  training_iteration: 472\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   472</td><td style=\"text-align: right;\">         12814.3</td><td style=\"text-align: right;\">943056</td><td style=\"text-align: right;\">  8.5052</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            105.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 945054\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-19-26\n",
      "  done: false\n",
      "  episode_len_mean: 105.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.523000000000017\n",
      "  episode_reward_min: 0.7999999999999989\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9180\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2526766532943363\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008167537136040471\n",
      "          policy_loss: -0.018848852210101626\n",
      "          total_loss: 0.112686083927041\n",
      "          vf_explained_var: 0.9828803539276123\n",
      "          vf_loss: 0.13621201266845068\n",
      "    num_agent_steps_sampled: 945054\n",
      "    num_agent_steps_trained: 945054\n",
      "    num_steps_sampled: 945054\n",
      "    num_steps_trained: 945054\n",
      "  iterations_since_restore: 473\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.71621621621622\n",
      "    ram_util_percent: 31.21351351351351\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435249391340239\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00156178990557\n",
      "    mean_inference_ms: 2.4713220035733965\n",
      "    mean_raw_obs_processing_ms: 2.0297865002205424\n",
      "  time_since_restore: 12839.913392305374\n",
      "  time_this_iter_s: 25.66115927696228\n",
      "  time_total_s: 12839.913392305374\n",
      "  timers:\n",
      "    learn_throughput: 1167.153\n",
      "    learn_time_ms: 1711.857\n",
      "    load_throughput: 59282.568\n",
      "    load_time_ms: 33.703\n",
      "    sample_throughput: 86.528\n",
      "    sample_time_ms: 23090.83\n",
      "    update_time_ms: 8.871\n",
      "  timestamp: 1636442366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 945054\n",
      "  training_iteration: 473\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   473</td><td style=\"text-align: right;\">         12839.9</td><td style=\"text-align: right;\">945054</td><td style=\"text-align: right;\">   8.523</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                 0.8</td><td style=\"text-align: right;\">            105.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 947052\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-19-51\n",
      "  done: false\n",
      "  episode_len_mean: 104.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.600500000000018\n",
      "  episode_reward_min: 1.1399999999999992\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9199\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.28315665324529\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01085669233394809\n",
      "          policy_loss: -0.03771705508586906\n",
      "          total_loss: 0.1273980721653927\n",
      "          vf_explained_var: 0.9730768203735352\n",
      "          vf_loss: 0.16751250245031857\n",
      "    num_agent_steps_sampled: 947052\n",
      "    num_agent_steps_trained: 947052\n",
      "    num_steps_sampled: 947052\n",
      "    num_steps_trained: 947052\n",
      "  iterations_since_restore: 474\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96571428571428\n",
      "    ram_util_percent: 31.205714285714286\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044353942533747484\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00116996478047\n",
      "    mean_inference_ms: 2.471306232523932\n",
      "    mean_raw_obs_processing_ms: 2.0269356536867322\n",
      "  time_since_restore: 12864.304997205734\n",
      "  time_this_iter_s: 24.391604900360107\n",
      "  time_total_s: 12864.304997205734\n",
      "  timers:\n",
      "    learn_throughput: 1167.431\n",
      "    learn_time_ms: 1711.45\n",
      "    load_throughput: 59350.584\n",
      "    load_time_ms: 33.664\n",
      "    sample_throughput: 86.321\n",
      "    sample_time_ms: 23146.197\n",
      "    update_time_ms: 8.477\n",
      "  timestamp: 1636442391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 947052\n",
      "  training_iteration: 474\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   474</td><td style=\"text-align: right;\">         12864.3</td><td style=\"text-align: right;\">947052</td><td style=\"text-align: right;\">  8.6005</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                1.14</td><td style=\"text-align: right;\">            104.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 949050\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-20-16\n",
      "  done: false\n",
      "  episode_len_mean: 103.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.69720000000002\n",
      "  episode_reward_min: 1.1000000000000034\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 9220\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2150553399608248\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008441232825798638\n",
      "          policy_loss: -0.006060245437991051\n",
      "          total_loss: 0.12324929353559301\n",
      "          vf_explained_var: 0.9729400873184204\n",
      "          vf_loss: 0.1333473578716318\n",
      "    num_agent_steps_sampled: 949050\n",
      "    num_agent_steps_trained: 949050\n",
      "    num_steps_sampled: 949050\n",
      "    num_steps_trained: 949050\n",
      "  iterations_since_restore: 475\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04594594594593\n",
      "    ram_util_percent: 31.151351351351355\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044371251342774906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00062519947609\n",
      "    mean_inference_ms: 2.471566938260848\n",
      "    mean_raw_obs_processing_ms: 2.0238873935430455\n",
      "  time_since_restore: 12890.108298301697\n",
      "  time_this_iter_s: 25.803301095962524\n",
      "  time_total_s: 12890.108298301697\n",
      "  timers:\n",
      "    learn_throughput: 1166.888\n",
      "    learn_time_ms: 1712.247\n",
      "    load_throughput: 59436.92\n",
      "    load_time_ms: 33.615\n",
      "    sample_throughput: 85.913\n",
      "    sample_time_ms: 23256.185\n",
      "    update_time_ms: 8.945\n",
      "  timestamp: 1636442416\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 949050\n",
      "  training_iteration: 475\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   475</td><td style=\"text-align: right;\">         12890.1</td><td style=\"text-align: right;\">949050</td><td style=\"text-align: right;\">  8.6972</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                 1.1</td><td style=\"text-align: right;\">            103.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 951048\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-20-40\n",
      "  done: false\n",
      "  episode_len_mean: 103.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.66860000000002\n",
      "  episode_reward_min: 1.1000000000000034\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 9238\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3041623478844053\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009737177060083407\n",
      "          policy_loss: -0.014926485983388764\n",
      "          total_loss: 0.16769730950750056\n",
      "          vf_explained_var: 0.9602910280227661\n",
      "          vf_loss: 0.18630717375448771\n",
      "    num_agent_steps_sampled: 951048\n",
      "    num_agent_steps_trained: 951048\n",
      "    num_steps_sampled: 951048\n",
      "    num_steps_trained: 951048\n",
      "  iterations_since_restore: 476\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.41764705882353\n",
      "    ram_util_percent: 31.13823529411765\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434876056708699\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00292329542183\n",
      "    mean_inference_ms: 2.471245374924622\n",
      "    mean_raw_obs_processing_ms: 2.0212881621211816\n",
      "  time_since_restore: 12914.0375893116\n",
      "  time_this_iter_s: 23.929291009902954\n",
      "  time_total_s: 12914.0375893116\n",
      "  timers:\n",
      "    learn_throughput: 1166.65\n",
      "    learn_time_ms: 1712.596\n",
      "    load_throughput: 59298.467\n",
      "    load_time_ms: 33.694\n",
      "    sample_throughput: 86.789\n",
      "    sample_time_ms: 23021.375\n",
      "    update_time_ms: 9.454\n",
      "  timestamp: 1636442440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 951048\n",
      "  training_iteration: 476\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   476</td><td style=\"text-align: right;\">           12914</td><td style=\"text-align: right;\">951048</td><td style=\"text-align: right;\">  8.6686</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                 1.1</td><td style=\"text-align: right;\">            103.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 953046\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-21-19\n",
      "  done: false\n",
      "  episode_len_mean: 103.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 8.518500000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9257\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3094225997016544\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007777644986223633\n",
      "          policy_loss: -0.016681447465504918\n",
      "          total_loss: 0.1634947405241075\n",
      "          vf_explained_var: 0.9456063508987427\n",
      "          vf_loss: 0.18579544357600666\n",
      "    num_agent_steps_sampled: 953046\n",
      "    num_agent_steps_trained: 953046\n",
      "    num_steps_sampled: 953046\n",
      "    num_steps_trained: 953046\n",
      "  iterations_since_restore: 477\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.09814814814816\n",
      "    ram_util_percent: 31.042592592592595\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434812878762191\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00212224834504\n",
      "    mean_inference_ms: 2.4712332250204123\n",
      "    mean_raw_obs_processing_ms: 2.022026858018881\n",
      "  time_since_restore: 12952.256504535675\n",
      "  time_this_iter_s: 38.21891522407532\n",
      "  time_total_s: 12952.256504535675\n",
      "  timers:\n",
      "    learn_throughput: 1167.015\n",
      "    learn_time_ms: 1712.06\n",
      "    load_throughput: 59244.011\n",
      "    load_time_ms: 33.725\n",
      "    sample_throughput: 81.771\n",
      "    sample_time_ms: 24433.96\n",
      "    update_time_ms: 9.936\n",
      "  timestamp: 1636442479\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 953046\n",
      "  training_iteration: 477\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   477</td><td style=\"text-align: right;\">         12952.3</td><td style=\"text-align: right;\">953046</td><td style=\"text-align: right;\">  8.5185</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            103.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 955044\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-22-01\n",
      "  done: false\n",
      "  episode_len_mean: 102.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 8.547400000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 9278\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.287097676027389\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0077633082392784365\n",
      "          policy_loss: -0.06014566260079543\n",
      "          total_loss: 0.09867889612380948\n",
      "          vf_explained_var: 0.965850830078125\n",
      "          vf_loss: 0.16423434496280692\n",
      "    num_agent_steps_sampled: 955044\n",
      "    num_agent_steps_trained: 955044\n",
      "    num_steps_sampled: 955044\n",
      "    num_steps_trained: 955044\n",
      "  iterations_since_restore: 478\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.69999999999999\n",
      "    ram_util_percent: 31.245901639344265\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435742208427275\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00219690641297\n",
      "    mean_inference_ms: 2.4713707028973904\n",
      "    mean_raw_obs_processing_ms: 2.026810410655707\n",
      "  time_since_restore: 12994.495206356049\n",
      "  time_this_iter_s: 42.238701820373535\n",
      "  time_total_s: 12994.495206356049\n",
      "  timers:\n",
      "    learn_throughput: 1164.861\n",
      "    learn_time_ms: 1715.227\n",
      "    load_throughput: 59169.846\n",
      "    load_time_ms: 33.767\n",
      "    sample_throughput: 76.656\n",
      "    sample_time_ms: 26064.576\n",
      "    update_time_ms: 10.431\n",
      "  timestamp: 1636442521\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 955044\n",
      "  training_iteration: 478\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   478</td><td style=\"text-align: right;\">         12994.5</td><td style=\"text-align: right;\">955044</td><td style=\"text-align: right;\">  8.5474</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            102.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 957042\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-22-41\n",
      "  done: false\n",
      "  episode_len_mean: 101.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 8.327500000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9297\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3046112406821477\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015099065091687461\n",
      "          policy_loss: -0.02815070826382864\n",
      "          total_loss: 0.2683397469066438\n",
      "          vf_explained_var: 0.9315003752708435\n",
      "          vf_loss: 0.2950250997961987\n",
      "    num_agent_steps_sampled: 957042\n",
      "    num_agent_steps_trained: 957042\n",
      "    num_steps_sampled: 957042\n",
      "    num_steps_trained: 957042\n",
      "  iterations_since_restore: 479\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.97678571428573\n",
      "    ram_util_percent: 30.916071428571428\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044360821031649865\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.000411607838043\n",
      "    mean_inference_ms: 2.4714310355160602\n",
      "    mean_raw_obs_processing_ms: 2.033805156133273\n",
      "  time_since_restore: 13034.067180395126\n",
      "  time_this_iter_s: 39.57197403907776\n",
      "  time_total_s: 13034.067180395126\n",
      "  timers:\n",
      "    learn_throughput: 1163.192\n",
      "    learn_time_ms: 1717.686\n",
      "    load_throughput: 59237.352\n",
      "    load_time_ms: 33.729\n",
      "    sample_throughput: 72.21\n",
      "    sample_time_ms: 27669.382\n",
      "    update_time_ms: 10.738\n",
      "  timestamp: 1636442561\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 957042\n",
      "  training_iteration: 479\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   479</td><td style=\"text-align: right;\">         13034.1</td><td style=\"text-align: right;\">957042</td><td style=\"text-align: right;\">  8.3275</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            101.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 959040\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-23-06\n",
      "  done: false\n",
      "  episode_len_mean: 101.83\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 8.43680000000002\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9317\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.33638847385134\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008844986538867838\n",
      "          policy_loss: 0.004775378178982508\n",
      "          total_loss: 0.21064449625001067\n",
      "          vf_explained_var: 0.9668878316879272\n",
      "          vf_loss: 0.21073222905397415\n",
      "    num_agent_steps_sampled: 959040\n",
      "    num_agent_steps_trained: 959040\n",
      "    num_steps_sampled: 959040\n",
      "    num_steps_trained: 959040\n",
      "  iterations_since_restore: 480\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69459459459459\n",
      "    ram_util_percent: 30.962162162162166\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434420773668477\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.999712363906806\n",
      "    mean_inference_ms: 2.4711406313877013\n",
      "    mean_raw_obs_processing_ms: 2.0411202048482298\n",
      "  time_since_restore: 13059.697427272797\n",
      "  time_this_iter_s: 25.630246877670288\n",
      "  time_total_s: 13059.697427272797\n",
      "  timers:\n",
      "    learn_throughput: 1162.852\n",
      "    learn_time_ms: 1718.189\n",
      "    load_throughput: 59090.783\n",
      "    load_time_ms: 33.812\n",
      "    sample_throughput: 72.239\n",
      "    sample_time_ms: 27658.329\n",
      "    update_time_ms: 10.825\n",
      "  timestamp: 1636442586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 959040\n",
      "  training_iteration: 480\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   480</td><td style=\"text-align: right;\">         13059.7</td><td style=\"text-align: right;\">959040</td><td style=\"text-align: right;\">  8.4368</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            101.83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 961038\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-23-30\n",
      "  done: false\n",
      "  episode_len_mean: 102.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000015\n",
      "  episode_reward_mean: 8.370900000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9336\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.370582634494418\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008615217275097566\n",
      "          policy_loss: -0.03377928815427281\n",
      "          total_loss: 0.12762245812586376\n",
      "          vf_explained_var: 0.9634919762611389\n",
      "          vf_loss: 0.1668276256039029\n",
      "    num_agent_steps_sampled: 961038\n",
      "    num_agent_steps_trained: 961038\n",
      "    num_steps_sampled: 961038\n",
      "    num_steps_trained: 961038\n",
      "  iterations_since_restore: 481\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.12058823529412\n",
      "    ram_util_percent: 31.108823529411765\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436675942704112\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99600957103614\n",
      "    mean_inference_ms: 2.471435219616528\n",
      "    mean_raw_obs_processing_ms: 2.048092175015229\n",
      "  time_since_restore: 13083.440314531326\n",
      "  time_this_iter_s: 23.742887258529663\n",
      "  time_total_s: 13083.440314531326\n",
      "  timers:\n",
      "    learn_throughput: 1162.018\n",
      "    learn_time_ms: 1719.422\n",
      "    load_throughput: 59415.597\n",
      "    load_time_ms: 33.628\n",
      "    sample_throughput: 72.327\n",
      "    sample_time_ms: 27624.631\n",
      "    update_time_ms: 11.156\n",
      "  timestamp: 1636442610\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 961038\n",
      "  training_iteration: 481\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   481</td><td style=\"text-align: right;\">         13083.4</td><td style=\"text-align: right;\">961038</td><td style=\"text-align: right;\">  8.3709</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            102.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 963036\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-23-55\n",
      "  done: false\n",
      "  episode_len_mean: 100.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000015\n",
      "  episode_reward_mean: 8.510100000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9355\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3483777273268926\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010576584070230093\n",
      "          policy_loss: -0.025897859036922453\n",
      "          total_loss: 0.1397572303545617\n",
      "          vf_explained_var: 0.9713127017021179\n",
      "          vf_loss: 0.16897388224800428\n",
      "    num_agent_steps_sampled: 963036\n",
      "    num_agent_steps_trained: 963036\n",
      "    num_steps_sampled: 963036\n",
      "    num_steps_trained: 963036\n",
      "  iterations_since_restore: 482\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33055555555555\n",
      "    ram_util_percent: 31.219444444444452\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437014703790092\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.995683018778003\n",
      "    mean_inference_ms: 2.4714032061440947\n",
      "    mean_raw_obs_processing_ms: 2.0525391186277995\n",
      "  time_since_restore: 13108.800734758377\n",
      "  time_this_iter_s: 25.36042022705078\n",
      "  time_total_s: 13108.800734758377\n",
      "  timers:\n",
      "    learn_throughput: 1162.346\n",
      "    learn_time_ms: 1718.938\n",
      "    load_throughput: 59365.426\n",
      "    load_time_ms: 33.656\n",
      "    sample_throughput: 72.18\n",
      "    sample_time_ms: 27680.788\n",
      "    update_time_ms: 11.336\n",
      "  timestamp: 1636442635\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 963036\n",
      "  training_iteration: 482\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   482</td><td style=\"text-align: right;\">         13108.8</td><td style=\"text-align: right;\">963036</td><td style=\"text-align: right;\">  8.5101</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             100.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 965034\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-24-19\n",
      "  done: false\n",
      "  episode_len_mean: 102.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000015\n",
      "  episode_reward_mean: 8.258200000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 9373\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3783443246568952\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012819865984949327\n",
      "          policy_loss: -0.02133625479681151\n",
      "          total_loss: 0.1971303440186949\n",
      "          vf_explained_var: 0.9488179683685303\n",
      "          vf_loss: 0.219929071977025\n",
      "    num_agent_steps_sampled: 965034\n",
      "    num_agent_steps_trained: 965034\n",
      "    num_steps_sampled: 965034\n",
      "    num_steps_trained: 965034\n",
      "  iterations_since_restore: 483\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.43235294117648\n",
      "    ram_util_percent: 31.291176470588237\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433108585739522\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.995017296610907\n",
      "    mean_inference_ms: 2.470709639012441\n",
      "    mean_raw_obs_processing_ms: 2.0527768144682392\n",
      "  time_since_restore: 13132.76003408432\n",
      "  time_this_iter_s: 23.959299325942993\n",
      "  time_total_s: 13132.76003408432\n",
      "  timers:\n",
      "    learn_throughput: 1161.441\n",
      "    learn_time_ms: 1720.276\n",
      "    load_throughput: 59665.479\n",
      "    load_time_ms: 33.487\n",
      "    sample_throughput: 72.629\n",
      "    sample_time_ms: 27509.548\n",
      "    update_time_ms: 11.434\n",
      "  timestamp: 1636442659\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 965034\n",
      "  training_iteration: 483\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   483</td><td style=\"text-align: right;\">         13132.8</td><td style=\"text-align: right;\">965034</td><td style=\"text-align: right;\">  8.2582</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            102.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 967032\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-24-44\n",
      "  done: false\n",
      "  episode_len_mean: 105.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000015\n",
      "  episode_reward_mean: 8.217800000000018\n",
      "  episode_reward_min: 3.8300000000000214\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9392\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2812024479820614\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013520465235456735\n",
      "          policy_loss: -0.00968151262828282\n",
      "          total_loss: 0.20174849164627848\n",
      "          vf_explained_var: 0.958791971206665\n",
      "          vf_loss: 0.21124772567834174\n",
      "    num_agent_steps_sampled: 967032\n",
      "    num_agent_steps_trained: 967032\n",
      "    num_steps_sampled: 967032\n",
      "    num_steps_trained: 967032\n",
      "  iterations_since_restore: 484\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.28571428571428\n",
      "    ram_util_percent: 31.305714285714295\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433590020345999\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.992673548237253\n",
      "    mean_inference_ms: 2.4706928105283463\n",
      "    mean_raw_obs_processing_ms: 2.049911571136511\n",
      "  time_since_restore: 13157.287494897842\n",
      "  time_this_iter_s: 24.52746081352234\n",
      "  time_total_s: 13157.287494897842\n",
      "  timers:\n",
      "    learn_throughput: 1162.568\n",
      "    learn_time_ms: 1718.609\n",
      "    load_throughput: 59046.275\n",
      "    load_time_ms: 33.838\n",
      "    sample_throughput: 72.592\n",
      "    sample_time_ms: 27523.879\n",
      "    update_time_ms: 12.063\n",
      "  timestamp: 1636442684\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 967032\n",
      "  training_iteration: 484\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   484</td><td style=\"text-align: right;\">         13157.3</td><td style=\"text-align: right;\">967032</td><td style=\"text-align: right;\">  8.2178</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                3.83</td><td style=\"text-align: right;\">            105.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 969030\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 106.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000015\n",
      "  episode_reward_mean: 7.869300000000019\n",
      "  episode_reward_min: 2.490000000000017\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 9410\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.9610839843749998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4192433005287535\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.023797281646626835\n",
      "          policy_loss: 0.0056829453756411874\n",
      "          total_loss: 0.32442486259554115\n",
      "          vf_explained_var: 0.9472231864929199\n",
      "          vf_loss: 0.31006315864977385\n",
      "    num_agent_steps_sampled: 969030\n",
      "    num_agent_steps_trained: 969030\n",
      "    num_steps_sampled: 969030\n",
      "    num_steps_trained: 969030\n",
      "  iterations_since_restore: 485\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.86571428571428\n",
      "    ram_util_percent: 31.31428571428572\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433307164202362\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.990733795222887\n",
      "    mean_inference_ms: 2.470583403507619\n",
      "    mean_raw_obs_processing_ms: 2.0471982158322275\n",
      "  time_since_restore: 13181.791589975357\n",
      "  time_this_iter_s: 24.50409507751465\n",
      "  time_total_s: 13181.791589975357\n",
      "  timers:\n",
      "    learn_throughput: 1162.278\n",
      "    learn_time_ms: 1719.038\n",
      "    load_throughput: 59010.103\n",
      "    load_time_ms: 33.859\n",
      "    sample_throughput: 72.937\n",
      "    sample_time_ms: 27393.537\n",
      "    update_time_ms: 11.963\n",
      "  timestamp: 1636442709\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 969030\n",
      "  training_iteration: 485\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   485</td><td style=\"text-align: right;\">         13181.8</td><td style=\"text-align: right;\">969030</td><td style=\"text-align: right;\">  7.8693</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                2.49</td><td style=\"text-align: right;\">            106.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 971028\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-25-34\n",
      "  done: false\n",
      "  episode_len_mean: 105.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 8.07710000000002\n",
      "  episode_reward_min: 2.490000000000017\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9430\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.4416259765625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2202425982270921\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0069970615434194255\n",
      "          policy_loss: -0.0776516702558313\n",
      "          total_loss: 0.11292846252520879\n",
      "          vf_explained_var: 0.9691931009292603\n",
      "          vf_loss: 0.19269541454102312\n",
      "    num_agent_steps_sampled: 971028\n",
      "    num_agent_steps_trained: 971028\n",
      "    num_steps_sampled: 971028\n",
      "    num_steps_trained: 971028\n",
      "  iterations_since_restore: 486\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72702702702702\n",
      "    ram_util_percent: 31.31621621621623\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432337066103289\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.987608191261998\n",
      "    mean_inference_ms: 2.4703738778177207\n",
      "    mean_raw_obs_processing_ms: 2.0441136899751253\n",
      "  time_since_restore: 13207.665608644485\n",
      "  time_this_iter_s: 25.874018669128418\n",
      "  time_total_s: 13207.665608644485\n",
      "  timers:\n",
      "    learn_throughput: 1161.993\n",
      "    learn_time_ms: 1719.46\n",
      "    load_throughput: 59263.451\n",
      "    load_time_ms: 33.714\n",
      "    sample_throughput: 72.422\n",
      "    sample_time_ms: 27588.148\n",
      "    update_time_ms: 11.797\n",
      "  timestamp: 1636442734\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 971028\n",
      "  training_iteration: 486\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   486</td><td style=\"text-align: right;\">         13207.7</td><td style=\"text-align: right;\">971028</td><td style=\"text-align: right;\">  8.0771</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">                2.49</td><td style=\"text-align: right;\">            105.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 973026\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-25-59\n",
      "  done: false\n",
      "  episode_len_mean: 105.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 7.93960000000002\n",
      "  episode_reward_min: 2.490000000000017\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9450\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.4416259765625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.316893546354203\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006095951624995006\n",
      "          policy_loss: -0.05780257515254475\n",
      "          total_loss: 0.055868073450844914\n",
      "          vf_explained_var: 0.9712629318237305\n",
      "          vf_loss: 0.11805150445018496\n",
      "    num_agent_steps_sampled: 973026\n",
      "    num_agent_steps_trained: 973026\n",
      "    num_steps_sampled: 973026\n",
      "    num_steps_trained: 973026\n",
      "  iterations_since_restore: 487\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9742857142857\n",
      "    ram_util_percent: 31.302857142857153\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044336375028917054\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.9851952442568\n",
      "    mean_inference_ms: 2.4704894096518104\n",
      "    mean_raw_obs_processing_ms: 2.041177603409719\n",
      "  time_since_restore: 13232.252811670303\n",
      "  time_this_iter_s: 24.58720302581787\n",
      "  time_total_s: 13232.252811670303\n",
      "  timers:\n",
      "    learn_throughput: 1160.875\n",
      "    learn_time_ms: 1721.116\n",
      "    load_throughput: 59094.825\n",
      "    load_time_ms: 33.81\n",
      "    sample_throughput: 76.192\n",
      "    sample_time_ms: 26223.374\n",
      "    update_time_ms: 11.897\n",
      "  timestamp: 1636442759\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 973026\n",
      "  training_iteration: 487\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   487</td><td style=\"text-align: right;\">         13232.3</td><td style=\"text-align: right;\">973026</td><td style=\"text-align: right;\">  7.9396</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">                2.49</td><td style=\"text-align: right;\">            105.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 975024\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-26-24\n",
      "  done: false\n",
      "  episode_len_mean: 105.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 8.223600000000017\n",
      "  episode_reward_min: 2.490000000000017\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 9468\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.4416259765625\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2455804075513568\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.004947152240946221\n",
      "          policy_loss: -0.1185408479755833\n",
      "          total_loss: 0.02198632698328722\n",
      "          vf_explained_var: 0.9807801842689514\n",
      "          vf_loss: 0.14585103813026631\n",
      "    num_agent_steps_sampled: 975024\n",
      "    num_agent_steps_trained: 975024\n",
      "    num_steps_sampled: 975024\n",
      "    num_steps_trained: 975024\n",
      "  iterations_since_restore: 488\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.86216216216216\n",
      "    ram_util_percent: 31.318918918918918\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044346827286846316\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.98369064808781\n",
      "    mean_inference_ms: 2.4705983700942524\n",
      "    mean_raw_obs_processing_ms: 2.0385660651893516\n",
      "  time_since_restore: 13257.655983448029\n",
      "  time_this_iter_s: 25.40317177772522\n",
      "  time_total_s: 13257.655983448029\n",
      "  timers:\n",
      "    learn_throughput: 1162.621\n",
      "    learn_time_ms: 1718.53\n",
      "    load_throughput: 58922.888\n",
      "    load_time_ms: 33.909\n",
      "    sample_throughput: 81.407\n",
      "    sample_time_ms: 24543.359\n",
      "    update_time_ms: 11.041\n",
      "  timestamp: 1636442784\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 975024\n",
      "  training_iteration: 488\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   488</td><td style=\"text-align: right;\">         13257.7</td><td style=\"text-align: right;\">975024</td><td style=\"text-align: right;\">  8.2236</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">                2.49</td><td style=\"text-align: right;\">            105.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 977022\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-26-50\n",
      "  done: false\n",
      "  episode_len_mean: 104.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.278500000000019\n",
      "  episode_reward_min: 2.490000000000017\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9488\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3649146148136684\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009937563007848805\n",
      "          policy_loss: -0.09258249751513913\n",
      "          total_loss: 0.03132838852526176\n",
      "          vf_explained_var: 0.9679703712463379\n",
      "          vf_loss: 0.1303969077411152\n",
      "    num_agent_steps_sampled: 977022\n",
      "    num_agent_steps_trained: 977022\n",
      "    num_steps_sampled: 977022\n",
      "    num_steps_trained: 977022\n",
      "  iterations_since_restore: 489\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.86285714285714\n",
      "    ram_util_percent: 31.228571428571428\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044345417641674344\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.982388879650333\n",
      "    mean_inference_ms: 2.470532090218927\n",
      "    mean_raw_obs_processing_ms: 2.035670450953336\n",
      "  time_since_restore: 13282.716559648514\n",
      "  time_this_iter_s: 25.06057620048523\n",
      "  time_total_s: 13282.716559648514\n",
      "  timers:\n",
      "    learn_throughput: 1162.231\n",
      "    learn_time_ms: 1719.108\n",
      "    load_throughput: 59133.021\n",
      "    load_time_ms: 33.788\n",
      "    sample_throughput: 86.523\n",
      "    sample_time_ms: 23092.238\n",
      "    update_time_ms: 10.705\n",
      "  timestamp: 1636442810\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 977022\n",
      "  training_iteration: 489\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   489</td><td style=\"text-align: right;\">         13282.7</td><td style=\"text-align: right;\">977022</td><td style=\"text-align: right;\">  8.2785</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.49</td><td style=\"text-align: right;\">            104.23</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 979020\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-27-14\n",
      "  done: false\n",
      "  episode_len_mean: 102.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.445200000000018\n",
      "  episode_reward_min: 2.820000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9508\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2767489217576526\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013613878900360695\n",
      "          policy_loss: -0.052184934727847576\n",
      "          total_loss: 0.25899076739414817\n",
      "          vf_explained_var: 0.9430850148200989\n",
      "          vf_loss: 0.3141301335323425\n",
      "    num_agent_steps_sampled: 979020\n",
      "    num_agent_steps_trained: 979020\n",
      "    num_steps_sampled: 979020\n",
      "    num_steps_trained: 979020\n",
      "  iterations_since_restore: 490\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96\n",
      "    ram_util_percent: 31.197142857142854\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435007080982453\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.980993592895587\n",
      "    mean_inference_ms: 2.4705639378269364\n",
      "    mean_raw_obs_processing_ms: 2.0328301520413588\n",
      "  time_since_restore: 13307.289641857147\n",
      "  time_this_iter_s: 24.573082208633423\n",
      "  time_total_s: 13307.289641857147\n",
      "  timers:\n",
      "    learn_throughput: 1163.403\n",
      "    learn_time_ms: 1717.376\n",
      "    load_throughput: 58926.493\n",
      "    load_time_ms: 33.907\n",
      "    sample_throughput: 86.916\n",
      "    sample_time_ms: 22987.674\n",
      "    update_time_ms: 11.5\n",
      "  timestamp: 1636442834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 979020\n",
      "  training_iteration: 490\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   490</td><td style=\"text-align: right;\">         13307.3</td><td style=\"text-align: right;\">979020</td><td style=\"text-align: right;\">  8.4452</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.82</td><td style=\"text-align: right;\">            102.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 981018\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-27-41\n",
      "  done: false\n",
      "  episode_len_mean: 101.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.298600000000016\n",
      "  episode_reward_min: 2.820000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9528\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2122203026499068\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009737003914263147\n",
      "          policy_loss: -0.005565816554285231\n",
      "          total_loss: 0.17958246196309727\n",
      "          vf_explained_var: 0.9662787914276123\n",
      "          vf_loss: 0.1902519224300271\n",
      "    num_agent_steps_sampled: 981018\n",
      "    num_agent_steps_trained: 981018\n",
      "    num_steps_sampled: 981018\n",
      "    num_steps_trained: 981018\n",
      "  iterations_since_restore: 491\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.17894736842102\n",
      "    ram_util_percent: 31.213157894736835\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044378558323244756\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.980263019921548\n",
      "    mean_inference_ms: 2.4709277118313433\n",
      "    mean_raw_obs_processing_ms: 2.030119295452234\n",
      "  time_since_restore: 13333.708466053009\n",
      "  time_this_iter_s: 26.418824195861816\n",
      "  time_total_s: 13333.708466053009\n",
      "  timers:\n",
      "    learn_throughput: 1163.455\n",
      "    learn_time_ms: 1717.298\n",
      "    load_throughput: 58916.964\n",
      "    load_time_ms: 33.912\n",
      "    sample_throughput: 85.912\n",
      "    sample_time_ms: 23256.283\n",
      "    update_time_ms: 10.734\n",
      "  timestamp: 1636442861\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 981018\n",
      "  training_iteration: 491\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   491</td><td style=\"text-align: right;\">         13333.7</td><td style=\"text-align: right;\">981018</td><td style=\"text-align: right;\">  8.2986</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.82</td><td style=\"text-align: right;\">            101.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 983016\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-28-06\n",
      "  done: false\n",
      "  episode_len_mean: 101.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.44430000000002\n",
      "  episode_reward_min: 2.820000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9548\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.173776033946446\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011706913208260821\n",
      "          policy_loss: -0.005429130420088768\n",
      "          total_loss: 0.18326009724821363\n",
      "          vf_explained_var: 0.9683172106742859\n",
      "          vf_loss: 0.19198849272160304\n",
      "    num_agent_steps_sampled: 983016\n",
      "    num_agent_steps_trained: 983016\n",
      "    num_steps_sampled: 983016\n",
      "    num_steps_trained: 983016\n",
      "  iterations_since_restore: 492\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.93513513513513\n",
      "    ram_util_percent: 31.14054054054054\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04438503284462938\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.979713904085507\n",
      "    mean_inference_ms: 2.470954757943984\n",
      "    mean_raw_obs_processing_ms: 2.0273473950924954\n",
      "  time_since_restore: 13359.53584241867\n",
      "  time_this_iter_s: 25.82737636566162\n",
      "  time_total_s: 13359.53584241867\n",
      "  timers:\n",
      "    learn_throughput: 1163.765\n",
      "    learn_time_ms: 1716.842\n",
      "    load_throughput: 58857.626\n",
      "    load_time_ms: 33.946\n",
      "    sample_throughput: 85.74\n",
      "    sample_time_ms: 23303.131\n",
      "    update_time_ms: 10.718\n",
      "  timestamp: 1636442886\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 983016\n",
      "  training_iteration: 492\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   492</td><td style=\"text-align: right;\">         13359.5</td><td style=\"text-align: right;\">983016</td><td style=\"text-align: right;\">  8.4443</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                2.82</td><td style=\"text-align: right;\">            101.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 985014\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-28-33\n",
      "  done: false\n",
      "  episode_len_mean: 100.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.393600000000019\n",
      "  episode_reward_min: 2.820000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9568\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2528010391053699\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00923721134907511\n",
      "          policy_loss: -0.042329334600695545\n",
      "          total_loss: 0.06646240665799096\n",
      "          vf_explained_var: 0.9808676838874817\n",
      "          vf_loss: 0.11466144811184634\n",
      "    num_agent_steps_sampled: 985014\n",
      "    num_agent_steps_trained: 985014\n",
      "    num_steps_sampled: 985014\n",
      "    num_steps_trained: 985014\n",
      "  iterations_since_restore: 493\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6842105263158\n",
      "    ram_util_percent: 31.115789473684206\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439132637988484\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.97965005870265\n",
      "    mean_inference_ms: 2.4709967046977166\n",
      "    mean_raw_obs_processing_ms: 2.0245903984098375\n",
      "  time_since_restore: 13386.171459674835\n",
      "  time_this_iter_s: 26.63561725616455\n",
      "  time_total_s: 13386.171459674835\n",
      "  timers:\n",
      "    learn_throughput: 1165.136\n",
      "    learn_time_ms: 1714.822\n",
      "    load_throughput: 58572.95\n",
      "    load_time_ms: 34.111\n",
      "    sample_throughput: 84.759\n",
      "    sample_time_ms: 23572.847\n",
      "    update_time_ms: 10.649\n",
      "  timestamp: 1636442913\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 985014\n",
      "  training_iteration: 493\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   493</td><td style=\"text-align: right;\">         13386.2</td><td style=\"text-align: right;\">985014</td><td style=\"text-align: right;\">  8.3936</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                2.82</td><td style=\"text-align: right;\">            100.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 987012\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-28-59\n",
      "  done: false\n",
      "  episode_len_mean: 100.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.765500000000019\n",
      "  episode_reward_min: 3.780000000000019\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9588\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1441243699618748\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010769665473099535\n",
      "          policy_loss: -0.04600232651545888\n",
      "          total_loss: 0.1697909929168721\n",
      "          vf_explained_var: 0.9758222103118896\n",
      "          vf_loss: 0.21947164535522462\n",
      "    num_agent_steps_sampled: 987012\n",
      "    num_agent_steps_trained: 987012\n",
      "    num_steps_sampled: 987012\n",
      "    num_steps_trained: 987012\n",
      "  iterations_since_restore: 494\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.10810810810813\n",
      "    ram_util_percent: 31.11351351351352\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04441003904349948\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.980266351370982\n",
      "    mean_inference_ms: 2.4712227399443605\n",
      "    mean_raw_obs_processing_ms: 2.021932724808579\n",
      "  time_since_restore: 13411.93982720375\n",
      "  time_this_iter_s: 25.768367528915405\n",
      "  time_total_s: 13411.93982720375\n",
      "  timers:\n",
      "    learn_throughput: 1164.478\n",
      "    learn_time_ms: 1715.79\n",
      "    load_throughput: 59932.255\n",
      "    load_time_ms: 33.338\n",
      "    sample_throughput: 84.316\n",
      "    sample_time_ms: 23696.642\n",
      "    update_time_ms: 10.818\n",
      "  timestamp: 1636442939\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 987012\n",
      "  training_iteration: 494\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   494</td><td style=\"text-align: right;\">         13411.9</td><td style=\"text-align: right;\">987012</td><td style=\"text-align: right;\">  8.7655</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                3.78</td><td style=\"text-align: right;\">             100.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 989010\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-29-37\n",
      "  done: false\n",
      "  episode_len_mean: 99.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.714100000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9608\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.293176571528117\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011951805224730222\n",
      "          policy_loss: -0.0030020952978659244\n",
      "          total_loss: 0.37717119983973957\n",
      "          vf_explained_var: 0.9318184852600098\n",
      "          vf_loss: 0.3844900409380595\n",
      "    num_agent_steps_sampled: 989010\n",
      "    num_agent_steps_trained: 989010\n",
      "    num_steps_sampled: 989010\n",
      "    num_steps_trained: 989010\n",
      "  iterations_since_restore: 495\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.43703703703703\n",
      "    ram_util_percent: 31.085185185185182\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04441137393238431\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.98063124573472\n",
      "    mean_inference_ms: 2.471162818485299\n",
      "    mean_raw_obs_processing_ms: 2.0227597305428135\n",
      "  time_since_restore: 13450.006911039352\n",
      "  time_this_iter_s: 38.06708383560181\n",
      "  time_total_s: 13450.006911039352\n",
      "  timers:\n",
      "    learn_throughput: 1165.105\n",
      "    learn_time_ms: 1714.867\n",
      "    load_throughput: 60064.345\n",
      "    load_time_ms: 33.264\n",
      "    sample_throughput: 79.747\n",
      "    sample_time_ms: 25054.251\n",
      "    update_time_ms: 10.45\n",
      "  timestamp: 1636442977\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 989010\n",
      "  training_iteration: 495\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   495</td><td style=\"text-align: right;\">           13450</td><td style=\"text-align: right;\">989010</td><td style=\"text-align: right;\">  8.7141</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 991008\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-30-03\n",
      "  done: false\n",
      "  episode_len_mean: 101.83\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.557800000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9627\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3879045554569789\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008707270143643088\n",
      "          policy_loss: -0.0369136057084515\n",
      "          total_loss: 0.06989564523766083\n",
      "          vf_explained_var: 0.9675561189651489\n",
      "          vf_loss: 0.11441198432197174\n",
      "    num_agent_steps_sampled: 991008\n",
      "    num_agent_steps_trained: 991008\n",
      "    num_steps_sampled: 991008\n",
      "    num_steps_trained: 991008\n",
      "  iterations_since_restore: 496\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.18421052631578\n",
      "    ram_util_percent: 31.071052631578944\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044380265767872656\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.982535564608053\n",
      "    mean_inference_ms: 2.4705925709865415\n",
      "    mean_raw_obs_processing_ms: 2.0236531427025617\n",
      "  time_since_restore: 13476.091195344925\n",
      "  time_this_iter_s: 26.08428430557251\n",
      "  time_total_s: 13476.091195344925\n",
      "  timers:\n",
      "    learn_throughput: 1164.335\n",
      "    learn_time_ms: 1716.001\n",
      "    load_throughput: 59954.08\n",
      "    load_time_ms: 33.326\n",
      "    sample_throughput: 79.684\n",
      "    sample_time_ms: 25074.106\n",
      "    update_time_ms: 10.257\n",
      "  timestamp: 1636443003\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 991008\n",
      "  training_iteration: 496\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   496</td><td style=\"text-align: right;\">         13476.1</td><td style=\"text-align: right;\">991008</td><td style=\"text-align: right;\">  8.5578</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            101.83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 993006\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-30-56\n",
      "  done: false\n",
      "  episode_len_mean: 99.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.703700000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 9648\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2216593884286426\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00790468234472834\n",
      "          policy_loss: -0.07293496633924189\n",
      "          total_loss: 0.10782630716760953\n",
      "          vf_explained_var: 0.9767476916313171\n",
      "          vf_loss: 0.18728006822722298\n",
      "    num_agent_steps_sampled: 993006\n",
      "    num_agent_steps_trained: 993006\n",
      "    num_steps_sampled: 993006\n",
      "    num_steps_trained: 993006\n",
      "  iterations_since_restore: 497\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.00945945945946\n",
      "    ram_util_percent: 31.08378378378378\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437947341856492\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.981283909183773\n",
      "    mean_inference_ms: 2.470482232062202\n",
      "    mean_raw_obs_processing_ms: 2.031586638521172\n",
      "  time_since_restore: 13528.410730600357\n",
      "  time_this_iter_s: 52.31953525543213\n",
      "  time_total_s: 13528.410730600357\n",
      "  timers:\n",
      "    learn_throughput: 1164.151\n",
      "    learn_time_ms: 1716.273\n",
      "    load_throughput: 60154.239\n",
      "    load_time_ms: 33.215\n",
      "    sample_throughput: 71.747\n",
      "    sample_time_ms: 27847.882\n",
      "    update_time_ms: 9.523\n",
      "  timestamp: 1636443056\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 993006\n",
      "  training_iteration: 497\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   497</td><td style=\"text-align: right;\">         13528.4</td><td style=\"text-align: right;\">993006</td><td style=\"text-align: right;\">  8.7037</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.47</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 995004\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-31-22\n",
      "  done: false\n",
      "  episode_len_mean: 98.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 9.050200000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 9669\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1634296638625008\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008926080411926171\n",
      "          policy_loss: -0.027532315502564114\n",
      "          total_loss: 0.08457667845123935\n",
      "          vf_explained_var: 0.9868634939193726\n",
      "          vf_loss: 0.11730925641244366\n",
      "    num_agent_steps_sampled: 995004\n",
      "    num_agent_steps_trained: 995004\n",
      "    num_steps_sampled: 995004\n",
      "    num_steps_trained: 995004\n",
      "  iterations_since_restore: 498\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.64210526315792\n",
      "    ram_util_percent: 30.907894736842106\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044364073370851305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.981188354935384\n",
      "    mean_inference_ms: 2.470122693513091\n",
      "    mean_raw_obs_processing_ms: 2.0395170560344873\n",
      "  time_since_restore: 13554.51971745491\n",
      "  time_this_iter_s: 26.108986854553223\n",
      "  time_total_s: 13554.51971745491\n",
      "  timers:\n",
      "    learn_throughput: 1164.396\n",
      "    learn_time_ms: 1715.911\n",
      "    load_throughput: 60047.258\n",
      "    load_time_ms: 33.274\n",
      "    sample_throughput: 71.564\n",
      "    sample_time_ms: 27919.257\n",
      "    update_time_ms: 8.888\n",
      "  timestamp: 1636443082\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 995004\n",
      "  training_iteration: 498\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   498</td><td style=\"text-align: right;\">         13554.5</td><td style=\"text-align: right;\">995004</td><td style=\"text-align: right;\">  9.0502</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 997002\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-31-47\n",
      "  done: false\n",
      "  episode_len_mean: 98.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 9.052100000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 9690\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.286922509897323\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015513240129523683\n",
      "          policy_loss: -0.024657367843957174\n",
      "          total_loss: 0.1840913502987297\n",
      "          vf_explained_var: 0.9751114845275879\n",
      "          vf_loss: 0.21043580014790808\n",
      "    num_agent_steps_sampled: 997002\n",
      "    num_agent_steps_trained: 997002\n",
      "    num_steps_sampled: 997002\n",
      "    num_steps_trained: 997002\n",
      "  iterations_since_restore: 499\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33611111111112\n",
      "    ram_util_percent: 31.025000000000002\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044347873967499146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.981293057096238\n",
      "    mean_inference_ms: 2.4697695122233436\n",
      "    mean_raw_obs_processing_ms: 2.0475312679750832\n",
      "  time_since_restore: 13579.965750455856\n",
      "  time_this_iter_s: 25.446033000946045\n",
      "  time_total_s: 13579.965750455856\n",
      "  timers:\n",
      "    learn_throughput: 1167.094\n",
      "    learn_time_ms: 1711.945\n",
      "    load_throughput: 59945.76\n",
      "    load_time_ms: 33.33\n",
      "    sample_throughput: 71.456\n",
      "    sample_time_ms: 27961.336\n",
      "    update_time_ms: 9.265\n",
      "  timestamp: 1636443107\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 997002\n",
      "  training_iteration: 499\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   499</td><td style=\"text-align: right;\">           13580</td><td style=\"text-align: right;\">997002</td><td style=\"text-align: right;\">  9.0521</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 999000\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-32-12\n",
      "  done: false\n",
      "  episode_len_mean: 97.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 9.507700000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9710\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2671563157013483\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012695640234861066\n",
      "          policy_loss: -0.04056090534265552\n",
      "          total_loss: 0.0822861924057915\n",
      "          vf_explained_var: 0.9800369143486023\n",
      "          vf_loss: 0.12636747842743284\n",
      "    num_agent_steps_sampled: 999000\n",
      "    num_agent_steps_trained: 999000\n",
      "    num_steps_sampled: 999000\n",
      "    num_steps_trained: 999000\n",
      "  iterations_since_restore: 500\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.06000000000002\n",
      "    ram_util_percent: 31.15428571428571\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436429192991646\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.98062589283839\n",
      "    mean_inference_ms: 2.4699831186146217\n",
      "    mean_raw_obs_processing_ms: 2.051725540370257\n",
      "  time_since_restore: 13604.331643104553\n",
      "  time_this_iter_s: 24.3658926486969\n",
      "  time_total_s: 13604.331643104553\n",
      "  timers:\n",
      "    learn_throughput: 1166.632\n",
      "    learn_time_ms: 1712.622\n",
      "    load_throughput: 60165.684\n",
      "    load_time_ms: 33.208\n",
      "    sample_throughput: 71.507\n",
      "    sample_time_ms: 27941.292\n",
      "    update_time_ms: 7.929\n",
      "  timestamp: 1636443132\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 999000\n",
      "  training_iteration: 500\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   500</td><td style=\"text-align: right;\">         13604.3</td><td style=\"text-align: right;\">999000</td><td style=\"text-align: right;\">  9.5077</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1000998\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-32-36\n",
      "  done: false\n",
      "  episode_len_mean: 97.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 9.378300000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9729\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3441310309228442\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011177307928497977\n",
      "          policy_loss: -0.02673974163564188\n",
      "          total_loss: 0.11399736968534334\n",
      "          vf_explained_var: 0.9755242466926575\n",
      "          vf_loss: 0.1461216751486063\n",
      "    num_agent_steps_sampled: 1000998\n",
      "    num_agent_steps_trained: 1000998\n",
      "    num_steps_sampled: 1000998\n",
      "    num_steps_trained: 1000998\n",
      "  iterations_since_restore: 501\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.08857142857144\n",
      "    ram_util_percent: 31.268571428571438\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437861030035608\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.979750596267166\n",
      "    mean_inference_ms: 2.4702170625049527\n",
      "    mean_raw_obs_processing_ms: 2.0544831924063915\n",
      "  time_since_restore: 13629.234230518341\n",
      "  time_this_iter_s: 24.902587413787842\n",
      "  time_total_s: 13629.234230518341\n",
      "  timers:\n",
      "    learn_throughput: 1166.029\n",
      "    learn_time_ms: 1713.508\n",
      "    load_throughput: 60022.056\n",
      "    load_time_ms: 33.288\n",
      "    sample_throughput: 71.9\n",
      "    sample_time_ms: 27788.573\n",
      "    update_time_ms: 8.282\n",
      "  timestamp: 1636443156\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1000998\n",
      "  training_iteration: 501\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   501</td><td style=\"text-align: right;\">         13629.2</td><td style=\"text-align: right;\">1000998</td><td style=\"text-align: right;\">  9.3783</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1002996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-33-01\n",
      "  done: false\n",
      "  episode_len_mean: 100.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 9.343900000000017\n",
      "  episode_reward_min: 2.860000000000026\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9748\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3184738885788692\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009309609400842786\n",
      "          policy_loss: -0.09460366501339844\n",
      "          total_loss: -0.0003235831501938048\n",
      "          vf_explained_var: 0.9868431687355042\n",
      "          vf_loss: 0.10075433364226705\n",
      "    num_agent_steps_sampled: 1002996\n",
      "    num_agent_steps_trained: 1002996\n",
      "    num_steps_sampled: 1002996\n",
      "    num_steps_trained: 1002996\n",
      "  iterations_since_restore: 502\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85555555555555\n",
      "    ram_util_percent: 31.325000000000006\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443878809190886\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.980542868424585\n",
      "    mean_inference_ms: 2.470386187679483\n",
      "    mean_raw_obs_processing_ms: 2.052020746407676\n",
      "  time_since_restore: 13653.842297792435\n",
      "  time_this_iter_s: 24.608067274093628\n",
      "  time_total_s: 13653.842297792435\n",
      "  timers:\n",
      "    learn_throughput: 1165.421\n",
      "    learn_time_ms: 1714.402\n",
      "    load_throughput: 59926.984\n",
      "    load_time_ms: 33.341\n",
      "    sample_throughput: 72.217\n",
      "    sample_time_ms: 27666.614\n",
      "    update_time_ms: 7.593\n",
      "  timestamp: 1636443181\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1002996\n",
      "  training_iteration: 502\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   502</td><td style=\"text-align: right;\">         13653.8</td><td style=\"text-align: right;\">1002996</td><td style=\"text-align: right;\">  9.3439</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">            100.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1004994\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-33-25\n",
      "  done: false\n",
      "  episode_len_mean: 101.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 9.146500000000017\n",
      "  episode_reward_min: 2.860000000000026\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9767\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2410378160930815\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012058443348733423\n",
      "          policy_loss: -0.01637920660986787\n",
      "          total_loss: 0.1004986823492107\n",
      "          vf_explained_var: 0.9865846037864685\n",
      "          vf_loss: 0.12059638388454914\n",
      "    num_agent_steps_sampled: 1004994\n",
      "    num_agent_steps_trained: 1004994\n",
      "    num_steps_sampled: 1004994\n",
      "    num_steps_trained: 1004994\n",
      "  iterations_since_restore: 503\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.18529411764706\n",
      "    ram_util_percent: 31.317647058823535\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044385183295368474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.98037296177824\n",
      "    mean_inference_ms: 2.470390617166035\n",
      "    mean_raw_obs_processing_ms: 2.0494894186604182\n",
      "  time_since_restore: 13677.971834897995\n",
      "  time_this_iter_s: 24.129537105560303\n",
      "  time_total_s: 13677.971834897995\n",
      "  timers:\n",
      "    learn_throughput: 1164.394\n",
      "    learn_time_ms: 1715.914\n",
      "    load_throughput: 59967.508\n",
      "    load_time_ms: 33.318\n",
      "    sample_throughput: 72.882\n",
      "    sample_time_ms: 27414.349\n",
      "    update_time_ms: 7.37\n",
      "  timestamp: 1636443205\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1004994\n",
      "  training_iteration: 503\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   503</td><td style=\"text-align: right;\">           13678</td><td style=\"text-align: right;\">1004994</td><td style=\"text-align: right;\">  9.1465</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">            101.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1006992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-33-50\n",
      "  done: false\n",
      "  episode_len_mean: 102.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 9.056900000000018\n",
      "  episode_reward_min: 2.860000000000026\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9787\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2499226910727366\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014336366053020098\n",
      "          policy_loss: -0.006340887255611874\n",
      "          total_loss: 0.12418926883754985\n",
      "          vf_explained_var: 0.979466438293457\n",
      "          vf_loss: 0.1326955452206589\n",
      "    num_agent_steps_sampled: 1006992\n",
      "    num_agent_steps_trained: 1006992\n",
      "    num_steps_sampled: 1006992\n",
      "    num_steps_trained: 1006992\n",
      "  iterations_since_restore: 504\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28857142857143\n",
      "    ram_util_percent: 31.34000000000001\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044378325492854\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.980609222548022\n",
      "    mean_inference_ms: 2.470310348510134\n",
      "    mean_raw_obs_processing_ms: 2.04674657874483\n",
      "  time_since_restore: 13702.40940785408\n",
      "  time_this_iter_s: 24.437572956085205\n",
      "  time_total_s: 13702.40940785408\n",
      "  timers:\n",
      "    learn_throughput: 1164.034\n",
      "    learn_time_ms: 1716.444\n",
      "    load_throughput: 59098.867\n",
      "    load_time_ms: 33.808\n",
      "    sample_throughput: 73.239\n",
      "    sample_time_ms: 27280.73\n",
      "    update_time_ms: 6.58\n",
      "  timestamp: 1636443230\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1006992\n",
      "  training_iteration: 504\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   504</td><td style=\"text-align: right;\">         13702.4</td><td style=\"text-align: right;\">1006992</td><td style=\"text-align: right;\">  9.0569</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">            102.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1008990\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-34-15\n",
      "  done: false\n",
      "  episode_len_mean: 103.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 8.962600000000018\n",
      "  episode_reward_min: 2.860000000000026\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9806\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.296113355386825\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008999051306867269\n",
      "          policy_loss: -0.05934094116091728\n",
      "          total_loss: 0.02492044443885485\n",
      "          vf_explained_var: 0.9776224493980408\n",
      "          vf_loss: 0.0907358868047595\n",
      "    num_agent_steps_sampled: 1008990\n",
      "    num_agent_steps_trained: 1008990\n",
      "    num_steps_sampled: 1008990\n",
      "    num_steps_trained: 1008990\n",
      "  iterations_since_restore: 505\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85555555555555\n",
      "    ram_util_percent: 31.336111111111123\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437163057607542\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.980823078066308\n",
      "    mean_inference_ms: 2.470222678036273\n",
      "    mean_raw_obs_processing_ms: 2.0441088027902374\n",
      "  time_since_restore: 13727.457319021225\n",
      "  time_this_iter_s: 25.047911167144775\n",
      "  time_total_s: 13727.457319021225\n",
      "  timers:\n",
      "    learn_throughput: 1163.646\n",
      "    learn_time_ms: 1717.018\n",
      "    load_throughput: 59149.299\n",
      "    load_time_ms: 33.779\n",
      "    sample_throughput: 76.912\n",
      "    sample_time_ms: 25977.624\n",
      "    update_time_ms: 7.023\n",
      "  timestamp: 1636443255\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1008990\n",
      "  training_iteration: 505\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   505</td><td style=\"text-align: right;\">         13727.5</td><td style=\"text-align: right;\">1008990</td><td style=\"text-align: right;\">  8.9626</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">            103.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1010988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-34-43\n",
      "  done: false\n",
      "  episode_len_mean: 104.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000015\n",
      "  episode_reward_mean: 8.68320000000002\n",
      "  episode_reward_min: 2.860000000000026\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9825\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.361094195502145\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010632199200278733\n",
      "          policy_loss: -0.04237221163653192\n",
      "          total_loss: 0.05779501452953333\n",
      "          vf_explained_var: 0.976884126663208\n",
      "          vf_loss: 0.10611434177983375\n",
      "    num_agent_steps_sampled: 1010988\n",
      "    num_agent_steps_trained: 1010988\n",
      "    num_steps_sampled: 1010988\n",
      "    num_steps_trained: 1010988\n",
      "  iterations_since_restore: 506\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.4948717948718\n",
      "    ram_util_percent: 31.248717948717957\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435490894457125\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.98277708155214\n",
      "    mean_inference_ms: 2.469968795275554\n",
      "    mean_raw_obs_processing_ms: 2.041358098100881\n",
      "  time_since_restore: 13755.24655532837\n",
      "  time_this_iter_s: 27.789236307144165\n",
      "  time_total_s: 13755.24655532837\n",
      "  timers:\n",
      "    learn_throughput: 1163.331\n",
      "    learn_time_ms: 1717.482\n",
      "    load_throughput: 59020.492\n",
      "    load_time_ms: 33.853\n",
      "    sample_throughput: 76.414\n",
      "    sample_time_ms: 26147.21\n",
      "    update_time_ms: 7.514\n",
      "  timestamp: 1636443283\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1010988\n",
      "  training_iteration: 506\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   506</td><td style=\"text-align: right;\">         13755.2</td><td style=\"text-align: right;\">1010988</td><td style=\"text-align: right;\">  8.6832</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">                2.86</td><td style=\"text-align: right;\">            104.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1012986\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-35-08\n",
      "  done: false\n",
      "  episode_len_mean: 102.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 9.29900000000002\n",
      "  episode_reward_min: 3.4200000000000257\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9845\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1649881958961488\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010360687013952721\n",
      "          policy_loss: -0.027379632155810085\n",
      "          total_loss: 0.15150520602862041\n",
      "          vf_explained_var: 0.9841035604476929\n",
      "          vf_loss: 0.18306660506696928\n",
      "    num_agent_steps_sampled: 1012986\n",
      "    num_agent_steps_trained: 1012986\n",
      "    num_steps_sampled: 1012986\n",
      "    num_steps_trained: 1012986\n",
      "  iterations_since_restore: 507\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28333333333335\n",
      "    ram_util_percent: 31.258333333333333\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437606090005973\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.982300718480193\n",
      "    mean_inference_ms: 2.4703133642483226\n",
      "    mean_raw_obs_processing_ms: 2.038636566726255\n",
      "  time_since_restore: 13780.32804608345\n",
      "  time_this_iter_s: 25.081490755081177\n",
      "  time_total_s: 13780.32804608345\n",
      "  timers:\n",
      "    learn_throughput: 1164.616\n",
      "    learn_time_ms: 1715.586\n",
      "    load_throughput: 59079.66\n",
      "    load_time_ms: 33.819\n",
      "    sample_throughput: 85.294\n",
      "    sample_time_ms: 23424.837\n",
      "    update_time_ms: 8.002\n",
      "  timestamp: 1636443308\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1012986\n",
      "  training_iteration: 507\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   507</td><td style=\"text-align: right;\">         13780.3</td><td style=\"text-align: right;\">1012986</td><td style=\"text-align: right;\">   9.299</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                3.42</td><td style=\"text-align: right;\">            102.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1014984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-35-33\n",
      "  done: false\n",
      "  episode_len_mean: 102.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.77280000000002\n",
      "  episode_reward_min: 3.4200000000000257\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9865\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3245310130573453\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.018732491706006067\n",
      "          policy_loss: -0.00622452763574464\n",
      "          total_loss: 0.34984508196246766\n",
      "          vf_explained_var: 0.9342565536499023\n",
      "          vf_loss: 0.3558122939651921\n",
      "    num_agent_steps_sampled: 1014984\n",
      "    num_agent_steps_trained: 1014984\n",
      "    num_steps_sampled: 1014984\n",
      "    num_steps_trained: 1014984\n",
      "  iterations_since_restore: 508\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8054054054054\n",
      "    ram_util_percent: 31.23243243243243\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439218878779913\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.9838166320466\n",
      "    mean_inference_ms: 2.4705656918627814\n",
      "    mean_raw_obs_processing_ms: 2.035948371766577\n",
      "  time_since_restore: 13805.890515327454\n",
      "  time_this_iter_s: 25.562469244003296\n",
      "  time_total_s: 13805.890515327454\n",
      "  timers:\n",
      "    learn_throughput: 1163.949\n",
      "    learn_time_ms: 1716.571\n",
      "    load_throughput: 59213.118\n",
      "    load_time_ms: 33.743\n",
      "    sample_throughput: 85.497\n",
      "    sample_time_ms: 23369.172\n",
      "    update_time_ms: 7.954\n",
      "  timestamp: 1636443333\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1014984\n",
      "  training_iteration: 508\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   508</td><td style=\"text-align: right;\">         13805.9</td><td style=\"text-align: right;\">1014984</td><td style=\"text-align: right;\">  8.7728</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                3.42</td><td style=\"text-align: right;\">            102.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1016982\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-35-59\n",
      "  done: false\n",
      "  episode_len_mean: 101.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.811000000000018\n",
      "  episode_reward_min: 0.9899999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9885\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.213129856189092\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008707676167329937\n",
      "          policy_loss: -0.0023268285163101695\n",
      "          total_loss: 0.16975901635097607\n",
      "          vf_explained_var: 0.9635918140411377\n",
      "          vf_loss: 0.1779405371596416\n",
      "    num_agent_steps_sampled: 1016982\n",
      "    num_agent_steps_trained: 1016982\n",
      "    num_steps_sampled: 1016982\n",
      "    num_steps_trained: 1016982\n",
      "  iterations_since_restore: 509\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.06216216216214\n",
      "    ram_util_percent: 31.21351351351351\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439063024519235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.986929056527902\n",
      "    mean_inference_ms: 2.470543670836649\n",
      "    mean_raw_obs_processing_ms: 2.0332273967758345\n",
      "  time_since_restore: 13831.745083808899\n",
      "  time_this_iter_s: 25.854568481445312\n",
      "  time_total_s: 13831.745083808899\n",
      "  timers:\n",
      "    learn_throughput: 1162.41\n",
      "    learn_time_ms: 1718.843\n",
      "    load_throughput: 58415.92\n",
      "    load_time_ms: 34.203\n",
      "    sample_throughput: 85.355\n",
      "    sample_time_ms: 23408.043\n",
      "    update_time_ms: 7.387\n",
      "  timestamp: 1636443359\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1016982\n",
      "  training_iteration: 509\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   509</td><td style=\"text-align: right;\">         13831.7</td><td style=\"text-align: right;\">1016982</td><td style=\"text-align: right;\">   8.811</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">            101.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1018980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-36-25\n",
      "  done: false\n",
      "  episode_len_mean: 101.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.769800000000018\n",
      "  episode_reward_min: 0.9899999999999991\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 9906\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2151677509148915\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015753049922310275\n",
      "          policy_loss: -0.049665897312973224\n",
      "          total_loss: 0.2219564316705579\n",
      "          vf_explained_var: 0.951881468296051\n",
      "          vf_loss: 0.2724190057743163\n",
      "    num_agent_steps_sampled: 1018980\n",
      "    num_agent_steps_trained: 1018980\n",
      "    num_steps_sampled: 1018980\n",
      "    num_steps_trained: 1018980\n",
      "  iterations_since_restore: 510\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99189189189188\n",
      "    ram_util_percent: 31.21621621621621\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439344097481164\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.989223576226546\n",
      "    mean_inference_ms: 2.470588592312296\n",
      "    mean_raw_obs_processing_ms: 2.0304071522092726\n",
      "  time_since_restore: 13857.634496688843\n",
      "  time_this_iter_s: 25.889412879943848\n",
      "  time_total_s: 13857.634496688843\n",
      "  timers:\n",
      "    learn_throughput: 1163.032\n",
      "    learn_time_ms: 1717.923\n",
      "    load_throughput: 58355.961\n",
      "    load_time_ms: 34.238\n",
      "    sample_throughput: 84.803\n",
      "    sample_time_ms: 23560.497\n",
      "    update_time_ms: 8.18\n",
      "  timestamp: 1636443385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1018980\n",
      "  training_iteration: 510\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   510</td><td style=\"text-align: right;\">         13857.6</td><td style=\"text-align: right;\">1018980</td><td style=\"text-align: right;\">  8.7698</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">            101.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1020978\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-36-51\n",
      "  done: false\n",
      "  episode_len_mean: 99.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 9.016600000000016\n",
      "  episode_reward_min: 0.9899999999999991\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 9925\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2401760793867564\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009758494539489435\n",
      "          policy_loss: -0.016422584528724353\n",
      "          total_loss: 0.11122261800226711\n",
      "          vf_explained_var: 0.976497232913971\n",
      "          vf_loss: 0.13301291424958478\n",
      "    num_agent_steps_sampled: 1020978\n",
      "    num_agent_steps_trained: 1020978\n",
      "    num_steps_sampled: 1020978\n",
      "    num_steps_trained: 1020978\n",
      "  iterations_since_restore: 511\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33055555555555\n",
      "    ram_util_percent: 31.166666666666668\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044391232040421225\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99066755636399\n",
      "    mean_inference_ms: 2.4705465197021654\n",
      "    mean_raw_obs_processing_ms: 2.0279381782429486\n",
      "  time_since_restore: 13883.24163532257\n",
      "  time_this_iter_s: 25.607138633728027\n",
      "  time_total_s: 13883.24163532257\n",
      "  timers:\n",
      "    learn_throughput: 1164.335\n",
      "    learn_time_ms: 1716.001\n",
      "    load_throughput: 58626.876\n",
      "    load_time_ms: 34.08\n",
      "    sample_throughput: 84.544\n",
      "    sample_time_ms: 23632.57\n",
      "    update_time_ms: 8.443\n",
      "  timestamp: 1636443411\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1020978\n",
      "  training_iteration: 511\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   511</td><td style=\"text-align: right;\">         13883.2</td><td style=\"text-align: right;\">1020978</td><td style=\"text-align: right;\">  9.0166</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">             99.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1022976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-37-16\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.555800000000017\n",
      "  episode_reward_min: 0.9899999999999991\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9945\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2567764824344998\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010591503337322363\n",
      "          policy_loss: -0.04268458311756452\n",
      "          total_loss: 0.09382198815721841\n",
      "          vf_explained_var: 0.979353129863739\n",
      "          vf_loss: 0.14143984276978744\n",
      "    num_agent_steps_sampled: 1022976\n",
      "    num_agent_steps_trained: 1022976\n",
      "    num_steps_sampled: 1022976\n",
      "    num_steps_trained: 1022976\n",
      "  iterations_since_restore: 512\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.82222222222222\n",
      "    ram_util_percent: 31.125\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044387951967011494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.992358638215425\n",
      "    mean_inference_ms: 2.4704984896053004\n",
      "    mean_raw_obs_processing_ms: 2.025356080166839\n",
      "  time_since_restore: 13908.500215053558\n",
      "  time_this_iter_s: 25.25857973098755\n",
      "  time_total_s: 13908.500215053558\n",
      "  timers:\n",
      "    learn_throughput: 1164.726\n",
      "    learn_time_ms: 1715.424\n",
      "    load_throughput: 58634.505\n",
      "    load_time_ms: 34.075\n",
      "    sample_throughput: 84.312\n",
      "    sample_time_ms: 23697.783\n",
      "    update_time_ms: 9.039\n",
      "  timestamp: 1636443436\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1022976\n",
      "  training_iteration: 512\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   512</td><td style=\"text-align: right;\">         13908.5</td><td style=\"text-align: right;\">1022976</td><td style=\"text-align: right;\">  8.5558</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1024974\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-37-58\n",
      "  done: false\n",
      "  episode_len_mean: 98.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.814200000000017\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 9966\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2410150919641767\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011226401426314815\n",
      "          policy_loss: -0.023201224247791936\n",
      "          total_loss: 0.21124985939157861\n",
      "          vf_explained_var: 0.9746416807174683\n",
      "          vf_loss: 0.2387690977503856\n",
      "    num_agent_steps_sampled: 1024974\n",
      "    num_agent_steps_trained: 1024974\n",
      "    num_steps_sampled: 1024974\n",
      "    num_steps_trained: 1024974\n",
      "  iterations_since_restore: 513\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.94166666666666\n",
      "    ram_util_percent: 31.15333333333333\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044363595088160256\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99571620617251\n",
      "    mean_inference_ms: 2.470101034265906\n",
      "    mean_raw_obs_processing_ms: 2.0266770343668004\n",
      "  time_since_restore: 13950.545794248581\n",
      "  time_this_iter_s: 42.04557919502258\n",
      "  time_total_s: 13950.545794248581\n",
      "  timers:\n",
      "    learn_throughput: 1165.036\n",
      "    learn_time_ms: 1714.969\n",
      "    load_throughput: 58723.007\n",
      "    load_time_ms: 34.024\n",
      "    sample_throughput: 78.386\n",
      "    sample_time_ms: 25489.4\n",
      "    update_time_ms: 9.731\n",
      "  timestamp: 1636443478\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1024974\n",
      "  training_iteration: 513\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   513</td><td style=\"text-align: right;\">         13950.5</td><td style=\"text-align: right;\">1024974</td><td style=\"text-align: right;\">  8.8142</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             98.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1026972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-38-23\n",
      "  done: false\n",
      "  episode_len_mean: 99.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.697900000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 9986\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2851168694950286\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010881784272154426\n",
      "          policy_loss: -0.016706717227186474\n",
      "          total_loss: 0.13344550459157853\n",
      "          vf_explained_var: 0.9678093194961548\n",
      "          vf_loss: 0.15515965961274647\n",
      "    num_agent_steps_sampled: 1026972\n",
      "    num_agent_steps_trained: 1026972\n",
      "    num_steps_sampled: 1026972\n",
      "    num_steps_trained: 1026972\n",
      "  iterations_since_restore: 514\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04285714285714\n",
      "    ram_util_percent: 31.17142857142857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435024584185197\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.996221616910244\n",
      "    mean_inference_ms: 2.4698891402220426\n",
      "    mean_raw_obs_processing_ms: 2.0276305198754794\n",
      "  time_since_restore: 13975.105189800262\n",
      "  time_this_iter_s: 24.55939555168152\n",
      "  time_total_s: 13975.105189800262\n",
      "  timers:\n",
      "    learn_throughput: 1164.702\n",
      "    learn_time_ms: 1715.46\n",
      "    load_throughput: 58530.363\n",
      "    load_time_ms: 34.136\n",
      "    sample_throughput: 78.349\n",
      "    sample_time_ms: 25501.136\n",
      "    update_time_ms: 9.788\n",
      "  timestamp: 1636443503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1026972\n",
      "  training_iteration: 514\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   514</td><td style=\"text-align: right;\">         13975.1</td><td style=\"text-align: right;\">1026972</td><td style=\"text-align: right;\">  8.6979</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             99.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1028970\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-39-05\n",
      "  done: false\n",
      "  episode_len_mean: 98.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.530300000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10007\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2281716028849283\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010286710268723555\n",
      "          policy_loss: -0.03553675835331281\n",
      "          total_loss: 0.3015340448490211\n",
      "          vf_explained_var: 0.9617236852645874\n",
      "          vf_loss: 0.34193772253181254\n",
      "    num_agent_steps_sampled: 1028970\n",
      "    num_agent_steps_trained: 1028970\n",
      "    num_steps_sampled: 1028970\n",
      "    num_steps_trained: 1028970\n",
      "  iterations_since_restore: 515\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.87704918032787\n",
      "    ram_util_percent: 30.959016393442628\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044348432715709846\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.997336799077367\n",
      "    mean_inference_ms: 2.469834716613743\n",
      "    mean_raw_obs_processing_ms: 2.035331991170447\n",
      "  time_since_restore: 14017.399557828903\n",
      "  time_this_iter_s: 42.29436802864075\n",
      "  time_total_s: 14017.399557828903\n",
      "  timers:\n",
      "    learn_throughput: 1163.306\n",
      "    learn_time_ms: 1717.518\n",
      "    load_throughput: 58494.779\n",
      "    load_time_ms: 34.157\n",
      "    sample_throughput: 73.391\n",
      "    sample_time_ms: 27223.964\n",
      "    update_time_ms: 9.742\n",
      "  timestamp: 1636443545\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1028970\n",
      "  training_iteration: 515\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   515</td><td style=\"text-align: right;\">         14017.4</td><td style=\"text-align: right;\">1028970</td><td style=\"text-align: right;\">  8.5303</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             98.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1030968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-39-30\n",
      "  done: false\n",
      "  episode_len_mean: 99.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.432600000000019\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 10025\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2643639275005885\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015935218353488063\n",
      "          policy_loss: -0.01025861817456427\n",
      "          total_loss: 0.1696725909553823\n",
      "          vf_explained_var: 0.9718122482299805\n",
      "          vf_loss: 0.1810885358424414\n",
      "    num_agent_steps_sampled: 1030968\n",
      "    num_agent_steps_trained: 1030968\n",
      "    num_steps_sampled: 1030968\n",
      "    num_steps_trained: 1030968\n",
      "  iterations_since_restore: 516\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.45999999999998\n",
      "    ram_util_percent: 31.08571428571428\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436311201756297\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.997311402106003\n",
      "    mean_inference_ms: 2.4700469071165547\n",
      "    mean_raw_obs_processing_ms: 2.041956798183967\n",
      "  time_since_restore: 14042.176548242569\n",
      "  time_this_iter_s: 24.77699041366577\n",
      "  time_total_s: 14042.176548242569\n",
      "  timers:\n",
      "    learn_throughput: 1164.602\n",
      "    learn_time_ms: 1715.607\n",
      "    load_throughput: 58321.359\n",
      "    load_time_ms: 34.258\n",
      "    sample_throughput: 74.206\n",
      "    sample_time_ms: 26924.936\n",
      "    update_time_ms: 9.416\n",
      "  timestamp: 1636443570\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1030968\n",
      "  training_iteration: 516\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   516</td><td style=\"text-align: right;\">         14042.2</td><td style=\"text-align: right;\">1030968</td><td style=\"text-align: right;\">  8.4326</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             99.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1032966\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-39-54\n",
      "  done: false\n",
      "  episode_len_mean: 99.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000017\n",
      "  episode_reward_mean: 8.531900000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10045\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2776159536270868\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009513246783243511\n",
      "          policy_loss: -0.02314571963534469\n",
      "          total_loss: 0.07234317621304875\n",
      "          vf_explained_var: 0.9863993525505066\n",
      "          vf_loss: 0.10140778280439831\n",
      "    num_agent_steps_sampled: 1032966\n",
      "    num_agent_steps_trained: 1032966\n",
      "    num_steps_sampled: 1032966\n",
      "    num_steps_trained: 1032966\n",
      "  iterations_since_restore: 517\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77428571428571\n",
      "    ram_util_percent: 31.22285714285714\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436285537573012\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99765347028115\n",
      "    mean_inference_ms: 2.470007875730255\n",
      "    mean_raw_obs_processing_ms: 2.049227740058869\n",
      "  time_since_restore: 14066.458044528961\n",
      "  time_this_iter_s: 24.281496286392212\n",
      "  time_total_s: 14066.458044528961\n",
      "  timers:\n",
      "    learn_throughput: 1164.425\n",
      "    learn_time_ms: 1715.869\n",
      "    load_throughput: 59213.369\n",
      "    load_time_ms: 33.742\n",
      "    sample_throughput: 74.427\n",
      "    sample_time_ms: 26845.152\n",
      "    update_time_ms: 9.178\n",
      "  timestamp: 1636443594\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1032966\n",
      "  training_iteration: 517\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   517</td><td style=\"text-align: right;\">         14066.5</td><td style=\"text-align: right;\">1032966</td><td style=\"text-align: right;\">  8.5319</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             99.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1034964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-40-20\n",
      "  done: false\n",
      "  episode_len_mean: 100.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 8.979900000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10065\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2633673633847917\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014655400485711685\n",
      "          policy_loss: -0.019934272127492086\n",
      "          total_loss: 0.15943897792271206\n",
      "          vf_explained_var: 0.9821833372116089\n",
      "          vf_loss: 0.18144312155033862\n",
      "    num_agent_steps_sampled: 1034964\n",
      "    num_agent_steps_trained: 1034964\n",
      "    num_steps_sampled: 1034964\n",
      "    num_steps_trained: 1034964\n",
      "  iterations_since_restore: 518\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85405405405405\n",
      "    ram_util_percent: 31.264864864864876\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436439224130823\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.998362618558403\n",
      "    mean_inference_ms: 2.4699837062800287\n",
      "    mean_raw_obs_processing_ms: 2.0529671571201806\n",
      "  time_since_restore: 14092.322101831436\n",
      "  time_this_iter_s: 25.864057302474976\n",
      "  time_total_s: 14092.322101831436\n",
      "  timers:\n",
      "    learn_throughput: 1165.051\n",
      "    learn_time_ms: 1714.946\n",
      "    load_throughput: 58942.864\n",
      "    load_time_ms: 33.897\n",
      "    sample_throughput: 74.341\n",
      "    sample_time_ms: 26876.047\n",
      "    update_time_ms: 9.603\n",
      "  timestamp: 1636443620\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1034964\n",
      "  training_iteration: 518\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   518</td><td style=\"text-align: right;\">         14092.3</td><td style=\"text-align: right;\">1034964</td><td style=\"text-align: right;\">  8.9799</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            100.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1036962\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-40-44\n",
      "  done: false\n",
      "  episode_len_mean: 101.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 9.143700000000019\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 10084\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2708647693906512\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011415090488834935\n",
      "          policy_loss: -0.0031029009348934604\n",
      "          total_loss: 0.2768696361088327\n",
      "          vf_explained_var: 0.9669061303138733\n",
      "          vf_loss: 0.28445304009531225\n",
      "    num_agent_steps_sampled: 1036962\n",
      "    num_agent_steps_trained: 1036962\n",
      "    num_steps_sampled: 1036962\n",
      "    num_steps_trained: 1036962\n",
      "  iterations_since_restore: 519\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73235294117647\n",
      "    ram_util_percent: 31.302941176470586\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044366684085182066\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99834732933232\n",
      "    mean_inference_ms: 2.469965239042233\n",
      "    mean_raw_obs_processing_ms: 2.0567851425425085\n",
      "  time_since_restore: 14116.35745048523\n",
      "  time_this_iter_s: 24.035348653793335\n",
      "  time_total_s: 14116.35745048523\n",
      "  timers:\n",
      "    learn_throughput: 1165.066\n",
      "    learn_time_ms: 1714.924\n",
      "    load_throughput: 59660.127\n",
      "    load_time_ms: 33.49\n",
      "    sample_throughput: 74.848\n",
      "    sample_time_ms: 26693.982\n",
      "    update_time_ms: 10.046\n",
      "  timestamp: 1636443644\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1036962\n",
      "  training_iteration: 519\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   519</td><td style=\"text-align: right;\">         14116.4</td><td style=\"text-align: right;\">1036962</td><td style=\"text-align: right;\">  9.1437</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            101.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1038960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-41-08\n",
      "  done: false\n",
      "  episode_len_mean: 103.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 9.168200000000018\n",
      "  episode_reward_min: 3.820000000000022\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 10103\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3125223818279448\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011352305855591808\n",
      "          policy_loss: -0.03207009709661915\n",
      "          total_loss: 0.11554123459472543\n",
      "          vf_explained_var: 0.9784771203994751\n",
      "          vf_loss: 0.15255366751835459\n",
      "    num_agent_steps_sampled: 1038960\n",
      "    num_agent_steps_trained: 1038960\n",
      "    num_steps_sampled: 1038960\n",
      "    num_steps_trained: 1038960\n",
      "  iterations_since_restore: 520\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8\n",
      "    ram_util_percent: 31.35\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434816908932603\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.999051857061023\n",
      "    mean_inference_ms: 2.469627237324241\n",
      "    mean_raw_obs_processing_ms: 2.054212105293108\n",
      "  time_since_restore: 14139.99299621582\n",
      "  time_this_iter_s: 23.63554573059082\n",
      "  time_total_s: 14139.99299621582\n",
      "  timers:\n",
      "    learn_throughput: 1163.641\n",
      "    learn_time_ms: 1717.024\n",
      "    load_throughput: 59586.824\n",
      "    load_time_ms: 33.531\n",
      "    sample_throughput: 75.492\n",
      "    sample_time_ms: 26466.383\n",
      "    update_time_ms: 10.089\n",
      "  timestamp: 1636443668\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1038960\n",
      "  training_iteration: 520\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   520</td><td style=\"text-align: right;\">           14140</td><td style=\"text-align: right;\">1038960</td><td style=\"text-align: right;\">  9.1682</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                3.82</td><td style=\"text-align: right;\">            103.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1040958\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-41-32\n",
      "  done: false\n",
      "  episode_len_mean: 104.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 9.116900000000017\n",
      "  episode_reward_min: 3.100000000000024\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 10121\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.285502997466496\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010670001256316805\n",
      "          policy_loss: -0.03397948287782215\n",
      "          total_loss: 0.12107719099592595\n",
      "          vf_explained_var: 0.9705522656440735\n",
      "          vf_loss: 0.16022062805436907\n",
      "    num_agent_steps_sampled: 1040958\n",
      "    num_agent_steps_trained: 1040958\n",
      "    num_steps_sampled: 1040958\n",
      "    num_steps_trained: 1040958\n",
      "  iterations_since_restore: 521\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.4\n",
      "    ram_util_percent: 31.388235294117642\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434909369549496\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99744106867599\n",
      "    mean_inference_ms: 2.4696110334761907\n",
      "    mean_raw_obs_processing_ms: 2.051725944958568\n",
      "  time_since_restore: 14163.771539926529\n",
      "  time_this_iter_s: 23.778543710708618\n",
      "  time_total_s: 14163.771539926529\n",
      "  timers:\n",
      "    learn_throughput: 1163.044\n",
      "    learn_time_ms: 1717.906\n",
      "    load_throughput: 59391.553\n",
      "    load_time_ms: 33.641\n",
      "    sample_throughput: 76.021\n",
      "    sample_time_ms: 26282.11\n",
      "    update_time_ms: 10.524\n",
      "  timestamp: 1636443692\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1040958\n",
      "  training_iteration: 521\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   521</td><td style=\"text-align: right;\">         14163.8</td><td style=\"text-align: right;\">1040958</td><td style=\"text-align: right;\">  9.1169</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                 3.1</td><td style=\"text-align: right;\">            104.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1042956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-41-57\n",
      "  done: false\n",
      "  episode_len_mean: 105.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 8.922600000000019\n",
      "  episode_reward_min: 3.100000000000024\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 10140\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3167627238091968\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01054320919423008\n",
      "          policy_loss: -0.019457407295703888\n",
      "          total_loss: 0.17544134280511312\n",
      "          vf_explained_var: 0.9637347459793091\n",
      "          vf_loss: 0.20046669638582637\n",
      "    num_agent_steps_sampled: 1042956\n",
      "    num_agent_steps_trained: 1042956\n",
      "    num_steps_sampled: 1042956\n",
      "    num_steps_trained: 1042956\n",
      "  iterations_since_restore: 522\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66666666666669\n",
      "    ram_util_percent: 31.424999999999997\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433424058757671\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.996460754551258\n",
      "    mean_inference_ms: 2.46935092762711\n",
      "    mean_raw_obs_processing_ms: 2.0490361451762027\n",
      "  time_since_restore: 14188.811136960983\n",
      "  time_this_iter_s: 25.039597034454346\n",
      "  time_total_s: 14188.811136960983\n",
      "  timers:\n",
      "    learn_throughput: 1163.127\n",
      "    learn_time_ms: 1717.784\n",
      "    load_throughput: 59170.347\n",
      "    load_time_ms: 33.767\n",
      "    sample_throughput: 76.083\n",
      "    sample_time_ms: 26260.635\n",
      "    update_time_ms: 10.027\n",
      "  timestamp: 1636443717\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1042956\n",
      "  training_iteration: 522\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   522</td><td style=\"text-align: right;\">         14188.8</td><td style=\"text-align: right;\">1042956</td><td style=\"text-align: right;\">  8.9226</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                 3.1</td><td style=\"text-align: right;\">            105.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1044954\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-42-23\n",
      "  done: false\n",
      "  episode_len_mean: 104.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 8.67140000000002\n",
      "  episode_reward_min: 2.610000000000009\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10161\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1430746044431415\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00913860965487973\n",
      "          policy_loss: -0.07027195887196631\n",
      "          total_loss: 0.11097053099601041\n",
      "          vf_explained_var: 0.9737758040428162\n",
      "          vf_loss: 0.18608600940732728\n",
      "    num_agent_steps_sampled: 1044954\n",
      "    num_agent_steps_trained: 1044954\n",
      "    num_steps_sampled: 1044954\n",
      "    num_steps_trained: 1044954\n",
      "  iterations_since_restore: 523\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.69189189189188\n",
      "    ram_util_percent: 31.4\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434128593497267\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99351985517387\n",
      "    mean_inference_ms: 2.469427049080446\n",
      "    mean_raw_obs_processing_ms: 2.0461037156161517\n",
      "  time_since_restore: 14214.925306081772\n",
      "  time_this_iter_s: 26.114169120788574\n",
      "  time_total_s: 14214.925306081772\n",
      "  timers:\n",
      "    learn_throughput: 1162.351\n",
      "    learn_time_ms: 1718.929\n",
      "    load_throughput: 59194.965\n",
      "    load_time_ms: 33.753\n",
      "    sample_throughput: 80.998\n",
      "    sample_time_ms: 24667.255\n",
      "    update_time_ms: 9.141\n",
      "  timestamp: 1636443743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1044954\n",
      "  training_iteration: 523\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   523</td><td style=\"text-align: right;\">         14214.9</td><td style=\"text-align: right;\">1044954</td><td style=\"text-align: right;\">  8.6714</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                2.61</td><td style=\"text-align: right;\">            104.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1046952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-42-48\n",
      "  done: false\n",
      "  episode_len_mean: 102.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.766200000000017\n",
      "  episode_reward_min: 2.610000000000009\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10181\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.196045578661419\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010803483550389511\n",
      "          policy_loss: -0.026828008748236157\n",
      "          total_loss: 0.08658951664609568\n",
      "          vf_explained_var: 0.9866426587104797\n",
      "          vf_loss: 0.11759068975668578\n",
      "    num_agent_steps_sampled: 1046952\n",
      "    num_agent_steps_trained: 1046952\n",
      "    num_steps_sampled: 1046952\n",
      "    num_steps_trained: 1046952\n",
      "  iterations_since_restore: 524\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.55714285714286\n",
      "    ram_util_percent: 31.388571428571424\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435383611767529\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.992656369981237\n",
      "    mean_inference_ms: 2.4695729239982462\n",
      "    mean_raw_obs_processing_ms: 2.0434515663229167\n",
      "  time_since_restore: 14239.635089159012\n",
      "  time_this_iter_s: 24.70978307723999\n",
      "  time_total_s: 14239.635089159012\n",
      "  timers:\n",
      "    learn_throughput: 1162.687\n",
      "    learn_time_ms: 1718.434\n",
      "    load_throughput: 59493.8\n",
      "    load_time_ms: 33.583\n",
      "    sample_throughput: 80.948\n",
      "    sample_time_ms: 24682.662\n",
      "    update_time_ms: 9.422\n",
      "  timestamp: 1636443768\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1046952\n",
      "  training_iteration: 524\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   524</td><td style=\"text-align: right;\">         14239.6</td><td style=\"text-align: right;\">1046952</td><td style=\"text-align: right;\">  8.7662</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.61</td><td style=\"text-align: right;\">            102.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1048950\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-43-12\n",
      "  done: false\n",
      "  episode_len_mean: 102.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.658400000000016\n",
      "  episode_reward_min: 2.610000000000009\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 10199\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.30164754986763\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010879206301524561\n",
      "          policy_loss: -0.007475979005297025\n",
      "          total_loss: 0.08584250497764774\n",
      "          vf_explained_var: 0.9809394478797913\n",
      "          vf_loss: 0.09849308727397806\n",
      "    num_agent_steps_sampled: 1048950\n",
      "    num_agent_steps_trained: 1048950\n",
      "    num_steps_sampled: 1048950\n",
      "    num_steps_trained: 1048950\n",
      "  iterations_since_restore: 525\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.35000000000002\n",
      "    ram_util_percent: 31.3264705882353\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044354748910487754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.992031830901997\n",
      "    mean_inference_ms: 2.469556360070405\n",
      "    mean_raw_obs_processing_ms: 2.041043869342852\n",
      "  time_since_restore: 14263.600459814072\n",
      "  time_this_iter_s: 23.965370655059814\n",
      "  time_total_s: 14263.600459814072\n",
      "  timers:\n",
      "    learn_throughput: 1163.914\n",
      "    learn_time_ms: 1716.621\n",
      "    load_throughput: 59790.207\n",
      "    load_time_ms: 33.417\n",
      "    sample_throughput: 87.435\n",
      "    sample_time_ms: 22851.183\n",
      "    update_time_ms: 9.999\n",
      "  timestamp: 1636443792\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1048950\n",
      "  training_iteration: 525\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   525</td><td style=\"text-align: right;\">         14263.6</td><td style=\"text-align: right;\">1048950</td><td style=\"text-align: right;\">  8.6584</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.61</td><td style=\"text-align: right;\">            102.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1050948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-43-37\n",
      "  done: false\n",
      "  episode_len_mean: 101.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.52910000000002\n",
      "  episode_reward_min: 2.170000000000018\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10220\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.21611683567365\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01060315038943243\n",
      "          policy_loss: -0.0029836052940005347\n",
      "          total_loss: 0.12884738580102012\n",
      "          vf_explained_var: 0.9806031584739685\n",
      "          vf_loss: 0.13634927143298445\n",
      "    num_agent_steps_sampled: 1050948\n",
      "    num_agent_steps_trained: 1050948\n",
      "    num_steps_sampled: 1050948\n",
      "    num_steps_trained: 1050948\n",
      "  iterations_since_restore: 526\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.48918918918919\n",
      "    ram_util_percent: 31.32162162162163\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437738936493727\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.990005074124678\n",
      "    mean_inference_ms: 2.4698759151202347\n",
      "    mean_raw_obs_processing_ms: 2.038290699657416\n",
      "  time_since_restore: 14289.060984611511\n",
      "  time_this_iter_s: 25.460524797439575\n",
      "  time_total_s: 14289.060984611511\n",
      "  timers:\n",
      "    learn_throughput: 1163.506\n",
      "    learn_time_ms: 1717.223\n",
      "    load_throughput: 60201.558\n",
      "    load_time_ms: 33.189\n",
      "    sample_throughput: 87.177\n",
      "    sample_time_ms: 22919.001\n",
      "    update_time_ms: 10.201\n",
      "  timestamp: 1636443817\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1050948\n",
      "  training_iteration: 526\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   526</td><td style=\"text-align: right;\">         14289.1</td><td style=\"text-align: right;\">1050948</td><td style=\"text-align: right;\">  8.5291</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.17</td><td style=\"text-align: right;\">            101.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1052946\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-44-03\n",
      "  done: false\n",
      "  episode_len_mean: 100.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.54550000000002\n",
      "  episode_reward_min: 2.170000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10240\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2535590239933558\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01439724202899461\n",
      "          policy_loss: -0.037997076252386686\n",
      "          total_loss: 0.11835167257647429\n",
      "          vf_explained_var: 0.9777389764785767\n",
      "          vf_loss: 0.1585066201254016\n",
      "    num_agent_steps_sampled: 1052946\n",
      "    num_agent_steps_trained: 1052946\n",
      "    num_steps_sampled: 1052946\n",
      "    num_steps_trained: 1052946\n",
      "  iterations_since_restore: 527\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.21666666666667\n",
      "    ram_util_percent: 31.300000000000004\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04439439737711973\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.98956108940472\n",
      "    mean_inference_ms: 2.4701036376230294\n",
      "    mean_raw_obs_processing_ms: 2.03579980387161\n",
      "  time_since_restore: 14314.4801197052\n",
      "  time_this_iter_s: 25.419135093688965\n",
      "  time_total_s: 14314.4801197052\n",
      "  timers:\n",
      "    learn_throughput: 1163.553\n",
      "    learn_time_ms: 1717.155\n",
      "    load_throughput: 59236.306\n",
      "    load_time_ms: 33.729\n",
      "    sample_throughput: 86.747\n",
      "    sample_time_ms: 23032.394\n",
      "    update_time_ms: 10.199\n",
      "  timestamp: 1636443843\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1052946\n",
      "  training_iteration: 527\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   527</td><td style=\"text-align: right;\">         14314.5</td><td style=\"text-align: right;\">1052946</td><td style=\"text-align: right;\">  8.5455</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.17</td><td style=\"text-align: right;\">            100.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1054944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-44-28\n",
      "  done: false\n",
      "  episode_len_mean: 102.28\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000014\n",
      "  episode_reward_mean: 8.509500000000019\n",
      "  episode_reward_min: 2.170000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10260\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3201450591995603\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01050506567816072\n",
      "          policy_loss: -0.016372356138059072\n",
      "          total_loss: 0.10069258065805549\n",
      "          vf_explained_var: 0.9748987555503845\n",
      "          vf_loss: 0.12269420228188946\n",
      "    num_agent_steps_sampled: 1054944\n",
      "    num_agent_steps_trained: 1054944\n",
      "    num_steps_sampled: 1054944\n",
      "    num_steps_trained: 1054944\n",
      "  iterations_since_restore: 528\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.62222222222223\n",
      "    ram_util_percent: 31.261111111111106\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044378787831129154\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99007438747156\n",
      "    mean_inference_ms: 2.469831504516789\n",
      "    mean_raw_obs_processing_ms: 2.033229825370869\n",
      "  time_since_restore: 14339.435492038727\n",
      "  time_this_iter_s: 24.95537233352661\n",
      "  time_total_s: 14339.435492038727\n",
      "  timers:\n",
      "    learn_throughput: 1163.305\n",
      "    learn_time_ms: 1717.52\n",
      "    load_throughput: 59541.778\n",
      "    load_time_ms: 33.556\n",
      "    sample_throughput: 87.095\n",
      "    sample_time_ms: 22940.496\n",
      "    update_time_ms: 10.97\n",
      "  timestamp: 1636443868\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1054944\n",
      "  training_iteration: 528\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   528</td><td style=\"text-align: right;\">         14339.4</td><td style=\"text-align: right;\">1054944</td><td style=\"text-align: right;\">  8.5095</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                2.17</td><td style=\"text-align: right;\">            102.28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1056942\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-44-55\n",
      "  done: false\n",
      "  episode_len_mean: 100.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000012\n",
      "  episode_reward_mean: 8.584400000000018\n",
      "  episode_reward_min: 2.170000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10280\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1851507513296036\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011171001636449426\n",
      "          policy_loss: -0.01947297959455422\n",
      "          total_loss: 0.12155022287652606\n",
      "          vf_explained_var: 0.9835809469223022\n",
      "          vf_loss: 0.1448225048148916\n",
      "    num_agent_steps_sampled: 1056942\n",
      "    num_agent_steps_trained: 1056942\n",
      "    num_steps_sampled: 1056942\n",
      "    num_steps_trained: 1056942\n",
      "  iterations_since_restore: 529\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.50512820512822\n",
      "    ram_util_percent: 31.23589743589743\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044367516451382184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.990374199424995\n",
      "    mean_inference_ms: 2.4696556583221003\n",
      "    mean_raw_obs_processing_ms: 2.030633154742018\n",
      "  time_since_restore: 14366.831305980682\n",
      "  time_this_iter_s: 27.395813941955566\n",
      "  time_total_s: 14366.831305980682\n",
      "  timers:\n",
      "    learn_throughput: 1163.116\n",
      "    learn_time_ms: 1717.8\n",
      "    load_throughput: 59646.963\n",
      "    load_time_ms: 33.497\n",
      "    sample_throughput: 85.837\n",
      "    sample_time_ms: 23276.778\n",
      "    update_time_ms: 10.472\n",
      "  timestamp: 1636443895\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1056942\n",
      "  training_iteration: 529\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   529</td><td style=\"text-align: right;\">         14366.8</td><td style=\"text-align: right;\">1056942</td><td style=\"text-align: right;\">  8.5844</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">                2.17</td><td style=\"text-align: right;\">            100.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1058940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-45-20\n",
      "  done: false\n",
      "  episode_len_mean: 99.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000012\n",
      "  episode_reward_mean: 8.59890000000002\n",
      "  episode_reward_min: 2.170000000000018\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10300\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2570944559006465\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008756233035629772\n",
      "          policy_loss: -0.072125640130114\n",
      "          total_loss: 0.03351811677040089\n",
      "          vf_explained_var: 0.9805317521095276\n",
      "          vf_loss: 0.11190309340045565\n",
      "    num_agent_steps_sampled: 1058940\n",
      "    num_agent_steps_trained: 1058940\n",
      "    num_steps_sampled: 1058940\n",
      "    num_steps_trained: 1058940\n",
      "  iterations_since_restore: 530\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.34\n",
      "    ram_util_percent: 31.185714285714287\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04437108481839725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.990384552281593\n",
      "    mean_inference_ms: 2.469736159269319\n",
      "    mean_raw_obs_processing_ms: 2.028123919921287\n",
      "  time_since_restore: 14391.596758365631\n",
      "  time_this_iter_s: 24.76545238494873\n",
      "  time_total_s: 14391.596758365631\n",
      "  timers:\n",
      "    learn_throughput: 1163.496\n",
      "    learn_time_ms: 1717.239\n",
      "    load_throughput: 60017.671\n",
      "    load_time_ms: 33.29\n",
      "    sample_throughput: 85.418\n",
      "    sample_time_ms: 23390.768\n",
      "    update_time_ms: 10.046\n",
      "  timestamp: 1636443920\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1058940\n",
      "  training_iteration: 530\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   530</td><td style=\"text-align: right;\">         14391.6</td><td style=\"text-align: right;\">1058940</td><td style=\"text-align: right;\">  8.5989</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">                2.17</td><td style=\"text-align: right;\">             99.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1060938\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-46-02\n",
      "  done: false\n",
      "  episode_len_mean: 99.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000012\n",
      "  episode_reward_mean: 8.64790000000002\n",
      "  episode_reward_min: 3.82000000000002\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 10319\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3059571039109004\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01033519548075554\n",
      "          policy_loss: -0.039181757332491025\n",
      "          total_loss: 0.09849048759788274\n",
      "          vf_explained_var: 0.9693161845207214\n",
      "          vf_loss: 0.14328207249442737\n",
      "    num_agent_steps_sampled: 1060938\n",
      "    num_agent_steps_trained: 1060938\n",
      "    num_steps_sampled: 1060938\n",
      "    num_steps_trained: 1060938\n",
      "  iterations_since_restore: 531\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.84098360655739\n",
      "    ram_util_percent: 31.108196721311465\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436478286280155\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.992721363674445\n",
      "    mean_inference_ms: 2.4696406169366933\n",
      "    mean_raw_obs_processing_ms: 2.0290840599120603\n",
      "  time_since_restore: 14434.20059967041\n",
      "  time_this_iter_s: 42.60384130477905\n",
      "  time_total_s: 14434.20059967041\n",
      "  timers:\n",
      "    learn_throughput: 1162.237\n",
      "    learn_time_ms: 1719.099\n",
      "    load_throughput: 60018.918\n",
      "    load_time_ms: 33.29\n",
      "    sample_throughput: 79.06\n",
      "    sample_time_ms: 25272.096\n",
      "    update_time_ms: 9.225\n",
      "  timestamp: 1636443962\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1060938\n",
      "  training_iteration: 531\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   531</td><td style=\"text-align: right;\">         14434.2</td><td style=\"text-align: right;\">1060938</td><td style=\"text-align: right;\">  8.6479</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">                3.82</td><td style=\"text-align: right;\">             99.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1062936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-46-29\n",
      "  done: false\n",
      "  episode_len_mean: 99.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000012\n",
      "  episode_reward_mean: 8.823100000000016\n",
      "  episode_reward_min: 3.0100000000000144\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10340\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2312117928550357\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015666045424478577\n",
      "          policy_loss: -0.07600178140259925\n",
      "          total_loss: 0.12290565082359882\n",
      "          vf_explained_var: 0.9714348912239075\n",
      "          vf_loss: 0.19992726234098276\n",
      "    num_agent_steps_sampled: 1062936\n",
      "    num_agent_steps_trained: 1062936\n",
      "    num_steps_sampled: 1062936\n",
      "    num_steps_trained: 1062936\n",
      "  iterations_since_restore: 532\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9263157894737\n",
      "    ram_util_percent: 31.12368421052631\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443579163403863\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99581640638262\n",
      "    mean_inference_ms: 2.469545292232031\n",
      "    mean_raw_obs_processing_ms: 2.0302701794023794\n",
      "  time_since_restore: 14460.565105199814\n",
      "  time_this_iter_s: 26.364505529403687\n",
      "  time_total_s: 14460.565105199814\n",
      "  timers:\n",
      "    learn_throughput: 1162.29\n",
      "    learn_time_ms: 1719.02\n",
      "    load_throughput: 60337.618\n",
      "    load_time_ms: 33.114\n",
      "    sample_throughput: 78.647\n",
      "    sample_time_ms: 25404.571\n",
      "    update_time_ms: 9.448\n",
      "  timestamp: 1636443989\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1062936\n",
      "  training_iteration: 532\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   532</td><td style=\"text-align: right;\">         14460.6</td><td style=\"text-align: right;\">1062936</td><td style=\"text-align: right;\">  8.8231</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">                3.01</td><td style=\"text-align: right;\">             99.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1064934\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-47-11\n",
      "  done: false\n",
      "  episode_len_mean: 97.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000012\n",
      "  episode_reward_mean: 8.725000000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 10362\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2270041902860005\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012506289993291566\n",
      "          policy_loss: -0.015901478034045013\n",
      "          total_loss: 0.49419116194226914\n",
      "          vf_explained_var: 0.9364272952079773\n",
      "          vf_loss: 0.5133479846730119\n",
      "    num_agent_steps_sampled: 1064934\n",
      "    num_agent_steps_trained: 1064934\n",
      "    num_steps_sampled: 1064934\n",
      "    num_steps_trained: 1064934\n",
      "  iterations_since_restore: 533\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.09999999999998\n",
      "    ram_util_percent: 31.065\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436024561135\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99673198313124\n",
      "    mean_inference_ms: 2.4696185319081976\n",
      "    mean_raw_obs_processing_ms: 2.038011519520698\n",
      "  time_since_restore: 14503.060512065887\n",
      "  time_this_iter_s: 42.49540686607361\n",
      "  time_total_s: 14503.060512065887\n",
      "  timers:\n",
      "    learn_throughput: 1162.507\n",
      "    learn_time_ms: 1718.7\n",
      "    load_throughput: 60310.175\n",
      "    load_time_ms: 33.129\n",
      "    sample_throughput: 73.882\n",
      "    sample_time_ms: 27043.159\n",
      "    update_time_ms: 9.267\n",
      "  timestamp: 1636444031\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1064934\n",
      "  training_iteration: 533\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   533</td><td style=\"text-align: right;\">         14503.1</td><td style=\"text-align: right;\">1064934</td><td style=\"text-align: right;\">   8.725</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             97.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1066932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-47-39\n",
      "  done: false\n",
      "  episode_len_mean: 97.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 8.721600000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10382\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1362243782906305\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016156361896301756\n",
      "          policy_loss: -0.033076024286094165\n",
      "          total_loss: 0.19395262299194221\n",
      "          vf_explained_var: 0.9717828035354614\n",
      "          vf_loss: 0.2267451787544858\n",
      "    num_agent_steps_sampled: 1066932\n",
      "    num_agent_steps_trained: 1066932\n",
      "    num_steps_sampled: 1066932\n",
      "    num_steps_trained: 1066932\n",
      "  iterations_since_restore: 534\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72\n",
      "    ram_util_percent: 31.064999999999998\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044356186430211525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.99932225806919\n",
      "    mean_inference_ms: 2.4696061760481007\n",
      "    mean_raw_obs_processing_ms: 2.045061756902348\n",
      "  time_since_restore: 14530.48278594017\n",
      "  time_this_iter_s: 27.422273874282837\n",
      "  time_total_s: 14530.48278594017\n",
      "  timers:\n",
      "    learn_throughput: 1162.616\n",
      "    learn_time_ms: 1718.539\n",
      "    load_throughput: 60130.284\n",
      "    load_time_ms: 33.228\n",
      "    sample_throughput: 73.149\n",
      "    sample_time_ms: 27313.958\n",
      "    update_time_ms: 9.732\n",
      "  timestamp: 1636444059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1066932\n",
      "  training_iteration: 534\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   534</td><td style=\"text-align: right;\">         14530.5</td><td style=\"text-align: right;\">1066932</td><td style=\"text-align: right;\">  8.7216</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">              97.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1068930\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-48-05\n",
      "  done: false\n",
      "  episode_len_mean: 96.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 8.813300000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 10404\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1665954379808334\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008606521286968576\n",
      "          policy_loss: -0.01327788338419937\n",
      "          total_loss: 0.09375183051008554\n",
      "          vf_explained_var: 0.9862886071205139\n",
      "          vf_loss: 0.11249197531668913\n",
      "    num_agent_steps_sampled: 1068930\n",
      "    num_agent_steps_trained: 1068930\n",
      "    num_steps_sampled: 1068930\n",
      "    num_steps_trained: 1068930\n",
      "  iterations_since_restore: 535\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5578947368421\n",
      "    ram_util_percent: 31.186842105263157\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044326151709184566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.002890362211485\n",
      "    mean_inference_ms: 2.4691851344337117\n",
      "    mean_raw_obs_processing_ms: 2.052760541158699\n",
      "  time_since_restore: 14557.084740638733\n",
      "  time_this_iter_s: 26.601954698562622\n",
      "  time_total_s: 14557.084740638733\n",
      "  timers:\n",
      "    learn_throughput: 1163.85\n",
      "    learn_time_ms: 1716.717\n",
      "    load_throughput: 59404.731\n",
      "    load_time_ms: 33.634\n",
      "    sample_throughput: 72.444\n",
      "    sample_time_ms: 27579.816\n",
      "    update_time_ms: 8.584\n",
      "  timestamp: 1636444085\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1068930\n",
      "  training_iteration: 535\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   535</td><td style=\"text-align: right;\">         14557.1</td><td style=\"text-align: right;\">1068930</td><td style=\"text-align: right;\">  8.8133</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             96.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1070928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-48-31\n",
      "  done: false\n",
      "  episode_len_mean: 96.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 9.138800000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 10423\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1646205254963466\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009243093117402236\n",
      "          policy_loss: -0.04495144271779628\n",
      "          total_loss: 0.07275239422562577\n",
      "          vf_explained_var: 0.9736900925636292\n",
      "          vf_loss: 0.12268750195701918\n",
      "    num_agent_steps_sampled: 1070928\n",
      "    num_agent_steps_trained: 1070928\n",
      "    num_steps_sampled: 1070928\n",
      "    num_steps_trained: 1070928\n",
      "  iterations_since_restore: 536\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.41944444444444\n",
      "    ram_util_percent: 31.21111111111111\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434005575280308\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.00436701178537\n",
      "    mean_inference_ms: 2.4694156017526425\n",
      "    mean_raw_obs_processing_ms: 2.0562512812928873\n",
      "  time_since_restore: 14582.600296258926\n",
      "  time_this_iter_s: 25.51555562019348\n",
      "  time_total_s: 14582.600296258926\n",
      "  timers:\n",
      "    learn_throughput: 1163.958\n",
      "    learn_time_ms: 1716.556\n",
      "    load_throughput: 59306.608\n",
      "    load_time_ms: 33.689\n",
      "    sample_throughput: 72.431\n",
      "    sample_time_ms: 27585.048\n",
      "    update_time_ms: 8.749\n",
      "  timestamp: 1636444111\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1070928\n",
      "  training_iteration: 536\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   536</td><td style=\"text-align: right;\">         14582.6</td><td style=\"text-align: right;\">1070928</td><td style=\"text-align: right;\">  9.1388</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             96.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1072926\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-48-57\n",
      "  done: false\n",
      "  episode_len_mean: 95.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 9.576600000000019\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10444\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.179175215959549\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008770940095384951\n",
      "          policy_loss: -0.07216532072495846\n",
      "          total_loss: 0.0038642801433092073\n",
      "          vf_explained_var: 0.9904115796089172\n",
      "          vf_loss: 0.08149914522433564\n",
      "    num_agent_steps_sampled: 1072926\n",
      "    num_agent_steps_trained: 1072926\n",
      "    num_steps_sampled: 1072926\n",
      "    num_steps_trained: 1072926\n",
      "  iterations_since_restore: 537\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.84736842105262\n",
      "    ram_util_percent: 31.31842105263159\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044343745316072276\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.005965610286477\n",
      "    mean_inference_ms: 2.469492083842821\n",
      "    mean_raw_obs_processing_ms: 2.0579890855130505\n",
      "  time_since_restore: 14609.056103944778\n",
      "  time_this_iter_s: 26.45580768585205\n",
      "  time_total_s: 14609.056103944778\n",
      "  timers:\n",
      "    learn_throughput: 1164.127\n",
      "    learn_time_ms: 1716.308\n",
      "    load_throughput: 59158.067\n",
      "    load_time_ms: 33.774\n",
      "    sample_throughput: 72.159\n",
      "    sample_time_ms: 27688.803\n",
      "    update_time_ms: 8.619\n",
      "  timestamp: 1636444137\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1072926\n",
      "  training_iteration: 537\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   537</td><td style=\"text-align: right;\">         14609.1</td><td style=\"text-align: right;\">1072926</td><td style=\"text-align: right;\">  9.5766</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             95.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1074924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-49-21\n",
      "  done: false\n",
      "  episode_len_mean: 98.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 9.76740000000002\n",
      "  episode_reward_min: 3.130000000000009\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 10462\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2391116482870919\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010495329223941615\n",
      "          policy_loss: -0.05150519135807242\n",
      "          total_loss: 0.04933085344022228\n",
      "          vf_explained_var: 0.9824755191802979\n",
      "          vf_loss: 0.10566198989039376\n",
      "    num_agent_steps_sampled: 1074924\n",
      "    num_agent_steps_trained: 1074924\n",
      "    num_steps_sampled: 1074924\n",
      "    num_steps_trained: 1074924\n",
      "  iterations_since_restore: 538\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.86470588235295\n",
      "    ram_util_percent: 31.302941176470586\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436540471935224\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.008089950644024\n",
      "    mean_inference_ms: 2.469828031482084\n",
      "    mean_raw_obs_processing_ms: 2.055888110086117\n",
      "  time_since_restore: 14632.607204914093\n",
      "  time_this_iter_s: 23.551100969314575\n",
      "  time_total_s: 14632.607204914093\n",
      "  timers:\n",
      "    learn_throughput: 1163.327\n",
      "    learn_time_ms: 1717.488\n",
      "    load_throughput: 59173.021\n",
      "    load_time_ms: 33.765\n",
      "    sample_throughput: 72.528\n",
      "    sample_time_ms: 27547.898\n",
      "    update_time_ms: 7.612\n",
      "  timestamp: 1636444161\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1074924\n",
      "  training_iteration: 538\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   538</td><td style=\"text-align: right;\">         14632.6</td><td style=\"text-align: right;\">1074924</td><td style=\"text-align: right;\">  9.7674</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">                3.13</td><td style=\"text-align: right;\">             98.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1076922\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-49-47\n",
      "  done: false\n",
      "  episode_len_mean: 99.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 9.496900000000016\n",
      "  episode_reward_min: 3.920000000000022\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10483\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2780751461074467\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008043441367100492\n",
      "          policy_loss: -0.054435378313064574\n",
      "          total_loss: 0.03688675335918864\n",
      "          vf_explained_var: 0.9836627840995789\n",
      "          vf_loss: 0.09830506504291579\n",
      "    num_agent_steps_sampled: 1076922\n",
      "    num_agent_steps_trained: 1076922\n",
      "    num_steps_sampled: 1076922\n",
      "    num_steps_trained: 1076922\n",
      "  iterations_since_restore: 539\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.25833333333334\n",
      "    ram_util_percent: 31.325000000000006\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436567627167207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.008932661117086\n",
      "    mean_inference_ms: 2.469841619995567\n",
      "    mean_raw_obs_processing_ms: 2.0532913096437677\n",
      "  time_since_restore: 14658.152837991714\n",
      "  time_this_iter_s: 25.54563307762146\n",
      "  time_total_s: 14658.152837991714\n",
      "  timers:\n",
      "    learn_throughput: 1163.983\n",
      "    learn_time_ms: 1716.52\n",
      "    load_throughput: 58955.097\n",
      "    load_time_ms: 33.89\n",
      "    sample_throughput: 73.017\n",
      "    sample_time_ms: 27363.395\n",
      "    update_time_ms: 8.028\n",
      "  timestamp: 1636444187\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1076922\n",
      "  training_iteration: 539\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   539</td><td style=\"text-align: right;\">         14658.2</td><td style=\"text-align: right;\">1076922</td><td style=\"text-align: right;\">  9.4969</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">                3.92</td><td style=\"text-align: right;\">             99.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1078920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-50-13\n",
      "  done: false\n",
      "  episode_len_mean: 99.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 9.311800000000016\n",
      "  episode_reward_min: 3.5000000000000213\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10503\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.269730071794419\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017238078849888913\n",
      "          policy_loss: -0.016617246859130404\n",
      "          total_loss: 0.22852272192637127\n",
      "          vf_explained_var: 0.9637792706489563\n",
      "          vf_loss: 0.24541183743803274\n",
      "    num_agent_steps_sampled: 1078920\n",
      "    num_agent_steps_trained: 1078920\n",
      "    num_steps_sampled: 1078920\n",
      "    num_steps_trained: 1078920\n",
      "  iterations_since_restore: 540\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97297297297295\n",
      "    ram_util_percent: 31.34324324324325\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436084338047008\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.01100371996816\n",
      "    mean_inference_ms: 2.46977465991576\n",
      "    mean_raw_obs_processing_ms: 2.0508121573459754\n",
      "  time_since_restore: 14684.109377861023\n",
      "  time_this_iter_s: 25.95653986930847\n",
      "  time_total_s: 14684.109377861023\n",
      "  timers:\n",
      "    learn_throughput: 1164.661\n",
      "    learn_time_ms: 1715.521\n",
      "    load_throughput: 58554.574\n",
      "    load_time_ms: 34.122\n",
      "    sample_throughput: 72.699\n",
      "    sample_time_ms: 27483.184\n",
      "    update_time_ms: 8.292\n",
      "  timestamp: 1636444213\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1078920\n",
      "  training_iteration: 540\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   540</td><td style=\"text-align: right;\">         14684.1</td><td style=\"text-align: right;\">1078920</td><td style=\"text-align: right;\">  9.3118</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                 3.5</td><td style=\"text-align: right;\">              99.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1080918\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-50-40\n",
      "  done: false\n",
      "  episode_len_mean: 99.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 9.266400000000019\n",
      "  episode_reward_min: 3.5000000000000213\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10523\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1409497823034014\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013170674848438408\n",
      "          policy_loss: -0.05417180614812034\n",
      "          total_loss: 0.09661461499830087\n",
      "          vf_explained_var: 0.9805542230606079\n",
      "          vf_loss: 0.152702326575915\n",
      "    num_agent_steps_sampled: 1080918\n",
      "    num_agent_steps_trained: 1080918\n",
      "    num_steps_sampled: 1080918\n",
      "    num_steps_trained: 1080918\n",
      "  iterations_since_restore: 541\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.55897435897437\n",
      "    ram_util_percent: 31.323076923076933\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044359628186686734\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.0121830991747\n",
      "    mean_inference_ms: 2.4698049980201335\n",
      "    mean_raw_obs_processing_ms: 2.048302917963674\n",
      "  time_since_restore: 14711.326064109802\n",
      "  time_this_iter_s: 27.216686248779297\n",
      "  time_total_s: 14711.326064109802\n",
      "  timers:\n",
      "    learn_throughput: 1163.8\n",
      "    learn_time_ms: 1716.79\n",
      "    load_throughput: 58584.948\n",
      "    load_time_ms: 34.104\n",
      "    sample_throughput: 77.016\n",
      "    sample_time_ms: 25942.595\n",
      "    update_time_ms: 8.903\n",
      "  timestamp: 1636444240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1080918\n",
      "  training_iteration: 541\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   541</td><td style=\"text-align: right;\">         14711.3</td><td style=\"text-align: right;\">1080918</td><td style=\"text-align: right;\">  9.2664</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                 3.5</td><td style=\"text-align: right;\">             99.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1082916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-51-06\n",
      "  done: false\n",
      "  episode_len_mean: 100.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 9.12410000000002\n",
      "  episode_reward_min: 3.4400000000000226\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10543\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.118549698023569\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012359889029906751\n",
      "          policy_loss: -0.054339907371572085\n",
      "          total_loss: 0.04726589938536996\n",
      "          vf_explained_var: 0.9861155152320862\n",
      "          vf_loss: 0.1038821337833291\n",
      "    num_agent_steps_sampled: 1082916\n",
      "    num_agent_steps_trained: 1082916\n",
      "    num_steps_sampled: 1082916\n",
      "    num_steps_trained: 1082916\n",
      "  iterations_since_restore: 542\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.22105263157896\n",
      "    ram_util_percent: 31.2657894736842\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044354743030139525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.01364494018758\n",
      "    mean_inference_ms: 2.469749140816\n",
      "    mean_raw_obs_processing_ms: 2.045829420248034\n",
      "  time_since_restore: 14737.812328338623\n",
      "  time_this_iter_s: 26.4862642288208\n",
      "  time_total_s: 14737.812328338623\n",
      "  timers:\n",
      "    learn_throughput: 1163.128\n",
      "    learn_time_ms: 1717.781\n",
      "    load_throughput: 58697.876\n",
      "    load_time_ms: 34.039\n",
      "    sample_throughput: 76.983\n",
      "    sample_time_ms: 25953.892\n",
      "    update_time_ms: 8.708\n",
      "  timestamp: 1636444266\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1082916\n",
      "  training_iteration: 542\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   542</td><td style=\"text-align: right;\">         14737.8</td><td style=\"text-align: right;\">1082916</td><td style=\"text-align: right;\">  9.1241</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                3.44</td><td style=\"text-align: right;\">            100.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1084914\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-51-32\n",
      "  done: false\n",
      "  episode_len_mean: 100.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 9.126000000000019\n",
      "  episode_reward_min: 3.4400000000000226\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 10562\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2156971096992493\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00990708548619749\n",
      "          policy_loss: -0.02326853122739565\n",
      "          total_loss: 0.09285352366665998\n",
      "          vf_explained_var: 0.9824304580688477\n",
      "          vf_loss: 0.12113786846221912\n",
      "    num_agent_steps_sampled: 1084914\n",
      "    num_agent_steps_trained: 1084914\n",
      "    num_steps_sampled: 1084914\n",
      "    num_steps_trained: 1084914\n",
      "  iterations_since_restore: 543\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.27499999999999\n",
      "    ram_util_percent: 31.21388888888889\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435839834261426\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.013186555518292\n",
      "    mean_inference_ms: 2.469845215273961\n",
      "    mean_raw_obs_processing_ms: 2.043426351742817\n",
      "  time_since_restore: 14763.2270154953\n",
      "  time_this_iter_s: 25.414687156677246\n",
      "  time_total_s: 14763.2270154953\n",
      "  timers:\n",
      "    learn_throughput: 1163.061\n",
      "    learn_time_ms: 1717.88\n",
      "    load_throughput: 58591.256\n",
      "    load_time_ms: 34.101\n",
      "    sample_throughput: 82.408\n",
      "    sample_time_ms: 24245.356\n",
      "    update_time_ms: 8.969\n",
      "  timestamp: 1636444292\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1084914\n",
      "  training_iteration: 543\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   543</td><td style=\"text-align: right;\">         14763.2</td><td style=\"text-align: right;\">1084914</td><td style=\"text-align: right;\">   9.126</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                3.44</td><td style=\"text-align: right;\">            100.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1086912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-51-58\n",
      "  done: false\n",
      "  episode_len_mean: 100.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 9.264900000000019\n",
      "  episode_reward_min: 3.4400000000000226\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10582\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2686386199224562\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010063039470355084\n",
      "          policy_loss: -0.06276469264356863\n",
      "          total_loss: 0.04348480062825339\n",
      "          vf_explained_var: 0.9745402932167053\n",
      "          vf_loss: 0.11168231067380735\n",
      "    num_agent_steps_sampled: 1086912\n",
      "    num_agent_steps_trained: 1086912\n",
      "    num_steps_sampled: 1086912\n",
      "    num_steps_trained: 1086912\n",
      "  iterations_since_restore: 544\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.54054054054055\n",
      "    ram_util_percent: 31.20810810810811\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435916202885455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.013818768617476\n",
      "    mean_inference_ms: 2.469850704059017\n",
      "    mean_raw_obs_processing_ms: 2.0409408491537704\n",
      "  time_since_restore: 14789.211496591568\n",
      "  time_this_iter_s: 25.9844810962677\n",
      "  time_total_s: 14789.211496591568\n",
      "  timers:\n",
      "    learn_throughput: 1162.334\n",
      "    learn_time_ms: 1718.955\n",
      "    load_throughput: 58436.898\n",
      "    load_time_ms: 34.191\n",
      "    sample_throughput: 82.902\n",
      "    sample_time_ms: 24100.728\n",
      "    update_time_ms: 8.953\n",
      "  timestamp: 1636444318\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1086912\n",
      "  training_iteration: 544\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   544</td><td style=\"text-align: right;\">         14789.2</td><td style=\"text-align: right;\">1086912</td><td style=\"text-align: right;\">  9.2649</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                3.44</td><td style=\"text-align: right;\">            100.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1088910\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-52-24\n",
      "  done: false\n",
      "  episode_len_mean: 100.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 9.111900000000018\n",
      "  episode_reward_min: 3.1200000000000156\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10603\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.151420529683431\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0093899127494549\n",
      "          policy_loss: -0.026944835421939692\n",
      "          total_loss: 0.10027517950428384\n",
      "          vf_explained_var: 0.9815118908882141\n",
      "          vf_loss: 0.13196584876804124\n",
      "    num_agent_steps_sampled: 1088910\n",
      "    num_agent_steps_trained: 1088910\n",
      "    num_steps_sampled: 1088910\n",
      "    num_steps_trained: 1088910\n",
      "  iterations_since_restore: 545\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.67837837837838\n",
      "    ram_util_percent: 31.151351351351348\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04436566699808479\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.01390593433765\n",
      "    mean_inference_ms: 2.4699196477921923\n",
      "    mean_raw_obs_processing_ms: 2.0383082276752647\n",
      "  time_since_restore: 14815.285215854645\n",
      "  time_this_iter_s: 26.073719263076782\n",
      "  time_total_s: 14815.285215854645\n",
      "  timers:\n",
      "    learn_throughput: 1161.193\n",
      "    learn_time_ms: 1720.644\n",
      "    load_throughput: 58997.224\n",
      "    load_time_ms: 33.866\n",
      "    sample_throughput: 83.091\n",
      "    sample_time_ms: 24046.062\n",
      "    update_time_ms: 9.521\n",
      "  timestamp: 1636444344\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1088910\n",
      "  training_iteration: 545\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   545</td><td style=\"text-align: right;\">         14815.3</td><td style=\"text-align: right;\">1088910</td><td style=\"text-align: right;\">  9.1119</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                3.12</td><td style=\"text-align: right;\">            100.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1090908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-52-49\n",
      "  done: false\n",
      "  episode_len_mean: 99.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 9.002700000000019\n",
      "  episode_reward_min: 2.490000000000027\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10624\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2164947066988263\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01354723147924594\n",
      "          policy_loss: -0.04213932092700686\n",
      "          total_loss: 0.07855692955532244\n",
      "          vf_explained_var: 0.9739426374435425\n",
      "          vf_loss: 0.12309617698192596\n",
      "    num_agent_steps_sampled: 1090908\n",
      "    num_agent_steps_trained: 1090908\n",
      "    num_steps_sampled: 1090908\n",
      "    num_steps_trained: 1090908\n",
      "  iterations_since_restore: 546\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97027027027026\n",
      "    ram_util_percent: 31.164864864864857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443567611022543\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.01479439467226\n",
      "    mean_inference_ms: 2.4697345921769323\n",
      "    mean_raw_obs_processing_ms: 2.0357095184902585\n",
      "  time_since_restore: 14840.70849108696\n",
      "  time_this_iter_s: 25.423275232315063\n",
      "  time_total_s: 14840.70849108696\n",
      "  timers:\n",
      "    learn_throughput: 1160.378\n",
      "    learn_time_ms: 1721.852\n",
      "    load_throughput: 59086.2\n",
      "    load_time_ms: 33.815\n",
      "    sample_throughput: 83.124\n",
      "    sample_time_ms: 24036.431\n",
      "    update_time_ms: 8.736\n",
      "  timestamp: 1636444369\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1090908\n",
      "  training_iteration: 546\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   546</td><td style=\"text-align: right;\">         14840.7</td><td style=\"text-align: right;\">1090908</td><td style=\"text-align: right;\">  9.0027</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                2.49</td><td style=\"text-align: right;\">              99.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1092906\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-53-16\n",
      "  done: false\n",
      "  episode_len_mean: 98.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.679800000000018\n",
      "  episode_reward_min: 2.490000000000027\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10645\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1496280812081836\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01380290144047515\n",
      "          policy_loss: -0.041624748866472924\n",
      "          total_loss: 0.08347647321366128\n",
      "          vf_explained_var: 0.964237630367279\n",
      "          vf_loss: 0.12664819397032262\n",
      "    num_agent_steps_sampled: 1092906\n",
      "    num_agent_steps_trained: 1092906\n",
      "    num_steps_sampled: 1092906\n",
      "    num_steps_trained: 1092906\n",
      "  iterations_since_restore: 547\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8736842105263\n",
      "    ram_util_percent: 31.14736842105263\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434281524154662\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.01806475669694\n",
      "    mean_inference_ms: 2.4694551198015513\n",
      "    mean_raw_obs_processing_ms: 2.0331872675726093\n",
      "  time_since_restore: 14867.198144197464\n",
      "  time_this_iter_s: 26.48965311050415\n",
      "  time_total_s: 14867.198144197464\n",
      "  timers:\n",
      "    learn_throughput: 1161.125\n",
      "    learn_time_ms: 1720.745\n",
      "    load_throughput: 59290.579\n",
      "    load_time_ms: 33.698\n",
      "    sample_throughput: 83.109\n",
      "    sample_time_ms: 24040.732\n",
      "    update_time_ms: 9.313\n",
      "  timestamp: 1636444396\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1092906\n",
      "  training_iteration: 547\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   547</td><td style=\"text-align: right;\">         14867.2</td><td style=\"text-align: right;\">1092906</td><td style=\"text-align: right;\">  8.6798</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                2.49</td><td style=\"text-align: right;\">             98.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1094904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-53-56\n",
      "  done: false\n",
      "  episode_len_mean: 97.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.303300000000016\n",
      "  episode_reward_min: -0.01\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10666\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2049337131636484\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014452583525187855\n",
      "          policy_loss: -0.04988464235904671\n",
      "          total_loss: 0.16584685662583937\n",
      "          vf_explained_var: 0.9631613492965698\n",
      "          vf_loss: 0.2173632238769815\n",
      "    num_agent_steps_sampled: 1094904\n",
      "    num_agent_steps_trained: 1094904\n",
      "    num_steps_sampled: 1094904\n",
      "    num_steps_trained: 1094904\n",
      "  iterations_since_restore: 548\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.97719298245616\n",
      "    ram_util_percent: 31.136842105263153\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431635974709359\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.02130991641134\n",
      "    mean_inference_ms: 2.468996980058867\n",
      "    mean_raw_obs_processing_ms: 2.034041169208972\n",
      "  time_since_restore: 14907.272053480148\n",
      "  time_this_iter_s: 40.073909282684326\n",
      "  time_total_s: 14907.272053480148\n",
      "  timers:\n",
      "    learn_throughput: 1162.047\n",
      "    learn_time_ms: 1719.38\n",
      "    load_throughput: 59057.386\n",
      "    load_time_ms: 33.832\n",
      "    sample_throughput: 77.76\n",
      "    sample_time_ms: 25694.357\n",
      "    update_time_ms: 9.087\n",
      "  timestamp: 1636444436\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1094904\n",
      "  training_iteration: 548\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   548</td><td style=\"text-align: right;\">         14907.3</td><td style=\"text-align: right;\">1094904</td><td style=\"text-align: right;\">  8.3033</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -0.01</td><td style=\"text-align: right;\">             97.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1096902\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-54-22\n",
      "  done: false\n",
      "  episode_len_mean: 96.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.308900000000017\n",
      "  episode_reward_min: -0.01\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 10685\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2011679655029661\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016909427850453143\n",
      "          policy_loss: -0.017594616292488006\n",
      "          total_loss: 0.12829647522774482\n",
      "          vf_explained_var: 0.9744007587432861\n",
      "          vf_loss: 0.14571423748774187\n",
      "    num_agent_steps_sampled: 1096902\n",
      "    num_agent_steps_trained: 1096902\n",
      "    num_steps_sampled: 1096902\n",
      "    num_steps_trained: 1096902\n",
      "  iterations_since_restore: 549\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92222222222223\n",
      "    ram_util_percent: 31.09444444444445\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044328100222333966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.023553273855974\n",
      "    mean_inference_ms: 2.4691398919150425\n",
      "    mean_raw_obs_processing_ms: 2.0348048168765938\n",
      "  time_since_restore: 14932.803080320358\n",
      "  time_this_iter_s: 25.53102684020996\n",
      "  time_total_s: 14932.803080320358\n",
      "  timers:\n",
      "    learn_throughput: 1161.003\n",
      "    learn_time_ms: 1720.926\n",
      "    load_throughput: 60244.966\n",
      "    load_time_ms: 33.165\n",
      "    sample_throughput: 77.767\n",
      "    sample_time_ms: 25691.982\n",
      "    update_time_ms: 9.108\n",
      "  timestamp: 1636444462\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1096902\n",
      "  training_iteration: 549\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   549</td><td style=\"text-align: right;\">         14932.8</td><td style=\"text-align: right;\">1096902</td><td style=\"text-align: right;\">  8.3089</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">               -0.01</td><td style=\"text-align: right;\">             96.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1098900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-55-01\n",
      "  done: false\n",
      "  episode_len_mean: 95.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.658500000000018\n",
      "  episode_reward_min: -0.02\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10706\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1999406658467793\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010780626779490276\n",
      "          policy_loss: -0.031076089736251603\n",
      "          total_loss: 0.17707314060202667\n",
      "          vf_explained_var: 0.9743521809577942\n",
      "          vf_loss: 0.2123778253261532\n",
      "    num_agent_steps_sampled: 1098900\n",
      "    num_agent_steps_trained: 1098900\n",
      "    num_steps_sampled: 1098900\n",
      "    num_steps_trained: 1098900\n",
      "  iterations_since_restore: 550\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.7517857142857\n",
      "    ram_util_percent: 31.089285714285715\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434212517108718\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.02320916968284\n",
      "    mean_inference_ms: 2.4693486819281874\n",
      "    mean_raw_obs_processing_ms: 2.0389088923825813\n",
      "  time_since_restore: 14971.95750784874\n",
      "  time_this_iter_s: 39.15442752838135\n",
      "  time_total_s: 14971.95750784874\n",
      "  timers:\n",
      "    learn_throughput: 1160.857\n",
      "    learn_time_ms: 1721.143\n",
      "    load_throughput: 48321.948\n",
      "    load_time_ms: 41.348\n",
      "    sample_throughput: 73.989\n",
      "    sample_time_ms: 27004.023\n",
      "    update_time_ms: 8.628\n",
      "  timestamp: 1636444501\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1098900\n",
      "  training_iteration: 550\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   550</td><td style=\"text-align: right;\">           14972</td><td style=\"text-align: right;\">1098900</td><td style=\"text-align: right;\">  8.6585</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.02</td><td style=\"text-align: right;\">              95.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1100898\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-55-43\n",
      "  done: false\n",
      "  episode_len_mean: 95.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.729700000000015\n",
      "  episode_reward_min: -0.16000000000000003\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 10728\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1231322762512026\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013123210888122641\n",
      "          policy_loss: -0.012529305652493522\n",
      "          total_loss: 0.2948206941774558\n",
      "          vf_explained_var: 0.958781361579895\n",
      "          vf_loss: 0.3091219393447751\n",
      "    num_agent_steps_sampled: 1100898\n",
      "    num_agent_steps_trained: 1100898\n",
      "    num_steps_sampled: 1100898\n",
      "    num_steps_trained: 1100898\n",
      "  iterations_since_restore: 551\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.24166666666665\n",
      "    ram_util_percent: 31.036666666666665\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432929637547334\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.023611193476096\n",
      "    mean_inference_ms: 2.4691289807718015\n",
      "    mean_raw_obs_processing_ms: 2.0465638585685677\n",
      "  time_since_restore: 15013.78215765953\n",
      "  time_this_iter_s: 41.824649810791016\n",
      "  time_total_s: 15013.78215765953\n",
      "  timers:\n",
      "    learn_throughput: 1162.597\n",
      "    learn_time_ms: 1718.566\n",
      "    load_throughput: 48362.579\n",
      "    load_time_ms: 41.313\n",
      "    sample_throughput: 70.185\n",
      "    sample_time_ms: 28467.755\n",
      "    update_time_ms: 8.233\n",
      "  timestamp: 1636444543\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1100898\n",
      "  training_iteration: 551\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   551</td><td style=\"text-align: right;\">         15013.8</td><td style=\"text-align: right;\">1100898</td><td style=\"text-align: right;\">  8.7297</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.16</td><td style=\"text-align: right;\">              95.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1102896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-56-07\n",
      "  done: false\n",
      "  episode_len_mean: 96.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.819100000000018\n",
      "  episode_reward_min: -0.16000000000000003\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10748\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1704670315697079\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010594518174290699\n",
      "          policy_loss: -0.08379408296729837\n",
      "          total_loss: 0.06854026420485405\n",
      "          vf_explained_var: 0.9801188111305237\n",
      "          vf_loss: 0.15640234895760105\n",
      "    num_agent_steps_sampled: 1102896\n",
      "    num_agent_steps_trained: 1102896\n",
      "    num_steps_sampled: 1102896\n",
      "    num_steps_trained: 1102896\n",
      "  iterations_since_restore: 552\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95588235294117\n",
      "    ram_util_percent: 31.182352941176465\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434833287474712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.02069475542394\n",
      "    mean_inference_ms: 2.4694259186428495\n",
      "    mean_raw_obs_processing_ms: 2.0535746662681857\n",
      "  time_since_restore: 15037.898211479187\n",
      "  time_this_iter_s: 24.116053819656372\n",
      "  time_total_s: 15037.898211479187\n",
      "  timers:\n",
      "    learn_throughput: 1162.055\n",
      "    learn_time_ms: 1719.368\n",
      "    load_throughput: 48258.67\n",
      "    load_time_ms: 41.402\n",
      "    sample_throughput: 70.776\n",
      "    sample_time_ms: 28230.017\n",
      "    update_time_ms: 8.195\n",
      "  timestamp: 1636444567\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1102896\n",
      "  training_iteration: 552\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   552</td><td style=\"text-align: right;\">         15037.9</td><td style=\"text-align: right;\">1102896</td><td style=\"text-align: right;\">  8.8191</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.16</td><td style=\"text-align: right;\">             96.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1104894\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-56-32\n",
      "  done: false\n",
      "  episode_len_mean: 96.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.000200000000017\n",
      "  episode_reward_min: -0.16000000000000003\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10768\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1888712746756418\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014212928512539413\n",
      "          policy_loss: -0.013008889254359971\n",
      "          total_loss: 0.19029493017920426\n",
      "          vf_explained_var: 0.968769907951355\n",
      "          vf_loss: 0.2049476663981165\n",
      "    num_agent_steps_sampled: 1104894\n",
      "    num_agent_steps_trained: 1104894\n",
      "    num_steps_sampled: 1104894\n",
      "    num_steps_trained: 1104894\n",
      "  iterations_since_restore: 553\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.93783783783783\n",
      "    ram_util_percent: 31.245945945945955\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435934322850988\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.02022455656096\n",
      "    mean_inference_ms: 2.4695839770820225\n",
      "    mean_raw_obs_processing_ms: 2.0572376925266327\n",
      "  time_since_restore: 15063.299283742905\n",
      "  time_this_iter_s: 25.40107226371765\n",
      "  time_total_s: 15063.299283742905\n",
      "  timers:\n",
      "    learn_throughput: 1161.834\n",
      "    learn_time_ms: 1719.694\n",
      "    load_throughput: 48216.022\n",
      "    load_time_ms: 41.439\n",
      "    sample_throughput: 70.781\n",
      "    sample_time_ms: 28228.035\n",
      "    update_time_ms: 8.52\n",
      "  timestamp: 1636444592\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1104894\n",
      "  training_iteration: 553\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   553</td><td style=\"text-align: right;\">         15063.3</td><td style=\"text-align: right;\">1104894</td><td style=\"text-align: right;\">  9.0002</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.16</td><td style=\"text-align: right;\">             96.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1106892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-56-58\n",
      "  done: false\n",
      "  episode_len_mean: 96.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.201900000000018\n",
      "  episode_reward_min: -0.16000000000000003\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10789\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0900143506981077\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01600017059990644\n",
      "          policy_loss: -0.02075664337192263\n",
      "          total_loss: 0.17834405195677563\n",
      "          vf_explained_var: 0.9764227271080017\n",
      "          vf_loss: 0.19846770717274576\n",
      "    num_agent_steps_sampled: 1106892\n",
      "    num_agent_steps_trained: 1106892\n",
      "    num_steps_sampled: 1106892\n",
      "    num_steps_trained: 1106892\n",
      "  iterations_since_restore: 554\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.42702702702702\n",
      "    ram_util_percent: 31.29729729729731\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433115088286392\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.02106490133339\n",
      "    mean_inference_ms: 2.469132834735274\n",
      "    mean_raw_obs_processing_ms: 2.0616327381964186\n",
      "  time_since_restore: 15089.192126274109\n",
      "  time_this_iter_s: 25.892842531204224\n",
      "  time_total_s: 15089.192126274109\n",
      "  timers:\n",
      "    learn_throughput: 1162.544\n",
      "    learn_time_ms: 1718.645\n",
      "    load_throughput: 48365.231\n",
      "    load_time_ms: 41.311\n",
      "    sample_throughput: 70.8\n",
      "    sample_time_ms: 28220.354\n",
      "    update_time_ms: 8.028\n",
      "  timestamp: 1636444618\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1106892\n",
      "  training_iteration: 554\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   554</td><td style=\"text-align: right;\">         15089.2</td><td style=\"text-align: right;\">1106892</td><td style=\"text-align: right;\">  9.2019</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.16</td><td style=\"text-align: right;\">             96.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1108890\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-57-24\n",
      "  done: false\n",
      "  episode_len_mean: 97.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 9.376100000000015\n",
      "  episode_reward_min: 0.9399999999999991\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10810\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0682557668004717\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01169809022795236\n",
      "          policy_loss: -0.06873271036006155\n",
      "          total_loss: 0.07666940243826026\n",
      "          vf_explained_var: 0.9814188480377197\n",
      "          vf_loss: 0.14765253625810146\n",
      "    num_agent_steps_sampled: 1108890\n",
      "    num_agent_steps_trained: 1108890\n",
      "    num_steps_sampled: 1108890\n",
      "    num_steps_trained: 1108890\n",
      "  iterations_since_restore: 555\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.12162162162161\n",
      "    ram_util_percent: 31.332432432432444\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433677742325497\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.023141596538935\n",
      "    mean_inference_ms: 2.4691994641166546\n",
      "    mean_raw_obs_processing_ms: 2.060712217217076\n",
      "  time_since_restore: 15115.111823320389\n",
      "  time_this_iter_s: 25.919697046279907\n",
      "  time_total_s: 15115.111823320389\n",
      "  timers:\n",
      "    learn_throughput: 1162.895\n",
      "    learn_time_ms: 1718.126\n",
      "    load_throughput: 48076.168\n",
      "    load_time_ms: 41.559\n",
      "    sample_throughput: 70.837\n",
      "    sample_time_ms: 28205.668\n",
      "    update_time_ms: 7.726\n",
      "  timestamp: 1636444644\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1108890\n",
      "  training_iteration: 555\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   555</td><td style=\"text-align: right;\">         15115.1</td><td style=\"text-align: right;\">1108890</td><td style=\"text-align: right;\">  9.3761</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                0.94</td><td style=\"text-align: right;\">             97.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1110888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-57-50\n",
      "  done: false\n",
      "  episode_len_mean: 97.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 9.161000000000017\n",
      "  episode_reward_min: 0.9399999999999991\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10831\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.185209574869701\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008080834390663448\n",
      "          policy_loss: -0.08922261106116432\n",
      "          total_loss: -0.010568709769064473\n",
      "          vf_explained_var: 0.9868283271789551\n",
      "          vf_loss: 0.08468122673886162\n",
      "    num_agent_steps_sampled: 1110888\n",
      "    num_agent_steps_trained: 1110888\n",
      "    num_steps_sampled: 1110888\n",
      "    num_steps_trained: 1110888\n",
      "  iterations_since_restore: 556\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.78108108108107\n",
      "    ram_util_percent: 31.362162162162164\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433150304447132\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.025015512717573\n",
      "    mean_inference_ms: 2.4691115709269047\n",
      "    mean_raw_obs_processing_ms: 2.0582554544158684\n",
      "  time_since_restore: 15141.343836545944\n",
      "  time_this_iter_s: 26.23201322555542\n",
      "  time_total_s: 15141.343836545944\n",
      "  timers:\n",
      "    learn_throughput: 1163.742\n",
      "    learn_time_ms: 1716.876\n",
      "    load_throughput: 48201.933\n",
      "    load_time_ms: 41.451\n",
      "    sample_throughput: 70.632\n",
      "    sample_time_ms: 28287.332\n",
      "    update_time_ms: 8.538\n",
      "  timestamp: 1636444670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1110888\n",
      "  training_iteration: 556\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   556</td><td style=\"text-align: right;\">         15141.3</td><td style=\"text-align: right;\">1110888</td><td style=\"text-align: right;\">   9.161</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                0.94</td><td style=\"text-align: right;\">              97.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1112886\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-58-17\n",
      "  done: false\n",
      "  episode_len_mean: 97.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 8.940900000000017\n",
      "  episode_reward_min: 0.9399999999999991\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 10850\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.111620284829821\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012338435444875222\n",
      "          policy_loss: -0.0065840943228630796\n",
      "          total_loss: 0.12003763678173224\n",
      "          vf_explained_var: 0.9780434966087341\n",
      "          vf_loss: 0.1288442284400974\n",
      "    num_agent_steps_sampled: 1112886\n",
      "    num_agent_steps_trained: 1112886\n",
      "    num_steps_sampled: 1112886\n",
      "    num_steps_trained: 1112886\n",
      "  iterations_since_restore: 557\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.71842105263158\n",
      "    ram_util_percent: 31.402631578947375\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044355781990595276\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.025262965903607\n",
      "    mean_inference_ms: 2.4695148652949843\n",
      "    mean_raw_obs_processing_ms: 2.0560860955947784\n",
      "  time_since_restore: 15167.962452888489\n",
      "  time_this_iter_s: 26.618616342544556\n",
      "  time_total_s: 15167.962452888489\n",
      "  timers:\n",
      "    learn_throughput: 1163.871\n",
      "    learn_time_ms: 1716.685\n",
      "    load_throughput: 48368.134\n",
      "    load_time_ms: 41.308\n",
      "    sample_throughput: 70.599\n",
      "    sample_time_ms: 28300.808\n",
      "    update_time_ms: 8.591\n",
      "  timestamp: 1636444697\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1112886\n",
      "  training_iteration: 557\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   557</td><td style=\"text-align: right;\">           15168</td><td style=\"text-align: right;\">1112886</td><td style=\"text-align: right;\">  8.9409</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                0.94</td><td style=\"text-align: right;\">             97.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1114884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-58-42\n",
      "  done: false\n",
      "  episode_len_mean: 97.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 8.968800000000018\n",
      "  episode_reward_min: 0.9399999999999991\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10871\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.109944763921556\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008729448297387556\n",
      "          policy_loss: -0.0474420781646456\n",
      "          total_loss: 0.04615315685846976\n",
      "          vf_explained_var: 0.979447066783905\n",
      "          vf_loss: 0.09840238298333827\n",
      "    num_agent_steps_sampled: 1114884\n",
      "    num_agent_steps_trained: 1114884\n",
      "    num_steps_sampled: 1114884\n",
      "    num_steps_trained: 1114884\n",
      "  iterations_since_restore: 558\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.75833333333334\n",
      "    ram_util_percent: 31.372222222222224\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434244834056528\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.02657523261154\n",
      "    mean_inference_ms: 2.469317755564995\n",
      "    mean_raw_obs_processing_ms: 2.0535030220708217\n",
      "  time_since_restore: 15193.187083005905\n",
      "  time_this_iter_s: 25.224630117416382\n",
      "  time_total_s: 15193.187083005905\n",
      "  timers:\n",
      "    learn_throughput: 1164.592\n",
      "    learn_time_ms: 1715.622\n",
      "    load_throughput: 48493.553\n",
      "    load_time_ms: 41.201\n",
      "    sample_throughput: 74.506\n",
      "    sample_time_ms: 26816.493\n",
      "    update_time_ms: 9.42\n",
      "  timestamp: 1636444722\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1114884\n",
      "  training_iteration: 558\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   558</td><td style=\"text-align: right;\">         15193.2</td><td style=\"text-align: right;\">1114884</td><td style=\"text-align: right;\">  8.9688</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                0.94</td><td style=\"text-align: right;\">             97.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1116882\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-59-10\n",
      "  done: false\n",
      "  episode_len_mean: 97.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.871700000000018\n",
      "  episode_reward_min: 4.050000000000024\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10891\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1131942110402244\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010279166425215265\n",
      "          policy_loss: -0.030730456415386426\n",
      "          total_loss: 0.13238212543406658\n",
      "          vf_explained_var: 0.9797065258026123\n",
      "          vf_loss: 0.16683516514798005\n",
      "    num_agent_steps_sampled: 1116882\n",
      "    num_agent_steps_trained: 1116882\n",
      "    num_steps_sampled: 1116882\n",
      "    num_steps_trained: 1116882\n",
      "  iterations_since_restore: 559\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.45384615384614\n",
      "    ram_util_percent: 31.325641025641033\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435128599510827\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.027991687219647\n",
      "    mean_inference_ms: 2.4694667322152704\n",
      "    mean_raw_obs_processing_ms: 2.0511694429091554\n",
      "  time_since_restore: 15220.590687274933\n",
      "  time_this_iter_s: 27.40360426902771\n",
      "  time_total_s: 15220.590687274933\n",
      "  timers:\n",
      "    learn_throughput: 1165.264\n",
      "    learn_time_ms: 1714.633\n",
      "    load_throughput: 47789.75\n",
      "    load_time_ms: 41.808\n",
      "    sample_throughput: 73.987\n",
      "    sample_time_ms: 27004.797\n",
      "    update_time_ms: 8.753\n",
      "  timestamp: 1636444750\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1116882\n",
      "  training_iteration: 559\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   559</td><td style=\"text-align: right;\">         15220.6</td><td style=\"text-align: right;\">1116882</td><td style=\"text-align: right;\">  8.8717</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                4.05</td><td style=\"text-align: right;\">             97.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1118880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_07-59-36\n",
      "  done: false\n",
      "  episode_len_mean: 97.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.759100000000018\n",
      "  episode_reward_min: 4.050000000000024\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10912\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1931125638030824\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015472837846016099\n",
      "          policy_loss: -0.030756391762267975\n",
      "          total_loss: 0.08763373821885104\n",
      "          vf_explained_var: 0.9757179021835327\n",
      "          vf_loss: 0.11916823356988884\n",
      "    num_agent_steps_sampled: 1118880\n",
      "    num_agent_steps_trained: 1118880\n",
      "    num_steps_sampled: 1118880\n",
      "    num_steps_trained: 1118880\n",
      "  iterations_since_restore: 560\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96756756756757\n",
      "    ram_util_percent: 31.278378378378385\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433878010354133\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.029854476668042\n",
      "    mean_inference_ms: 2.4692848325348176\n",
      "    mean_raw_obs_processing_ms: 2.0486031250514767\n",
      "  time_since_restore: 15246.5782828331\n",
      "  time_this_iter_s: 25.987595558166504\n",
      "  time_total_s: 15246.5782828331\n",
      "  timers:\n",
      "    learn_throughput: 1164.237\n",
      "    learn_time_ms: 1716.146\n",
      "    load_throughput: 59602.547\n",
      "    load_time_ms: 33.522\n",
      "    sample_throughput: 77.762\n",
      "    sample_time_ms: 25693.929\n",
      "    update_time_ms: 9.519\n",
      "  timestamp: 1636444776\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1118880\n",
      "  training_iteration: 560\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   560</td><td style=\"text-align: right;\">         15246.6</td><td style=\"text-align: right;\">1118880</td><td style=\"text-align: right;\">  8.7591</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                4.05</td><td style=\"text-align: right;\">             97.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1120878\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-00-02\n",
      "  done: false\n",
      "  episode_len_mean: 97.18\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.765600000000017\n",
      "  episode_reward_min: 3.78000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10933\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1499791378066653\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011037428155291917\n",
      "          policy_loss: -0.03533576175215698\n",
      "          total_loss: 0.10954555885954982\n",
      "          vf_explained_var: 0.9786244630813599\n",
      "          vf_loss: 0.1484251920311224\n",
      "    num_agent_steps_sampled: 1120878\n",
      "    num_agent_steps_trained: 1120878\n",
      "    num_steps_sampled: 1120878\n",
      "    num_steps_trained: 1120878\n",
      "  iterations_since_restore: 561\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16052631578948\n",
      "    ram_util_percent: 31.236842105263158\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443532653035415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.03089000021072\n",
      "    mean_inference_ms: 2.469502650467108\n",
      "    mean_raw_obs_processing_ms: 2.0461708414188946\n",
      "  time_since_restore: 15273.142410516739\n",
      "  time_this_iter_s: 26.564127683639526\n",
      "  time_total_s: 15273.142410516739\n",
      "  timers:\n",
      "    learn_throughput: 1163.758\n",
      "    learn_time_ms: 1716.851\n",
      "    load_throughput: 59743.235\n",
      "    load_time_ms: 33.443\n",
      "    sample_throughput: 82.672\n",
      "    sample_time_ms: 24167.656\n",
      "    update_time_ms: 9.285\n",
      "  timestamp: 1636444802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1120878\n",
      "  training_iteration: 561\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   561</td><td style=\"text-align: right;\">         15273.1</td><td style=\"text-align: right;\">1120878</td><td style=\"text-align: right;\">  8.7656</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                3.78</td><td style=\"text-align: right;\">             97.18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1122876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-00-28\n",
      "  done: false\n",
      "  episode_len_mean: 96.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.841800000000013\n",
      "  episode_reward_min: 3.78000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10953\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2265807390213013\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014158091322215911\n",
      "          policy_loss: -0.005763029094253268\n",
      "          total_loss: 0.15307200676983312\n",
      "          vf_explained_var: 0.9755216836929321\n",
      "          vf_loss: 0.16089550535238925\n",
      "    num_agent_steps_sampled: 1122876\n",
      "    num_agent_steps_trained: 1122876\n",
      "    num_steps_sampled: 1122876\n",
      "    num_steps_trained: 1122876\n",
      "  iterations_since_restore: 562\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.35945945945944\n",
      "    ram_util_percent: 31.22432432432432\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044322109071547856\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.03518255312888\n",
      "    mean_inference_ms: 2.4689839166146688\n",
      "    mean_raw_obs_processing_ms: 2.0438020061300257\n",
      "  time_since_restore: 15299.096145391464\n",
      "  time_this_iter_s: 25.953734874725342\n",
      "  time_total_s: 15299.096145391464\n",
      "  timers:\n",
      "    learn_throughput: 1164.421\n",
      "    learn_time_ms: 1715.874\n",
      "    load_throughput: 59428.195\n",
      "    load_time_ms: 33.62\n",
      "    sample_throughput: 82.046\n",
      "    sample_time_ms: 24352.059\n",
      "    update_time_ms: 9.341\n",
      "  timestamp: 1636444828\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1122876\n",
      "  training_iteration: 562\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   562</td><td style=\"text-align: right;\">         15299.1</td><td style=\"text-align: right;\">1122876</td><td style=\"text-align: right;\">  8.8418</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                3.78</td><td style=\"text-align: right;\">             96.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1124874\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-00-54\n",
      "  done: false\n",
      "  episode_len_mean: 96.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.797000000000017\n",
      "  episode_reward_min: 3.78000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 10973\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.222155671460288\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010934656796231698\n",
      "          policy_loss: -0.07321024911389465\n",
      "          total_loss: 0.02400197529544433\n",
      "          vf_explained_var: 0.9781283140182495\n",
      "          vf_loss: 0.10155193798598788\n",
      "    num_agent_steps_sampled: 1124874\n",
      "    num_agent_steps_trained: 1124874\n",
      "    num_steps_sampled: 1124874\n",
      "    num_steps_trained: 1124874\n",
      "  iterations_since_restore: 563\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.20270270270271\n",
      "    ram_util_percent: 31.186486486486483\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434363098401179\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.03773664904586\n",
      "    mean_inference_ms: 2.4693094715257367\n",
      "    mean_raw_obs_processing_ms: 2.041648377603815\n",
      "  time_since_restore: 15324.817991495132\n",
      "  time_this_iter_s: 25.721846103668213\n",
      "  time_total_s: 15324.817991495132\n",
      "  timers:\n",
      "    learn_throughput: 1165.303\n",
      "    learn_time_ms: 1714.575\n",
      "    load_throughput: 59545.162\n",
      "    load_time_ms: 33.554\n",
      "    sample_throughput: 81.935\n",
      "    sample_time_ms: 24385.274\n",
      "    update_time_ms: 9.596\n",
      "  timestamp: 1636444854\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1124874\n",
      "  training_iteration: 563\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   563</td><td style=\"text-align: right;\">         15324.8</td><td style=\"text-align: right;\">1124874</td><td style=\"text-align: right;\">   8.797</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                3.78</td><td style=\"text-align: right;\">              96.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1126872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-01-19\n",
      "  done: false\n",
      "  episode_len_mean: 98.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.471900000000016\n",
      "  episode_reward_min: 3.78000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 10994\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2328336959793453\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014763346441153211\n",
      "          policy_loss: -0.09882621985106241\n",
      "          total_loss: 0.0915580518721115\n",
      "          vf_explained_var: 0.9656042456626892\n",
      "          vf_loss: 0.1920709995641595\n",
      "    num_agent_steps_sampled: 1126872\n",
      "    num_agent_steps_trained: 1126872\n",
      "    num_steps_sampled: 1126872\n",
      "    num_steps_trained: 1126872\n",
      "  iterations_since_restore: 564\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.09166666666665\n",
      "    ram_util_percent: 31.21944444444444\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044332761634269365\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.03959798388416\n",
      "    mean_inference_ms: 2.469131284729301\n",
      "    mean_raw_obs_processing_ms: 2.039191708340394\n",
      "  time_since_restore: 15349.870284318924\n",
      "  time_this_iter_s: 25.052292823791504\n",
      "  time_total_s: 15349.870284318924\n",
      "  timers:\n",
      "    learn_throughput: 1164.964\n",
      "    learn_time_ms: 1715.075\n",
      "    load_throughput: 59474.758\n",
      "    load_time_ms: 33.594\n",
      "    sample_throughput: 82.221\n",
      "    sample_time_ms: 24300.384\n",
      "    update_time_ms: 9.692\n",
      "  timestamp: 1636444879\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1126872\n",
      "  training_iteration: 564\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   564</td><td style=\"text-align: right;\">         15349.9</td><td style=\"text-align: right;\">1126872</td><td style=\"text-align: right;\">  8.4719</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                3.78</td><td style=\"text-align: right;\">             98.47</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1128870\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-01-47\n",
      "  done: false\n",
      "  episode_len_mean: 96.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.906100000000016\n",
      "  episode_reward_min: 2.7700000000000187\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 11016\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2523648256347293\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009825697650125894\n",
      "          policy_loss: -0.00252850635775498\n",
      "          total_loss: 0.15776293693731228\n",
      "          vf_explained_var: 0.983879029750824\n",
      "          vf_loss: 0.16573260036252793\n",
      "    num_agent_steps_sampled: 1128870\n",
      "    num_agent_steps_trained: 1128870\n",
      "    num_steps_sampled: 1128870\n",
      "    num_steps_trained: 1128870\n",
      "  iterations_since_restore: 565\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16666666666667\n",
      "    ram_util_percent: 31.151282051282053\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431605192600998\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.04330330445212\n",
      "    mean_inference_ms: 2.468875809397801\n",
      "    mean_raw_obs_processing_ms: 2.036690925946851\n",
      "  time_since_restore: 15377.351095199585\n",
      "  time_this_iter_s: 27.48081088066101\n",
      "  time_total_s: 15377.351095199585\n",
      "  timers:\n",
      "    learn_throughput: 1165.332\n",
      "    learn_time_ms: 1714.532\n",
      "    load_throughput: 59794.09\n",
      "    load_time_ms: 33.415\n",
      "    sample_throughput: 81.695\n",
      "    sample_time_ms: 24456.718\n",
      "    update_time_ms: 10.115\n",
      "  timestamp: 1636444907\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1128870\n",
      "  training_iteration: 565\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   565</td><td style=\"text-align: right;\">         15377.4</td><td style=\"text-align: right;\">1128870</td><td style=\"text-align: right;\">  8.9061</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                2.77</td><td style=\"text-align: right;\">             96.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1130868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-02-28\n",
      "  done: false\n",
      "  episode_len_mean: 98.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.545200000000017\n",
      "  episode_reward_min: 2.7700000000000187\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11035\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1971680101894198\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01189799337686547\n",
      "          policy_loss: -0.017777546131539913\n",
      "          total_loss: 0.18137832581109944\n",
      "          vf_explained_var: 0.9593068361282349\n",
      "          vf_loss: 0.20255132225297745\n",
      "    num_agent_steps_sampled: 1130868\n",
      "    num_agent_steps_trained: 1130868\n",
      "    num_steps_sampled: 1130868\n",
      "    num_steps_trained: 1130868\n",
      "  iterations_since_restore: 566\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.81864406779661\n",
      "    ram_util_percent: 31.15084745762712\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432581829239025\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.044577363543993\n",
      "    mean_inference_ms: 2.4690218318082127\n",
      "    mean_raw_obs_processing_ms: 2.0375991250292365\n",
      "  time_since_restore: 15418.362271308899\n",
      "  time_this_iter_s: 41.011176109313965\n",
      "  time_total_s: 15418.362271308899\n",
      "  timers:\n",
      "    learn_throughput: 1164.313\n",
      "    learn_time_ms: 1716.033\n",
      "    load_throughput: 59532.557\n",
      "    load_time_ms: 33.561\n",
      "    sample_throughput: 77.045\n",
      "    sample_time_ms: 25932.926\n",
      "    update_time_ms: 10.176\n",
      "  timestamp: 1636444948\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1130868\n",
      "  training_iteration: 566\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   566</td><td style=\"text-align: right;\">         15418.4</td><td style=\"text-align: right;\">1130868</td><td style=\"text-align: right;\">  8.5452</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                2.77</td><td style=\"text-align: right;\">             98.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1132866\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-02-54\n",
      "  done: false\n",
      "  episode_len_mean: 97.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000016\n",
      "  episode_reward_mean: 8.819800000000019\n",
      "  episode_reward_min: 2.7700000000000187\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11055\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2405942184584482\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011041575172661905\n",
      "          policy_loss: -0.027570117264986038\n",
      "          total_loss: 0.14383365948285376\n",
      "          vf_explained_var: 0.9799565672874451\n",
      "          vf_loss: 0.1758508094009899\n",
      "    num_agent_steps_sampled: 1132866\n",
      "    num_agent_steps_trained: 1132866\n",
      "    num_steps_sampled: 1132866\n",
      "    num_steps_trained: 1132866\n",
      "  iterations_since_restore: 567\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.21351351351352\n",
      "    ram_util_percent: 31.113513513513514\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432987463174459\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.045159362865444\n",
      "    mean_inference_ms: 2.4690736604094714\n",
      "    mean_raw_obs_processing_ms: 2.037850654730881\n",
      "  time_since_restore: 15444.737862348557\n",
      "  time_this_iter_s: 26.375591039657593\n",
      "  time_total_s: 15444.737862348557\n",
      "  timers:\n",
      "    learn_throughput: 1162.713\n",
      "    learn_time_ms: 1718.395\n",
      "    load_throughput: 59037.582\n",
      "    load_time_ms: 33.843\n",
      "    sample_throughput: 77.124\n",
      "    sample_time_ms: 25906.304\n",
      "    update_time_ms: 9.777\n",
      "  timestamp: 1636444974\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1132866\n",
      "  training_iteration: 567\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   567</td><td style=\"text-align: right;\">         15444.7</td><td style=\"text-align: right;\">1132866</td><td style=\"text-align: right;\">  8.8198</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">                2.77</td><td style=\"text-align: right;\">             97.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1134864\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-03-36\n",
      "  done: false\n",
      "  episode_len_mean: 97.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000016\n",
      "  episode_reward_mean: 8.680800000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11076\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.310881505126045\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008719307028719916\n",
      "          policy_loss: -0.03013240768618527\n",
      "          total_loss: 0.10589551071503332\n",
      "          vf_explained_var: 0.9841346144676208\n",
      "          vf_loss: 0.14285174377617382\n",
      "    num_agent_steps_sampled: 1134864\n",
      "    num_agent_steps_trained: 1134864\n",
      "    num_steps_sampled: 1134864\n",
      "    num_steps_trained: 1134864\n",
      "  iterations_since_restore: 568\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.56393442622951\n",
      "    ram_util_percent: 30.916393442622947\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431769647014059\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.046656118293285\n",
      "    mean_inference_ms: 2.4688318319392386\n",
      "    mean_raw_obs_processing_ms: 2.0446007123846246\n",
      "  time_since_restore: 15486.99523115158\n",
      "  time_this_iter_s: 42.25736880302429\n",
      "  time_total_s: 15486.99523115158\n",
      "  timers:\n",
      "    learn_throughput: 1160.807\n",
      "    learn_time_ms: 1721.216\n",
      "    load_throughput: 58885.046\n",
      "    load_time_ms: 33.931\n",
      "    sample_throughput: 72.374\n",
      "    sample_time_ms: 27606.68\n",
      "    update_time_ms: 9.649\n",
      "  timestamp: 1636445016\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1134864\n",
      "  training_iteration: 568\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   568</td><td style=\"text-align: right;\">           15487</td><td style=\"text-align: right;\">1134864</td><td style=\"text-align: right;\">  8.6808</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             97.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1136862\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-04-01\n",
      "  done: false\n",
      "  episode_len_mean: 96.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000016\n",
      "  episode_reward_mean: 8.732000000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11097\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.254251408860797\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01306861441258231\n",
      "          policy_loss: -0.0015804200388845942\n",
      "          total_loss: 0.24759219275077893\n",
      "          vf_explained_var: 0.9591472744941711\n",
      "          vf_loss: 0.2522950999083973\n",
      "    num_agent_steps_sampled: 1136862\n",
      "    num_agent_steps_trained: 1136862\n",
      "    num_steps_sampled: 1136862\n",
      "    num_steps_trained: 1136862\n",
      "  iterations_since_restore: 569\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.63428571428571\n",
      "    ram_util_percent: 31.031428571428574\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044316990308434966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.048456173431234\n",
      "    mean_inference_ms: 2.4687721082656533\n",
      "    mean_raw_obs_processing_ms: 2.0514158157646802\n",
      "  time_since_restore: 15511.818553447723\n",
      "  time_this_iter_s: 24.823322296142578\n",
      "  time_total_s: 15511.818553447723\n",
      "  timers:\n",
      "    learn_throughput: 1159.609\n",
      "    learn_time_ms: 1722.995\n",
      "    load_throughput: 58965.26\n",
      "    load_time_ms: 33.884\n",
      "    sample_throughput: 73.062\n",
      "    sample_time_ms: 27346.487\n",
      "    update_time_ms: 9.776\n",
      "  timestamp: 1636445041\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1136862\n",
      "  training_iteration: 569\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   569</td><td style=\"text-align: right;\">         15511.8</td><td style=\"text-align: right;\">1136862</td><td style=\"text-align: right;\">   8.732</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             96.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1138860\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-04-26\n",
      "  done: false\n",
      "  episode_len_mean: 98.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000016\n",
      "  episode_reward_mean: 8.502300000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11117\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2945103878066653\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012386565313414807\n",
      "          policy_loss: -0.008064204543119385\n",
      "          total_loss: 0.10562647238728545\n",
      "          vf_explained_var: 0.9750449657440186\n",
      "          vf_loss: 0.11770738457285222\n",
      "    num_agent_steps_sampled: 1138860\n",
      "    num_agent_steps_trained: 1138860\n",
      "    num_steps_sampled: 1138860\n",
      "    num_steps_trained: 1138860\n",
      "  iterations_since_restore: 570\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5942857142857\n",
      "    ram_util_percent: 31.174285714285713\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434672145860999\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.047146929488918\n",
      "    mean_inference_ms: 2.469205507994595\n",
      "    mean_raw_obs_processing_ms: 2.0579045644464755\n",
      "  time_since_restore: 15536.336372375488\n",
      "  time_this_iter_s: 24.517818927764893\n",
      "  time_total_s: 15536.336372375488\n",
      "  timers:\n",
      "    learn_throughput: 1161.204\n",
      "    learn_time_ms: 1720.628\n",
      "    load_throughput: 59066.543\n",
      "    load_time_ms: 33.826\n",
      "    sample_throughput: 73.449\n",
      "    sample_time_ms: 27202.64\n",
      "    update_time_ms: 9.186\n",
      "  timestamp: 1636445066\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1138860\n",
      "  training_iteration: 570\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   570</td><td style=\"text-align: right;\">         15536.3</td><td style=\"text-align: right;\">1138860</td><td style=\"text-align: right;\">  8.5023</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             98.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1140858\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-04-53\n",
      "  done: false\n",
      "  episode_len_mean: 96.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000016\n",
      "  episode_reward_mean: 8.719600000000016\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11138\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2265705437887282\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016651337487026737\n",
      "          policy_loss: -0.02309680956282786\n",
      "          total_loss: 0.2290974009161194\n",
      "          vf_explained_var: 0.9727886915206909\n",
      "          vf_loss: 0.25245741369823615\n",
      "    num_agent_steps_sampled: 1140858\n",
      "    num_agent_steps_trained: 1140858\n",
      "    num_steps_sampled: 1140858\n",
      "    num_steps_trained: 1140858\n",
      "  iterations_since_restore: 571\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04615384615386\n",
      "    ram_util_percent: 31.32051282051282\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044333435586245855\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.049304773778694\n",
      "    mean_inference_ms: 2.469005365451707\n",
      "    mean_raw_obs_processing_ms: 2.0616197479159353\n",
      "  time_since_restore: 15563.332013368607\n",
      "  time_this_iter_s: 26.995640993118286\n",
      "  time_total_s: 15563.332013368607\n",
      "  timers:\n",
      "    learn_throughput: 1161.657\n",
      "    learn_time_ms: 1719.957\n",
      "    load_throughput: 58806.906\n",
      "    load_time_ms: 33.976\n",
      "    sample_throughput: 73.33\n",
      "    sample_time_ms: 27246.725\n",
      "    update_time_ms: 8.918\n",
      "  timestamp: 1636445093\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1140858\n",
      "  training_iteration: 571\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   571</td><td style=\"text-align: right;\">         15563.3</td><td style=\"text-align: right;\">1140858</td><td style=\"text-align: right;\">  8.7196</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             96.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1142856\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-05-19\n",
      "  done: false\n",
      "  episode_len_mean: 97.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000012\n",
      "  episode_reward_mean: 8.467300000000016\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11159\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3022868082636878\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01704127863927241\n",
      "          policy_loss: -0.03846891557886487\n",
      "          total_loss: 0.2702337888202497\n",
      "          vf_explained_var: 0.9617610573768616\n",
      "          vf_loss: 0.3094419985654808\n",
      "    num_agent_steps_sampled: 1142856\n",
      "    num_agent_steps_trained: 1142856\n",
      "    num_steps_sampled: 1142856\n",
      "    num_steps_trained: 1142856\n",
      "  iterations_since_restore: 572\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.75263157894734\n",
      "    ram_util_percent: 31.400000000000002\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044316049749465215\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.052332969188456\n",
      "    mean_inference_ms: 2.4687395805841055\n",
      "    mean_raw_obs_processing_ms: 2.064060696242842\n",
      "  time_since_restore: 15589.939654827118\n",
      "  time_this_iter_s: 26.607641458511353\n",
      "  time_total_s: 15589.939654827118\n",
      "  timers:\n",
      "    learn_throughput: 1160.871\n",
      "    learn_time_ms: 1721.121\n",
      "    load_throughput: 59254.567\n",
      "    load_time_ms: 33.719\n",
      "    sample_throughput: 73.157\n",
      "    sample_time_ms: 27311.209\n",
      "    update_time_ms: 9.227\n",
      "  timestamp: 1636445119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1142856\n",
      "  training_iteration: 572\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   572</td><td style=\"text-align: right;\">         15589.9</td><td style=\"text-align: right;\">1142856</td><td style=\"text-align: right;\">  8.4673</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             97.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1144854\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-05-44\n",
      "  done: false\n",
      "  episode_len_mean: 98.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000012\n",
      "  episode_reward_mean: 8.635900000000017\n",
      "  episode_reward_min: 1.320000000000007\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11178\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2155894313539777\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012812745842806738\n",
      "          policy_loss: -0.06593584624074754\n",
      "          total_loss: 0.12476973460898513\n",
      "          vf_explained_var: 0.9695593118667603\n",
      "          vf_loss: 0.19362588363389174\n",
      "    num_agent_steps_sampled: 1144854\n",
      "    num_agent_steps_trained: 1144854\n",
      "    num_steps_sampled: 1144854\n",
      "    num_steps_trained: 1144854\n",
      "  iterations_since_restore: 573\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.26\n",
      "    ram_util_percent: 31.42571428571429\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432561436565909\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.053976494150838\n",
      "    mean_inference_ms: 2.468911334693661\n",
      "    mean_raw_obs_processing_ms: 2.06194284531138\n",
      "  time_since_restore: 15614.452857255936\n",
      "  time_this_iter_s: 24.51320242881775\n",
      "  time_total_s: 15614.452857255936\n",
      "  timers:\n",
      "    learn_throughput: 1161.517\n",
      "    learn_time_ms: 1720.164\n",
      "    load_throughput: 58871.85\n",
      "    load_time_ms: 33.938\n",
      "    sample_throughput: 73.48\n",
      "    sample_time_ms: 27191.067\n",
      "    update_time_ms: 9.116\n",
      "  timestamp: 1636445144\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1144854\n",
      "  training_iteration: 573\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   573</td><td style=\"text-align: right;\">         15614.5</td><td style=\"text-align: right;\">1144854</td><td style=\"text-align: right;\">  8.6359</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                1.32</td><td style=\"text-align: right;\">             98.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1146852\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-06-11\n",
      "  done: false\n",
      "  episode_len_mean: 97.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000012\n",
      "  episode_reward_mean: 8.775400000000017\n",
      "  episode_reward_min: 1.320000000000007\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 11200\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.212841012364342\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0104673565345143\n",
      "          policy_loss: -0.033277778558078265\n",
      "          total_loss: 0.07193362006828899\n",
      "          vf_explained_var: 0.9802035093307495\n",
      "          vf_loss: 0.10979480283955732\n",
      "    num_agent_steps_sampled: 1146852\n",
      "    num_agent_steps_trained: 1146852\n",
      "    num_steps_sampled: 1146852\n",
      "    num_steps_trained: 1146852\n",
      "  iterations_since_restore: 574\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.36315789473683\n",
      "    ram_util_percent: 31.41578947368421\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044324870431748646\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.056527342989728\n",
      "    mean_inference_ms: 2.468909821089925\n",
      "    mean_raw_obs_processing_ms: 2.0594208130566107\n",
      "  time_since_restore: 15641.285563230515\n",
      "  time_this_iter_s: 26.832705974578857\n",
      "  time_total_s: 15641.285563230515\n",
      "  timers:\n",
      "    learn_throughput: 1161.709\n",
      "    learn_time_ms: 1719.879\n",
      "    load_throughput: 59067.584\n",
      "    load_time_ms: 33.826\n",
      "    sample_throughput: 73.003\n",
      "    sample_time_ms: 27368.925\n",
      "    update_time_ms: 9.624\n",
      "  timestamp: 1636445171\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1146852\n",
      "  training_iteration: 574\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   574</td><td style=\"text-align: right;\">         15641.3</td><td style=\"text-align: right;\">1146852</td><td style=\"text-align: right;\">  8.7754</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                1.32</td><td style=\"text-align: right;\">             97.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1148850\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-06-37\n",
      "  done: false\n",
      "  episode_len_mean: 96.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 8.849800000000016\n",
      "  episode_reward_min: 2.630000000000019\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11220\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.256214916138422\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010511875537661109\n",
      "          policy_loss: -0.018334892250242686\n",
      "          total_loss: 0.11242261616779226\n",
      "          vf_explained_var: 0.9820168614387512\n",
      "          vf_loss: 0.1357425640381518\n",
      "    num_agent_steps_sampled: 1148850\n",
      "    num_agent_steps_trained: 1148850\n",
      "    num_steps_sampled: 1148850\n",
      "    num_steps_trained: 1148850\n",
      "  iterations_since_restore: 575\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14864864864866\n",
      "    ram_util_percent: 31.48918918918918\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044325018375217295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.059179592597747\n",
      "    mean_inference_ms: 2.4688935513978048\n",
      "    mean_raw_obs_processing_ms: 2.0571438369201607\n",
      "  time_since_restore: 15667.051391839981\n",
      "  time_this_iter_s: 25.765828609466553\n",
      "  time_total_s: 15667.051391839981\n",
      "  timers:\n",
      "    learn_throughput: 1161.655\n",
      "    learn_time_ms: 1719.959\n",
      "    load_throughput: 58911.332\n",
      "    load_time_ms: 33.915\n",
      "    sample_throughput: 73.462\n",
      "    sample_time_ms: 27197.587\n",
      "    update_time_ms: 9.155\n",
      "  timestamp: 1636445197\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1148850\n",
      "  training_iteration: 575\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   575</td><td style=\"text-align: right;\">         15667.1</td><td style=\"text-align: right;\">1148850</td><td style=\"text-align: right;\">  8.8498</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                2.63</td><td style=\"text-align: right;\">             96.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1150848\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-07-00\n",
      "  done: false\n",
      "  episode_len_mean: 99.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 8.530600000000018\n",
      "  episode_reward_min: 1.9900000000000195\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 11238\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2499564687410991\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014086590911982192\n",
      "          policy_loss: -0.019357238053565935\n",
      "          total_loss: 0.19145376303543646\n",
      "          vf_explained_var: 0.9575318694114685\n",
      "          vf_loss: 0.21315676765072913\n",
      "    num_agent_steps_sampled: 1150848\n",
      "    num_agent_steps_trained: 1150848\n",
      "    num_steps_sampled: 1150848\n",
      "    num_steps_trained: 1150848\n",
      "  iterations_since_restore: 576\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.29090909090908\n",
      "    ram_util_percent: 31.47575757575757\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434112682634806\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.058945673831587\n",
      "    mean_inference_ms: 2.4691338708168113\n",
      "    mean_raw_obs_processing_ms: 2.0550645991068404\n",
      "  time_since_restore: 15690.131027460098\n",
      "  time_this_iter_s: 23.079635620117188\n",
      "  time_total_s: 15690.131027460098\n",
      "  timers:\n",
      "    learn_throughput: 1163.23\n",
      "    learn_time_ms: 1717.631\n",
      "    load_throughput: 58887.197\n",
      "    load_time_ms: 33.929\n",
      "    sample_throughput: 78.639\n",
      "    sample_time_ms: 25407.134\n",
      "    update_time_ms: 8.803\n",
      "  timestamp: 1636445220\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1150848\n",
      "  training_iteration: 576\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   576</td><td style=\"text-align: right;\">         15690.1</td><td style=\"text-align: right;\">1150848</td><td style=\"text-align: right;\">  8.5306</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                1.99</td><td style=\"text-align: right;\">             99.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1152846\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-07-25\n",
      "  done: false\n",
      "  episode_len_mean: 99.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 8.591000000000017\n",
      "  episode_reward_min: 1.3300000000000016\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11258\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2479133872758774\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010587978012012004\n",
      "          policy_loss: -0.030192634237131904\n",
      "          total_loss: 0.08132267039091814\n",
      "          vf_explained_var: 0.9767553210258484\n",
      "          vf_loss: 0.11636248481947752\n",
      "    num_agent_steps_sampled: 1152846\n",
      "    num_agent_steps_trained: 1152846\n",
      "    num_steps_sampled: 1152846\n",
      "    num_steps_trained: 1152846\n",
      "  iterations_since_restore: 577\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.30810810810812\n",
      "    ram_util_percent: 31.41891891891892\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044336582961207086\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.060133085256954\n",
      "    mean_inference_ms: 2.469040117897773\n",
      "    mean_raw_obs_processing_ms: 2.05273808721517\n",
      "  time_since_restore: 15715.700590610504\n",
      "  time_this_iter_s: 25.569563150405884\n",
      "  time_total_s: 15715.700590610504\n",
      "  timers:\n",
      "    learn_throughput: 1163.868\n",
      "    learn_time_ms: 1716.69\n",
      "    load_throughput: 59124.177\n",
      "    load_time_ms: 33.793\n",
      "    sample_throughput: 78.886\n",
      "    sample_time_ms: 25327.769\n",
      "    update_time_ms: 8.486\n",
      "  timestamp: 1636445245\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1152846\n",
      "  training_iteration: 577\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   577</td><td style=\"text-align: right;\">         15715.7</td><td style=\"text-align: right;\">1152846</td><td style=\"text-align: right;\">   8.591</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                1.33</td><td style=\"text-align: right;\">              99.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1154844\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-07-52\n",
      "  done: false\n",
      "  episode_len_mean: 99.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000013\n",
      "  episode_reward_mean: 8.664300000000019\n",
      "  episode_reward_min: 1.3300000000000016\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11279\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.229554318530219\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016557797403242053\n",
      "          policy_loss: -0.006706793322449639\n",
      "          total_loss: 0.17160867037517682\n",
      "          vf_explained_var: 0.9756263494491577\n",
      "          vf_loss: 0.17867593006009147\n",
      "    num_agent_steps_sampled: 1154844\n",
      "    num_agent_steps_trained: 1154844\n",
      "    num_steps_sampled: 1154844\n",
      "    num_steps_trained: 1154844\n",
      "  iterations_since_restore: 578\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.12105263157893\n",
      "    ram_util_percent: 31.378947368421056\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433198366267517\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.05986445544479\n",
      "    mean_inference_ms: 2.4689199065119296\n",
      "    mean_raw_obs_processing_ms: 2.05016936942069\n",
      "  time_since_restore: 15742.677055597305\n",
      "  time_this_iter_s: 26.976464986801147\n",
      "  time_total_s: 15742.677055597305\n",
      "  timers:\n",
      "    learn_throughput: 1164.782\n",
      "    learn_time_ms: 1715.343\n",
      "    load_throughput: 59277.284\n",
      "    load_time_ms: 33.706\n",
      "    sample_throughput: 83.944\n",
      "    sample_time_ms: 23801.671\n",
      "    update_time_ms: 8.07\n",
      "  timestamp: 1636445272\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1154844\n",
      "  training_iteration: 578\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   578</td><td style=\"text-align: right;\">         15742.7</td><td style=\"text-align: right;\">1154844</td><td style=\"text-align: right;\">  8.6643</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                1.33</td><td style=\"text-align: right;\">              99.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1156842\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-08-19\n",
      "  done: false\n",
      "  episode_len_mean: 99.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 8.841900000000017\n",
      "  episode_reward_min: 1.3300000000000016\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 11301\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1765087644259136\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010686575526623375\n",
      "          policy_loss: -0.05879766469200452\n",
      "          total_loss: 0.08633443895017817\n",
      "          vf_explained_var: 0.9779351353645325\n",
      "          vf_loss: 0.14919416939928418\n",
      "    num_agent_steps_sampled: 1156842\n",
      "    num_agent_steps_trained: 1156842\n",
      "    num_steps_sampled: 1156842\n",
      "    num_steps_trained: 1156842\n",
      "  iterations_since_restore: 579\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.55526315789473\n",
      "    ram_util_percent: 31.326315789473686\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443183339652694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.061423508412936\n",
      "    mean_inference_ms: 2.468641728673468\n",
      "    mean_raw_obs_processing_ms: 2.0475907155074005\n",
      "  time_since_restore: 15769.156399011612\n",
      "  time_this_iter_s: 26.47934341430664\n",
      "  time_total_s: 15769.156399011612\n",
      "  timers:\n",
      "    learn_throughput: 1165.629\n",
      "    learn_time_ms: 1714.096\n",
      "    load_throughput: 59368.159\n",
      "    load_time_ms: 33.654\n",
      "    sample_throughput: 83.359\n",
      "    sample_time_ms: 23968.628\n",
      "    update_time_ms: 8.374\n",
      "  timestamp: 1636445299\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1156842\n",
      "  training_iteration: 579\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   579</td><td style=\"text-align: right;\">         15769.2</td><td style=\"text-align: right;\">1156842</td><td style=\"text-align: right;\">  8.8419</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">                1.33</td><td style=\"text-align: right;\">             99.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1158840\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-08-45\n",
      "  done: false\n",
      "  episode_len_mean: 100.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 8.636700000000017\n",
      "  episode_reward_min: 0.8600000000000059\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11320\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2081686417261759\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013227539862893321\n",
      "          policy_loss: -0.06354603643218676\n",
      "          total_loss: 0.15919230534207254\n",
      "          vf_explained_var: 0.973554253578186\n",
      "          vf_loss: 0.22528544637773718\n",
      "    num_agent_steps_sampled: 1158840\n",
      "    num_agent_steps_trained: 1158840\n",
      "    num_steps_sampled: 1158840\n",
      "    num_steps_trained: 1158840\n",
      "  iterations_since_restore: 580\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.74054054054054\n",
      "    ram_util_percent: 31.337837837837846\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431535737313728\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.062801932479882\n",
      "    mean_inference_ms: 2.468541553534342\n",
      "    mean_raw_obs_processing_ms: 2.0454331513616406\n",
      "  time_since_restore: 15795.203929662704\n",
      "  time_this_iter_s: 26.04753065109253\n",
      "  time_total_s: 15795.203929662704\n",
      "  timers:\n",
      "    learn_throughput: 1164.103\n",
      "    learn_time_ms: 1716.342\n",
      "    load_throughput: 59293.809\n",
      "    load_time_ms: 33.697\n",
      "    sample_throughput: 82.842\n",
      "    sample_time_ms: 24118.198\n",
      "    update_time_ms: 9.433\n",
      "  timestamp: 1636445325\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1158840\n",
      "  training_iteration: 580\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   580</td><td style=\"text-align: right;\">         15795.2</td><td style=\"text-align: right;\">1158840</td><td style=\"text-align: right;\">  8.6367</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">                0.86</td><td style=\"text-align: right;\">            100.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1160838\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-09-08\n",
      "  done: false\n",
      "  episode_len_mean: 100.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 8.667200000000015\n",
      "  episode_reward_min: 0.8600000000000059\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 11337\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2825754727636065\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01257599439837944\n",
      "          policy_loss: -0.03259665391274861\n",
      "          total_loss: 0.11966072961333252\n",
      "          vf_explained_var: 0.9658541679382324\n",
      "          vf_loss: 0.1560181984944003\n",
      "    num_agent_steps_sampled: 1160838\n",
      "    num_agent_steps_trained: 1160838\n",
      "    num_steps_sampled: 1160838\n",
      "    num_steps_trained: 1160838\n",
      "  iterations_since_restore: 581\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03939393939395\n",
      "    ram_util_percent: 31.321212121212124\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431204178759236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.06422609700188\n",
      "    mean_inference_ms: 2.468436859276814\n",
      "    mean_raw_obs_processing_ms: 2.043514724155969\n",
      "  time_since_restore: 15818.361712694168\n",
      "  time_this_iter_s: 23.157783031463623\n",
      "  time_total_s: 15818.361712694168\n",
      "  timers:\n",
      "    learn_throughput: 1163.233\n",
      "    learn_time_ms: 1717.627\n",
      "    load_throughput: 59441.853\n",
      "    load_time_ms: 33.613\n",
      "    sample_throughput: 84.189\n",
      "    sample_time_ms: 23732.424\n",
      "    update_time_ms: 10.039\n",
      "  timestamp: 1636445348\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1160838\n",
      "  training_iteration: 581\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   581</td><td style=\"text-align: right;\">         15818.4</td><td style=\"text-align: right;\">1160838</td><td style=\"text-align: right;\">  8.6672</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">                0.86</td><td style=\"text-align: right;\">            100.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1162836\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-09-34\n",
      "  done: false\n",
      "  episode_len_mean: 100.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 8.668400000000016\n",
      "  episode_reward_min: 0.8600000000000059\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11358\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2019055057139623\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013594934574723928\n",
      "          policy_loss: -0.0027881018462635222\n",
      "          total_loss: 0.36108723653347363\n",
      "          vf_explained_var: 0.9585960507392883\n",
      "          vf_loss: 0.36609498524949663\n",
      "    num_agent_steps_sampled: 1162836\n",
      "    num_agent_steps_trained: 1162836\n",
      "    num_steps_sampled: 1162836\n",
      "    num_steps_trained: 1162836\n",
      "  iterations_since_restore: 582\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.98108108108109\n",
      "    ram_util_percent: 31.289189189189198\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431866654413696\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.064072765307138\n",
      "    mean_inference_ms: 2.4684881291602125\n",
      "    mean_raw_obs_processing_ms: 2.0410480632287267\n",
      "  time_since_restore: 15844.097034454346\n",
      "  time_this_iter_s: 25.735321760177612\n",
      "  time_total_s: 15844.097034454346\n",
      "  timers:\n",
      "    learn_throughput: 1164.426\n",
      "    learn_time_ms: 1715.867\n",
      "    load_throughput: 59655.455\n",
      "    load_time_ms: 33.492\n",
      "    sample_throughput: 84.492\n",
      "    sample_time_ms: 23647.268\n",
      "    update_time_ms: 9.663\n",
      "  timestamp: 1636445374\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1162836\n",
      "  training_iteration: 582\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   582</td><td style=\"text-align: right;\">         15844.1</td><td style=\"text-align: right;\">1162836</td><td style=\"text-align: right;\">  8.6684</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">                0.86</td><td style=\"text-align: right;\">            100.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1164834\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-10-19\n",
      "  done: false\n",
      "  episode_len_mean: 99.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000012\n",
      "  episode_reward_mean: 8.511400000000018\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 11381\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2293853634879703\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011417585142053963\n",
      "          policy_loss: -0.11314159502230939\n",
      "          total_loss: 0.11457300783977623\n",
      "          vf_explained_var: 0.9689325094223022\n",
      "          vf_loss: 0.2317785130370231\n",
      "    num_agent_steps_sampled: 1164834\n",
      "    num_agent_steps_trained: 1164834\n",
      "    num_steps_sampled: 1164834\n",
      "    num_steps_trained: 1164834\n",
      "  iterations_since_restore: 583\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.87538461538462\n",
      "    ram_util_percent: 31.267692307692304\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431762839337689\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.066898985753223\n",
      "    mean_inference_ms: 2.468379108807128\n",
      "    mean_raw_obs_processing_ms: 2.042105077919234\n",
      "  time_since_restore: 15889.433761119843\n",
      "  time_this_iter_s: 45.336726665496826\n",
      "  time_total_s: 15889.433761119843\n",
      "  timers:\n",
      "    learn_throughput: 1163.731\n",
      "    learn_time_ms: 1716.892\n",
      "    load_throughput: 60297.59\n",
      "    load_time_ms: 33.136\n",
      "    sample_throughput: 77.655\n",
      "    sample_time_ms: 25729.315\n",
      "    update_time_ms: 9.13\n",
      "  timestamp: 1636445419\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1164834\n",
      "  training_iteration: 583\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   583</td><td style=\"text-align: right;\">         15889.4</td><td style=\"text-align: right;\">1164834</td><td style=\"text-align: right;\">  8.5114</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">             99.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1166832\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-10-46\n",
      "  done: false\n",
      "  episode_len_mean: 98.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000012\n",
      "  episode_reward_mean: 8.214400000000017\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11401\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2794532276335218\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01337932516832524\n",
      "          policy_loss: -0.07034727508823077\n",
      "          total_loss: 0.09614722098977793\n",
      "          vf_explained_var: 0.9695448875427246\n",
      "          vf_loss: 0.1696450375020504\n",
      "    num_agent_steps_sampled: 1166832\n",
      "    num_agent_steps_trained: 1166832\n",
      "    num_steps_sampled: 1166832\n",
      "    num_steps_trained: 1166832\n",
      "  iterations_since_restore: 584\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.36486486486487\n",
      "    ram_util_percent: 31.294594594594603\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04435010415885848\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.06658108711162\n",
      "    mean_inference_ms: 2.468849709243947\n",
      "    mean_raw_obs_processing_ms: 2.0426079561711257\n",
      "  time_since_restore: 15915.91559267044\n",
      "  time_this_iter_s: 26.481831550598145\n",
      "  time_total_s: 15915.91559267044\n",
      "  timers:\n",
      "    learn_throughput: 1162.73\n",
      "    learn_time_ms: 1718.37\n",
      "    load_throughput: 60150.655\n",
      "    load_time_ms: 33.217\n",
      "    sample_throughput: 77.764\n",
      "    sample_time_ms: 25693.102\n",
      "    update_time_ms: 9.041\n",
      "  timestamp: 1636445446\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1166832\n",
      "  training_iteration: 584\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   584</td><td style=\"text-align: right;\">         15915.9</td><td style=\"text-align: right;\">1166832</td><td style=\"text-align: right;\">  8.2144</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">             98.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1168830\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-11-23\n",
      "  done: false\n",
      "  episode_len_mean: 98.23\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000012\n",
      "  episode_reward_mean: 8.385100000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11421\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2547413684072948\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009436446555038398\n",
      "          policy_loss: -0.09305353920374598\n",
      "          total_loss: 0.04251474084421283\n",
      "          vf_explained_var: 0.9756455421447754\n",
      "          vf_loss: 0.14131377985080082\n",
      "    num_agent_steps_sampled: 1168830\n",
      "    num_agent_steps_trained: 1168830\n",
      "    num_steps_sampled: 1168830\n",
      "    num_steps_trained: 1168830\n",
      "  iterations_since_restore: 585\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.15849056603773\n",
      "    ram_util_percent: 31.320754716981124\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434019053510511\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.067351507552903\n",
      "    mean_inference_ms: 2.4686125273742805\n",
      "    mean_raw_obs_processing_ms: 2.046288257006954\n",
      "  time_since_restore: 15952.908410787582\n",
      "  time_this_iter_s: 36.992818117141724\n",
      "  time_total_s: 15952.908410787582\n",
      "  timers:\n",
      "    learn_throughput: 1163.025\n",
      "    learn_time_ms: 1717.934\n",
      "    load_throughput: 60326.89\n",
      "    load_time_ms: 33.12\n",
      "    sample_throughput: 74.507\n",
      "    sample_time_ms: 26816.326\n",
      "    update_time_ms: 9.354\n",
      "  timestamp: 1636445483\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1168830\n",
      "  training_iteration: 585\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   585</td><td style=\"text-align: right;\">         15952.9</td><td style=\"text-align: right;\">1168830</td><td style=\"text-align: right;\">  8.3851</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.23</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1170828\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-12-03\n",
      "  done: false\n",
      "  episode_len_mean: 94.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000012\n",
      "  episode_reward_mean: 8.584700000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11442\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.325715292635418\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009186123164908907\n",
      "          policy_loss: -0.08644554889982654\n",
      "          total_loss: 0.11345042998769454\n",
      "          vf_explained_var: 0.956781268119812\n",
      "          vf_loss: 0.20653165497240566\n",
      "    num_agent_steps_sampled: 1170828\n",
      "    num_agent_steps_trained: 1170828\n",
      "    num_steps_sampled: 1170828\n",
      "    num_steps_trained: 1170828\n",
      "  iterations_since_restore: 586\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.33275862068966\n",
      "    ram_util_percent: 31.07586206896552\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431489542604094\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.070262614615864\n",
      "    mean_inference_ms: 2.4681085499690196\n",
      "    mean_raw_obs_processing_ms: 2.052845448387014\n",
      "  time_since_restore: 15993.1936211586\n",
      "  time_this_iter_s: 40.285210371017456\n",
      "  time_total_s: 15993.1936211586\n",
      "  timers:\n",
      "    learn_throughput: 1161.687\n",
      "    learn_time_ms: 1719.913\n",
      "    load_throughput: 60401.155\n",
      "    load_time_ms: 33.079\n",
      "    sample_throughput: 70.02\n",
      "    sample_time_ms: 28534.68\n",
      "    update_time_ms: 9.417\n",
      "  timestamp: 1636445523\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1170828\n",
      "  training_iteration: 586\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   586</td><td style=\"text-align: right;\">         15993.2</td><td style=\"text-align: right;\">1170828</td><td style=\"text-align: right;\">  8.5847</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">              94.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1172826\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-12-31\n",
      "  done: false\n",
      "  episode_len_mean: 93.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.614000000000015\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 11464\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2356121233531407\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01564862659729151\n",
      "          policy_loss: -0.010710703457395237\n",
      "          total_loss: 0.22066519229362408\n",
      "          vf_explained_var: 0.9725030660629272\n",
      "          vf_loss: 0.2324522863186541\n",
      "    num_agent_steps_sampled: 1172826\n",
      "    num_agent_steps_trained: 1172826\n",
      "    num_steps_sampled: 1172826\n",
      "    num_steps_trained: 1172826\n",
      "  iterations_since_restore: 587\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.60769230769233\n",
      "    ram_util_percent: 31.16410256410256\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429949420331822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.07295660250291\n",
      "    mean_inference_ms: 2.4677797205532728\n",
      "    mean_raw_obs_processing_ms: 2.0598402916216525\n",
      "  time_since_restore: 16020.68828010559\n",
      "  time_this_iter_s: 27.494658946990967\n",
      "  time_total_s: 16020.68828010559\n",
      "  timers:\n",
      "    learn_throughput: 1162.362\n",
      "    learn_time_ms: 1718.913\n",
      "    load_throughput: 60268.449\n",
      "    load_time_ms: 33.152\n",
      "    sample_throughput: 69.548\n",
      "    sample_time_ms: 28728.22\n",
      "    update_time_ms: 9.318\n",
      "  timestamp: 1636445551\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1172826\n",
      "  training_iteration: 587\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   587</td><td style=\"text-align: right;\">         16020.7</td><td style=\"text-align: right;\">1172826</td><td style=\"text-align: right;\">   8.614</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             93.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1174824\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-12-54\n",
      "  done: false\n",
      "  episode_len_mean: 97.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000012\n",
      "  episode_reward_mean: 8.584600000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11483\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3416056735174997\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014049330448570783\n",
      "          policy_loss: -0.025090493669822102\n",
      "          total_loss: 0.2797824927383945\n",
      "          vf_explained_var: 0.9498615860939026\n",
      "          vf_loss: 0.30816210288377033\n",
      "    num_agent_steps_sampled: 1174824\n",
      "    num_agent_steps_trained: 1174824\n",
      "    num_steps_sampled: 1174824\n",
      "    num_steps_trained: 1174824\n",
      "  iterations_since_restore: 588\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85882352941178\n",
      "    ram_util_percent: 31.264705882352942\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044327065113108174\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.070268499265516\n",
      "    mean_inference_ms: 2.4682210574377503\n",
      "    mean_raw_obs_processing_ms: 2.0622765323184065\n",
      "  time_since_restore: 16044.085996866226\n",
      "  time_this_iter_s: 23.397716760635376\n",
      "  time_total_s: 16044.085996866226\n",
      "  timers:\n",
      "    learn_throughput: 1161.928\n",
      "    learn_time_ms: 1719.556\n",
      "    load_throughput: 60399.24\n",
      "    load_time_ms: 33.08\n",
      "    sample_throughput: 70.428\n",
      "    sample_time_ms: 28369.535\n",
      "    update_time_ms: 9.646\n",
      "  timestamp: 1636445574\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1174824\n",
      "  training_iteration: 588\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   588</td><td style=\"text-align: right;\">         16044.1</td><td style=\"text-align: right;\">1174824</td><td style=\"text-align: right;\">  8.5846</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1176822\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-13-20\n",
      "  done: false\n",
      "  episode_len_mean: 98.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000012\n",
      "  episode_reward_mean: 8.669300000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11502\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.25374234801247\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009870591461370653\n",
      "          policy_loss: 0.004632343316362018\n",
      "          total_loss: 0.1499114258126134\n",
      "          vf_explained_var: 0.9779947400093079\n",
      "          vf_loss: 0.1507016537444932\n",
      "    num_agent_steps_sampled: 1176822\n",
      "    num_agent_steps_trained: 1176822\n",
      "    num_steps_sampled: 1176822\n",
      "    num_steps_trained: 1176822\n",
      "  iterations_since_restore: 589\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.90810810810811\n",
      "    ram_util_percent: 31.32972972972974\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431925876841421\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.070475763323092\n",
      "    mean_inference_ms: 2.4680862164953696\n",
      "    mean_raw_obs_processing_ms: 2.0655677896524893\n",
      "  time_since_restore: 16070.131113052368\n",
      "  time_this_iter_s: 26.045116186141968\n",
      "  time_total_s: 16070.131113052368\n",
      "  timers:\n",
      "    learn_throughput: 1162.77\n",
      "    learn_time_ms: 1718.31\n",
      "    load_throughput: 60507.523\n",
      "    load_time_ms: 33.021\n",
      "    sample_throughput: 70.532\n",
      "    sample_time_ms: 28327.394\n",
      "    update_time_ms: 9.627\n",
      "  timestamp: 1636445600\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1176822\n",
      "  training_iteration: 589\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   589</td><td style=\"text-align: right;\">         16070.1</td><td style=\"text-align: right;\">1176822</td><td style=\"text-align: right;\">  8.6693</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1178820\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-13-46\n",
      "  done: false\n",
      "  episode_len_mean: 98.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000014\n",
      "  episode_reward_mean: 8.860500000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11523\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2458668277377174\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010775609476583464\n",
      "          policy_loss: 0.008329662999936512\n",
      "          total_loss: 0.1646213180252484\n",
      "          vf_explained_var: 0.983469545841217\n",
      "          vf_loss: 0.16098312382541952\n",
      "    num_agent_steps_sampled: 1178820\n",
      "    num_agent_steps_trained: 1178820\n",
      "    num_steps_sampled: 1178820\n",
      "    num_steps_trained: 1178820\n",
      "  iterations_since_restore: 590\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66756756756756\n",
      "    ram_util_percent: 31.310810810810818\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044316203923303515\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.071106852898957\n",
      "    mean_inference_ms: 2.4680702190724837\n",
      "    mean_raw_obs_processing_ms: 2.065312770738217\n",
      "  time_since_restore: 16096.420943260193\n",
      "  time_this_iter_s: 26.289830207824707\n",
      "  time_total_s: 16096.420943260193\n",
      "  timers:\n",
      "    learn_throughput: 1164.114\n",
      "    learn_time_ms: 1716.326\n",
      "    load_throughput: 60266.976\n",
      "    load_time_ms: 33.152\n",
      "    sample_throughput: 70.465\n",
      "    sample_time_ms: 28354.385\n",
      "    update_time_ms: 8.632\n",
      "  timestamp: 1636445626\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1178820\n",
      "  training_iteration: 590\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   590</td><td style=\"text-align: right;\">         16096.4</td><td style=\"text-align: right;\">1178820</td><td style=\"text-align: right;\">  8.8605</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">                98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1180818\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-14-11\n",
      "  done: false\n",
      "  episode_len_mean: 99.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000014\n",
      "  episode_reward_mean: 9.064700000000018\n",
      "  episode_reward_min: 3.940000000000019\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11543\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.283076254526774\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00783134667473679\n",
      "          policy_loss: -0.06132342472140278\n",
      "          total_loss: 0.037316318840852805\n",
      "          vf_explained_var: 0.9828341007232666\n",
      "          vf_loss: 0.10582556937422072\n",
      "    num_agent_steps_sampled: 1180818\n",
      "    num_agent_steps_trained: 1180818\n",
      "    num_steps_sampled: 1180818\n",
      "    num_steps_trained: 1180818\n",
      "  iterations_since_restore: 591\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.07777777777778\n",
      "    ram_util_percent: 31.338888888888896\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432850161674926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.069704254560616\n",
      "    mean_inference_ms: 2.4683097331324175\n",
      "    mean_raw_obs_processing_ms: 2.0630561537248426\n",
      "  time_since_restore: 16121.205400943756\n",
      "  time_this_iter_s: 24.784457683563232\n",
      "  time_total_s: 16121.205400943756\n",
      "  timers:\n",
      "    learn_throughput: 1165.622\n",
      "    learn_time_ms: 1714.106\n",
      "    load_throughput: 59780.867\n",
      "    load_time_ms: 33.422\n",
      "    sample_throughput: 70.059\n",
      "    sample_time_ms: 28519.014\n",
      "    update_time_ms: 8.569\n",
      "  timestamp: 1636445651\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1180818\n",
      "  training_iteration: 591\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   591</td><td style=\"text-align: right;\">         16121.2</td><td style=\"text-align: right;\">1180818</td><td style=\"text-align: right;\">  9.0647</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">                3.94</td><td style=\"text-align: right;\">             99.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1182816\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-14-37\n",
      "  done: false\n",
      "  episode_len_mean: 101.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.870000000000013\n",
      "  episode_reward_mean: 9.015500000000017\n",
      "  episode_reward_min: 3.8700000000000276\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11563\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2606658634685335\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017106901156946464\n",
      "          policy_loss: -0.047630026670438905\n",
      "          total_loss: 0.11598009958508469\n",
      "          vf_explained_var: 0.9793890714645386\n",
      "          vf_loss: 0.1638859088044791\n",
      "    num_agent_steps_sampled: 1182816\n",
      "    num_agent_steps_trained: 1182816\n",
      "    num_steps_sampled: 1182816\n",
      "    num_steps_trained: 1182816\n",
      "  iterations_since_restore: 592\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88611111111112\n",
      "    ram_util_percent: 31.41111111111111\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044339933805352096\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.067488979983388\n",
      "    mean_inference_ms: 2.4685360719160796\n",
      "    mean_raw_obs_processing_ms: 2.0607670383507215\n",
      "  time_since_restore: 16146.477508068085\n",
      "  time_this_iter_s: 25.272107124328613\n",
      "  time_total_s: 16146.477508068085\n",
      "  timers:\n",
      "    learn_throughput: 1165.488\n",
      "    learn_time_ms: 1714.303\n",
      "    load_throughput: 59802.41\n",
      "    load_time_ms: 33.41\n",
      "    sample_throughput: 70.174\n",
      "    sample_time_ms: 28472.281\n",
      "    update_time_ms: 8.817\n",
      "  timestamp: 1636445677\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1182816\n",
      "  training_iteration: 592\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   592</td><td style=\"text-align: right;\">         16146.5</td><td style=\"text-align: right;\">1182816</td><td style=\"text-align: right;\">  9.0155</td><td style=\"text-align: right;\">               14.87</td><td style=\"text-align: right;\">                3.87</td><td style=\"text-align: right;\">             101.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1184814\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-15-00\n",
      "  done: false\n",
      "  episode_len_mean: 101.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.870000000000013\n",
      "  episode_reward_mean: 8.98870000000002\n",
      "  episode_reward_min: 3.8700000000000276\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 11580\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.266347511893227\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006544807724119312\n",
      "          policy_loss: -0.11705489563090461\n",
      "          total_loss: -0.04243711508100941\n",
      "          vf_explained_var: 0.976871907711029\n",
      "          vf_loss: 0.08256367542559193\n",
      "    num_agent_steps_sampled: 1184814\n",
      "    num_agent_steps_trained: 1184814\n",
      "    num_steps_sampled: 1184814\n",
      "    num_steps_trained: 1184814\n",
      "  iterations_since_restore: 593\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99090909090908\n",
      "    ram_util_percent: 31.436363636363637\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044329700547472595\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.068289145793475\n",
      "    mean_inference_ms: 2.468363803419677\n",
      "    mean_raw_obs_processing_ms: 2.0589074960427256\n",
      "  time_since_restore: 16169.965628147125\n",
      "  time_this_iter_s: 23.488120079040527\n",
      "  time_total_s: 16169.965628147125\n",
      "  timers:\n",
      "    learn_throughput: 1160.31\n",
      "    learn_time_ms: 1721.954\n",
      "    load_throughput: 59459.777\n",
      "    load_time_ms: 33.603\n",
      "    sample_throughput: 76.029\n",
      "    sample_time_ms: 26279.339\n",
      "    update_time_ms: 9.26\n",
      "  timestamp: 1636445700\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1184814\n",
      "  training_iteration: 593\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   593</td><td style=\"text-align: right;\">           16170</td><td style=\"text-align: right;\">1184814</td><td style=\"text-align: right;\">  8.9887</td><td style=\"text-align: right;\">               14.87</td><td style=\"text-align: right;\">                3.87</td><td style=\"text-align: right;\">            101.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1186812\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-15-26\n",
      "  done: false\n",
      "  episode_len_mean: 101.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.870000000000013\n",
      "  episode_reward_mean: 8.868300000000017\n",
      "  episode_reward_min: 3.8700000000000276\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11601\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.236019470010485\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011052569961059805\n",
      "          policy_loss: -0.045649270145666034\n",
      "          total_loss: 0.05834439465155204\n",
      "          vf_explained_var: 0.9822437167167664\n",
      "          vf_loss: 0.10838702330809263\n",
      "    num_agent_steps_sampled: 1186812\n",
      "    num_agent_steps_trained: 1186812\n",
      "    num_steps_sampled: 1186812\n",
      "    num_steps_trained: 1186812\n",
      "  iterations_since_restore: 594\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92432432432433\n",
      "    ram_util_percent: 31.37027027027028\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04434747001582735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.06470861102288\n",
      "    mean_inference_ms: 2.4686663989826316\n",
      "    mean_raw_obs_processing_ms: 2.0563753010950325\n",
      "  time_since_restore: 16195.695588588715\n",
      "  time_this_iter_s: 25.729960441589355\n",
      "  time_total_s: 16195.695588588715\n",
      "  timers:\n",
      "    learn_throughput: 1162.78\n",
      "    learn_time_ms: 1718.296\n",
      "    load_throughput: 59403.804\n",
      "    load_time_ms: 33.634\n",
      "    sample_throughput: 76.237\n",
      "    sample_time_ms: 26207.796\n",
      "    update_time_ms: 8.865\n",
      "  timestamp: 1636445726\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1186812\n",
      "  training_iteration: 594\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   594</td><td style=\"text-align: right;\">         16195.7</td><td style=\"text-align: right;\">1186812</td><td style=\"text-align: right;\">  8.8683</td><td style=\"text-align: right;\">               14.87</td><td style=\"text-align: right;\">                3.87</td><td style=\"text-align: right;\">            101.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1188810\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-15-49\n",
      "  done: false\n",
      "  episode_len_mean: 103.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.870000000000013\n",
      "  episode_reward_mean: 8.523800000000017\n",
      "  episode_reward_min: 3.8700000000000276\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 11619\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.252519206773667\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0170087908002479\n",
      "          policy_loss: -0.02996995303602446\n",
      "          total_loss: 0.1671207610429043\n",
      "          vf_explained_var: 0.9636685252189636\n",
      "          vf_loss: 0.1973557464955818\n",
      "    num_agent_steps_sampled: 1188810\n",
      "    num_agent_steps_trained: 1188810\n",
      "    num_steps_sampled: 1188810\n",
      "    num_steps_trained: 1188810\n",
      "  iterations_since_restore: 595\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77575757575758\n",
      "    ram_util_percent: 31.33636363636364\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432642610495751\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.064620983783243\n",
      "    mean_inference_ms: 2.4683130248552927\n",
      "    mean_raw_obs_processing_ms: 2.0543276057008586\n",
      "  time_since_restore: 16218.473928689957\n",
      "  time_this_iter_s: 22.778340101242065\n",
      "  time_total_s: 16218.473928689957\n",
      "  timers:\n",
      "    learn_throughput: 1161.67\n",
      "    learn_time_ms: 1719.937\n",
      "    load_throughput: 59100.201\n",
      "    load_time_ms: 33.807\n",
      "    sample_throughput: 80.614\n",
      "    sample_time_ms: 24784.831\n",
      "    update_time_ms: 8.5\n",
      "  timestamp: 1636445749\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1188810\n",
      "  training_iteration: 595\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   595</td><td style=\"text-align: right;\">         16218.5</td><td style=\"text-align: right;\">1188810</td><td style=\"text-align: right;\">  8.5238</td><td style=\"text-align: right;\">               14.87</td><td style=\"text-align: right;\">                3.87</td><td style=\"text-align: right;\">            103.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1190808\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-16-14\n",
      "  done: false\n",
      "  episode_len_mean: 105.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.870000000000013\n",
      "  episode_reward_mean: 8.312900000000019\n",
      "  episode_reward_min: 3.8700000000000276\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11638\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2560804849579221\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012650307943018366\n",
      "          policy_loss: -0.06597449208299319\n",
      "          total_loss: 0.09537678439879702\n",
      "          vf_explained_var: 0.9651963114738464\n",
      "          vf_loss: 0.16479357509385972\n",
      "    num_agent_steps_sampled: 1190808\n",
      "    num_agent_steps_trained: 1190808\n",
      "    num_steps_sampled: 1190808\n",
      "    num_steps_trained: 1190808\n",
      "  iterations_since_restore: 596\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92857142857143\n",
      "    ram_util_percent: 31.305714285714295\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433481277833897\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.06223723096044\n",
      "    mean_inference_ms: 2.4684522663719424\n",
      "    mean_raw_obs_processing_ms: 2.052124382261001\n",
      "  time_since_restore: 16243.562297344208\n",
      "  time_this_iter_s: 25.0883686542511\n",
      "  time_total_s: 16243.562297344208\n",
      "  timers:\n",
      "    learn_throughput: 1162.871\n",
      "    learn_time_ms: 1718.161\n",
      "    load_throughput: 58990.662\n",
      "    load_time_ms: 33.87\n",
      "    sample_throughput: 85.872\n",
      "    sample_time_ms: 23267.251\n",
      "    update_time_ms: 8.224\n",
      "  timestamp: 1636445774\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1190808\n",
      "  training_iteration: 596\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   596</td><td style=\"text-align: right;\">         16243.6</td><td style=\"text-align: right;\">1190808</td><td style=\"text-align: right;\">  8.3129</td><td style=\"text-align: right;\">               14.87</td><td style=\"text-align: right;\">                3.87</td><td style=\"text-align: right;\">            105.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1192806\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-16-39\n",
      "  done: false\n",
      "  episode_len_mean: 104.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.850000000000012\n",
      "  episode_reward_mean: 8.481600000000018\n",
      "  episode_reward_min: 3.9200000000000252\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11657\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2683675368626912\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010050105375776072\n",
      "          policy_loss: -0.07570912476096835\n",
      "          total_loss: 0.054231782701043854\n",
      "          vf_explained_var: 0.9834554195404053\n",
      "          vf_loss: 0.135380338283167\n",
      "    num_agent_steps_sampled: 1192806\n",
      "    num_agent_steps_trained: 1192806\n",
      "    num_steps_sampled: 1192806\n",
      "    num_steps_trained: 1192806\n",
      "  iterations_since_restore: 597\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1861111111111\n",
      "    ram_util_percent: 31.30555555555556\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044313556761714175\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.06273726196459\n",
      "    mean_inference_ms: 2.4680876143955506\n",
      "    mean_raw_obs_processing_ms: 2.049872266227247\n",
      "  time_since_restore: 16268.59871172905\n",
      "  time_this_iter_s: 25.03641438484192\n",
      "  time_total_s: 16268.59871172905\n",
      "  timers:\n",
      "    learn_throughput: 1162.92\n",
      "    learn_time_ms: 1718.089\n",
      "    load_throughput: 59085.2\n",
      "    load_time_ms: 33.816\n",
      "    sample_throughput: 86.796\n",
      "    sample_time_ms: 23019.455\n",
      "    update_time_ms: 10.396\n",
      "  timestamp: 1636445799\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1192806\n",
      "  training_iteration: 597\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   597</td><td style=\"text-align: right;\">         16268.6</td><td style=\"text-align: right;\">1192806</td><td style=\"text-align: right;\">  8.4816</td><td style=\"text-align: right;\">               14.85</td><td style=\"text-align: right;\">                3.92</td><td style=\"text-align: right;\">            104.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1194804\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-17-04\n",
      "  done: false\n",
      "  episode_len_mean: 103.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.850000000000012\n",
      "  episode_reward_mean: 8.640300000000018\n",
      "  episode_reward_min: 3.9200000000000252\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11677\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3325378173873539\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00992387427293198\n",
      "          policy_loss: -0.03600194157943839\n",
      "          total_loss: 0.03878304967213245\n",
      "          vf_explained_var: 0.9898245930671692\n",
      "          vf_loss: 0.0809571103592004\n",
      "    num_agent_steps_sampled: 1194804\n",
      "    num_agent_steps_trained: 1194804\n",
      "    num_steps_sampled: 1194804\n",
      "    num_steps_trained: 1194804\n",
      "  iterations_since_restore: 598\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.26666666666668\n",
      "    ram_util_percent: 31.258333333333326\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443205267433891\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.05964278544468\n",
      "    mean_inference_ms: 2.4682048735864965\n",
      "    mean_raw_obs_processing_ms: 2.047328555770059\n",
      "  time_since_restore: 16293.896525621414\n",
      "  time_this_iter_s: 25.297813892364502\n",
      "  time_total_s: 16293.896525621414\n",
      "  timers:\n",
      "    learn_throughput: 1162.204\n",
      "    learn_time_ms: 1719.147\n",
      "    load_throughput: 59339.279\n",
      "    load_time_ms: 33.671\n",
      "    sample_throughput: 86.088\n",
      "    sample_time_ms: 23208.802\n",
      "    update_time_ms: 9.786\n",
      "  timestamp: 1636445824\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1194804\n",
      "  training_iteration: 598\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   598</td><td style=\"text-align: right;\">         16293.9</td><td style=\"text-align: right;\">1194804</td><td style=\"text-align: right;\">  8.6403</td><td style=\"text-align: right;\">               14.85</td><td style=\"text-align: right;\">                3.92</td><td style=\"text-align: right;\">            103.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1196802\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-17-28\n",
      "  done: false\n",
      "  episode_len_mean: 103.98\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.850000000000012\n",
      "  episode_reward_mean: 8.669700000000017\n",
      "  episode_reward_min: 3.9200000000000252\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11696\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2695517869222732\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015443643223734461\n",
      "          policy_loss: -0.08381520338090402\n",
      "          total_loss: 0.04689810343441509\n",
      "          vf_explained_var: 0.9754631519317627\n",
      "          vf_loss: 0.13227684747959886\n",
      "    num_agent_steps_sampled: 1196802\n",
      "    num_agent_steps_trained: 1196802\n",
      "    num_steps_sampled: 1196802\n",
      "    num_steps_trained: 1196802\n",
      "  iterations_since_restore: 599\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.40857142857143\n",
      "    ram_util_percent: 31.202857142857148\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430399749845947\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.059500412047345\n",
      "    mean_inference_ms: 2.467914891621716\n",
      "    mean_raw_obs_processing_ms: 2.0450792490242238\n",
      "  time_since_restore: 16317.821327447891\n",
      "  time_this_iter_s: 23.92480182647705\n",
      "  time_total_s: 16317.821327447891\n",
      "  timers:\n",
      "    learn_throughput: 1162.2\n",
      "    learn_time_ms: 1719.153\n",
      "    load_throughput: 59022.945\n",
      "    load_time_ms: 33.851\n",
      "    sample_throughput: 86.883\n",
      "    sample_time_ms: 22996.553\n",
      "    update_time_ms: 9.469\n",
      "  timestamp: 1636445848\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1196802\n",
      "  training_iteration: 599\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   599</td><td style=\"text-align: right;\">         16317.8</td><td style=\"text-align: right;\">1196802</td><td style=\"text-align: right;\">  8.6697</td><td style=\"text-align: right;\">               14.85</td><td style=\"text-align: right;\">                3.92</td><td style=\"text-align: right;\">            103.98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1198800\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-17-54\n",
      "  done: false\n",
      "  episode_len_mean: 103.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.785200000000017\n",
      "  episode_reward_min: 3.9200000000000252\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11716\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.303409613314129\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013575976232199548\n",
      "          policy_loss: 0.0038519746845676783\n",
      "          total_loss: 0.1369843549405535\n",
      "          vf_explained_var: 0.9800182580947876\n",
      "          vf_loss: 0.13638073810864063\n",
      "    num_agent_steps_sampled: 1198800\n",
      "    num_agent_steps_trained: 1198800\n",
      "    num_steps_sampled: 1198800\n",
      "    num_steps_trained: 1198800\n",
      "  iterations_since_restore: 600\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88888888888887\n",
      "    ram_util_percent: 31.227777777777774\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044321581035786324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.056707816568956\n",
      "    mean_inference_ms: 2.468198935741755\n",
      "    mean_raw_obs_processing_ms: 2.0426454682885575\n",
      "  time_since_restore: 16343.19082736969\n",
      "  time_this_iter_s: 25.369499921798706\n",
      "  time_total_s: 16343.19082736969\n",
      "  timers:\n",
      "    learn_throughput: 1161.039\n",
      "    learn_time_ms: 1720.873\n",
      "    load_throughput: 59306.818\n",
      "    load_time_ms: 33.689\n",
      "    sample_throughput: 87.237\n",
      "    sample_time_ms: 22903.061\n",
      "    update_time_ms: 9.349\n",
      "  timestamp: 1636445874\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1198800\n",
      "  training_iteration: 600\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   600</td><td style=\"text-align: right;\">         16343.2</td><td style=\"text-align: right;\">1198800</td><td style=\"text-align: right;\">  8.7852</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                3.92</td><td style=\"text-align: right;\">            103.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1200798\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-18-32\n",
      "  done: false\n",
      "  episode_len_mean: 104.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.771600000000017\n",
      "  episode_reward_min: 3.9200000000000252\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11735\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3613951705750964\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011087387550959383\n",
      "          policy_loss: -0.012078646712359928\n",
      "          total_loss: 0.09706137631798074\n",
      "          vf_explained_var: 0.9780488610267639\n",
      "          vf_loss: 0.11476204052035298\n",
      "    num_agent_steps_sampled: 1200798\n",
      "    num_agent_steps_trained: 1200798\n",
      "    num_steps_sampled: 1200798\n",
      "    num_steps_trained: 1200798\n",
      "  iterations_since_restore: 601\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.17272727272727\n",
      "    ram_util_percent: 31.170909090909092\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429037986413545\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.05751547703685\n",
      "    mean_inference_ms: 2.467645048068378\n",
      "    mean_raw_obs_processing_ms: 2.0432022904944898\n",
      "  time_since_restore: 16381.649987220764\n",
      "  time_this_iter_s: 38.45915985107422\n",
      "  time_total_s: 16381.649987220764\n",
      "  timers:\n",
      "    learn_throughput: 1160.023\n",
      "    learn_time_ms: 1722.38\n",
      "    load_throughput: 59758.316\n",
      "    load_time_ms: 33.435\n",
      "    sample_throughput: 82.325\n",
      "    sample_time_ms: 24269.73\n",
      "    update_time_ms: 9.022\n",
      "  timestamp: 1636445912\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1200798\n",
      "  training_iteration: 601\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   601</td><td style=\"text-align: right;\">         16381.6</td><td style=\"text-align: right;\">1200798</td><td style=\"text-align: right;\">  8.7716</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                3.92</td><td style=\"text-align: right;\">            104.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1202796\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-18-59\n",
      "  done: false\n",
      "  episode_len_mean: 103.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.990200000000018\n",
      "  episode_reward_min: 3.9300000000000264\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11754\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2996774713198345\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012234850658557722\n",
      "          policy_loss: -0.03783887880189078\n",
      "          total_loss: 0.08592387955813181\n",
      "          vf_explained_var: 0.9824906587600708\n",
      "          vf_loss: 0.1279404919062342\n",
      "    num_agent_steps_sampled: 1202796\n",
      "    num_agent_steps_trained: 1202796\n",
      "    num_steps_sampled: 1202796\n",
      "    num_steps_trained: 1202796\n",
      "  iterations_since_restore: 602\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.4948717948718\n",
      "    ram_util_percent: 30.97948717948717\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044289550381040405\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.056426873654235\n",
      "    mean_inference_ms: 2.4675938161778905\n",
      "    mean_raw_obs_processing_ms: 2.043787397098534\n",
      "  time_since_restore: 16408.862709999084\n",
      "  time_this_iter_s: 27.212722778320312\n",
      "  time_total_s: 16408.862709999084\n",
      "  timers:\n",
      "    learn_throughput: 1159.21\n",
      "    learn_time_ms: 1723.588\n",
      "    load_throughput: 59379.139\n",
      "    load_time_ms: 33.648\n",
      "    sample_throughput: 81.677\n",
      "    sample_time_ms: 24462.253\n",
      "    update_time_ms: 9.019\n",
      "  timestamp: 1636445939\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1202796\n",
      "  training_iteration: 602\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   602</td><td style=\"text-align: right;\">         16408.9</td><td style=\"text-align: right;\">1202796</td><td style=\"text-align: right;\">  8.9902</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                3.93</td><td style=\"text-align: right;\">            103.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1204794\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-19-38\n",
      "  done: false\n",
      "  episode_len_mean: 103.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 8.738300000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11774\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3379359869729905\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016331907889772766\n",
      "          policy_loss: -0.00167775982547374\n",
      "          total_loss: 0.31654432574730546\n",
      "          vf_explained_var: 0.9607222676277161\n",
      "          vf_loss: 0.3198291964119389\n",
      "    num_agent_steps_sampled: 1204794\n",
      "    num_agent_steps_trained: 1204794\n",
      "    num_steps_sampled: 1204794\n",
      "    num_steps_trained: 1204794\n",
      "  iterations_since_restore: 603\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.94727272727273\n",
      "    ram_util_percent: 31.089090909090903\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429341623131669\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.053184932547094\n",
      "    mean_inference_ms: 2.4676264149400366\n",
      "    mean_raw_obs_processing_ms: 2.0471500759835983\n",
      "  time_since_restore: 16447.374325037003\n",
      "  time_this_iter_s: 38.51161503791809\n",
      "  time_total_s: 16447.374325037003\n",
      "  timers:\n",
      "    learn_throughput: 1164.412\n",
      "    learn_time_ms: 1715.888\n",
      "    load_throughput: 59410.753\n",
      "    load_time_ms: 33.63\n",
      "    sample_throughput: 76.927\n",
      "    sample_time_ms: 25972.708\n",
      "    update_time_ms: 8.747\n",
      "  timestamp: 1636445978\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1204794\n",
      "  training_iteration: 603\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   603</td><td style=\"text-align: right;\">         16447.4</td><td style=\"text-align: right;\">1204794</td><td style=\"text-align: right;\">  8.7383</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            103.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1206792\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-20-17\n",
      "  done: false\n",
      "  episode_len_mean: 100.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 8.944800000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 11796\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3255388435863313\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012947364114134023\n",
      "          policy_loss: -0.01470340472601709\n",
      "          total_loss: 0.49971890409610104\n",
      "          vf_explained_var: 0.9380393624305725\n",
      "          vf_loss: 0.5183450663728374\n",
      "    num_agent_steps_sampled: 1206792\n",
      "    num_agent_steps_trained: 1206792\n",
      "    num_steps_sampled: 1206792\n",
      "    num_steps_trained: 1206792\n",
      "  iterations_since_restore: 604\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.17636363636363\n",
      "    ram_util_percent: 30.99272727272727\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044322113963888174\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.048994404159384\n",
      "    mean_inference_ms: 2.4680558512243698\n",
      "    mean_raw_obs_processing_ms: 2.053561885637098\n",
      "  time_since_restore: 16486.193282842636\n",
      "  time_this_iter_s: 38.818957805633545\n",
      "  time_total_s: 16486.193282842636\n",
      "  timers:\n",
      "    learn_throughput: 1162.941\n",
      "    learn_time_ms: 1718.059\n",
      "    load_throughput: 59722.543\n",
      "    load_time_ms: 33.455\n",
      "    sample_throughput: 73.241\n",
      "    sample_time_ms: 27279.702\n",
      "    update_time_ms: 8.893\n",
      "  timestamp: 1636446017\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1206792\n",
      "  training_iteration: 604\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   604</td><td style=\"text-align: right;\">         16486.2</td><td style=\"text-align: right;\">1206792</td><td style=\"text-align: right;\">  8.9448</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             100.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1208790\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-20-44\n",
      "  done: false\n",
      "  episode_len_mean: 100.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 9.206900000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11815\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3255429563068208\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010474564180351075\n",
      "          policy_loss: -0.013407075458339282\n",
      "          total_loss: 0.11360417489139807\n",
      "          vf_explained_var: 0.9829782247543335\n",
      "          vf_loss: 0.13271647705031292\n",
      "    num_agent_steps_sampled: 1208790\n",
      "    num_agent_steps_trained: 1208790\n",
      "    num_steps_sampled: 1208790\n",
      "    num_steps_trained: 1208790\n",
      "  iterations_since_restore: 605\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72105263157897\n",
      "    ram_util_percent: 30.942105263157895\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431791924825987\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.048665437986486\n",
      "    mean_inference_ms: 2.4679208686599905\n",
      "    mean_raw_obs_processing_ms: 2.0592056272441344\n",
      "  time_since_restore: 16512.970909118652\n",
      "  time_this_iter_s: 26.777626276016235\n",
      "  time_total_s: 16512.970909118652\n",
      "  timers:\n",
      "    learn_throughput: 1163.244\n",
      "    learn_time_ms: 1717.61\n",
      "    load_throughput: 59770.975\n",
      "    load_time_ms: 33.428\n",
      "    sample_throughput: 72.184\n",
      "    sample_time_ms: 27679.432\n",
      "    update_time_ms: 9.372\n",
      "  timestamp: 1636446044\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1208790\n",
      "  training_iteration: 605\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   605</td><td style=\"text-align: right;\">           16513</td><td style=\"text-align: right;\">1208790</td><td style=\"text-align: right;\">  9.2069</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            100.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1210788\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-21-10\n",
      "  done: false\n",
      "  episode_len_mean: 99.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 9.348700000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11836\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.32356158608482\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009321907184005388\n",
      "          policy_loss: -0.02062250854713576\n",
      "          total_loss: 0.08662578416544767\n",
      "          vf_explained_var: 0.9833887219429016\n",
      "          vf_loss: 0.11376455571679842\n",
      "    num_agent_steps_sampled: 1210788\n",
      "    num_agent_steps_trained: 1210788\n",
      "    num_steps_sampled: 1210788\n",
      "    num_steps_trained: 1210788\n",
      "  iterations_since_restore: 606\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.71052631578948\n",
      "    ram_util_percent: 31.163157894736838\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044321727385657754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.047394608892454\n",
      "    mean_inference_ms: 2.4679557073304066\n",
      "    mean_raw_obs_processing_ms: 2.0625425564343733\n",
      "  time_since_restore: 16539.27641892433\n",
      "  time_this_iter_s: 26.30550980567932\n",
      "  time_total_s: 16539.27641892433\n",
      "  timers:\n",
      "    learn_throughput: 1161.944\n",
      "    learn_time_ms: 1719.533\n",
      "    load_throughput: 59906.25\n",
      "    load_time_ms: 33.352\n",
      "    sample_throughput: 71.872\n",
      "    sample_time_ms: 27799.51\n",
      "    update_time_ms: 9.25\n",
      "  timestamp: 1636446070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1210788\n",
      "  training_iteration: 606\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   606</td><td style=\"text-align: right;\">         16539.3</td><td style=\"text-align: right;\">1210788</td><td style=\"text-align: right;\">  9.3487</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             99.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1212786\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-21-36\n",
      "  done: false\n",
      "  episode_len_mean: 98.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 8.96250000000002\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11856\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3317113447756994\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016014919219598446\n",
      "          policy_loss: -0.12007804864219257\n",
      "          total_loss: 0.03841071946635133\n",
      "          vf_explained_var: 0.9795452952384949\n",
      "          vf_loss: 0.1602621178187075\n",
      "    num_agent_steps_sampled: 1212786\n",
      "    num_agent_steps_trained: 1212786\n",
      "    num_steps_sampled: 1212786\n",
      "    num_steps_trained: 1212786\n",
      "  iterations_since_restore: 607\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.2891891891892\n",
      "    ram_util_percent: 31.28378378378379\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044320993772299914\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.047493973732948\n",
      "    mean_inference_ms: 2.4679214442656106\n",
      "    mean_raw_obs_processing_ms: 2.0657048187461826\n",
      "  time_since_restore: 16565.07878804207\n",
      "  time_this_iter_s: 25.802369117736816\n",
      "  time_total_s: 16565.07878804207\n",
      "  timers:\n",
      "    learn_throughput: 1161.534\n",
      "    learn_time_ms: 1720.14\n",
      "    load_throughput: 59730.162\n",
      "    load_time_ms: 33.45\n",
      "    sample_throughput: 71.674\n",
      "    sample_time_ms: 27876.215\n",
      "    update_time_ms: 8.178\n",
      "  timestamp: 1636446096\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1212786\n",
      "  training_iteration: 607\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   607</td><td style=\"text-align: right;\">         16565.1</td><td style=\"text-align: right;\">1212786</td><td style=\"text-align: right;\">  8.9625</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1214784\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-22-01\n",
      "  done: false\n",
      "  episode_len_mean: 98.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 9.187700000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11875\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.287409024011521\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009245091251705924\n",
      "          policy_loss: -0.03965367300524598\n",
      "          total_loss: 0.0591152681126481\n",
      "          vf_explained_var: 0.9857556819915771\n",
      "          vf_loss: 0.10497904874916587\n",
      "    num_agent_steps_sampled: 1214784\n",
      "    num_agent_steps_trained: 1214784\n",
      "    num_steps_sampled: 1214784\n",
      "    num_steps_trained: 1214784\n",
      "  iterations_since_restore: 608\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0542857142857\n",
      "    ram_util_percent: 31.32285714285715\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433019611468696\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.04821359381926\n",
      "    mean_inference_ms: 2.4680651824371695\n",
      "    mean_raw_obs_processing_ms: 2.0652485325808643\n",
      "  time_since_restore: 16589.894659996033\n",
      "  time_this_iter_s: 24.815871953964233\n",
      "  time_total_s: 16589.894659996033\n",
      "  timers:\n",
      "    learn_throughput: 1162.196\n",
      "    learn_time_ms: 1719.159\n",
      "    load_throughput: 59379.98\n",
      "    load_time_ms: 33.648\n",
      "    sample_throughput: 71.795\n",
      "    sample_time_ms: 27829.043\n",
      "    update_time_ms: 8.197\n",
      "  timestamp: 1636446121\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1214784\n",
      "  training_iteration: 608\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   608</td><td style=\"text-align: right;\">         16589.9</td><td style=\"text-align: right;\">1214784</td><td style=\"text-align: right;\">  9.1877</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">              98.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1216782\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-22-27\n",
      "  done: false\n",
      "  episode_len_mean: 99.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000014\n",
      "  episode_reward_mean: 9.063700000000019\n",
      "  episode_reward_min: 4.260000000000024\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11895\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3534018039703368\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008400210989836664\n",
      "          policy_loss: 0.0015835936935175033\n",
      "          total_loss: 0.0438487762053098\n",
      "          vf_explained_var: 0.9932838082313538\n",
      "          vf_loss: 0.04974422014894939\n",
      "    num_agent_steps_sampled: 1216782\n",
      "    num_agent_steps_trained: 1216782\n",
      "    num_steps_sampled: 1216782\n",
      "    num_steps_trained: 1216782\n",
      "  iterations_since_restore: 609\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.10000000000001\n",
      "    ram_util_percent: 31.35789473684211\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432445297968255\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.05091036652321\n",
      "    mean_inference_ms: 2.467972669081966\n",
      "    mean_raw_obs_processing_ms: 2.063039710267666\n",
      "  time_since_restore: 16616.150023698807\n",
      "  time_this_iter_s: 26.255363702774048\n",
      "  time_total_s: 16616.150023698807\n",
      "  timers:\n",
      "    learn_throughput: 1162.715\n",
      "    learn_time_ms: 1718.392\n",
      "    load_throughput: 59333.986\n",
      "    load_time_ms: 33.674\n",
      "    sample_throughput: 71.198\n",
      "    sample_time_ms: 28062.536\n",
      "    update_time_ms: 8.733\n",
      "  timestamp: 1636446147\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1216782\n",
      "  training_iteration: 609\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   609</td><td style=\"text-align: right;\">         16616.2</td><td style=\"text-align: right;\">1216782</td><td style=\"text-align: right;\">  9.0637</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">                4.26</td><td style=\"text-align: right;\">             99.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1218780\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-22-52\n",
      "  done: false\n",
      "  episode_len_mean: 99.16\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000014\n",
      "  episode_reward_mean: 8.933900000000017\n",
      "  episode_reward_min: 4.260000000000024\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11916\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2869734292938595\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011293992615096268\n",
      "          policy_loss: -0.02116825899020547\n",
      "          total_loss: 0.08384563069613207\n",
      "          vf_explained_var: 0.9828331470489502\n",
      "          vf_loss: 0.10974276851685275\n",
      "    num_agent_steps_sampled: 1218780\n",
      "    num_agent_steps_trained: 1218780\n",
      "    num_steps_sampled: 1218780\n",
      "    num_steps_trained: 1218780\n",
      "  iterations_since_restore: 610\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.42571428571428\n",
      "    ram_util_percent: 31.391428571428566\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431076187334496\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.052075873612658\n",
      "    mean_inference_ms: 2.4677976851093644\n",
      "    mean_raw_obs_processing_ms: 2.0606328127069005\n",
      "  time_since_restore: 16641.022884845734\n",
      "  time_this_iter_s: 24.87286114692688\n",
      "  time_total_s: 16641.022884845734\n",
      "  timers:\n",
      "    learn_throughput: 1163.617\n",
      "    learn_time_ms: 1717.06\n",
      "    load_throughput: 59091.908\n",
      "    load_time_ms: 33.812\n",
      "    sample_throughput: 71.321\n",
      "    sample_time_ms: 28014.05\n",
      "    update_time_ms: 8.811\n",
      "  timestamp: 1636446172\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1218780\n",
      "  training_iteration: 610\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   610</td><td style=\"text-align: right;\">           16641</td><td style=\"text-align: right;\">1218780</td><td style=\"text-align: right;\">  8.9339</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">                4.26</td><td style=\"text-align: right;\">             99.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1220778\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-23-18\n",
      "  done: false\n",
      "  episode_len_mean: 99.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000014\n",
      "  episode_reward_mean: 8.771500000000017\n",
      "  episode_reward_min: 4.280000000000023\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 11936\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3372842771666391\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010385735098632236\n",
      "          policy_loss: -0.04039885603955814\n",
      "          total_loss: 0.05219663934161266\n",
      "          vf_explained_var: 0.9855237007141113\n",
      "          vf_loss: 0.09848216492682696\n",
      "    num_agent_steps_sampled: 1220778\n",
      "    num_agent_steps_trained: 1220778\n",
      "    num_steps_sampled: 1220778\n",
      "    num_steps_trained: 1220778\n",
      "  iterations_since_restore: 611\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.25135135135137\n",
      "    ram_util_percent: 31.424324324324324\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430970133974196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.053185890357387\n",
      "    mean_inference_ms: 2.467775511065677\n",
      "    mean_raw_obs_processing_ms: 2.0584004779413743\n",
      "  time_since_restore: 16666.699321985245\n",
      "  time_this_iter_s: 25.67643713951111\n",
      "  time_total_s: 16666.699321985245\n",
      "  timers:\n",
      "    learn_throughput: 1163.562\n",
      "    learn_time_ms: 1717.14\n",
      "    load_throughput: 59027.684\n",
      "    load_time_ms: 33.849\n",
      "    sample_throughput: 74.734\n",
      "    sample_time_ms: 26734.987\n",
      "    update_time_ms: 9.236\n",
      "  timestamp: 1636446198\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1220778\n",
      "  training_iteration: 611\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   611</td><td style=\"text-align: right;\">         16666.7</td><td style=\"text-align: right;\">1220778</td><td style=\"text-align: right;\">  8.7715</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">                4.28</td><td style=\"text-align: right;\">             99.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1222776\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-23-42\n",
      "  done: false\n",
      "  episode_len_mean: 100.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.820000000000013\n",
      "  episode_reward_mean: 8.802500000000018\n",
      "  episode_reward_min: 4.280000000000023\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 11954\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3415996994291033\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012873443411758246\n",
      "          policy_loss: 0.03333962935776938\n",
      "          total_loss: 0.1269429067948035\n",
      "          vf_explained_var: 0.9823428392410278\n",
      "          vf_loss: 0.09773992945750555\n",
      "    num_agent_steps_sampled: 1222776\n",
      "    num_agent_steps_trained: 1222776\n",
      "    num_steps_sampled: 1222776\n",
      "    num_steps_trained: 1222776\n",
      "  iterations_since_restore: 612\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.26285714285716\n",
      "    ram_util_percent: 31.42\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429415449256141\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.05468135041329\n",
      "    mean_inference_ms: 2.467501504596022\n",
      "    mean_raw_obs_processing_ms: 2.0563818529648956\n",
      "  time_since_restore: 16691.015156269073\n",
      "  time_this_iter_s: 24.315834283828735\n",
      "  time_total_s: 16691.015156269073\n",
      "  timers:\n",
      "    learn_throughput: 1163.964\n",
      "    learn_time_ms: 1716.548\n",
      "    load_throughput: 58999.218\n",
      "    load_time_ms: 33.865\n",
      "    sample_throughput: 75.552\n",
      "    sample_time_ms: 26445.361\n",
      "    update_time_ms: 9.86\n",
      "  timestamp: 1636446222\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1222776\n",
      "  training_iteration: 612\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   612</td><td style=\"text-align: right;\">           16691</td><td style=\"text-align: right;\">1222776</td><td style=\"text-align: right;\">  8.8025</td><td style=\"text-align: right;\">               14.82</td><td style=\"text-align: right;\">                4.28</td><td style=\"text-align: right;\">            100.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1224774\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-24-06\n",
      "  done: false\n",
      "  episode_len_mean: 101.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.890000000000011\n",
      "  episode_reward_mean: 8.674000000000017\n",
      "  episode_reward_min: 3.800000000000022\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 11975\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3951383602051508\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009472101293147971\n",
      "          policy_loss: -0.03439628332853317\n",
      "          total_loss: 0.019542882254435904\n",
      "          vf_explained_var: 0.9915066957473755\n",
      "          vf_loss: 0.06106293484391201\n",
      "    num_agent_steps_sampled: 1224774\n",
      "    num_agent_steps_trained: 1224774\n",
      "    num_steps_sampled: 1224774\n",
      "    num_steps_trained: 1224774\n",
      "  iterations_since_restore: 613\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96176470588235\n",
      "    ram_util_percent: 31.32058823529412\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044309637820063745\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.054035080455265\n",
      "    mean_inference_ms: 2.4677298683189037\n",
      "    mean_raw_obs_processing_ms: 2.054036760819446\n",
      "  time_since_restore: 16715.42861557007\n",
      "  time_this_iter_s: 24.413459300994873\n",
      "  time_total_s: 16715.42861557007\n",
      "  timers:\n",
      "    learn_throughput: 1163.62\n",
      "    learn_time_ms: 1717.055\n",
      "    load_throughput: 59121.215\n",
      "    load_time_ms: 33.795\n",
      "    sample_throughput: 79.81\n",
      "    sample_time_ms: 25034.42\n",
      "    update_time_ms: 10.496\n",
      "  timestamp: 1636446246\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1224774\n",
      "  training_iteration: 613\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   613</td><td style=\"text-align: right;\">         16715.4</td><td style=\"text-align: right;\">1224774</td><td style=\"text-align: right;\">   8.674</td><td style=\"text-align: right;\">               14.89</td><td style=\"text-align: right;\">                 3.8</td><td style=\"text-align: right;\">             101.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1226772\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-24-32\n",
      "  done: false\n",
      "  episode_len_mean: 101.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.890000000000011\n",
      "  episode_reward_mean: 8.834400000000018\n",
      "  episode_reward_min: 3.800000000000022\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 11994\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3589021319434755\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008525342608613396\n",
      "          policy_loss: -0.10235122768651872\n",
      "          total_loss: -0.00928196974453472\n",
      "          vf_explained_var: 0.9803726077079773\n",
      "          vf_loss: 0.10051310120948724\n",
      "    num_agent_steps_sampled: 1226772\n",
      "    num_agent_steps_trained: 1226772\n",
      "    num_steps_sampled: 1226772\n",
      "    num_steps_trained: 1226772\n",
      "  iterations_since_restore: 614\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72162162162161\n",
      "    ram_util_percent: 31.327027027027036\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429507645306873\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.055027404000406\n",
      "    mean_inference_ms: 2.4674583627610946\n",
      "    mean_raw_obs_processing_ms: 2.0519796395960883\n",
      "  time_since_restore: 16741.36371922493\n",
      "  time_this_iter_s: 25.93510365486145\n",
      "  time_total_s: 16741.36371922493\n",
      "  timers:\n",
      "    learn_throughput: 1164.091\n",
      "    learn_time_ms: 1716.361\n",
      "    load_throughput: 58840.434\n",
      "    load_time_ms: 33.956\n",
      "    sample_throughput: 84.138\n",
      "    sample_time_ms: 23746.57\n",
      "    update_time_ms: 10.695\n",
      "  timestamp: 1636446272\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1226772\n",
      "  training_iteration: 614\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   614</td><td style=\"text-align: right;\">         16741.4</td><td style=\"text-align: right;\">1226772</td><td style=\"text-align: right;\">  8.8344</td><td style=\"text-align: right;\">               14.89</td><td style=\"text-align: right;\">                 3.8</td><td style=\"text-align: right;\">            101.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1228770\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-24-59\n",
      "  done: false\n",
      "  episode_len_mean: 101.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.890000000000011\n",
      "  episode_reward_mean: 8.632700000000018\n",
      "  episode_reward_min: 2.930000000000011\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12015\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.72081298828125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3489574403989883\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.02241078035136297\n",
      "          policy_loss: -0.011188921758106776\n",
      "          total_loss: 0.17491353595008452\n",
      "          vf_explained_var: 0.9743120670318604\n",
      "          vf_loss: 0.18343805209511801\n",
      "    num_agent_steps_sampled: 1228770\n",
      "    num_agent_steps_trained: 1228770\n",
      "    num_steps_sampled: 1228770\n",
      "    num_steps_trained: 1228770\n",
      "  iterations_since_restore: 615\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.29743589743589\n",
      "    ram_util_percent: 31.30256410256411\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443076972525789\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.055556585578362\n",
      "    mean_inference_ms: 2.4675969074682644\n",
      "    mean_raw_obs_processing_ms: 2.049748666420098\n",
      "  time_since_restore: 16768.376697063446\n",
      "  time_this_iter_s: 27.012977838516235\n",
      "  time_total_s: 16768.376697063446\n",
      "  timers:\n",
      "    learn_throughput: 1158.712\n",
      "    learn_time_ms: 1724.328\n",
      "    load_throughput: 58586.463\n",
      "    load_time_ms: 34.103\n",
      "    sample_throughput: 84.084\n",
      "    sample_time_ms: 23761.929\n",
      "    update_time_ms: 11.019\n",
      "  timestamp: 1636446299\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1228770\n",
      "  training_iteration: 615\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   615</td><td style=\"text-align: right;\">         16768.4</td><td style=\"text-align: right;\">1228770</td><td style=\"text-align: right;\">  8.6327</td><td style=\"text-align: right;\">               14.89</td><td style=\"text-align: right;\">                2.93</td><td style=\"text-align: right;\">            101.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1230768\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-25-25\n",
      "  done: false\n",
      "  episode_len_mean: 100.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.890000000000011\n",
      "  episode_reward_mean: 8.71730000000002\n",
      "  episode_reward_min: 2.930000000000011\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12035\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.283601290839059\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014635536565390515\n",
      "          policy_loss: -0.02218578244958605\n",
      "          total_loss: 0.2392082364608844\n",
      "          vf_explained_var: 0.9675130844116211\n",
      "          vf_loss: 0.2584058028956254\n",
      "    num_agent_steps_sampled: 1230768\n",
      "    num_agent_steps_trained: 1230768\n",
      "    num_steps_sampled: 1230768\n",
      "    num_steps_trained: 1230768\n",
      "  iterations_since_restore: 616\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66756756756756\n",
      "    ram_util_percent: 31.28648648648649\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044322802857596814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.054855464220136\n",
      "    mean_inference_ms: 2.4678372923915575\n",
      "    mean_raw_obs_processing_ms: 2.0475776010894178\n",
      "  time_since_restore: 16793.86181950569\n",
      "  time_this_iter_s: 25.485122442245483\n",
      "  time_total_s: 16793.86181950569\n",
      "  timers:\n",
      "    learn_throughput: 1159.029\n",
      "    learn_time_ms: 1723.857\n",
      "    load_throughput: 58617.321\n",
      "    load_time_ms: 34.085\n",
      "    sample_throughput: 84.376\n",
      "    sample_time_ms: 23679.674\n",
      "    update_time_ms: 11.579\n",
      "  timestamp: 1636446325\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1230768\n",
      "  training_iteration: 616\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   616</td><td style=\"text-align: right;\">         16793.9</td><td style=\"text-align: right;\">1230768</td><td style=\"text-align: right;\">  8.7173</td><td style=\"text-align: right;\">               14.89</td><td style=\"text-align: right;\">                2.93</td><td style=\"text-align: right;\">            100.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1232766\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-25-52\n",
      "  done: false\n",
      "  episode_len_mean: 98.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.890000000000011\n",
      "  episode_reward_mean: 8.985800000000017\n",
      "  episode_reward_min: 2.930000000000011\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12056\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.254894391127995\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006907387903316812\n",
      "          policy_loss: -0.006019060961192563\n",
      "          total_loss: 0.058138880515027615\n",
      "          vf_explained_var: 0.9918188452720642\n",
      "          vf_loss: 0.06923848097877842\n",
      "    num_agent_steps_sampled: 1232766\n",
      "    num_agent_steps_trained: 1232766\n",
      "    num_steps_sampled: 1232766\n",
      "    num_steps_trained: 1232766\n",
      "  iterations_since_restore: 617\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08157894736841\n",
      "    ram_util_percent: 31.239473684210523\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443110446090003\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.056734215421194\n",
      "    mean_inference_ms: 2.467654107867371\n",
      "    mean_raw_obs_processing_ms: 2.0453304973766997\n",
      "  time_since_restore: 16820.79586315155\n",
      "  time_this_iter_s: 26.934043645858765\n",
      "  time_total_s: 16820.79586315155\n",
      "  timers:\n",
      "    learn_throughput: 1158.898\n",
      "    learn_time_ms: 1724.052\n",
      "    load_throughput: 58681.188\n",
      "    load_time_ms: 34.048\n",
      "    sample_throughput: 83.971\n",
      "    sample_time_ms: 23793.893\n",
      "    update_time_ms: 10.489\n",
      "  timestamp: 1636446352\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1232766\n",
      "  training_iteration: 617\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   617</td><td style=\"text-align: right;\">         16820.8</td><td style=\"text-align: right;\">1232766</td><td style=\"text-align: right;\">  8.9858</td><td style=\"text-align: right;\">               14.89</td><td style=\"text-align: right;\">                2.93</td><td style=\"text-align: right;\">              98.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1234764\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-26-17\n",
      "  done: false\n",
      "  episode_len_mean: 98.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 9.124400000000017\n",
      "  episode_reward_min: 2.930000000000011\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 12075\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2826514232726325\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008412801799957771\n",
      "          policy_loss: -0.031301449948833104\n",
      "          total_loss: 0.08162949443573043\n",
      "          vf_explained_var: 0.9817975759506226\n",
      "          vf_loss: 0.11666137318880786\n",
      "    num_agent_steps_sampled: 1234764\n",
      "    num_agent_steps_trained: 1234764\n",
      "    num_steps_sampled: 1234764\n",
      "    num_steps_trained: 1234764\n",
      "  iterations_since_restore: 618\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.80277777777778\n",
      "    ram_util_percent: 31.224999999999998\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432320778256045\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.058571307855964\n",
      "    mean_inference_ms: 2.4678218551940434\n",
      "    mean_raw_obs_processing_ms: 2.0433550788319805\n",
      "  time_since_restore: 16845.991980314255\n",
      "  time_this_iter_s: 25.196117162704468\n",
      "  time_total_s: 16845.991980314255\n",
      "  timers:\n",
      "    learn_throughput: 1159.84\n",
      "    learn_time_ms: 1722.652\n",
      "    load_throughput: 58795.89\n",
      "    load_time_ms: 33.982\n",
      "    sample_throughput: 83.832\n",
      "    sample_time_ms: 23833.432\n",
      "    update_time_ms: 10.637\n",
      "  timestamp: 1636446377\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1234764\n",
      "  training_iteration: 618\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   618</td><td style=\"text-align: right;\">           16846</td><td style=\"text-align: right;\">1234764</td><td style=\"text-align: right;\">  9.1244</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                2.93</td><td style=\"text-align: right;\">             98.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1236762\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-26-58\n",
      "  done: false\n",
      "  episode_len_mean: 97.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.805700000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 12097\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.311692013627007\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013338883004562391\n",
      "          policy_loss: -0.010666448729378837\n",
      "          total_loss: 0.22383627325651193\n",
      "          vf_explained_var: 0.944995105266571\n",
      "          vf_loss: 0.23319738241178647\n",
      "    num_agent_steps_sampled: 1236762\n",
      "    num_agent_steps_trained: 1236762\n",
      "    num_steps_sampled: 1236762\n",
      "    num_steps_trained: 1236762\n",
      "  iterations_since_restore: 619\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.13220338983051\n",
      "    ram_util_percent: 31.215254237288132\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429669614936134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.061973323353108\n",
      "    mean_inference_ms: 2.4673556539970156\n",
      "    mean_raw_obs_processing_ms: 2.0444695982531327\n",
      "  time_since_restore: 16887.40870332718\n",
      "  time_this_iter_s: 41.416723012924194\n",
      "  time_total_s: 16887.40870332718\n",
      "  timers:\n",
      "    learn_throughput: 1157.97\n",
      "    learn_time_ms: 1725.434\n",
      "    load_throughput: 59977.079\n",
      "    load_time_ms: 33.313\n",
      "    sample_throughput: 78.824\n",
      "    sample_time_ms: 25347.592\n",
      "    update_time_ms: 10.653\n",
      "  timestamp: 1636446418\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1236762\n",
      "  training_iteration: 619\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   619</td><td style=\"text-align: right;\">         16887.4</td><td style=\"text-align: right;\">1236762</td><td style=\"text-align: right;\">  8.8057</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             97.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1238760\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-27-23\n",
      "  done: false\n",
      "  episode_len_mean: 97.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.797000000000017\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12117\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2803097338903517\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008421634479631549\n",
      "          policy_loss: 0.006516434500614802\n",
      "          total_loss: 0.09173519755048411\n",
      "          vf_explained_var: 0.9892157912254333\n",
      "          vf_loss: 0.08891622464039496\n",
      "    num_agent_steps_sampled: 1238760\n",
      "    num_agent_steps_trained: 1238760\n",
      "    num_steps_sampled: 1238760\n",
      "    num_steps_trained: 1238760\n",
      "  iterations_since_restore: 620\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66666666666669\n",
      "    ram_util_percent: 31.266666666666666\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044302615239056264\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.062131738214248\n",
      "    mean_inference_ms: 2.4674097691746666\n",
      "    mean_raw_obs_processing_ms: 2.044901950825582\n",
      "  time_since_restore: 16912.233725070953\n",
      "  time_this_iter_s: 24.825021743774414\n",
      "  time_total_s: 16912.233725070953\n",
      "  timers:\n",
      "    learn_throughput: 1156.66\n",
      "    learn_time_ms: 1727.388\n",
      "    load_throughput: 60140.166\n",
      "    load_time_ms: 33.222\n",
      "    sample_throughput: 78.845\n",
      "    sample_time_ms: 25340.795\n",
      "    update_time_ms: 10.864\n",
      "  timestamp: 1636446443\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1238760\n",
      "  training_iteration: 620\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   620</td><td style=\"text-align: right;\">         16912.2</td><td style=\"text-align: right;\">1238760</td><td style=\"text-align: right;\">   8.797</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             97.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1240758\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-28-03\n",
      "  done: false\n",
      "  episode_len_mean: 96.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000014\n",
      "  episode_reward_mean: 8.827200000000015\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12138\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3354975882030669\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010604790646963212\n",
      "          policy_loss: -0.014837046952119895\n",
      "          total_loss: 0.21610503113784252\n",
      "          vf_explained_var: 0.9700362682342529\n",
      "          vf_loss: 0.23283094751338165\n",
      "    num_agent_steps_sampled: 1240758\n",
      "    num_agent_steps_trained: 1240758\n",
      "    num_steps_sampled: 1240758\n",
      "    num_steps_trained: 1240758\n",
      "  iterations_since_restore: 621\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.42321428571428\n",
      "    ram_util_percent: 31.205357142857142\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427695842129035\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.06392190260536\n",
      "    mean_inference_ms: 2.4669275577427174\n",
      "    mean_raw_obs_processing_ms: 2.048917122532199\n",
      "  time_since_restore: 16952.025768995285\n",
      "  time_this_iter_s: 39.792043924331665\n",
      "  time_total_s: 16952.025768995285\n",
      "  timers:\n",
      "    learn_throughput: 1156.151\n",
      "    learn_time_ms: 1728.147\n",
      "    load_throughput: 59824.097\n",
      "    load_time_ms: 33.398\n",
      "    sample_throughput: 74.686\n",
      "    sample_time_ms: 26751.904\n",
      "    update_time_ms: 10.478\n",
      "  timestamp: 1636446483\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1240758\n",
      "  training_iteration: 621\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   621</td><td style=\"text-align: right;\">           16952</td><td style=\"text-align: right;\">1240758</td><td style=\"text-align: right;\">  8.8272</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1242756\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-28-43\n",
      "  done: false\n",
      "  episode_len_mean: 97.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 8.559200000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12159\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3078789955093748\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007389390237840555\n",
      "          policy_loss: -0.09472893905781564\n",
      "          total_loss: 0.09937409355881668\n",
      "          vf_explained_var: 0.9526451230049133\n",
      "          vf_loss: 0.19919226558967715\n",
      "    num_agent_steps_sampled: 1242756\n",
      "    num_agent_steps_trained: 1242756\n",
      "    num_steps_sampled: 1242756\n",
      "    num_steps_trained: 1242756\n",
      "  iterations_since_restore: 622\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.95789473684208\n",
      "    ram_util_percent: 31.0280701754386\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044292069746933664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.062144878429546\n",
      "    mean_inference_ms: 2.467104656090699\n",
      "    mean_raw_obs_processing_ms: 2.0552908253601987\n",
      "  time_since_restore: 16991.389662981033\n",
      "  time_this_iter_s: 39.36389398574829\n",
      "  time_total_s: 16991.389662981033\n",
      "  timers:\n",
      "    learn_throughput: 1155.63\n",
      "    learn_time_ms: 1728.927\n",
      "    load_throughput: 59733.44\n",
      "    load_time_ms: 33.449\n",
      "    sample_throughput: 70.71\n",
      "    sample_time_ms: 28256.213\n",
      "    update_time_ms: 10.078\n",
      "  timestamp: 1636446523\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1242756\n",
      "  training_iteration: 622\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   622</td><td style=\"text-align: right;\">         16991.4</td><td style=\"text-align: right;\">1242756</td><td style=\"text-align: right;\">  8.5592</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1244754\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-29-08\n",
      "  done: false\n",
      "  episode_len_mean: 96.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 8.686100000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 12178\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3298520508266631\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0066219162958837275\n",
      "          policy_loss: -0.0872648075222969\n",
      "          total_loss: 0.01165081269684292\n",
      "          vf_explained_var: 0.9840903878211975\n",
      "          vf_loss: 0.10505439614256223\n",
      "    num_agent_steps_sampled: 1244754\n",
      "    num_agent_steps_trained: 1244754\n",
      "    num_steps_sampled: 1244754\n",
      "    num_steps_trained: 1244754\n",
      "  iterations_since_restore: 623\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.06857142857142\n",
      "    ram_util_percent: 31.17142857142857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428960515333461\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.06118600873002\n",
      "    mean_inference_ms: 2.4670461629447935\n",
      "    mean_raw_obs_processing_ms: 2.0611052619237706\n",
      "  time_since_restore: 17016.333383083344\n",
      "  time_this_iter_s: 24.94372010231018\n",
      "  time_total_s: 17016.333383083344\n",
      "  timers:\n",
      "    learn_throughput: 1154.734\n",
      "    learn_time_ms: 1730.268\n",
      "    load_throughput: 59922.827\n",
      "    load_time_ms: 33.343\n",
      "    sample_throughput: 70.581\n",
      "    sample_time_ms: 28307.945\n",
      "    update_time_ms: 10.097\n",
      "  timestamp: 1636446548\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1244754\n",
      "  training_iteration: 623\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   623</td><td style=\"text-align: right;\">         17016.3</td><td style=\"text-align: right;\">1244754</td><td style=\"text-align: right;\">  8.6861</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">              96.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1246752\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-29-33\n",
      "  done: false\n",
      "  episode_len_mean: 97.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000012\n",
      "  episode_reward_mean: 8.804900000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12199\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.296181153115772\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008361694609429824\n",
      "          policy_loss: -0.05216062530165627\n",
      "          total_loss: 0.056886499610152984\n",
      "          vf_explained_var: 0.978830099105835\n",
      "          vf_loss: 0.11296810796927838\n",
      "    num_agent_steps_sampled: 1246752\n",
      "    num_agent_steps_trained: 1246752\n",
      "    num_steps_sampled: 1246752\n",
      "    num_steps_trained: 1246752\n",
      "  iterations_since_restore: 624\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28055555555554\n",
      "    ram_util_percent: 31.238888888888894\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430320682818081\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.059179753751092\n",
      "    mean_inference_ms: 2.4672527041446353\n",
      "    mean_raw_obs_processing_ms: 2.0640380385552817\n",
      "  time_since_restore: 17041.601239919662\n",
      "  time_this_iter_s: 25.26785683631897\n",
      "  time_total_s: 17041.601239919662\n",
      "  timers:\n",
      "    learn_throughput: 1154.791\n",
      "    learn_time_ms: 1730.184\n",
      "    load_throughput: 59960.686\n",
      "    load_time_ms: 33.322\n",
      "    sample_throughput: 70.747\n",
      "    sample_time_ms: 28241.635\n",
      "    update_time_ms: 9.763\n",
      "  timestamp: 1636446573\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1246752\n",
      "  training_iteration: 624\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   624</td><td style=\"text-align: right;\">         17041.6</td><td style=\"text-align: right;\">1246752</td><td style=\"text-align: right;\">  8.8049</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1248750\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-29-58\n",
      "  done: false\n",
      "  episode_len_mean: 97.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 8.659800000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12219\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3444948718661354\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010329118358945902\n",
      "          policy_loss: -0.0490782818978741\n",
      "          total_loss: 0.0703558391580979\n",
      "          vf_explained_var: 0.9760794043540955\n",
      "          vf_loss: 0.12171102783509663\n",
      "    num_agent_steps_sampled: 1248750\n",
      "    num_agent_steps_trained: 1248750\n",
      "    num_steps_sampled: 1248750\n",
      "    num_steps_trained: 1248750\n",
      "  iterations_since_restore: 625\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.78918918918919\n",
      "    ram_util_percent: 31.354054054054057\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044285579896496834\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.059732753775783\n",
      "    mean_inference_ms: 2.4669450750519992\n",
      "    mean_raw_obs_processing_ms: 2.067543087213806\n",
      "  time_since_restore: 17066.97366666794\n",
      "  time_this_iter_s: 25.372426748275757\n",
      "  time_total_s: 17066.97366666794\n",
      "  timers:\n",
      "    learn_throughput: 1159.489\n",
      "    learn_time_ms: 1723.173\n",
      "    load_throughput: 60186.209\n",
      "    load_time_ms: 33.197\n",
      "    sample_throughput: 71.141\n",
      "    sample_time_ms: 28085.1\n",
      "    update_time_ms: 9.255\n",
      "  timestamp: 1636446598\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1248750\n",
      "  training_iteration: 625\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   625</td><td style=\"text-align: right;\">           17067</td><td style=\"text-align: right;\">1248750</td><td style=\"text-align: right;\">  8.6598</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1250748\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-30-25\n",
      "  done: false\n",
      "  episode_len_mean: 98.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 8.712400000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12239\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2197730649085272\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008251213137048817\n",
      "          policy_loss: -0.11757340910179274\n",
      "          total_loss: 0.020074249741931758\n",
      "          vf_explained_var: 0.9818271994590759\n",
      "          vf_loss: 0.14092401677653904\n",
      "    num_agent_steps_sampled: 1250748\n",
      "    num_agent_steps_trained: 1250748\n",
      "    num_steps_sampled: 1250748\n",
      "    num_steps_trained: 1250748\n",
      "  iterations_since_restore: 626\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.91315789473684\n",
      "    ram_util_percent: 31.389473684210525\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431080949201673\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.059072313240378\n",
      "    mean_inference_ms: 2.4673395142624606\n",
      "    mean_raw_obs_processing_ms: 2.066976129054934\n",
      "  time_since_restore: 17093.833567142487\n",
      "  time_this_iter_s: 26.85990047454834\n",
      "  time_total_s: 17093.833567142487\n",
      "  timers:\n",
      "    learn_throughput: 1159.769\n",
      "    learn_time_ms: 1722.757\n",
      "    load_throughput: 60346.83\n",
      "    load_time_ms: 33.109\n",
      "    sample_throughput: 70.791\n",
      "    sample_time_ms: 28223.996\n",
      "    update_time_ms: 8.428\n",
      "  timestamp: 1636446625\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1250748\n",
      "  training_iteration: 626\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   626</td><td style=\"text-align: right;\">         17093.8</td><td style=\"text-align: right;\">1250748</td><td style=\"text-align: right;\">  8.7124</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1252746\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-30-52\n",
      "  done: false\n",
      "  episode_len_mean: 98.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000012\n",
      "  episode_reward_mean: 9.048200000000016\n",
      "  episode_reward_min: 4.180000000000023\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 12261\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2705732084455945\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009477001941735284\n",
      "          policy_loss: -0.05996169564979417\n",
      "          total_loss: 0.03793432402114073\n",
      "          vf_explained_var: 0.9827896952629089\n",
      "          vf_loss: 0.10035503297334626\n",
      "    num_agent_steps_sampled: 1252746\n",
      "    num_agent_steps_trained: 1252746\n",
      "    num_steps_sampled: 1252746\n",
      "    num_steps_trained: 1252746\n",
      "  iterations_since_restore: 627\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.38421052631578\n",
      "    ram_util_percent: 31.410526315789472\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427829895942457\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.0625836273001\n",
      "    mean_inference_ms: 2.466814619680557\n",
      "    mean_raw_obs_processing_ms: 2.0647150565907086\n",
      "  time_since_restore: 17120.324341773987\n",
      "  time_this_iter_s: 26.490774631500244\n",
      "  time_total_s: 17120.324341773987\n",
      "  timers:\n",
      "    learn_throughput: 1160.327\n",
      "    learn_time_ms: 1721.928\n",
      "    load_throughput: 60070.501\n",
      "    load_time_ms: 33.261\n",
      "    sample_throughput: 70.902\n",
      "    sample_time_ms: 28179.939\n",
      "    update_time_ms: 8.846\n",
      "  timestamp: 1636446652\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1252746\n",
      "  training_iteration: 627\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   627</td><td style=\"text-align: right;\">         17120.3</td><td style=\"text-align: right;\">1252746</td><td style=\"text-align: right;\">  9.0482</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">                4.18</td><td style=\"text-align: right;\">              98.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1254744\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-31-19\n",
      "  done: false\n",
      "  episode_len_mean: 96.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000012\n",
      "  episode_reward_mean: 8.963000000000017\n",
      "  episode_reward_min: 2.0400000000000147\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12281\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2107374409834544\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011854897315275198\n",
      "          policy_loss: -0.043274852739913126\n",
      "          total_loss: 0.0932677251952035\n",
      "          vf_explained_var: 0.9761278629302979\n",
      "          vf_loss: 0.13583220557442732\n",
      "    num_agent_steps_sampled: 1254744\n",
      "    num_agent_steps_trained: 1254744\n",
      "    num_steps_sampled: 1254744\n",
      "    num_steps_trained: 1254744\n",
      "  iterations_since_restore: 628\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.82307692307691\n",
      "    ram_util_percent: 31.471794871794867\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428302290041089\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.063274016139314\n",
      "    mean_inference_ms: 2.4668770806560314\n",
      "    mean_raw_obs_processing_ms: 2.062566479933881\n",
      "  time_since_restore: 17147.56671524048\n",
      "  time_this_iter_s: 27.2423734664917\n",
      "  time_total_s: 17147.56671524048\n",
      "  timers:\n",
      "    learn_throughput: 1160.622\n",
      "    learn_time_ms: 1721.491\n",
      "    load_throughput: 59787.648\n",
      "    load_time_ms: 33.418\n",
      "    sample_throughput: 70.392\n",
      "    sample_time_ms: 28384.07\n",
      "    update_time_ms: 9.157\n",
      "  timestamp: 1636446679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1254744\n",
      "  training_iteration: 628\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   628</td><td style=\"text-align: right;\">         17147.6</td><td style=\"text-align: right;\">1254744</td><td style=\"text-align: right;\">   8.963</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">                2.04</td><td style=\"text-align: right;\">             96.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1256742\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-31-46\n",
      "  done: false\n",
      "  episode_len_mean: 94.22\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000012\n",
      "  episode_reward_mean: 9.519500000000019\n",
      "  episode_reward_min: 2.0400000000000147\n",
      "  episodes_this_iter: 24\n",
      "  episodes_total: 12305\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1830482471556891\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009609657309736314\n",
      "          policy_loss: -0.06510703024410067\n",
      "          total_loss: 0.05334972892666147\n",
      "          vf_explained_var: 0.9904260039329529\n",
      "          vf_loss: 0.11989709147739978\n",
      "    num_agent_steps_sampled: 1256742\n",
      "    num_agent_steps_trained: 1256742\n",
      "    num_steps_sampled: 1256742\n",
      "    num_steps_trained: 1256742\n",
      "  iterations_since_restore: 629\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.01538461538462\n",
      "    ram_util_percent: 31.405128205128204\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425628455168409\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.06787216413836\n",
      "    mean_inference_ms: 2.466429893232997\n",
      "    mean_raw_obs_processing_ms: 2.060163648229181\n",
      "  time_since_restore: 17174.96997308731\n",
      "  time_this_iter_s: 27.403257846832275\n",
      "  time_total_s: 17174.96997308731\n",
      "  timers:\n",
      "    learn_throughput: 1161.837\n",
      "    learn_time_ms: 1719.691\n",
      "    load_throughput: 58731.691\n",
      "    load_time_ms: 34.019\n",
      "    sample_throughput: 74.045\n",
      "    sample_time_ms: 26983.648\n",
      "    update_time_ms: 9.341\n",
      "  timestamp: 1636446706\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1256742\n",
      "  training_iteration: 629\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   629</td><td style=\"text-align: right;\">           17175</td><td style=\"text-align: right;\">1256742</td><td style=\"text-align: right;\">  9.5195</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">                2.04</td><td style=\"text-align: right;\">             94.22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1258740\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-32-13\n",
      "  done: false\n",
      "  episode_len_mean: 92.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000012\n",
      "  episode_reward_mean: 9.921000000000015\n",
      "  episode_reward_min: 2.0400000000000147\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12326\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2225059287888662\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0072212366364690465\n",
      "          policy_loss: -0.006228557388697352\n",
      "          total_loss: 0.0625874171122199\n",
      "          vf_explained_var: 0.9909363985061646\n",
      "          vf_loss: 0.07323329352019799\n",
      "    num_agent_steps_sampled: 1258740\n",
      "    num_agent_steps_trained: 1258740\n",
      "    num_steps_sampled: 1258740\n",
      "    num_steps_trained: 1258740\n",
      "  iterations_since_restore: 630\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.30526315789473\n",
      "    ram_util_percent: 31.38684210526316\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425854981460498\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.07173294548919\n",
      "    mean_inference_ms: 2.4664252388090233\n",
      "    mean_raw_obs_processing_ms: 2.0581178477688207\n",
      "  time_since_restore: 17201.509786128998\n",
      "  time_this_iter_s: 26.53981304168701\n",
      "  time_total_s: 17201.509786128998\n",
      "  timers:\n",
      "    learn_throughput: 1163.008\n",
      "    learn_time_ms: 1717.959\n",
      "    load_throughput: 58740.13\n",
      "    load_time_ms: 34.014\n",
      "    sample_throughput: 73.575\n",
      "    sample_time_ms: 27156.072\n",
      "    update_time_ms: 9.885\n",
      "  timestamp: 1636446733\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1258740\n",
      "  training_iteration: 630\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   630</td><td style=\"text-align: right;\">         17201.5</td><td style=\"text-align: right;\">1258740</td><td style=\"text-align: right;\">   9.921</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">                2.04</td><td style=\"text-align: right;\">             92.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1260738\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-32-39\n",
      "  done: false\n",
      "  episode_len_mean: 93.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000012\n",
      "  episode_reward_mean: 9.698900000000016\n",
      "  episode_reward_min: 2.0400000000000147\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12346\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.251102043049676\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008335439516220596\n",
      "          policy_loss: -0.006247666961557808\n",
      "          total_loss: 0.07842084760999396\n",
      "          vf_explained_var: 0.985125720500946\n",
      "          vf_loss: 0.08816709423526412\n",
      "    num_agent_steps_sampled: 1260738\n",
      "    num_agent_steps_trained: 1260738\n",
      "    num_steps_sampled: 1260738\n",
      "    num_steps_trained: 1260738\n",
      "  iterations_since_restore: 631\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.36486486486486\n",
      "    ram_util_percent: 31.337837837837846\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044261474666805564\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.07541630912556\n",
      "    mean_inference_ms: 2.466414290171871\n",
      "    mean_raw_obs_processing_ms: 2.0561889759693304\n",
      "  time_since_restore: 17227.740885734558\n",
      "  time_this_iter_s: 26.231099605560303\n",
      "  time_total_s: 17227.740885734558\n",
      "  timers:\n",
      "    learn_throughput: 1163.048\n",
      "    learn_time_ms: 1717.9\n",
      "    load_throughput: 58874.538\n",
      "    load_time_ms: 33.937\n",
      "    sample_throughput: 77.442\n",
      "    sample_time_ms: 25799.872\n",
      "    update_time_ms: 10.31\n",
      "  timestamp: 1636446759\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1260738\n",
      "  training_iteration: 631\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   631</td><td style=\"text-align: right;\">         17227.7</td><td style=\"text-align: right;\">1260738</td><td style=\"text-align: right;\">  9.6989</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">                2.04</td><td style=\"text-align: right;\">             93.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1262736\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-33-06\n",
      "  done: false\n",
      "  episode_len_mean: 94.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000014\n",
      "  episode_reward_mean: 9.503400000000017\n",
      "  episode_reward_min: 2.0400000000000147\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 12368\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2203390104430063\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008834782378908734\n",
      "          policy_loss: -0.03671047580206678\n",
      "          total_loss: 0.05017363276510012\n",
      "          vf_explained_var: 0.9901627898216248\n",
      "          vf_loss: 0.08953515872181882\n",
      "    num_agent_steps_sampled: 1262736\n",
      "    num_agent_steps_trained: 1262736\n",
      "    num_steps_sampled: 1262736\n",
      "    num_steps_trained: 1262736\n",
      "  iterations_since_restore: 632\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.54358974358973\n",
      "    ram_util_percent: 31.33076923076924\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428008024065596\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.078115760710006\n",
      "    mean_inference_ms: 2.4666587348591866\n",
      "    mean_raw_obs_processing_ms: 2.054040471486409\n",
      "  time_since_restore: 17254.607472896576\n",
      "  time_this_iter_s: 26.866587162017822\n",
      "  time_total_s: 17254.607472896576\n",
      "  timers:\n",
      "    learn_throughput: 1162.817\n",
      "    learn_time_ms: 1718.241\n",
      "    load_throughput: 59321.217\n",
      "    load_time_ms: 33.681\n",
      "    sample_throughput: 81.383\n",
      "    sample_time_ms: 24550.477\n",
      "    update_time_ms: 9.742\n",
      "  timestamp: 1636446786\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1262736\n",
      "  training_iteration: 632\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   632</td><td style=\"text-align: right;\">         17254.6</td><td style=\"text-align: right;\">1262736</td><td style=\"text-align: right;\">  9.5034</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                2.04</td><td style=\"text-align: right;\">             94.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1264734\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-33-32\n",
      "  done: false\n",
      "  episode_len_mean: 95.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 9.564200000000017\n",
      "  episode_reward_min: 2.6000000000000165\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 12387\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2959547559420268\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007663109496478844\n",
      "          policy_loss: -0.019962161300437792\n",
      "          total_loss: 0.07507175933126183\n",
      "          vf_explained_var: 0.987800657749176\n",
      "          vf_loss: 0.09970796217343637\n",
      "    num_agent_steps_sampled: 1264734\n",
      "    num_agent_steps_trained: 1264734\n",
      "    num_steps_sampled: 1264734\n",
      "    num_steps_trained: 1264734\n",
      "  iterations_since_restore: 633\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.70540540540541\n",
      "    ram_util_percent: 31.313513513513524\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429257499228358\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.080839927238895\n",
      "    mean_inference_ms: 2.466813826467467\n",
      "    mean_raw_obs_processing_ms: 2.0522395501786836\n",
      "  time_since_restore: 17280.700340747833\n",
      "  time_this_iter_s: 26.092867851257324\n",
      "  time_total_s: 17280.700340747833\n",
      "  timers:\n",
      "    learn_throughput: 1164.49\n",
      "    learn_time_ms: 1715.773\n",
      "    load_throughput: 58955.594\n",
      "    load_time_ms: 33.89\n",
      "    sample_throughput: 80.997\n",
      "    sample_time_ms: 24667.701\n",
      "    update_time_ms: 9.563\n",
      "  timestamp: 1636446812\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1264734\n",
      "  training_iteration: 633\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   633</td><td style=\"text-align: right;\">         17280.7</td><td style=\"text-align: right;\">1264734</td><td style=\"text-align: right;\">  9.5642</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                 2.6</td><td style=\"text-align: right;\">             95.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1266732\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-33-58\n",
      "  done: false\n",
      "  episode_len_mean: 96.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 9.173700000000018\n",
      "  episode_reward_min: 2.6000000000000165\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12407\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.286963263012114\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011262219375509686\n",
      "          policy_loss: -0.0187643520179249\n",
      "          total_loss: 0.09475278306220258\n",
      "          vf_explained_var: 0.9822729229927063\n",
      "          vf_loss: 0.11420983824701536\n",
      "    num_agent_steps_sampled: 1266732\n",
      "    num_agent_steps_trained: 1266732\n",
      "    num_steps_sampled: 1266732\n",
      "    num_steps_trained: 1266732\n",
      "  iterations_since_restore: 634\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.15675675675675\n",
      "    ram_util_percent: 31.29729729729731\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431962323746645\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.081906534813633\n",
      "    mean_inference_ms: 2.467220746409278\n",
      "    mean_raw_obs_processing_ms: 2.0502109577229803\n",
      "  time_since_restore: 17306.717813253403\n",
      "  time_this_iter_s: 26.017472505569458\n",
      "  time_total_s: 17306.717813253403\n",
      "  timers:\n",
      "    learn_throughput: 1163.881\n",
      "    learn_time_ms: 1716.671\n",
      "    load_throughput: 59063.254\n",
      "    load_time_ms: 33.828\n",
      "    sample_throughput: 80.755\n",
      "    sample_time_ms: 24741.404\n",
      "    update_time_ms: 9.686\n",
      "  timestamp: 1636446838\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1266732\n",
      "  training_iteration: 634\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   634</td><td style=\"text-align: right;\">         17306.7</td><td style=\"text-align: right;\">1266732</td><td style=\"text-align: right;\">  9.1737</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                 2.6</td><td style=\"text-align: right;\">             96.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1268730\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-34-23\n",
      "  done: false\n",
      "  episode_len_mean: 98.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 9.163800000000016\n",
      "  episode_reward_min: 2.6000000000000165\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 12426\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.35548472234181\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009379483093931707\n",
      "          policy_loss: -0.024192883322636288\n",
      "          total_loss: 0.12640542827014412\n",
      "          vf_explained_var: 0.9783480763435364\n",
      "          vf_loss: 0.15401187783905437\n",
      "    num_agent_steps_sampled: 1268730\n",
      "    num_agent_steps_trained: 1268730\n",
      "    num_steps_sampled: 1268730\n",
      "    num_steps_trained: 1268730\n",
      "  iterations_since_restore: 635\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14857142857142\n",
      "    ram_util_percent: 31.208571428571428\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044329726536483254\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.083278041375078\n",
      "    mean_inference_ms: 2.4673844967841827\n",
      "    mean_raw_obs_processing_ms: 2.048268717006423\n",
      "  time_since_restore: 17331.54327392578\n",
      "  time_this_iter_s: 24.82546067237854\n",
      "  time_total_s: 17331.54327392578\n",
      "  timers:\n",
      "    learn_throughput: 1164.697\n",
      "    learn_time_ms: 1715.468\n",
      "    load_throughput: 59188.694\n",
      "    load_time_ms: 33.756\n",
      "    sample_throughput: 80.929\n",
      "    sample_time_ms: 24688.187\n",
      "    update_time_ms: 9.23\n",
      "  timestamp: 1636446863\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1268730\n",
      "  training_iteration: 635\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   635</td><td style=\"text-align: right;\">         17331.5</td><td style=\"text-align: right;\">1268730</td><td style=\"text-align: right;\">  9.1638</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                 2.6</td><td style=\"text-align: right;\">             98.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1270728\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-35-06\n",
      "  done: false\n",
      "  episode_len_mean: 98.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000011\n",
      "  episode_reward_mean: 9.224700000000018\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 12448\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2135692590758913\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008652762782309273\n",
      "          policy_loss: -0.014720471895166806\n",
      "          total_loss: 0.20391237408898416\n",
      "          vf_explained_var: 0.9739631414413452\n",
      "          vf_loss: 0.22141300138263476\n",
      "    num_agent_steps_sampled: 1270728\n",
      "    num_agent_steps_trained: 1270728\n",
      "    num_steps_sampled: 1270728\n",
      "    num_steps_trained: 1270728\n",
      "  iterations_since_restore: 636\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.75806451612901\n",
      "    ram_util_percent: 31.243548387096777\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044297413554541816\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.086252565739287\n",
      "    mean_inference_ms: 2.466851573196891\n",
      "    mean_raw_obs_processing_ms: 2.049485946398638\n",
      "  time_since_restore: 17374.318379878998\n",
      "  time_this_iter_s: 42.77510595321655\n",
      "  time_total_s: 17374.318379878998\n",
      "  timers:\n",
      "    learn_throughput: 1164.034\n",
      "    learn_time_ms: 1716.444\n",
      "    load_throughput: 59199.523\n",
      "    load_time_ms: 33.75\n",
      "    sample_throughput: 76.032\n",
      "    sample_time_ms: 26278.483\n",
      "    update_time_ms: 9.474\n",
      "  timestamp: 1636446906\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1270728\n",
      "  training_iteration: 636\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   636</td><td style=\"text-align: right;\">         17374.3</td><td style=\"text-align: right;\">1270728</td><td style=\"text-align: right;\">  9.2247</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             98.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1272726\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-35-33\n",
      "  done: false\n",
      "  episode_len_mean: 98.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.06450000000002\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12469\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2926972758202326\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009981622814344287\n",
      "          policy_loss: -0.025238562197912307\n",
      "          total_loss: 0.12895993107841128\n",
      "          vf_explained_var: 0.9810957908630371\n",
      "          vf_loss: 0.15633314177393914\n",
      "    num_agent_steps_sampled: 1272726\n",
      "    num_agent_steps_trained: 1272726\n",
      "    num_steps_sampled: 1272726\n",
      "    num_steps_trained: 1272726\n",
      "  iterations_since_restore: 637\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.35000000000001\n",
      "    ram_util_percent: 31.255263157894746\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429611118946215\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.087512990628355\n",
      "    mean_inference_ms: 2.4668342821737577\n",
      "    mean_raw_obs_processing_ms: 2.050281054319515\n",
      "  time_since_restore: 17401.454264879227\n",
      "  time_this_iter_s: 27.135885000228882\n",
      "  time_total_s: 17401.454264879227\n",
      "  timers:\n",
      "    learn_throughput: 1163.12\n",
      "    learn_time_ms: 1717.793\n",
      "    load_throughput: 59367.739\n",
      "    load_time_ms: 33.655\n",
      "    sample_throughput: 75.848\n",
      "    sample_time_ms: 26342.054\n",
      "    update_time_ms: 9.269\n",
      "  timestamp: 1636446933\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1272726\n",
      "  training_iteration: 637\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   637</td><td style=\"text-align: right;\">         17401.5</td><td style=\"text-align: right;\">1272726</td><td style=\"text-align: right;\">  9.0645</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             98.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1274724\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-36-15\n",
      "  done: false\n",
      "  episode_len_mean: 95.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.145800000000017\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 12491\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1479822783243088\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010570059855658153\n",
      "          policy_loss: -0.044234084036378636\n",
      "          total_loss: 0.19491075525681179\n",
      "          vf_explained_var: 0.9726147055625916\n",
      "          vf_loss: 0.23919611257456597\n",
      "    num_agent_steps_sampled: 1274724\n",
      "    num_agent_steps_trained: 1274724\n",
      "    num_steps_sampled: 1274724\n",
      "    num_steps_trained: 1274724\n",
      "  iterations_since_restore: 638\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.10999999999999\n",
      "    ram_util_percent: 31.276666666666667\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044256559518796514\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.089473116165937\n",
      "    mean_inference_ms: 2.46619609520349\n",
      "    mean_raw_obs_processing_ms: 2.054176953859865\n",
      "  time_since_restore: 17443.364867687225\n",
      "  time_this_iter_s: 41.91060280799866\n",
      "  time_total_s: 17443.364867687225\n",
      "  timers:\n",
      "    learn_throughput: 1162.069\n",
      "    learn_time_ms: 1719.348\n",
      "    load_throughput: 59560.609\n",
      "    load_time_ms: 33.546\n",
      "    sample_throughput: 71.85\n",
      "    sample_time_ms: 27808.103\n",
      "    update_time_ms: 8.852\n",
      "  timestamp: 1636446975\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1274724\n",
      "  training_iteration: 638\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   638</td><td style=\"text-align: right;\">         17443.4</td><td style=\"text-align: right;\">1274724</td><td style=\"text-align: right;\">  9.1458</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             95.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1276722\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-36-56\n",
      "  done: false\n",
      "  episode_len_mean: 95.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.753000000000016\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12512\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2694011120569137\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01320512384681715\n",
      "          policy_loss: -0.042826520491923606\n",
      "          total_loss: 0.19273785439408606\n",
      "          vf_explained_var: 0.9646519422531128\n",
      "          vf_loss: 0.23398074557383855\n",
      "    num_agent_steps_sampled: 1276722\n",
      "    num_agent_steps_trained: 1276722\n",
      "    num_steps_sampled: 1276722\n",
      "    num_steps_trained: 1276722\n",
      "  iterations_since_restore: 639\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.4915254237288\n",
      "    ram_util_percent: 31.072881355932203\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426832769716335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.090325356668327\n",
      "    mean_inference_ms: 2.4663295791356337\n",
      "    mean_raw_obs_processing_ms: 2.0607010407365345\n",
      "  time_since_restore: 17484.479958295822\n",
      "  time_this_iter_s: 41.1150906085968\n",
      "  time_total_s: 17484.479958295822\n",
      "  timers:\n",
      "    learn_throughput: 1161.352\n",
      "    learn_time_ms: 1720.408\n",
      "    load_throughput: 59523.804\n",
      "    load_time_ms: 33.566\n",
      "    sample_throughput: 68.475\n",
      "    sample_time_ms: 29178.58\n",
      "    update_time_ms: 8.175\n",
      "  timestamp: 1636447016\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1276722\n",
      "  training_iteration: 639\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   639</td><td style=\"text-align: right;\">         17484.5</td><td style=\"text-align: right;\">1276722</td><td style=\"text-align: right;\">   8.753</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             95.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1278720\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-37-22\n",
      "  done: false\n",
      "  episode_len_mean: 93.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.804500000000019\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12533\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1098250846068065\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0076403499347162855\n",
      "          policy_loss: -0.11313867144996212\n",
      "          total_loss: -0.01605150732433512\n",
      "          vf_explained_var: 0.9839546084403992\n",
      "          vf_loss: 0.09992451896624906\n",
      "    num_agent_steps_sampled: 1278720\n",
      "    num_agent_steps_trained: 1278720\n",
      "    num_steps_sampled: 1278720\n",
      "    num_steps_trained: 1278720\n",
      "  iterations_since_restore: 640\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.41891891891892\n",
      "    ram_util_percent: 31.18648648648649\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044259846009288575\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.090194356405956\n",
      "    mean_inference_ms: 2.466187220451516\n",
      "    mean_raw_obs_processing_ms: 2.0670806345754262\n",
      "  time_since_restore: 17510.527965545654\n",
      "  time_this_iter_s: 26.048007249832153\n",
      "  time_total_s: 17510.527965545654\n",
      "  timers:\n",
      "    learn_throughput: 1160.578\n",
      "    learn_time_ms: 1721.556\n",
      "    load_throughput: 59509.517\n",
      "    load_time_ms: 33.574\n",
      "    sample_throughput: 68.591\n",
      "    sample_time_ms: 29129.06\n",
      "    update_time_ms: 7.45\n",
      "  timestamp: 1636447042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1278720\n",
      "  training_iteration: 640\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   640</td><td style=\"text-align: right;\">         17510.5</td><td style=\"text-align: right;\">1278720</td><td style=\"text-align: right;\">  8.8045</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             93.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1280718\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-37-48\n",
      "  done: false\n",
      "  episode_len_mean: 94.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000014\n",
      "  episode_reward_mean: 8.904900000000016\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12553\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2397700113909584\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008831233734096942\n",
      "          policy_loss: -0.046813892821470894\n",
      "          total_loss: 0.06021699877012344\n",
      "          vf_explained_var: 0.986810564994812\n",
      "          vf_loss: 0.10988009002591882\n",
      "    num_agent_steps_sampled: 1280718\n",
      "    num_agent_steps_trained: 1280718\n",
      "    num_steps_sampled: 1280718\n",
      "    num_steps_trained: 1280718\n",
      "  iterations_since_restore: 641\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.575\n",
      "    ram_util_percent: 31.244444444444454\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428588606745945\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.090147400284454\n",
      "    mean_inference_ms: 2.466590548461431\n",
      "    mean_raw_obs_processing_ms: 2.0698353997553607\n",
      "  time_since_restore: 17536.01663541794\n",
      "  time_this_iter_s: 25.488669872283936\n",
      "  time_total_s: 17536.01663541794\n",
      "  timers:\n",
      "    learn_throughput: 1162.35\n",
      "    learn_time_ms: 1718.931\n",
      "    load_throughput: 59511.503\n",
      "    load_time_ms: 33.573\n",
      "    sample_throughput: 68.759\n",
      "    sample_time_ms: 29057.941\n",
      "    update_time_ms: 6.78\n",
      "  timestamp: 1636447068\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1280718\n",
      "  training_iteration: 641\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   641</td><td style=\"text-align: right;\">           17536</td><td style=\"text-align: right;\">1280718</td><td style=\"text-align: right;\">  8.9049</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             94.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1282716\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-38-15\n",
      "  done: false\n",
      "  episode_len_mean: 95.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000014\n",
      "  episode_reward_mean: 8.998800000000017\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12574\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.190911754256203\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008025322007527902\n",
      "          policy_loss: -0.011068396944375265\n",
      "          total_loss: 0.051031778987851883\n",
      "          vf_explained_var: 0.99098801612854\n",
      "          vf_loss: 0.06533215910728489\n",
      "    num_agent_steps_sampled: 1282716\n",
      "    num_agent_steps_trained: 1282716\n",
      "    num_steps_sampled: 1282716\n",
      "    num_steps_trained: 1282716\n",
      "  iterations_since_restore: 642\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59230769230771\n",
      "    ram_util_percent: 31.35128205128205\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044284772140720643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.09093436256704\n",
      "    mean_inference_ms: 2.4665619127849796\n",
      "    mean_raw_obs_processing_ms: 2.073291551369228\n",
      "  time_since_restore: 17562.922285318375\n",
      "  time_this_iter_s: 26.9056499004364\n",
      "  time_total_s: 17562.922285318375\n",
      "  timers:\n",
      "    learn_throughput: 1162.17\n",
      "    learn_time_ms: 1719.198\n",
      "    load_throughput: 59367.234\n",
      "    load_time_ms: 33.655\n",
      "    sample_throughput: 68.752\n",
      "    sample_time_ms: 29061.109\n",
      "    update_time_ms: 7.407\n",
      "  timestamp: 1636447095\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1282716\n",
      "  training_iteration: 642\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   642</td><td style=\"text-align: right;\">         17562.9</td><td style=\"text-align: right;\">1282716</td><td style=\"text-align: right;\">  8.9988</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             95.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1284714\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-38-41\n",
      "  done: false\n",
      "  episode_len_mean: 97.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 8.947400000000016\n",
      "  episode_reward_min: 3.9100000000000255\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12595\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1703751481714704\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010164446269404633\n",
      "          policy_loss: -0.006511962271872021\n",
      "          total_loss: 0.10581306834660825\n",
      "          vf_explained_var: 0.9859546422958374\n",
      "          vf_loss: 0.11303878376881281\n",
      "    num_agent_steps_sampled: 1284714\n",
      "    num_agent_steps_trained: 1284714\n",
      "    num_steps_sampled: 1284714\n",
      "    num_steps_trained: 1284714\n",
      "  iterations_since_restore: 643\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.65945945945946\n",
      "    ram_util_percent: 31.32972972972973\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429612318199231\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.092706898423977\n",
      "    mean_inference_ms: 2.466725178277868\n",
      "    mean_raw_obs_processing_ms: 2.071991807212375\n",
      "  time_since_restore: 17589.180226564407\n",
      "  time_this_iter_s: 26.257941246032715\n",
      "  time_total_s: 17589.180226564407\n",
      "  timers:\n",
      "    learn_throughput: 1160.69\n",
      "    learn_time_ms: 1721.389\n",
      "    load_throughput: 59417.071\n",
      "    load_time_ms: 33.627\n",
      "    sample_throughput: 68.716\n",
      "    sample_time_ms: 29076.084\n",
      "    update_time_ms: 6.76\n",
      "  timestamp: 1636447121\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1284714\n",
      "  training_iteration: 643\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   643</td><td style=\"text-align: right;\">         17589.2</td><td style=\"text-align: right;\">1284714</td><td style=\"text-align: right;\">  8.9474</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                3.91</td><td style=\"text-align: right;\">             97.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1286712\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-39-08\n",
      "  done: false\n",
      "  episode_len_mean: 96.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 9.362400000000017\n",
      "  episode_reward_min: 3.9100000000000255\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12616\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.21723207008271\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006452303521016946\n",
      "          policy_loss: -0.09270382483622858\n",
      "          total_loss: -0.053758642210492064\n",
      "          vf_explained_var: 0.9956234097480774\n",
      "          vf_loss: 0.044141146837778034\n",
      "    num_agent_steps_sampled: 1286712\n",
      "    num_agent_steps_trained: 1286712\n",
      "    num_steps_sampled: 1286712\n",
      "    num_steps_trained: 1286712\n",
      "  iterations_since_restore: 644\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.06315789473683\n",
      "    ram_util_percent: 31.363157894736847\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044284894036143656\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.094706649006447\n",
      "    mean_inference_ms: 2.466529052952482\n",
      "    mean_raw_obs_processing_ms: 2.0698066268308177\n",
      "  time_since_restore: 17615.71703505516\n",
      "  time_this_iter_s: 26.536808490753174\n",
      "  time_total_s: 17615.71703505516\n",
      "  timers:\n",
      "    learn_throughput: 1161.506\n",
      "    learn_time_ms: 1720.18\n",
      "    load_throughput: 59136.109\n",
      "    load_time_ms: 33.786\n",
      "    sample_throughput: 68.591\n",
      "    sample_time_ms: 29129.104\n",
      "    update_time_ms: 6.982\n",
      "  timestamp: 1636447148\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1286712\n",
      "  training_iteration: 644\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   644</td><td style=\"text-align: right;\">         17615.7</td><td style=\"text-align: right;\">1286712</td><td style=\"text-align: right;\">  9.3624</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                3.91</td><td style=\"text-align: right;\">             96.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1288710\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-39-34\n",
      "  done: false\n",
      "  episode_len_mean: 96.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 9.495600000000017\n",
      "  episode_reward_min: 4.330000000000021\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 12635\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.261260790768124\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007981061084907886\n",
      "          policy_loss: -0.03602490520903042\n",
      "          total_loss: 0.035203607309432255\n",
      "          vf_explained_var: 0.9862095713615417\n",
      "          vf_loss: 0.0752118424202005\n",
      "    num_agent_steps_sampled: 1288710\n",
      "    num_agent_steps_trained: 1288710\n",
      "    num_steps_sampled: 1288710\n",
      "    num_steps_trained: 1288710\n",
      "  iterations_since_restore: 645\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.22051282051282\n",
      "    ram_util_percent: 31.43589743589744\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429698530134189\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.096709311102256\n",
      "    mean_inference_ms: 2.4666709086145526\n",
      "    mean_raw_obs_processing_ms: 2.0678731362867864\n",
      "  time_since_restore: 17642.604076385498\n",
      "  time_this_iter_s: 26.887041330337524\n",
      "  time_total_s: 17642.604076385498\n",
      "  timers:\n",
      "    learn_throughput: 1161.193\n",
      "    learn_time_ms: 1720.645\n",
      "    load_throughput: 59131.686\n",
      "    load_time_ms: 33.789\n",
      "    sample_throughput: 68.11\n",
      "    sample_time_ms: 29335.009\n",
      "    update_time_ms: 7.09\n",
      "  timestamp: 1636447174\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1288710\n",
      "  training_iteration: 645\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   645</td><td style=\"text-align: right;\">         17642.6</td><td style=\"text-align: right;\">1288710</td><td style=\"text-align: right;\">  9.4956</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                4.33</td><td style=\"text-align: right;\">             96.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1290708\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-40-01\n",
      "  done: false\n",
      "  episode_len_mean: 96.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 9.376100000000015\n",
      "  episode_reward_min: 4.330000000000021\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 12657\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2403569919722421\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012365096689341604\n",
      "          policy_loss: -0.002159638206164042\n",
      "          total_loss: 0.062094802444889435\n",
      "          vf_explained_var: 0.990706741809845\n",
      "          vf_loss: 0.06328862622557652\n",
      "    num_agent_steps_sampled: 1290708\n",
      "    num_agent_steps_trained: 1290708\n",
      "    num_steps_sampled: 1290708\n",
      "    num_steps_trained: 1290708\n",
      "  iterations_since_restore: 646\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.75263157894737\n",
      "    ram_util_percent: 31.402631578947375\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428660233190325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.09882708246796\n",
      "    mean_inference_ms: 2.466462335372882\n",
      "    mean_raw_obs_processing_ms: 2.0656036732387877\n",
      "  time_since_restore: 17669.114943742752\n",
      "  time_this_iter_s: 26.51086735725403\n",
      "  time_total_s: 17669.114943742752\n",
      "  timers:\n",
      "    learn_throughput: 1161.522\n",
      "    learn_time_ms: 1720.157\n",
      "    load_throughput: 58965.384\n",
      "    load_time_ms: 33.884\n",
      "    sample_throughput: 72.107\n",
      "    sample_time_ms: 27708.633\n",
      "    update_time_ms: 7.486\n",
      "  timestamp: 1636447201\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1290708\n",
      "  training_iteration: 646\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   646</td><td style=\"text-align: right;\">         17669.1</td><td style=\"text-align: right;\">1290708</td><td style=\"text-align: right;\">  9.3761</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                4.33</td><td style=\"text-align: right;\">             96.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1292706\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-40-28\n",
      "  done: false\n",
      "  episode_len_mean: 96.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 9.432400000000017\n",
      "  episode_reward_min: 4.330000000000021\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12678\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1249242158163162\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010793706915283608\n",
      "          policy_loss: -0.023923201264724844\n",
      "          total_loss: 0.05356610369469438\n",
      "          vf_explained_var: 0.9836084246635437\n",
      "          vf_loss: 0.07706817920275387\n",
      "    num_agent_steps_sampled: 1292706\n",
      "    num_agent_steps_trained: 1292706\n",
      "    num_steps_sampled: 1292706\n",
      "    num_steps_trained: 1292706\n",
      "  iterations_since_restore: 647\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.81842105263159\n",
      "    ram_util_percent: 31.310526315789485\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428954921407744\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.100881058600844\n",
      "    mean_inference_ms: 2.466441830946825\n",
      "    mean_raw_obs_processing_ms: 2.0634933815593475\n",
      "  time_since_restore: 17695.790763616562\n",
      "  time_this_iter_s: 26.675819873809814\n",
      "  time_total_s: 17695.790763616562\n",
      "  timers:\n",
      "    learn_throughput: 1162.414\n",
      "    learn_time_ms: 1718.837\n",
      "    load_throughput: 59187.105\n",
      "    load_time_ms: 33.757\n",
      "    sample_throughput: 72.224\n",
      "    sample_time_ms: 27664.017\n",
      "    update_time_ms: 7.474\n",
      "  timestamp: 1636447228\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1292706\n",
      "  training_iteration: 647\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   647</td><td style=\"text-align: right;\">         17695.8</td><td style=\"text-align: right;\">1292706</td><td style=\"text-align: right;\">  9.4324</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                4.33</td><td style=\"text-align: right;\">              96.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1294704\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-40-53\n",
      "  done: false\n",
      "  episode_len_mean: 96.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 9.427700000000018\n",
      "  episode_reward_min: 3.910000000000025\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12698\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2907880028088887\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007723855578735686\n",
      "          policy_loss: -0.022666135980259804\n",
      "          total_loss: 0.04298130479153423\n",
      "          vf_explained_var: 0.9864258766174316\n",
      "          vf_loss: 0.07020413687541371\n",
      "    num_agent_steps_sampled: 1294704\n",
      "    num_agent_steps_trained: 1294704\n",
      "    num_steps_sampled: 1294704\n",
      "    num_steps_trained: 1294704\n",
      "  iterations_since_restore: 648\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11666666666666\n",
      "    ram_util_percent: 31.30555555555556\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429075720783529\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.102575114505438\n",
      "    mean_inference_ms: 2.466428962789577\n",
      "    mean_raw_obs_processing_ms: 2.061482084886097\n",
      "  time_since_restore: 17721.00402188301\n",
      "  time_this_iter_s: 25.213258266448975\n",
      "  time_total_s: 17721.00402188301\n",
      "  timers:\n",
      "    learn_throughput: 1163.376\n",
      "    learn_time_ms: 1717.415\n",
      "    load_throughput: 59056.428\n",
      "    load_time_ms: 33.832\n",
      "    sample_throughput: 76.86\n",
      "    sample_time_ms: 25995.193\n",
      "    update_time_ms: 7.824\n",
      "  timestamp: 1636447253\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1294704\n",
      "  training_iteration: 648\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   648</td><td style=\"text-align: right;\">           17721</td><td style=\"text-align: right;\">1294704</td><td style=\"text-align: right;\">  9.4277</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                3.91</td><td style=\"text-align: right;\">             96.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1296702\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-41-20\n",
      "  done: false\n",
      "  episode_len_mean: 97.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 9.327300000000019\n",
      "  episode_reward_min: 3.6700000000000266\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12718\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2250310179733095\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008363750548962283\n",
      "          policy_loss: -0.010835238155864534\n",
      "          total_loss: 0.07507364881180581\n",
      "          vf_explained_var: 0.9895300269126892\n",
      "          vf_loss: 0.08911614694765636\n",
      "    num_agent_steps_sampled: 1296702\n",
      "    num_agent_steps_trained: 1296702\n",
      "    num_steps_sampled: 1296702\n",
      "    num_steps_trained: 1296702\n",
      "  iterations_since_restore: 649\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.21315789473685\n",
      "    ram_util_percent: 31.32105263157896\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430672873784122\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.103566845413813\n",
      "    mean_inference_ms: 2.466688682776692\n",
      "    mean_raw_obs_processing_ms: 2.059417428499072\n",
      "  time_since_restore: 17747.658639907837\n",
      "  time_this_iter_s: 26.65461802482605\n",
      "  time_total_s: 17747.658639907837\n",
      "  timers:\n",
      "    learn_throughput: 1163.485\n",
      "    learn_time_ms: 1717.255\n",
      "    load_throughput: 59133.105\n",
      "    load_time_ms: 33.788\n",
      "    sample_throughput: 81.387\n",
      "    sample_time_ms: 24549.262\n",
      "    update_time_ms: 8.112\n",
      "  timestamp: 1636447280\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1296702\n",
      "  training_iteration: 649\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   649</td><td style=\"text-align: right;\">         17747.7</td><td style=\"text-align: right;\">1296702</td><td style=\"text-align: right;\">  9.3273</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                3.67</td><td style=\"text-align: right;\">             97.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1298700\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-41-46\n",
      "  done: false\n",
      "  episode_len_mean: 96.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.810000000000015\n",
      "  episode_reward_mean: 9.363600000000018\n",
      "  episode_reward_min: 3.6700000000000266\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12739\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1528286894162496\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006842658997132297\n",
      "          policy_loss: -0.09493403202366262\n",
      "          total_loss: -0.03751039652242547\n",
      "          vf_explained_var: 0.9935289025306702\n",
      "          vf_loss: 0.061553505364628065\n",
      "    num_agent_steps_sampled: 1298700\n",
      "    num_agent_steps_trained: 1298700\n",
      "    num_steps_sampled: 1298700\n",
      "    num_steps_trained: 1298700\n",
      "  iterations_since_restore: 650\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.40540540540539\n",
      "    ram_util_percent: 31.275675675675682\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044292129974841776\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.106653449208196\n",
      "    mean_inference_ms: 2.466441860639369\n",
      "    mean_raw_obs_processing_ms: 2.0574093182340714\n",
      "  time_since_restore: 17774.072386980057\n",
      "  time_this_iter_s: 26.41374707221985\n",
      "  time_total_s: 17774.072386980057\n",
      "  timers:\n",
      "    learn_throughput: 1164.316\n",
      "    learn_time_ms: 1716.029\n",
      "    load_throughput: 59298.928\n",
      "    load_time_ms: 33.694\n",
      "    sample_throughput: 81.261\n",
      "    sample_time_ms: 24587.292\n",
      "    update_time_ms: 8.128\n",
      "  timestamp: 1636447306\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1298700\n",
      "  training_iteration: 650\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   650</td><td style=\"text-align: right;\">         17774.1</td><td style=\"text-align: right;\">1298700</td><td style=\"text-align: right;\">  9.3636</td><td style=\"text-align: right;\">               14.81</td><td style=\"text-align: right;\">                3.67</td><td style=\"text-align: right;\">             96.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1300698\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-42-14\n",
      "  done: false\n",
      "  episode_len_mean: 95.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.810000000000015\n",
      "  episode_reward_mean: 9.779300000000017\n",
      "  episode_reward_min: 3.6700000000000266\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 12761\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1736947999114082\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008339263478537194\n",
      "          policy_loss: -0.03534576312771865\n",
      "          total_loss: 0.049221687763929364\n",
      "          vf_explained_var: 0.9916967749595642\n",
      "          vf_loss: 0.08728782530164435\n",
      "    num_agent_steps_sampled: 1300698\n",
      "    num_agent_steps_trained: 1300698\n",
      "    num_steps_sampled: 1300698\n",
      "    num_steps_trained: 1300698\n",
      "  iterations_since_restore: 651\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.19\n",
      "    ram_util_percent: 31.252499999999998\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044276752302090445\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.1108047030723\n",
      "    mean_inference_ms: 2.4661838679046015\n",
      "    mean_raw_obs_processing_ms: 2.055329141321681\n",
      "  time_since_restore: 17801.634271144867\n",
      "  time_this_iter_s: 27.56188416481018\n",
      "  time_total_s: 17801.634271144867\n",
      "  timers:\n",
      "    learn_throughput: 1162.143\n",
      "    learn_time_ms: 1719.238\n",
      "    load_throughput: 59493.04\n",
      "    load_time_ms: 33.584\n",
      "    sample_throughput: 80.592\n",
      "    sample_time_ms: 24791.539\n",
      "    update_time_ms: 8.233\n",
      "  timestamp: 1636447334\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1300698\n",
      "  training_iteration: 651\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   651</td><td style=\"text-align: right;\">         17801.6</td><td style=\"text-align: right;\">1300698</td><td style=\"text-align: right;\">  9.7793</td><td style=\"text-align: right;\">               14.81</td><td style=\"text-align: right;\">                3.67</td><td style=\"text-align: right;\">             95.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1302696\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-42-40\n",
      "  done: false\n",
      "  episode_len_mean: 96.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.810000000000015\n",
      "  episode_reward_mean: 9.54590000000002\n",
      "  episode_reward_min: 3.6700000000000266\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12782\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2212655640783765\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009448861632094125\n",
      "          policy_loss: -0.00847012106151808\n",
      "          total_loss: 0.07940345324043717\n",
      "          vf_explained_var: 0.9870811104774475\n",
      "          vf_loss: 0.08986993974872998\n",
      "    num_agent_steps_sampled: 1302696\n",
      "    num_agent_steps_trained: 1302696\n",
      "    num_steps_sampled: 1302696\n",
      "    num_steps_trained: 1302696\n",
      "  iterations_since_restore: 652\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.29729729729729\n",
      "    ram_util_percent: 31.23243243243243\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442779207176709\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.113622865222688\n",
      "    mean_inference_ms: 2.4661812547293533\n",
      "    mean_raw_obs_processing_ms: 2.053307441517965\n",
      "  time_since_restore: 17827.420379638672\n",
      "  time_this_iter_s: 25.78610849380493\n",
      "  time_total_s: 17827.420379638672\n",
      "  timers:\n",
      "    learn_throughput: 1161.738\n",
      "    learn_time_ms: 1719.837\n",
      "    load_throughput: 59227.346\n",
      "    load_time_ms: 33.734\n",
      "    sample_throughput: 80.958\n",
      "    sample_time_ms: 24679.4\n",
      "    update_time_ms: 7.483\n",
      "  timestamp: 1636447360\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1302696\n",
      "  training_iteration: 652\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   652</td><td style=\"text-align: right;\">         17827.4</td><td style=\"text-align: right;\">1302696</td><td style=\"text-align: right;\">  9.5459</td><td style=\"text-align: right;\">               14.81</td><td style=\"text-align: right;\">                3.67</td><td style=\"text-align: right;\">              96.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1304694\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-43-20\n",
      "  done: false\n",
      "  episode_len_mean: 96.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.810000000000015\n",
      "  episode_reward_mean: 9.450200000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 12801\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3232117352031527\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005881713325121277\n",
      "          policy_loss: -0.08926365006537665\n",
      "          total_loss: -0.010836234059007395\n",
      "          vf_explained_var: 0.9785871505737305\n",
      "          vf_loss: 0.0853001119125457\n",
      "    num_agent_steps_sampled: 1304694\n",
      "    num_agent_steps_trained: 1304694\n",
      "    num_steps_sampled: 1304694\n",
      "    num_steps_trained: 1304694\n",
      "  iterations_since_restore: 653\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.74912280701756\n",
      "    ram_util_percent: 31.23684210526316\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044290868915826634\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.116067135440026\n",
      "    mean_inference_ms: 2.466338087284703\n",
      "    mean_raw_obs_processing_ms: 2.054149852085853\n",
      "  time_since_restore: 17867.69877552986\n",
      "  time_this_iter_s: 40.278395891189575\n",
      "  time_total_s: 17867.69877552986\n",
      "  timers:\n",
      "    learn_throughput: 1161.674\n",
      "    learn_time_ms: 1719.932\n",
      "    load_throughput: 58981.777\n",
      "    load_time_ms: 33.875\n",
      "    sample_throughput: 76.606\n",
      "    sample_time_ms: 26081.488\n",
      "    update_time_ms: 7.354\n",
      "  timestamp: 1636447400\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1304694\n",
      "  training_iteration: 653\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   653</td><td style=\"text-align: right;\">         17867.7</td><td style=\"text-align: right;\">1304694</td><td style=\"text-align: right;\">  9.4502</td><td style=\"text-align: right;\">               14.81</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1306692\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-43-47\n",
      "  done: false\n",
      "  episode_len_mean: 96.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.91000000000001\n",
      "  episode_reward_mean: 9.538500000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12822\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2720087681497847\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00741449143897124\n",
      "          policy_loss: -0.07380073906055519\n",
      "          total_loss: -0.040260686796335945\n",
      "          vf_explained_var: 0.9900240898132324\n",
      "          vf_loss: 0.03824344729738576\n",
      "    num_agent_steps_sampled: 1306692\n",
      "    num_agent_steps_trained: 1306692\n",
      "    num_steps_sampled: 1306692\n",
      "    num_steps_trained: 1306692\n",
      "  iterations_since_restore: 654\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.31794871794872\n",
      "    ram_util_percent: 31.105128205128196\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426504336490773\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.119364515871357\n",
      "    mean_inference_ms: 2.4658651259091022\n",
      "    mean_raw_obs_processing_ms: 2.054776681732149\n",
      "  time_since_restore: 17894.74268770218\n",
      "  time_this_iter_s: 27.043912172317505\n",
      "  time_total_s: 17894.74268770218\n",
      "  timers:\n",
      "    learn_throughput: 1160.634\n",
      "    learn_time_ms: 1721.474\n",
      "    load_throughput: 59237.269\n",
      "    load_time_ms: 33.729\n",
      "    sample_throughput: 76.46\n",
      "    sample_time_ms: 26131.479\n",
      "    update_time_ms: 6.63\n",
      "  timestamp: 1636447427\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1306692\n",
      "  training_iteration: 654\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   654</td><td style=\"text-align: right;\">         17894.7</td><td style=\"text-align: right;\">1306692</td><td style=\"text-align: right;\">  9.5385</td><td style=\"text-align: right;\">               14.91</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1308690\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-44-26\n",
      "  done: false\n",
      "  episode_len_mean: 95.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.91000000000001\n",
      "  episode_reward_mean: 9.097500000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12843\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.266231746332986\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008014454130963324\n",
      "          policy_loss: -0.024224236394677842\n",
      "          total_loss: 0.08861018015692632\n",
      "          vf_explained_var: 0.9852057099342346\n",
      "          vf_loss: 0.11683135044184469\n",
      "    num_agent_steps_sampled: 1308690\n",
      "    num_agent_steps_trained: 1308690\n",
      "    num_steps_sampled: 1308690\n",
      "    num_steps_trained: 1308690\n",
      "  iterations_since_restore: 655\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.49642857142855\n",
      "    ram_util_percent: 31.078571428571426\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044268982335972866\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.119585199361723\n",
      "    mean_inference_ms: 2.4658689557217732\n",
      "    mean_raw_obs_processing_ms: 2.0579649195671887\n",
      "  time_since_restore: 17934.120507478714\n",
      "  time_this_iter_s: 39.377819776535034\n",
      "  time_total_s: 17934.120507478714\n",
      "  timers:\n",
      "    learn_throughput: 1162.002\n",
      "    learn_time_ms: 1719.447\n",
      "    load_throughput: 59084.742\n",
      "    load_time_ms: 33.816\n",
      "    sample_throughput: 72.966\n",
      "    sample_time_ms: 27382.668\n",
      "    update_time_ms: 6.529\n",
      "  timestamp: 1636447466\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1308690\n",
      "  training_iteration: 655\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   655</td><td style=\"text-align: right;\">         17934.1</td><td style=\"text-align: right;\">1308690</td><td style=\"text-align: right;\">  9.0975</td><td style=\"text-align: right;\">               14.91</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             95.47</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1310688\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-45-07\n",
      "  done: false\n",
      "  episode_len_mean: 96.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.91000000000001\n",
      "  episode_reward_mean: 8.745500000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12864\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2231091777483623\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009674737107475918\n",
      "          policy_loss: -0.030291850297223952\n",
      "          total_loss: 0.01824868034039225\n",
      "          vf_explained_var: 0.9923801422119141\n",
      "          vf_loss: 0.050311109210763656\n",
      "    num_agent_steps_sampled: 1310688\n",
      "    num_agent_steps_trained: 1310688\n",
      "    num_steps_sampled: 1310688\n",
      "    num_steps_trained: 1310688\n",
      "  iterations_since_restore: 656\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.87758620689655\n",
      "    ram_util_percent: 31.087931034482757\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428394247650139\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.11840117850107\n",
      "    mean_inference_ms: 2.466026982140657\n",
      "    mean_raw_obs_processing_ms: 2.063830782399115\n",
      "  time_since_restore: 17974.610317468643\n",
      "  time_this_iter_s: 40.4898099899292\n",
      "  time_total_s: 17974.610317468643\n",
      "  timers:\n",
      "    learn_throughput: 1161.66\n",
      "    learn_time_ms: 1719.952\n",
      "    load_throughput: 59011.682\n",
      "    load_time_ms: 33.858\n",
      "    sample_throughput: 69.422\n",
      "    sample_time_ms: 28780.497\n",
      "    update_time_ms: 6.046\n",
      "  timestamp: 1636447507\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1310688\n",
      "  training_iteration: 656\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   656</td><td style=\"text-align: right;\">         17974.6</td><td style=\"text-align: right;\">1310688</td><td style=\"text-align: right;\">  8.7455</td><td style=\"text-align: right;\">               14.91</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1312686\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-45-33\n",
      "  done: false\n",
      "  episode_len_mean: 97.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.91000000000001\n",
      "  episode_reward_mean: 8.531600000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 12883\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2603014963013786\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0100103868016515\n",
      "          policy_loss: -0.04835105804460389\n",
      "          total_loss: 0.009021919894786108\n",
      "          vf_explained_var: 0.9913392663002014\n",
      "          vf_loss: 0.059152568362298465\n",
      "    num_agent_steps_sampled: 1312686\n",
      "    num_agent_steps_trained: 1312686\n",
      "    num_steps_sampled: 1312686\n",
      "    num_steps_trained: 1312686\n",
      "  iterations_since_restore: 657\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95675675675675\n",
      "    ram_util_percent: 31.143243243243248\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429493125233156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.118041119212783\n",
      "    mean_inference_ms: 2.4661072557933905\n",
      "    mean_raw_obs_processing_ms: 2.0691722293683843\n",
      "  time_since_restore: 18000.879551410675\n",
      "  time_this_iter_s: 26.26923394203186\n",
      "  time_total_s: 18000.879551410675\n",
      "  timers:\n",
      "    learn_throughput: 1161.472\n",
      "    learn_time_ms: 1720.23\n",
      "    load_throughput: 58822.097\n",
      "    load_time_ms: 33.967\n",
      "    sample_throughput: 69.524\n",
      "    sample_time_ms: 28738.45\n",
      "    update_time_ms: 7.016\n",
      "  timestamp: 1636447533\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1312686\n",
      "  training_iteration: 657\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   657</td><td style=\"text-align: right;\">         18000.9</td><td style=\"text-align: right;\">1312686</td><td style=\"text-align: right;\">  8.5316</td><td style=\"text-align: right;\">               14.91</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1314684\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-45-59\n",
      "  done: false\n",
      "  episode_len_mean: 97.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.91000000000001\n",
      "  episode_reward_mean: 8.99320000000002\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 12904\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1985279812699272\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006029998791266465\n",
      "          policy_loss: -0.0782765228833471\n",
      "          total_loss: -0.054671440104998296\n",
      "          vf_explained_var: 0.9958929419517517\n",
      "          vf_loss: 0.029070610400023206\n",
      "    num_agent_steps_sampled: 1314684\n",
      "    num_agent_steps_trained: 1314684\n",
      "    num_steps_sampled: 1314684\n",
      "    num_steps_trained: 1314684\n",
      "  iterations_since_restore: 658\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.04594594594596\n",
      "    ram_util_percent: 31.28648648648649\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428359273532708\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.11809422566119\n",
      "    mean_inference_ms: 2.4658524756044624\n",
      "    mean_raw_obs_processing_ms: 2.072350765176985\n",
      "  time_since_restore: 18026.83862566948\n",
      "  time_this_iter_s: 25.95907425880432\n",
      "  time_total_s: 18026.83862566948\n",
      "  timers:\n",
      "    learn_throughput: 1160.864\n",
      "    learn_time_ms: 1721.132\n",
      "    load_throughput: 59939.843\n",
      "    load_time_ms: 33.333\n",
      "    sample_throughput: 69.344\n",
      "    sample_time_ms: 28812.699\n",
      "    update_time_ms: 7.235\n",
      "  timestamp: 1636447559\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1314684\n",
      "  training_iteration: 658\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   658</td><td style=\"text-align: right;\">         18026.8</td><td style=\"text-align: right;\">1314684</td><td style=\"text-align: right;\">  8.9932</td><td style=\"text-align: right;\">               14.91</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             97.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1316682\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-46-26\n",
      "  done: false\n",
      "  episode_len_mean: 97.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000011\n",
      "  episode_reward_mean: 8.782100000000018\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12924\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0812194824218753\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.283687971319471\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.02213853888992628\n",
      "          policy_loss: 0.02219343957092081\n",
      "          total_loss: 0.19020061425509907\n",
      "          vf_explained_var: 0.9804750084877014\n",
      "          vf_loss: 0.15690743662416934\n",
      "    num_agent_steps_sampled: 1316682\n",
      "    num_agent_steps_trained: 1316682\n",
      "    num_steps_sampled: 1316682\n",
      "    num_steps_trained: 1316682\n",
      "  iterations_since_restore: 659\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.38974358974359\n",
      "    ram_util_percent: 31.34871794871795\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443117650349344\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.116798717427947\n",
      "    mean_inference_ms: 2.466216496798434\n",
      "    mean_raw_obs_processing_ms: 2.0752669586737533\n",
      "  time_since_restore: 18053.970625400543\n",
      "  time_this_iter_s: 27.131999731063843\n",
      "  time_total_s: 18053.970625400543\n",
      "  timers:\n",
      "    learn_throughput: 1160.784\n",
      "    learn_time_ms: 1721.25\n",
      "    load_throughput: 59430.555\n",
      "    load_time_ms: 33.619\n",
      "    sample_throughput: 69.23\n",
      "    sample_time_ms: 28860.265\n",
      "    update_time_ms: 6.842\n",
      "  timestamp: 1636447586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1316682\n",
      "  training_iteration: 659\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   659</td><td style=\"text-align: right;\">           18054</td><td style=\"text-align: right;\">1316682</td><td style=\"text-align: right;\">  8.7821</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">             97.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1318680\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-46-54\n",
      "  done: false\n",
      "  episode_len_mean: 98.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.105600000000019\n",
      "  episode_reward_min: 3.3400000000000247\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12944\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.217301338627225\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006622773297336591\n",
      "          policy_loss: -0.034176618641331084\n",
      "          total_loss: 0.05959947474655651\n",
      "          vf_explained_var: 0.9819309711456299\n",
      "          vf_loss: 0.09520809856199083\n",
      "    num_agent_steps_sampled: 1318680\n",
      "    num_agent_steps_trained: 1318680\n",
      "    num_steps_sampled: 1318680\n",
      "    num_steps_trained: 1318680\n",
      "  iterations_since_restore: 660\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72051282051282\n",
      "    ram_util_percent: 31.392307692307693\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430944312814738\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.118603065458696\n",
      "    mean_inference_ms: 2.46609717945874\n",
      "    mean_raw_obs_processing_ms: 2.0752099761564633\n",
      "  time_since_restore: 18081.37317633629\n",
      "  time_this_iter_s: 27.40255093574524\n",
      "  time_total_s: 18081.37317633629\n",
      "  timers:\n",
      "    learn_throughput: 1159.668\n",
      "    learn_time_ms: 1722.907\n",
      "    load_throughput: 59390.88\n",
      "    load_time_ms: 33.642\n",
      "    sample_throughput: 68.998\n",
      "    sample_time_ms: 28957.532\n",
      "    update_time_ms: 6.524\n",
      "  timestamp: 1636447614\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1318680\n",
      "  training_iteration: 660\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   660</td><td style=\"text-align: right;\">         18081.4</td><td style=\"text-align: right;\">1318680</td><td style=\"text-align: right;\">  9.1056</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                3.34</td><td style=\"text-align: right;\">             98.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1320678\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-47-20\n",
      "  done: false\n",
      "  episode_len_mean: 99.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.048500000000018\n",
      "  episode_reward_min: 2.500000000000025\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12964\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2488238760403225\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007382721854620309\n",
      "          policy_loss: -0.02345167566977796\n",
      "          total_loss: 0.05038989078076113\n",
      "          vf_explained_var: 0.9833713173866272\n",
      "          vf_loss: 0.07435629074240015\n",
      "    num_agent_steps_sampled: 1320678\n",
      "    num_agent_steps_trained: 1320678\n",
      "    num_steps_sampled: 1320678\n",
      "    num_steps_trained: 1320678\n",
      "  iterations_since_restore: 661\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5027027027027\n",
      "    ram_util_percent: 31.424324324324324\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431058373455359\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.12015100374564\n",
      "    mean_inference_ms: 2.466076046070796\n",
      "    mean_raw_obs_processing_ms: 2.0731184440727715\n",
      "  time_since_restore: 18107.149307012558\n",
      "  time_this_iter_s: 25.77613067626953\n",
      "  time_total_s: 18107.149307012558\n",
      "  timers:\n",
      "    learn_throughput: 1160.094\n",
      "    learn_time_ms: 1722.274\n",
      "    load_throughput: 59383.346\n",
      "    load_time_ms: 33.646\n",
      "    sample_throughput: 69.424\n",
      "    sample_time_ms: 28779.529\n",
      "    update_time_ms: 6.826\n",
      "  timestamp: 1636447640\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1320678\n",
      "  training_iteration: 661\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   661</td><td style=\"text-align: right;\">         18107.1</td><td style=\"text-align: right;\">1320678</td><td style=\"text-align: right;\">  9.0485</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">             99.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1322676\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-47-46\n",
      "  done: false\n",
      "  episode_len_mean: 99.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.12080000000002\n",
      "  episode_reward_min: 2.500000000000025\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 12984\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3000020390465146\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00687733346060433\n",
      "          policy_loss: -0.021917596388430823\n",
      "          total_loss: 0.04478064484539486\n",
      "          vf_explained_var: 0.9868665337562561\n",
      "          vf_loss: 0.06854440006649211\n",
      "    num_agent_steps_sampled: 1322676\n",
      "    num_agent_steps_trained: 1322676\n",
      "    num_steps_sampled: 1322676\n",
      "    num_steps_trained: 1322676\n",
      "  iterations_since_restore: 662\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.82105263157895\n",
      "    ram_util_percent: 31.457894736842107\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431448348687634\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.120659279385965\n",
      "    mean_inference_ms: 2.4661316312390036\n",
      "    mean_raw_obs_processing_ms: 2.0709762293616993\n",
      "  time_since_restore: 18133.335416793823\n",
      "  time_this_iter_s: 26.18610978126526\n",
      "  time_total_s: 18133.335416793823\n",
      "  timers:\n",
      "    learn_throughput: 1161.513\n",
      "    learn_time_ms: 1720.171\n",
      "    load_throughput: 59592.714\n",
      "    load_time_ms: 33.528\n",
      "    sample_throughput: 69.323\n",
      "    sample_time_ms: 28821.62\n",
      "    update_time_ms: 7.183\n",
      "  timestamp: 1636447666\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1322676\n",
      "  training_iteration: 662\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   662</td><td style=\"text-align: right;\">         18133.3</td><td style=\"text-align: right;\">1322676</td><td style=\"text-align: right;\">  9.1208</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">             99.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1324674\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-48-12\n",
      "  done: false\n",
      "  episode_len_mean: 100.76\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 9.039500000000016\n",
      "  episode_reward_min: 2.500000000000025\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 13003\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.309872573330289\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007036717105510712\n",
      "          policy_loss: -0.03862335140417729\n",
      "          total_loss: 0.03677923939235154\n",
      "          vf_explained_var: 0.9878404140472412\n",
      "          vf_loss: 0.07708896449101822\n",
      "    num_agent_steps_sampled: 1324674\n",
      "    num_agent_steps_trained: 1324674\n",
      "    num_steps_sampled: 1324674\n",
      "    num_steps_trained: 1324674\n",
      "  iterations_since_restore: 663\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.15405405405404\n",
      "    ram_util_percent: 31.443243243243245\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044325185951336936\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.121792595090543\n",
      "    mean_inference_ms: 2.4662700841948935\n",
      "    mean_raw_obs_processing_ms: 2.06906397904188\n",
      "  time_since_restore: 18159.35334920883\n",
      "  time_this_iter_s: 26.017932415008545\n",
      "  time_total_s: 18159.35334920883\n",
      "  timers:\n",
      "    learn_throughput: 1163.25\n",
      "    learn_time_ms: 1717.602\n",
      "    load_throughput: 59782.189\n",
      "    load_time_ms: 33.421\n",
      "    sample_throughput: 72.925\n",
      "    sample_time_ms: 27397.827\n",
      "    update_time_ms: 7.703\n",
      "  timestamp: 1636447692\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1324674\n",
      "  training_iteration: 663\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   663</td><td style=\"text-align: right;\">         18159.4</td><td style=\"text-align: right;\">1324674</td><td style=\"text-align: right;\">  9.0395</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">            100.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1326672\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-48-37\n",
      "  done: false\n",
      "  episode_len_mean: 101.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 9.019100000000018\n",
      "  episode_reward_min: 2.500000000000025\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13023\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3106338330677578\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00785424343105336\n",
      "          policy_loss: -0.013927834232648213\n",
      "          total_loss: 0.09010957616070907\n",
      "          vf_explained_var: 0.9777507781982422\n",
      "          vf_loss: 0.10440550914832523\n",
      "    num_agent_steps_sampled: 1326672\n",
      "    num_agent_steps_trained: 1326672\n",
      "    num_steps_sampled: 1326672\n",
      "    num_steps_trained: 1326672\n",
      "  iterations_since_restore: 664\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.475\n",
      "    ram_util_percent: 31.40277777777778\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431209435353214\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.122996196672176\n",
      "    mean_inference_ms: 2.4660641273584663\n",
      "    mean_raw_obs_processing_ms: 2.066935348508814\n",
      "  time_since_restore: 18184.841247081757\n",
      "  time_this_iter_s: 25.487897872924805\n",
      "  time_total_s: 18184.841247081757\n",
      "  timers:\n",
      "    learn_throughput: 1163.265\n",
      "    learn_time_ms: 1717.579\n",
      "    load_throughput: 59519.745\n",
      "    load_time_ms: 33.569\n",
      "    sample_throughput: 73.343\n",
      "    sample_time_ms: 27241.784\n",
      "    update_time_ms: 8.014\n",
      "  timestamp: 1636447717\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1326672\n",
      "  training_iteration: 664\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   664</td><td style=\"text-align: right;\">         18184.8</td><td style=\"text-align: right;\">1326672</td><td style=\"text-align: right;\">  9.0191</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">            101.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1328670\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-49-03\n",
      "  done: false\n",
      "  episode_len_mean: 100.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 9.110300000000018\n",
      "  episode_reward_min: 2.500000000000025\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 13044\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2326831601914905\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005925884406240395\n",
      "          policy_loss: -0.0052621138947350635\n",
      "          total_loss: 0.052121062461464175\n",
      "          vf_explained_var: 0.9938401579856873\n",
      "          vf_loss: 0.060099235416523046\n",
      "    num_agent_steps_sampled: 1328670\n",
      "    num_agent_steps_trained: 1328670\n",
      "    num_steps_sampled: 1328670\n",
      "    num_steps_trained: 1328670\n",
      "  iterations_since_restore: 665\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.02972972972972\n",
      "    ram_util_percent: 31.383783783783784\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0443220946924796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.123501750391224\n",
      "    mean_inference_ms: 2.4662236389009706\n",
      "    mean_raw_obs_processing_ms: 2.0648036047178966\n",
      "  time_since_restore: 18210.669934272766\n",
      "  time_this_iter_s: 25.82868719100952\n",
      "  time_total_s: 18210.669934272766\n",
      "  timers:\n",
      "    learn_throughput: 1162.188\n",
      "    learn_time_ms: 1719.17\n",
      "    load_throughput: 59707.309\n",
      "    load_time_ms: 33.463\n",
      "    sample_throughput: 77.189\n",
      "    sample_time_ms: 25884.384\n",
      "    update_time_ms: 8.856\n",
      "  timestamp: 1636447743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1328670\n",
      "  training_iteration: 665\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   665</td><td style=\"text-align: right;\">         18210.7</td><td style=\"text-align: right;\">1328670</td><td style=\"text-align: right;\">  9.1103</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">            100.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1330668\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-49-27\n",
      "  done: false\n",
      "  episode_len_mean: 101.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 8.97250000000002\n",
      "  episode_reward_min: 3.150000000000014\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 13062\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3993623994645619\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0073951318938820215\n",
      "          policy_loss: -0.05562752818777448\n",
      "          total_loss: 0.015461691021032276\n",
      "          vf_explained_var: 0.9811099171638489\n",
      "          vf_loss: 0.07308919964624302\n",
      "    num_agent_steps_sampled: 1330668\n",
      "    num_agent_steps_trained: 1330668\n",
      "    num_steps_sampled: 1330668\n",
      "    num_steps_trained: 1330668\n",
      "  iterations_since_restore: 666\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.70606060606062\n",
      "    ram_util_percent: 31.324242424242424\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044316344724325905\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.124227520517106\n",
      "    mean_inference_ms: 2.46612850848806\n",
      "    mean_raw_obs_processing_ms: 2.0630407448840034\n",
      "  time_since_restore: 18234.06334376335\n",
      "  time_this_iter_s: 23.393409490585327\n",
      "  time_total_s: 18234.06334376335\n",
      "  timers:\n",
      "    learn_throughput: 1163.329\n",
      "    learn_time_ms: 1717.484\n",
      "    load_throughput: 59628.841\n",
      "    load_time_ms: 33.507\n",
      "    sample_throughput: 82.643\n",
      "    sample_time_ms: 24176.37\n",
      "    update_time_ms: 8.77\n",
      "  timestamp: 1636447767\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1330668\n",
      "  training_iteration: 666\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   666</td><td style=\"text-align: right;\">         18234.1</td><td style=\"text-align: right;\">1330668</td><td style=\"text-align: right;\">  8.9725</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">                3.15</td><td style=\"text-align: right;\">            101.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1332666\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-49-52\n",
      "  done: false\n",
      "  episode_len_mean: 101.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.730000000000013\n",
      "  episode_reward_mean: 8.793000000000019\n",
      "  episode_reward_min: 3.150000000000014\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13082\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3236934281530834\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006821052917090314\n",
      "          policy_loss: -0.016592174999061085\n",
      "          total_loss: 0.05053114593029022\n",
      "          vf_explained_var: 0.988635241985321\n",
      "          vf_loss: 0.06929767470629443\n",
      "    num_agent_steps_sampled: 1332666\n",
      "    num_agent_steps_trained: 1332666\n",
      "    num_steps_sampled: 1332666\n",
      "    num_steps_trained: 1332666\n",
      "  iterations_since_restore: 667\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03611111111111\n",
      "    ram_util_percent: 31.302777777777788\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431454526459255\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.124003674387932\n",
      "    mean_inference_ms: 2.4661203257811657\n",
      "    mean_raw_obs_processing_ms: 2.0609458922822537\n",
      "  time_since_restore: 18259.18187022209\n",
      "  time_this_iter_s: 25.118526458740234\n",
      "  time_total_s: 18259.18187022209\n",
      "  timers:\n",
      "    learn_throughput: 1162.624\n",
      "    learn_time_ms: 1718.526\n",
      "    load_throughput: 59763.174\n",
      "    load_time_ms: 33.432\n",
      "    sample_throughput: 83.039\n",
      "    sample_time_ms: 24061.01\n",
      "    update_time_ms: 8.244\n",
      "  timestamp: 1636447792\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1332666\n",
      "  training_iteration: 667\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   667</td><td style=\"text-align: right;\">         18259.2</td><td style=\"text-align: right;\">1332666</td><td style=\"text-align: right;\">   8.793</td><td style=\"text-align: right;\">               14.73</td><td style=\"text-align: right;\">                3.15</td><td style=\"text-align: right;\">            101.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1334664\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-50-17\n",
      "  done: false\n",
      "  episode_len_mean: 102.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.646800000000018\n",
      "  episode_reward_min: 3.150000000000014\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13102\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3411377725147067\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011304285371534713\n",
      "          policy_loss: -0.04991903024769965\n",
      "          total_loss: 0.07972798455683958\n",
      "          vf_explained_var: 0.9810722470283508\n",
      "          vf_loss: 0.12472477262573582\n",
      "    num_agent_steps_sampled: 1334664\n",
      "    num_agent_steps_trained: 1334664\n",
      "    num_steps_sampled: 1334664\n",
      "    num_steps_trained: 1334664\n",
      "  iterations_since_restore: 668\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.35\n",
      "    ram_util_percent: 31.286111111111122\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044316127624540805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.122800402983493\n",
      "    mean_inference_ms: 2.4661909450271042\n",
      "    mean_raw_obs_processing_ms: 2.058777777384027\n",
      "  time_since_restore: 18284.293305397034\n",
      "  time_this_iter_s: 25.111435174942017\n",
      "  time_total_s: 18284.293305397034\n",
      "  timers:\n",
      "    learn_throughput: 1163.237\n",
      "    learn_time_ms: 1717.621\n",
      "    load_throughput: 58744.824\n",
      "    load_time_ms: 34.012\n",
      "    sample_throughput: 83.331\n",
      "    sample_time_ms: 23976.576\n",
      "    update_time_ms: 8.163\n",
      "  timestamp: 1636447817\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1334664\n",
      "  training_iteration: 668\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   668</td><td style=\"text-align: right;\">         18284.3</td><td style=\"text-align: right;\">1334664</td><td style=\"text-align: right;\">  8.6468</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                3.15</td><td style=\"text-align: right;\">            102.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1336662\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-50-41\n",
      "  done: false\n",
      "  episode_len_mean: 102.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.820000000000011\n",
      "  episode_reward_mean: 8.570500000000019\n",
      "  episode_reward_min: 3.150000000000014\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 13120\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2255451611110142\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006526733071534407\n",
      "          policy_loss: -0.08858051839328948\n",
      "          total_loss: -0.02819291190022514\n",
      "          vf_explained_var: 0.9873955845832825\n",
      "          vf_loss: 0.06205781056944813\n",
      "    num_agent_steps_sampled: 1336662\n",
      "    num_agent_steps_trained: 1336662\n",
      "    num_steps_sampled: 1336662\n",
      "    num_steps_trained: 1336662\n",
      "  iterations_since_restore: 669\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99411764705881\n",
      "    ram_util_percent: 31.25\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044305087356591694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.123445879080265\n",
      "    mean_inference_ms: 2.466018597851104\n",
      "    mean_raw_obs_processing_ms: 2.0571079910497665\n",
      "  time_since_restore: 18308.218639612198\n",
      "  time_this_iter_s: 23.925334215164185\n",
      "  time_total_s: 18308.218639612198\n",
      "  timers:\n",
      "    learn_throughput: 1162.772\n",
      "    learn_time_ms: 1718.308\n",
      "    load_throughput: 59119.88\n",
      "    load_time_ms: 33.796\n",
      "    sample_throughput: 84.463\n",
      "    sample_time_ms: 23655.207\n",
      "    update_time_ms: 8.722\n",
      "  timestamp: 1636447841\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1336662\n",
      "  training_iteration: 669\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   669</td><td style=\"text-align: right;\">         18308.2</td><td style=\"text-align: right;\">1336662</td><td style=\"text-align: right;\">  8.5705</td><td style=\"text-align: right;\">               14.82</td><td style=\"text-align: right;\">                3.15</td><td style=\"text-align: right;\">            102.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1338660\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-51-06\n",
      "  done: false\n",
      "  episode_len_mean: 102.83\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.820000000000011\n",
      "  episode_reward_mean: 8.415800000000019\n",
      "  episode_reward_min: 3.150000000000014\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13140\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3322919340360733\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007925814567907051\n",
      "          policy_loss: -0.01688239292374679\n",
      "          total_loss: 0.11659631439085517\n",
      "          vf_explained_var: 0.9841570258140564\n",
      "          vf_loss: 0.13394730704880897\n",
      "    num_agent_steps_sampled: 1338660\n",
      "    num_agent_steps_trained: 1338660\n",
      "    num_steps_sampled: 1338660\n",
      "    num_steps_trained: 1338660\n",
      "  iterations_since_restore: 670\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96666666666665\n",
      "    ram_util_percent: 31.224999999999998\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044305660523999604\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.122090926572692\n",
      "    mean_inference_ms: 2.4660687323512356\n",
      "    mean_raw_obs_processing_ms: 2.054923937298045\n",
      "  time_since_restore: 18333.38681769371\n",
      "  time_this_iter_s: 25.16817808151245\n",
      "  time_total_s: 18333.38681769371\n",
      "  timers:\n",
      "    learn_throughput: 1163.75\n",
      "    learn_time_ms: 1716.864\n",
      "    load_throughput: 59003.206\n",
      "    load_time_ms: 33.863\n",
      "    sample_throughput: 85.265\n",
      "    sample_time_ms: 23432.807\n",
      "    update_time_ms: 9.404\n",
      "  timestamp: 1636447866\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1338660\n",
      "  training_iteration: 670\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   670</td><td style=\"text-align: right;\">         18333.4</td><td style=\"text-align: right;\">1338660</td><td style=\"text-align: right;\">  8.4158</td><td style=\"text-align: right;\">               14.82</td><td style=\"text-align: right;\">                3.15</td><td style=\"text-align: right;\">            102.83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1340658\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-51-33\n",
      "  done: false\n",
      "  episode_len_mean: 101.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.820000000000011\n",
      "  episode_reward_mean: 8.661200000000019\n",
      "  episode_reward_min: 3.7300000000000244\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 13161\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.181570570525669\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006885744160275978\n",
      "          policy_loss: -0.050683824629301114\n",
      "          total_loss: 0.042643861135556585\n",
      "          vf_explained_var: 0.9860342741012573\n",
      "          vf_loss: 0.0939758895630283\n",
      "    num_agent_steps_sampled: 1340658\n",
      "    num_agent_steps_trained: 1340658\n",
      "    num_steps_sampled: 1340658\n",
      "    num_steps_trained: 1340658\n",
      "  iterations_since_restore: 671\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1578947368421\n",
      "    ram_util_percent: 31.189473684210522\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432324754378074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.120666563109342\n",
      "    mean_inference_ms: 2.466376936988068\n",
      "    mean_raw_obs_processing_ms: 2.0525926938726644\n",
      "  time_since_restore: 18360.08391880989\n",
      "  time_this_iter_s: 26.69710111618042\n",
      "  time_total_s: 18360.08391880989\n",
      "  timers:\n",
      "    learn_throughput: 1164.383\n",
      "    learn_time_ms: 1715.93\n",
      "    load_throughput: 58947.383\n",
      "    load_time_ms: 33.895\n",
      "    sample_throughput: 84.93\n",
      "    sample_time_ms: 23525.354\n",
      "    update_time_ms: 9.811\n",
      "  timestamp: 1636447893\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1340658\n",
      "  training_iteration: 671\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   671</td><td style=\"text-align: right;\">         18360.1</td><td style=\"text-align: right;\">1340658</td><td style=\"text-align: right;\">  8.6612</td><td style=\"text-align: right;\">               14.82</td><td style=\"text-align: right;\">                3.73</td><td style=\"text-align: right;\">            101.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1342656\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-52-15\n",
      "  done: false\n",
      "  episode_len_mean: 99.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.820000000000011\n",
      "  episode_reward_mean: 9.065400000000016\n",
      "  episode_reward_min: 3.7300000000000244\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 13183\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2292774699983142\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006423010271734597\n",
      "          policy_loss: 0.0008458766908872696\n",
      "          total_loss: 0.07683403760283476\n",
      "          vf_explained_var: 0.9886442422866821\n",
      "          vf_loss: 0.07786391145505366\n",
      "    num_agent_steps_sampled: 1342656\n",
      "    num_agent_steps_trained: 1342656\n",
      "    num_steps_sampled: 1342656\n",
      "    num_steps_trained: 1342656\n",
      "  iterations_since_restore: 672\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.51833333333335\n",
      "    ram_util_percent: 31.088333333333335\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430497971840022\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.121866643127678\n",
      "    mean_inference_ms: 2.466062663104628\n",
      "    mean_raw_obs_processing_ms: 2.0532995042792503\n",
      "  time_since_restore: 18401.839700460434\n",
      "  time_this_iter_s: 41.75578165054321\n",
      "  time_total_s: 18401.839700460434\n",
      "  timers:\n",
      "    learn_throughput: 1164.148\n",
      "    learn_time_ms: 1716.277\n",
      "    load_throughput: 58391.376\n",
      "    load_time_ms: 34.217\n",
      "    sample_throughput: 79.662\n",
      "    sample_time_ms: 25081.076\n",
      "    update_time_ms: 10.137\n",
      "  timestamp: 1636447935\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1342656\n",
      "  training_iteration: 672\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   672</td><td style=\"text-align: right;\">         18401.8</td><td style=\"text-align: right;\">1342656</td><td style=\"text-align: right;\">  9.0654</td><td style=\"text-align: right;\">               14.82</td><td style=\"text-align: right;\">                3.73</td><td style=\"text-align: right;\">             99.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1344654\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-52-55\n",
      "  done: false\n",
      "  episode_len_mean: 96.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.820000000000011\n",
      "  episode_reward_mean: 9.410900000000018\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 13205\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1719917490368799\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005535530451353335\n",
      "          policy_loss: -0.03552097033132755\n",
      "          total_loss: 0.0471725614386655\n",
      "          vf_explained_var: 0.9876457452774048\n",
      "          vf_loss: 0.08543576400372244\n",
      "    num_agent_steps_sampled: 1344654\n",
      "    num_agent_steps_trained: 1344654\n",
      "    num_steps_sampled: 1344654\n",
      "    num_steps_trained: 1344654\n",
      "  iterations_since_restore: 673\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.57368421052631\n",
      "    ram_util_percent: 31.033333333333335\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427583984664468\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.123739626861347\n",
      "    mean_inference_ms: 2.4655638851520627\n",
      "    mean_raw_obs_processing_ms: 2.056511332460677\n",
      "  time_since_restore: 18441.96825361252\n",
      "  time_this_iter_s: 40.12855315208435\n",
      "  time_total_s: 18441.96825361252\n",
      "  timers:\n",
      "    learn_throughput: 1161.344\n",
      "    learn_time_ms: 1720.421\n",
      "    load_throughput: 58478.982\n",
      "    load_time_ms: 34.166\n",
      "    sample_throughput: 75.43\n",
      "    sample_time_ms: 26488.297\n",
      "    update_time_ms: 9.621\n",
      "  timestamp: 1636447975\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1344654\n",
      "  training_iteration: 673\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   673</td><td style=\"text-align: right;\">           18442</td><td style=\"text-align: right;\">1344654</td><td style=\"text-align: right;\">  9.4109</td><td style=\"text-align: right;\">               14.82</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">             96.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1346652\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-53-38\n",
      "  done: false\n",
      "  episode_len_mean: 92.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000012\n",
      "  episode_reward_mean: 9.699200000000015\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 13228\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0941498617331187\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006146314835217052\n",
      "          policy_loss: -0.043700874880665826\n",
      "          total_loss: 0.08256608984832253\n",
      "          vf_explained_var: 0.98946613073349\n",
      "          vf_loss: 0.1272401882424241\n",
      "    num_agent_steps_sampled: 1346652\n",
      "    num_agent_steps_trained: 1346652\n",
      "    num_steps_sampled: 1346652\n",
      "    num_steps_trained: 1346652\n",
      "  iterations_since_restore: 674\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.52741935483873\n",
      "    ram_util_percent: 31.064516129032253\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044258733674004666\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.126307127983186\n",
      "    mean_inference_ms: 2.4652301491970148\n",
      "    mean_raw_obs_processing_ms: 2.06265977911092\n",
      "  time_since_restore: 18484.928368091583\n",
      "  time_this_iter_s: 42.96011447906494\n",
      "  time_total_s: 18484.928368091583\n",
      "  timers:\n",
      "    learn_throughput: 1161.272\n",
      "    learn_time_ms: 1720.527\n",
      "    load_throughput: 58483.757\n",
      "    load_time_ms: 34.163\n",
      "    sample_throughput: 70.764\n",
      "    sample_time_ms: 28234.715\n",
      "    update_time_ms: 10.218\n",
      "  timestamp: 1636448018\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1346652\n",
      "  training_iteration: 674\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   674</td><td style=\"text-align: right;\">         18484.9</td><td style=\"text-align: right;\">1346652</td><td style=\"text-align: right;\">  9.6992</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             92.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1348650\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-54-05\n",
      "  done: false\n",
      "  episode_len_mean: 91.69\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000012\n",
      "  episode_reward_mean: 9.886700000000015\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 13249\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.204881107239496\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0051269311498880685\n",
      "          policy_loss: -0.004397079117950939\n",
      "          total_loss: 0.053660883541618076\n",
      "          vf_explained_var: 0.9896718263626099\n",
      "          vf_loss: 0.06179176568541499\n",
      "    num_agent_steps_sampled: 1348650\n",
      "    num_agent_steps_trained: 1348650\n",
      "    num_steps_sampled: 1348650\n",
      "    num_steps_trained: 1348650\n",
      "  iterations_since_restore: 675\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9421052631579\n",
      "    ram_util_percent: 31.11842105263158\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044253585497980176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.128750701711397\n",
      "    mean_inference_ms: 2.465082213969583\n",
      "    mean_raw_obs_processing_ms: 2.068347911246001\n",
      "  time_since_restore: 18512.11199069023\n",
      "  time_this_iter_s: 27.18362259864807\n",
      "  time_total_s: 18512.11199069023\n",
      "  timers:\n",
      "    learn_throughput: 1161.403\n",
      "    learn_time_ms: 1720.333\n",
      "    load_throughput: 58429.157\n",
      "    load_time_ms: 34.195\n",
      "    sample_throughput: 70.424\n",
      "    sample_time_ms: 28370.966\n",
      "    update_time_ms: 9.625\n",
      "  timestamp: 1636448045\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1348650\n",
      "  training_iteration: 675\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   675</td><td style=\"text-align: right;\">         18512.1</td><td style=\"text-align: right;\">1348650</td><td style=\"text-align: right;\">  9.8867</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             91.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1350648\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-54-32\n",
      "  done: false\n",
      "  episode_len_mean: 91.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.780000000000012\n",
      "  episode_reward_mean: 10.130400000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13269\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.172662498553594\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006093419790985352\n",
      "          policy_loss: -0.06490945321995588\n",
      "          total_loss: 0.008977502061142808\n",
      "          vf_explained_var: 0.9918490648269653\n",
      "          vf_loss: 0.07573109403075207\n",
      "    num_agent_steps_sampled: 1350648\n",
      "    num_agent_steps_trained: 1350648\n",
      "    num_steps_sampled: 1350648\n",
      "    num_steps_trained: 1350648\n",
      "  iterations_since_restore: 676\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.33846153846154\n",
      "    ram_util_percent: 31.294871794871796\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425726365007433\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.12986678179004\n",
      "    mean_inference_ms: 2.4650967084036868\n",
      "    mean_raw_obs_processing_ms: 2.073559450215175\n",
      "  time_since_restore: 18539.097580432892\n",
      "  time_this_iter_s: 26.985589742660522\n",
      "  time_total_s: 18539.097580432892\n",
      "  timers:\n",
      "    learn_throughput: 1161.149\n",
      "    learn_time_ms: 1720.709\n",
      "    load_throughput: 58047.986\n",
      "    load_time_ms: 34.42\n",
      "    sample_throughput: 69.547\n",
      "    sample_time_ms: 28728.958\n",
      "    update_time_ms: 10.444\n",
      "  timestamp: 1636448072\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1350648\n",
      "  training_iteration: 676\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   676</td><td style=\"text-align: right;\">         18539.1</td><td style=\"text-align: right;\">1350648</td><td style=\"text-align: right;\"> 10.1304</td><td style=\"text-align: right;\">               14.78</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             91.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1352646\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-54-59\n",
      "  done: false\n",
      "  episode_len_mean: 92.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000013\n",
      "  episode_reward_mean: 10.044500000000015\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 13292\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2305462769099644\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008798772155506064\n",
      "          policy_loss: -0.02353605663492566\n",
      "          total_loss: 0.07284996682955396\n",
      "          vf_explained_var: 0.9849663376808167\n",
      "          vf_loss: 0.09442138138803698\n",
      "    num_agent_steps_sampled: 1352646\n",
      "    num_agent_steps_trained: 1352646\n",
      "    num_steps_sampled: 1352646\n",
      "    num_steps_trained: 1352646\n",
      "  iterations_since_restore: 677\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33076923076923\n",
      "    ram_util_percent: 31.376923076923084\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427031488397325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.132354384020463\n",
      "    mean_inference_ms: 2.465238263362739\n",
      "    mean_raw_obs_processing_ms: 2.076153671793808\n",
      "  time_since_restore: 18566.228056669235\n",
      "  time_this_iter_s: 27.130476236343384\n",
      "  time_total_s: 18566.228056669235\n",
      "  timers:\n",
      "    learn_throughput: 1162.07\n",
      "    learn_time_ms: 1719.346\n",
      "    load_throughput: 57865.332\n",
      "    load_time_ms: 34.528\n",
      "    sample_throughput: 69.061\n",
      "    sample_time_ms: 28930.935\n",
      "    update_time_ms: 10.891\n",
      "  timestamp: 1636448099\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1352646\n",
      "  training_iteration: 677\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   677</td><td style=\"text-align: right;\">         18566.2</td><td style=\"text-align: right;\">1352646</td><td style=\"text-align: right;\"> 10.0445</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             92.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1354644\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-55-25\n",
      "  done: false\n",
      "  episode_len_mean: 93.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.603800000000017\n",
      "  episode_reward_min: 4.6600000000000215\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 13313\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.263250206198011\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005873614222542295\n",
      "          policy_loss: -0.04307774069408576\n",
      "          total_loss: 0.01539721806489286\n",
      "          vf_explained_var: 0.9898597598075867\n",
      "          vf_loss: 0.061581462022981474\n",
      "    num_agent_steps_sampled: 1354644\n",
      "    num_agent_steps_trained: 1354644\n",
      "    num_steps_sampled: 1354644\n",
      "    num_steps_trained: 1354644\n",
      "  iterations_since_restore: 678\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.22222222222221\n",
      "    ram_util_percent: 31.39166666666667\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425992653936186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.1348791186627\n",
      "    mean_inference_ms: 2.465063339998237\n",
      "    mean_raw_obs_processing_ms: 2.074181211186212\n",
      "  time_since_restore: 18591.900774478912\n",
      "  time_this_iter_s: 25.672717809677124\n",
      "  time_total_s: 18591.900774478912\n",
      "  timers:\n",
      "    learn_throughput: 1161.996\n",
      "    learn_time_ms: 1719.455\n",
      "    load_throughput: 58009.251\n",
      "    load_time_ms: 34.443\n",
      "    sample_throughput: 68.927\n",
      "    sample_time_ms: 28987.134\n",
      "    update_time_ms: 10.746\n",
      "  timestamp: 1636448125\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1354644\n",
      "  training_iteration: 678\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   678</td><td style=\"text-align: right;\">         18591.9</td><td style=\"text-align: right;\">1354644</td><td style=\"text-align: right;\">  9.6038</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                4.66</td><td style=\"text-align: right;\">             93.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1356642\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-55-51\n",
      "  done: false\n",
      "  episode_len_mean: 95.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.293300000000016\n",
      "  episode_reward_min: 4.340000000000023\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13333\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2813897961661929\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0059628203831454335\n",
      "          policy_loss: -0.08009058402052947\n",
      "          total_loss: 0.003362820865142913\n",
      "          vf_explained_var: 0.9872331619262695\n",
      "          vf_loss: 0.08659662575948807\n",
      "    num_agent_steps_sampled: 1356642\n",
      "    num_agent_steps_trained: 1356642\n",
      "    num_steps_sampled: 1356642\n",
      "    num_steps_trained: 1356642\n",
      "  iterations_since_restore: 679\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.22972972972973\n",
      "    ram_util_percent: 31.440540540540532\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426076002618034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.13663572205278\n",
      "    mean_inference_ms: 2.465076697056866\n",
      "    mean_raw_obs_processing_ms: 2.072301008976637\n",
      "  time_since_restore: 18617.595165729523\n",
      "  time_this_iter_s: 25.69439125061035\n",
      "  time_total_s: 18617.595165729523\n",
      "  timers:\n",
      "    learn_throughput: 1162.54\n",
      "    learn_time_ms: 1718.65\n",
      "    load_throughput: 58099.378\n",
      "    load_time_ms: 34.389\n",
      "    sample_throughput: 68.508\n",
      "    sample_time_ms: 29164.658\n",
      "    update_time_ms: 10.905\n",
      "  timestamp: 1636448151\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1356642\n",
      "  training_iteration: 679\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   679</td><td style=\"text-align: right;\">         18617.6</td><td style=\"text-align: right;\">1356642</td><td style=\"text-align: right;\">  9.2933</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                4.34</td><td style=\"text-align: right;\">             95.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1358640\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-56-15\n",
      "  done: false\n",
      "  episode_len_mean: 96.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.140600000000017\n",
      "  episode_reward_min: 4.340000000000023\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13353\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3121890033994401\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007941641992387708\n",
      "          policy_loss: 0.002167681444968496\n",
      "          total_loss: 0.10344541769119955\n",
      "          vf_explained_var: 0.9846817851066589\n",
      "          vf_loss: 0.10151963829994201\n",
      "    num_agent_steps_sampled: 1358640\n",
      "    num_agent_steps_trained: 1358640\n",
      "    num_steps_sampled: 1358640\n",
      "    num_steps_trained: 1358640\n",
      "  iterations_since_restore: 680\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.06857142857143\n",
      "    ram_util_percent: 31.419999999999995\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427242882578145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.13744996096254\n",
      "    mean_inference_ms: 2.4652658264764726\n",
      "    mean_raw_obs_processing_ms: 2.0704508571443925\n",
      "  time_since_restore: 18642.094321012497\n",
      "  time_this_iter_s: 24.499155282974243\n",
      "  time_total_s: 18642.094321012497\n",
      "  timers:\n",
      "    learn_throughput: 1162.413\n",
      "    learn_time_ms: 1718.839\n",
      "    load_throughput: 58236.936\n",
      "    load_time_ms: 34.308\n",
      "    sample_throughput: 68.666\n",
      "    sample_time_ms: 29097.335\n",
      "    update_time_ms: 11.192\n",
      "  timestamp: 1636448175\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1358640\n",
      "  training_iteration: 680\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   680</td><td style=\"text-align: right;\">         18642.1</td><td style=\"text-align: right;\">1358640</td><td style=\"text-align: right;\">  9.1406</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                4.34</td><td style=\"text-align: right;\">             96.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1360638\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-56-41\n",
      "  done: false\n",
      "  episode_len_mean: 97.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 9.001800000000017\n",
      "  episode_reward_min: 4.010000000000021\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 13372\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.248548750650315\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005957962733000045\n",
      "          policy_loss: -0.04336427308929463\n",
      "          total_loss: 0.006140669641484108\n",
      "          vf_explained_var: 0.9876665472984314\n",
      "          vf_loss: 0.052327630087910665\n",
      "    num_agent_steps_sampled: 1360638\n",
      "    num_agent_steps_trained: 1360638\n",
      "    num_steps_sampled: 1360638\n",
      "    num_steps_trained: 1360638\n",
      "  iterations_since_restore: 681\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.87297297297297\n",
      "    ram_util_percent: 31.44054054054054\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044282684699867875\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.13769145389426\n",
      "    mean_inference_ms: 2.4654629290063728\n",
      "    mean_raw_obs_processing_ms: 2.068662965313399\n",
      "  time_since_restore: 18667.58541750908\n",
      "  time_this_iter_s: 25.49109649658203\n",
      "  time_total_s: 18667.58541750908\n",
      "  timers:\n",
      "    learn_throughput: 1162.074\n",
      "    learn_time_ms: 1719.34\n",
      "    load_throughput: 58159.134\n",
      "    load_time_ms: 34.354\n",
      "    sample_throughput: 68.952\n",
      "    sample_time_ms: 28976.756\n",
      "    update_time_ms: 10.434\n",
      "  timestamp: 1636448201\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1360638\n",
      "  training_iteration: 681\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   681</td><td style=\"text-align: right;\">         18667.6</td><td style=\"text-align: right;\">1360638</td><td style=\"text-align: right;\">  9.0018</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                4.01</td><td style=\"text-align: right;\">             97.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1362636\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-57-07\n",
      "  done: false\n",
      "  episode_len_mean: 99.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.969300000000018\n",
      "  episode_reward_min: 4.010000000000021\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 13393\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2566591481367746\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0070156565926856075\n",
      "          policy_loss: -0.05277776416568529\n",
      "          total_loss: 0.06858783476054668\n",
      "          vf_explained_var: 0.9753118753433228\n",
      "          vf_loss: 0.12255399138444946\n",
      "    num_agent_steps_sampled: 1362636\n",
      "    num_agent_steps_trained: 1362636\n",
      "    num_steps_sampled: 1362636\n",
      "    num_steps_trained: 1362636\n",
      "  iterations_since_restore: 682\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94864864864866\n",
      "    ram_util_percent: 31.402702702702705\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044297965446666414\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.136874974512892\n",
      "    mean_inference_ms: 2.465737305412423\n",
      "    mean_raw_obs_processing_ms: 2.0665241640950947\n",
      "  time_since_restore: 18693.667580366135\n",
      "  time_this_iter_s: 26.082162857055664\n",
      "  time_total_s: 18693.667580366135\n",
      "  timers:\n",
      "    learn_throughput: 1161.718\n",
      "    learn_time_ms: 1719.866\n",
      "    load_throughput: 58651.495\n",
      "    load_time_ms: 34.066\n",
      "    sample_throughput: 72.894\n",
      "    sample_time_ms: 27409.734\n",
      "    update_time_ms: 9.769\n",
      "  timestamp: 1636448227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1362636\n",
      "  training_iteration: 682\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   682</td><td style=\"text-align: right;\">         18693.7</td><td style=\"text-align: right;\">1362636</td><td style=\"text-align: right;\">  8.9693</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                4.01</td><td style=\"text-align: right;\">             99.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1364634\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-57-31\n",
      "  done: false\n",
      "  episode_len_mean: 100.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.761900000000018\n",
      "  episode_reward_min: 4.010000000000021\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 13412\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.315309273061298\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015449277361608378\n",
      "          policy_loss: -0.053531751480130924\n",
      "          total_loss: 0.058717756257170725\n",
      "          vf_explained_var: 0.9866886138916016\n",
      "          vf_loss: 0.10034650812546413\n",
      "    num_agent_steps_sampled: 1364634\n",
      "    num_agent_steps_trained: 1364634\n",
      "    num_steps_sampled: 1364634\n",
      "    num_steps_trained: 1364634\n",
      "  iterations_since_restore: 683\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.83714285714285\n",
      "    ram_util_percent: 31.43142857142857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04430885210157828\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.13609859626186\n",
      "    mean_inference_ms: 2.465924531503072\n",
      "    mean_raw_obs_processing_ms: 2.06465251607965\n",
      "  time_since_restore: 18718.29918193817\n",
      "  time_this_iter_s: 24.631601572036743\n",
      "  time_total_s: 18718.29918193817\n",
      "  timers:\n",
      "    learn_throughput: 1163.215\n",
      "    learn_time_ms: 1717.653\n",
      "    load_throughput: 58548.847\n",
      "    load_time_ms: 34.125\n",
      "    sample_throughput: 77.257\n",
      "    sample_time_ms: 25861.711\n",
      "    update_time_ms: 10.48\n",
      "  timestamp: 1636448251\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1364634\n",
      "  training_iteration: 683\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   683</td><td style=\"text-align: right;\">         18718.3</td><td style=\"text-align: right;\">1364634</td><td style=\"text-align: right;\">  8.7619</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                4.01</td><td style=\"text-align: right;\">            100.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1366632\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-57-58\n",
      "  done: false\n",
      "  episode_len_mean: 100.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.701100000000018\n",
      "  episode_reward_min: 3.0500000000000127\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 13433\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2843522003718786\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00862833461451106\n",
      "          policy_loss: -0.0043237074500038514\n",
      "          total_loss: 0.11661525954093252\n",
      "          vf_explained_var: 0.978865385055542\n",
      "          vf_loss: 0.11978880516475156\n",
      "    num_agent_steps_sampled: 1366632\n",
      "    num_agent_steps_trained: 1366632\n",
      "    num_steps_sampled: 1366632\n",
      "    num_steps_trained: 1366632\n",
      "  iterations_since_restore: 684\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.40526315789474\n",
      "    ram_util_percent: 31.3921052631579\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433910042620055\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.13368660571537\n",
      "    mean_inference_ms: 2.466444591348125\n",
      "    mean_raw_obs_processing_ms: 2.062438896858749\n",
      "  time_since_restore: 18744.779507637024\n",
      "  time_this_iter_s: 26.48032569885254\n",
      "  time_total_s: 18744.779507637024\n",
      "  timers:\n",
      "    learn_throughput: 1162.87\n",
      "    learn_time_ms: 1718.163\n",
      "    load_throughput: 58807.03\n",
      "    load_time_ms: 33.976\n",
      "    sample_throughput: 82.513\n",
      "    sample_time_ms: 24214.363\n",
      "    update_time_ms: 9.708\n",
      "  timestamp: 1636448278\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1366632\n",
      "  training_iteration: 684\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   684</td><td style=\"text-align: right;\">         18744.8</td><td style=\"text-align: right;\">1366632</td><td style=\"text-align: right;\">  8.7011</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                3.05</td><td style=\"text-align: right;\">            100.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1368630\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-58-25\n",
      "  done: false\n",
      "  episode_len_mean: 99.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.816000000000018\n",
      "  episode_reward_min: 3.0500000000000127\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 13452\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2738367353166853\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006157152074554764\n",
      "          policy_loss: -0.0757567801202337\n",
      "          total_loss: 0.025904023602959656\n",
      "          vf_explained_var: 0.9866077303886414\n",
      "          vf_loss: 0.10441332156991674\n",
      "    num_agent_steps_sampled: 1368630\n",
      "    num_agent_steps_trained: 1368630\n",
      "    num_steps_sampled: 1368630\n",
      "    num_steps_trained: 1368630\n",
      "  iterations_since_restore: 685\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96315789473682\n",
      "    ram_util_percent: 31.352631578947378\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433906921887726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.13370904197125\n",
      "    mean_inference_ms: 2.466429948105329\n",
      "    mean_raw_obs_processing_ms: 2.060536402610177\n",
      "  time_since_restore: 18771.474366903305\n",
      "  time_this_iter_s: 26.694859266281128\n",
      "  time_total_s: 18771.474366903305\n",
      "  timers:\n",
      "    learn_throughput: 1163.142\n",
      "    learn_time_ms: 1717.762\n",
      "    load_throughput: 59239.488\n",
      "    load_time_ms: 33.728\n",
      "    sample_throughput: 82.678\n",
      "    sample_time_ms: 24165.957\n",
      "    update_time_ms: 9.858\n",
      "  timestamp: 1636448305\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1368630\n",
      "  training_iteration: 685\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   685</td><td style=\"text-align: right;\">         18771.5</td><td style=\"text-align: right;\">1368630</td><td style=\"text-align: right;\">   8.816</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                3.05</td><td style=\"text-align: right;\">             99.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1370628\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-58-49\n",
      "  done: false\n",
      "  episode_len_mean: 100.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.531900000000018\n",
      "  episode_reward_min: 3.0500000000000127\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13472\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3428153038024901\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0064412299718208\n",
      "          policy_loss: -0.0394525288293759\n",
      "          total_loss: 0.026905758403951215\n",
      "          vf_explained_var: 0.9848993420600891\n",
      "          vf_loss: 0.06933986671446335\n",
      "    num_agent_steps_sampled: 1370628\n",
      "    num_agent_steps_trained: 1370628\n",
      "    num_steps_sampled: 1370628\n",
      "    num_steps_trained: 1370628\n",
      "  iterations_since_restore: 686\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.30571428571429\n",
      "    ram_util_percent: 31.29142857142858\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04432767968935822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.13365548133501\n",
      "    mean_inference_ms: 2.466238653240443\n",
      "    mean_raw_obs_processing_ms: 2.0584856204017\n",
      "  time_since_restore: 18796.015432834625\n",
      "  time_this_iter_s: 24.54106593132019\n",
      "  time_total_s: 18796.015432834625\n",
      "  timers:\n",
      "    learn_throughput: 1163.358\n",
      "    learn_time_ms: 1717.442\n",
      "    load_throughput: 59610.941\n",
      "    load_time_ms: 33.517\n",
      "    sample_throughput: 83.52\n",
      "    sample_time_ms: 23922.296\n",
      "    update_time_ms: 9.404\n",
      "  timestamp: 1636448329\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1370628\n",
      "  training_iteration: 686\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   686</td><td style=\"text-align: right;\">           18796</td><td style=\"text-align: right;\">1370628</td><td style=\"text-align: right;\">  8.5319</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                3.05</td><td style=\"text-align: right;\">            100.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1372626\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-59-16\n",
      "  done: false\n",
      "  episode_len_mean: 99.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.751800000000017\n",
      "  episode_reward_min: 3.0500000000000127\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13492\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2415805498758952\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005914008515457899\n",
      "          policy_loss: -0.01951642396549384\n",
      "          total_loss: 0.04025724563925039\n",
      "          vf_explained_var: 0.9915178418159485\n",
      "          vf_loss: 0.06259796290347973\n",
      "    num_agent_steps_sampled: 1372626\n",
      "    num_agent_steps_trained: 1372626\n",
      "    num_steps_sampled: 1372626\n",
      "    num_steps_trained: 1372626\n",
      "  iterations_since_restore: 687\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.42105263157893\n",
      "    ram_util_percent: 31.31315789473685\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044330112026538034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.133407238774826\n",
      "    mean_inference_ms: 2.466289505295007\n",
      "    mean_raw_obs_processing_ms: 2.056420521833998\n",
      "  time_since_restore: 18822.893174886703\n",
      "  time_this_iter_s: 26.877742052078247\n",
      "  time_total_s: 18822.893174886703\n",
      "  timers:\n",
      "    learn_throughput: 1163.546\n",
      "    learn_time_ms: 1717.164\n",
      "    load_throughput: 59622.562\n",
      "    load_time_ms: 33.511\n",
      "    sample_throughput: 83.605\n",
      "    sample_time_ms: 23897.976\n",
      "    update_time_ms: 8.704\n",
      "  timestamp: 1636448356\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1372626\n",
      "  training_iteration: 687\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   687</td><td style=\"text-align: right;\">         18822.9</td><td style=\"text-align: right;\">1372626</td><td style=\"text-align: right;\">  8.7518</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                3.05</td><td style=\"text-align: right;\">             99.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1374624\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_08-59-42\n",
      "  done: false\n",
      "  episode_len_mean: 99.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000013\n",
      "  episode_reward_mean: 8.877600000000015\n",
      "  episode_reward_min: 2.9100000000000175\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13512\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3226680823734829\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0067968771569144205\n",
      "          policy_loss: -0.03107089503180413\n",
      "          total_loss: 0.1013406416844754\n",
      "          vf_explained_var: 0.9734025001525879\n",
      "          vf_loss: 0.1346148450459753\n",
      "    num_agent_steps_sampled: 1374624\n",
      "    num_agent_steps_trained: 1374624\n",
      "    num_steps_sampled: 1374624\n",
      "    num_steps_trained: 1374624\n",
      "  iterations_since_restore: 688\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.41081081081082\n",
      "    ram_util_percent: 31.30000000000001\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04433243448777033\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.133244239450132\n",
      "    mean_inference_ms: 2.4663362839246012\n",
      "    mean_raw_obs_processing_ms: 2.05435365041487\n",
      "  time_since_restore: 18848.357309818268\n",
      "  time_this_iter_s: 25.46413493156433\n",
      "  time_total_s: 18848.357309818268\n",
      "  timers:\n",
      "    learn_throughput: 1163.395\n",
      "    learn_time_ms: 1717.388\n",
      "    load_throughput: 59465.769\n",
      "    load_time_ms: 33.599\n",
      "    sample_throughput: 83.679\n",
      "    sample_time_ms: 23876.974\n",
      "    update_time_ms: 8.639\n",
      "  timestamp: 1636448382\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1374624\n",
      "  training_iteration: 688\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   688</td><td style=\"text-align: right;\">         18848.4</td><td style=\"text-align: right;\">1374624</td><td style=\"text-align: right;\">  8.8776</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                2.91</td><td style=\"text-align: right;\">             99.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1376622\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-00-21\n",
      "  done: false\n",
      "  episode_len_mean: 98.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.703000000000017\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 13534\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2433201159749712\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.005592113518239455\n",
      "          policy_loss: -0.06001191708658423\n",
      "          total_loss: 0.06379068286291191\n",
      "          vf_explained_var: 0.9818100929260254\n",
      "          vf_loss: 0.12716634712581124\n",
      "    num_agent_steps_sampled: 1376622\n",
      "    num_agent_steps_trained: 1376622\n",
      "    num_steps_sampled: 1376622\n",
      "    num_steps_trained: 1376622\n",
      "  iterations_since_restore: 689\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.84000000000002\n",
      "    ram_util_percent: 31.238181818181822\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04431545643194615\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.134357765776095\n",
      "    mean_inference_ms: 2.4660334608823207\n",
      "    mean_raw_obs_processing_ms: 2.054670574186541\n",
      "  time_since_restore: 18887.219163894653\n",
      "  time_this_iter_s: 38.8618540763855\n",
      "  time_total_s: 18887.219163894653\n",
      "  timers:\n",
      "    learn_throughput: 1163.203\n",
      "    learn_time_ms: 1717.672\n",
      "    load_throughput: 59416.018\n",
      "    load_time_ms: 33.627\n",
      "    sample_throughput: 79.307\n",
      "    sample_time_ms: 25193.288\n",
      "    update_time_ms: 8.806\n",
      "  timestamp: 1636448421\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1376622\n",
      "  training_iteration: 689\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   689</td><td style=\"text-align: right;\">         18887.2</td><td style=\"text-align: right;\">1376622</td><td style=\"text-align: right;\">   8.703</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">              98.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1378620\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-01-17\n",
      "  done: false\n",
      "  episode_len_mean: 96.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.607100000000017\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 13556\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.621829223632812\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3395450932638986\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.004800749025442335\n",
      "          policy_loss: -0.005823692360094616\n",
      "          total_loss: 0.19197020178572052\n",
      "          vf_explained_var: 0.9616831541061401\n",
      "          vf_loss: 0.20340335058669248\n",
      "    num_agent_steps_sampled: 1378620\n",
      "    num_agent_steps_trained: 1378620\n",
      "    num_steps_sampled: 1378620\n",
      "    num_steps_trained: 1378620\n",
      "  iterations_since_restore: 690\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.11111111111111\n",
      "    ram_util_percent: 30.98518518518518\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044286156419535684\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.1351127023021\n",
      "    mean_inference_ms: 2.465558590265063\n",
      "    mean_raw_obs_processing_ms: 2.0601836286395216\n",
      "  time_since_restore: 18943.758455753326\n",
      "  time_this_iter_s: 56.539291858673096\n",
      "  time_total_s: 18943.758455753326\n",
      "  timers:\n",
      "    learn_throughput: 1162.594\n",
      "    learn_time_ms: 1718.571\n",
      "    load_throughput: 59214.791\n",
      "    load_time_ms: 33.742\n",
      "    sample_throughput: 70.36\n",
      "    sample_time_ms: 28396.72\n",
      "    update_time_ms: 8.288\n",
      "  timestamp: 1636448477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1378620\n",
      "  training_iteration: 690\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   690</td><td style=\"text-align: right;\">         18943.8</td><td style=\"text-align: right;\">1378620</td><td style=\"text-align: right;\">  8.6071</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             96.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1380618\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-01-46\n",
      "  done: false\n",
      "  episode_len_mean: 95.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.946800000000017\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 13577\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2927107481729416\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010467782327326267\n",
      "          policy_loss: -0.003602953204175546\n",
      "          total_loss: 0.13348480439523147\n",
      "          vf_explained_var: 0.984724760055542\n",
      "          vf_loss: 0.1415263874544984\n",
      "    num_agent_steps_sampled: 1380618\n",
      "    num_agent_steps_trained: 1380618\n",
      "    num_steps_sampled: 1380618\n",
      "    num_steps_trained: 1380618\n",
      "  iterations_since_restore: 691\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.43414634146342\n",
      "    ram_util_percent: 31.043902439024393\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442835258918327\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.136656335839316\n",
      "    mean_inference_ms: 2.465521610806783\n",
      "    mean_raw_obs_processing_ms: 2.065484804792458\n",
      "  time_since_restore: 18972.532425403595\n",
      "  time_this_iter_s: 28.773969650268555\n",
      "  time_total_s: 18972.532425403595\n",
      "  timers:\n",
      "    learn_throughput: 1162.397\n",
      "    learn_time_ms: 1718.862\n",
      "    load_throughput: 59225.84\n",
      "    load_time_ms: 33.735\n",
      "    sample_throughput: 69.558\n",
      "    sample_time_ms: 28724.19\n",
      "    update_time_ms: 8.544\n",
      "  timestamp: 1636448506\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1380618\n",
      "  training_iteration: 691\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   691</td><td style=\"text-align: right;\">         18972.5</td><td style=\"text-align: right;\">1380618</td><td style=\"text-align: right;\">  8.9468</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             95.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1382616\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-02-14\n",
      "  done: false\n",
      "  episode_len_mean: 94.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.891800000000018\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 13598\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2721043830826169\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009710206886207846\n",
      "          policy_loss: -0.07200060349312566\n",
      "          total_loss: 0.026134473865940457\n",
      "          vf_explained_var: 0.9855723977088928\n",
      "          vf_loss: 0.10298197271213645\n",
      "    num_agent_steps_sampled: 1382616\n",
      "    num_agent_steps_trained: 1382616\n",
      "    num_steps_sampled: 1382616\n",
      "    num_steps_trained: 1382616\n",
      "  iterations_since_restore: 692\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.47073170731707\n",
      "    ram_util_percent: 31.41219512195122\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426196134955593\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.139982003083805\n",
      "    mean_inference_ms: 2.4651666384084634\n",
      "    mean_raw_obs_processing_ms: 2.0709392031792846\n",
      "  time_since_restore: 19000.82857298851\n",
      "  time_this_iter_s: 28.29614758491516\n",
      "  time_total_s: 19000.82857298851\n",
      "  timers:\n",
      "    learn_throughput: 1162.368\n",
      "    learn_time_ms: 1718.905\n",
      "    load_throughput: 59313.492\n",
      "    load_time_ms: 33.685\n",
      "    sample_throughput: 69.027\n",
      "    sample_time_ms: 28945.117\n",
      "    update_time_ms: 9.174\n",
      "  timestamp: 1636448534\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1382616\n",
      "  training_iteration: 692\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   692</td><td style=\"text-align: right;\">         19000.8</td><td style=\"text-align: right;\">1382616</td><td style=\"text-align: right;\">  8.8918</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             94.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1384614\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-02-40\n",
      "  done: false\n",
      "  episode_len_mean: 95.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000014\n",
      "  episode_reward_mean: 8.880800000000017\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13618\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3554275296983265\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011626010565616357\n",
      "          policy_loss: -0.051418148318216915\n",
      "          total_loss: 0.09265112713467152\n",
      "          vf_explained_var: 0.9800949692726135\n",
      "          vf_loss: 0.14819584964286714\n",
      "    num_agent_steps_sampled: 1384614\n",
      "    num_agent_steps_trained: 1384614\n",
      "    num_steps_sampled: 1384614\n",
      "    num_steps_trained: 1384614\n",
      "  iterations_since_restore: 693\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.18333333333331\n",
      "    ram_util_percent: 31.416666666666668\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425967958161956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.14211319522998\n",
      "    mean_inference_ms: 2.46514393140525\n",
      "    mean_raw_obs_processing_ms: 2.075994828133235\n",
      "  time_since_restore: 19026.131284952164\n",
      "  time_this_iter_s: 25.302711963653564\n",
      "  time_total_s: 19026.131284952164\n",
      "  timers:\n",
      "    learn_throughput: 1162.821\n",
      "    learn_time_ms: 1718.235\n",
      "    load_throughput: 59508.84\n",
      "    load_time_ms: 33.575\n",
      "    sample_throughput: 68.865\n",
      "    sample_time_ms: 29013.351\n",
      "    update_time_ms: 8.818\n",
      "  timestamp: 1636448560\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1384614\n",
      "  training_iteration: 693\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   693</td><td style=\"text-align: right;\">         19026.1</td><td style=\"text-align: right;\">1384614</td><td style=\"text-align: right;\">  8.8808</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             95.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1386612\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-03-06\n",
      "  done: false\n",
      "  episode_len_mean: 96.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000014\n",
      "  episode_reward_mean: 8.948700000000017\n",
      "  episode_reward_min: -0.15000000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13638\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3252718766530356\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01259927665571874\n",
      "          policy_loss: -0.019165671395049207\n",
      "          total_loss: 0.024091794137798606\n",
      "          vf_explained_var: 0.9863520860671997\n",
      "          vf_loss: 0.04629324819626553\n",
      "    num_agent_steps_sampled: 1386612\n",
      "    num_agent_steps_trained: 1386612\n",
      "    num_steps_sampled: 1386612\n",
      "    num_steps_trained: 1386612\n",
      "  iterations_since_restore: 694\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.92702702702702\n",
      "    ram_util_percent: 31.41621621621622\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427246175770822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.143901812156972\n",
      "    mean_inference_ms: 2.465376361774189\n",
      "    mean_raw_obs_processing_ms: 2.0771815339870625\n",
      "  time_since_restore: 19052.37048625946\n",
      "  time_this_iter_s: 26.239201307296753\n",
      "  time_total_s: 19052.37048625946\n",
      "  timers:\n",
      "    learn_throughput: 1164.516\n",
      "    learn_time_ms: 1715.734\n",
      "    load_throughput: 59313.702\n",
      "    load_time_ms: 33.685\n",
      "    sample_throughput: 68.917\n",
      "    sample_time_ms: 28991.267\n",
      "    update_time_ms: 8.845\n",
      "  timestamp: 1636448586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1386612\n",
      "  training_iteration: 694\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   694</td><td style=\"text-align: right;\">         19052.4</td><td style=\"text-align: right;\">1386612</td><td style=\"text-align: right;\">  8.9487</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">               -0.15</td><td style=\"text-align: right;\">             96.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1388610\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-03-33\n",
      "  done: false\n",
      "  episode_len_mean: 97.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000014\n",
      "  episode_reward_mean: 9.31950000000002\n",
      "  episode_reward_min: 4.290000000000022\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13658\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2093930817785716\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010795493346354488\n",
      "          policy_loss: -0.02450297267309257\n",
      "          total_loss: 0.025695695053963435\n",
      "          vf_explained_var: 0.9906748533248901\n",
      "          vf_loss: 0.05353837632352398\n",
      "    num_agent_steps_sampled: 1388610\n",
      "    num_agent_steps_trained: 1388610\n",
      "    num_steps_sampled: 1388610\n",
      "    num_steps_trained: 1388610\n",
      "  iterations_since_restore: 695\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.7051282051282\n",
      "    ram_util_percent: 31.366666666666678\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044287310866895274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.14626735004788\n",
      "    mean_inference_ms: 2.46559840508096\n",
      "    mean_raw_obs_processing_ms: 2.075216720227018\n",
      "  time_since_restore: 19079.30499815941\n",
      "  time_this_iter_s: 26.93451189994812\n",
      "  time_total_s: 19079.30499815941\n",
      "  timers:\n",
      "    learn_throughput: 1164.102\n",
      "    learn_time_ms: 1716.344\n",
      "    load_throughput: 58867.052\n",
      "    load_time_ms: 33.941\n",
      "    sample_throughput: 68.864\n",
      "    sample_time_ms: 29013.882\n",
      "    update_time_ms: 9.194\n",
      "  timestamp: 1636448613\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1388610\n",
      "  training_iteration: 695\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   695</td><td style=\"text-align: right;\">         19079.3</td><td style=\"text-align: right;\">1388610</td><td style=\"text-align: right;\">  9.3195</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">                4.29</td><td style=\"text-align: right;\">             97.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1390608\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-03-58\n",
      "  done: false\n",
      "  episode_len_mean: 98.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000014\n",
      "  episode_reward_mean: 8.834700000000018\n",
      "  episode_reward_min: 2.7600000000000167\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13678\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3315526525179544\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009471123882516214\n",
      "          policy_loss: -0.04954805828276135\n",
      "          total_loss: 0.05370632562608946\n",
      "          vf_explained_var: 0.9756466150283813\n",
      "          vf_loss: 0.10888963871236358\n",
      "    num_agent_steps_sampled: 1390608\n",
      "    num_agent_steps_trained: 1390608\n",
      "    num_steps_sampled: 1390608\n",
      "    num_steps_trained: 1390608\n",
      "  iterations_since_restore: 696\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95428571428573\n",
      "    ram_util_percent: 31.20571428571428\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044299068052947935\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.147489362634587\n",
      "    mean_inference_ms: 2.465755189418553\n",
      "    mean_raw_obs_processing_ms: 2.0733001181344815\n",
      "  time_since_restore: 19104.149169683456\n",
      "  time_this_iter_s: 24.84417152404785\n",
      "  time_total_s: 19104.149169683456\n",
      "  timers:\n",
      "    learn_throughput: 1164.157\n",
      "    learn_time_ms: 1716.263\n",
      "    load_throughput: 58988.503\n",
      "    load_time_ms: 33.871\n",
      "    sample_throughput: 68.792\n",
      "    sample_time_ms: 29044.257\n",
      "    update_time_ms: 9.348\n",
      "  timestamp: 1636448638\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1390608\n",
      "  training_iteration: 696\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   696</td><td style=\"text-align: right;\">         19104.1</td><td style=\"text-align: right;\">1390608</td><td style=\"text-align: right;\">  8.8347</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">                2.76</td><td style=\"text-align: right;\">             98.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1392606\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-04-22\n",
      "  done: false\n",
      "  episode_len_mean: 101.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.770000000000014\n",
      "  episode_reward_mean: 8.629400000000018\n",
      "  episode_reward_min: 2.7600000000000167\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 13697\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3155990980920338\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009762484711078562\n",
      "          policy_loss: -0.02726903690823487\n",
      "          total_loss: 0.08189096273410888\n",
      "          vf_explained_var: 0.9821460247039795\n",
      "          vf_loss: 0.11439944762913953\n",
      "    num_agent_steps_sampled: 1392606\n",
      "    num_agent_steps_trained: 1392606\n",
      "    num_steps_sampled: 1392606\n",
      "    num_steps_trained: 1392606\n",
      "  iterations_since_restore: 697\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96285714285715\n",
      "    ram_util_percent: 31.228571428571428\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04429922492358795\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.147445080269918\n",
      "    mean_inference_ms: 2.465730248590778\n",
      "    mean_raw_obs_processing_ms: 2.0714077904185766\n",
      "  time_since_restore: 19128.510442972183\n",
      "  time_this_iter_s: 24.361273288726807\n",
      "  time_total_s: 19128.510442972183\n",
      "  timers:\n",
      "    learn_throughput: 1162.592\n",
      "    learn_time_ms: 1718.573\n",
      "    load_throughput: 59217.344\n",
      "    load_time_ms: 33.74\n",
      "    sample_throughput: 69.4\n",
      "    sample_time_ms: 28789.528\n",
      "    update_time_ms: 10.284\n",
      "  timestamp: 1636448662\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1392606\n",
      "  training_iteration: 697\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   697</td><td style=\"text-align: right;\">         19128.5</td><td style=\"text-align: right;\">1392606</td><td style=\"text-align: right;\">  8.6294</td><td style=\"text-align: right;\">               14.77</td><td style=\"text-align: right;\">                2.76</td><td style=\"text-align: right;\">            101.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1394604\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-04-48\n",
      "  done: false\n",
      "  episode_len_mean: 100.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 8.535800000000018\n",
      "  episode_reward_min: 2.7600000000000167\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 13716\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3443699859437488\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013684543733235834\n",
      "          policy_loss: -0.027837980893396196\n",
      "          total_loss: 0.07579493566992737\n",
      "          vf_explained_var: 0.964390218257904\n",
      "          vf_loss: 0.10597962127732379\n",
      "    num_agent_steps_sampled: 1394604\n",
      "    num_agent_steps_trained: 1394604\n",
      "    num_steps_sampled: 1394604\n",
      "    num_steps_trained: 1394604\n",
      "  iterations_since_restore: 698\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.23611111111111\n",
      "    ram_util_percent: 31.14166666666667\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044281014600272034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.147830260743305\n",
      "    mean_inference_ms: 2.465384816543769\n",
      "    mean_raw_obs_processing_ms: 2.0696187648137214\n",
      "  time_since_restore: 19154.042978048325\n",
      "  time_this_iter_s: 25.532535076141357\n",
      "  time_total_s: 19154.042978048325\n",
      "  timers:\n",
      "    learn_throughput: 1162.44\n",
      "    learn_time_ms: 1718.799\n",
      "    load_throughput: 59355.334\n",
      "    load_time_ms: 33.662\n",
      "    sample_throughput: 69.384\n",
      "    sample_time_ms: 28796.082\n",
      "    update_time_ms: 10.553\n",
      "  timestamp: 1636448688\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1394604\n",
      "  training_iteration: 698\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   698</td><td style=\"text-align: right;\">           19154</td><td style=\"text-align: right;\">1394604</td><td style=\"text-align: right;\">  8.5358</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">                2.76</td><td style=\"text-align: right;\">            100.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1396602\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-05-14\n",
      "  done: false\n",
      "  episode_len_mean: 101.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.760000000000014\n",
      "  episode_reward_mean: 8.498600000000017\n",
      "  episode_reward_min: 2.7600000000000167\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 13735\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2333616097768147\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010746766872083905\n",
      "          policy_loss: -0.0571823254405033\n",
      "          total_loss: 0.021458234371883527\n",
      "          vf_explained_var: 0.9888936877250671\n",
      "          vf_loss: 0.0822594639179962\n",
      "    num_agent_steps_sampled: 1396602\n",
      "    num_agent_steps_trained: 1396602\n",
      "    num_steps_sampled: 1396602\n",
      "    num_steps_trained: 1396602\n",
      "  iterations_since_restore: 699\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.95526315789475\n",
      "    ram_util_percent: 31.076315789473682\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428092344351372\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.14828623561081\n",
      "    mean_inference_ms: 2.4653719834136494\n",
      "    mean_raw_obs_processing_ms: 2.06770002059106\n",
      "  time_since_restore: 19180.32786464691\n",
      "  time_this_iter_s: 26.284886598587036\n",
      "  time_total_s: 19180.32786464691\n",
      "  timers:\n",
      "    learn_throughput: 1163.359\n",
      "    learn_time_ms: 1717.44\n",
      "    load_throughput: 59229.523\n",
      "    load_time_ms: 33.733\n",
      "    sample_throughput: 72.548\n",
      "    sample_time_ms: 27540.492\n",
      "    update_time_ms: 9.73\n",
      "  timestamp: 1636448714\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1396602\n",
      "  training_iteration: 699\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   699</td><td style=\"text-align: right;\">         19180.3</td><td style=\"text-align: right;\">1396602</td><td style=\"text-align: right;\">  8.4986</td><td style=\"text-align: right;\">               14.76</td><td style=\"text-align: right;\">                2.76</td><td style=\"text-align: right;\">            101.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1398600\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-05-43\n",
      "  done: false\n",
      "  episode_len_mean: 101.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.66740000000002\n",
      "  episode_reward_min: 2.7600000000000167\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 13757\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.19825515520005\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01382894993892035\n",
      "          policy_loss: -0.015305639767930621\n",
      "          total_loss: 0.11432807807411466\n",
      "          vf_explained_var: 0.9878824353218079\n",
      "          vf_loss: 0.13040217596682765\n",
      "    num_agent_steps_sampled: 1398600\n",
      "    num_agent_steps_trained: 1398600\n",
      "    num_steps_sampled: 1398600\n",
      "    num_steps_trained: 1398600\n",
      "  iterations_since_restore: 700\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.23170731707317\n",
      "    ram_util_percent: 31.004878048780483\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044294665664718263\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.149338233517543\n",
      "    mean_inference_ms: 2.4656142882072434\n",
      "    mean_raw_obs_processing_ms: 2.065457752989549\n",
      "  time_since_restore: 19209.12645506859\n",
      "  time_this_iter_s: 28.798590421676636\n",
      "  time_total_s: 19209.12645506859\n",
      "  timers:\n",
      "    learn_throughput: 1164.139\n",
      "    learn_time_ms: 1716.29\n",
      "    load_throughput: 59313.954\n",
      "    load_time_ms: 33.685\n",
      "    sample_throughput: 80.672\n",
      "    sample_time_ms: 24767.06\n",
      "    update_time_ms: 10.215\n",
      "  timestamp: 1636448743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1398600\n",
      "  training_iteration: 700\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   700</td><td style=\"text-align: right;\">         19209.1</td><td style=\"text-align: right;\">1398600</td><td style=\"text-align: right;\">  8.6674</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.76</td><td style=\"text-align: right;\">            101.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1400598\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-06-08\n",
      "  done: false\n",
      "  episode_len_mean: 100.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 8.886700000000019\n",
      "  episode_reward_min: 2.4500000000000117\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 13776\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3206002717926388\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006851144472114062\n",
      "          policy_loss: -0.1352340169250965\n",
      "          total_loss: -0.03465234695800713\n",
      "          vf_explained_var: 0.9776091575622559\n",
      "          vf_loss: 0.10823198109865188\n",
      "    num_agent_steps_sampled: 1400598\n",
      "    num_agent_steps_trained: 1400598\n",
      "    num_steps_sampled: 1400598\n",
      "    num_steps_trained: 1400598\n",
      "  iterations_since_restore: 701\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.225\n",
      "    ram_util_percent: 30.98333333333333\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04428194855101156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.150052639960535\n",
      "    mean_inference_ms: 2.465432571292874\n",
      "    mean_raw_obs_processing_ms: 2.0635509984256233\n",
      "  time_since_restore: 19234.036582946777\n",
      "  time_this_iter_s: 24.910127878189087\n",
      "  time_total_s: 19234.036582946777\n",
      "  timers:\n",
      "    learn_throughput: 1163.862\n",
      "    learn_time_ms: 1716.699\n",
      "    load_throughput: 59694.635\n",
      "    load_time_ms: 33.47\n",
      "    sample_throughput: 81.95\n",
      "    sample_time_ms: 24380.759\n",
      "    update_time_ms: 10.262\n",
      "  timestamp: 1636448768\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1400598\n",
      "  training_iteration: 701\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   701</td><td style=\"text-align: right;\">           19234</td><td style=\"text-align: right;\">1400598</td><td style=\"text-align: right;\">  8.8867</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.45</td><td style=\"text-align: right;\">            100.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1402596\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-06-34\n",
      "  done: false\n",
      "  episode_len_mean: 100.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000012\n",
      "  episode_reward_mean: 9.182700000000018\n",
      "  episode_reward_min: 2.4500000000000117\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 13797\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.295796297277723\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012315355200212383\n",
      "          policy_loss: -0.006641550016190325\n",
      "          total_loss: 0.1367329704087405\n",
      "          vf_explained_var: 0.9847707152366638\n",
      "          vf_loss: 0.14634578230657747\n",
      "    num_agent_steps_sampled: 1402596\n",
      "    num_agent_steps_trained: 1402596\n",
      "    num_steps_sampled: 1402596\n",
      "    num_steps_trained: 1402596\n",
      "  iterations_since_restore: 702\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96486486486486\n",
      "    ram_util_percent: 30.95675675675676\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044295424981915285\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.151704282568527\n",
      "    mean_inference_ms: 2.465666590543736\n",
      "    mean_raw_obs_processing_ms: 2.0614693699154647\n",
      "  time_since_restore: 19260.017052173615\n",
      "  time_this_iter_s: 25.980469226837158\n",
      "  time_total_s: 19260.017052173615\n",
      "  timers:\n",
      "    learn_throughput: 1164.147\n",
      "    learn_time_ms: 1716.278\n",
      "    load_throughput: 59528.412\n",
      "    load_time_ms: 33.564\n",
      "    sample_throughput: 82.733\n",
      "    sample_time_ms: 24149.895\n",
      "    update_time_ms: 10.148\n",
      "  timestamp: 1636448794\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1402596\n",
      "  training_iteration: 702\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   702</td><td style=\"text-align: right;\">           19260</td><td style=\"text-align: right;\">1402596</td><td style=\"text-align: right;\">  9.1827</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.45</td><td style=\"text-align: right;\">            100.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1404594\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-07-01\n",
      "  done: false\n",
      "  episode_len_mean: 99.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 9.328900000000017\n",
      "  episode_reward_min: 2.4500000000000117\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 13815\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3112182526361376\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006881269986514948\n",
      "          policy_loss: -0.11725655265507244\n",
      "          total_loss: -0.02106045557274705\n",
      "          vf_explained_var: 0.9717731475830078\n",
      "          vf_loss: 0.1037281553837515\n",
      "    num_agent_steps_sampled: 1404594\n",
      "    num_agent_steps_trained: 1404594\n",
      "    num_steps_sampled: 1404594\n",
      "    num_steps_trained: 1404594\n",
      "  iterations_since_restore: 703\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33947368421053\n",
      "    ram_util_percent: 30.942105263157895\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044293781755602044\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.15351977723494\n",
      "    mean_inference_ms: 2.4656468873897497\n",
      "    mean_raw_obs_processing_ms: 2.059764407274174\n",
      "  time_since_restore: 19287.010187625885\n",
      "  time_this_iter_s: 26.993135452270508\n",
      "  time_total_s: 19287.010187625885\n",
      "  timers:\n",
      "    learn_throughput: 1164.896\n",
      "    learn_time_ms: 1715.175\n",
      "    load_throughput: 59536.744\n",
      "    load_time_ms: 33.559\n",
      "    sample_throughput: 82.158\n",
      "    sample_time_ms: 24319.122\n",
      "    update_time_ms: 10.889\n",
      "  timestamp: 1636448821\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1404594\n",
      "  training_iteration: 703\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   703</td><td style=\"text-align: right;\">           19287</td><td style=\"text-align: right;\">1404594</td><td style=\"text-align: right;\">  9.3289</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.45</td><td style=\"text-align: right;\">             99.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1406592\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-07-28\n",
      "  done: false\n",
      "  episode_len_mean: 98.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 9.504100000000017\n",
      "  episode_reward_min: 2.4500000000000117\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 13837\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2038532864479792\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010390783466387925\n",
      "          policy_loss: -0.004999851701515062\n",
      "          total_loss: 0.109050997843345\n",
      "          vf_explained_var: 0.9874171614646912\n",
      "          vf_loss: 0.11766334328623045\n",
      "    num_agent_steps_sampled: 1406592\n",
      "    num_agent_steps_trained: 1406592\n",
      "    num_steps_sampled: 1406592\n",
      "    num_steps_trained: 1406592\n",
      "  iterations_since_restore: 704\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9974358974359\n",
      "    ram_util_percent: 30.892307692307693\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426140985143657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.15560596179887\n",
      "    mean_inference_ms: 2.4651245355959173\n",
      "    mean_raw_obs_processing_ms: 2.0577827348108055\n",
      "  time_since_restore: 19314.403129339218\n",
      "  time_this_iter_s: 27.39294171333313\n",
      "  time_total_s: 19314.403129339218\n",
      "  timers:\n",
      "    learn_throughput: 1164.362\n",
      "    learn_time_ms: 1715.962\n",
      "    load_throughput: 59614.843\n",
      "    load_time_ms: 33.515\n",
      "    sample_throughput: 81.774\n",
      "    sample_time_ms: 24433.32\n",
      "    update_time_ms: 11.453\n",
      "  timestamp: 1636448848\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1406592\n",
      "  training_iteration: 704\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   704</td><td style=\"text-align: right;\">         19314.4</td><td style=\"text-align: right;\">1406592</td><td style=\"text-align: right;\">  9.5041</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.45</td><td style=\"text-align: right;\">             98.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1408590\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-07-54\n",
      "  done: false\n",
      "  episode_len_mean: 99.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 9.118900000000018\n",
      "  episode_reward_min: 2.4500000000000117\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13857\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2683304820741925\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01928933892390318\n",
      "          policy_loss: -0.025454692977170148\n",
      "          total_loss: 0.1338591212761544\n",
      "          vf_explained_var: 0.9784581065177917\n",
      "          vf_loss: 0.15635511147834005\n",
      "    num_agent_steps_sampled: 1408590\n",
      "    num_agent_steps_trained: 1408590\n",
      "    num_steps_sampled: 1408590\n",
      "    num_steps_trained: 1408590\n",
      "  iterations_since_restore: 705\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.23783783783784\n",
      "    ram_util_percent: 30.9\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044275486741326114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.157904117993088\n",
      "    mean_inference_ms: 2.4653526103844143\n",
      "    mean_raw_obs_processing_ms: 2.055868736985604\n",
      "  time_since_restore: 19340.211253643036\n",
      "  time_this_iter_s: 25.80812430381775\n",
      "  time_total_s: 19340.211253643036\n",
      "  timers:\n",
      "    learn_throughput: 1163.448\n",
      "    learn_time_ms: 1717.31\n",
      "    load_throughput: 59620.78\n",
      "    load_time_ms: 33.512\n",
      "    sample_throughput: 82.155\n",
      "    sample_time_ms: 24319.947\n",
      "    update_time_ms: 10.87\n",
      "  timestamp: 1636448874\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1408590\n",
      "  training_iteration: 705\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   705</td><td style=\"text-align: right;\">         19340.2</td><td style=\"text-align: right;\">1408590</td><td style=\"text-align: right;\">  9.1189</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.45</td><td style=\"text-align: right;\">             99.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1410588\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-08-18\n",
      "  done: false\n",
      "  episode_len_mean: 100.83\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.84140000000002\n",
      "  episode_reward_min: 2.3800000000000194\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 13875\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.367545599596841\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009017536156109911\n",
      "          policy_loss: -0.056267387473157474\n",
      "          total_loss: 0.018105980026580037\n",
      "          vf_explained_var: 0.9762893915176392\n",
      "          vf_loss: 0.08073637047339054\n",
      "    num_agent_steps_sampled: 1410588\n",
      "    num_agent_steps_trained: 1410588\n",
      "    num_steps_sampled: 1410588\n",
      "    num_steps_trained: 1410588\n",
      "  iterations_since_restore: 706\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59714285714286\n",
      "    ram_util_percent: 30.865714285714283\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426722034320982\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.159155977266856\n",
      "    mean_inference_ms: 2.465181076314345\n",
      "    mean_raw_obs_processing_ms: 2.0543147086669147\n",
      "  time_since_restore: 19364.430989265442\n",
      "  time_this_iter_s: 24.219735622406006\n",
      "  time_total_s: 19364.430989265442\n",
      "  timers:\n",
      "    learn_throughput: 1162.839\n",
      "    learn_time_ms: 1718.209\n",
      "    load_throughput: 59521.943\n",
      "    load_time_ms: 33.567\n",
      "    sample_throughput: 82.369\n",
      "    sample_time_ms: 24256.784\n",
      "    update_time_ms: 10.486\n",
      "  timestamp: 1636448898\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1410588\n",
      "  training_iteration: 706\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   706</td><td style=\"text-align: right;\">         19364.4</td><td style=\"text-align: right;\">1410588</td><td style=\"text-align: right;\">  8.8414</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.38</td><td style=\"text-align: right;\">            100.83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1412586\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-08-45\n",
      "  done: false\n",
      "  episode_len_mean: 101.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.60570000000002\n",
      "  episode_reward_min: 2.3800000000000194\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13895\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3285768946011862\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013331427538354809\n",
      "          policy_loss: -0.033077572605439594\n",
      "          total_loss: 0.11261446782875628\n",
      "          vf_explained_var: 0.9804988503456116\n",
      "          vf_loss: 0.14816715923093615\n",
      "    num_agent_steps_sampled: 1412586\n",
      "    num_agent_steps_trained: 1412586\n",
      "    num_steps_sampled: 1412586\n",
      "    num_steps_trained: 1412586\n",
      "  iterations_since_restore: 707\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.38947368421051\n",
      "    ram_util_percent: 30.842105263157908\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044266978194900296\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.160425765517385\n",
      "    mean_inference_ms: 2.4651730702058665\n",
      "    mean_raw_obs_processing_ms: 2.0524018053671296\n",
      "  time_since_restore: 19390.812465190887\n",
      "  time_this_iter_s: 26.381475925445557\n",
      "  time_total_s: 19390.812465190887\n",
      "  timers:\n",
      "    learn_throughput: 1162.423\n",
      "    learn_time_ms: 1718.824\n",
      "    load_throughput: 59260.098\n",
      "    load_time_ms: 33.716\n",
      "    sample_throughput: 81.688\n",
      "    sample_time_ms: 24458.824\n",
      "    update_time_ms: 9.484\n",
      "  timestamp: 1636448925\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1412586\n",
      "  training_iteration: 707\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   707</td><td style=\"text-align: right;\">         19390.8</td><td style=\"text-align: right;\">1412586</td><td style=\"text-align: right;\">  8.6057</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.38</td><td style=\"text-align: right;\">            101.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1414584\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-09-31\n",
      "  done: false\n",
      "  episode_len_mean: 97.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000013\n",
      "  episode_reward_mean: 8.408900000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 23\n",
      "  episodes_total: 13918\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2505701479457674\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00810755379948203\n",
      "          policy_loss: -0.01854188335793359\n",
      "          total_loss: 0.33633456913133464\n",
      "          vf_explained_var: 0.945305585861206\n",
      "          vf_loss: 0.3608076205299724\n",
      "    num_agent_steps_sampled: 1414584\n",
      "    num_agent_steps_trained: 1414584\n",
      "    num_steps_sampled: 1414584\n",
      "    num_steps_trained: 1414584\n",
      "  iterations_since_restore: 708\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.17384615384616\n",
      "    ram_util_percent: 30.675384615384612\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424441800436915\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.161547744465878\n",
      "    mean_inference_ms: 2.464826409352887\n",
      "    mean_raw_obs_processing_ms: 2.0586493238253976\n",
      "  time_since_restore: 19436.836571216583\n",
      "  time_this_iter_s: 46.0241060256958\n",
      "  time_total_s: 19436.836571216583\n",
      "  timers:\n",
      "    learn_throughput: 1161.413\n",
      "    learn_time_ms: 1720.319\n",
      "    load_throughput: 59303.754\n",
      "    load_time_ms: 33.691\n",
      "    sample_throughput: 75.38\n",
      "    sample_time_ms: 26505.837\n",
      "    update_time_ms: 10.056\n",
      "  timestamp: 1636448971\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1414584\n",
      "  training_iteration: 708\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   708</td><td style=\"text-align: right;\">         19436.8</td><td style=\"text-align: right;\">1414584</td><td style=\"text-align: right;\">  8.4089</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1416582\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-09-56\n",
      "  done: false\n",
      "  episode_len_mean: 98.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000013\n",
      "  episode_reward_mean: 8.141900000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 13939\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3004207849502563\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015985798015870956\n",
      "          policy_loss: -0.05681214658986954\n",
      "          total_loss: 0.18876212109323767\n",
      "          vf_explained_var: 0.9635576009750366\n",
      "          vf_loss: 0.24561535723152614\n",
      "    num_agent_steps_sampled: 1416582\n",
      "    num_agent_steps_trained: 1416582\n",
      "    num_steps_sampled: 1416582\n",
      "    num_steps_trained: 1416582\n",
      "  iterations_since_restore: 709\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.81944444444446\n",
      "    ram_util_percent: 31.069444444444443\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426101146588104\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.1632077111594\n",
      "    mean_inference_ms: 2.465070938801475\n",
      "    mean_raw_obs_processing_ms: 2.06443385922762\n",
      "  time_since_restore: 19461.594782829285\n",
      "  time_this_iter_s: 24.758211612701416\n",
      "  time_total_s: 19461.594782829285\n",
      "  timers:\n",
      "    learn_throughput: 1161.3\n",
      "    learn_time_ms: 1720.486\n",
      "    load_throughput: 59226.258\n",
      "    load_time_ms: 33.735\n",
      "    sample_throughput: 75.817\n",
      "    sample_time_ms: 26352.806\n",
      "    update_time_ms: 10.027\n",
      "  timestamp: 1636448996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1416582\n",
      "  training_iteration: 709\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   709</td><td style=\"text-align: right;\">         19461.6</td><td style=\"text-align: right;\">1416582</td><td style=\"text-align: right;\">  8.1419</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             98.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1418580\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-10-21\n",
      "  done: false\n",
      "  episode_len_mean: 97.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000013\n",
      "  episode_reward_mean: 8.415900000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13959\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2797698616981505\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011893132661756853\n",
      "          policy_loss: -0.022780553588554974\n",
      "          total_loss: 0.13693864293219077\n",
      "          vf_explained_var: 0.9784082174301147\n",
      "          vf_loss: 0.1628725815741789\n",
      "    num_agent_steps_sampled: 1418580\n",
      "    num_agent_steps_trained: 1418580\n",
      "    num_steps_sampled: 1418580\n",
      "    num_steps_trained: 1418580\n",
      "  iterations_since_restore: 710\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.94444444444444\n",
      "    ram_util_percent: 31.13055555555555\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044247066020874505\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.163782459679126\n",
      "    mean_inference_ms: 2.464808688375326\n",
      "    mean_raw_obs_processing_ms: 2.069960834465781\n",
      "  time_since_restore: 19487.23382973671\n",
      "  time_this_iter_s: 25.639046907424927\n",
      "  time_total_s: 19487.23382973671\n",
      "  timers:\n",
      "    learn_throughput: 1161.553\n",
      "    learn_time_ms: 1720.111\n",
      "    load_throughput: 58975.136\n",
      "    load_time_ms: 33.879\n",
      "    sample_throughput: 76.736\n",
      "    sample_time_ms: 26037.331\n",
      "    update_time_ms: 9.804\n",
      "  timestamp: 1636449021\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1418580\n",
      "  training_iteration: 710\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   710</td><td style=\"text-align: right;\">         19487.2</td><td style=\"text-align: right;\">1418580</td><td style=\"text-align: right;\">  8.4159</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1420578\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-10-47\n",
      "  done: false\n",
      "  episode_len_mean: 96.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 8.465000000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 13979\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2638129977952866\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014140880565890626\n",
      "          policy_loss: -0.05343586547921101\n",
      "          total_loss: 0.14916546085760707\n",
      "          vf_explained_var: 0.9736220836639404\n",
      "          vf_loss: 0.20377240895870186\n",
      "    num_agent_steps_sampled: 1420578\n",
      "    num_agent_steps_trained: 1420578\n",
      "    num_steps_sampled: 1420578\n",
      "    num_steps_trained: 1420578\n",
      "  iterations_since_restore: 711\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.47631578947367\n",
      "    ram_util_percent: 31.25000000000001\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424016458247762\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.16496254532226\n",
      "    mean_inference_ms: 2.46470372623018\n",
      "    mean_raw_obs_processing_ms: 2.075411651450566\n",
      "  time_since_restore: 19513.335493326187\n",
      "  time_this_iter_s: 26.10166358947754\n",
      "  time_total_s: 19513.335493326187\n",
      "  timers:\n",
      "    learn_throughput: 1162.6\n",
      "    learn_time_ms: 1718.561\n",
      "    load_throughput: 58481.512\n",
      "    load_time_ms: 34.165\n",
      "    sample_throughput: 76.384\n",
      "    sample_time_ms: 26157.213\n",
      "    update_time_ms: 10.259\n",
      "  timestamp: 1636449047\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1420578\n",
      "  training_iteration: 711\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   711</td><td style=\"text-align: right;\">         19513.3</td><td style=\"text-align: right;\">1420578</td><td style=\"text-align: right;\">   8.465</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1422576\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-11-14\n",
      "  done: false\n",
      "  episode_len_mean: 94.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.516800000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 14001\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1847849249839784\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010906800150229672\n",
      "          policy_loss: -0.015475643231045631\n",
      "          total_loss: 0.1261001084177267\n",
      "          vf_explained_var: 0.9736136794090271\n",
      "          vf_loss: 0.14457911863213493\n",
      "    num_agent_steps_sampled: 1422576\n",
      "    num_agent_steps_trained: 1422576\n",
      "    num_steps_sampled: 1422576\n",
      "    num_steps_trained: 1422576\n",
      "  iterations_since_restore: 712\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.67837837837837\n",
      "    ram_util_percent: 31.394594594594587\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04421411781869592\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.166531565860478\n",
      "    mean_inference_ms: 2.4642735737609587\n",
      "    mean_raw_obs_processing_ms: 2.0792307680034043\n",
      "  time_since_restore: 19539.484904289246\n",
      "  time_this_iter_s: 26.14941096305847\n",
      "  time_total_s: 19539.484904289246\n",
      "  timers:\n",
      "    learn_throughput: 1163.673\n",
      "    learn_time_ms: 1716.978\n",
      "    load_throughput: 58232.97\n",
      "    load_time_ms: 34.31\n",
      "    sample_throughput: 76.33\n",
      "    sample_time_ms: 26175.727\n",
      "    update_time_ms: 10.0\n",
      "  timestamp: 1636449074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1422576\n",
      "  training_iteration: 712\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   712</td><td style=\"text-align: right;\">         19539.5</td><td style=\"text-align: right;\">1422576</td><td style=\"text-align: right;\">  8.5168</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             94.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1424574\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-11-38\n",
      "  done: false\n",
      "  episode_len_mean: 97.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.603500000000018\n",
      "  episode_reward_min: 2.560000000000019\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14020\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3898662550108773\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010506506437683453\n",
      "          policy_loss: -0.06077478217581908\n",
      "          total_loss: 0.020398384447963464\n",
      "          vf_explained_var: 0.9858205318450928\n",
      "          vf_loss: 0.08655194848598469\n",
      "    num_agent_steps_sampled: 1424574\n",
      "    num_agent_steps_trained: 1424574\n",
      "    num_steps_sampled: 1424574\n",
      "    num_steps_trained: 1424574\n",
      "  iterations_since_restore: 713\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.68\n",
      "    ram_util_percent: 31.508571428571422\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425220751272584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.16875254331044\n",
      "    mean_inference_ms: 2.4648596209745413\n",
      "    mean_raw_obs_processing_ms: 2.077575681208675\n",
      "  time_since_restore: 19563.71017098427\n",
      "  time_this_iter_s: 24.225266695022583\n",
      "  time_total_s: 19563.71017098427\n",
      "  timers:\n",
      "    learn_throughput: 1163.601\n",
      "    learn_time_ms: 1717.084\n",
      "    load_throughput: 57900.275\n",
      "    load_time_ms: 34.508\n",
      "    sample_throughput: 77.145\n",
      "    sample_time_ms: 25899.119\n",
      "    update_time_ms: 9.531\n",
      "  timestamp: 1636449098\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1424574\n",
      "  training_iteration: 713\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   713</td><td style=\"text-align: right;\">         19563.7</td><td style=\"text-align: right;\">1424574</td><td style=\"text-align: right;\">  8.6035</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">                2.56</td><td style=\"text-align: right;\">             97.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1426572\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-12-04\n",
      "  done: false\n",
      "  episode_len_mean: 97.25\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.987800000000016\n",
      "  episode_reward_min: 4.050000000000024\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14041\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.283646705604735\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011960673184501601\n",
      "          policy_loss: -0.0598969089399491\n",
      "          total_loss: 0.11982433633612735\n",
      "          vf_explained_var: 0.9832010865211487\n",
      "          vf_loss: 0.18285862654447554\n",
      "    num_agent_steps_sampled: 1426572\n",
      "    num_agent_steps_trained: 1426572\n",
      "    num_steps_sampled: 1426572\n",
      "    num_steps_trained: 1426572\n",
      "  iterations_since_restore: 714\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33513513513512\n",
      "    ram_util_percent: 31.597297297297295\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044251504720290755\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.170253272876895\n",
      "    mean_inference_ms: 2.464867121054764\n",
      "    mean_raw_obs_processing_ms: 2.0755915480237634\n",
      "  time_since_restore: 19589.988110780716\n",
      "  time_this_iter_s: 26.277939796447754\n",
      "  time_total_s: 19589.988110780716\n",
      "  timers:\n",
      "    learn_throughput: 1164.156\n",
      "    learn_time_ms: 1716.265\n",
      "    load_throughput: 58048.79\n",
      "    load_time_ms: 34.419\n",
      "    sample_throughput: 77.475\n",
      "    sample_time_ms: 25788.826\n",
      "    update_time_ms: 9.298\n",
      "  timestamp: 1636449124\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1426572\n",
      "  training_iteration: 714\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   714</td><td style=\"text-align: right;\">           19590</td><td style=\"text-align: right;\">1426572</td><td style=\"text-align: right;\">  8.9878</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">                4.05</td><td style=\"text-align: right;\">             97.25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1428570\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-12-29\n",
      "  done: false\n",
      "  episode_len_mean: 98.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.920600000000018\n",
      "  episode_reward_min: 2.04000000000003\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14061\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4393076652572268\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010062287145701019\n",
      "          policy_loss: -0.030382744914719036\n",
      "          total_loss: 0.08409307568023602\n",
      "          vf_explained_var: 0.9835439324378967\n",
      "          vf_loss: 0.12070924055186055\n",
      "    num_agent_steps_sampled: 1428570\n",
      "    num_agent_steps_trained: 1428570\n",
      "    num_steps_sampled: 1428570\n",
      "    num_steps_trained: 1428570\n",
      "  iterations_since_restore: 715\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.14857142857143\n",
      "    ram_util_percent: 31.602857142857147\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044250481489466524\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.17134259721023\n",
      "    mean_inference_ms: 2.4648888012143897\n",
      "    mean_raw_obs_processing_ms: 2.0737078933145963\n",
      "  time_since_restore: 19614.735328435898\n",
      "  time_this_iter_s: 24.747217655181885\n",
      "  time_total_s: 19614.735328435898\n",
      "  timers:\n",
      "    learn_throughput: 1165.652\n",
      "    learn_time_ms: 1714.062\n",
      "    load_throughput: 57998.451\n",
      "    load_time_ms: 34.449\n",
      "    sample_throughput: 77.789\n",
      "    sample_time_ms: 25684.973\n",
      "    update_time_ms: 9.458\n",
      "  timestamp: 1636449149\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1428570\n",
      "  training_iteration: 715\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   715</td><td style=\"text-align: right;\">         19614.7</td><td style=\"text-align: right;\">1428570</td><td style=\"text-align: right;\">  8.9206</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">                2.04</td><td style=\"text-align: right;\">             98.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1430568\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-12-55\n",
      "  done: false\n",
      "  episode_len_mean: 99.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.863000000000019\n",
      "  episode_reward_min: 2.04000000000003\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14081\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3018848027501788\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013983792233172126\n",
      "          policy_loss: -0.05473707162198566\n",
      "          total_loss: 0.08569193365318435\n",
      "          vf_explained_var: 0.9665969014167786\n",
      "          vf_loss: 0.14210818997096447\n",
      "    num_agent_steps_sampled: 1430568\n",
      "    num_agent_steps_trained: 1430568\n",
      "    num_steps_sampled: 1430568\n",
      "    num_steps_trained: 1430568\n",
      "  iterations_since_restore: 716\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.54054054054055\n",
      "    ram_util_percent: 31.591891891891894\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424922556830129\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.17185223511643\n",
      "    mean_inference_ms: 2.4648985142139295\n",
      "    mean_raw_obs_processing_ms: 2.071823737933851\n",
      "  time_since_restore: 19640.578410863876\n",
      "  time_this_iter_s: 25.843082427978516\n",
      "  time_total_s: 19640.578410863876\n",
      "  timers:\n",
      "    learn_throughput: 1165.927\n",
      "    learn_time_ms: 1713.659\n",
      "    load_throughput: 57956.295\n",
      "    load_time_ms: 34.474\n",
      "    sample_throughput: 77.3\n",
      "    sample_time_ms: 25847.396\n",
      "    update_time_ms: 9.775\n",
      "  timestamp: 1636449175\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1430568\n",
      "  training_iteration: 716\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   716</td><td style=\"text-align: right;\">         19640.6</td><td style=\"text-align: right;\">1430568</td><td style=\"text-align: right;\">   8.863</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.04</td><td style=\"text-align: right;\">             99.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1432566\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-13-20\n",
      "  done: false\n",
      "  episode_len_mean: 100.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.94220000000002\n",
      "  episode_reward_min: 2.04000000000003\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14101\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3651200606709435\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009418473009130785\n",
      "          policy_loss: 0.007640982507949784\n",
      "          total_loss: 0.06691027070794786\n",
      "          vf_explained_var: 0.9900712966918945\n",
      "          vf_loss: 0.06528291017526672\n",
      "    num_agent_steps_sampled: 1432566\n",
      "    num_agent_steps_trained: 1432566\n",
      "    num_steps_sampled: 1432566\n",
      "    num_steps_trained: 1432566\n",
      "  iterations_since_restore: 717\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.74444444444445\n",
      "    ram_util_percent: 31.541666666666654\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425907709302491\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.172409838772545\n",
      "    mean_inference_ms: 2.4650713656654997\n",
      "    mean_raw_obs_processing_ms: 2.0699549218668905\n",
      "  time_since_restore: 19665.866404294968\n",
      "  time_this_iter_s: 25.28799343109131\n",
      "  time_total_s: 19665.866404294968\n",
      "  timers:\n",
      "    learn_throughput: 1167.284\n",
      "    learn_time_ms: 1711.666\n",
      "    load_throughput: 58129.2\n",
      "    load_time_ms: 34.372\n",
      "    sample_throughput: 77.624\n",
      "    sample_time_ms: 25739.546\n",
      "    update_time_ms: 10.596\n",
      "  timestamp: 1636449200\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1432566\n",
      "  training_iteration: 717\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   717</td><td style=\"text-align: right;\">         19665.9</td><td style=\"text-align: right;\">1432566</td><td style=\"text-align: right;\">  8.9422</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.04</td><td style=\"text-align: right;\">            100.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1434564\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-13-45\n",
      "  done: false\n",
      "  episode_len_mean: 99.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.971000000000016\n",
      "  episode_reward_min: 2.04000000000003\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14121\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3411444124721346\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010797664821245504\n",
      "          policy_loss: -0.053732581028626075\n",
      "          total_loss: 0.06073695449602036\n",
      "          vf_explained_var: 0.9834532737731934\n",
      "          vf_loss: 0.1191249972830216\n",
      "    num_agent_steps_sampled: 1434564\n",
      "    num_agent_steps_trained: 1434564\n",
      "    num_steps_sampled: 1434564\n",
      "    num_steps_trained: 1434564\n",
      "  iterations_since_restore: 718\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.68055555555556\n",
      "    ram_util_percent: 31.51666666666666\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425735215186037\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.172846571064085\n",
      "    mean_inference_ms: 2.4650603666900817\n",
      "    mean_raw_obs_processing_ms: 2.0680569365465287\n",
      "  time_since_restore: 19691.010259389877\n",
      "  time_this_iter_s: 25.143855094909668\n",
      "  time_total_s: 19691.010259389877\n",
      "  timers:\n",
      "    learn_throughput: 1167.903\n",
      "    learn_time_ms: 1710.758\n",
      "    load_throughput: 58057.557\n",
      "    load_time_ms: 34.414\n",
      "    sample_throughput: 84.473\n",
      "    sample_time_ms: 23652.582\n",
      "    update_time_ms: 10.46\n",
      "  timestamp: 1636449225\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1434564\n",
      "  training_iteration: 718\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   718</td><td style=\"text-align: right;\">           19691</td><td style=\"text-align: right;\">1434564</td><td style=\"text-align: right;\">   8.971</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.04</td><td style=\"text-align: right;\">              99.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1436562\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-14-11\n",
      "  done: false\n",
      "  episode_len_mean: 99.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 9.005200000000016\n",
      "  episode_reward_min: 2.04000000000003\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14141\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3037128068151929\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008691990720124844\n",
      "          policy_loss: -0.02323718390294484\n",
      "          total_loss: 0.030374400370887348\n",
      "          vf_explained_var: 0.9944575428962708\n",
      "          vf_loss: 0.05960024976659389\n",
      "    num_agent_steps_sampled: 1436562\n",
      "    num_agent_steps_trained: 1436562\n",
      "    num_steps_sampled: 1436562\n",
      "    num_steps_trained: 1436562\n",
      "  iterations_since_restore: 719\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.36388888888888\n",
      "    ram_util_percent: 31.5\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427072162768687\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.173479816123926\n",
      "    mean_inference_ms: 2.4652991479583086\n",
      "    mean_raw_obs_processing_ms: 2.066140349180977\n",
      "  time_since_restore: 19716.28260087967\n",
      "  time_this_iter_s: 25.27234148979187\n",
      "  time_total_s: 19716.28260087967\n",
      "  timers:\n",
      "    learn_throughput: 1168.388\n",
      "    learn_time_ms: 1710.049\n",
      "    load_throughput: 58003.469\n",
      "    load_time_ms: 34.446\n",
      "    sample_throughput: 84.289\n",
      "    sample_time_ms: 23704.147\n",
      "    update_time_ms: 11.202\n",
      "  timestamp: 1636449251\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1436562\n",
      "  training_iteration: 719\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   719</td><td style=\"text-align: right;\">         19716.3</td><td style=\"text-align: right;\">1436562</td><td style=\"text-align: right;\">  9.0052</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                2.04</td><td style=\"text-align: right;\">             99.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1438560\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-14-37\n",
      "  done: false\n",
      "  episode_len_mean: 98.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.710000000000013\n",
      "  episode_reward_mean: 8.992400000000016\n",
      "  episode_reward_min: 3.7900000000000276\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 14163\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3613367903800238\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010008571995937784\n",
      "          policy_loss: -0.016655310881989342\n",
      "          total_loss: 0.13637435273045584\n",
      "          vf_explained_var: 0.9823057651519775\n",
      "          vf_loss: 0.15852693377860955\n",
      "    num_agent_steps_sampled: 1438560\n",
      "    num_agent_steps_trained: 1438560\n",
      "    num_steps_sampled: 1438560\n",
      "    num_steps_trained: 1438560\n",
      "  iterations_since_restore: 720\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.78108108108107\n",
      "    ram_util_percent: 31.43783783783784\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044254269816855804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.17399114364053\n",
      "    mean_inference_ms: 2.4650478310223827\n",
      "    mean_raw_obs_processing_ms: 2.0641166601628713\n",
      "  time_since_restore: 19742.194560050964\n",
      "  time_this_iter_s: 25.911959171295166\n",
      "  time_total_s: 19742.194560050964\n",
      "  timers:\n",
      "    learn_throughput: 1166.897\n",
      "    learn_time_ms: 1712.234\n",
      "    load_throughput: 58341.823\n",
      "    load_time_ms: 34.246\n",
      "    sample_throughput: 84.196\n",
      "    sample_time_ms: 23730.369\n",
      "    update_time_ms: 10.355\n",
      "  timestamp: 1636449277\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1438560\n",
      "  training_iteration: 720\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   720</td><td style=\"text-align: right;\">         19742.2</td><td style=\"text-align: right;\">1438560</td><td style=\"text-align: right;\">  8.9924</td><td style=\"text-align: right;\">               14.71</td><td style=\"text-align: right;\">                3.79</td><td style=\"text-align: right;\">             98.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1440558\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-15-03\n",
      "  done: false\n",
      "  episode_len_mean: 97.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000012\n",
      "  episode_reward_mean: 9.351500000000017\n",
      "  episode_reward_min: 6.020000000000017\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14183\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.376398898306347\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012197637569473459\n",
      "          policy_loss: -0.026145340182951518\n",
      "          total_loss: 0.07024775284032027\n",
      "          vf_explained_var: 0.989946186542511\n",
      "          vf_loss: 0.10026583929679224\n",
      "    num_agent_steps_sampled: 1440558\n",
      "    num_agent_steps_trained: 1440558\n",
      "    num_steps_sampled: 1440558\n",
      "    num_steps_trained: 1440558\n",
      "  iterations_since_restore: 721\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.36052631578947\n",
      "    ram_util_percent: 31.421052631578952\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425463834887594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.175335685650783\n",
      "    mean_inference_ms: 2.4650500246854934\n",
      "    mean_raw_obs_processing_ms: 2.062277411092936\n",
      "  time_since_restore: 19768.68116211891\n",
      "  time_this_iter_s: 26.486602067947388\n",
      "  time_total_s: 19768.68116211891\n",
      "  timers:\n",
      "    learn_throughput: 1165.963\n",
      "    learn_time_ms: 1713.605\n",
      "    load_throughput: 58533.062\n",
      "    load_time_ms: 34.135\n",
      "    sample_throughput: 84.063\n",
      "    sample_time_ms: 23767.899\n",
      "    update_time_ms: 9.927\n",
      "  timestamp: 1636449303\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1440558\n",
      "  training_iteration: 721\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   721</td><td style=\"text-align: right;\">         19768.7</td><td style=\"text-align: right;\">1440558</td><td style=\"text-align: right;\">  9.3515</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                6.02</td><td style=\"text-align: right;\">             97.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1442556\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-15-29\n",
      "  done: false\n",
      "  episode_len_mean: 96.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 9.513700000000018\n",
      "  episode_reward_min: 4.40000000000002\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14204\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2734625393436068\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008345899529486223\n",
      "          policy_loss: -0.03366851003042289\n",
      "          total_loss: 0.05077763444611005\n",
      "          vf_explained_var: 0.9903940558433533\n",
      "          vf_loss: 0.0904129566713458\n",
      "    num_agent_steps_sampled: 1442556\n",
      "    num_agent_steps_trained: 1442556\n",
      "    num_steps_sampled: 1442556\n",
      "    num_steps_trained: 1442556\n",
      "  iterations_since_restore: 722\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.82702702702704\n",
      "    ram_util_percent: 31.42432432432432\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044255407647157574\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.176831464954404\n",
      "    mean_inference_ms: 2.465048533207151\n",
      "    mean_raw_obs_processing_ms: 2.0603827781863124\n",
      "  time_since_restore: 19794.33788394928\n",
      "  time_this_iter_s: 25.656721830368042\n",
      "  time_total_s: 19794.33788394928\n",
      "  timers:\n",
      "    learn_throughput: 1166.037\n",
      "    learn_time_ms: 1713.497\n",
      "    load_throughput: 58943.942\n",
      "    load_time_ms: 33.897\n",
      "    sample_throughput: 84.237\n",
      "    sample_time_ms: 23718.853\n",
      "    update_time_ms: 9.685\n",
      "  timestamp: 1636449329\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1442556\n",
      "  training_iteration: 722\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   722</td><td style=\"text-align: right;\">         19794.3</td><td style=\"text-align: right;\">1442556</td><td style=\"text-align: right;\">  9.5137</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                 4.4</td><td style=\"text-align: right;\">             96.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1444554\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-15-54\n",
      "  done: false\n",
      "  episode_len_mean: 97.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 9.178900000000018\n",
      "  episode_reward_min: 4.09000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14224\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3948853447323755\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0137715748408687\n",
      "          policy_loss: -0.032554617417710166\n",
      "          total_loss: 0.07501030473836831\n",
      "          vf_explained_var: 0.9793698191642761\n",
      "          vf_loss: 0.11034620351025036\n",
      "    num_agent_steps_sampled: 1444554\n",
      "    num_agent_steps_trained: 1444554\n",
      "    num_steps_sampled: 1444554\n",
      "    num_steps_trained: 1444554\n",
      "  iterations_since_restore: 723\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00277777777778\n",
      "    ram_util_percent: 31.41111111111111\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424585081682805\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.177929450469392\n",
      "    mean_inference_ms: 2.464884530316405\n",
      "    mean_raw_obs_processing_ms: 2.0585175567318843\n",
      "  time_since_restore: 19819.29627251625\n",
      "  time_this_iter_s: 24.958388566970825\n",
      "  time_total_s: 19819.29627251625\n",
      "  timers:\n",
      "    learn_throughput: 1164.502\n",
      "    learn_time_ms: 1715.755\n",
      "    load_throughput: 59375.352\n",
      "    load_time_ms: 33.65\n",
      "    sample_throughput: 83.982\n",
      "    sample_time_ms: 23790.717\n",
      "    update_time_ms: 9.405\n",
      "  timestamp: 1636449354\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1444554\n",
      "  training_iteration: 723\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   723</td><td style=\"text-align: right;\">         19819.3</td><td style=\"text-align: right;\">1444554</td><td style=\"text-align: right;\">  9.1789</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                4.09</td><td style=\"text-align: right;\">             97.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1446552\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-16-19\n",
      "  done: false\n",
      "  episode_len_mean: 98.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.925900000000018\n",
      "  episode_reward_min: 4.09000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14244\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3157034181413196\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013054119493138356\n",
      "          policy_loss: -0.013813453753079687\n",
      "          total_loss: 0.2439291763163748\n",
      "          vf_explained_var: 0.968942403793335\n",
      "          vf_loss: 0.26031388665239014\n",
      "    num_agent_steps_sampled: 1446552\n",
      "    num_agent_steps_trained: 1446552\n",
      "    num_steps_sampled: 1446552\n",
      "    num_steps_trained: 1446552\n",
      "  iterations_since_restore: 724\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.53888888888888\n",
      "    ram_util_percent: 31.416666666666668\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424381447637009\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.178970762374792\n",
      "    mean_inference_ms: 2.464799967536801\n",
      "    mean_raw_obs_processing_ms: 2.056790692780312\n",
      "  time_since_restore: 19844.66955089569\n",
      "  time_this_iter_s: 25.373278379440308\n",
      "  time_total_s: 19844.66955089569\n",
      "  timers:\n",
      "    learn_throughput: 1163.809\n",
      "    learn_time_ms: 1716.777\n",
      "    load_throughput: 59269.906\n",
      "    load_time_ms: 33.71\n",
      "    sample_throughput: 84.308\n",
      "    sample_time_ms: 23698.779\n",
      "    update_time_ms: 9.704\n",
      "  timestamp: 1636449379\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1446552\n",
      "  training_iteration: 724\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   724</td><td style=\"text-align: right;\">         19844.7</td><td style=\"text-align: right;\">1446552</td><td style=\"text-align: right;\">  8.9259</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                4.09</td><td style=\"text-align: right;\">             98.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1448550\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-17-02\n",
      "  done: false\n",
      "  episode_len_mean: 96.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.81620000000002\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 22\n",
      "  episodes_total: 14266\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3380583734739395\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015794081772538552\n",
      "          policy_loss: 0.015332226614866938\n",
      "          total_loss: 0.5111816029818285\n",
      "          vf_explained_var: 0.9383745193481445\n",
      "          vf_loss: 0.49642230286484673\n",
      "    num_agent_steps_sampled: 1448550\n",
      "    num_agent_steps_trained: 1448550\n",
      "    num_steps_sampled: 1448550\n",
      "    num_steps_trained: 1448550\n",
      "  iterations_since_restore: 725\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.40327868852458\n",
      "    ram_util_percent: 31.190163934426227\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044235298854251676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.179764392808664\n",
      "    mean_inference_ms: 2.4646104816829473\n",
      "    mean_raw_obs_processing_ms: 2.0603403452452302\n",
      "  time_since_restore: 19887.276061296463\n",
      "  time_this_iter_s: 42.606510400772095\n",
      "  time_total_s: 19887.276061296463\n",
      "  timers:\n",
      "    learn_throughput: 1161.932\n",
      "    learn_time_ms: 1719.55\n",
      "    load_throughput: 59413.364\n",
      "    load_time_ms: 33.629\n",
      "    sample_throughput: 78.407\n",
      "    sample_time_ms: 25482.34\n",
      "    update_time_ms: 9.398\n",
      "  timestamp: 1636449422\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1448550\n",
      "  training_iteration: 725\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   725</td><td style=\"text-align: right;\">         19887.3</td><td style=\"text-align: right;\">1448550</td><td style=\"text-align: right;\">  8.8162</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1450548\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-17-40\n",
      "  done: false\n",
      "  episode_len_mean: 96.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000015\n",
      "  episode_reward_mean: 8.417700000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14286\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4408395338626134\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01083991841691267\n",
      "          policy_loss: -0.08202542591662634\n",
      "          total_loss: 0.04049351210040705\n",
      "          vf_explained_var: 0.9768261313438416\n",
      "          vf_loss: 0.12813708478850977\n",
      "    num_agent_steps_sampled: 1450548\n",
      "    num_agent_steps_trained: 1450548\n",
      "    num_steps_sampled: 1450548\n",
      "    num_steps_trained: 1450548\n",
      "  iterations_since_restore: 726\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.96296296296299\n",
      "    ram_util_percent: 31.274074074074065\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422050022797716\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.179378453489672\n",
      "    mean_inference_ms: 2.4643273403267902\n",
      "    mean_raw_obs_processing_ms: 2.065493087710451\n",
      "  time_since_restore: 19925.207847595215\n",
      "  time_this_iter_s: 37.93178629875183\n",
      "  time_total_s: 19925.207847595215\n",
      "  timers:\n",
      "    learn_throughput: 1160.797\n",
      "    learn_time_ms: 1721.231\n",
      "    load_throughput: 59693.444\n",
      "    load_time_ms: 33.471\n",
      "    sample_throughput: 74.861\n",
      "    sample_time_ms: 26689.64\n",
      "    update_time_ms: 9.457\n",
      "  timestamp: 1636449460\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1450548\n",
      "  training_iteration: 726\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   726</td><td style=\"text-align: right;\">         19925.2</td><td style=\"text-align: right;\">1450548</td><td style=\"text-align: right;\">  8.4177</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             96.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1452546\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-18-05\n",
      "  done: false\n",
      "  episode_len_mean: 97.86\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 8.173200000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14307\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3066244710059394\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0177831616465032\n",
      "          policy_loss: -0.026724471692882834\n",
      "          total_loss: 0.3243134947404975\n",
      "          vf_explained_var: 0.9593973755836487\n",
      "          vf_loss: 0.34968357877362344\n",
      "    num_agent_steps_sampled: 1452546\n",
      "    num_agent_steps_trained: 1452546\n",
      "    num_steps_sampled: 1452546\n",
      "    num_steps_trained: 1452546\n",
      "  iterations_since_restore: 727\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.525\n",
      "    ram_util_percent: 31.216666666666665\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04421978492915366\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.179239289139815\n",
      "    mean_inference_ms: 2.4642949388966526\n",
      "    mean_raw_obs_processing_ms: 2.0708729435234647\n",
      "  time_since_restore: 19950.624363422394\n",
      "  time_this_iter_s: 25.416515827178955\n",
      "  time_total_s: 19950.624363422394\n",
      "  timers:\n",
      "    learn_throughput: 1159.854\n",
      "    learn_time_ms: 1722.63\n",
      "    load_throughput: 59726.458\n",
      "    load_time_ms: 33.453\n",
      "    sample_throughput: 74.826\n",
      "    sample_time_ms: 26702.035\n",
      "    update_time_ms: 8.483\n",
      "  timestamp: 1636449485\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1452546\n",
      "  training_iteration: 727\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   727</td><td style=\"text-align: right;\">         19950.6</td><td style=\"text-align: right;\">1452546</td><td style=\"text-align: right;\">  8.1732</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1454544\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-18-31\n",
      "  done: false\n",
      "  episode_len_mean: 97.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 8.525800000000016\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14326\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3555492781457448\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013693946535145135\n",
      "          policy_loss: -0.016771529881017547\n",
      "          total_loss: 0.17864038470600332\n",
      "          vf_explained_var: 0.9812930226325989\n",
      "          vf_loss: 0.19786278185035502\n",
      "    num_agent_steps_sampled: 1454544\n",
      "    num_agent_steps_trained: 1454544\n",
      "    num_steps_sampled: 1454544\n",
      "    num_steps_trained: 1454544\n",
      "  iterations_since_restore: 728\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.45675675675676\n",
      "    ram_util_percent: 31.294594594594603\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423301313183632\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.179522536957148\n",
      "    mean_inference_ms: 2.4645111466982565\n",
      "    mean_raw_obs_processing_ms: 2.075719470862434\n",
      "  time_since_restore: 19976.08393597603\n",
      "  time_this_iter_s: 25.459572553634644\n",
      "  time_total_s: 19976.08393597603\n",
      "  timers:\n",
      "    learn_throughput: 1158.769\n",
      "    learn_time_ms: 1724.244\n",
      "    load_throughput: 59645.477\n",
      "    load_time_ms: 33.498\n",
      "    sample_throughput: 74.742\n",
      "    sample_time_ms: 26732.069\n",
      "    update_time_ms: 8.243\n",
      "  timestamp: 1636449511\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1454544\n",
      "  training_iteration: 728\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   728</td><td style=\"text-align: right;\">         19976.1</td><td style=\"text-align: right;\">1454544</td><td style=\"text-align: right;\">  8.5258</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1456542\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-18-55\n",
      "  done: false\n",
      "  episode_len_mean: 97.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 8.597400000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14346\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4168452773775373\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014484459326759978\n",
      "          policy_loss: -0.019293680893523353\n",
      "          total_loss: 0.2188887469027014\n",
      "          vf_explained_var: 0.9649420380592346\n",
      "          vf_loss: 0.24060521786588998\n",
      "    num_agent_steps_sampled: 1456542\n",
      "    num_agent_steps_trained: 1456542\n",
      "    num_steps_sampled: 1456542\n",
      "    num_steps_trained: 1456542\n",
      "  iterations_since_restore: 729\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.00588235294119\n",
      "    ram_util_percent: 31.358823529411758\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423077040097785\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.179255656745468\n",
      "    mean_inference_ms: 2.464476671522316\n",
      "    mean_raw_obs_processing_ms: 2.080805484508002\n",
      "  time_since_restore: 20000.364231586456\n",
      "  time_this_iter_s: 24.280295610427856\n",
      "  time_total_s: 20000.364231586456\n",
      "  timers:\n",
      "    learn_throughput: 1157.819\n",
      "    learn_time_ms: 1725.659\n",
      "    load_throughput: 59933.113\n",
      "    load_time_ms: 33.337\n",
      "    sample_throughput: 75.022\n",
      "    sample_time_ms: 26632.021\n",
      "    update_time_ms: 7.51\n",
      "  timestamp: 1636449535\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1456542\n",
      "  training_iteration: 729\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   729</td><td style=\"text-align: right;\">         20000.4</td><td style=\"text-align: right;\">1456542</td><td style=\"text-align: right;\">  8.5974</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">             97.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1458540\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-19-21\n",
      "  done: false\n",
      "  episode_len_mean: 99.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 8.864100000000017\n",
      "  episode_reward_min: 2.240000000000014\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14367\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.255632468064626\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011781849452241151\n",
      "          policy_loss: -0.021836299990259465\n",
      "          total_loss: 0.21769836745446636\n",
      "          vf_explained_var: 0.971335768699646\n",
      "          vf_loss: 0.24253691945757186\n",
      "    num_agent_steps_sampled: 1458540\n",
      "    num_agent_steps_trained: 1458540\n",
      "    num_steps_sampled: 1458540\n",
      "    num_steps_trained: 1458540\n",
      "  iterations_since_restore: 730\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.07368421052634\n",
      "    ram_util_percent: 31.478947368421046\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425321078419286\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.179983294345366\n",
      "    mean_inference_ms: 2.464869292875756\n",
      "    mean_raw_obs_processing_ms: 2.0802402678759275\n",
      "  time_since_restore: 20026.683856010437\n",
      "  time_this_iter_s: 26.319624423980713\n",
      "  time_total_s: 20026.683856010437\n",
      "  timers:\n",
      "    learn_throughput: 1158.754\n",
      "    learn_time_ms: 1724.266\n",
      "    load_throughput: 59911.817\n",
      "    load_time_ms: 33.349\n",
      "    sample_throughput: 74.905\n",
      "    sample_time_ms: 26673.754\n",
      "    update_time_ms: 7.949\n",
      "  timestamp: 1636449561\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1458540\n",
      "  training_iteration: 730\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   730</td><td style=\"text-align: right;\">         20026.7</td><td style=\"text-align: right;\">1458540</td><td style=\"text-align: right;\">  8.8641</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                2.24</td><td style=\"text-align: right;\">             99.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1460538\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-19-47\n",
      "  done: false\n",
      "  episode_len_mean: 98.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 8.875400000000017\n",
      "  episode_reward_min: 2.240000000000014\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14388\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.284760924748012\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011622344286517818\n",
      "          policy_loss: -0.01653712076090631\n",
      "          total_loss: 0.18227842544161138\n",
      "          vf_explained_var: 0.9699729084968567\n",
      "          vf_loss: 0.2022384255769707\n",
      "    num_agent_steps_sampled: 1460538\n",
      "    num_agent_steps_trained: 1460538\n",
      "    num_steps_sampled: 1460538\n",
      "    num_steps_trained: 1460538\n",
      "  iterations_since_restore: 731\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.80277777777778\n",
      "    ram_util_percent: 31.58055555555556\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442514681406757\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.180994587652876\n",
      "    mean_inference_ms: 2.46486521760442\n",
      "    mean_raw_obs_processing_ms: 2.0782907022004906\n",
      "  time_since_restore: 20052.002405166626\n",
      "  time_this_iter_s: 25.318549156188965\n",
      "  time_total_s: 20052.002405166626\n",
      "  timers:\n",
      "    learn_throughput: 1159.41\n",
      "    learn_time_ms: 1723.29\n",
      "    load_throughput: 60122.001\n",
      "    load_time_ms: 33.232\n",
      "    sample_throughput: 75.23\n",
      "    sample_time_ms: 26558.452\n",
      "    update_time_ms: 7.649\n",
      "  timestamp: 1636449587\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1460538\n",
      "  training_iteration: 731\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   731</td><td style=\"text-align: right;\">           20052</td><td style=\"text-align: right;\">1460538</td><td style=\"text-align: right;\">  8.8754</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                2.24</td><td style=\"text-align: right;\">             98.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1462536\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-20-12\n",
      "  done: false\n",
      "  episode_len_mean: 98.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.690000000000014\n",
      "  episode_reward_mean: 9.244300000000017\n",
      "  episode_reward_min: 2.7000000000000184\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14408\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3360064756302608\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010349919547245621\n",
      "          policy_loss: -0.06597645657048339\n",
      "          total_loss: 0.0940927607672555\n",
      "          vf_explained_var: 0.9790105819702148\n",
      "          vf_loss: 0.1650363821891092\n",
      "    num_agent_steps_sampled: 1462536\n",
      "    num_agent_steps_trained: 1462536\n",
      "    num_steps_sampled: 1462536\n",
      "    num_steps_trained: 1462536\n",
      "  iterations_since_restore: 732\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.25675675675674\n",
      "    ram_util_percent: 31.597297297297303\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426498162333841\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.18224845185438\n",
      "    mean_inference_ms: 2.4650987188003346\n",
      "    mean_raw_obs_processing_ms: 2.0764086363586576\n",
      "  time_since_restore: 20077.629554271698\n",
      "  time_this_iter_s: 25.62714910507202\n",
      "  time_total_s: 20077.629554271698\n",
      "  timers:\n",
      "    learn_throughput: 1158.228\n",
      "    learn_time_ms: 1725.049\n",
      "    load_throughput: 59954.466\n",
      "    load_time_ms: 33.325\n",
      "    sample_throughput: 75.245\n",
      "    sample_time_ms: 26553.27\n",
      "    update_time_ms: 8.315\n",
      "  timestamp: 1636449612\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1462536\n",
      "  training_iteration: 732\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   732</td><td style=\"text-align: right;\">         20077.6</td><td style=\"text-align: right;\">1462536</td><td style=\"text-align: right;\">  9.2443</td><td style=\"text-align: right;\">               14.69</td><td style=\"text-align: right;\">                 2.7</td><td style=\"text-align: right;\">             98.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1464534\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-20-36\n",
      "  done: false\n",
      "  episode_len_mean: 98.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000015\n",
      "  episode_reward_mean: 8.865000000000018\n",
      "  episode_reward_min: 3.0400000000000156\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14427\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4012778957684835\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011349619038908573\n",
      "          policy_loss: -0.016447316393965766\n",
      "          total_loss: 0.14325855683890126\n",
      "          vf_explained_var: 0.977283775806427\n",
      "          vf_loss: 0.16451508053356692\n",
      "    num_agent_steps_sampled: 1464534\n",
      "    num_agent_steps_trained: 1464534\n",
      "    num_steps_sampled: 1464534\n",
      "    num_steps_trained: 1464534\n",
      "  iterations_since_restore: 733\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.76470588235294\n",
      "    ram_util_percent: 31.523529411764706\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426013962647767\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.182862086184205\n",
      "    mean_inference_ms: 2.465012989330889\n",
      "    mean_raw_obs_processing_ms: 2.0746986714208084\n",
      "  time_since_restore: 20101.716568231583\n",
      "  time_this_iter_s: 24.087013959884644\n",
      "  time_total_s: 20101.716568231583\n",
      "  timers:\n",
      "    learn_throughput: 1159.432\n",
      "    learn_time_ms: 1723.258\n",
      "    load_throughput: 59499.249\n",
      "    load_time_ms: 33.58\n",
      "    sample_throughput: 75.489\n",
      "    sample_time_ms: 26467.421\n",
      "    update_time_ms: 8.1\n",
      "  timestamp: 1636449636\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1464534\n",
      "  training_iteration: 733\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   733</td><td style=\"text-align: right;\">         20101.7</td><td style=\"text-align: right;\">1464534</td><td style=\"text-align: right;\">   8.865</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">                3.04</td><td style=\"text-align: right;\">             98.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1466532\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 98.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.610000000000014\n",
      "  episode_reward_mean: 8.927100000000017\n",
      "  episode_reward_min: 3.0400000000000156\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14448\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.40463026818775\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011156920271087974\n",
      "          policy_loss: -0.02730188878873984\n",
      "          total_loss: 0.19583196712746506\n",
      "          vf_explained_var: 0.9691962599754333\n",
      "          vf_loss: 0.22813285037520387\n",
      "    num_agent_steps_sampled: 1466532\n",
      "    num_agent_steps_trained: 1466532\n",
      "    num_steps_sampled: 1466532\n",
      "    num_steps_trained: 1466532\n",
      "  iterations_since_restore: 734\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.10833333333333\n",
      "    ram_util_percent: 31.502777777777776\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044248194251054064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.183642521955697\n",
      "    mean_inference_ms: 2.4648483766420397\n",
      "    mean_raw_obs_processing_ms: 2.0727293914430374\n",
      "  time_since_restore: 20126.97496032715\n",
      "  time_this_iter_s: 25.258392095565796\n",
      "  time_total_s: 20126.97496032715\n",
      "  timers:\n",
      "    learn_throughput: 1159.384\n",
      "    learn_time_ms: 1723.329\n",
      "    load_throughput: 59383.641\n",
      "    load_time_ms: 33.646\n",
      "    sample_throughput: 75.522\n",
      "    sample_time_ms: 26455.792\n",
      "    update_time_ms: 7.917\n",
      "  timestamp: 1636449662\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1466532\n",
      "  training_iteration: 734\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   734</td><td style=\"text-align: right;\">           20127</td><td style=\"text-align: right;\">1466532</td><td style=\"text-align: right;\">  8.9271</td><td style=\"text-align: right;\">               14.61</td><td style=\"text-align: right;\">                3.04</td><td style=\"text-align: right;\">             98.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1468530\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-21-28\n",
      "  done: false\n",
      "  episode_len_mean: 98.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000015\n",
      "  episode_reward_mean: 9.031900000000014\n",
      "  episode_reward_min: 3.0400000000000156\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14468\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2884160643532163\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01556849931937716\n",
      "          policy_loss: -0.004182571740377517\n",
      "          total_loss: 0.2679397824708195\n",
      "          vf_explained_var: 0.9700998067855835\n",
      "          vf_loss: 0.2723817912063428\n",
      "    num_agent_steps_sampled: 1468530\n",
      "    num_agent_steps_trained: 1468530\n",
      "    num_steps_sampled: 1468530\n",
      "    num_steps_trained: 1468530\n",
      "  iterations_since_restore: 735\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.83243243243244\n",
      "    ram_util_percent: 31.5054054054054\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426173882386873\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.18445009374127\n",
      "    mean_inference_ms: 2.465089613484142\n",
      "    mean_raw_obs_processing_ms: 2.070871781058091\n",
      "  time_since_restore: 20153.10764026642\n",
      "  time_this_iter_s: 26.13267993927002\n",
      "  time_total_s: 20153.10764026642\n",
      "  timers:\n",
      "    learn_throughput: 1160.441\n",
      "    learn_time_ms: 1721.759\n",
      "    load_throughput: 59086.283\n",
      "    load_time_ms: 33.815\n",
      "    sample_throughput: 80.533\n",
      "    sample_time_ms: 24809.572\n",
      "    update_time_ms: 7.885\n",
      "  timestamp: 1636449688\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1468530\n",
      "  training_iteration: 735\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   735</td><td style=\"text-align: right;\">         20153.1</td><td style=\"text-align: right;\">1468530</td><td style=\"text-align: right;\">  9.0319</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">                3.04</td><td style=\"text-align: right;\">              98.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1470528\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-21-53\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000015\n",
      "  episode_reward_mean: 9.126900000000017\n",
      "  episode_reward_min: 2.8200000000000176\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14487\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4024760371162779\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014763886808595006\n",
      "          policy_loss: -0.04632566686542261\n",
      "          total_loss: 0.2219617084910472\n",
      "          vf_explained_var: 0.9553524851799011\n",
      "          vf_loss: 0.27033988787304786\n",
      "    num_agent_steps_sampled: 1470528\n",
      "    num_agent_steps_trained: 1470528\n",
      "    num_steps_sampled: 1470528\n",
      "    num_steps_trained: 1470528\n",
      "  iterations_since_restore: 736\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.92777777777778\n",
      "    ram_util_percent: 31.472222222222214\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425838499775716\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.18487060312417\n",
      "    mean_inference_ms: 2.4650103456919585\n",
      "    mean_raw_obs_processing_ms: 2.069179245483754\n",
      "  time_since_restore: 20178.07477736473\n",
      "  time_this_iter_s: 24.967137098312378\n",
      "  time_total_s: 20178.07477736473\n",
      "  timers:\n",
      "    learn_throughput: 1161.382\n",
      "    learn_time_ms: 1720.364\n",
      "    load_throughput: 58922.225\n",
      "    load_time_ms: 33.909\n",
      "    sample_throughput: 84.97\n",
      "    sample_time_ms: 23514.199\n",
      "    update_time_ms: 7.958\n",
      "  timestamp: 1636449713\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1470528\n",
      "  training_iteration: 736\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   736</td><td style=\"text-align: right;\">         20178.1</td><td style=\"text-align: right;\">1470528</td><td style=\"text-align: right;\">  9.1269</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">                2.82</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1472526\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-22-20\n",
      "  done: false\n",
      "  episode_len_mean: 101.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000015\n",
      "  episode_reward_mean: 8.774900000000017\n",
      "  episode_reward_min: 2.5300000000000233\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14506\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4111402500243413\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008770753231209127\n",
      "          policy_loss: 0.011650483292483148\n",
      "          total_loss: 0.11237498610502197\n",
      "          vf_explained_var: 0.9784845113754272\n",
      "          vf_loss: 0.10772357448225929\n",
      "    num_agent_steps_sampled: 1472526\n",
      "    num_agent_steps_trained: 1472526\n",
      "    num_steps_sampled: 1472526\n",
      "    num_steps_trained: 1472526\n",
      "  iterations_since_restore: 737\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.79736842105262\n",
      "    ram_util_percent: 31.415789473684214\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044240560415947844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.184763031413148\n",
      "    mean_inference_ms: 2.4646819409135863\n",
      "    mean_raw_obs_processing_ms: 2.0674691479047618\n",
      "  time_since_restore: 20204.75018811226\n",
      "  time_this_iter_s: 26.675410747528076\n",
      "  time_total_s: 20204.75018811226\n",
      "  timers:\n",
      "    learn_throughput: 1161.705\n",
      "    learn_time_ms: 1719.885\n",
      "    load_throughput: 58818.959\n",
      "    load_time_ms: 33.969\n",
      "    sample_throughput: 84.517\n",
      "    sample_time_ms: 23640.133\n",
      "    update_time_ms: 8.073\n",
      "  timestamp: 1636449740\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1472526\n",
      "  training_iteration: 737\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   737</td><td style=\"text-align: right;\">         20204.8</td><td style=\"text-align: right;\">1472526</td><td style=\"text-align: right;\">  8.7749</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">                2.53</td><td style=\"text-align: right;\">            101.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1474524\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-22-46\n",
      "  done: false\n",
      "  episode_len_mean: 101.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000015\n",
      "  episode_reward_mean: 8.918000000000019\n",
      "  episode_reward_min: 2.5300000000000233\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14526\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3654576874914623\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010941719558483573\n",
      "          policy_loss: -0.08572297587635971\n",
      "          total_loss: 0.05570207302059446\n",
      "          vf_explained_var: 0.9854839444160461\n",
      "          vf_loss: 0.14620682669005225\n",
      "    num_agent_steps_sampled: 1474524\n",
      "    num_agent_steps_trained: 1474524\n",
      "    num_steps_sampled: 1474524\n",
      "    num_steps_trained: 1474524\n",
      "  iterations_since_restore: 738\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33243243243244\n",
      "    ram_util_percent: 31.405405405405407\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426055809456561\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.185582910204676\n",
      "    mean_inference_ms: 2.4649918083031235\n",
      "    mean_raw_obs_processing_ms: 2.0655064159443084\n",
      "  time_since_restore: 20230.727375745773\n",
      "  time_this_iter_s: 25.977187633514404\n",
      "  time_total_s: 20230.727375745773\n",
      "  timers:\n",
      "    learn_throughput: 1160.341\n",
      "    learn_time_ms: 1721.908\n",
      "    load_throughput: 58658.679\n",
      "    load_time_ms: 34.061\n",
      "    sample_throughput: 84.341\n",
      "    sample_time_ms: 23689.464\n",
      "    update_time_ms: 8.544\n",
      "  timestamp: 1636449766\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1474524\n",
      "  training_iteration: 738\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   738</td><td style=\"text-align: right;\">         20230.7</td><td style=\"text-align: right;\">1474524</td><td style=\"text-align: right;\">   8.918</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">                2.53</td><td style=\"text-align: right;\">            101.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1476522\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-23-18\n",
      "  done: false\n",
      "  episode_len_mean: 101.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000015\n",
      "  episode_reward_mean: 8.897700000000018\n",
      "  episode_reward_min: 2.5300000000000233\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14546\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3784159700075784\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014680687126363282\n",
      "          policy_loss: -0.038714049304170266\n",
      "          total_loss: 0.19034699983894826\n",
      "          vf_explained_var: 0.9499005079269409\n",
      "          vf_loss: 0.23094042834071887\n",
      "    num_agent_steps_sampled: 1476522\n",
      "    num_agent_steps_trained: 1476522\n",
      "    num_steps_sampled: 1476522\n",
      "    num_steps_trained: 1476522\n",
      "  iterations_since_restore: 739\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.59782608695652\n",
      "    ram_util_percent: 31.463043478260875\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424802826309797\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.188802994589988\n",
      "    mean_inference_ms: 2.4647321206695065\n",
      "    mean_raw_obs_processing_ms: 2.0636548442222122\n",
      "  time_since_restore: 20262.9228181839\n",
      "  time_this_iter_s: 32.19544243812561\n",
      "  time_total_s: 20262.9228181839\n",
      "  timers:\n",
      "    learn_throughput: 1160.173\n",
      "    learn_time_ms: 1722.157\n",
      "    load_throughput: 58555.351\n",
      "    load_time_ms: 34.122\n",
      "    sample_throughput: 81.617\n",
      "    sample_time_ms: 24480.082\n",
      "    update_time_ms: 9.432\n",
      "  timestamp: 1636449798\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1476522\n",
      "  training_iteration: 739\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   739</td><td style=\"text-align: right;\">         20262.9</td><td style=\"text-align: right;\">1476522</td><td style=\"text-align: right;\">  8.8977</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">                2.53</td><td style=\"text-align: right;\">            101.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1478520\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-23-47\n",
      "  done: false\n",
      "  episode_len_mean: 103.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.620000000000015\n",
      "  episode_reward_mean: 8.608100000000016\n",
      "  episode_reward_min: 2.5300000000000233\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14565\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2951421170007615\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013674452472592573\n",
      "          policy_loss: -0.03320092959772973\n",
      "          total_loss: 0.14939617403738556\n",
      "          vf_explained_var: 0.9607049822807312\n",
      "          vf_loss: 0.1844597123385895\n",
      "    num_agent_steps_sampled: 1478520\n",
      "    num_agent_steps_trained: 1478520\n",
      "    num_steps_sampled: 1478520\n",
      "    num_steps_trained: 1478520\n",
      "  iterations_since_restore: 740\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.5404761904762\n",
      "    ram_util_percent: 31.407142857142862\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424583266272512\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.1927636083899\n",
      "    mean_inference_ms: 2.4646326128957785\n",
      "    mean_raw_obs_processing_ms: 2.0619454854026613\n",
      "  time_since_restore: 20292.003447055817\n",
      "  time_this_iter_s: 29.080628871917725\n",
      "  time_total_s: 20292.003447055817\n",
      "  timers:\n",
      "    learn_throughput: 1159.961\n",
      "    learn_time_ms: 1722.472\n",
      "    load_throughput: 58415.594\n",
      "    load_time_ms: 34.203\n",
      "    sample_throughput: 80.71\n",
      "    sample_time_ms: 24755.392\n",
      "    update_time_ms: 10.0\n",
      "  timestamp: 1636449827\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1478520\n",
      "  training_iteration: 740\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   740</td><td style=\"text-align: right;\">           20292</td><td style=\"text-align: right;\">1478520</td><td style=\"text-align: right;\">  8.6081</td><td style=\"text-align: right;\">               14.62</td><td style=\"text-align: right;\">                2.53</td><td style=\"text-align: right;\">            103.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1480518\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-24-12\n",
      "  done: false\n",
      "  episode_len_mean: 102.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.430000000000012\n",
      "  episode_reward_mean: 8.140100000000016\n",
      "  episode_reward_min: 0.8500000000000068\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14585\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4008424957593282\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009497220103103946\n",
      "          policy_loss: -0.06828908817399115\n",
      "          total_loss: 0.053263115492605026\n",
      "          vf_explained_var: 0.9783375263214111\n",
      "          vf_loss: 0.12785919509118512\n",
      "    num_agent_steps_sampled: 1480518\n",
      "    num_agent_steps_trained: 1480518\n",
      "    num_steps_sampled: 1480518\n",
      "    num_steps_trained: 1480518\n",
      "  iterations_since_restore: 741\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.9457142857143\n",
      "    ram_util_percent: 31.288571428571434\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424968650672907\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.196974325933482\n",
      "    mean_inference_ms: 2.4646830105382342\n",
      "    mean_raw_obs_processing_ms: 2.0600140870228625\n",
      "  time_since_restore: 20316.931123256683\n",
      "  time_this_iter_s: 24.9276762008667\n",
      "  time_total_s: 20316.931123256683\n",
      "  timers:\n",
      "    learn_throughput: 1160.335\n",
      "    learn_time_ms: 1721.917\n",
      "    load_throughput: 58289.312\n",
      "    load_time_ms: 34.277\n",
      "    sample_throughput: 80.838\n",
      "    sample_time_ms: 24716.035\n",
      "    update_time_ms: 10.68\n",
      "  timestamp: 1636449852\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1480518\n",
      "  training_iteration: 741\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   741</td><td style=\"text-align: right;\">         20316.9</td><td style=\"text-align: right;\">1480518</td><td style=\"text-align: right;\">  8.1401</td><td style=\"text-align: right;\">               14.43</td><td style=\"text-align: right;\">                0.85</td><td style=\"text-align: right;\">            102.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1482516\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-24-51\n",
      "  done: false\n",
      "  episode_len_mean: 100.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000018\n",
      "  episode_reward_mean: 8.290200000000016\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14606\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3387184915088473\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008559552786776675\n",
      "          policy_loss: -0.012723932770036516\n",
      "          total_loss: 0.16879298589414074\n",
      "          vf_explained_var: 0.9630074501037598\n",
      "          vf_loss: 0.18796303588010016\n",
      "    num_agent_steps_sampled: 1482516\n",
      "    num_agent_steps_trained: 1482516\n",
      "    num_steps_sampled: 1482516\n",
      "    num_steps_trained: 1482516\n",
      "  iterations_since_restore: 742\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.01578947368421\n",
      "    ram_util_percent: 31.29649122807018\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427098846913577\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.20129134889381\n",
      "    mean_inference_ms: 2.465051244299633\n",
      "    mean_raw_obs_processing_ms: 2.060507016175641\n",
      "  time_since_restore: 20356.37132692337\n",
      "  time_this_iter_s: 39.44020366668701\n",
      "  time_total_s: 20356.37132692337\n",
      "  timers:\n",
      "    learn_throughput: 1160.467\n",
      "    learn_time_ms: 1721.721\n",
      "    load_throughput: 58448.718\n",
      "    load_time_ms: 34.184\n",
      "    sample_throughput: 76.557\n",
      "    sample_time_ms: 26098.285\n",
      "    update_time_ms: 10.024\n",
      "  timestamp: 1636449891\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1482516\n",
      "  training_iteration: 742\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   742</td><td style=\"text-align: right;\">         20356.4</td><td style=\"text-align: right;\">1482516</td><td style=\"text-align: right;\">  8.2902</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            100.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1484514\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-25-47\n",
      "  done: false\n",
      "  episode_len_mean: 99.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000018\n",
      "  episode_reward_mean: 7.916200000000016\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14627\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3156664138748533\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009198049562641567\n",
      "          policy_loss: -0.07803447651011604\n",
      "          total_loss: 0.060144736174316635\n",
      "          vf_explained_var: 0.975882887840271\n",
      "          vf_loss: 0.14387704424027886\n",
      "    num_agent_steps_sampled: 1484514\n",
      "    num_agent_steps_trained: 1484514\n",
      "    num_steps_sampled: 1484514\n",
      "    num_steps_trained: 1484514\n",
      "  iterations_since_restore: 743\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.05128205128204\n",
      "    ram_util_percent: 31.001282051282043\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424987581954301\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.20427248426711\n",
      "    mean_inference_ms: 2.4646835930069333\n",
      "    mean_raw_obs_processing_ms: 2.0657171589293712\n",
      "  time_since_restore: 20411.5233874321\n",
      "  time_this_iter_s: 55.15206050872803\n",
      "  time_total_s: 20411.5233874321\n",
      "  timers:\n",
      "    learn_throughput: 1159.292\n",
      "    learn_time_ms: 1723.465\n",
      "    load_throughput: 58640.455\n",
      "    load_time_ms: 34.072\n",
      "    sample_throughput: 68.419\n",
      "    sample_time_ms: 29202.605\n",
      "    update_time_ms: 10.64\n",
      "  timestamp: 1636449947\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1484514\n",
      "  training_iteration: 743\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   743</td><td style=\"text-align: right;\">         20411.5</td><td style=\"text-align: right;\">1484514</td><td style=\"text-align: right;\">  7.9162</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             99.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1486512\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-26-12\n",
      "  done: false\n",
      "  episode_len_mean: 98.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000018\n",
      "  episode_reward_mean: 8.117900000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14646\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2852475569361732\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009964728507952655\n",
      "          policy_loss: -0.023212738902795883\n",
      "          total_loss: 0.08452968994998152\n",
      "          vf_explained_var: 0.9823452830314636\n",
      "          vf_loss: 0.11251435801386833\n",
      "    num_agent_steps_sampled: 1486512\n",
      "    num_agent_steps_trained: 1486512\n",
      "    num_steps_sampled: 1486512\n",
      "    num_steps_trained: 1486512\n",
      "  iterations_since_restore: 744\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.15675675675676\n",
      "    ram_util_percent: 30.98648648648649\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426232119164541\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.205256408211902\n",
      "    mean_inference_ms: 2.464888916402645\n",
      "    mean_raw_obs_processing_ms: 2.070274716953376\n",
      "  time_since_restore: 20436.83904838562\n",
      "  time_this_iter_s: 25.31566095352173\n",
      "  time_total_s: 20436.83904838562\n",
      "  timers:\n",
      "    learn_throughput: 1158.515\n",
      "    learn_time_ms: 1724.622\n",
      "    load_throughput: 58962.314\n",
      "    load_time_ms: 33.886\n",
      "    sample_throughput: 68.407\n",
      "    sample_time_ms: 29207.593\n",
      "    update_time_ms: 10.417\n",
      "  timestamp: 1636449972\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1486512\n",
      "  training_iteration: 744\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   744</td><td style=\"text-align: right;\">         20436.8</td><td style=\"text-align: right;\">1486512</td><td style=\"text-align: right;\">  8.1179</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             98.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1488510\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-26-36\n",
      "  done: false\n",
      "  episode_len_mean: 98.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.19130000000002\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14666\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3580980306579953\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012534103833421644\n",
      "          policy_loss: -0.0009969731171925863\n",
      "          total_loss: 0.15387288630008697\n",
      "          vf_explained_var: 0.9787412881851196\n",
      "          vf_loss: 0.1582867538645154\n",
      "    num_agent_steps_sampled: 1488510\n",
      "    num_agent_steps_trained: 1488510\n",
      "    num_steps_sampled: 1488510\n",
      "    num_steps_trained: 1488510\n",
      "  iterations_since_restore: 745\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03235294117648\n",
      "    ram_util_percent: 31.211764705882356\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044236792449376526\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.204202163445487\n",
      "    mean_inference_ms: 2.4644328381404623\n",
      "    mean_raw_obs_processing_ms: 2.075059019043556\n",
      "  time_since_restore: 20461.0163064003\n",
      "  time_this_iter_s: 24.177258014678955\n",
      "  time_total_s: 20461.0163064003\n",
      "  timers:\n",
      "    learn_throughput: 1158.863\n",
      "    learn_time_ms: 1724.104\n",
      "    load_throughput: 59338.103\n",
      "    load_time_ms: 33.671\n",
      "    sample_throughput: 68.865\n",
      "    sample_time_ms: 29013.096\n",
      "    update_time_ms: 10.458\n",
      "  timestamp: 1636449996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1488510\n",
      "  training_iteration: 745\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   745</td><td style=\"text-align: right;\">           20461</td><td style=\"text-align: right;\">1488510</td><td style=\"text-align: right;\">  8.1913</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             98.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1490508\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-27-00\n",
      "  done: false\n",
      "  episode_len_mean: 99.96\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.533500000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14685\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3102842609087626\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009852372957830216\n",
      "          policy_loss: -0.030123441400272507\n",
      "          total_loss: 0.11099113364304815\n",
      "          vf_explained_var: 0.9806880354881287\n",
      "          vf_loss: 0.14622798290635858\n",
      "    num_agent_steps_sampled: 1490508\n",
      "    num_agent_steps_trained: 1490508\n",
      "    num_steps_sampled: 1490508\n",
      "    num_steps_trained: 1490508\n",
      "  iterations_since_restore: 746\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6735294117647\n",
      "    ram_util_percent: 31.394117647058827\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044262769307467004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.203187038975525\n",
      "    mean_inference_ms: 2.464817085271527\n",
      "    mean_raw_obs_processing_ms: 2.079625401935956\n",
      "  time_since_restore: 20484.92937350273\n",
      "  time_this_iter_s: 23.91306710243225\n",
      "  time_total_s: 20484.92937350273\n",
      "  timers:\n",
      "    learn_throughput: 1158.613\n",
      "    learn_time_ms: 1724.476\n",
      "    load_throughput: 59372.155\n",
      "    load_time_ms: 33.652\n",
      "    sample_throughput: 69.117\n",
      "    sample_time_ms: 28907.567\n",
      "    update_time_ms: 10.517\n",
      "  timestamp: 1636450020\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1490508\n",
      "  training_iteration: 746\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   746</td><td style=\"text-align: right;\">         20484.9</td><td style=\"text-align: right;\">1490508</td><td style=\"text-align: right;\">  8.5335</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">             99.96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1492506\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-27-25\n",
      "  done: false\n",
      "  episode_len_mean: 100.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.774300000000016\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14705\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3877046868914649\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010413579273365524\n",
      "          policy_loss: -0.050537983878027826\n",
      "          total_loss: 0.08633773692307017\n",
      "          vf_explained_var: 0.9836568236351013\n",
      "          vf_loss: 0.14230824118213994\n",
      "    num_agent_steps_sampled: 1492506\n",
      "    num_agent_steps_trained: 1492506\n",
      "    num_steps_sampled: 1492506\n",
      "    num_steps_trained: 1492506\n",
      "  iterations_since_restore: 747\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.50857142857144\n",
      "    ram_util_percent: 31.465714285714277\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424561951086235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.201708142741197\n",
      "    mean_inference_ms: 2.4644806034364355\n",
      "    mean_raw_obs_processing_ms: 2.081927015529724\n",
      "  time_since_restore: 20509.333502054214\n",
      "  time_this_iter_s: 24.404128551483154\n",
      "  time_total_s: 20509.333502054214\n",
      "  timers:\n",
      "    learn_throughput: 1160.123\n",
      "    learn_time_ms: 1722.23\n",
      "    load_throughput: 59231.449\n",
      "    load_time_ms: 33.732\n",
      "    sample_throughput: 69.658\n",
      "    sample_time_ms: 28682.946\n",
      "    update_time_ms: 10.313\n",
      "  timestamp: 1636450045\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1492506\n",
      "  training_iteration: 747\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   747</td><td style=\"text-align: right;\">         20509.3</td><td style=\"text-align: right;\">1492506</td><td style=\"text-align: right;\">  8.7743</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            100.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1494504\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-27-49\n",
      "  done: false\n",
      "  episode_len_mean: 102.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.764200000000018\n",
      "  episode_reward_min: 2.4600000000000213\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14725\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3870780047916231\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008174703156904682\n",
      "          policy_loss: -0.054882796534470146\n",
      "          total_loss: 0.009300771462065833\n",
      "          vf_explained_var: 0.988538384437561\n",
      "          vf_loss: 0.07142536186923583\n",
      "    num_agent_steps_sampled: 1494504\n",
      "    num_agent_steps_trained: 1494504\n",
      "    num_steps_sampled: 1494504\n",
      "    num_steps_trained: 1494504\n",
      "  iterations_since_restore: 748\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.09428571428572\n",
      "    ram_util_percent: 31.54857142857143\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425216699244125\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.200597194590912\n",
      "    mean_inference_ms: 2.4645558938598735\n",
      "    mean_raw_obs_processing_ms: 2.08028712987239\n",
      "  time_since_restore: 20533.789252996445\n",
      "  time_this_iter_s: 24.455750942230225\n",
      "  time_total_s: 20533.789252996445\n",
      "  timers:\n",
      "    learn_throughput: 1162.891\n",
      "    learn_time_ms: 1718.132\n",
      "    load_throughput: 59363.365\n",
      "    load_time_ms: 33.657\n",
      "    sample_throughput: 70.018\n",
      "    sample_time_ms: 28535.337\n",
      "    update_time_ms: 9.57\n",
      "  timestamp: 1636450069\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1494504\n",
      "  training_iteration: 748\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   748</td><td style=\"text-align: right;\">         20533.8</td><td style=\"text-align: right;\">1494504</td><td style=\"text-align: right;\">  8.7642</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            102.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1496502\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-28-14\n",
      "  done: false\n",
      "  episode_len_mean: 101.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.670000000000014\n",
      "  episode_reward_mean: 8.85680000000002\n",
      "  episode_reward_min: 4.580000000000021\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14745\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3014665944235666\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008507562814928416\n",
      "          policy_loss: -0.07959831158320109\n",
      "          total_loss: -0.018066416467939106\n",
      "          vf_explained_var: 0.9897040724754333\n",
      "          vf_loss: 0.06764765281585\n",
      "    num_agent_steps_sampled: 1496502\n",
      "    num_agent_steps_trained: 1496502\n",
      "    num_steps_sampled: 1496502\n",
      "    num_steps_trained: 1496502\n",
      "  iterations_since_restore: 749\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.09722222222221\n",
      "    ram_util_percent: 31.59722222222222\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044254736400979766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.199268972531037\n",
      "    mean_inference_ms: 2.4645626851074063\n",
      "    mean_raw_obs_processing_ms: 2.0783933935401873\n",
      "  time_since_restore: 20558.712013959885\n",
      "  time_this_iter_s: 24.92276096343994\n",
      "  time_total_s: 20558.712013959885\n",
      "  timers:\n",
      "    learn_throughput: 1162.424\n",
      "    learn_time_ms: 1718.822\n",
      "    load_throughput: 59568.823\n",
      "    load_time_ms: 33.541\n",
      "    sample_throughput: 71.85\n",
      "    sample_time_ms: 27807.897\n",
      "    update_time_ms: 8.877\n",
      "  timestamp: 1636450094\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1496502\n",
      "  training_iteration: 749\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   749</td><td style=\"text-align: right;\">         20558.7</td><td style=\"text-align: right;\">1496502</td><td style=\"text-align: right;\">  8.8568</td><td style=\"text-align: right;\">               14.67</td><td style=\"text-align: right;\">                4.58</td><td style=\"text-align: right;\">            101.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1498500\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-28-38\n",
      "  done: false\n",
      "  episode_len_mean: 100.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.610000000000012\n",
      "  episode_reward_mean: 8.982800000000019\n",
      "  episode_reward_min: 4.400000000000022\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14765\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3294279098510742\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016628562783175413\n",
      "          policy_loss: -0.042413101469477014\n",
      "          total_loss: 0.06885081836510272\n",
      "          vf_explained_var: 0.9831401109695435\n",
      "          vf_loss: 0.11107385294245822\n",
      "    num_agent_steps_sampled: 1498500\n",
      "    num_agent_steps_trained: 1498500\n",
      "    num_steps_sampled: 1498500\n",
      "    num_steps_trained: 1498500\n",
      "  iterations_since_restore: 750\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33529411764707\n",
      "    ram_util_percent: 31.579411764705885\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044270619702817024\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.198412959546303\n",
      "    mean_inference_ms: 2.4648248302412794\n",
      "    mean_raw_obs_processing_ms: 2.076504054946552\n",
      "  time_since_restore: 20583.02410721779\n",
      "  time_this_iter_s: 24.312093257904053\n",
      "  time_total_s: 20583.02410721779\n",
      "  timers:\n",
      "    learn_throughput: 1162.12\n",
      "    learn_time_ms: 1719.271\n",
      "    load_throughput: 59605.472\n",
      "    load_time_ms: 33.52\n",
      "    sample_throughput: 73.111\n",
      "    sample_time_ms: 27328.494\n",
      "    update_time_ms: 10.784\n",
      "  timestamp: 1636450118\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1498500\n",
      "  training_iteration: 750\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   750</td><td style=\"text-align: right;\">           20583</td><td style=\"text-align: right;\">1498500</td><td style=\"text-align: right;\">  8.9828</td><td style=\"text-align: right;\">               14.61</td><td style=\"text-align: right;\">                 4.4</td><td style=\"text-align: right;\">            100.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1500498\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-29-04\n",
      "  done: false\n",
      "  episode_len_mean: 100.06\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000015\n",
      "  episode_reward_mean: 8.895700000000017\n",
      "  episode_reward_min: 3.180000000000013\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14784\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3760944156419663\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011503674740917074\n",
      "          policy_loss: -0.025973766217274326\n",
      "          total_loss: 0.14077278531733015\n",
      "          vf_explained_var: 0.971867024898529\n",
      "          vf_loss: 0.17117899633234457\n",
      "    num_agent_steps_sampled: 1500498\n",
      "    num_agent_steps_trained: 1500498\n",
      "    num_steps_sampled: 1500498\n",
      "    num_steps_trained: 1500498\n",
      "  iterations_since_restore: 751\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73783783783784\n",
      "    ram_util_percent: 31.610810810810815\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425683082533436\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.197668544254363\n",
      "    mean_inference_ms: 2.464590555709735\n",
      "    mean_raw_obs_processing_ms: 2.0747514965405798\n",
      "  time_since_restore: 20608.444476366043\n",
      "  time_this_iter_s: 25.420369148254395\n",
      "  time_total_s: 20608.444476366043\n",
      "  timers:\n",
      "    learn_throughput: 1161.952\n",
      "    learn_time_ms: 1719.521\n",
      "    load_throughput: 59539.959\n",
      "    load_time_ms: 33.557\n",
      "    sample_throughput: 72.981\n",
      "    sample_time_ms: 27377.083\n",
      "    update_time_ms: 11.024\n",
      "  timestamp: 1636450144\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1500498\n",
      "  training_iteration: 751\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   751</td><td style=\"text-align: right;\">         20608.4</td><td style=\"text-align: right;\">1500498</td><td style=\"text-align: right;\">  8.8957</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                3.18</td><td style=\"text-align: right;\">            100.06</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1502496\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 100.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000015\n",
      "  episode_reward_mean: 8.726000000000017\n",
      "  episode_reward_min: 3.180000000000013\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14805\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3419737702324277\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013450655842873227\n",
      "          policy_loss: -0.05458953281243642\n",
      "          total_loss: 0.10283135394787504\n",
      "          vf_explained_var: 0.9803155660629272\n",
      "          vf_loss: 0.15993329080797378\n",
      "    num_agent_steps_sampled: 1502496\n",
      "    num_agent_steps_trained: 1502496\n",
      "    num_steps_sampled: 1502496\n",
      "    num_steps_trained: 1502496\n",
      "  iterations_since_restore: 752\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99722222222222\n",
      "    ram_util_percent: 31.538888888888877\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427260355999115\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.19758071516074\n",
      "    mean_inference_ms: 2.4648394680366836\n",
      "    mean_raw_obs_processing_ms: 2.072779408340576\n",
      "  time_since_restore: 20633.95147871971\n",
      "  time_this_iter_s: 25.507002353668213\n",
      "  time_total_s: 20633.95147871971\n",
      "  timers:\n",
      "    learn_throughput: 1161.725\n",
      "    learn_time_ms: 1719.856\n",
      "    load_throughput: 59337.641\n",
      "    load_time_ms: 33.672\n",
      "    sample_throughput: 76.896\n",
      "    sample_time_ms: 25983.037\n",
      "    update_time_ms: 11.337\n",
      "  timestamp: 1636450169\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1502496\n",
      "  training_iteration: 752\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   752</td><td style=\"text-align: right;\">           20634</td><td style=\"text-align: right;\">1502496</td><td style=\"text-align: right;\">   8.726</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                3.18</td><td style=\"text-align: right;\">            100.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1504494\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-29-54\n",
      "  done: false\n",
      "  episode_len_mean: 100.64\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000015\n",
      "  episode_reward_mean: 8.577000000000018\n",
      "  episode_reward_min: 1.6500000000000279\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14825\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.810914611816406\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2952942581403823\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.020252566161475246\n",
      "          policy_loss: -0.03257388337737038\n",
      "          total_loss: 0.1344655189352731\n",
      "          vf_explained_var: 0.970023512840271\n",
      "          vf_loss: 0.1635692417000731\n",
      "    num_agent_steps_sampled: 1504494\n",
      "    num_agent_steps_trained: 1504494\n",
      "    num_steps_sampled: 1504494\n",
      "    num_steps_trained: 1504494\n",
      "  iterations_since_restore: 753\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.4\n",
      "    ram_util_percent: 31.54166666666666\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425849031442718\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.197219114367094\n",
      "    mean_inference_ms: 2.4646009042117725\n",
      "    mean_raw_obs_processing_ms: 2.070959886803709\n",
      "  time_since_restore: 20659.051510810852\n",
      "  time_this_iter_s: 25.100032091140747\n",
      "  time_total_s: 20659.051510810852\n",
      "  timers:\n",
      "    learn_throughput: 1162.222\n",
      "    learn_time_ms: 1719.121\n",
      "    load_throughput: 59250.294\n",
      "    load_time_ms: 33.721\n",
      "    sample_throughput: 86.949\n",
      "    sample_time_ms: 22978.968\n",
      "    update_time_ms: 11.206\n",
      "  timestamp: 1636450194\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1504494\n",
      "  training_iteration: 753\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   753</td><td style=\"text-align: right;\">         20659.1</td><td style=\"text-align: right;\">1504494</td><td style=\"text-align: right;\">   8.577</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                1.65</td><td style=\"text-align: right;\">            100.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1506492\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-30-18\n",
      "  done: false\n",
      "  episode_len_mean: 102.1\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000015\n",
      "  episode_reward_mean: 8.461800000000018\n",
      "  episode_reward_min: 1.6500000000000279\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 14843\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3490342276436942\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011572634572735736\n",
      "          policy_loss: -0.02904938023005213\n",
      "          total_loss: 0.10002674632484004\n",
      "          vf_explained_var: 0.9823638796806335\n",
      "          vf_loss: 0.12848984184009687\n",
      "    num_agent_steps_sampled: 1506492\n",
      "    num_agent_steps_trained: 1506492\n",
      "    num_steps_sampled: 1506492\n",
      "    num_steps_trained: 1506492\n",
      "  iterations_since_restore: 754\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11818181818182\n",
      "    ram_util_percent: 31.518181818181816\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425579276366236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.1961264879347\n",
      "    mean_inference_ms: 2.4645191968417297\n",
      "    mean_raw_obs_processing_ms: 2.0693685160031103\n",
      "  time_since_restore: 20682.433804035187\n",
      "  time_this_iter_s: 23.382293224334717\n",
      "  time_total_s: 20682.433804035187\n",
      "  timers:\n",
      "    learn_throughput: 1162.55\n",
      "    learn_time_ms: 1718.636\n",
      "    load_throughput: 58890.508\n",
      "    load_time_ms: 33.927\n",
      "    sample_throughput: 87.685\n",
      "    sample_time_ms: 22786.154\n",
      "    update_time_ms: 11.121\n",
      "  timestamp: 1636450218\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1506492\n",
      "  training_iteration: 754\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   754</td><td style=\"text-align: right;\">         20682.4</td><td style=\"text-align: right;\">1506492</td><td style=\"text-align: right;\">  8.4618</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                1.65</td><td style=\"text-align: right;\">             102.1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1508490\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-30-44\n",
      "  done: false\n",
      "  episode_len_mean: 102.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.700000000000015\n",
      "  episode_reward_mean: 8.452300000000019\n",
      "  episode_reward_min: 1.6500000000000279\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14863\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.301761948494684\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012528765623050424\n",
      "          policy_loss: -0.06097597128578595\n",
      "          total_loss: 0.12423248620082934\n",
      "          vf_explained_var: 0.9773728251457214\n",
      "          vf_loss: 0.18298643909039952\n",
      "    num_agent_steps_sampled: 1508490\n",
      "    num_agent_steps_trained: 1508490\n",
      "    num_steps_sampled: 1508490\n",
      "    num_steps_trained: 1508490\n",
      "  iterations_since_restore: 755\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.01578947368422\n",
      "    ram_util_percent: 31.5157894736842\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425781311263611\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.195465147719332\n",
      "    mean_inference_ms: 2.46449994426202\n",
      "    mean_raw_obs_processing_ms: 2.0674810279757425\n",
      "  time_since_restore: 20708.43181204796\n",
      "  time_this_iter_s: 25.998008012771606\n",
      "  time_total_s: 20708.43181204796\n",
      "  timers:\n",
      "    learn_throughput: 1163.184\n",
      "    learn_time_ms: 1717.699\n",
      "    load_throughput: 58801.088\n",
      "    load_time_ms: 33.979\n",
      "    sample_throughput: 86.988\n",
      "    sample_time_ms: 22968.609\n",
      "    update_time_ms: 11.469\n",
      "  timestamp: 1636450244\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1508490\n",
      "  training_iteration: 755\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   755</td><td style=\"text-align: right;\">         20708.4</td><td style=\"text-align: right;\">1508490</td><td style=\"text-align: right;\">  8.4523</td><td style=\"text-align: right;\">                14.7</td><td style=\"text-align: right;\">                1.65</td><td style=\"text-align: right;\">            102.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1510488\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-31-09\n",
      "  done: false\n",
      "  episode_len_mean: 101.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.590000000000016\n",
      "  episode_reward_mean: 8.408400000000018\n",
      "  episode_reward_min: 1.6500000000000279\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 14883\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3341641238757542\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010735460312768346\n",
      "          policy_loss: -0.04067390351777985\n",
      "          total_loss: 0.16443542187944765\n",
      "          vf_explained_var: 0.9746527075767517\n",
      "          vf_loss: 0.20539265182756242\n",
      "    num_agent_steps_sampled: 1510488\n",
      "    num_agent_steps_trained: 1510488\n",
      "    num_steps_sampled: 1510488\n",
      "    num_steps_trained: 1510488\n",
      "  iterations_since_restore: 756\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.07777777777778\n",
      "    ram_util_percent: 31.505555555555546\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442778746978619\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.195175400572644\n",
      "    mean_inference_ms: 2.4647998048074213\n",
      "    mean_raw_obs_processing_ms: 2.065514782109231\n",
      "  time_since_restore: 20733.962455511093\n",
      "  time_this_iter_s: 25.530643463134766\n",
      "  time_total_s: 20733.962455511093\n",
      "  timers:\n",
      "    learn_throughput: 1163.381\n",
      "    learn_time_ms: 1717.408\n",
      "    load_throughput: 58616.501\n",
      "    load_time_ms: 34.086\n",
      "    sample_throughput: 86.38\n",
      "    sample_time_ms: 23130.268\n",
      "    update_time_ms: 11.715\n",
      "  timestamp: 1636450269\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1510488\n",
      "  training_iteration: 756\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   756</td><td style=\"text-align: right;\">           20734</td><td style=\"text-align: right;\">1510488</td><td style=\"text-align: right;\">  8.4084</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">                1.65</td><td style=\"text-align: right;\">            101.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1512486\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-31-35\n",
      "  done: false\n",
      "  episode_len_mean: 101.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.590000000000016\n",
      "  episode_reward_mean: 8.260900000000019\n",
      "  episode_reward_min: 1.6500000000000279\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14904\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3270491282145183\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007279933889752262\n",
      "          policy_loss: -0.08036397564269247\n",
      "          total_loss: 0.014115040021992865\n",
      "          vf_explained_var: 0.9825208187103271\n",
      "          vf_loss: 0.09889439995444957\n",
      "    num_agent_steps_sampled: 1512486\n",
      "    num_agent_steps_trained: 1512486\n",
      "    num_steps_sampled: 1512486\n",
      "    num_steps_trained: 1512486\n",
      "  iterations_since_restore: 757\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.07222222222222\n",
      "    ram_util_percent: 31.433333333333337\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426343313466887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.1944470915913\n",
      "    mean_inference_ms: 2.4645298803434246\n",
      "    mean_raw_obs_processing_ms: 2.0636092925437404\n",
      "  time_since_restore: 20759.506806135178\n",
      "  time_this_iter_s: 25.544350624084473\n",
      "  time_total_s: 20759.506806135178\n",
      "  timers:\n",
      "    learn_throughput: 1161.872\n",
      "    learn_time_ms: 1719.639\n",
      "    load_throughput: 58938.47\n",
      "    load_time_ms: 33.9\n",
      "    sample_throughput: 85.966\n",
      "    sample_time_ms: 23241.677\n",
      "    update_time_ms: 12.559\n",
      "  timestamp: 1636450295\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1512486\n",
      "  training_iteration: 757\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   757</td><td style=\"text-align: right;\">         20759.5</td><td style=\"text-align: right;\">1512486</td><td style=\"text-align: right;\">  8.2609</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">                1.65</td><td style=\"text-align: right;\">            101.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1514484\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-31-59\n",
      "  done: false\n",
      "  episode_len_mean: 101.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.490000000000016\n",
      "  episode_reward_mean: 8.29860000000002\n",
      "  episode_reward_min: 2.9100000000000126\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 14922\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3859994235492887\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009072487155523367\n",
      "          policy_loss: -0.0624593772703693\n",
      "          total_loss: 0.06332084487768866\n",
      "          vf_explained_var: 0.974980354309082\n",
      "          vf_loss: 0.12860469685069154\n",
      "    num_agent_steps_sampled: 1514484\n",
      "    num_agent_steps_trained: 1514484\n",
      "    num_steps_sampled: 1514484\n",
      "    num_steps_trained: 1514484\n",
      "  iterations_since_restore: 758\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.99714285714286\n",
      "    ram_util_percent: 31.434285714285714\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044260074513359025\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.193798696717828\n",
      "    mean_inference_ms: 2.464430952080319\n",
      "    mean_raw_obs_processing_ms: 2.062033353069457\n",
      "  time_since_restore: 20783.54250717163\n",
      "  time_this_iter_s: 24.035701036453247\n",
      "  time_total_s: 20783.54250717163\n",
      "  timers:\n",
      "    learn_throughput: 1160.867\n",
      "    learn_time_ms: 1721.128\n",
      "    load_throughput: 59136.86\n",
      "    load_time_ms: 33.786\n",
      "    sample_throughput: 86.124\n",
      "    sample_time_ms: 23199.054\n",
      "    update_time_ms: 12.185\n",
      "  timestamp: 1636450319\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1514484\n",
      "  training_iteration: 758\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   758</td><td style=\"text-align: right;\">         20783.5</td><td style=\"text-align: right;\">1514484</td><td style=\"text-align: right;\">  8.2986</td><td style=\"text-align: right;\">               14.49</td><td style=\"text-align: right;\">                2.91</td><td style=\"text-align: right;\">            101.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1516482\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-32-23\n",
      "  done: false\n",
      "  episode_len_mean: 102.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.490000000000016\n",
      "  episode_reward_mean: 8.201800000000016\n",
      "  episode_reward_min: 2.9100000000000126\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14941\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.376065905321212\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008076899438439323\n",
      "          policy_loss: -0.010227163100526446\n",
      "          total_loss: 0.09144182606112389\n",
      "          vf_explained_var: 0.9789856672286987\n",
      "          vf_loss: 0.10560513725060793\n",
      "    num_agent_steps_sampled: 1516482\n",
      "    num_agent_steps_trained: 1516482\n",
      "    num_steps_sampled: 1516482\n",
      "    num_steps_trained: 1516482\n",
      "  iterations_since_restore: 759\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.96764705882352\n",
      "    ram_util_percent: 31.397058823529413\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044274071229162625\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.193786534923973\n",
      "    mean_inference_ms: 2.464645402403263\n",
      "    mean_raw_obs_processing_ms: 2.0602501270603795\n",
      "  time_since_restore: 20807.291500091553\n",
      "  time_this_iter_s: 23.748992919921875\n",
      "  time_total_s: 20807.291500091553\n",
      "  timers:\n",
      "    learn_throughput: 1162.155\n",
      "    learn_time_ms: 1719.219\n",
      "    load_throughput: 59098.659\n",
      "    load_time_ms: 33.808\n",
      "    sample_throughput: 86.553\n",
      "    sample_time_ms: 23083.991\n",
      "    update_time_ms: 12.07\n",
      "  timestamp: 1636450343\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1516482\n",
      "  training_iteration: 759\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   759</td><td style=\"text-align: right;\">         20807.3</td><td style=\"text-align: right;\">1516482</td><td style=\"text-align: right;\">  8.2018</td><td style=\"text-align: right;\">               14.49</td><td style=\"text-align: right;\">                2.91</td><td style=\"text-align: right;\">            102.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1518480\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-33-06\n",
      "  done: false\n",
      "  episode_len_mean: 100.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000017\n",
      "  episode_reward_mean: 8.407700000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 14962\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3435429170018152\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009050339621185528\n",
      "          policy_loss: -0.038155263697817215\n",
      "          total_loss: 0.3968169504599202\n",
      "          vf_explained_var: 0.9591821432113647\n",
      "          vf_loss: 0.4373990592325018\n",
      "    num_agent_steps_sampled: 1518480\n",
      "    num_agent_steps_trained: 1518480\n",
      "    num_steps_sampled: 1518480\n",
      "    num_steps_trained: 1518480\n",
      "  iterations_since_restore: 760\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.56229508196722\n",
      "    ram_util_percent: 31.329508196721314\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426227020086589\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.19386952285694\n",
      "    mean_inference_ms: 2.4644451859739465\n",
      "    mean_raw_obs_processing_ms: 2.0609313258438386\n",
      "  time_since_restore: 20850.360916376114\n",
      "  time_this_iter_s: 43.06941628456116\n",
      "  time_total_s: 20850.360916376114\n",
      "  timers:\n",
      "    learn_throughput: 1162.637\n",
      "    learn_time_ms: 1718.507\n",
      "    load_throughput: 59099.576\n",
      "    load_time_ms: 33.807\n",
      "    sample_throughput: 80.038\n",
      "    sample_time_ms: 24963.026\n",
      "    update_time_ms: 9.368\n",
      "  timestamp: 1636450386\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1518480\n",
      "  training_iteration: 760\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   760</td><td style=\"text-align: right;\">         20850.4</td><td style=\"text-align: right;\">1518480</td><td style=\"text-align: right;\">  8.4077</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            100.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1520478\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-33-46\n",
      "  done: false\n",
      "  episode_len_mean: 101.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000017\n",
      "  episode_reward_mean: 8.642900000000019\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 14981\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3522028690292722\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007253134046017063\n",
      "          policy_loss: -0.05356485584662074\n",
      "          total_loss: 0.06746525230507056\n",
      "          vf_explained_var: 0.9817623496055603\n",
      "          vf_loss: 0.12572962916677907\n",
      "    num_agent_steps_sampled: 1520478\n",
      "    num_agent_steps_trained: 1520478\n",
      "    num_steps_sampled: 1520478\n",
      "    num_steps_trained: 1520478\n",
      "  iterations_since_restore: 761\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.8736842105263\n",
      "    ram_util_percent: 31.324561403508767\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425753448530613\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.19281142211761\n",
      "    mean_inference_ms: 2.464330474269661\n",
      "    mean_raw_obs_processing_ms: 2.063277946055556\n",
      "  time_since_restore: 20890.029471874237\n",
      "  time_this_iter_s: 39.66855549812317\n",
      "  time_total_s: 20890.029471874237\n",
      "  timers:\n",
      "    learn_throughput: 1162.688\n",
      "    learn_time_ms: 1718.432\n",
      "    load_throughput: 59053.058\n",
      "    load_time_ms: 33.834\n",
      "    sample_throughput: 75.713\n",
      "    sample_time_ms: 26389.117\n",
      "    update_time_ms: 8.379\n",
      "  timestamp: 1636450426\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1520478\n",
      "  training_iteration: 761\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   761</td><td style=\"text-align: right;\">           20890</td><td style=\"text-align: right;\">1520478</td><td style=\"text-align: right;\">  8.6429</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            101.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1522476\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-34-27\n",
      "  done: false\n",
      "  episode_len_mean: 101.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000017\n",
      "  episode_reward_mean: 8.786400000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 15002\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.295983304296221\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010543704275471622\n",
      "          policy_loss: 0.004936846664973668\n",
      "          total_loss: 0.16584080615568728\n",
      "          vf_explained_var: 0.9701365828514099\n",
      "          vf_loss: 0.16103872511358489\n",
      "    num_agent_steps_sampled: 1522476\n",
      "    num_agent_steps_trained: 1522476\n",
      "    num_steps_sampled: 1522476\n",
      "    num_steps_trained: 1522476\n",
      "  iterations_since_restore: 762\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.82758620689657\n",
      "    ram_util_percent: 31.18103448275862\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427097976177679\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.191903599281996\n",
      "    mean_inference_ms: 2.464528609029256\n",
      "    mean_raw_obs_processing_ms: 2.06822012996238\n",
      "  time_since_restore: 20931.003556251526\n",
      "  time_this_iter_s: 40.97408437728882\n",
      "  time_total_s: 20931.003556251526\n",
      "  timers:\n",
      "    learn_throughput: 1162.859\n",
      "    learn_time_ms: 1718.18\n",
      "    load_throughput: 59072.539\n",
      "    load_time_ms: 33.823\n",
      "    sample_throughput: 71.521\n",
      "    sample_time_ms: 27935.975\n",
      "    update_time_ms: 8.121\n",
      "  timestamp: 1636450467\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1522476\n",
      "  training_iteration: 762\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   762</td><td style=\"text-align: right;\">           20931</td><td style=\"text-align: right;\">1522476</td><td style=\"text-align: right;\">  8.7864</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            101.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1524474\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-34-50\n",
      "  done: false\n",
      "  episode_len_mean: 102.38\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000017\n",
      "  episode_reward_mean: 8.83960000000002\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15020\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.446981015659514\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00754916692890497\n",
      "          policy_loss: -0.06977074025642305\n",
      "          total_loss: 0.09614415480977014\n",
      "          vf_explained_var: 0.974113404750824\n",
      "          vf_loss: 0.17120211198925972\n",
      "    num_agent_steps_sampled: 1524474\n",
      "    num_agent_steps_trained: 1524474\n",
      "    num_steps_sampled: 1524474\n",
      "    num_steps_trained: 1524474\n",
      "  iterations_since_restore: 763\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5\n",
      "    ram_util_percent: 31.170588235294115\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427087919651557\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.190755295911032\n",
      "    mean_inference_ms: 2.4644934965737484\n",
      "    mean_raw_obs_processing_ms: 2.072465774410891\n",
      "  time_since_restore: 20954.540002822876\n",
      "  time_this_iter_s: 23.536446571350098\n",
      "  time_total_s: 20954.540002822876\n",
      "  timers:\n",
      "    learn_throughput: 1162.469\n",
      "    learn_time_ms: 1718.756\n",
      "    load_throughput: 59303.544\n",
      "    load_time_ms: 33.691\n",
      "    sample_throughput: 71.924\n",
      "    sample_time_ms: 27779.318\n",
      "    update_time_ms: 7.899\n",
      "  timestamp: 1636450490\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1524474\n",
      "  training_iteration: 763\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   763</td><td style=\"text-align: right;\">         20954.5</td><td style=\"text-align: right;\">1524474</td><td style=\"text-align: right;\">  8.8396</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            102.38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1526472\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-35-15\n",
      "  done: false\n",
      "  episode_len_mean: 100.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000017\n",
      "  episode_reward_mean: 9.275300000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 15041\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3751984136445181\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0081332013395732\n",
      "          policy_loss: -0.04871730088655438\n",
      "          total_loss: 0.05310261943155811\n",
      "          vf_explained_var: 0.9829019904136658\n",
      "          vf_loss: 0.10567890795923415\n",
      "    num_agent_steps_sampled: 1526472\n",
      "    num_agent_steps_trained: 1526472\n",
      "    num_steps_sampled: 1526472\n",
      "    num_steps_trained: 1526472\n",
      "  iterations_since_restore: 764\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.1142857142857\n",
      "    ram_util_percent: 31.248571428571438\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044274334002181066\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.19001128663501\n",
      "    mean_inference_ms: 2.4645369825974077\n",
      "    mean_raw_obs_processing_ms: 2.0773392542404037\n",
      "  time_since_restore: 20979.172744512558\n",
      "  time_this_iter_s: 24.632741689682007\n",
      "  time_total_s: 20979.172744512558\n",
      "  timers:\n",
      "    learn_throughput: 1161.804\n",
      "    learn_time_ms: 1719.74\n",
      "    load_throughput: 59621.374\n",
      "    load_time_ms: 33.511\n",
      "    sample_throughput: 71.602\n",
      "    sample_time_ms: 27904.136\n",
      "    update_time_ms: 7.488\n",
      "  timestamp: 1636450515\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1526472\n",
      "  training_iteration: 764\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   764</td><td style=\"text-align: right;\">         20979.2</td><td style=\"text-align: right;\">1526472</td><td style=\"text-align: right;\">  9.2753</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            100.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1528470\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-35-39\n",
      "  done: false\n",
      "  episode_len_mean: 103.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.720000000000017\n",
      "  episode_reward_mean: 9.149400000000016\n",
      "  episode_reward_min: 2.780000000000017\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15060\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4183958842640831\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008690365839758615\n",
      "          policy_loss: -0.07002579749872287\n",
      "          total_loss: 0.07121065699805816\n",
      "          vf_explained_var: 0.9772526621818542\n",
      "          vf_loss: 0.14484969741176992\n",
      "    num_agent_steps_sampled: 1528470\n",
      "    num_agent_steps_trained: 1528470\n",
      "    num_steps_sampled: 1528470\n",
      "    num_steps_trained: 1528470\n",
      "  iterations_since_restore: 765\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.10857142857144\n",
      "    ram_util_percent: 31.445714285714278\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044269654414776004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.188265721848893\n",
      "    mean_inference_ms: 2.464439078703437\n",
      "    mean_raw_obs_processing_ms: 2.0792743999524337\n",
      "  time_since_restore: 21003.414150714874\n",
      "  time_this_iter_s: 24.241406202316284\n",
      "  time_total_s: 21003.414150714874\n",
      "  timers:\n",
      "    learn_throughput: 1160.307\n",
      "    learn_time_ms: 1721.958\n",
      "    load_throughput: 59439.702\n",
      "    load_time_ms: 33.614\n",
      "    sample_throughput: 72.062\n",
      "    sample_time_ms: 27726.294\n",
      "    update_time_ms: 7.346\n",
      "  timestamp: 1636450539\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1528470\n",
      "  training_iteration: 765\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   765</td><td style=\"text-align: right;\">         21003.4</td><td style=\"text-align: right;\">1528470</td><td style=\"text-align: right;\">  9.1494</td><td style=\"text-align: right;\">               14.72</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">            103.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1530468\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-36-05\n",
      "  done: false\n",
      "  episode_len_mean: 102.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 8.55650000000002\n",
      "  episode_reward_min: 2.780000000000017\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 15077\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5302906405358088\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008199174395047552\n",
      "          policy_loss: -0.056169701048306056\n",
      "          total_loss: 0.05740644193830944\n",
      "          vf_explained_var: 0.9620155692100525\n",
      "          vf_loss: 0.11890580423531077\n",
      "    num_agent_steps_sampled: 1530468\n",
      "    num_agent_steps_trained: 1530468\n",
      "    num_steps_sampled: 1530468\n",
      "    num_steps_trained: 1530468\n",
      "  iterations_since_restore: 766\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.89444444444443\n",
      "    ram_util_percent: 31.525000000000002\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424976162243202\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.187221145393334\n",
      "    mean_inference_ms: 2.4640957467359126\n",
      "    mean_raw_obs_processing_ms: 2.0806920089797982\n",
      "  time_since_restore: 21028.907814741135\n",
      "  time_this_iter_s: 25.493664026260376\n",
      "  time_total_s: 21028.907814741135\n",
      "  timers:\n",
      "    learn_throughput: 1160.21\n",
      "    learn_time_ms: 1722.102\n",
      "    load_throughput: 59604.242\n",
      "    load_time_ms: 33.521\n",
      "    sample_throughput: 72.071\n",
      "    sample_time_ms: 27722.708\n",
      "    update_time_ms: 7.207\n",
      "  timestamp: 1636450565\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1530468\n",
      "  training_iteration: 766\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   766</td><td style=\"text-align: right;\">         21028.9</td><td style=\"text-align: right;\">1530468</td><td style=\"text-align: right;\">  8.5565</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                2.78</td><td style=\"text-align: right;\">            102.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1532466\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-36-29\n",
      "  done: false\n",
      "  episode_len_mean: 104.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 8.328200000000018\n",
      "  episode_reward_min: 2.8500000000000165\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 15097\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4260697376160394\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01031541087185494\n",
      "          policy_loss: -0.06240008655225947\n",
      "          total_loss: 0.12778800645222266\n",
      "          vf_explained_var: 0.972048819065094\n",
      "          vf_loss: 0.19190141124029955\n",
      "    num_agent_steps_sampled: 1532466\n",
      "    num_agent_steps_trained: 1532466\n",
      "    num_steps_sampled: 1532466\n",
      "    num_steps_trained: 1532466\n",
      "  iterations_since_restore: 767\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.73823529411764\n",
      "    ram_util_percent: 31.57058823529412\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424952722631366\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.185996408233464\n",
      "    mean_inference_ms: 2.4640916362187495\n",
      "    mean_raw_obs_processing_ms: 2.078766633137169\n",
      "  time_since_restore: 21052.5980989933\n",
      "  time_this_iter_s: 23.690284252166748\n",
      "  time_total_s: 21052.5980989933\n",
      "  timers:\n",
      "    learn_throughput: 1161.012\n",
      "    learn_time_ms: 1720.912\n",
      "    load_throughput: 59304.09\n",
      "    load_time_ms: 33.691\n",
      "    sample_throughput: 72.553\n",
      "    sample_time_ms: 27538.616\n",
      "    update_time_ms: 6.744\n",
      "  timestamp: 1636450589\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1532466\n",
      "  training_iteration: 767\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   767</td><td style=\"text-align: right;\">         21052.6</td><td style=\"text-align: right;\">1532466</td><td style=\"text-align: right;\">  8.3282</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                2.85</td><td style=\"text-align: right;\">            104.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1534464\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-36-52\n",
      "  done: false\n",
      "  episode_len_mean: 105.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 8.085300000000018\n",
      "  episode_reward_min: 2.8500000000000165\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15115\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4185200691223145\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00802315607770619\n",
      "          policy_loss: -0.04360355429706119\n",
      "          total_loss: 0.030063048448591007\n",
      "          vf_explained_var: 0.9789707660675049\n",
      "          vf_loss: 0.0780926621385983\n",
      "    num_agent_steps_sampled: 1534464\n",
      "    num_agent_steps_trained: 1534464\n",
      "    num_steps_sampled: 1534464\n",
      "    num_steps_trained: 1534464\n",
      "  iterations_since_restore: 768\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.19411764705882\n",
      "    ram_util_percent: 31.549999999999994\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424944792940653\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.18478543955164\n",
      "    mean_inference_ms: 2.464085995251768\n",
      "    mean_raw_obs_processing_ms: 2.077005730862639\n",
      "  time_since_restore: 21076.13000178337\n",
      "  time_this_iter_s: 23.53190279006958\n",
      "  time_total_s: 21076.13000178337\n",
      "  timers:\n",
      "    learn_throughput: 1161.744\n",
      "    learn_time_ms: 1719.828\n",
      "    load_throughput: 59186.353\n",
      "    load_time_ms: 33.758\n",
      "    sample_throughput: 72.684\n",
      "    sample_time_ms: 27488.811\n",
      "    update_time_ms: 7.016\n",
      "  timestamp: 1636450612\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1534464\n",
      "  training_iteration: 768\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   768</td><td style=\"text-align: right;\">         21076.1</td><td style=\"text-align: right;\">1534464</td><td style=\"text-align: right;\">  8.0853</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                2.85</td><td style=\"text-align: right;\">            105.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1536462\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-37-16\n",
      "  done: false\n",
      "  episode_len_mean: 106.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.600000000000016\n",
      "  episode_reward_mean: 7.773400000000017\n",
      "  episode_reward_min: 2.8500000000000165\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15134\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.473924081666129\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009033015069768583\n",
      "          policy_loss: 0.0037231260821932836\n",
      "          total_loss: 0.1636185457486482\n",
      "          vf_explained_var: 0.969031035900116\n",
      "          vf_loss: 0.16364715567656926\n",
      "    num_agent_steps_sampled: 1536462\n",
      "    num_agent_steps_trained: 1536462\n",
      "    num_steps_sampled: 1536462\n",
      "    num_steps_trained: 1536462\n",
      "  iterations_since_restore: 769\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.2470588235294\n",
      "    ram_util_percent: 31.514705882352935\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442304065317723\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.182768347174104\n",
      "    mean_inference_ms: 2.4637556912802454\n",
      "    mean_raw_obs_processing_ms: 2.0752681364590706\n",
      "  time_since_restore: 21099.97572183609\n",
      "  time_this_iter_s: 23.845720052719116\n",
      "  time_total_s: 21099.97572183609\n",
      "  timers:\n",
      "    learn_throughput: 1160.765\n",
      "    learn_time_ms: 1721.278\n",
      "    load_throughput: 59173.941\n",
      "    load_time_ms: 33.765\n",
      "    sample_throughput: 72.664\n",
      "    sample_time_ms: 27496.537\n",
      "    update_time_ms: 7.275\n",
      "  timestamp: 1636450636\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1536462\n",
      "  training_iteration: 769\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   769</td><td style=\"text-align: right;\">           21100</td><td style=\"text-align: right;\">1536462</td><td style=\"text-align: right;\">  7.7734</td><td style=\"text-align: right;\">                14.6</td><td style=\"text-align: right;\">                2.85</td><td style=\"text-align: right;\">            106.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1538460\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-37-39\n",
      "  done: false\n",
      "  episode_len_mean: 107.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.420000000000018\n",
      "  episode_reward_mean: 7.55980000000002\n",
      "  episode_reward_min: 2.8500000000000165\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 15151\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4176537298020861\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010291171571778468\n",
      "          policy_loss: -0.07030648803781896\n",
      "          total_loss: 0.08487040808069564\n",
      "          vf_explained_var: 0.9734088778495789\n",
      "          vf_loss: 0.15683554187417031\n",
      "    num_agent_steps_sampled: 1538460\n",
      "    num_agent_steps_trained: 1538460\n",
      "    num_steps_sampled: 1538460\n",
      "    num_steps_trained: 1538460\n",
      "  iterations_since_restore: 770\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.6969696969697\n",
      "    ram_util_percent: 31.493939393939392\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423443821834337\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.181101432283803\n",
      "    mean_inference_ms: 2.4638285600676526\n",
      "    mean_raw_obs_processing_ms: 2.073481686804773\n",
      "  time_since_restore: 21123.194620370865\n",
      "  time_this_iter_s: 23.21889853477478\n",
      "  time_total_s: 21123.194620370865\n",
      "  timers:\n",
      "    learn_throughput: 1160.415\n",
      "    learn_time_ms: 1721.797\n",
      "    load_throughput: 59103.911\n",
      "    load_time_ms: 33.805\n",
      "    sample_throughput: 78.32\n",
      "    sample_time_ms: 25510.817\n",
      "    update_time_ms: 7.284\n",
      "  timestamp: 1636450659\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1538460\n",
      "  training_iteration: 770\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   770</td><td style=\"text-align: right;\">         21123.2</td><td style=\"text-align: right;\">1538460</td><td style=\"text-align: right;\">  7.5598</td><td style=\"text-align: right;\">               14.42</td><td style=\"text-align: right;\">                2.85</td><td style=\"text-align: right;\">             107.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1540458\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-38-04\n",
      "  done: false\n",
      "  episode_len_mean: 108.31\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.430000000000017\n",
      "  episode_reward_mean: 7.809000000000019\n",
      "  episode_reward_min: 2.3300000000000116\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15170\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4195697733334132\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014802501119834706\n",
      "          policy_loss: -0.014700900124652045\n",
      "          total_loss: 0.18017939668858335\n",
      "          vf_explained_var: 0.9681430459022522\n",
      "          vf_loss: 0.19107065026958783\n",
      "    num_agent_steps_sampled: 1540458\n",
      "    num_agent_steps_trained: 1540458\n",
      "    num_steps_sampled: 1540458\n",
      "    num_steps_trained: 1540458\n",
      "  iterations_since_restore: 771\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5027777777778\n",
      "    ram_util_percent: 31.41111111111111\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423453401298676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.178607438504304\n",
      "    mean_inference_ms: 2.463826377250377\n",
      "    mean_raw_obs_processing_ms: 2.071560481733708\n",
      "  time_since_restore: 21148.04713320732\n",
      "  time_this_iter_s: 24.8525128364563\n",
      "  time_total_s: 21148.04713320732\n",
      "  timers:\n",
      "    learn_throughput: 1159.41\n",
      "    learn_time_ms: 1723.291\n",
      "    load_throughput: 59054.847\n",
      "    load_time_ms: 33.833\n",
      "    sample_throughput: 83.154\n",
      "    sample_time_ms: 24027.66\n",
      "    update_time_ms: 7.352\n",
      "  timestamp: 1636450684\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1540458\n",
      "  training_iteration: 771\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   771</td><td style=\"text-align: right;\">           21148</td><td style=\"text-align: right;\">1540458</td><td style=\"text-align: right;\">   7.809</td><td style=\"text-align: right;\">               14.43</td><td style=\"text-align: right;\">                2.33</td><td style=\"text-align: right;\">            108.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1542456\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-38-30\n",
      "  done: false\n",
      "  episode_len_mean: 107.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.430000000000017\n",
      "  episode_reward_mean: 7.9421000000000195\n",
      "  episode_reward_min: 2.3300000000000116\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 15190\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2686521388235545\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007104860357786664\n",
      "          policy_loss: -0.06762673793626683\n",
      "          total_loss: 0.015546484433469319\n",
      "          vf_explained_var: 0.9819949269294739\n",
      "          vf_loss: 0.08721759048778387\n",
      "    num_agent_steps_sampled: 1542456\n",
      "    num_agent_steps_trained: 1542456\n",
      "    num_steps_sampled: 1542456\n",
      "    num_steps_trained: 1542456\n",
      "  iterations_since_restore: 772\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.58918918918921\n",
      "    ram_util_percent: 31.383783783783784\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044230383414077784\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.176321760422006\n",
      "    mean_inference_ms: 2.4637319000896665\n",
      "    mean_raw_obs_processing_ms: 2.0696902709568996\n",
      "  time_since_restore: 21173.989407539368\n",
      "  time_this_iter_s: 25.94227433204651\n",
      "  time_total_s: 21173.989407539368\n",
      "  timers:\n",
      "    learn_throughput: 1158.871\n",
      "    learn_time_ms: 1724.092\n",
      "    load_throughput: 59215.921\n",
      "    load_time_ms: 33.741\n",
      "    sample_throughput: 88.708\n",
      "    sample_time_ms: 22523.353\n",
      "    update_time_ms: 7.887\n",
      "  timestamp: 1636450710\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1542456\n",
      "  training_iteration: 772\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   772</td><td style=\"text-align: right;\">           21174</td><td style=\"text-align: right;\">1542456</td><td style=\"text-align: right;\">  7.9421</td><td style=\"text-align: right;\">               14.43</td><td style=\"text-align: right;\">                2.33</td><td style=\"text-align: right;\">            107.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1544454\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-38-54\n",
      "  done: false\n",
      "  episode_len_mean: 106.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.490000000000016\n",
      "  episode_reward_mean: 8.278800000000018\n",
      "  episode_reward_min: 2.3300000000000116\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15208\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3700681601251874\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012090053156661078\n",
      "          policy_loss: -0.07664689052672613\n",
      "          total_loss: 0.151424932391161\n",
      "          vf_explained_var: 0.9537420868873596\n",
      "          vf_loss: 0.22706650502624967\n",
      "    num_agent_steps_sampled: 1544454\n",
      "    num_agent_steps_trained: 1544454\n",
      "    num_steps_sampled: 1544454\n",
      "    num_steps_trained: 1544454\n",
      "  iterations_since_restore: 773\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72941176470589\n",
      "    ram_util_percent: 31.414705882352937\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044230147916433704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.174463515840248\n",
      "    mean_inference_ms: 2.4637196245236637\n",
      "    mean_raw_obs_processing_ms: 2.0679241479805306\n",
      "  time_since_restore: 21197.8160033226\n",
      "  time_this_iter_s: 23.826595783233643\n",
      "  time_total_s: 21197.8160033226\n",
      "  timers:\n",
      "    learn_throughput: 1157.778\n",
      "    learn_time_ms: 1725.719\n",
      "    load_throughput: 59110.998\n",
      "    load_time_ms: 33.801\n",
      "    sample_throughput: 88.599\n",
      "    sample_time_ms: 22550.978\n",
      "    update_time_ms: 7.478\n",
      "  timestamp: 1636450734\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1544454\n",
      "  training_iteration: 773\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   773</td><td style=\"text-align: right;\">         21197.8</td><td style=\"text-align: right;\">1544454</td><td style=\"text-align: right;\">  8.2788</td><td style=\"text-align: right;\">               14.49</td><td style=\"text-align: right;\">                2.33</td><td style=\"text-align: right;\">            106.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1546452\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-39-18\n",
      "  done: false\n",
      "  episode_len_mean: 107.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.490000000000016\n",
      "  episode_reward_mean: 8.383400000000018\n",
      "  episode_reward_min: 2.3300000000000116\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15226\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4630757678122748\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007258871425318112\n",
      "          policy_loss: -0.041490176027374606\n",
      "          total_loss: 0.04091547681462197\n",
      "          vf_explained_var: 0.9808811545372009\n",
      "          vf_loss: 0.08820692304344405\n",
      "    num_agent_steps_sampled: 1546452\n",
      "    num_agent_steps_trained: 1546452\n",
      "    num_steps_sampled: 1546452\n",
      "    num_steps_trained: 1546452\n",
      "  iterations_since_restore: 774\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03235294117648\n",
      "    ram_util_percent: 31.344117647058823\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044229455130499015\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.172717205107418\n",
      "    mean_inference_ms: 2.4637164150405932\n",
      "    mean_raw_obs_processing_ms: 2.0661645964967055\n",
      "  time_since_restore: 21221.918219804764\n",
      "  time_this_iter_s: 24.102216482162476\n",
      "  time_total_s: 21221.918219804764\n",
      "  timers:\n",
      "    learn_throughput: 1158.861\n",
      "    learn_time_ms: 1724.107\n",
      "    load_throughput: 59218.725\n",
      "    load_time_ms: 33.739\n",
      "    sample_throughput: 88.802\n",
      "    sample_time_ms: 22499.45\n",
      "    update_time_ms: 7.655\n",
      "  timestamp: 1636450758\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1546452\n",
      "  training_iteration: 774\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   774</td><td style=\"text-align: right;\">         21221.9</td><td style=\"text-align: right;\">1546452</td><td style=\"text-align: right;\">  8.3834</td><td style=\"text-align: right;\">               14.49</td><td style=\"text-align: right;\">                2.33</td><td style=\"text-align: right;\">            107.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1548450\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-39-43\n",
      "  done: false\n",
      "  episode_len_mean: 105.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 8.484100000000018\n",
      "  episode_reward_min: 2.3300000000000116\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 15246\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.423000446955363\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007020768182973958\n",
      "          policy_loss: -0.03610693906389532\n",
      "          total_loss: 0.08501919547007197\n",
      "          vf_explained_var: 0.9794930815696716\n",
      "          vf_loss: 0.1268162743144092\n",
      "    num_agent_steps_sampled: 1548450\n",
      "    num_agent_steps_trained: 1548450\n",
      "    num_steps_sampled: 1548450\n",
      "    num_steps_trained: 1548450\n",
      "  iterations_since_restore: 775\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.81142857142856\n",
      "    ram_util_percent: 31.282857142857154\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044242879910596764\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.171644331257866\n",
      "    mean_inference_ms: 2.463949013172819\n",
      "    mean_raw_obs_processing_ms: 2.0641978600032274\n",
      "  time_since_restore: 21246.773379087448\n",
      "  time_this_iter_s: 24.855159282684326\n",
      "  time_total_s: 21246.773379087448\n",
      "  timers:\n",
      "    learn_throughput: 1160.85\n",
      "    learn_time_ms: 1721.152\n",
      "    load_throughput: 59450.582\n",
      "    load_time_ms: 33.608\n",
      "    sample_throughput: 88.549\n",
      "    sample_time_ms: 22563.76\n",
      "    update_time_ms: 7.8\n",
      "  timestamp: 1636450783\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1548450\n",
      "  training_iteration: 775\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   775</td><td style=\"text-align: right;\">         21246.8</td><td style=\"text-align: right;\">1548450</td><td style=\"text-align: right;\">  8.4841</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">                2.33</td><td style=\"text-align: right;\">            105.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1550448\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-40-08\n",
      "  done: false\n",
      "  episode_len_mean: 105.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 8.175600000000019\n",
      "  episode_reward_min: 2.3300000000000116\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15265\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4084159209614708\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010889766900296343\n",
      "          policy_loss: 0.013271900230929966\n",
      "          total_loss: 0.21727421752044132\n",
      "          vf_explained_var: 0.960392415523529\n",
      "          vf_loss: 0.20484046875720932\n",
      "    num_agent_steps_sampled: 1550448\n",
      "    num_agent_steps_trained: 1550448\n",
      "    num_steps_sampled: 1550448\n",
      "    num_steps_trained: 1550448\n",
      "  iterations_since_restore: 776\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03333333333333\n",
      "    ram_util_percent: 31.325000000000006\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442411156225857\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.170412346890025\n",
      "    mean_inference_ms: 2.463933976462063\n",
      "    mean_raw_obs_processing_ms: 2.0624251774090383\n",
      "  time_since_restore: 21271.512676000595\n",
      "  time_this_iter_s: 24.739296913146973\n",
      "  time_total_s: 21271.512676000595\n",
      "  timers:\n",
      "    learn_throughput: 1161.281\n",
      "    learn_time_ms: 1720.513\n",
      "    load_throughput: 59384.272\n",
      "    load_time_ms: 33.645\n",
      "    sample_throughput: 88.843\n",
      "    sample_time_ms: 22489.119\n",
      "    update_time_ms: 7.404\n",
      "  timestamp: 1636450808\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1550448\n",
      "  training_iteration: 776\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   776</td><td style=\"text-align: right;\">         21271.5</td><td style=\"text-align: right;\">1550448</td><td style=\"text-align: right;\">  8.1756</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">                2.33</td><td style=\"text-align: right;\">            105.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1552446\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-40-32\n",
      "  done: false\n",
      "  episode_len_mean: 106.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 8.244500000000018\n",
      "  episode_reward_min: 0.5100000000000093\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15283\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.386458672795977\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01283962815845628\n",
      "          policy_loss: -0.06083663994712489\n",
      "          total_loss: 0.17467579152435064\n",
      "          vf_explained_var: 0.9531303644180298\n",
      "          vf_loss: 0.23375925279798962\n",
      "    num_agent_steps_sampled: 1552446\n",
      "    num_agent_steps_trained: 1552446\n",
      "    num_steps_sampled: 1552446\n",
      "    num_steps_trained: 1552446\n",
      "  iterations_since_restore: 777\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.27058823529411\n",
      "    ram_util_percent: 31.25588235294118\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422518071692906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.16877961075993\n",
      "    mean_inference_ms: 2.4636699260131136\n",
      "    mean_raw_obs_processing_ms: 2.0607840295937017\n",
      "  time_since_restore: 21295.709448337555\n",
      "  time_this_iter_s: 24.19677233695984\n",
      "  time_total_s: 21295.709448337555\n",
      "  timers:\n",
      "    learn_throughput: 1159.89\n",
      "    learn_time_ms: 1722.577\n",
      "    load_throughput: 59932.17\n",
      "    load_time_ms: 33.338\n",
      "    sample_throughput: 88.652\n",
      "    sample_time_ms: 22537.677\n",
      "    update_time_ms: 7.65\n",
      "  timestamp: 1636450832\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1552446\n",
      "  training_iteration: 777\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   777</td><td style=\"text-align: right;\">         21295.7</td><td style=\"text-align: right;\">1552446</td><td style=\"text-align: right;\">  8.2445</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">                0.51</td><td style=\"text-align: right;\">            106.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1554444\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-40-56\n",
      "  done: false\n",
      "  episode_len_mean: 107.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 8.076300000000018\n",
      "  episode_reward_min: 0.5100000000000093\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15302\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4648079230671838\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016078046153503965\n",
      "          policy_loss: -0.03215121259646756\n",
      "          total_loss: 0.3685498942665401\n",
      "          vf_explained_var: 0.9392228126525879\n",
      "          vf_loss: 0.39579230028958545\n",
      "    num_agent_steps_sampled: 1554444\n",
      "    num_agent_steps_trained: 1554444\n",
      "    num_steps_sampled: 1554444\n",
      "    num_steps_trained: 1554444\n",
      "  iterations_since_restore: 778\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.85882352941175\n",
      "    ram_util_percent: 31.238235294117644\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422429459294786\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.16718150483106\n",
      "    mean_inference_ms: 2.4636493106996826\n",
      "    mean_raw_obs_processing_ms: 2.058976113980199\n",
      "  time_since_restore: 21319.460997104645\n",
      "  time_this_iter_s: 23.751548767089844\n",
      "  time_total_s: 21319.460997104645\n",
      "  timers:\n",
      "    learn_throughput: 1160.222\n",
      "    learn_time_ms: 1722.085\n",
      "    load_throughput: 59669.685\n",
      "    load_time_ms: 33.484\n",
      "    sample_throughput: 88.563\n",
      "    sample_time_ms: 22560.241\n",
      "    update_time_ms: 7.425\n",
      "  timestamp: 1636450856\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1554444\n",
      "  training_iteration: 778\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   778</td><td style=\"text-align: right;\">         21319.5</td><td style=\"text-align: right;\">1554444</td><td style=\"text-align: right;\">  8.0763</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">                0.51</td><td style=\"text-align: right;\">            107.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1556442\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-41-50\n",
      "  done: false\n",
      "  episode_len_mean: 106.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 7.739200000000019\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15321\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5063958951405116\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008841582871274343\n",
      "          policy_loss: -0.035649309307336806\n",
      "          total_loss: 0.21793146931699345\n",
      "          vf_explained_var: 0.9293957948684692\n",
      "          vf_loss: 0.25789008584050904\n",
      "    num_agent_steps_sampled: 1556442\n",
      "    num_agent_steps_trained: 1556442\n",
      "    num_steps_sampled: 1556442\n",
      "    num_steps_trained: 1556442\n",
      "  iterations_since_restore: 779\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.08846153846154\n",
      "    ram_util_percent: 31.18461538461538\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442268090822363\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.165415297789142\n",
      "    mean_inference_ms: 2.463690104092293\n",
      "    mean_raw_obs_processing_ms: 2.061194051484723\n",
      "  time_since_restore: 21373.60630631447\n",
      "  time_this_iter_s: 54.14530920982361\n",
      "  time_total_s: 21373.60630631447\n",
      "  timers:\n",
      "    learn_throughput: 1159.859\n",
      "    learn_time_ms: 1722.623\n",
      "    load_throughput: 59731.865\n",
      "    load_time_ms: 33.449\n",
      "    sample_throughput: 78.077\n",
      "    sample_time_ms: 25590.05\n",
      "    update_time_ms: 7.265\n",
      "  timestamp: 1636450910\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1556442\n",
      "  training_iteration: 779\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   779</td><td style=\"text-align: right;\">         21373.6</td><td style=\"text-align: right;\">1556442</td><td style=\"text-align: right;\">  7.7392</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            106.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1558440\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-42-14\n",
      "  done: false\n",
      "  episode_len_mean: 106.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000015\n",
      "  episode_reward_mean: 7.914000000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15339\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.343229223432995\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009716422363716665\n",
      "          policy_loss: -0.05848057202640034\n",
      "          total_loss: 0.08399235230116617\n",
      "          vf_explained_var: 0.9732779264450073\n",
      "          vf_loss: 0.14408643442605223\n",
      "    num_agent_steps_sampled: 1558440\n",
      "    num_agent_steps_trained: 1558440\n",
      "    num_steps_sampled: 1558440\n",
      "    num_steps_trained: 1558440\n",
      "  iterations_since_restore: 780\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11470588235295\n",
      "    ram_util_percent: 31.038235294117644\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04421009858030655\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.16329071712591\n",
      "    mean_inference_ms: 2.4634054925158693\n",
      "    mean_raw_obs_processing_ms: 2.063300103584225\n",
      "  time_since_restore: 21397.722128152847\n",
      "  time_this_iter_s: 24.115821838378906\n",
      "  time_total_s: 21397.722128152847\n",
      "  timers:\n",
      "    learn_throughput: 1160.147\n",
      "    learn_time_ms: 1722.196\n",
      "    load_throughput: 59850.288\n",
      "    load_time_ms: 33.383\n",
      "    sample_throughput: 77.802\n",
      "    sample_time_ms: 25680.503\n",
      "    update_time_ms: 7.155\n",
      "  timestamp: 1636450934\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1558440\n",
      "  training_iteration: 780\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   780</td><td style=\"text-align: right;\">         21397.7</td><td style=\"text-align: right;\">1558440</td><td style=\"text-align: right;\">   7.914</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            106.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1560438\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-42-53\n",
      "  done: false\n",
      "  episode_len_mean: 106.39\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000018\n",
      "  episode_reward_mean: 8.095800000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15358\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3738634938285463\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010823603858361333\n",
      "          policy_loss: -0.05181260486798627\n",
      "          total_loss: 0.37264308201237806\n",
      "          vf_explained_var: 0.9483891725540161\n",
      "          vf_loss: 0.4250287941346566\n",
      "    num_agent_steps_sampled: 1560438\n",
      "    num_agent_steps_trained: 1560438\n",
      "    num_steps_sampled: 1560438\n",
      "    num_steps_trained: 1560438\n",
      "  iterations_since_restore: 781\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.62000000000002\n",
      "    ram_util_percent: 31.105454545454545\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422244486684018\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.160673499858614\n",
      "    mean_inference_ms: 2.4635883450143385\n",
      "    mean_raw_obs_processing_ms: 2.0673806107411394\n",
      "  time_since_restore: 21436.48250770569\n",
      "  time_this_iter_s: 38.76037955284119\n",
      "  time_total_s: 21436.48250770569\n",
      "  timers:\n",
      "    learn_throughput: 1159.756\n",
      "    learn_time_ms: 1722.776\n",
      "    load_throughput: 60187.246\n",
      "    load_time_ms: 33.196\n",
      "    sample_throughput: 73.808\n",
      "    sample_time_ms: 27070.355\n",
      "    update_time_ms: 7.749\n",
      "  timestamp: 1636450973\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1560438\n",
      "  training_iteration: 781\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   781</td><td style=\"text-align: right;\">         21436.5</td><td style=\"text-align: right;\">1560438</td><td style=\"text-align: right;\">  8.0958</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            106.39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1562436\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-43-16\n",
      "  done: false\n",
      "  episode_len_mean: 106.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000018\n",
      "  episode_reward_mean: 8.503900000000018\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15377\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.357987167721703\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00998051973739714\n",
      "          policy_loss: -0.06781209309895833\n",
      "          total_loss: 0.12685884371222483\n",
      "          vf_explained_var: 0.9782810807228088\n",
      "          vf_loss: 0.19611078193854717\n",
      "    num_agent_steps_sampled: 1562436\n",
      "    num_agent_steps_trained: 1562436\n",
      "    num_steps_sampled: 1562436\n",
      "    num_steps_trained: 1562436\n",
      "  iterations_since_restore: 782\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.61764705882354\n",
      "    ram_util_percent: 31.16176470588235\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044232800745076385\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.157685296456904\n",
      "    mean_inference_ms: 2.463711303674172\n",
      "    mean_raw_obs_processing_ms: 2.0715416585877815\n",
      "  time_since_restore: 21460.00948548317\n",
      "  time_this_iter_s: 23.52697777748108\n",
      "  time_total_s: 21460.00948548317\n",
      "  timers:\n",
      "    learn_throughput: 1161.16\n",
      "    learn_time_ms: 1720.693\n",
      "    load_throughput: 59777.199\n",
      "    load_time_ms: 33.424\n",
      "    sample_throughput: 74.467\n",
      "    sample_time_ms: 26830.581\n",
      "    update_time_ms: 7.902\n",
      "  timestamp: 1636450996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1562436\n",
      "  training_iteration: 782\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   782</td><td style=\"text-align: right;\">           21460</td><td style=\"text-align: right;\">1562436</td><td style=\"text-align: right;\">  8.5039</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            106.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1564434\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-43-39\n",
      "  done: false\n",
      "  episode_len_mean: 106.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000018\n",
      "  episode_reward_mean: 8.512500000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 15394\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4705533192271278\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009161799951674815\n",
      "          policy_loss: -0.022177232659998394\n",
      "          total_loss: 0.10955650301738865\n",
      "          vf_explained_var: 0.9591698050498962\n",
      "          vf_loss: 0.13529511280357837\n",
      "    num_agent_steps_sampled: 1564434\n",
      "    num_agent_steps_trained: 1564434\n",
      "    num_steps_sampled: 1564434\n",
      "    num_steps_trained: 1564434\n",
      "  iterations_since_restore: 783\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.240625\n",
      "    ram_util_percent: 31.290625\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04421787984040493\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.154295559201756\n",
      "    mean_inference_ms: 2.4634366333244513\n",
      "    mean_raw_obs_processing_ms: 2.0752416070191613\n",
      "  time_since_restore: 21482.18403172493\n",
      "  time_this_iter_s: 22.174546241760254\n",
      "  time_total_s: 21482.18403172493\n",
      "  timers:\n",
      "    learn_throughput: 1162.872\n",
      "    learn_time_ms: 1718.16\n",
      "    load_throughput: 59780.952\n",
      "    load_time_ms: 33.422\n",
      "    sample_throughput: 74.922\n",
      "    sample_time_ms: 26667.669\n",
      "    update_time_ms: 8.078\n",
      "  timestamp: 1636451019\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1564434\n",
      "  training_iteration: 783\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   783</td><td style=\"text-align: right;\">         21482.2</td><td style=\"text-align: right;\">1564434</td><td style=\"text-align: right;\">  8.5125</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            106.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1566432\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-44-02\n",
      "  done: false\n",
      "  episode_len_mean: 108.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000018\n",
      "  episode_reward_mean: 8.67350000000002\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15413\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3749867564155942\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008432337175384818\n",
      "          policy_loss: -0.015429498308471271\n",
      "          total_loss: 0.14463084081986122\n",
      "          vf_explained_var: 0.9631080031394958\n",
      "          vf_loss: 0.1635533487335557\n",
      "    num_agent_steps_sampled: 1566432\n",
      "    num_agent_steps_trained: 1566432\n",
      "    num_steps_sampled: 1566432\n",
      "    num_steps_trained: 1566432\n",
      "  iterations_since_restore: 784\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.76969696969695\n",
      "    ram_util_percent: 31.393939393939394\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044223776419200576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.151041908482693\n",
      "    mean_inference_ms: 2.4634847773563466\n",
      "    mean_raw_obs_processing_ms: 2.0776344251081222\n",
      "  time_since_restore: 21505.785184144974\n",
      "  time_this_iter_s: 23.601152420043945\n",
      "  time_total_s: 21505.785184144974\n",
      "  timers:\n",
      "    learn_throughput: 1162.128\n",
      "    learn_time_ms: 1719.261\n",
      "    load_throughput: 59361.893\n",
      "    load_time_ms: 33.658\n",
      "    sample_throughput: 75.067\n",
      "    sample_time_ms: 26616.141\n",
      "    update_time_ms: 8.24\n",
      "  timestamp: 1636451042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1566432\n",
      "  training_iteration: 784\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   784</td><td style=\"text-align: right;\">         21505.8</td><td style=\"text-align: right;\">1566432</td><td style=\"text-align: right;\">  8.6735</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            108.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1568430\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-44-27\n",
      "  done: false\n",
      "  episode_len_mean: 107.78\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.510000000000018\n",
      "  episode_reward_mean: 8.698400000000019\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15432\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4064187469936553\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00937735674267497\n",
      "          policy_loss: -0.028088787606074698\n",
      "          total_loss: 0.28884897551588007\n",
      "          vf_explained_var: 0.9498924612998962\n",
      "          vf_loss: 0.31959559757794653\n",
      "    num_agent_steps_sampled: 1568430\n",
      "    num_agent_steps_trained: 1568430\n",
      "    num_steps_sampled: 1568430\n",
      "    num_steps_trained: 1568430\n",
      "  iterations_since_restore: 785\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.67222222222223\n",
      "    ram_util_percent: 31.527777777777786\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422206022023374\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.14767512732508\n",
      "    mean_inference_ms: 2.4633816948262592\n",
      "    mean_raw_obs_processing_ms: 2.077722450023441\n",
      "  time_since_restore: 21530.398821115494\n",
      "  time_this_iter_s: 24.61363697052002\n",
      "  time_total_s: 21530.398821115494\n",
      "  timers:\n",
      "    learn_throughput: 1160.557\n",
      "    learn_time_ms: 1721.587\n",
      "    load_throughput: 59143.496\n",
      "    load_time_ms: 33.782\n",
      "    sample_throughput: 75.144\n",
      "    sample_time_ms: 26589.077\n",
      "    update_time_ms: 8.436\n",
      "  timestamp: 1636451067\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1568430\n",
      "  training_iteration: 785\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   785</td><td style=\"text-align: right;\">         21530.4</td><td style=\"text-align: right;\">1568430</td><td style=\"text-align: right;\">  8.6984</td><td style=\"text-align: right;\">               14.51</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            107.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1570428\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-44-51\n",
      "  done: false\n",
      "  episode_len_mean: 108.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 8.602800000000018\n",
      "  episode_reward_min: 2.5500000000000083\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15451\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3423923901149204\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007879531997679741\n",
      "          policy_loss: -0.05029438442683646\n",
      "          total_loss: 0.051203963586262294\n",
      "          vf_explained_var: 0.9827382564544678\n",
      "          vf_loss: 0.10533782940890107\n",
      "    num_agent_steps_sampled: 1570428\n",
      "    num_agent_steps_trained: 1570428\n",
      "    num_steps_sampled: 1570428\n",
      "    num_steps_trained: 1570428\n",
      "  iterations_since_restore: 786\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.47941176470589\n",
      "    ram_util_percent: 31.614705882352943\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422503476828158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.145212353596886\n",
      "    mean_inference_ms: 2.463374356189378\n",
      "    mean_raw_obs_processing_ms: 2.0758997294733033\n",
      "  time_since_restore: 21554.647459983826\n",
      "  time_this_iter_s: 24.24863886833191\n",
      "  time_total_s: 21554.647459983826\n",
      "  timers:\n",
      "    learn_throughput: 1160.642\n",
      "    learn_time_ms: 1721.461\n",
      "    load_throughput: 59162.661\n",
      "    load_time_ms: 33.771\n",
      "    sample_throughput: 75.281\n",
      "    sample_time_ms: 26540.491\n",
      "    update_time_ms: 8.286\n",
      "  timestamp: 1636451091\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1570428\n",
      "  training_iteration: 786\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   786</td><td style=\"text-align: right;\">         21554.6</td><td style=\"text-align: right;\">1570428</td><td style=\"text-align: right;\">  8.6028</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">                2.55</td><td style=\"text-align: right;\">             108.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1572426\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-45-16\n",
      "  done: false\n",
      "  episode_len_mean: 108.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.400000000000016\n",
      "  episode_reward_mean: 8.37780000000002\n",
      "  episode_reward_min: 2.5500000000000083\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15470\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.405622132619222\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009463620441557019\n",
      "          policy_loss: -0.03551664779938403\n",
      "          total_loss: 0.09762663567172629\n",
      "          vf_explained_var: 0.9789922833442688\n",
      "          vf_loss: 0.13568822415102097\n",
      "    num_agent_steps_sampled: 1572426\n",
      "    num_agent_steps_trained: 1572426\n",
      "    num_steps_sampled: 1572426\n",
      "    num_steps_trained: 1572426\n",
      "  iterations_since_restore: 787\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.64857142857143\n",
      "    ram_util_percent: 31.617142857142863\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04421631417284369\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.14314058214219\n",
      "    mean_inference_ms: 2.4632117703193086\n",
      "    mean_raw_obs_processing_ms: 2.0740530549732545\n",
      "  time_since_restore: 21579.21414375305\n",
      "  time_this_iter_s: 24.566683769226074\n",
      "  time_total_s: 21579.21414375305\n",
      "  timers:\n",
      "    learn_throughput: 1161.142\n",
      "    learn_time_ms: 1720.719\n",
      "    load_throughput: 58790.446\n",
      "    load_time_ms: 33.985\n",
      "    sample_throughput: 75.174\n",
      "    sample_time_ms: 26578.424\n",
      "    update_time_ms: 8.014\n",
      "  timestamp: 1636451116\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1572426\n",
      "  training_iteration: 787\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   787</td><td style=\"text-align: right;\">         21579.2</td><td style=\"text-align: right;\">1572426</td><td style=\"text-align: right;\">  8.3778</td><td style=\"text-align: right;\">                14.4</td><td style=\"text-align: right;\">                2.55</td><td style=\"text-align: right;\">            108.19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1574424\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-45-39\n",
      "  done: false\n",
      "  episode_len_mean: 107.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.380000000000013\n",
      "  episode_reward_mean: 8.695400000000017\n",
      "  episode_reward_min: 2.5500000000000083\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15488\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4122321929250445\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007660747793288673\n",
      "          policy_loss: -0.04282119061265673\n",
      "          total_loss: 0.033009111872386365\n",
      "          vf_explained_var: 0.9909237623214722\n",
      "          vf_loss: 0.08063430720496745\n",
      "    num_agent_steps_sampled: 1574424\n",
      "    num_agent_steps_trained: 1574424\n",
      "    num_steps_sampled: 1574424\n",
      "    num_steps_trained: 1574424\n",
      "  iterations_since_restore: 788\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.38823529411764\n",
      "    ram_util_percent: 31.602941176470587\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423386081223787\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.141605876363545\n",
      "    mean_inference_ms: 2.463451745487738\n",
      "    mean_raw_obs_processing_ms: 2.072318200498517\n",
      "  time_since_restore: 21602.895837068558\n",
      "  time_this_iter_s: 23.68169331550598\n",
      "  time_total_s: 21602.895837068558\n",
      "  timers:\n",
      "    learn_throughput: 1161.389\n",
      "    learn_time_ms: 1720.354\n",
      "    load_throughput: 58813.964\n",
      "    load_time_ms: 33.972\n",
      "    sample_throughput: 75.194\n",
      "    sample_time_ms: 26571.334\n",
      "    update_time_ms: 8.45\n",
      "  timestamp: 1636451139\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1574424\n",
      "  training_iteration: 788\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   788</td><td style=\"text-align: right;\">         21602.9</td><td style=\"text-align: right;\">1574424</td><td style=\"text-align: right;\">  8.6954</td><td style=\"text-align: right;\">               14.38</td><td style=\"text-align: right;\">                2.55</td><td style=\"text-align: right;\">            107.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1576422\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-46-04\n",
      "  done: false\n",
      "  episode_len_mean: 106.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.380000000000013\n",
      "  episode_reward_mean: 8.72490000000002\n",
      "  episode_reward_min: 2.5500000000000083\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 15508\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4389271912120638\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006347783989866549\n",
      "          policy_loss: -0.003081551016796203\n",
      "          total_loss: 0.07925814931236562\n",
      "          vf_explained_var: 0.9791468977928162\n",
      "          vf_loss: 0.08900770301974956\n",
      "    num_agent_steps_sampled: 1576422\n",
      "    num_agent_steps_trained: 1576422\n",
      "    num_steps_sampled: 1576422\n",
      "    num_steps_trained: 1576422\n",
      "  iterations_since_restore: 789\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.24705882352941\n",
      "    ram_util_percent: 31.549999999999994\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425019804475545\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.140370300642715\n",
      "    mean_inference_ms: 2.4636822254678448\n",
      "    mean_raw_obs_processing_ms: 2.070436854335655\n",
      "  time_since_restore: 21626.90831065178\n",
      "  time_this_iter_s: 24.012473583221436\n",
      "  time_total_s: 21626.90831065178\n",
      "  timers:\n",
      "    learn_throughput: 1161.806\n",
      "    learn_time_ms: 1719.736\n",
      "    load_throughput: 58707.58\n",
      "    load_time_ms: 34.033\n",
      "    sample_throughput: 84.81\n",
      "    sample_time_ms: 23558.497\n",
      "    update_time_ms: 8.766\n",
      "  timestamp: 1636451164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1576422\n",
      "  training_iteration: 789\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   789</td><td style=\"text-align: right;\">         21626.9</td><td style=\"text-align: right;\">1576422</td><td style=\"text-align: right;\">  8.7249</td><td style=\"text-align: right;\">               14.38</td><td style=\"text-align: right;\">                2.55</td><td style=\"text-align: right;\">            106.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1578420\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-46-28\n",
      "  done: false\n",
      "  episode_len_mean: 106.36\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.390000000000017\n",
      "  episode_reward_mean: 9.01810000000002\n",
      "  episode_reward_min: 2.5500000000000083\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15526\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3922534925597054\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009498482193040891\n",
      "          policy_loss: -0.04770283769993555\n",
      "          total_loss: 0.10533243918880111\n",
      "          vf_explained_var: 0.9785324931144714\n",
      "          vf_loss: 0.1554041259345554\n",
      "    num_agent_steps_sampled: 1578420\n",
      "    num_agent_steps_trained: 1578420\n",
      "    num_steps_sampled: 1578420\n",
      "    num_steps_trained: 1578420\n",
      "  iterations_since_restore: 790\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.21142857142858\n",
      "    ram_util_percent: 31.55999999999999\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442376006671103\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.138485420267507\n",
      "    mean_inference_ms: 2.4634434155017937\n",
      "    mean_raw_obs_processing_ms: 2.0688092946523273\n",
      "  time_since_restore: 21650.91672515869\n",
      "  time_this_iter_s: 24.00841450691223\n",
      "  time_total_s: 21650.91672515869\n",
      "  timers:\n",
      "    learn_throughput: 1161.53\n",
      "    learn_time_ms: 1720.145\n",
      "    load_throughput: 58596.868\n",
      "    load_time_ms: 34.097\n",
      "    sample_throughput: 84.85\n",
      "    sample_time_ms: 23547.316\n",
      "    update_time_ms: 8.75\n",
      "  timestamp: 1636451188\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1578420\n",
      "  training_iteration: 790\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   790</td><td style=\"text-align: right;\">         21650.9</td><td style=\"text-align: right;\">1578420</td><td style=\"text-align: right;\">  9.0181</td><td style=\"text-align: right;\">               14.39</td><td style=\"text-align: right;\">                2.55</td><td style=\"text-align: right;\">            106.36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1580418\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-46-52\n",
      "  done: false\n",
      "  episode_len_mean: 107.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.390000000000017\n",
      "  episode_reward_mean: 9.025500000000019\n",
      "  episode_reward_min: 2.7200000000000215\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15544\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4245651421092806\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007597952266447879\n",
      "          policy_loss: -0.048067301387588184\n",
      "          total_loss: 0.022155585929396607\n",
      "          vf_explained_var: 0.9848585724830627\n",
      "          vf_loss: 0.07522660312021062\n",
      "    num_agent_steps_sampled: 1580418\n",
      "    num_agent_steps_trained: 1580418\n",
      "    num_steps_sampled: 1580418\n",
      "    num_steps_trained: 1580418\n",
      "  iterations_since_restore: 791\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0794117647059\n",
      "    ram_util_percent: 31.52647058823529\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422886058507637\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.136569154098456\n",
      "    mean_inference_ms: 2.4632878933332387\n",
      "    mean_raw_obs_processing_ms: 2.067076899942036\n",
      "  time_since_restore: 21674.90427327156\n",
      "  time_this_iter_s: 23.987548112869263\n",
      "  time_total_s: 21674.90427327156\n",
      "  timers:\n",
      "    learn_throughput: 1162.31\n",
      "    learn_time_ms: 1718.991\n",
      "    load_throughput: 58325.986\n",
      "    load_time_ms: 34.256\n",
      "    sample_throughput: 90.525\n",
      "    sample_time_ms: 22071.166\n",
      "    update_time_ms: 8.433\n",
      "  timestamp: 1636451212\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1580418\n",
      "  training_iteration: 791\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   791</td><td style=\"text-align: right;\">         21674.9</td><td style=\"text-align: right;\">1580418</td><td style=\"text-align: right;\">  9.0255</td><td style=\"text-align: right;\">               14.39</td><td style=\"text-align: right;\">                2.72</td><td style=\"text-align: right;\">            107.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1582416\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-47-16\n",
      "  done: false\n",
      "  episode_len_mean: 105.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.390000000000017\n",
      "  episode_reward_mean: 9.00800000000002\n",
      "  episode_reward_min: -0.9500000000000007\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 15564\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.35453940090679\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012668774639496354\n",
      "          policy_loss: -0.02844721328999315\n",
      "          total_loss: 0.2721462094712825\n",
      "          vf_explained_var: 0.9643126130104065\n",
      "          vf_loss: 0.29872887758981614\n",
      "    num_agent_steps_sampled: 1582416\n",
      "    num_agent_steps_trained: 1582416\n",
      "    num_steps_sampled: 1582416\n",
      "    num_steps_trained: 1582416\n",
      "  iterations_since_restore: 792\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.02222222222221\n",
      "    ram_util_percent: 31.505555555555546\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424097991372162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.134501230591958\n",
      "    mean_inference_ms: 2.4634497569234193\n",
      "    mean_raw_obs_processing_ms: 2.0652220984548952\n",
      "  time_since_restore: 21699.768615961075\n",
      "  time_this_iter_s: 24.86434268951416\n",
      "  time_total_s: 21699.768615961075\n",
      "  timers:\n",
      "    learn_throughput: 1161.796\n",
      "    learn_time_ms: 1719.751\n",
      "    load_throughput: 58171.447\n",
      "    load_time_ms: 34.347\n",
      "    sample_throughput: 89.983\n",
      "    sample_time_ms: 22204.298\n",
      "    update_time_ms: 8.492\n",
      "  timestamp: 1636451236\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1582416\n",
      "  training_iteration: 792\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   792</td><td style=\"text-align: right;\">         21699.8</td><td style=\"text-align: right;\">1582416</td><td style=\"text-align: right;\">   9.008</td><td style=\"text-align: right;\">               14.39</td><td style=\"text-align: right;\">               -0.95</td><td style=\"text-align: right;\">            105.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1584414\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-47-41\n",
      "  done: false\n",
      "  episode_len_mean: 104.83\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.390000000000017\n",
      "  episode_reward_mean: 8.961800000000018\n",
      "  episode_reward_min: -0.9500000000000007\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15583\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3562438539096286\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008103302841176706\n",
      "          policy_loss: -0.0425676155125811\n",
      "          total_loss: 0.03562439900955983\n",
      "          vf_explained_var: 0.9886753559112549\n",
      "          vf_loss: 0.08189782429309118\n",
      "    num_agent_steps_sampled: 1584414\n",
      "    num_agent_steps_trained: 1584414\n",
      "    num_steps_sampled: 1584414\n",
      "    num_steps_trained: 1584414\n",
      "  iterations_since_restore: 793\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.5794117647059\n",
      "    ram_util_percent: 31.452941176470585\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425697659636656\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.133106428430892\n",
      "    mean_inference_ms: 2.4636984297519917\n",
      "    mean_raw_obs_processing_ms: 2.0634110607990057\n",
      "  time_since_restore: 21724.224672794342\n",
      "  time_this_iter_s: 24.456056833267212\n",
      "  time_total_s: 21724.224672794342\n",
      "  timers:\n",
      "    learn_throughput: 1162.51\n",
      "    learn_time_ms: 1718.695\n",
      "    load_throughput: 58196.13\n",
      "    load_time_ms: 34.332\n",
      "    sample_throughput: 89.065\n",
      "    sample_time_ms: 22432.932\n",
      "    update_time_ms: 9.172\n",
      "  timestamp: 1636451261\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1584414\n",
      "  training_iteration: 793\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   793</td><td style=\"text-align: right;\">         21724.2</td><td style=\"text-align: right;\">1584414</td><td style=\"text-align: right;\">  8.9618</td><td style=\"text-align: right;\">               14.39</td><td style=\"text-align: right;\">               -0.95</td><td style=\"text-align: right;\">            104.83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1586412\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-48-05\n",
      "  done: false\n",
      "  episode_len_mean: 104.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 8.942400000000019\n",
      "  episode_reward_min: -0.9500000000000007\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15602\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3801090115592594\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010471115782131026\n",
      "          policy_loss: -0.03278036931795733\n",
      "          total_loss: 0.1431515704663027\n",
      "          vf_explained_var: 0.9760290384292603\n",
      "          vf_loss: 0.17699625472582523\n",
      "    num_agent_steps_sampled: 1586412\n",
      "    num_agent_steps_trained: 1586412\n",
      "    num_steps_sampled: 1586412\n",
      "    num_steps_trained: 1586412\n",
      "  iterations_since_restore: 794\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.56285714285715\n",
      "    ram_util_percent: 31.42\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424355333966835\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.131506995037817\n",
      "    mean_inference_ms: 2.46347858806628\n",
      "    mean_raw_obs_processing_ms: 2.0616983388826498\n",
      "  time_since_restore: 21748.42228102684\n",
      "  time_this_iter_s: 24.19760823249817\n",
      "  time_total_s: 21748.42228102684\n",
      "  timers:\n",
      "    learn_throughput: 1162.385\n",
      "    learn_time_ms: 1718.88\n",
      "    load_throughput: 58360.634\n",
      "    load_time_ms: 34.235\n",
      "    sample_throughput: 88.828\n",
      "    sample_time_ms: 22492.843\n",
      "    update_time_ms: 8.844\n",
      "  timestamp: 1636451285\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1586412\n",
      "  training_iteration: 794\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   794</td><td style=\"text-align: right;\">         21748.4</td><td style=\"text-align: right;\">1586412</td><td style=\"text-align: right;\">  8.9424</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.95</td><td style=\"text-align: right;\">             104.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1588410\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-48-29\n",
      "  done: false\n",
      "  episode_len_mean: 104.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 8.675100000000018\n",
      "  episode_reward_min: -0.9500000000000007\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15621\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.46319918405442\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008596446798079426\n",
      "          policy_loss: -0.06941911092116719\n",
      "          total_loss: 0.057061701374394556\n",
      "          vf_explained_var: 0.9778438806533813\n",
      "          vf_loss: 0.1306563286376851\n",
      "    num_agent_steps_sampled: 1588410\n",
      "    num_agent_steps_trained: 1588410\n",
      "    num_steps_sampled: 1588410\n",
      "    num_steps_trained: 1588410\n",
      "  iterations_since_restore: 795\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11764705882354\n",
      "    ram_util_percent: 31.41176470588235\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425935766942342\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.130615051409933\n",
      "    mean_inference_ms: 2.463738358911321\n",
      "    mean_raw_obs_processing_ms: 2.0599155600260386\n",
      "  time_since_restore: 21772.326658010483\n",
      "  time_this_iter_s: 23.904376983642578\n",
      "  time_total_s: 21772.326658010483\n",
      "  timers:\n",
      "    learn_throughput: 1162.023\n",
      "    learn_time_ms: 1719.416\n",
      "    load_throughput: 58505.928\n",
      "    load_time_ms: 34.15\n",
      "    sample_throughput: 89.111\n",
      "    sample_time_ms: 22421.483\n",
      "    update_time_ms: 8.864\n",
      "  timestamp: 1636451309\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1588410\n",
      "  training_iteration: 795\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   795</td><td style=\"text-align: right;\">         21772.3</td><td style=\"text-align: right;\">1588410</td><td style=\"text-align: right;\">  8.6751</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.95</td><td style=\"text-align: right;\">             104.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1590408\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-48-54\n",
      "  done: false\n",
      "  episode_len_mean: 103.94\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 8.735500000000018\n",
      "  episode_reward_min: -0.9500000000000007\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15640\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4148144727661496\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007982502408667484\n",
      "          policy_loss: -0.053071493016822\n",
      "          total_loss: 0.009075194668202172\n",
      "          vf_explained_var: 0.9885252714157104\n",
      "          vf_loss: 0.06658514169532628\n",
      "    num_agent_steps_sampled: 1590408\n",
      "    num_agent_steps_trained: 1590408\n",
      "    num_steps_sampled: 1590408\n",
      "    num_steps_trained: 1590408\n",
      "  iterations_since_restore: 796\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.27142857142859\n",
      "    ram_util_percent: 31.40285714285714\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427570237256721\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.129854836735625\n",
      "    mean_inference_ms: 2.4640042086580523\n",
      "    mean_raw_obs_processing_ms: 2.0581547079606533\n",
      "  time_since_restore: 21796.71759366989\n",
      "  time_this_iter_s: 24.39093565940857\n",
      "  time_total_s: 21796.71759366989\n",
      "  timers:\n",
      "    learn_throughput: 1161.873\n",
      "    learn_time_ms: 1719.637\n",
      "    load_throughput: 58560.303\n",
      "    load_time_ms: 34.119\n",
      "    sample_throughput: 89.056\n",
      "    sample_time_ms: 22435.354\n",
      "    update_time_ms: 8.733\n",
      "  timestamp: 1636451334\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1590408\n",
      "  training_iteration: 796\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   796</td><td style=\"text-align: right;\">         21796.7</td><td style=\"text-align: right;\">1590408</td><td style=\"text-align: right;\">  8.7355</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.95</td><td style=\"text-align: right;\">            103.94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1592406\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-49-19\n",
      "  done: false\n",
      "  episode_len_mean: 104.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 8.811000000000021\n",
      "  episode_reward_min: 3.8600000000000203\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15659\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4577801233246213\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01023328991678829\n",
      "          policy_loss: -0.02623872756071034\n",
      "          total_loss: 0.09571247130100216\n",
      "          vf_explained_var: 0.9829581379890442\n",
      "          vf_loss: 0.12408151464270693\n",
      "    num_agent_steps_sampled: 1592406\n",
      "    num_agent_steps_trained: 1592406\n",
      "    num_steps_sampled: 1592406\n",
      "    num_steps_trained: 1592406\n",
      "  iterations_since_restore: 797\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.54166666666669\n",
      "    ram_util_percent: 31.394444444444446\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425980436356275\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.128427475235835\n",
      "    mean_inference_ms: 2.4637086999061997\n",
      "    mean_raw_obs_processing_ms: 2.056544698224438\n",
      "  time_since_restore: 21821.74512529373\n",
      "  time_this_iter_s: 25.027531623840332\n",
      "  time_total_s: 21821.74512529373\n",
      "  timers:\n",
      "    learn_throughput: 1162.114\n",
      "    learn_time_ms: 1719.281\n",
      "    load_throughput: 58593.673\n",
      "    load_time_ms: 34.099\n",
      "    sample_throughput: 88.874\n",
      "    sample_time_ms: 22481.36\n",
      "    update_time_ms: 9.277\n",
      "  timestamp: 1636451359\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1592406\n",
      "  training_iteration: 797\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   797</td><td style=\"text-align: right;\">         21821.7</td><td style=\"text-align: right;\">1592406</td><td style=\"text-align: right;\">   8.811</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                3.86</td><td style=\"text-align: right;\">            104.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1594404\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-50-14\n",
      "  done: false\n",
      "  episode_len_mean: 103.75\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 8.588700000000017\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 15680\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3916197231837681\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00984210499619018\n",
      "          policy_loss: -0.04102796195518403\n",
      "          total_loss: 0.12716502151673748\n",
      "          vf_explained_var: 0.9798147082328796\n",
      "          vf_loss: 0.17013751837824073\n",
      "    num_agent_steps_sampled: 1594404\n",
      "    num_agent_steps_trained: 1594404\n",
      "    num_steps_sampled: 1594404\n",
      "    num_steps_trained: 1594404\n",
      "  iterations_since_restore: 798\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.07848101265822\n",
      "    ram_util_percent: 31.27974683544302\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426506444797096\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.127552243082217\n",
      "    mean_inference_ms: 2.463788919525389\n",
      "    mean_raw_obs_processing_ms: 2.0589363743766653\n",
      "  time_since_restore: 21877.228209018707\n",
      "  time_this_iter_s: 55.483083724975586\n",
      "  time_total_s: 21877.228209018707\n",
      "  timers:\n",
      "    learn_throughput: 1161.043\n",
      "    learn_time_ms: 1720.867\n",
      "    load_throughput: 58787.105\n",
      "    load_time_ms: 33.987\n",
      "    sample_throughput: 77.863\n",
      "    sample_time_ms: 25660.392\n",
      "    update_time_ms: 9.073\n",
      "  timestamp: 1636451414\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1594404\n",
      "  training_iteration: 798\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   798</td><td style=\"text-align: right;\">         21877.2</td><td style=\"text-align: right;\">1594404</td><td style=\"text-align: right;\">  8.5887</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">            103.75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1596402\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-50-54\n",
      "  done: false\n",
      "  episode_len_mean: 102.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.410000000000018\n",
      "  episode_reward_mean: 8.574800000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15699\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4519960727010455\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009675914194247083\n",
      "          policy_loss: -0.03569229646098046\n",
      "          total_loss: 0.3624910578974301\n",
      "          vf_explained_var: 0.9499946236610413\n",
      "          vf_loss: 0.4009337987218584\n",
      "    num_agent_steps_sampled: 1596402\n",
      "    num_agent_steps_trained: 1596402\n",
      "    num_steps_sampled: 1596402\n",
      "    num_steps_trained: 1596402\n",
      "  iterations_since_restore: 799\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.2982142857143\n",
      "    ram_util_percent: 31.246428571428574\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044275429767318145\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.12636022684136\n",
      "    mean_inference_ms: 2.4639342667058997\n",
      "    mean_raw_obs_processing_ms: 2.0631210010225285\n",
      "  time_since_restore: 21916.736976385117\n",
      "  time_this_iter_s: 39.5087673664093\n",
      "  time_total_s: 21916.736976385117\n",
      "  timers:\n",
      "    learn_throughput: 1162.06\n",
      "    learn_time_ms: 1719.361\n",
      "    load_throughput: 58653.834\n",
      "    load_time_ms: 34.064\n",
      "    sample_throughput: 73.424\n",
      "    sample_time_ms: 27211.774\n",
      "    update_time_ms: 8.617\n",
      "  timestamp: 1636451454\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1596402\n",
      "  training_iteration: 799\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   799</td><td style=\"text-align: right;\">         21916.7</td><td style=\"text-align: right;\">1596402</td><td style=\"text-align: right;\">  8.5748</td><td style=\"text-align: right;\">               14.41</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            102.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1598400\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-51-19\n",
      "  done: false\n",
      "  episode_len_mean: 103.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.430000000000016\n",
      "  episode_reward_mean: 8.884400000000017\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15718\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.400562254020146\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0077682554824936596\n",
      "          policy_loss: -0.09330821328219913\n",
      "          total_loss: -0.011202858876259554\n",
      "          vf_explained_var: 0.9893081188201904\n",
      "          vf_loss: 0.08666189059260346\n",
      "    num_agent_steps_sampled: 1598400\n",
      "    num_agent_steps_trained: 1598400\n",
      "    num_steps_sampled: 1598400\n",
      "    num_steps_trained: 1598400\n",
      "  iterations_since_restore: 800\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.98055555555555\n",
      "    ram_util_percent: 31.0\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427461944680727\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.12550930988945\n",
      "    mean_inference_ms: 2.463914161311626\n",
      "    mean_raw_obs_processing_ms: 2.0672584049671876\n",
      "  time_since_restore: 21941.768793582916\n",
      "  time_this_iter_s: 25.031817197799683\n",
      "  time_total_s: 21941.768793582916\n",
      "  timers:\n",
      "    learn_throughput: 1162.405\n",
      "    learn_time_ms: 1718.849\n",
      "    load_throughput: 58752.526\n",
      "    load_time_ms: 34.007\n",
      "    sample_throughput: 73.148\n",
      "    sample_time_ms: 27314.413\n",
      "    update_time_ms: 8.888\n",
      "  timestamp: 1636451479\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1598400\n",
      "  training_iteration: 800\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   800</td><td style=\"text-align: right;\">         21941.8</td><td style=\"text-align: right;\">1598400</td><td style=\"text-align: right;\">  8.8844</td><td style=\"text-align: right;\">               14.43</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            103.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1600398\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-51-44\n",
      "  done: false\n",
      "  episode_len_mean: 103.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.430000000000016\n",
      "  episode_reward_mean: 8.775500000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15736\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.427791464328766\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011133701719940195\n",
      "          policy_loss: -0.07044526966554777\n",
      "          total_loss: 0.07977577481596243\n",
      "          vf_explained_var: 0.975238025188446\n",
      "          vf_loss: 0.15095623378597556\n",
      "    num_agent_steps_sampled: 1600398\n",
      "    num_agent_steps_trained: 1600398\n",
      "    num_steps_sampled: 1600398\n",
      "    num_steps_trained: 1600398\n",
      "  iterations_since_restore: 801\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.81944444444443\n",
      "    ram_util_percent: 31.133333333333333\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425856088685063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.124348932225292\n",
      "    mean_inference_ms: 2.4636449722155866\n",
      "    mean_raw_obs_processing_ms: 2.071203421314192\n",
      "  time_since_restore: 21966.488077402115\n",
      "  time_this_iter_s: 24.71928381919861\n",
      "  time_total_s: 21966.488077402115\n",
      "  timers:\n",
      "    learn_throughput: 1161.519\n",
      "    learn_time_ms: 1720.162\n",
      "    load_throughput: 58878.261\n",
      "    load_time_ms: 33.934\n",
      "    sample_throughput: 72.955\n",
      "    sample_time_ms: 27386.889\n",
      "    update_time_ms: 8.652\n",
      "  timestamp: 1636451504\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1600398\n",
      "  training_iteration: 801\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   801</td><td style=\"text-align: right;\">         21966.5</td><td style=\"text-align: right;\">1600398</td><td style=\"text-align: right;\">  8.7755</td><td style=\"text-align: right;\">               14.43</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            103.65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1602396\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-52-08\n",
      "  done: false\n",
      "  episode_len_mean: 104.12\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.430000000000016\n",
      "  episode_reward_mean: 8.776100000000019\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15755\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4914989800680252\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011277600505665068\n",
      "          policy_loss: -0.03987844435586816\n",
      "          total_loss: 0.1007592525333166\n",
      "          vf_explained_var: 0.9759935736656189\n",
      "          vf_loss: 0.14183493068530445\n",
      "    num_agent_steps_sampled: 1602396\n",
      "    num_agent_steps_trained: 1602396\n",
      "    num_steps_sampled: 1602396\n",
      "    num_steps_trained: 1602396\n",
      "  iterations_since_restore: 802\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.24411764705884\n",
      "    ram_util_percent: 31.23823529411765\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044260307688391586\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.123592192502382\n",
      "    mean_inference_ms: 2.463704362598776\n",
      "    mean_raw_obs_processing_ms: 2.0752769079148137\n",
      "  time_since_restore: 21990.516536474228\n",
      "  time_this_iter_s: 24.028459072113037\n",
      "  time_total_s: 21990.516536474228\n",
      "  timers:\n",
      "    learn_throughput: 1161.052\n",
      "    learn_time_ms: 1720.853\n",
      "    load_throughput: 59089.366\n",
      "    load_time_ms: 33.813\n",
      "    sample_throughput: 73.179\n",
      "    sample_time_ms: 27303.024\n",
      "    update_time_ms: 7.882\n",
      "  timestamp: 1636451528\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1602396\n",
      "  training_iteration: 802\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   802</td><td style=\"text-align: right;\">         21990.5</td><td style=\"text-align: right;\">1602396</td><td style=\"text-align: right;\">  8.7761</td><td style=\"text-align: right;\">               14.43</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            104.12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1604394\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-52-32\n",
      "  done: false\n",
      "  episode_len_mean: 106.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.430000000000016\n",
      "  episode_reward_mean: 8.828300000000018\n",
      "  episode_reward_min: -0.060000000000000005\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15774\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5025533210663569\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008765449263420917\n",
      "          policy_loss: -0.025794495739752336\n",
      "          total_loss: 0.05494457832759335\n",
      "          vf_explained_var: 0.9805922508239746\n",
      "          vf_loss: 0.0851025598212367\n",
      "    num_agent_steps_sampled: 1604394\n",
      "    num_agent_steps_trained: 1604394\n",
      "    num_steps_sampled: 1604394\n",
      "    num_steps_trained: 1604394\n",
      "  iterations_since_restore: 803\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.16285714285712\n",
      "    ram_util_percent: 31.419999999999995\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424177112636724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.121907357305346\n",
      "    mean_inference_ms: 2.4633719711443383\n",
      "    mean_raw_obs_processing_ms: 2.0769775733705673\n",
      "  time_since_restore: 22014.822636127472\n",
      "  time_this_iter_s: 24.30609965324402\n",
      "  time_total_s: 22014.822636127472\n",
      "  timers:\n",
      "    learn_throughput: 1160.036\n",
      "    learn_time_ms: 1722.36\n",
      "    load_throughput: 59171.852\n",
      "    load_time_ms: 33.766\n",
      "    sample_throughput: 73.223\n",
      "    sample_time_ms: 27286.686\n",
      "    update_time_ms: 7.681\n",
      "  timestamp: 1636451552\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1604394\n",
      "  training_iteration: 803\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   803</td><td style=\"text-align: right;\">         22014.8</td><td style=\"text-align: right;\">1604394</td><td style=\"text-align: right;\">  8.8283</td><td style=\"text-align: right;\">               14.43</td><td style=\"text-align: right;\">               -0.06</td><td style=\"text-align: right;\">            106.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1606392\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-52-57\n",
      "  done: false\n",
      "  episode_len_mean: 106.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 9.102400000000017\n",
      "  episode_reward_min: 3.3400000000000074\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15793\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3516904967171806\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007794625192183042\n",
      "          policy_loss: -0.059440128930977415\n",
      "          total_loss: -0.013506880633178212\n",
      "          vf_explained_var: 0.9946184158325195\n",
      "          vf_loss: 0.04996898841290247\n",
      "    num_agent_steps_sampled: 1606392\n",
      "    num_agent_steps_trained: 1606392\n",
      "    num_steps_sampled: 1606392\n",
      "    num_steps_trained: 1606392\n",
      "  iterations_since_restore: 804\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08857142857143\n",
      "    ram_util_percent: 31.585714285714293\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424150291210945\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.120991355328005\n",
      "    mean_inference_ms: 2.463361349616487\n",
      "    mean_raw_obs_processing_ms: 2.075215857144019\n",
      "  time_since_restore: 22039.658376693726\n",
      "  time_this_iter_s: 24.835740566253662\n",
      "  time_total_s: 22039.658376693726\n",
      "  timers:\n",
      "    learn_throughput: 1161.637\n",
      "    learn_time_ms: 1719.987\n",
      "    load_throughput: 59674.146\n",
      "    load_time_ms: 33.482\n",
      "    sample_throughput: 73.047\n",
      "    sample_time_ms: 27352.344\n",
      "    update_time_ms: 8.381\n",
      "  timestamp: 1636451577\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1606392\n",
      "  training_iteration: 804\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   804</td><td style=\"text-align: right;\">         22039.7</td><td style=\"text-align: right;\">1606392</td><td style=\"text-align: right;\">  9.1024</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">                3.34</td><td style=\"text-align: right;\">            106.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1608390\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-53-20\n",
      "  done: false\n",
      "  episode_len_mean: 106.67\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 8.97420000000002\n",
      "  episode_reward_min: 3.3400000000000074\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15811\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4180253255934943\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008892303653711874\n",
      "          policy_loss: -0.04154622045656045\n",
      "          total_loss: 0.08078336389291854\n",
      "          vf_explained_var: 0.9777621030807495\n",
      "          vf_loss: 0.12569348721631934\n",
      "    num_agent_steps_sampled: 1608390\n",
      "    num_agent_steps_trained: 1608390\n",
      "    num_steps_sampled: 1608390\n",
      "    num_steps_trained: 1608390\n",
      "  iterations_since_restore: 805\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.06666666666666\n",
      "    ram_util_percent: 31.62424242424242\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424175392605869\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.11981613449505\n",
      "    mean_inference_ms: 2.4633567071432907\n",
      "    mean_raw_obs_processing_ms: 2.0735575842948553\n",
      "  time_since_restore: 22062.641731262207\n",
      "  time_this_iter_s: 22.983354568481445\n",
      "  time_total_s: 22062.641731262207\n",
      "  timers:\n",
      "    learn_throughput: 1162.501\n",
      "    learn_time_ms: 1718.708\n",
      "    load_throughput: 59769.312\n",
      "    load_time_ms: 33.429\n",
      "    sample_throughput: 73.287\n",
      "    sample_time_ms: 27262.535\n",
      "    update_time_ms: 7.696\n",
      "  timestamp: 1636451600\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1608390\n",
      "  training_iteration: 805\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   805</td><td style=\"text-align: right;\">         22062.6</td><td style=\"text-align: right;\">1608390</td><td style=\"text-align: right;\">  8.9742</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">                3.34</td><td style=\"text-align: right;\">            106.67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1610388\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-53-43\n",
      "  done: false\n",
      "  episode_len_mean: 107.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 8.89280000000002\n",
      "  episode_reward_min: 3.3400000000000074\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15829\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4664179171834673\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011923139198207318\n",
      "          policy_loss: -0.05730473856840815\n",
      "          total_loss: 0.08206304255872965\n",
      "          vf_explained_var: 0.9784966111183167\n",
      "          vf_loss: 0.1395289895789964\n",
      "    num_agent_steps_sampled: 1610388\n",
      "    num_agent_steps_trained: 1610388\n",
      "    num_steps_sampled: 1610388\n",
      "    num_steps_trained: 1610388\n",
      "  iterations_since_restore: 806\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.06176470588235\n",
      "    ram_util_percent: 31.60588235294118\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424657621982714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.11891559911153\n",
      "    mean_inference_ms: 2.4634271004121477\n",
      "    mean_raw_obs_processing_ms: 2.0718280240978237\n",
      "  time_since_restore: 22086.229593753815\n",
      "  time_this_iter_s: 23.587862491607666\n",
      "  time_total_s: 22086.229593753815\n",
      "  timers:\n",
      "    learn_throughput: 1161.877\n",
      "    learn_time_ms: 1719.632\n",
      "    load_throughput: 60826.591\n",
      "    load_time_ms: 32.847\n",
      "    sample_throughput: 73.505\n",
      "    sample_time_ms: 27181.699\n",
      "    update_time_ms: 8.012\n",
      "  timestamp: 1636451623\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1610388\n",
      "  training_iteration: 806\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   806</td><td style=\"text-align: right;\">         22086.2</td><td style=\"text-align: right;\">1610388</td><td style=\"text-align: right;\">  8.8928</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">                3.34</td><td style=\"text-align: right;\">            107.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1612386\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-54-08\n",
      "  done: false\n",
      "  episode_len_mean: 108.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.470000000000017\n",
      "  episode_reward_mean: 9.18920000000002\n",
      "  episode_reward_min: 4.530000000000019\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15847\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4263930252620152\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008536450654679752\n",
      "          policy_loss: -0.021974415314339454\n",
      "          total_loss: 0.09274969546213037\n",
      "          vf_explained_var: 0.9806737899780273\n",
      "          vf_loss: 0.11860454357450917\n",
      "    num_agent_steps_sampled: 1612386\n",
      "    num_agent_steps_trained: 1612386\n",
      "    num_steps_sampled: 1612386\n",
      "    num_steps_trained: 1612386\n",
      "  iterations_since_restore: 807\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.32058823529412\n",
      "    ram_util_percent: 31.58823529411765\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424696510891283\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.117499886181296\n",
      "    mean_inference_ms: 2.4634213322154954\n",
      "    mean_raw_obs_processing_ms: 2.070142943729377\n",
      "  time_since_restore: 22110.501935243607\n",
      "  time_this_iter_s: 24.27234148979187\n",
      "  time_total_s: 22110.501935243607\n",
      "  timers:\n",
      "    learn_throughput: 1161.731\n",
      "    learn_time_ms: 1719.847\n",
      "    load_throughput: 60715.976\n",
      "    load_time_ms: 32.907\n",
      "    sample_throughput: 73.711\n",
      "    sample_time_ms: 27105.899\n",
      "    update_time_ms: 7.646\n",
      "  timestamp: 1636451648\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1612386\n",
      "  training_iteration: 807\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   807</td><td style=\"text-align: right;\">         22110.5</td><td style=\"text-align: right;\">1612386</td><td style=\"text-align: right;\">  9.1892</td><td style=\"text-align: right;\">               14.47</td><td style=\"text-align: right;\">                4.53</td><td style=\"text-align: right;\">            108.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1614384\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-54-32\n",
      "  done: false\n",
      "  episode_len_mean: 108.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000016\n",
      "  episode_reward_mean: 9.42010000000002\n",
      "  episode_reward_min: 4.530000000000019\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15865\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4747022617430914\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009110978256766065\n",
      "          policy_loss: -0.04369945640542677\n",
      "          total_loss: 0.067540368065238\n",
      "          vf_explained_var: 0.9838581681251526\n",
      "          vf_loss: 0.11490450878405854\n",
      "    num_agent_steps_sampled: 1614384\n",
      "    num_agent_steps_trained: 1614384\n",
      "    num_steps_sampled: 1614384\n",
      "    num_steps_trained: 1614384\n",
      "  iterations_since_restore: 808\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.24285714285716\n",
      "    ram_util_percent: 31.522857142857134\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424759424743028\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.115803631718578\n",
      "    mean_inference_ms: 2.463403809154464\n",
      "    mean_raw_obs_processing_ms: 2.068456036056313\n",
      "  time_since_restore: 22134.515734434128\n",
      "  time_this_iter_s: 24.01379919052124\n",
      "  time_total_s: 22134.515734434128\n",
      "  timers:\n",
      "    learn_throughput: 1161.964\n",
      "    learn_time_ms: 1719.503\n",
      "    load_throughput: 60769.074\n",
      "    load_time_ms: 32.879\n",
      "    sample_throughput: 83.393\n",
      "    sample_time_ms: 23958.983\n",
      "    update_time_ms: 7.948\n",
      "  timestamp: 1636451672\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1614384\n",
      "  training_iteration: 808\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   808</td><td style=\"text-align: right;\">         22134.5</td><td style=\"text-align: right;\">1614384</td><td style=\"text-align: right;\">  9.4201</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">                4.53</td><td style=\"text-align: right;\">            108.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1616382\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-54-56\n",
      "  done: false\n",
      "  episode_len_mean: 108.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000016\n",
      "  episode_reward_mean: 9.305700000000021\n",
      "  episode_reward_min: 2.4600000000000186\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15884\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4430197693052746\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008904239917523529\n",
      "          policy_loss: -0.05450032956543423\n",
      "          total_loss: 0.06696530821777526\n",
      "          vf_explained_var: 0.9788404107093811\n",
      "          vf_loss: 0.1250649672888574\n",
      "    num_agent_steps_sampled: 1616382\n",
      "    num_agent_steps_trained: 1616382\n",
      "    num_steps_sampled: 1616382\n",
      "    num_steps_trained: 1616382\n",
      "  iterations_since_restore: 809\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.40294117647058\n",
      "    ram_util_percent: 31.479411764705873\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044236931123889656\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.114188508151855\n",
      "    mean_inference_ms: 2.4632192776226445\n",
      "    mean_raw_obs_processing_ms: 2.066644652218136\n",
      "  time_since_restore: 22158.80512046814\n",
      "  time_this_iter_s: 24.28938603401184\n",
      "  time_total_s: 22158.80512046814\n",
      "  timers:\n",
      "    learn_throughput: 1162.459\n",
      "    learn_time_ms: 1718.77\n",
      "    load_throughput: 61000.686\n",
      "    load_time_ms: 32.754\n",
      "    sample_throughput: 89.05\n",
      "    sample_time_ms: 22436.797\n",
      "    update_time_ms: 8.995\n",
      "  timestamp: 1636451696\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1616382\n",
      "  training_iteration: 809\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   809</td><td style=\"text-align: right;\">         22158.8</td><td style=\"text-align: right;\">1616382</td><td style=\"text-align: right;\">  9.3057</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            108.72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1618380\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-55-21\n",
      "  done: false\n",
      "  episode_len_mean: 108.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.580000000000016\n",
      "  episode_reward_mean: 9.27490000000002\n",
      "  episode_reward_min: 2.4600000000000186\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15903\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4667568416822525\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011363182117897897\n",
      "          policy_loss: -0.018792332016995976\n",
      "          total_loss: 0.15049520887079693\n",
      "          vf_explained_var: 0.9765924215316772\n",
      "          vf_loss: 0.17013325444644406\n",
      "    num_agent_steps_sampled: 1618380\n",
      "    num_agent_steps_trained: 1618380\n",
      "    num_steps_sampled: 1618380\n",
      "    num_steps_trained: 1618380\n",
      "  iterations_since_restore: 810\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08611111111112\n",
      "    ram_util_percent: 31.499999999999986\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044236742826725656\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.112738776067882\n",
      "    mean_inference_ms: 2.4631977118629376\n",
      "    mean_raw_obs_processing_ms: 2.0648732108957817\n",
      "  time_since_restore: 22183.824618577957\n",
      "  time_this_iter_s: 25.019498109817505\n",
      "  time_total_s: 22183.824618577957\n",
      "  timers:\n",
      "    learn_throughput: 1162.074\n",
      "    learn_time_ms: 1719.34\n",
      "    load_throughput: 60715.756\n",
      "    load_time_ms: 32.907\n",
      "    sample_throughput: 89.06\n",
      "    sample_time_ms: 22434.352\n",
      "    update_time_ms: 9.375\n",
      "  timestamp: 1636451721\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1618380\n",
      "  training_iteration: 810\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   810</td><td style=\"text-align: right;\">         22183.8</td><td style=\"text-align: right;\">1618380</td><td style=\"text-align: right;\">  9.2749</td><td style=\"text-align: right;\">               14.58</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            108.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1620378\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-55-49\n",
      "  done: false\n",
      "  episode_len_mean: 108.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.590000000000016\n",
      "  episode_reward_mean: 9.18670000000002\n",
      "  episode_reward_min: 2.4600000000000186\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15922\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4322925533567157\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008991412402219862\n",
      "          policy_loss: -0.07435132586175487\n",
      "          total_loss: 0.05529102283929076\n",
      "          vf_explained_var: 0.9715009331703186\n",
      "          vf_loss: 0.133028373335089\n",
      "    num_agent_steps_sampled: 1620378\n",
      "    num_agent_steps_trained: 1620378\n",
      "    num_steps_sampled: 1620378\n",
      "    num_steps_trained: 1620378\n",
      "  iterations_since_restore: 811\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.915\n",
      "    ram_util_percent: 31.415\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044246204845062975\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.112117877565787\n",
      "    mean_inference_ms: 2.4633264111435604\n",
      "    mean_raw_obs_processing_ms: 2.063140710843742\n",
      "  time_since_restore: 22212.151623249054\n",
      "  time_this_iter_s: 28.3270046710968\n",
      "  time_total_s: 22212.151623249054\n",
      "  timers:\n",
      "    learn_throughput: 1163.975\n",
      "    learn_time_ms: 1716.531\n",
      "    load_throughput: 60658.404\n",
      "    load_time_ms: 32.939\n",
      "    sample_throughput: 87.644\n",
      "    sample_time_ms: 22796.747\n",
      "    update_time_ms: 10.406\n",
      "  timestamp: 1636451749\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1620378\n",
      "  training_iteration: 811\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   811</td><td style=\"text-align: right;\">         22212.2</td><td style=\"text-align: right;\">1620378</td><td style=\"text-align: right;\">  9.1867</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            108.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1622376\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-56-14\n",
      "  done: false\n",
      "  episode_len_mean: 106.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.590000000000016\n",
      "  episode_reward_mean: 9.341200000000018\n",
      "  episode_reward_min: 2.4600000000000186\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15941\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3187714207740058\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009207312476377065\n",
      "          policy_loss: -0.03880346811243466\n",
      "          total_loss: 0.08215555240000998\n",
      "          vf_explained_var: 0.9829033017158508\n",
      "          vf_loss: 0.12294722016723383\n",
      "    num_agent_steps_sampled: 1622376\n",
      "    num_agent_steps_trained: 1622376\n",
      "    num_steps_sampled: 1622376\n",
      "    num_steps_trained: 1622376\n",
      "  iterations_since_restore: 812\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03333333333335\n",
      "    ram_util_percent: 31.461111111111116\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424618115536587\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.112211588325863\n",
      "    mean_inference_ms: 2.4632833154263682\n",
      "    mean_raw_obs_processing_ms: 2.0614083030045403\n",
      "  time_since_restore: 22237.056888103485\n",
      "  time_this_iter_s: 24.905264854431152\n",
      "  time_total_s: 22237.056888103485\n",
      "  timers:\n",
      "    learn_throughput: 1165.12\n",
      "    learn_time_ms: 1714.844\n",
      "    load_throughput: 61004.639\n",
      "    load_time_ms: 32.752\n",
      "    sample_throughput: 87.301\n",
      "    sample_time_ms: 22886.257\n",
      "    update_time_ms: 10.463\n",
      "  timestamp: 1636451774\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1622376\n",
      "  training_iteration: 812\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   812</td><td style=\"text-align: right;\">         22237.1</td><td style=\"text-align: right;\">1622376</td><td style=\"text-align: right;\">  9.3412</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            106.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1624374\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-56-39\n",
      "  done: false\n",
      "  episode_len_mean: 106.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.590000000000016\n",
      "  episode_reward_mean: 9.199500000000018\n",
      "  episode_reward_min: 2.4600000000000186\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 15959\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4025768535477774\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007077441655040791\n",
      "          policy_loss: -0.09857259435313089\n",
      "          total_loss: 0.008677196316421032\n",
      "          vf_explained_var: 0.9775927662849426\n",
      "          vf_loss: 0.11266675791924909\n",
      "    num_agent_steps_sampled: 1624374\n",
      "    num_agent_steps_trained: 1624374\n",
      "    num_steps_sampled: 1624374\n",
      "    num_steps_trained: 1624374\n",
      "  iterations_since_restore: 813\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0942857142857\n",
      "    ram_util_percent: 31.42\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424636773137215\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.112095451254326\n",
      "    mean_inference_ms: 2.4632545492477598\n",
      "    mean_raw_obs_processing_ms: 2.059775074774501\n",
      "  time_since_restore: 22261.486052036285\n",
      "  time_this_iter_s: 24.429163932800293\n",
      "  time_total_s: 22261.486052036285\n",
      "  timers:\n",
      "    learn_throughput: 1166.237\n",
      "    learn_time_ms: 1713.202\n",
      "    load_throughput: 60888.287\n",
      "    load_time_ms: 32.814\n",
      "    sample_throughput: 87.251\n",
      "    sample_time_ms: 22899.447\n",
      "    update_time_ms: 11.262\n",
      "  timestamp: 1636451799\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1624374\n",
      "  training_iteration: 813\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   813</td><td style=\"text-align: right;\">         22261.5</td><td style=\"text-align: right;\">1624374</td><td style=\"text-align: right;\">  9.1995</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">            106.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1626372\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-57-03\n",
      "  done: false\n",
      "  episode_len_mean: 106.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.590000000000016\n",
      "  episode_reward_mean: 9.038300000000019\n",
      "  episode_reward_min: 3.8400000000000265\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 15978\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4307321701731002\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008731259643096798\n",
      "          policy_loss: -0.014163332751819066\n",
      "          total_loss: 0.08022268895237218\n",
      "          vf_explained_var: 0.9759594798088074\n",
      "          vf_loss: 0.09807288620088782\n",
      "    num_agent_steps_sampled: 1626372\n",
      "    num_agent_steps_trained: 1626372\n",
      "    num_steps_sampled: 1626372\n",
      "    num_steps_trained: 1626372\n",
      "  iterations_since_restore: 814\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.21764705882352\n",
      "    ram_util_percent: 31.4\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04426071153958892\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.11217520271357\n",
      "    mean_inference_ms: 2.4634721190311657\n",
      "    mean_raw_obs_processing_ms: 2.0580267570028523\n",
      "  time_since_restore: 22285.485028266907\n",
      "  time_this_iter_s: 23.998976230621338\n",
      "  time_total_s: 22285.485028266907\n",
      "  timers:\n",
      "    learn_throughput: 1165.687\n",
      "    learn_time_ms: 1714.011\n",
      "    load_throughput: 60330.494\n",
      "    load_time_ms: 33.118\n",
      "    sample_throughput: 87.573\n",
      "    sample_time_ms: 22815.178\n",
      "    update_time_ms: 10.675\n",
      "  timestamp: 1636451823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1626372\n",
      "  training_iteration: 814\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   814</td><td style=\"text-align: right;\">         22285.5</td><td style=\"text-align: right;\">1626372</td><td style=\"text-align: right;\">  9.0383</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">                3.84</td><td style=\"text-align: right;\">            106.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1628370\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-57-26\n",
      "  done: false\n",
      "  episode_len_mean: 108.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.590000000000016\n",
      "  episode_reward_mean: 8.698500000000019\n",
      "  episode_reward_min: 0.43000000000001837\n",
      "  episodes_this_iter: 17\n",
      "  episodes_total: 15995\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4094694710913158\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012825270867826644\n",
      "          policy_loss: -0.07055078205608187\n",
      "          total_loss: 0.13605198422890333\n",
      "          vf_explained_var: 0.9589438438415527\n",
      "          vf_loss: 0.20509716290093605\n",
      "    num_agent_steps_sampled: 1628370\n",
      "    num_agent_steps_trained: 1628370\n",
      "    num_steps_sampled: 1628370\n",
      "    num_steps_trained: 1628370\n",
      "  iterations_since_restore: 815\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5\n",
      "    ram_util_percent: 31.321212121212124\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425118383590823\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.111804401279677\n",
      "    mean_inference_ms: 2.4632844224409705\n",
      "    mean_raw_obs_processing_ms: 2.0564436982688177\n",
      "  time_since_restore: 22308.687616825104\n",
      "  time_this_iter_s: 23.20258855819702\n",
      "  time_total_s: 22308.687616825104\n",
      "  timers:\n",
      "    learn_throughput: 1165.47\n",
      "    learn_time_ms: 1714.329\n",
      "    load_throughput: 60329.018\n",
      "    load_time_ms: 33.118\n",
      "    sample_throughput: 87.491\n",
      "    sample_time_ms: 22836.68\n",
      "    update_time_ms: 10.991\n",
      "  timestamp: 1636451846\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1628370\n",
      "  training_iteration: 815\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   815</td><td style=\"text-align: right;\">         22308.7</td><td style=\"text-align: right;\">1628370</td><td style=\"text-align: right;\">  8.6985</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">                0.43</td><td style=\"text-align: right;\">            108.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1630368\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-57-51\n",
      "  done: false\n",
      "  episode_len_mean: 107.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000017\n",
      "  episode_reward_mean: 8.37810000000002\n",
      "  episode_reward_min: 0.43000000000001837\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16014\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3800362802687145\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01044106782133613\n",
      "          policy_loss: -0.025369624474218914\n",
      "          total_loss: 0.1599076929945676\n",
      "          vf_explained_var: 0.971102774143219\n",
      "          vf_loss: 0.18637745997735433\n",
      "    num_agent_steps_sampled: 1630368\n",
      "    num_agent_steps_trained: 1630368\n",
      "    num_steps_sampled: 1630368\n",
      "    num_steps_trained: 1630368\n",
      "  iterations_since_restore: 816\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.5027027027027\n",
      "    ram_util_percent: 31.286486486486496\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424241581731116\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.110968055193958\n",
      "    mean_inference_ms: 2.463092739111836\n",
      "    mean_raw_obs_processing_ms: 2.054675367987182\n",
      "  time_since_restore: 22334.00079202652\n",
      "  time_this_iter_s: 25.313175201416016\n",
      "  time_total_s: 22334.00079202652\n",
      "  timers:\n",
      "    learn_throughput: 1166.633\n",
      "    learn_time_ms: 1712.621\n",
      "    load_throughput: 59235.175\n",
      "    load_time_ms: 33.73\n",
      "    sample_throughput: 86.83\n",
      "    sample_time_ms: 23010.406\n",
      "    update_time_ms: 10.997\n",
      "  timestamp: 1636451871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1630368\n",
      "  training_iteration: 816\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   816</td><td style=\"text-align: right;\">           22334</td><td style=\"text-align: right;\">1630368</td><td style=\"text-align: right;\">  8.3781</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">                0.43</td><td style=\"text-align: right;\">            107.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1632366\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-58-46\n",
      "  done: false\n",
      "  episode_len_mean: 108.09\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000017\n",
      "  episode_reward_mean: 8.29580000000002\n",
      "  episode_reward_min: -0.02\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16033\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3195824887071337\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015609503336533999\n",
      "          policy_loss: -0.01088421813966263\n",
      "          total_loss: 0.3509893502507891\n",
      "          vf_explained_var: 0.9595812559127808\n",
      "          vf_loss: 0.3560824308721792\n",
      "    num_agent_steps_sampled: 1632366\n",
      "    num_agent_steps_trained: 1632366\n",
      "    num_steps_sampled: 1632366\n",
      "    num_steps_trained: 1632366\n",
      "  iterations_since_restore: 817\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.24285714285713\n",
      "    ram_util_percent: 31.185714285714287\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425314106793753\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.10822384136749\n",
      "    mean_inference_ms: 2.463240338577624\n",
      "    mean_raw_obs_processing_ms: 2.0565572001319996\n",
      "  time_since_restore: 22388.2517721653\n",
      "  time_this_iter_s: 54.25098013877869\n",
      "  time_total_s: 22388.2517721653\n",
      "  timers:\n",
      "    learn_throughput: 1166.947\n",
      "    learn_time_ms: 1712.16\n",
      "    load_throughput: 59063.962\n",
      "    load_time_ms: 33.828\n",
      "    sample_throughput: 76.819\n",
      "    sample_time_ms: 26009.098\n",
      "    update_time_ms: 10.641\n",
      "  timestamp: 1636451926\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1632366\n",
      "  training_iteration: 817\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   817</td><td style=\"text-align: right;\">         22388.3</td><td style=\"text-align: right;\">1632366</td><td style=\"text-align: right;\">  8.2958</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">               -0.02</td><td style=\"text-align: right;\">            108.09</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1634364\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-59-12\n",
      "  done: false\n",
      "  episode_len_mean: 107.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000017\n",
      "  episode_reward_mean: 8.341800000000019\n",
      "  episode_reward_min: -0.02\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16052\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4136370783760435\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007994732209194586\n",
      "          policy_loss: -0.051494778586285456\n",
      "          total_loss: 0.05521023502307279\n",
      "          vf_explained_var: 0.9737691283226013\n",
      "          vf_loss: 0.11111681542492338\n",
      "    num_agent_steps_sampled: 1634364\n",
      "    num_agent_steps_trained: 1634364\n",
      "    num_steps_sampled: 1634364\n",
      "    num_steps_trained: 1634364\n",
      "  iterations_since_restore: 818\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77297297297295\n",
      "    ram_util_percent: 30.794594594594585\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044253334566215746\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.106396643021593\n",
      "    mean_inference_ms: 2.4632134253565954\n",
      "    mean_raw_obs_processing_ms: 2.058737188329634\n",
      "  time_since_restore: 22414.279136180878\n",
      "  time_this_iter_s: 26.027364015579224\n",
      "  time_total_s: 22414.279136180878\n",
      "  timers:\n",
      "    learn_throughput: 1167.715\n",
      "    learn_time_ms: 1711.034\n",
      "    load_throughput: 58648.416\n",
      "    load_time_ms: 34.067\n",
      "    sample_throughput: 76.225\n",
      "    sample_time_ms: 26211.82\n",
      "    update_time_ms: 9.947\n",
      "  timestamp: 1636451952\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1634364\n",
      "  training_iteration: 818\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   818</td><td style=\"text-align: right;\">         22414.3</td><td style=\"text-align: right;\">1634364</td><td style=\"text-align: right;\">  8.3418</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">               -0.02</td><td style=\"text-align: right;\">            107.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1636362\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_09-59-50\n",
      "  done: false\n",
      "  episode_len_mean: 106.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.540000000000017\n",
      "  episode_reward_mean: 8.383500000000017\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16070\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.368496356691633\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010338177125388284\n",
      "          policy_loss: -0.012396152388481867\n",
      "          total_loss: 0.2150921221290316\n",
      "          vf_explained_var: 0.9740027189254761\n",
      "          vf_loss: 0.2285981668248063\n",
      "    num_agent_steps_sampled: 1636362\n",
      "    num_agent_steps_trained: 1636362\n",
      "    num_steps_sampled: 1636362\n",
      "    num_steps_trained: 1636362\n",
      "  iterations_since_restore: 819\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.57272727272728\n",
      "    ram_util_percent: 31.020000000000003\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442530064526502\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.104219450785752\n",
      "    mean_inference_ms: 2.463170017306281\n",
      "    mean_raw_obs_processing_ms: 2.06249092590748\n",
      "  time_since_restore: 22452.579832792282\n",
      "  time_this_iter_s: 38.30069661140442\n",
      "  time_total_s: 22452.579832792282\n",
      "  timers:\n",
      "    learn_throughput: 1165.735\n",
      "    learn_time_ms: 1713.94\n",
      "    load_throughput: 58235.762\n",
      "    load_time_ms: 34.309\n",
      "    sample_throughput: 72.365\n",
      "    sample_time_ms: 27610.214\n",
      "    update_time_ms: 9.455\n",
      "  timestamp: 1636451990\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1636362\n",
      "  training_iteration: 819\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   819</td><td style=\"text-align: right;\">         22452.6</td><td style=\"text-align: right;\">1636362</td><td style=\"text-align: right;\">  8.3835</td><td style=\"text-align: right;\">               14.54</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">            106.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1638360\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-00-14\n",
      "  done: false\n",
      "  episode_len_mean: 106.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000013\n",
      "  episode_reward_mean: 8.67090000000002\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16090\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4030587536948067\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012031574321534186\n",
      "          policy_loss: -0.03803053963042441\n",
      "          total_loss: 0.17230262680067904\n",
      "          vf_explained_var: 0.9697033166885376\n",
      "          vf_loss: 0.20972888540653956\n",
      "    num_agent_steps_sampled: 1638360\n",
      "    num_agent_steps_trained: 1638360\n",
      "    num_steps_sampled: 1638360\n",
      "    num_steps_trained: 1638360\n",
      "  iterations_since_restore: 820\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89705882352942\n",
      "    ram_util_percent: 31.238235294117644\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04427259656122935\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.10126714702441\n",
      "    mean_inference_ms: 2.4634687796065307\n",
      "    mean_raw_obs_processing_ms: 2.0666986839437937\n",
      "  time_since_restore: 22476.477548122406\n",
      "  time_this_iter_s: 23.8977153301239\n",
      "  time_total_s: 22476.477548122406\n",
      "  timers:\n",
      "    learn_throughput: 1164.434\n",
      "    learn_time_ms: 1715.855\n",
      "    load_throughput: 58374.497\n",
      "    load_time_ms: 34.227\n",
      "    sample_throughput: 72.664\n",
      "    sample_time_ms: 27496.556\n",
      "    update_time_ms: 9.132\n",
      "  timestamp: 1636452014\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1638360\n",
      "  training_iteration: 820\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   820</td><td style=\"text-align: right;\">         22476.5</td><td style=\"text-align: right;\">1638360</td><td style=\"text-align: right;\">  8.6709</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">            106.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1640358\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-00-47\n",
      "  done: false\n",
      "  episode_len_mean: 106.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000013\n",
      "  episode_reward_mean: 8.819900000000017\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16109\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3380953164327711\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011095698813231764\n",
      "          policy_loss: -0.025229258374089285\n",
      "          total_loss: 0.1524853133995618\n",
      "          vf_explained_var: 0.9764301776885986\n",
      "          vf_loss: 0.17759902656433127\n",
      "    num_agent_steps_sampled: 1640358\n",
      "    num_agent_steps_trained: 1640358\n",
      "    num_steps_sampled: 1640358\n",
      "    num_steps_trained: 1640358\n",
      "  iterations_since_restore: 821\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.02978723404256\n",
      "    ram_util_percent: 31.512765957446796\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442704794747725\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.102028005487792\n",
      "    mean_inference_ms: 2.4634500114694204\n",
      "    mean_raw_obs_processing_ms: 2.0707249659340956\n",
      "  time_since_restore: 22509.177185058594\n",
      "  time_this_iter_s: 32.699636936187744\n",
      "  time_total_s: 22509.177185058594\n",
      "  timers:\n",
      "    learn_throughput: 1164.74\n",
      "    learn_time_ms: 1715.405\n",
      "    load_throughput: 58045.252\n",
      "    load_time_ms: 34.421\n",
      "    sample_throughput: 71.524\n",
      "    sample_time_ms: 27934.808\n",
      "    update_time_ms: 8.541\n",
      "  timestamp: 1636452047\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1640358\n",
      "  training_iteration: 821\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   821</td><td style=\"text-align: right;\">         22509.2</td><td style=\"text-align: right;\">1640358</td><td style=\"text-align: right;\">  8.8199</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">            106.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1642356\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-01-12\n",
      "  done: false\n",
      "  episode_len_mean: 106.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000013\n",
      "  episode_reward_mean: 8.924200000000019\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16128\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3360841313997904\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009782747730820376\n",
      "          policy_loss: -0.09964706880217862\n",
      "          total_loss: 0.12381848088864769\n",
      "          vf_explained_var: 0.9667130708694458\n",
      "          vf_loss: 0.22492693488796553\n",
      "    num_agent_steps_sampled: 1642356\n",
      "    num_agent_steps_trained: 1642356\n",
      "    num_steps_sampled: 1642356\n",
      "    num_steps_trained: 1642356\n",
      "  iterations_since_restore: 822\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.6\n",
      "    ram_util_percent: 31.591428571428573\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425600669028937\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.103194056506837\n",
      "    mean_inference_ms: 2.4631976220023386\n",
      "    mean_raw_obs_processing_ms: 2.072636609246115\n",
      "  time_since_restore: 22534.11134171486\n",
      "  time_this_iter_s: 24.93415665626526\n",
      "  time_total_s: 22534.11134171486\n",
      "  timers:\n",
      "    learn_throughput: 1163.123\n",
      "    learn_time_ms: 1717.789\n",
      "    load_throughput: 58239.85\n",
      "    load_time_ms: 34.306\n",
      "    sample_throughput: 71.523\n",
      "    sample_time_ms: 27935.112\n",
      "    update_time_ms: 9.353\n",
      "  timestamp: 1636452072\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1642356\n",
      "  training_iteration: 822\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   822</td><td style=\"text-align: right;\">         22534.1</td><td style=\"text-align: right;\">1642356</td><td style=\"text-align: right;\">  8.9242</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">            106.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1644354\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-01-36\n",
      "  done: false\n",
      "  episode_len_mean: 104.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000013\n",
      "  episode_reward_mean: 9.018400000000018\n",
      "  episode_reward_min: -0.03\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16147\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3406386647905622\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007938331587774572\n",
      "          policy_loss: -0.08980019037567434\n",
      "          total_loss: 0.11221112718450882\n",
      "          vf_explained_var: 0.9744575023651123\n",
      "          vf_loss: 0.20576174055181798\n",
      "    num_agent_steps_sampled: 1644354\n",
      "    num_agent_steps_trained: 1644354\n",
      "    num_steps_sampled: 1644354\n",
      "    num_steps_trained: 1644354\n",
      "  iterations_since_restore: 823\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.66857142857143\n",
      "    ram_util_percent: 31.662857142857145\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425526730768442\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.10461104500574\n",
      "    mean_inference_ms: 2.463194329275772\n",
      "    mean_raw_obs_processing_ms: 2.072737157423434\n",
      "  time_since_restore: 22558.687523126602\n",
      "  time_this_iter_s: 24.576181411743164\n",
      "  time_total_s: 22558.687523126602\n",
      "  timers:\n",
      "    learn_throughput: 1162.789\n",
      "    learn_time_ms: 1718.283\n",
      "    load_throughput: 58260.459\n",
      "    load_time_ms: 34.294\n",
      "    sample_throughput: 71.485\n",
      "    sample_time_ms: 27949.92\n",
      "    update_time_ms: 8.814\n",
      "  timestamp: 1636452096\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1644354\n",
      "  training_iteration: 823\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   823</td><td style=\"text-align: right;\">         22558.7</td><td style=\"text-align: right;\">1644354</td><td style=\"text-align: right;\">  9.0184</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">               -0.03</td><td style=\"text-align: right;\">            104.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1646352\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-01-59\n",
      "  done: false\n",
      "  episode_len_mean: 107.05\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.630000000000013\n",
      "  episode_reward_mean: 9.09840000000002\n",
      "  episode_reward_min: 4.110000000000021\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16165\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3707582377252125\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009616539838880412\n",
      "          policy_loss: -0.03527739965135143\n",
      "          total_loss: 0.09608380156790926\n",
      "          vf_explained_var: 0.9774616956710815\n",
      "          vf_loss: 0.13337149424921899\n",
      "    num_agent_steps_sampled: 1646352\n",
      "    num_agent_steps_trained: 1646352\n",
      "    num_steps_sampled: 1646352\n",
      "    num_steps_trained: 1646352\n",
      "  iterations_since_restore: 824\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.328125\n",
      "    ram_util_percent: 31.681250000000002\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044244551915342926\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.106213266491586\n",
      "    mean_inference_ms: 2.4630465998985387\n",
      "    mean_raw_obs_processing_ms: 2.071123006099311\n",
      "  time_since_restore: 22580.997492313385\n",
      "  time_this_iter_s: 22.309969186782837\n",
      "  time_total_s: 22580.997492313385\n",
      "  timers:\n",
      "    learn_throughput: 1162.073\n",
      "    learn_time_ms: 1719.342\n",
      "    load_throughput: 58120.694\n",
      "    load_time_ms: 34.377\n",
      "    sample_throughput: 71.923\n",
      "    sample_time_ms: 27779.643\n",
      "    update_time_ms: 9.104\n",
      "  timestamp: 1636452119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1646352\n",
      "  training_iteration: 824\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   824</td><td style=\"text-align: right;\">           22581</td><td style=\"text-align: right;\">1646352</td><td style=\"text-align: right;\">  9.0984</td><td style=\"text-align: right;\">               14.63</td><td style=\"text-align: right;\">                4.11</td><td style=\"text-align: right;\">            107.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1648350\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-02-23\n",
      "  done: false\n",
      "  episode_len_mean: 106.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 9.077900000000017\n",
      "  episode_reward_min: 4.110000000000021\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16183\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.368929203919002\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009615148543530187\n",
      "          policy_loss: -0.029344881370308853\n",
      "          total_loss: 0.08621092056412072\n",
      "          vf_explained_var: 0.9853140115737915\n",
      "          vf_loss: 0.11754949946133864\n",
      "    num_agent_steps_sampled: 1648350\n",
      "    num_agent_steps_trained: 1648350\n",
      "    num_steps_sampled: 1648350\n",
      "    num_steps_trained: 1648350\n",
      "  iterations_since_restore: 825\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.77142857142856\n",
      "    ram_util_percent: 31.625714285714288\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044230646170413356\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.107493835155683\n",
      "    mean_inference_ms: 2.462820327409857\n",
      "    mean_raw_obs_processing_ms: 2.0695512153113573\n",
      "  time_since_restore: 22605.293540477753\n",
      "  time_this_iter_s: 24.296048164367676\n",
      "  time_total_s: 22605.293540477753\n",
      "  timers:\n",
      "    learn_throughput: 1162.219\n",
      "    learn_time_ms: 1719.125\n",
      "    load_throughput: 57965.635\n",
      "    load_time_ms: 34.469\n",
      "    sample_throughput: 71.642\n",
      "    sample_time_ms: 27888.622\n",
      "    update_time_ms: 9.337\n",
      "  timestamp: 1636452143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1648350\n",
      "  training_iteration: 825\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   825</td><td style=\"text-align: right;\">         22605.3</td><td style=\"text-align: right;\">1648350</td><td style=\"text-align: right;\">  9.0779</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                4.11</td><td style=\"text-align: right;\">            106.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1650348\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-02-47\n",
      "  done: false\n",
      "  episode_len_mean: 106.43\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 8.956400000000018\n",
      "  episode_reward_min: 4.110000000000021\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16203\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3772373750096276\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009125368828100614\n",
      "          policy_loss: -0.08224509181011291\n",
      "          total_loss: 0.06826940072434289\n",
      "          vf_explained_var: 0.9800993204116821\n",
      "          vf_loss: 0.15318702475300858\n",
      "    num_agent_steps_sampled: 1650348\n",
      "    num_agent_steps_trained: 1650348\n",
      "    num_steps_sampled: 1650348\n",
      "    num_steps_trained: 1650348\n",
      "  iterations_since_restore: 826\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.40571428571427\n",
      "    ram_util_percent: 31.59714285714286\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044241073920252255\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.10675935922297\n",
      "    mean_inference_ms: 2.46299993966299\n",
      "    mean_raw_obs_processing_ms: 2.067759902679928\n",
      "  time_since_restore: 22629.482256174088\n",
      "  time_this_iter_s: 24.18871569633484\n",
      "  time_total_s: 22629.482256174088\n",
      "  timers:\n",
      "    learn_throughput: 1159.832\n",
      "    learn_time_ms: 1722.664\n",
      "    load_throughput: 58007.926\n",
      "    load_time_ms: 34.444\n",
      "    sample_throughput: 71.941\n",
      "    sample_time_ms: 27772.866\n",
      "    update_time_ms: 9.197\n",
      "  timestamp: 1636452167\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1650348\n",
      "  training_iteration: 826\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   826</td><td style=\"text-align: right;\">         22629.5</td><td style=\"text-align: right;\">1650348</td><td style=\"text-align: right;\">  8.9564</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                4.11</td><td style=\"text-align: right;\">            106.43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1652346\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-03-11\n",
      "  done: false\n",
      "  episode_len_mean: 105.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000017\n",
      "  episode_reward_mean: 9.090600000000018\n",
      "  episode_reward_min: 4.05000000000002\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16221\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3724467379706247\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00824753387473213\n",
      "          policy_loss: -0.05807019674352237\n",
      "          total_loss: 0.05171900178704943\n",
      "          vf_explained_var: 0.9768297672271729\n",
      "          vf_loss: 0.11348159671539353\n",
      "    num_agent_steps_sampled: 1652346\n",
      "    num_agent_steps_trained: 1652346\n",
      "    num_steps_sampled: 1652346\n",
      "    num_steps_trained: 1652346\n",
      "  iterations_since_restore: 827\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.17878787878787\n",
      "    ram_util_percent: 31.581818181818175\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424050807800963\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.105374636224802\n",
      "    mean_inference_ms: 2.4630092638665095\n",
      "    mean_raw_obs_processing_ms: 2.066148685163798\n",
      "  time_since_restore: 22653.16283583641\n",
      "  time_this_iter_s: 23.680579662322998\n",
      "  time_total_s: 22653.16283583641\n",
      "  timers:\n",
      "    learn_throughput: 1160.143\n",
      "    learn_time_ms: 1722.202\n",
      "    load_throughput: 58238.434\n",
      "    load_time_ms: 34.307\n",
      "    sample_throughput: 80.838\n",
      "    sample_time_ms: 24716.187\n",
      "    update_time_ms: 9.517\n",
      "  timestamp: 1636452191\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1652346\n",
      "  training_iteration: 827\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   827</td><td style=\"text-align: right;\">         22653.2</td><td style=\"text-align: right;\">1652346</td><td style=\"text-align: right;\">  9.0906</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">                4.05</td><td style=\"text-align: right;\">            105.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1654344\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-03-36\n",
      "  done: false\n",
      "  episode_len_mean: 107.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.68910000000002\n",
      "  episode_reward_min: 2.8300000000000196\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16240\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3632143769945417\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009291575183977349\n",
      "          policy_loss: -0.042278051873048145\n",
      "          total_loss: 0.0967505992878051\n",
      "          vf_explained_var: 0.9800856709480286\n",
      "          vf_loss: 0.14135878394756998\n",
      "    num_agent_steps_sampled: 1654344\n",
      "    num_agent_steps_trained: 1654344\n",
      "    num_steps_sampled: 1654344\n",
      "    num_steps_trained: 1654344\n",
      "  iterations_since_restore: 828\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.74\n",
      "    ram_util_percent: 31.511428571428567\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044239228482061535\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.103475568039133\n",
      "    mean_inference_ms: 2.4630156174920557\n",
      "    mean_raw_obs_processing_ms: 2.0644252320833263\n",
      "  time_since_restore: 22677.70573282242\n",
      "  time_this_iter_s: 24.54289698600769\n",
      "  time_total_s: 22677.70573282242\n",
      "  timers:\n",
      "    learn_throughput: 1159.581\n",
      "    learn_time_ms: 1723.036\n",
      "    load_throughput: 58193.099\n",
      "    load_time_ms: 34.334\n",
      "    sample_throughput: 81.33\n",
      "    sample_time_ms: 24566.714\n",
      "    update_time_ms: 9.703\n",
      "  timestamp: 1636452216\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1654344\n",
      "  training_iteration: 828\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   828</td><td style=\"text-align: right;\">         22677.7</td><td style=\"text-align: right;\">1654344</td><td style=\"text-align: right;\">  8.6891</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                2.83</td><td style=\"text-align: right;\">            107.56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1656342\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-04-00\n",
      "  done: false\n",
      "  episode_len_mean: 107.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.670600000000018\n",
      "  episode_reward_min: 2.8300000000000196\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16258\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3415612998462858\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008779053022821464\n",
      "          policy_loss: -0.02115984729358128\n",
      "          total_loss: 0.10672806714262281\n",
      "          vf_explained_var: 0.9727094173431396\n",
      "          vf_loss: 0.13062493504867667\n",
      "    num_agent_steps_sampled: 1656342\n",
      "    num_agent_steps_trained: 1656342\n",
      "    num_steps_sampled: 1656342\n",
      "    num_steps_trained: 1656342\n",
      "  iterations_since_restore: 829\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.97428571428571\n",
      "    ram_util_percent: 31.48285714285713\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423853266435875\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.10186840697054\n",
      "    mean_inference_ms: 2.4630137083884542\n",
      "    mean_raw_obs_processing_ms: 2.0627952422697886\n",
      "  time_since_restore: 22702.084839344025\n",
      "  time_this_iter_s: 24.379106521606445\n",
      "  time_total_s: 22702.084839344025\n",
      "  timers:\n",
      "    learn_throughput: 1159.812\n",
      "    learn_time_ms: 1722.693\n",
      "    load_throughput: 58409.202\n",
      "    load_time_ms: 34.207\n",
      "    sample_throughput: 86.211\n",
      "    sample_time_ms: 23175.684\n",
      "    update_time_ms: 9.072\n",
      "  timestamp: 1636452240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1656342\n",
      "  training_iteration: 829\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   829</td><td style=\"text-align: right;\">         22702.1</td><td style=\"text-align: right;\">1656342</td><td style=\"text-align: right;\">  8.6706</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                2.83</td><td style=\"text-align: right;\">            107.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1658340\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-04-24\n",
      "  done: false\n",
      "  episode_len_mean: 106.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.758600000000019\n",
      "  episode_reward_min: 2.8300000000000196\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16278\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4006566950253079\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009877408230199844\n",
      "          policy_loss: -0.038792249666793004\n",
      "          total_loss: 0.1013863057785091\n",
      "          vf_explained_var: 0.9739933609962463\n",
      "          vf_loss: 0.142170520996054\n",
      "    num_agent_steps_sampled: 1658340\n",
      "    num_agent_steps_trained: 1658340\n",
      "    num_steps_sampled: 1658340\n",
      "    num_steps_trained: 1658340\n",
      "  iterations_since_restore: 830\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66857142857141\n",
      "    ram_util_percent: 31.437142857142856\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423740568025186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.10037546224713\n",
      "    mean_inference_ms: 2.4630163484255116\n",
      "    mean_raw_obs_processing_ms: 2.0610093864791224\n",
      "  time_since_restore: 22726.58469891548\n",
      "  time_this_iter_s: 24.49985957145691\n",
      "  time_total_s: 22726.58469891548\n",
      "  timers:\n",
      "    learn_throughput: 1161.694\n",
      "    learn_time_ms: 1719.903\n",
      "    load_throughput: 58484.9\n",
      "    load_time_ms: 34.163\n",
      "    sample_throughput: 85.977\n",
      "    sample_time_ms: 23238.904\n",
      "    update_time_ms: 8.795\n",
      "  timestamp: 1636452264\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1658340\n",
      "  training_iteration: 830\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   830</td><td style=\"text-align: right;\">         22726.6</td><td style=\"text-align: right;\">1658340</td><td style=\"text-align: right;\">  8.7586</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                2.83</td><td style=\"text-align: right;\">            106.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1660338\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-04-50\n",
      "  done: false\n",
      "  episode_len_mean: 106.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.769800000000018\n",
      "  episode_reward_min: 2.8300000000000196\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16296\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3746763649440947\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016263930339060175\n",
      "          policy_loss: -0.013409013212436722\n",
      "          total_loss: 0.2059663671822775\n",
      "          vf_explained_var: 0.9689200520515442\n",
      "          vf_loss: 0.21333915475933324\n",
      "    num_agent_steps_sampled: 1660338\n",
      "    num_agent_steps_trained: 1660338\n",
      "    num_steps_sampled: 1660338\n",
      "    num_steps_trained: 1660338\n",
      "  iterations_since_restore: 831\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.89444444444445\n",
      "    ram_util_percent: 31.46944444444445\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044222531510407\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.098862063943784\n",
      "    mean_inference_ms: 2.462781644748061\n",
      "    mean_raw_obs_processing_ms: 2.059439007026407\n",
      "  time_since_restore: 22751.576971769333\n",
      "  time_this_iter_s: 24.99227285385132\n",
      "  time_total_s: 22751.576971769333\n",
      "  timers:\n",
      "    learn_throughput: 1160.833\n",
      "    learn_time_ms: 1721.178\n",
      "    load_throughput: 58937.89\n",
      "    load_time_ms: 33.9\n",
      "    sample_throughput: 88.93\n",
      "    sample_time_ms: 22467.084\n",
      "    update_time_ms: 8.727\n",
      "  timestamp: 1636452290\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1660338\n",
      "  training_iteration: 831\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   831</td><td style=\"text-align: right;\">         22751.6</td><td style=\"text-align: right;\">1660338</td><td style=\"text-align: right;\">  8.7698</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                2.83</td><td style=\"text-align: right;\">            106.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1662336\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-05-14\n",
      "  done: false\n",
      "  episode_len_mean: 106.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.680000000000014\n",
      "  episode_reward_mean: 8.841400000000018\n",
      "  episode_reward_min: 2.6200000000000205\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16314\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.394651528767177\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009081601746839361\n",
      "          policy_loss: -0.03400879385215896\n",
      "          total_loss: 0.11714513704535506\n",
      "          vf_explained_var: 0.9713095426559448\n",
      "          vf_loss: 0.15405384195702418\n",
      "    num_agent_steps_sampled: 1662336\n",
      "    num_agent_steps_trained: 1662336\n",
      "    num_steps_sampled: 1662336\n",
      "    num_steps_trained: 1662336\n",
      "  iterations_since_restore: 832\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28529411764707\n",
      "    ram_util_percent: 31.414705882352937\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422560079930718\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.098129051855643\n",
      "    mean_inference_ms: 2.462864663919693\n",
      "    mean_raw_obs_processing_ms: 2.057772387701994\n",
      "  time_since_restore: 22775.52744603157\n",
      "  time_this_iter_s: 23.95047426223755\n",
      "  time_total_s: 22775.52744603157\n",
      "  timers:\n",
      "    learn_throughput: 1162.283\n",
      "    learn_time_ms: 1719.03\n",
      "    load_throughput: 58838.906\n",
      "    load_time_ms: 33.957\n",
      "    sample_throughput: 89.312\n",
      "    sample_time_ms: 22371.115\n",
      "    update_time_ms: 8.219\n",
      "  timestamp: 1636452314\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1662336\n",
      "  training_iteration: 832\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   832</td><td style=\"text-align: right;\">         22775.5</td><td style=\"text-align: right;\">1662336</td><td style=\"text-align: right;\">  8.8414</td><td style=\"text-align: right;\">               14.68</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">            106.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1664334\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-05-39\n",
      "  done: false\n",
      "  episode_len_mean: 107.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.570000000000014\n",
      "  episode_reward_mean: 8.635600000000016\n",
      "  episode_reward_min: 2.6200000000000205\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16334\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4042484663781665\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01006137814812107\n",
      "          policy_loss: -0.011300418384018398\n",
      "          total_loss: 0.199104731804913\n",
      "          vf_explained_var: 0.9776636958122253\n",
      "          vf_loss: 0.2122092560288452\n",
      "    num_agent_steps_sampled: 1664334\n",
      "    num_agent_steps_trained: 1664334\n",
      "    num_steps_sampled: 1664334\n",
      "    num_steps_trained: 1664334\n",
      "  iterations_since_restore: 833\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.10277777777777\n",
      "    ram_util_percent: 31.41944444444444\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423898839107318\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.097307382509516\n",
      "    mean_inference_ms: 2.4631060898823027\n",
      "    mean_raw_obs_processing_ms: 2.055965804451462\n",
      "  time_since_restore: 22800.514321804047\n",
      "  time_this_iter_s: 24.986875772476196\n",
      "  time_total_s: 22800.514321804047\n",
      "  timers:\n",
      "    learn_throughput: 1162.434\n",
      "    learn_time_ms: 1718.807\n",
      "    load_throughput: 58904.623\n",
      "    load_time_ms: 33.919\n",
      "    sample_throughput: 89.143\n",
      "    sample_time_ms: 22413.358\n",
      "    update_time_ms: 7.451\n",
      "  timestamp: 1636452339\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1664334\n",
      "  training_iteration: 833\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   833</td><td style=\"text-align: right;\">         22800.5</td><td style=\"text-align: right;\">1664334</td><td style=\"text-align: right;\">  8.6356</td><td style=\"text-align: right;\">               14.57</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">             107.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1666332\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-06-04\n",
      "  done: false\n",
      "  episode_len_mean: 105.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000013\n",
      "  episode_reward_mean: 9.240700000000018\n",
      "  episode_reward_min: 2.6200000000000205\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16352\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3501358304704938\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009299811601631684\n",
      "          policy_loss: -0.004321863111995516\n",
      "          total_loss: 0.16800050582914125\n",
      "          vf_explained_var: 0.9758537411689758\n",
      "          vf_loss: 0.17451169932527202\n",
      "    num_agent_steps_sampled: 1666332\n",
      "    num_agent_steps_trained: 1666332\n",
      "    num_steps_sampled: 1666332\n",
      "    num_steps_trained: 1666332\n",
      "  iterations_since_restore: 834\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.11388888888888\n",
      "    ram_util_percent: 31.38611111111112\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423809757021748\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.096927983699672\n",
      "    mean_inference_ms: 2.4631085726303015\n",
      "    mean_raw_obs_processing_ms: 2.0543660631546463\n",
      "  time_since_restore: 22826.23525094986\n",
      "  time_this_iter_s: 25.72092914581299\n",
      "  time_total_s: 22826.23525094986\n",
      "  timers:\n",
      "    learn_throughput: 1162.057\n",
      "    learn_time_ms: 1719.365\n",
      "    load_throughput: 59179.373\n",
      "    load_time_ms: 33.762\n",
      "    sample_throughput: 87.809\n",
      "    sample_time_ms: 22753.829\n",
      "    update_time_ms: 7.649\n",
      "  timestamp: 1636452364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1666332\n",
      "  training_iteration: 834\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   834</td><td style=\"text-align: right;\">         22826.2</td><td style=\"text-align: right;\">1666332</td><td style=\"text-align: right;\">  9.2407</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">            105.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1668330\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-06-30\n",
      "  done: false\n",
      "  episode_len_mean: 104.42\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000013\n",
      "  episode_reward_mean: 9.26460000000002\n",
      "  episode_reward_min: 2.6200000000000205\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 16373\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2756472661381677\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012020708945195998\n",
      "          policy_loss: -0.01118973804016908\n",
      "          total_loss: 0.2139585891117652\n",
      "          vf_explained_var: 0.973414957523346\n",
      "          vf_loss: 0.223283147936066\n",
      "    num_agent_steps_sampled: 1668330\n",
      "    num_agent_steps_trained: 1668330\n",
      "    num_steps_sampled: 1668330\n",
      "    num_steps_trained: 1668330\n",
      "  iterations_since_restore: 835\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.46216216216216\n",
      "    ram_util_percent: 31.310810810810818\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425062318241684\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.09682335694065\n",
      "    mean_inference_ms: 2.4633578097255113\n",
      "    mean_raw_obs_processing_ms: 2.0525126837839\n",
      "  time_since_restore: 22851.538636684418\n",
      "  time_this_iter_s: 25.303385734558105\n",
      "  time_total_s: 22851.538636684418\n",
      "  timers:\n",
      "    learn_throughput: 1161.756\n",
      "    learn_time_ms: 1719.81\n",
      "    load_throughput: 59289.782\n",
      "    load_time_ms: 33.699\n",
      "    sample_throughput: 87.425\n",
      "    sample_time_ms: 22853.942\n",
      "    update_time_ms: 7.931\n",
      "  timestamp: 1636452390\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1668330\n",
      "  training_iteration: 835\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   835</td><td style=\"text-align: right;\">         22851.5</td><td style=\"text-align: right;\">1668330</td><td style=\"text-align: right;\">  9.2646</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">                2.62</td><td style=\"text-align: right;\">            104.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1670328\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-07-12\n",
      "  done: false\n",
      "  episode_len_mean: 102.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000013\n",
      "  episode_reward_mean: 9.146200000000016\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16393\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4098585946219309\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008660736867762777\n",
      "          policy_loss: -0.04289105491978781\n",
      "          total_loss: 0.2467676018142984\n",
      "          vf_explained_var: 0.9542752504348755\n",
      "          vf_loss: 0.29322256452980494\n",
      "    num_agent_steps_sampled: 1670328\n",
      "    num_agent_steps_trained: 1670328\n",
      "    num_steps_sampled: 1670328\n",
      "    num_steps_trained: 1670328\n",
      "  iterations_since_restore: 836\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.35000000000001\n",
      "    ram_util_percent: 31.18666666666667\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442526338871956\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.0973818074881\n",
      "    mean_inference_ms: 2.463435866702616\n",
      "    mean_raw_obs_processing_ms: 2.054993098962001\n",
      "  time_since_restore: 22893.985816955566\n",
      "  time_this_iter_s: 42.44718027114868\n",
      "  time_total_s: 22893.985816955566\n",
      "  timers:\n",
      "    learn_throughput: 1163.203\n",
      "    learn_time_ms: 1717.671\n",
      "    load_throughput: 59096.784\n",
      "    load_time_ms: 33.809\n",
      "    sample_throughput: 80.952\n",
      "    sample_time_ms: 24681.155\n",
      "    update_time_ms: 8.649\n",
      "  timestamp: 1636452432\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1670328\n",
      "  training_iteration: 836\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   836</td><td style=\"text-align: right;\">           22894</td><td style=\"text-align: right;\">1670328</td><td style=\"text-align: right;\">  9.1462</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            102.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1672326\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-07-37\n",
      "  done: false\n",
      "  episode_len_mean: 102.34\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000013\n",
      "  episode_reward_mean: 9.168100000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16413\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3441459547905694\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00955839103554329\n",
      "          policy_loss: -0.05888264518053759\n",
      "          total_loss: 0.04861881514745099\n",
      "          vf_explained_var: 0.9837036728858948\n",
      "          vf_loss: 0.1093163611633437\n",
      "    num_agent_steps_sampled: 1672326\n",
      "    num_agent_steps_trained: 1672326\n",
      "    num_steps_sampled: 1672326\n",
      "    num_steps_trained: 1672326\n",
      "  iterations_since_restore: 837\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.72777777777777\n",
      "    ram_util_percent: 31.275000000000002\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04425486783652479\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.098291559040963\n",
      "    mean_inference_ms: 2.463516477201806\n",
      "    mean_raw_obs_processing_ms: 2.057532739123778\n",
      "  time_since_restore: 22919.222110271454\n",
      "  time_this_iter_s: 25.23629331588745\n",
      "  time_total_s: 22919.222110271454\n",
      "  timers:\n",
      "    learn_throughput: 1162.865\n",
      "    learn_time_ms: 1718.17\n",
      "    load_throughput: 59080.618\n",
      "    load_time_ms: 33.818\n",
      "    sample_throughput: 80.446\n",
      "    sample_time_ms: 24836.607\n",
      "    update_time_ms: 8.368\n",
      "  timestamp: 1636452457\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1672326\n",
      "  training_iteration: 837\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   837</td><td style=\"text-align: right;\">         22919.2</td><td style=\"text-align: right;\">1672326</td><td style=\"text-align: right;\">  9.1681</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            102.34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1674324\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-08-16\n",
      "  done: false\n",
      "  episode_len_mean: 101.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.650000000000013\n",
      "  episode_reward_mean: 9.335000000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16432\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4103782818430946\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007974149470693014\n",
      "          policy_loss: -0.04742362820321605\n",
      "          total_loss: 0.13502751323616222\n",
      "          vf_explained_var: 0.9604730010032654\n",
      "          vf_loss: 0.18685539210037816\n",
      "    num_agent_steps_sampled: 1674324\n",
      "    num_agent_steps_trained: 1674324\n",
      "    num_steps_sampled: 1674324\n",
      "    num_steps_trained: 1674324\n",
      "  iterations_since_restore: 838\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.13750000000002\n",
      "    ram_util_percent: 31.34642857142857\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424948900574135\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.097746553509587\n",
      "    mean_inference_ms: 2.463420204713969\n",
      "    mean_raw_obs_processing_ms: 2.061688199051016\n",
      "  time_since_restore: 22958.216661691666\n",
      "  time_this_iter_s: 38.99455142021179\n",
      "  time_total_s: 22958.216661691666\n",
      "  timers:\n",
      "    learn_throughput: 1161.172\n",
      "    learn_time_ms: 1720.675\n",
      "    load_throughput: 59531.288\n",
      "    load_time_ms: 33.562\n",
      "    sample_throughput: 76.031\n",
      "    sample_time_ms: 26278.736\n",
      "    update_time_ms: 9.304\n",
      "  timestamp: 1636452496\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1674324\n",
      "  training_iteration: 838\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   838</td><td style=\"text-align: right;\">         22958.2</td><td style=\"text-align: right;\">1674324</td><td style=\"text-align: right;\">   9.335</td><td style=\"text-align: right;\">               14.65</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            101.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1676322\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-08-41\n",
      "  done: false\n",
      "  episode_len_mean: 101.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000013\n",
      "  episode_reward_mean: 8.849000000000016\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16451\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4456986966587249\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010911552611077843\n",
      "          policy_loss: -0.028392475630555834\n",
      "          total_loss: 0.1090450997863497\n",
      "          vf_explained_var: 0.977282702922821\n",
      "          vf_loss: 0.13862205733145985\n",
      "    num_agent_steps_sampled: 1676322\n",
      "    num_agent_steps_trained: 1676322\n",
      "    num_steps_sampled: 1676322\n",
      "    num_steps_trained: 1676322\n",
      "  iterations_since_restore: 839\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.03428571428572\n",
      "    ram_util_percent: 31.397142857142853\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424829254180934\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.097315712512273\n",
      "    mean_inference_ms: 2.463405901518285\n",
      "    mean_raw_obs_processing_ms: 2.065807199969264\n",
      "  time_since_restore: 22982.61608028412\n",
      "  time_this_iter_s: 24.399418592453003\n",
      "  time_total_s: 22982.61608028412\n",
      "  timers:\n",
      "    learn_throughput: 1160.416\n",
      "    learn_time_ms: 1721.796\n",
      "    load_throughput: 59621.459\n",
      "    load_time_ms: 33.511\n",
      "    sample_throughput: 76.03\n",
      "    sample_time_ms: 26279.164\n",
      "    update_time_ms: 10.033\n",
      "  timestamp: 1636452521\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1676322\n",
      "  training_iteration: 839\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   839</td><td style=\"text-align: right;\">         22982.6</td><td style=\"text-align: right;\">1676322</td><td style=\"text-align: right;\">   8.849</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            101.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1678320\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-09-05\n",
      "  done: false\n",
      "  episode_len_mean: 102.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000013\n",
      "  episode_reward_mean: 8.784000000000017\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16469\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3788982871032895\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008223874477498632\n",
      "          policy_loss: -0.11332817279866764\n",
      "          total_loss: -0.021942010796850635\n",
      "          vf_explained_var: 0.9827289581298828\n",
      "          vf_loss: 0.09517185335003195\n",
      "    num_agent_steps_sampled: 1678320\n",
      "    num_agent_steps_trained: 1678320\n",
      "    num_steps_sampled: 1678320\n",
      "    num_steps_trained: 1678320\n",
      "  iterations_since_restore: 840\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.15882352941175\n",
      "    ram_util_percent: 31.44411764705882\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422923487875648\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.09595949282368\n",
      "    mean_inference_ms: 2.4630650948524284\n",
      "    mean_raw_obs_processing_ms: 2.069760493828258\n",
      "  time_since_restore: 23006.724945306778\n",
      "  time_this_iter_s: 24.1088650226593\n",
      "  time_total_s: 23006.724945306778\n",
      "  timers:\n",
      "    learn_throughput: 1159.758\n",
      "    learn_time_ms: 1722.773\n",
      "    load_throughput: 59429.038\n",
      "    load_time_ms: 33.62\n",
      "    sample_throughput: 76.148\n",
      "    sample_time_ms: 26238.539\n",
      "    update_time_ms: 10.366\n",
      "  timestamp: 1636452545\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1678320\n",
      "  training_iteration: 840\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   840</td><td style=\"text-align: right;\">         23006.7</td><td style=\"text-align: right;\">1678320</td><td style=\"text-align: right;\">   8.784</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            102.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1680318\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-09-30\n",
      "  done: false\n",
      "  episode_len_mean: 104.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000013\n",
      "  episode_reward_mean: 8.98130000000002\n",
      "  episode_reward_min: -0.07\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16488\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4077376456487747\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008910629809858607\n",
      "          policy_loss: -0.01629850541551908\n",
      "          total_loss: 0.07495114328783183\n",
      "          vf_explained_var: 0.9845319390296936\n",
      "          vf_loss: 0.09448838697835094\n",
      "    num_agent_steps_sampled: 1680318\n",
      "    num_agent_steps_trained: 1680318\n",
      "    num_steps_sampled: 1680318\n",
      "    num_steps_trained: 1680318\n",
      "  iterations_since_restore: 841\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.88888888888889\n",
      "    ram_util_percent: 31.505555555555546\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423823275497996\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.094500207264254\n",
      "    mean_inference_ms: 2.4632100565011794\n",
      "    mean_raw_obs_processing_ms: 2.071091070818673\n",
      "  time_since_restore: 23031.48661017418\n",
      "  time_this_iter_s: 24.761664867401123\n",
      "  time_total_s: 23031.48661017418\n",
      "  timers:\n",
      "    learn_throughput: 1159.185\n",
      "    learn_time_ms: 1723.625\n",
      "    load_throughput: 58814.913\n",
      "    load_time_ms: 33.971\n",
      "    sample_throughput: 76.217\n",
      "    sample_time_ms: 26214.679\n",
      "    update_time_ms: 9.988\n",
      "  timestamp: 1636452570\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1680318\n",
      "  training_iteration: 841\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   841</td><td style=\"text-align: right;\">         23031.5</td><td style=\"text-align: right;\">1680318</td><td style=\"text-align: right;\">  8.9813</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.07</td><td style=\"text-align: right;\">            104.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1682316\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-09-54\n",
      "  done: false\n",
      "  episode_len_mean: 105.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000013\n",
      "  episode_reward_mean: 9.16090000000002\n",
      "  episode_reward_min: -0.04\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16507\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.472584499063946\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008903728324110951\n",
      "          policy_loss: -0.07377894133041125\n",
      "          total_loss: -0.0028079715036299258\n",
      "          vf_explained_var: 0.9857209920883179\n",
      "          vf_loss: 0.07486656946795327\n",
      "    num_agent_steps_sampled: 1682316\n",
      "    num_agent_steps_trained: 1682316\n",
      "    num_steps_sampled: 1682316\n",
      "    num_steps_trained: 1682316\n",
      "  iterations_since_restore: 842\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.23142857142858\n",
      "    ram_util_percent: 31.625714285714288\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044233245389882825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.092834997991176\n",
      "    mean_inference_ms: 2.463110754793846\n",
      "    mean_raw_obs_processing_ms: 2.0712326567377066\n",
      "  time_since_restore: 23055.962443351746\n",
      "  time_this_iter_s: 24.47583317756653\n",
      "  time_total_s: 23055.962443351746\n",
      "  timers:\n",
      "    learn_throughput: 1158.31\n",
      "    learn_time_ms: 1724.927\n",
      "    load_throughput: 58564.313\n",
      "    load_time_ms: 34.116\n",
      "    sample_throughput: 76.069\n",
      "    sample_time_ms: 26265.754\n",
      "    update_time_ms: 9.942\n",
      "  timestamp: 1636452594\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1682316\n",
      "  training_iteration: 842\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   842</td><td style=\"text-align: right;\">           23056</td><td style=\"text-align: right;\">1682316</td><td style=\"text-align: right;\">  9.1609</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">               -0.04</td><td style=\"text-align: right;\">            105.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1684314\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-10-19\n",
      "  done: false\n",
      "  episode_len_mean: 106.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.610000000000015\n",
      "  episode_reward_mean: 9.07400000000002\n",
      "  episode_reward_min: 2.750000000000016\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16525\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3711709811573938\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008819318886048238\n",
      "          policy_loss: -0.049830750375986096\n",
      "          total_loss: 0.10626755042799882\n",
      "          vf_explained_var: 0.9794594645500183\n",
      "          vf_loss: 0.1590824392402456\n",
      "    num_agent_steps_sampled: 1684314\n",
      "    num_agent_steps_trained: 1684314\n",
      "    num_steps_sampled: 1684314\n",
      "    num_steps_trained: 1684314\n",
      "  iterations_since_restore: 843\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.86764705882354\n",
      "    ram_util_percent: 31.635294117647064\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044221846634041724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.09201244161378\n",
      "    mean_inference_ms: 2.462947586930487\n",
      "    mean_raw_obs_processing_ms: 2.0696295542050014\n",
      "  time_since_restore: 23080.23042678833\n",
      "  time_this_iter_s: 24.267983436584473\n",
      "  time_total_s: 23080.23042678833\n",
      "  timers:\n",
      "    learn_throughput: 1159.048\n",
      "    learn_time_ms: 1723.828\n",
      "    load_throughput: 58343.163\n",
      "    load_time_ms: 34.246\n",
      "    sample_throughput: 76.277\n",
      "    sample_time_ms: 26193.937\n",
      "    update_time_ms: 10.74\n",
      "  timestamp: 1636452619\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1684314\n",
      "  training_iteration: 843\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   843</td><td style=\"text-align: right;\">         23080.2</td><td style=\"text-align: right;\">1684314</td><td style=\"text-align: right;\">   9.074</td><td style=\"text-align: right;\">               14.61</td><td style=\"text-align: right;\">                2.75</td><td style=\"text-align: right;\">            106.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1686312\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-10-43\n",
      "  done: false\n",
      "  episode_len_mean: 106.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.610000000000015\n",
      "  episode_reward_mean: 9.206400000000018\n",
      "  episode_reward_min: 3.070000000000011\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16543\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4040573761576698\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.006997465678371401\n",
      "          policy_loss: -0.0648050725105263\n",
      "          total_loss: -0.004654657148889133\n",
      "          vf_explained_var: 0.988818883895874\n",
      "          vf_loss: 0.06567946935870818\n",
      "    num_agent_steps_sampled: 1686312\n",
      "    num_agent_steps_trained: 1686312\n",
      "    num_steps_sampled: 1686312\n",
      "    num_steps_trained: 1686312\n",
      "  iterations_since_restore: 844\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.43142857142855\n",
      "    ram_util_percent: 31.608571428571427\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422125570390694\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.09108968308984\n",
      "    mean_inference_ms: 2.4629379491451955\n",
      "    mean_raw_obs_processing_ms: 2.0680142159787724\n",
      "  time_since_restore: 23104.854885578156\n",
      "  time_this_iter_s: 24.62445878982544\n",
      "  time_total_s: 23104.854885578156\n",
      "  timers:\n",
      "    learn_throughput: 1159.738\n",
      "    learn_time_ms: 1722.803\n",
      "    load_throughput: 58169.953\n",
      "    load_time_ms: 34.348\n",
      "    sample_throughput: 76.598\n",
      "    sample_time_ms: 26084.384\n",
      "    update_time_ms: 11.381\n",
      "  timestamp: 1636452643\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1686312\n",
      "  training_iteration: 844\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   844</td><td style=\"text-align: right;\">         23104.9</td><td style=\"text-align: right;\">1686312</td><td style=\"text-align: right;\">  9.2064</td><td style=\"text-align: right;\">               14.61</td><td style=\"text-align: right;\">                3.07</td><td style=\"text-align: right;\">             106.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1688310\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-11-07\n",
      "  done: false\n",
      "  episode_len_mean: 106.44\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.610000000000015\n",
      "  episode_reward_mean: 9.212600000000016\n",
      "  episode_reward_min: 3.070000000000011\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16563\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3439697481337047\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007581661524566216\n",
      "          policy_loss: -0.08364584423779022\n",
      "          total_loss: -0.04055590512497084\n",
      "          vf_explained_var: 0.9936171770095825\n",
      "          vf_loss: 0.047307516643334005\n",
      "    num_agent_steps_sampled: 1688310\n",
      "    num_agent_steps_trained: 1688310\n",
      "    num_steps_sampled: 1688310\n",
      "    num_steps_trained: 1688310\n",
      "  iterations_since_restore: 845\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.0457142857143\n",
      "    ram_util_percent: 31.594285714285718\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423041585036848\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.089652819793937\n",
      "    mean_inference_ms: 2.4630913397249325\n",
      "    mean_raw_obs_processing_ms: 2.066229689135609\n",
      "  time_since_restore: 23129.024116277695\n",
      "  time_this_iter_s: 24.169230699539185\n",
      "  time_total_s: 23129.024116277695\n",
      "  timers:\n",
      "    learn_throughput: 1160.493\n",
      "    learn_time_ms: 1721.682\n",
      "    load_throughput: 58012.463\n",
      "    load_time_ms: 34.441\n",
      "    sample_throughput: 76.929\n",
      "    sample_time_ms: 25972.066\n",
      "    update_time_ms: 11.436\n",
      "  timestamp: 1636452667\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1688310\n",
      "  training_iteration: 845\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   845</td><td style=\"text-align: right;\">           23129</td><td style=\"text-align: right;\">1688310</td><td style=\"text-align: right;\">  9.2126</td><td style=\"text-align: right;\">               14.61</td><td style=\"text-align: right;\">                3.07</td><td style=\"text-align: right;\">            106.44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1690308\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-11-32\n",
      "  done: false\n",
      "  episode_len_mean: 105.89\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000012\n",
      "  episode_reward_mean: 9.272100000000018\n",
      "  episode_reward_min: 4.34000000000002\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16583\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.351705545470828\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010064854557534043\n",
      "          policy_loss: -0.026600954592937515\n",
      "          total_loss: 0.0970964405863058\n",
      "          vf_explained_var: 0.9749687314033508\n",
      "          vf_loss: 0.12497184480584803\n",
      "    num_agent_steps_sampled: 1690308\n",
      "    num_agent_steps_trained: 1690308\n",
      "    num_steps_sampled: 1690308\n",
      "    num_steps_trained: 1690308\n",
      "  iterations_since_restore: 846\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.25714285714285\n",
      "    ram_util_percent: 31.55999999999999\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04421877237756142\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.088972557535406\n",
      "    mean_inference_ms: 2.4629197501452595\n",
      "    mean_raw_obs_processing_ms: 2.064480772688746\n",
      "  time_since_restore: 23153.436172246933\n",
      "  time_this_iter_s: 24.41205596923828\n",
      "  time_total_s: 23153.436172246933\n",
      "  timers:\n",
      "    learn_throughput: 1160.317\n",
      "    learn_time_ms: 1721.943\n",
      "    load_throughput: 58133.354\n",
      "    load_time_ms: 34.369\n",
      "    sample_throughput: 82.668\n",
      "    sample_time_ms: 24168.989\n",
      "    update_time_ms: 10.683\n",
      "  timestamp: 1636452692\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1690308\n",
      "  training_iteration: 846\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   846</td><td style=\"text-align: right;\">         23153.4</td><td style=\"text-align: right;\">1690308</td><td style=\"text-align: right;\">  9.2721</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">                4.34</td><td style=\"text-align: right;\">            105.89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1692306\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-11-55\n",
      "  done: false\n",
      "  episode_len_mean: 105.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000012\n",
      "  episode_reward_mean: 8.97620000000002\n",
      "  episode_reward_min: 2.9900000000000153\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16601\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3977924965676807\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010342318253836712\n",
      "          policy_loss: -0.0486785406158084\n",
      "          total_loss: 0.08439511097967625\n",
      "          vf_explained_var: 0.9745340943336487\n",
      "          vf_loss: 0.13447147150124822\n",
      "    num_agent_steps_sampled: 1692306\n",
      "    num_agent_steps_trained: 1692306\n",
      "    num_steps_sampled: 1692306\n",
      "    num_steps_trained: 1692306\n",
      "  iterations_since_restore: 847\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.20606060606062\n",
      "    ram_util_percent: 31.548484848484847\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044217598356067374\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.087555857401394\n",
      "    mean_inference_ms: 2.4628998738546515\n",
      "    mean_raw_obs_processing_ms: 2.0629129885124917\n",
      "  time_since_restore: 23176.595039844513\n",
      "  time_this_iter_s: 23.158867597579956\n",
      "  time_total_s: 23176.595039844513\n",
      "  timers:\n",
      "    learn_throughput: 1160.392\n",
      "    learn_time_ms: 1721.832\n",
      "    load_throughput: 58239.526\n",
      "    load_time_ms: 34.307\n",
      "    sample_throughput: 83.383\n",
      "    sample_time_ms: 23961.647\n",
      "    update_time_ms: 10.433\n",
      "  timestamp: 1636452715\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1692306\n",
      "  training_iteration: 847\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   847</td><td style=\"text-align: right;\">         23176.6</td><td style=\"text-align: right;\">1692306</td><td style=\"text-align: right;\">  8.9762</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">                2.99</td><td style=\"text-align: right;\">             105.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1694304\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-12-19\n",
      "  done: false\n",
      "  episode_len_mean: 105.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000012\n",
      "  episode_reward_mean: 8.805100000000017\n",
      "  episode_reward_min: 2.840000000000019\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16620\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4341133185795376\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011286200059099406\n",
      "          policy_loss: -0.06952212587708519\n",
      "          total_loss: 0.03474110526343187\n",
      "          vf_explained_var: 0.9792494773864746\n",
      "          vf_loss: 0.10487614880715097\n",
      "    num_agent_steps_sampled: 1694304\n",
      "    num_agent_steps_trained: 1694304\n",
      "    num_steps_sampled: 1694304\n",
      "    num_steps_trained: 1694304\n",
      "  iterations_since_restore: 848\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.33142857142857\n",
      "    ram_util_percent: 31.51428571428571\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044219145403794416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.08648499350913\n",
      "    mean_inference_ms: 2.462958007659657\n",
      "    mean_raw_obs_processing_ms: 2.061200092505995\n",
      "  time_since_restore: 23200.913556337357\n",
      "  time_this_iter_s: 24.318516492843628\n",
      "  time_total_s: 23200.913556337357\n",
      "  timers:\n",
      "    learn_throughput: 1161.853\n",
      "    learn_time_ms: 1719.667\n",
      "    load_throughput: 58148.117\n",
      "    load_time_ms: 34.361\n",
      "    sample_throughput: 88.811\n",
      "    sample_time_ms: 22497.104\n",
      "    update_time_ms: 9.507\n",
      "  timestamp: 1636452739\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1694304\n",
      "  training_iteration: 848\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   848</td><td style=\"text-align: right;\">         23200.9</td><td style=\"text-align: right;\">1694304</td><td style=\"text-align: right;\">  8.8051</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">                2.84</td><td style=\"text-align: right;\">            105.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1696302\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-12-44\n",
      "  done: false\n",
      "  episode_len_mean: 104.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000012\n",
      "  episode_reward_mean: 8.719400000000018\n",
      "  episode_reward_min: 2.840000000000019\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16639\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3621345957120259\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010058779042171697\n",
      "          policy_loss: -0.07764048175442786\n",
      "          total_loss: 0.04131183133771022\n",
      "          vf_explained_var: 0.9766743779182434\n",
      "          vf_loss: 0.12033844313451222\n",
      "    num_agent_steps_sampled: 1696302\n",
      "    num_agent_steps_trained: 1696302\n",
      "    num_steps_sampled: 1696302\n",
      "    num_steps_trained: 1696302\n",
      "  iterations_since_restore: 849\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.22571428571429\n",
      "    ram_util_percent: 31.497142857142848\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423112661460451\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.085058558205127\n",
      "    mean_inference_ms: 2.4631822668816783\n",
      "    mean_raw_obs_processing_ms: 2.0595209067662337\n",
      "  time_since_restore: 23225.654136180878\n",
      "  time_this_iter_s: 24.740579843521118\n",
      "  time_total_s: 23225.654136180878\n",
      "  timers:\n",
      "    learn_throughput: 1163.389\n",
      "    learn_time_ms: 1717.396\n",
      "    load_throughput: 58180.211\n",
      "    load_time_ms: 34.342\n",
      "    sample_throughput: 88.666\n",
      "    sample_time_ms: 22533.971\n",
      "    update_time_ms: 8.754\n",
      "  timestamp: 1636452764\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1696302\n",
      "  training_iteration: 849\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   849</td><td style=\"text-align: right;\">         23225.7</td><td style=\"text-align: right;\">1696302</td><td style=\"text-align: right;\">  8.7194</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">                2.84</td><td style=\"text-align: right;\">            104.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1698300\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-13-08\n",
      "  done: false\n",
      "  episode_len_mean: 105.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000012\n",
      "  episode_reward_mean: 8.780200000000017\n",
      "  episode_reward_min: 2.840000000000019\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16657\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3687753654661632\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012349856466467045\n",
      "          policy_loss: -0.042661495435805545\n",
      "          total_loss: 0.13729925490915776\n",
      "          vf_explained_var: 0.9705672264099121\n",
      "          vf_loss: 0.17862648703157902\n",
      "    num_agent_steps_sampled: 1698300\n",
      "    num_agent_steps_trained: 1698300\n",
      "    num_steps_sampled: 1698300\n",
      "    num_steps_trained: 1698300\n",
      "  iterations_since_restore: 850\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.7470588235294\n",
      "    ram_util_percent: 31.499999999999993\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04421145485031536\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.08331488043028\n",
      "    mean_inference_ms: 2.4628296850668874\n",
      "    mean_raw_obs_processing_ms: 2.058067465745742\n",
      "  time_since_restore: 23249.633398771286\n",
      "  time_this_iter_s: 23.979262590408325\n",
      "  time_total_s: 23249.633398771286\n",
      "  timers:\n",
      "    learn_throughput: 1164.481\n",
      "    learn_time_ms: 1715.785\n",
      "    load_throughput: 58360.431\n",
      "    load_time_ms: 34.236\n",
      "    sample_throughput: 88.709\n",
      "    sample_time_ms: 22523.18\n",
      "    update_time_ms: 8.529\n",
      "  timestamp: 1636452788\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1698300\n",
      "  training_iteration: 850\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   850</td><td style=\"text-align: right;\">         23249.6</td><td style=\"text-align: right;\">1698300</td><td style=\"text-align: right;\">  8.7802</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">                2.84</td><td style=\"text-align: right;\">            105.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1700298\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-13-34\n",
      "  done: false\n",
      "  episode_len_mean: 105.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.750000000000012\n",
      "  episode_reward_mean: 9.149600000000017\n",
      "  episode_reward_min: 2.840000000000019\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16677\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.341354220821744\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008595986670308961\n",
      "          policy_loss: -0.023003303933711278\n",
      "          total_loss: 0.0681826136119309\n",
      "          vf_explained_var: 0.9881670475006104\n",
      "          vf_loss: 0.09414354589368616\n",
      "    num_agent_steps_sampled: 1700298\n",
      "    num_agent_steps_trained: 1700298\n",
      "    num_steps_sampled: 1700298\n",
      "    num_steps_trained: 1700298\n",
      "  iterations_since_restore: 851\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.21315789473681\n",
      "    ram_util_percent: 31.468421052631577\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422464437512133\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.08224228076683\n",
      "    mean_inference_ms: 2.4630576960424286\n",
      "    mean_raw_obs_processing_ms: 2.056324633167665\n",
      "  time_since_restore: 23275.83362030983\n",
      "  time_this_iter_s: 26.2002215385437\n",
      "  time_total_s: 23275.83362030983\n",
      "  timers:\n",
      "    learn_throughput: 1165.597\n",
      "    learn_time_ms: 1714.144\n",
      "    load_throughput: 58745.154\n",
      "    load_time_ms: 34.011\n",
      "    sample_throughput: 88.139\n",
      "    sample_time_ms: 22668.648\n",
      "    update_time_ms: 8.713\n",
      "  timestamp: 1636452814\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1700298\n",
      "  training_iteration: 851\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   851</td><td style=\"text-align: right;\">         23275.8</td><td style=\"text-align: right;\">1700298</td><td style=\"text-align: right;\">  9.1496</td><td style=\"text-align: right;\">               14.75</td><td style=\"text-align: right;\">                2.84</td><td style=\"text-align: right;\">            105.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1702296\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-14-00\n",
      "  done: false\n",
      "  episode_len_mean: 105.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000014\n",
      "  episode_reward_mean: 9.095500000000017\n",
      "  episode_reward_min: 1.1700000000000161\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16696\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3759015650976272\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013308438842954955\n",
      "          policy_loss: -0.02086525417509533\n",
      "          total_loss: 0.23901858660614206\n",
      "          vf_explained_var: 0.95055091381073\n",
      "          vf_loss: 0.25745484933611895\n",
      "    num_agent_steps_sampled: 1702296\n",
      "    num_agent_steps_trained: 1702296\n",
      "    num_steps_sampled: 1702296\n",
      "    num_steps_trained: 1702296\n",
      "  iterations_since_restore: 852\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.51351351351352\n",
      "    ram_util_percent: 31.52162162162161\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422828417975724\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.081853226881236\n",
      "    mean_inference_ms: 2.4631324811747377\n",
      "    mean_raw_obs_processing_ms: 2.0546747193849417\n",
      "  time_since_restore: 23301.626438856125\n",
      "  time_this_iter_s: 25.792818546295166\n",
      "  time_total_s: 23301.626438856125\n",
      "  timers:\n",
      "    learn_throughput: 1165.334\n",
      "    learn_time_ms: 1714.529\n",
      "    load_throughput: 58904.375\n",
      "    load_time_ms: 33.919\n",
      "    sample_throughput: 87.63\n",
      "    sample_time_ms: 22800.328\n",
      "    update_time_ms: 8.477\n",
      "  timestamp: 1636452840\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1702296\n",
      "  training_iteration: 852\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   852</td><td style=\"text-align: right;\">         23301.6</td><td style=\"text-align: right;\">1702296</td><td style=\"text-align: right;\">  9.0955</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">                1.17</td><td style=\"text-align: right;\">            105.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1704294\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-14-26\n",
      "  done: false\n",
      "  episode_len_mean: 105.45\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000014\n",
      "  episode_reward_mean: 9.454100000000016\n",
      "  episode_reward_min: 1.1700000000000161\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16715\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.369614182767414\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00845920213979852\n",
      "          policy_loss: -0.051003808643491494\n",
      "          total_loss: 0.059141410106704345\n",
      "          vf_explained_var: 0.9853562116622925\n",
      "          vf_loss: 0.11355182497451703\n",
      "    num_agent_steps_sampled: 1704294\n",
      "    num_agent_steps_trained: 1704294\n",
      "    num_steps_sampled: 1704294\n",
      "    num_steps_trained: 1704294\n",
      "  iterations_since_restore: 853\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.7527777777778\n",
      "    ram_util_percent: 31.44722222222222\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423549756101339\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.080541867583737\n",
      "    mean_inference_ms: 2.4631880987791934\n",
      "    mean_raw_obs_processing_ms: 2.0531507682318515\n",
      "  time_since_restore: 23327.102625608444\n",
      "  time_this_iter_s: 25.476186752319336\n",
      "  time_total_s: 23327.102625608444\n",
      "  timers:\n",
      "    learn_throughput: 1164.404\n",
      "    learn_time_ms: 1715.899\n",
      "    load_throughput: 58982.026\n",
      "    load_time_ms: 33.875\n",
      "    sample_throughput: 87.171\n",
      "    sample_time_ms: 22920.429\n",
      "    update_time_ms: 7.771\n",
      "  timestamp: 1636452866\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1704294\n",
      "  training_iteration: 853\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   853</td><td style=\"text-align: right;\">         23327.1</td><td style=\"text-align: right;\">1704294</td><td style=\"text-align: right;\">  9.4541</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">                1.17</td><td style=\"text-align: right;\">            105.45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=163)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1706292\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-15-05\n",
      "  done: false\n",
      "  episode_len_mean: 104.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.740000000000014\n",
      "  episode_reward_mean: 9.326600000000019\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16734\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3613509643645514\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008103028260022275\n",
      "          policy_loss: -0.08150580954693612\n",
      "          total_loss: -0.005307117556887013\n",
      "          vf_explained_var: 0.985023558139801\n",
      "          vf_loss: 0.07995590581780389\n",
      "    num_agent_steps_sampled: 1706292\n",
      "    num_agent_steps_trained: 1706292\n",
      "    num_steps_sampled: 1706292\n",
      "    num_steps_trained: 1706292\n",
      "  iterations_since_restore: 854\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.49821428571428\n",
      "    ram_util_percent: 31.45\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04422310829917654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.080058676055614\n",
      "    mean_inference_ms: 2.4629225612173333\n",
      "    mean_raw_obs_processing_ms: 2.053615107796396\n",
      "  time_since_restore: 23366.74639582634\n",
      "  time_this_iter_s: 39.64377021789551\n",
      "  time_total_s: 23366.74639582634\n",
      "  timers:\n",
      "    learn_throughput: 1164.455\n",
      "    learn_time_ms: 1715.824\n",
      "    load_throughput: 59034.712\n",
      "    load_time_ms: 33.844\n",
      "    sample_throughput: 81.807\n",
      "    sample_time_ms: 24423.472\n",
      "    update_time_ms: 6.89\n",
      "  timestamp: 1636452905\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1706292\n",
      "  training_iteration: 854\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   854</td><td style=\"text-align: right;\">         23366.7</td><td style=\"text-align: right;\">1706292</td><td style=\"text-align: right;\">  9.3266</td><td style=\"text-align: right;\">               14.74</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            104.47</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=168)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1708290\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-15-46\n",
      "  done: false\n",
      "  episode_len_mean: 102.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 9.318200000000019\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16754\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3038408234005883\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01266846847102756\n",
      "          policy_loss: -0.021927619335197268\n",
      "          total_loss: 0.23095140778681353\n",
      "          vf_explained_var: 0.9568880796432495\n",
      "          vf_loss: 0.2505078680281128\n",
      "    num_agent_steps_sampled: 1708290\n",
      "    num_agent_steps_trained: 1708290\n",
      "    num_steps_sampled: 1708290\n",
      "    num_steps_trained: 1708290\n",
      "  iterations_since_restore: 855\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.12068965517241\n",
      "    ram_util_percent: 31.18275862068965\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423179569573796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.07995627178877\n",
      "    mean_inference_ms: 2.4630584640227284\n",
      "    mean_raw_obs_processing_ms: 2.05595254469151\n",
      "  time_since_restore: 23407.41352534294\n",
      "  time_this_iter_s: 40.66712951660156\n",
      "  time_total_s: 23407.41352534294\n",
      "  timers:\n",
      "    learn_throughput: 1164.039\n",
      "    learn_time_ms: 1716.437\n",
      "    load_throughput: 59340.918\n",
      "    load_time_ms: 33.67\n",
      "    sample_throughput: 76.632\n",
      "    sample_time_ms: 26072.673\n",
      "    update_time_ms: 6.946\n",
      "  timestamp: 1636452946\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1708290\n",
      "  training_iteration: 855\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   855</td><td style=\"text-align: right;\">         23407.4</td><td style=\"text-align: right;\">1708290</td><td style=\"text-align: right;\">  9.3182</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">             102.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=167)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1710288\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-16-28\n",
      "  done: false\n",
      "  episode_len_mean: 102.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 8.917500000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 21\n",
      "  episodes_total: 16775\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3366328693571545\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009387890097870812\n",
      "          policy_loss: -0.023993409136753706\n",
      "          total_loss: 0.08568253125108424\n",
      "          vf_explained_var: 0.9747622609138489\n",
      "          vf_loss: 0.11162310423595564\n",
      "    num_agent_steps_sampled: 1710288\n",
      "    num_agent_steps_trained: 1710288\n",
      "    num_steps_sampled: 1710288\n",
      "    num_steps_trained: 1710288\n",
      "  iterations_since_restore: 856\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.79666666666667\n",
      "    ram_util_percent: 31.213333333333342\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.044245887084733544\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.0786456559862\n",
      "    mean_inference_ms: 2.463251115489642\n",
      "    mean_raw_obs_processing_ms: 2.060375266394112\n",
      "  time_since_restore: 23449.11792063713\n",
      "  time_this_iter_s: 41.70439529418945\n",
      "  time_total_s: 23449.11792063713\n",
      "  timers:\n",
      "    learn_throughput: 1164.08\n",
      "    learn_time_ms: 1716.377\n",
      "    load_throughput: 59403.088\n",
      "    load_time_ms: 33.635\n",
      "    sample_throughput: 71.865\n",
      "    sample_time_ms: 27802.297\n",
      "    update_time_ms: 6.767\n",
      "  timestamp: 1636452988\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1710288\n",
      "  training_iteration: 856\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   856</td><td style=\"text-align: right;\">         23449.1</td><td style=\"text-align: right;\">1710288</td><td style=\"text-align: right;\">  8.9175</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            102.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1712286\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-16-53\n",
      "  done: false\n",
      "  episode_len_mean: 102.81\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.550000000000015\n",
      "  episode_reward_mean: 9.055900000000017\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16793\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3667687370663597\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008267318610633706\n",
      "          policy_loss: -0.010102544352412224\n",
      "          total_loss: 0.09599313003321489\n",
      "          vf_explained_var: 0.9834508299827576\n",
      "          vf_loss: 0.10970722817416702\n",
      "    num_agent_steps_sampled: 1712286\n",
      "    num_agent_steps_trained: 1712286\n",
      "    num_steps_sampled: 1712286\n",
      "    num_steps_trained: 1712286\n",
      "  iterations_since_restore: 857\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.66666666666667\n",
      "    ram_util_percent: 31.199999999999996\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04424217802440431\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.077265707296274\n",
      "    mean_inference_ms: 2.463121781532118\n",
      "    mean_raw_obs_processing_ms: 2.0642249417692558\n",
      "  time_since_restore: 23474.169263362885\n",
      "  time_this_iter_s: 25.051342725753784\n",
      "  time_total_s: 23474.169263362885\n",
      "  timers:\n",
      "    learn_throughput: 1163.649\n",
      "    learn_time_ms: 1717.012\n",
      "    load_throughput: 59432.916\n",
      "    load_time_ms: 33.618\n",
      "    sample_throughput: 71.383\n",
      "    sample_time_ms: 27989.894\n",
      "    update_time_ms: 7.807\n",
      "  timestamp: 1636453013\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1712286\n",
      "  training_iteration: 857\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   857</td><td style=\"text-align: right;\">         23474.2</td><td style=\"text-align: right;\">1712286</td><td style=\"text-align: right;\">  9.0559</td><td style=\"text-align: right;\">               14.55</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            102.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1714284\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-17-17\n",
      "  done: false\n",
      "  episode_len_mean: 102.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.590000000000016\n",
      "  episode_reward_mean: 8.865800000000018\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 18\n",
      "  episodes_total: 16811\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4526844490142095\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00917424487004774\n",
      "          policy_loss: -0.04334788194724492\n",
      "          total_loss: 0.10693526936783677\n",
      "          vf_explained_var: 0.9755388498306274\n",
      "          vf_loss: 0.1536507011169479\n",
      "    num_agent_steps_sampled: 1714284\n",
      "    num_agent_steps_trained: 1714284\n",
      "    num_steps_sampled: 1714284\n",
      "    num_steps_trained: 1714284\n",
      "  iterations_since_restore: 858\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.76176470588237\n",
      "    ram_util_percent: 31.46470588235294\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04423150363254608\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.076619338476238\n",
      "    mean_inference_ms: 2.4629365788189723\n",
      "    mean_raw_obs_processing_ms: 2.0679910116231355\n",
      "  time_since_restore: 23497.78274178505\n",
      "  time_this_iter_s: 23.613478422164917\n",
      "  time_total_s: 23497.78274178505\n",
      "  timers:\n",
      "    learn_throughput: 1163.315\n",
      "    learn_time_ms: 1717.506\n",
      "    load_throughput: 59583.858\n",
      "    load_time_ms: 33.533\n",
      "    sample_throughput: 71.566\n",
      "    sample_time_ms: 27918.347\n",
      "    update_time_ms: 8.226\n",
      "  timestamp: 1636453037\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1714284\n",
      "  training_iteration: 858\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   858</td><td style=\"text-align: right;\">         23497.8</td><td style=\"text-align: right;\">1714284</td><td style=\"text-align: right;\">  8.8658</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            102.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1716282\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-17-41\n",
      "  done: false\n",
      "  episode_len_mean: 102.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.590000000000016\n",
      "  episode_reward_mean: 8.978300000000017\n",
      "  episode_reward_min: -0.05\n",
      "  episodes_this_iter: 20\n",
      "  episodes_total: 16831\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3277374909037636\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010084683919337051\n",
      "          policy_loss: -0.05189268554427794\n",
      "          total_loss: 0.08386854852239291\n",
      "          vf_explained_var: 0.9799172282218933\n",
      "          vf_loss: 0.13677188420579547\n",
      "    num_agent_steps_sampled: 1716282\n",
      "    num_agent_steps_trained: 1716282\n",
      "    num_steps_sampled: 1716282\n",
      "    num_steps_trained: 1716282\n",
      "  iterations_since_restore: 859\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.8294117647059\n",
      "    ram_util_percent: 31.497058823529407\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442344687068314\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.075704201433084\n",
      "    mean_inference_ms: 2.462997602406199\n",
      "    mean_raw_obs_processing_ms: 2.0709839503207554\n",
      "  time_since_restore: 23522.174394130707\n",
      "  time_this_iter_s: 24.39165234565735\n",
      "  time_total_s: 23522.174394130707\n",
      "  timers:\n",
      "    learn_throughput: 1163.324\n",
      "    learn_time_ms: 1717.492\n",
      "    load_throughput: 59590.086\n",
      "    load_time_ms: 33.529\n",
      "    sample_throughput: 71.657\n",
      "    sample_time_ms: 27882.954\n",
      "    update_time_ms: 8.924\n",
      "  timestamp: 1636453061\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1716282\n",
      "  training_iteration: 859\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 14.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   859</td><td style=\"text-align: right;\">         23522.2</td><td style=\"text-align: right;\">1716282</td><td style=\"text-align: right;\">  8.9783</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">               -0.05</td><td style=\"text-align: right;\">            102.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_693ef_00000:\n",
      "  agent_timesteps_total: 1718280\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_10-18-06\n",
      "  done: false\n",
      "  episode_len_mean: 104.61\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.590000000000016\n",
      "  episode_reward_mean: 9.098800000000018\n",
      "  episode_reward_min: -0.02\n",
      "  episodes_this_iter: 19\n",
      "  episodes_total: 16850\n",
      "  experiment_id: 919abc63de9242ecb5d48569c8e42c93\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.2163719177246097\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.405408165000734\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010105208621496161\n",
      "          policy_loss: -0.07035905475772562\n",
      "          total_loss: 0.038200175744437036\n",
      "          vf_explained_var: 0.9817296862602234\n",
      "          vf_loss: 0.11032161866092965\n",
      "    num_agent_steps_sampled: 1718280\n",
      "    num_agent_steps_trained: 1718280\n",
      "    num_steps_sampled: 1718280\n",
      "    num_steps_trained: 1718280\n",
      "  iterations_since_restore: 860\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.59166666666668\n",
      "    ram_util_percent: 31.619444444444444\n",
      "  pid: 170\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0442443663665545\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.074598244625953\n",
      "    mean_inference_ms: 2.4631598801435435\n",
      "    mean_raw_obs_processing_ms: 2.0712008039027547\n",
      "  time_since_restore: 23547.245108366013\n",
      "  time_this_iter_s: 25.070714235305786\n",
      "  time_total_s: 23547.245108366013\n",
      "  timers:\n",
      "    learn_throughput: 1152.77\n",
      "    learn_time_ms: 1733.217\n",
      "    load_throughput: 59118.838\n",
      "    load_time_ms: 33.796\n",
      "    sample_throughput: 71.421\n",
      "    sample_time_ms: 27975.122\n",
      "    update_time_ms: 9.884\n",
      "  timestamp: 1636453086\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1718280\n",
      "  training_iteration: 860\n",
      "  trial_id: 693ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/27.77 GiB heap, 0.0/13.88 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/3_tasks2/PPO_2021-11-09_03-44-58<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_693ef_00000</td><td>RUNNING </td><td>192.168.3.5:170</td><td style=\"text-align: right;\">   860</td><td style=\"text-align: right;\">         23547.2</td><td style=\"text-align: right;\">1718280</td><td style=\"text-align: right;\">  9.0988</td><td style=\"text-align: right;\">               14.59</td><td style=\"text-align: right;\">               -0.02</td><td style=\"text-align: right;\">            104.61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 10:18:08,221\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2021-11-09 10:18:08,220\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "Process _WandbLoggingProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/integration/wandb.py\", line 200, in run\n",
      "    result = self.queue.get()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/util.py\", line 322, in _exit_function\n",
      "    p.join()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt\n",
      "Process wandb_internal:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/wandb/sdk/internal/internal.py\", line 152, in wandb_internal\n",
      "    thread.join()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/threading.py\", line 1032, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "2021-11-09 10:18:08,723\tWARNING tune.py:519 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_56/438550406.py\", line 33, in <module>\n",
      "    checkpoint_at_end=True)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\", line 532, in run\n",
      "    runner.step()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 554, in step\n",
      "    self._process_events(timeout=timeout)  # blocking\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 675, in _process_events\n",
      "    timeout=timeout)  # blocking\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 718, in get_next_available_trial\n",
      "    ready, _ = ray.wait(shuffled_results, timeout=timeout)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\", line 1793, in wait\n",
      "    fetch_local,\n",
      "  File \"python/ray/_raylet.pyx\", line 1222, in ray._raylet.CoreWorker.wait\n",
      "  File \"python/ray/_raylet.pyx\", line 155, in ray._raylet.check_status\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_56/438550406.py\", line 33, in <module>\n",
      "    checkpoint_at_end=True)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\", line 532, in run\n",
      "    runner.step()\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 554, in step\n",
      "    self._process_events(timeout=timeout)  # blocking\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 675, in _process_events\n",
      "    timeout=timeout)  # blocking\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 718, in get_next_available_trial\n",
      "    ready, _ = ray.wait(shuffled_results, timeout=timeout)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\", line 1793, in wait\n",
      "    fetch_local,\n",
      "  File \"python/ray/_raylet.pyx\", line 1222, in ray._raylet.CoreWorker.wait\n",
      "  File \"python/ray/_raylet.pyx\", line 155, in ray._raylet.check_status\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_56/438550406.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcheckpoint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         checkpoint_at_end=True)\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    674\u001b[0m             trial = self.trial_executor.get_next_available_trial(\n\u001b[0;32m--> 675\u001b[0;31m                 timeout=timeout)  # blocking\n\u001b[0m\u001b[1;32m    676\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0mready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mfetch_local\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m         )\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3360\u001b[0m                         \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple)\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0;32m-> 3170\u001b[0;31m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3378\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3379\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3380\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2064\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0;32m-> 1143\u001b[0;31m                                                                      chained_exceptions_tb_offset)\n\u001b[0m\u001b[1;32m   1144\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ipython-7.25.0-py3.7.egg/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 256,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 1000,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO MultiTask (C18, C118, C135) pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/3_tasks2\",\n",
    "        keep_checkpoints_num=50,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
