{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 256 \n",
    "        self.policy_network = nn.Sequential(\n",
    "            nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            #nn.ELU(),\n",
    "        )\n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        target_features = target_features.reshape(target_features.shape[0], -1)\n",
    "        features = torch.cat([visual_features, target_features], dim=1)\n",
    "        features = self.policy_network(features)\n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=250)\n",
    "    env.update_taskset(TaskSet(preset=['C3', 'C17', 'C32', 'C8']))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n",
      "2021-11-08 22:06:08,725\tINFO trainable.py:76 -- Checkpoint size is 31502439 bytes\n",
      "2021-11-08 22:06:08,755\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-11-08 22:06:08,790\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 19.8/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id 78cf0_00000 but id 1379e_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=62698)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62698)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO MultiTask (C3, C17, C32, C8) pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/1379e_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/1379e_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211108_220609-1379e_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62698)\u001b[0m 2021-11-08 22:06:13,782\tWARNING ppo.py:143 -- `train_batch_size` (1000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 333.\n",
      "\u001b[2m\u001b[36m(pid=62698)\u001b[0m 2021-11-08 22:06:13,782\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=62698)\u001b[0m 2021-11-08 22:06:13,782\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62698)\u001b[0m 2021-11-08 22:06:22,360\tINFO trainable.py:109 -- Trainable.setup took 12.264 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=62698)\u001b[0m 2021-11-08 22:06:22,363\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.9/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62698)\u001b[0m 2021-11-08 22:06:22,467\tINFO trainable.py:383 -- Restored on 192.168.1.96 from checkpoint: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08/PPO_my_env_1379e_00000_0_2021-11-08_22-06-08/tmpnemumt2yrestore_from_object/checkpoint-50\n",
      "\u001b[2m\u001b[36m(pid=62698)\u001b[0m 2021-11-08 22:06:22,467\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 50, '_timesteps_total': None, '_time_total': 5104.906400442123, '_episodes_total': 637}\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 51998\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-10-28\n",
      "  done: false\n",
      "  episode_len_mean: 65.62068965517241\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.93\n",
      "  episode_reward_mean: 5.784482758620698\n",
      "  episode_reward_min: 1.9200000000000113\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 666\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0565471910295035\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014241318434432656\n",
      "          policy_loss: -0.012536534879888808\n",
      "          total_loss: 0.6745009437203408\n",
      "          vf_explained_var: 0.8480382561683655\n",
      "          vf_loss: 0.7047546832334428\n",
      "    num_agent_steps_sampled: 51998\n",
      "    num_agent_steps_trained: 51998\n",
      "    num_steps_sampled: 51998\n",
      "    num_steps_trained: 51998\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 68.54615384615386\n",
      "    ram_util_percent: 25.896866096866095\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07365689506662894\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 135.17522342275427\n",
      "    mean_inference_ms: 4.646305349381826\n",
      "    mean_raw_obs_processing_ms: 133.34472646685154\n",
      "  time_since_restore: 245.87017130851746\n",
      "  time_this_iter_s: 245.87017130851746\n",
      "  time_total_s: 5350.776571750641\n",
      "  timers:\n",
      "    learn_throughput: 723.816\n",
      "    learn_time_ms: 2760.37\n",
      "    load_throughput: 49551.912\n",
      "    load_time_ms: 40.321\n",
      "    sample_throughput: 8.221\n",
      "    sample_time_ms: 243038.854\n",
      "    update_time_ms: 8.25\n",
      "  timestamp: 1636409428\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 51998\n",
      "  training_iteration: 51\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.1/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         5350.78</td><td style=\"text-align: right;\">51998</td><td style=\"text-align: right;\"> 5.78448</td><td style=\"text-align: right;\">                9.93</td><td style=\"text-align: right;\">                1.92</td><td style=\"text-align: right;\">           65.6207</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 53996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-13-53\n",
      "  done: false\n",
      "  episode_len_mean: 67.55172413793103\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000013\n",
      "  episode_reward_mean: 5.695344827586217\n",
      "  episode_reward_min: -4.85722573273506e-16\n",
      "  episodes_this_iter: 29\n",
      "  episodes_total: 695\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.054632428714207\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01787651900069836\n",
      "          policy_loss: -0.05959009737485931\n",
      "          total_loss: 0.5696755209494204\n",
      "          vf_explained_var: 0.8116239905357361\n",
      "          vf_loss: 0.6462366400730042\n",
      "    num_agent_steps_sampled: 53996\n",
      "    num_agent_steps_trained: 53996\n",
      "    num_steps_sampled: 53996\n",
      "    num_steps_trained: 53996\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.14421768707483\n",
      "    ram_util_percent: 27.313265306122453\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07335071447870083\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 112.79964592134814\n",
      "    mean_inference_ms: 4.576556984560969\n",
      "    mean_raw_obs_processing_ms: 139.89254094007603\n",
      "  time_since_restore: 451.37171959877014\n",
      "  time_this_iter_s: 205.50154829025269\n",
      "  time_total_s: 5556.278120040894\n",
      "  timers:\n",
      "    learn_throughput: 712.399\n",
      "    learn_time_ms: 2804.608\n",
      "    load_throughput: 46980.513\n",
      "    load_time_ms: 42.528\n",
      "    sample_throughput: 8.967\n",
      "    sample_time_ms: 222812.741\n",
      "    update_time_ms: 7.845\n",
      "  timestamp: 1636409633\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 53996\n",
      "  training_iteration: 52\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.1/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         5556.28</td><td style=\"text-align: right;\">53996</td><td style=\"text-align: right;\"> 5.69534</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">        -4.85723e-16</td><td style=\"text-align: right;\">           67.5517</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 55994\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-18-43\n",
      "  done: false\n",
      "  episode_len_mean: 60.618556701030926\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.370000000000013\n",
      "  episode_reward_mean: 5.9547422680412465\n",
      "  episode_reward_min: -4.85722573273506e-16\n",
      "  episodes_this_iter: 39\n",
      "  episodes_total: 734\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0246361442974634\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016678847650928304\n",
      "          policy_loss: -0.010106236221534864\n",
      "          total_loss: 0.561548975890591\n",
      "          vf_explained_var: 0.8909662961959839\n",
      "          vf_loss: 0.5885658003035046\n",
      "    num_agent_steps_sampled: 55994\n",
      "    num_agent_steps_trained: 55994\n",
      "    num_steps_sampled: 55994\n",
      "    num_steps_trained: 55994\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.2903147699758\n",
      "    ram_util_percent: 27.434382566585956\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07365539534509412\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 97.75057639305909\n",
      "    mean_inference_ms: 4.575823642474306\n",
      "    mean_raw_obs_processing_ms: 156.08867790481636\n",
      "  time_since_restore: 740.9552721977234\n",
      "  time_this_iter_s: 289.58355259895325\n",
      "  time_total_s: 5845.861672639847\n",
      "  timers:\n",
      "    learn_throughput: 701.557\n",
      "    learn_time_ms: 2847.951\n",
      "    load_throughput: 47389.871\n",
      "    load_time_ms: 42.161\n",
      "    sample_throughput: 8.186\n",
      "    sample_time_ms: 244069.835\n",
      "    update_time_ms: 7.87\n",
      "  timestamp: 1636409923\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 55994\n",
      "  training_iteration: 53\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.3/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         5845.86</td><td style=\"text-align: right;\">55994</td><td style=\"text-align: right;\"> 5.95474</td><td style=\"text-align: right;\">               10.37</td><td style=\"text-align: right;\">        -4.85723e-16</td><td style=\"text-align: right;\">           60.6186</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 57992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-23-26\n",
      "  done: false\n",
      "  episode_len_mean: 57.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.430000000000016\n",
      "  episode_reward_mean: 6.061600000000007\n",
      "  episode_reward_min: -4.85722573273506e-16\n",
      "  episodes_this_iter: 37\n",
      "  episodes_total: 771\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0439789698237463\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013555709987890128\n",
      "          policy_loss: -0.01903611549309322\n",
      "          total_loss: 0.5942185406173979\n",
      "          vf_explained_var: 0.8720524311065674\n",
      "          vf_loss: 0.6309833000813212\n",
      "    num_agent_steps_sampled: 57992\n",
      "    num_agent_steps_trained: 57992\n",
      "    num_steps_sampled: 57992\n",
      "    num_steps_trained: 57992\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.764764267990074\n",
      "    ram_util_percent: 27.522828784119103\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07395802519603233\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 75.81112347044812\n",
      "    mean_inference_ms: 4.5656351677573275\n",
      "    mean_raw_obs_processing_ms: 175.77373287518873\n",
      "  time_since_restore: 1023.8971314430237\n",
      "  time_this_iter_s: 282.9418592453003\n",
      "  time_total_s: 6128.803531885147\n",
      "  timers:\n",
      "    learn_throughput: 698.762\n",
      "    learn_time_ms: 2859.344\n",
      "    load_throughput: 46193.896\n",
      "    load_time_ms: 43.252\n",
      "    sample_throughput: 7.896\n",
      "    sample_time_ms: 253047.321\n",
      "    update_time_ms: 7.603\n",
      "  timestamp: 1636410206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 57992\n",
      "  training_iteration: 54\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.3/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">          6128.8</td><td style=\"text-align: right;\">57992</td><td style=\"text-align: right;\">  6.0616</td><td style=\"text-align: right;\">               10.43</td><td style=\"text-align: right;\">        -4.85723e-16</td><td style=\"text-align: right;\">             57.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 59990\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-27-48\n",
      "  done: false\n",
      "  episode_len_mean: 53.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.430000000000016\n",
      "  episode_reward_mean: 6.204500000000007\n",
      "  episode_reward_min: 0.259999999999999\n",
      "  episodes_this_iter: 36\n",
      "  episodes_total: 807\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.045295785722278\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011321829703586458\n",
      "          policy_loss: 0.02418609272156443\n",
      "          total_loss: 0.547794891645511\n",
      "          vf_explained_var: 0.8846254348754883\n",
      "          vf_loss: 0.5417973879547346\n",
      "    num_agent_steps_sampled: 59990\n",
      "    num_agent_steps_trained: 59990\n",
      "    num_steps_sampled: 59990\n",
      "    num_steps_trained: 59990\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.22219251336898\n",
      "    ram_util_percent: 27.644385026737968\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07417668285303913\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 67.15404763241176\n",
      "    mean_inference_ms: 4.565423551775945\n",
      "    mean_raw_obs_processing_ms: 190.26116118238434\n",
      "  time_since_restore: 1285.8664820194244\n",
      "  time_this_iter_s: 261.96935057640076\n",
      "  time_total_s: 6390.772882461548\n",
      "  timers:\n",
      "    learn_throughput: 702.597\n",
      "    learn_time_ms: 2843.735\n",
      "    load_throughput: 46771.925\n",
      "    load_time_ms: 42.718\n",
      "    sample_throughput: 7.858\n",
      "    sample_time_ms: 254263.479\n",
      "    update_time_ms: 7.706\n",
      "  timestamp: 1636410468\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59990\n",
      "  training_iteration: 55\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.4/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         6390.77</td><td style=\"text-align: right;\">59990</td><td style=\"text-align: right;\">  6.2045</td><td style=\"text-align: right;\">               10.43</td><td style=\"text-align: right;\">                0.26</td><td style=\"text-align: right;\">             53.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 61988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-31-35\n",
      "  done: false\n",
      "  episode_len_mean: 56.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.430000000000016\n",
      "  episode_reward_mean: 6.124800000000007\n",
      "  episode_reward_min: 0.2900000000000009\n",
      "  episodes_this_iter: 34\n",
      "  episodes_total: 841\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.051380259082431\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014229876312188486\n",
      "          policy_loss: -0.058776423494730674\n",
      "          total_loss: 0.45497791082376526\n",
      "          vf_explained_var: 0.8710749745368958\n",
      "          vf_loss: 0.5314221621978851\n",
      "    num_agent_steps_sampled: 61988\n",
      "    num_agent_steps_trained: 61988\n",
      "    num_steps_sampled: 61988\n",
      "    num_steps_trained: 61988\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.895665634674934\n",
      "    ram_util_percent: 27.675851393188854\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07434547211551136\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 61.91376014599898\n",
      "    mean_inference_ms: 4.555412727657694\n",
      "    mean_raw_obs_processing_ms: 204.126217774736\n",
      "  time_since_restore: 1512.4263322353363\n",
      "  time_this_iter_s: 226.55985021591187\n",
      "  time_total_s: 6617.33273267746\n",
      "  timers:\n",
      "    learn_throughput: 707.074\n",
      "    learn_time_ms: 2825.728\n",
      "    load_throughput: 47590.592\n",
      "    load_time_ms: 41.983\n",
      "    sample_throughput: 8.018\n",
      "    sample_time_ms: 249180.487\n",
      "    update_time_ms: 7.978\n",
      "  timestamp: 1636410695\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 61988\n",
      "  training_iteration: 56\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.5/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         6617.33</td><td style=\"text-align: right;\">61988</td><td style=\"text-align: right;\">  6.1248</td><td style=\"text-align: right;\">               10.43</td><td style=\"text-align: right;\">                0.29</td><td style=\"text-align: right;\">             56.33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 63986\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-39-14\n",
      "  done: false\n",
      "  episode_len_mean: 43.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.720000000000011\n",
      "  episode_reward_mean: 6.475100000000005\n",
      "  episode_reward_min: 0.9899999999999995\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 901\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.694506301198687\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013006005140032969\n",
      "          policy_loss: -0.026389063238388015\n",
      "          total_loss: 0.6102047068732125\n",
      "          vf_explained_var: 0.8971973061561584\n",
      "          vf_loss: 0.6509376311586017\n",
      "    num_agent_steps_sampled: 63986\n",
      "    num_agent_steps_trained: 63986\n",
      "    num_steps_sampled: 63986\n",
      "    num_steps_trained: 63986\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.833689024390246\n",
      "    ram_util_percent: 27.790853658536584\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07409371683355133\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 56.78120721461405\n",
      "    mean_inference_ms: 4.52087607057014\n",
      "    mean_raw_obs_processing_ms: 234.54143706157694\n",
      "  time_since_restore: 1972.1564645767212\n",
      "  time_this_iter_s: 459.7301323413849\n",
      "  time_total_s: 7077.062865018845\n",
      "  timers:\n",
      "    learn_throughput: 707.385\n",
      "    learn_time_ms: 2824.485\n",
      "    load_throughput: 46749.784\n",
      "    load_time_ms: 42.738\n",
      "    sample_throughput: 7.165\n",
      "    sample_time_ms: 278846.674\n",
      "    update_time_ms: 7.881\n",
      "  timestamp: 1636411154\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 63986\n",
      "  training_iteration: 57\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.8/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         7077.06</td><td style=\"text-align: right;\">63986</td><td style=\"text-align: right;\">  6.4751</td><td style=\"text-align: right;\">               10.72</td><td style=\"text-align: right;\">                0.99</td><td style=\"text-align: right;\">             43.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 65984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-42-26\n",
      "  done: false\n",
      "  episode_len_mean: 43.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.070000000000016\n",
      "  episode_reward_mean: 6.520400000000003\n",
      "  episode_reward_min: -2.0999999999999996\n",
      "  episodes_this_iter: 32\n",
      "  episodes_total: 933\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9657836465608507\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.019692241517673157\n",
      "          policy_loss: 0.020175657137518836\n",
      "          total_loss: 0.9074083562408175\n",
      "          vf_explained_var: 0.8329024314880371\n",
      "          vf_loss: 0.9029520955823717\n",
      "    num_agent_steps_sampled: 65984\n",
      "    num_agent_steps_trained: 65984\n",
      "    num_steps_sampled: 65984\n",
      "    num_steps_trained: 65984\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.389377289377286\n",
      "    ram_util_percent: 27.94139194139194\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07379874579408377\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 55.26930331683329\n",
      "    mean_inference_ms: 4.505903705990752\n",
      "    mean_raw_obs_processing_ms: 242.7062258465706\n",
      "  time_since_restore: 2163.4653992652893\n",
      "  time_this_iter_s: 191.30893468856812\n",
      "  time_total_s: 7268.371799707413\n",
      "  timers:\n",
      "    learn_throughput: 706.794\n",
      "    learn_time_ms: 2826.848\n",
      "    load_throughput: 46574.725\n",
      "    load_time_ms: 42.899\n",
      "    sample_throughput: 7.468\n",
      "    sample_time_ms: 267539.891\n",
      "    update_time_ms: 8.168\n",
      "  timestamp: 1636411346\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 65984\n",
      "  training_iteration: 58\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.6/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         7268.37</td><td style=\"text-align: right;\">65984</td><td style=\"text-align: right;\">  6.5204</td><td style=\"text-align: right;\">               12.07</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">             43.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 67982\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-47-44\n",
      "  done: false\n",
      "  episode_len_mean: 47.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 6.430700000000004\n",
      "  episode_reward_min: -2.0999999999999996\n",
      "  episodes_this_iter: 38\n",
      "  episodes_total: 971\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9742300726118542\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.019366018994173506\n",
      "          policy_loss: 0.017919089285922903\n",
      "          total_loss: 0.5774223250647386\n",
      "          vf_explained_var: 0.8858834505081177\n",
      "          vf_loss: 0.5753723369467826\n",
      "    num_agent_steps_sampled: 67982\n",
      "    num_agent_steps_trained: 67982\n",
      "    num_steps_sampled: 67982\n",
      "    num_steps_trained: 67982\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.57819383259912\n",
      "    ram_util_percent: 27.829074889867844\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07390644669178323\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 54.064675464669406\n",
      "    mean_inference_ms: 4.5025130835889335\n",
      "    mean_raw_obs_processing_ms: 245.16282863269447\n",
      "  time_since_restore: 2481.6820969581604\n",
      "  time_this_iter_s: 318.2166976928711\n",
      "  time_total_s: 7586.588497400284\n",
      "  timers:\n",
      "    learn_throughput: 705.939\n",
      "    learn_time_ms: 2830.274\n",
      "    load_throughput: 46060.177\n",
      "    load_time_ms: 43.378\n",
      "    sample_throughput: 7.323\n",
      "    sample_time_ms: 272845.702\n",
      "    update_time_ms: 8.123\n",
      "  timestamp: 1636411664\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 67982\n",
      "  training_iteration: 59\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.6/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         7586.59</td><td style=\"text-align: right;\">67982</td><td style=\"text-align: right;\">  6.4307</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">             47.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 69980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-54-34\n",
      "  done: false\n",
      "  episode_len_mean: 50.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.660000000000014\n",
      "  episode_reward_mean: 6.630000000000007\n",
      "  episode_reward_min: -2.0999999999999996\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 1016\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7242689575467791\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013401096964467453\n",
      "          policy_loss: -0.023200519515999725\n",
      "          total_loss: 0.7075032752184641\n",
      "          vf_explained_var: 0.8726544976234436\n",
      "          vf_loss: 0.7452662675153642\n",
      "    num_agent_steps_sampled: 69980\n",
      "    num_agent_steps_trained: 69980\n",
      "    num_steps_sampled: 69980\n",
      "    num_steps_trained: 69980\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.63333333333333\n",
      "    ram_util_percent: 27.83094017094017\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07362747231857134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 52.61219855138975\n",
      "    mean_inference_ms: 4.474401038322322\n",
      "    mean_raw_obs_processing_ms: 250.60164279891143\n",
      "  time_since_restore: 2891.753532886505\n",
      "  time_this_iter_s: 410.0714359283447\n",
      "  time_total_s: 7996.6599333286285\n",
      "  timers:\n",
      "    learn_throughput: 705.74\n",
      "    learn_time_ms: 2831.072\n",
      "    load_throughput: 46591.796\n",
      "    load_time_ms: 42.883\n",
      "    sample_throughput: 6.979\n",
      "    sample_time_ms: 286278.537\n",
      "    update_time_ms: 8.116\n",
      "  timestamp: 1636412074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69980\n",
      "  training_iteration: 60\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.7/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         7996.66</td><td style=\"text-align: right;\">69980</td><td style=\"text-align: right;\">    6.63</td><td style=\"text-align: right;\">               14.66</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">             50.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 71978\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_22-58-42\n",
      "  done: false\n",
      "  episode_len_mean: 47.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.529999999999966\n",
      "  episode_reward_mean: 7.454400000000005\n",
      "  episode_reward_min: 0.44999999999999885\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 1057\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7103699905531746\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014930061264465565\n",
      "          policy_loss: -0.08898957311397507\n",
      "          total_loss: 0.8049651164384115\n",
      "          vf_explained_var: 0.8457402586936951\n",
      "          vf_loss: 0.9080723778122948\n",
      "    num_agent_steps_sampled: 71978\n",
      "    num_agent_steps_trained: 71978\n",
      "    num_steps_sampled: 71978\n",
      "    num_steps_trained: 71978\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.257627118644066\n",
      "    ram_util_percent: 27.858757062146893\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07352452306386148\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 51.69967795391829\n",
      "    mean_inference_ms: 4.457102087239272\n",
      "    mean_raw_obs_processing_ms: 256.63939075814136\n",
      "  time_since_restore: 3139.8841042518616\n",
      "  time_this_iter_s: 248.13057136535645\n",
      "  time_total_s: 8244.790504693985\n",
      "  timers:\n",
      "    learn_throughput: 703.183\n",
      "    learn_time_ms: 2841.364\n",
      "    load_throughput: 46233.117\n",
      "    load_time_ms: 43.216\n",
      "    sample_throughput: 6.974\n",
      "    sample_time_ms: 286494.171\n",
      "    update_time_ms: 8.791\n",
      "  timestamp: 1636412322\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 71978\n",
      "  training_iteration: 61\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.7/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         8244.79</td><td style=\"text-align: right;\">71978</td><td style=\"text-align: right;\">  7.4544</td><td style=\"text-align: right;\">               16.53</td><td style=\"text-align: right;\">                0.45</td><td style=\"text-align: right;\">             47.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 73976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-04-18\n",
      "  done: false\n",
      "  episode_len_mean: 47.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.689999999999973\n",
      "  episode_reward_mean: 7.556900000000004\n",
      "  episode_reward_min: 0.44999999999999885\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 1097\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.2\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.7255965743746076\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.028060248551755262\n",
      "          policy_loss: 0.0022073060451518922\n",
      "          total_loss: 1.1145887005896795\n",
      "          vf_explained_var: 0.8709076046943665\n",
      "          vf_loss: 1.1240253061056138\n",
      "    num_agent_steps_sampled: 73976\n",
      "    num_agent_steps_trained: 73976\n",
      "    num_steps_sampled: 73976\n",
      "    num_steps_trained: 73976\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.10753138075313\n",
      "    ram_util_percent: 27.860669456066947\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07311815018532945\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 50.97067385553888\n",
      "    mean_inference_ms: 4.436062923171945\n",
      "    mean_raw_obs_processing_ms: 253.09992130681377\n",
      "  time_since_restore: 3475.0971834659576\n",
      "  time_this_iter_s: 335.21307921409607\n",
      "  time_total_s: 8580.003583908081\n",
      "  timers:\n",
      "    learn_throughput: 702.264\n",
      "    learn_time_ms: 2845.083\n",
      "    load_throughput: 45953.935\n",
      "    load_time_ms: 43.478\n",
      "    sample_throughput: 6.672\n",
      "    sample_time_ms: 299461.278\n",
      "    update_time_ms: 8.962\n",
      "  timestamp: 1636412658\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 73976\n",
      "  training_iteration: 62\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.6/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">            8580</td><td style=\"text-align: right;\">73976</td><td style=\"text-align: right;\">  7.5569</td><td style=\"text-align: right;\">               16.69</td><td style=\"text-align: right;\">                0.45</td><td style=\"text-align: right;\">             47.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 75974\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-11-01\n",
      "  done: false\n",
      "  episode_len_mean: 45.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.689999999999973\n",
      "  episode_reward_mean: 7.544900000000004\n",
      "  episode_reward_min: 0.32999999999999896\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 1148\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5828127270653134\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012638548451890738\n",
      "          policy_loss: -0.013457118826253073\n",
      "          total_loss: 0.9778148995978492\n",
      "          vf_explained_var: 0.9065148234367371\n",
      "          vf_loss: 1.003308578474181\n",
      "    num_agent_steps_sampled: 75974\n",
      "    num_agent_steps_trained: 75974\n",
      "    num_steps_sampled: 75974\n",
      "    num_steps_trained: 75974\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.623437499999994\n",
      "    ram_util_percent: 27.894270833333334\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07284979080119071\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 50.153390945611626\n",
      "    mean_inference_ms: 4.414409422516701\n",
      "    mean_raw_obs_processing_ms: 255.90525553310624\n",
      "  time_since_restore: 3878.458774328232\n",
      "  time_this_iter_s: 403.36159086227417\n",
      "  time_total_s: 8983.365174770355\n",
      "  timers:\n",
      "    learn_throughput: 702.592\n",
      "    learn_time_ms: 2843.756\n",
      "    load_throughput: 45481.219\n",
      "    load_time_ms: 43.93\n",
      "    sample_throughput: 6.428\n",
      "    sample_time_ms: 310839.628\n",
      "    update_time_ms: 9.354\n",
      "  timestamp: 1636413061\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 75974\n",
      "  training_iteration: 63\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.8/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         8983.37</td><td style=\"text-align: right;\">75974</td><td style=\"text-align: right;\">  7.5449</td><td style=\"text-align: right;\">               16.69</td><td style=\"text-align: right;\">                0.33</td><td style=\"text-align: right;\">             45.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 77972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-15-25\n",
      "  done: false\n",
      "  episode_len_mean: 42.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 16.45999999999994\n",
      "  episode_reward_mean: 7.924300000000003\n",
      "  episode_reward_min: 0.32999999999999896\n",
      "  episodes_this_iter: 43\n",
      "  episodes_total: 1191\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5897380516642616\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011531099724723761\n",
      "          policy_loss: -0.04896400904371625\n",
      "          total_loss: 0.867828046636922\n",
      "          vf_explained_var: 0.901735782623291\n",
      "          vf_loss: 0.9292301036062695\n",
      "    num_agent_steps_sampled: 77972\n",
      "    num_agent_steps_trained: 77972\n",
      "    num_steps_sampled: 77972\n",
      "    num_steps_trained: 77972\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.97047872340426\n",
      "    ram_util_percent: 28.01436170212766\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07282493733099592\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 49.64783692608803\n",
      "    mean_inference_ms: 4.41053909511337\n",
      "    mean_raw_obs_processing_ms: 261.4933452128628\n",
      "  time_since_restore: 4142.285966396332\n",
      "  time_this_iter_s: 263.8271920681\n",
      "  time_total_s: 9247.192366838455\n",
      "  timers:\n",
      "    learn_throughput: 702.262\n",
      "    learn_time_ms: 2845.091\n",
      "    load_throughput: 45814.653\n",
      "    load_time_ms: 43.611\n",
      "    sample_throughput: 6.468\n",
      "    sample_time_ms: 308925.836\n",
      "    update_time_ms: 10.569\n",
      "  timestamp: 1636413325\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 77972\n",
      "  training_iteration: 64\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.8/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         9247.19</td><td style=\"text-align: right;\">77972</td><td style=\"text-align: right;\">  7.9243</td><td style=\"text-align: right;\">               16.46</td><td style=\"text-align: right;\">                0.33</td><td style=\"text-align: right;\">              42.3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 79970\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-20-43\n",
      "  done: false\n",
      "  episode_len_mean: 46.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.48999999999996\n",
      "  episode_reward_mean: 7.916000000000002\n",
      "  episode_reward_min: 0.3299999999999996\n",
      "  episodes_this_iter: 44\n",
      "  episodes_total: 1235\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6630878255480812\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.017094586689314437\n",
      "          policy_loss: 0.011365789068596704\n",
      "          total_loss: 1.0502808430365154\n",
      "          vf_explained_var: 0.8861271739006042\n",
      "          vf_loss: 1.050417555655752\n",
      "    num_agent_steps_sampled: 79970\n",
      "    num_agent_steps_trained: 79970\n",
      "    num_steps_sampled: 79970\n",
      "    num_steps_trained: 79970\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.547136563876656\n",
      "    ram_util_percent: 27.998458149779733\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.073010245044141\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 49.36858741674802\n",
      "    mean_inference_ms: 4.421068875532485\n",
      "    mean_raw_obs_processing_ms: 261.9358494195951\n",
      "  time_since_restore: 4460.081254720688\n",
      "  time_this_iter_s: 317.7952883243561\n",
      "  time_total_s: 9564.987655162811\n",
      "  timers:\n",
      "    learn_throughput: 698.45\n",
      "    learn_time_ms: 2860.622\n",
      "    load_throughput: 45581.978\n",
      "    load_time_ms: 43.833\n",
      "    sample_throughput: 6.353\n",
      "    sample_time_ms: 314491.656\n",
      "    update_time_ms: 10.46\n",
      "  timestamp: 1636413643\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 79970\n",
      "  training_iteration: 65\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 30.9/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         9564.99</td><td style=\"text-align: right;\">79970</td><td style=\"text-align: right;\">   7.916</td><td style=\"text-align: right;\">               18.49</td><td style=\"text-align: right;\">                0.33</td><td style=\"text-align: right;\">             46.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 81968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-24-38\n",
      "  done: false\n",
      "  episode_len_mean: 47.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.48999999999996\n",
      "  episode_reward_mean: 7.695200000000003\n",
      "  episode_reward_min: 0.3299999999999996\n",
      "  episodes_this_iter: 37\n",
      "  episodes_total: 1272\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.6312147350538344\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012180574847359956\n",
      "          policy_loss: -0.004455973305517719\n",
      "          total_loss: 0.6670942361156146\n",
      "          vf_explained_var: 0.9349812865257263\n",
      "          vf_loss: 0.6842081883123943\n",
      "    num_agent_steps_sampled: 81968\n",
      "    num_agent_steps_trained: 81968\n",
      "    num_steps_sampled: 81968\n",
      "    num_steps_trained: 81968\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.346865671641794\n",
      "    ram_util_percent: 28.05194029850746\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07275831361141692\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 49.001911294311874\n",
      "    mean_inference_ms: 4.410489334064292\n",
      "    mean_raw_obs_processing_ms: 260.9166457727209\n",
      "  time_since_restore: 4695.173352241516\n",
      "  time_this_iter_s: 235.09209752082825\n",
      "  time_total_s: 9800.07975268364\n",
      "  timers:\n",
      "    learn_throughput: 694.361\n",
      "    learn_time_ms: 2877.466\n",
      "    load_throughput: 45416.246\n",
      "    load_time_ms: 43.993\n",
      "    sample_throughput: 6.336\n",
      "    sample_time_ms: 315327.547\n",
      "    update_time_ms: 10.34\n",
      "  timestamp: 1636413878\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 81968\n",
      "  training_iteration: 66\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.0/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         9800.08</td><td style=\"text-align: right;\">81968</td><td style=\"text-align: right;\">  7.6952</td><td style=\"text-align: right;\">               18.49</td><td style=\"text-align: right;\">                0.33</td><td style=\"text-align: right;\">             47.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 83966\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-30-40\n",
      "  done: false\n",
      "  episode_len_mean: 44.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 14.640000000000013\n",
      "  episode_reward_mean: 7.693300000000006\n",
      "  episode_reward_min: 0.389999999999999\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 1322\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.5412240056764512\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008054698144283706\n",
      "          policy_loss: 0.0008719766689907936\n",
      "          total_loss: 0.7544911801815033\n",
      "          vf_explained_var: 0.9178794026374817\n",
      "          vf_loss: 0.7666150382586888\n",
      "    num_agent_steps_sampled: 83966\n",
      "    num_agent_steps_trained: 83966\n",
      "    num_steps_sampled: 83966\n",
      "    num_steps_trained: 83966\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.06240310077519\n",
      "    ram_util_percent: 28.327906976744185\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07246595732109588\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 48.59684409149479\n",
      "    mean_inference_ms: 4.395347681332193\n",
      "    mean_raw_obs_processing_ms: 263.4965767796873\n",
      "  time_since_restore: 5056.740653753281\n",
      "  time_this_iter_s: 361.5673015117645\n",
      "  time_total_s: 10161.647054195404\n",
      "  timers:\n",
      "    learn_throughput: 275.963\n",
      "    learn_time_ms: 7240.102\n",
      "    load_throughput: 44907.689\n",
      "    load_time_ms: 44.491\n",
      "    sample_throughput: 6.635\n",
      "    sample_time_ms: 301148.238\n",
      "    update_time_ms: 10.337\n",
      "  timestamp: 1636414240\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 83966\n",
      "  training_iteration: 67\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.3/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">         10161.6</td><td style=\"text-align: right;\">83966</td><td style=\"text-align: right;\">  7.6933</td><td style=\"text-align: right;\">               14.64</td><td style=\"text-align: right;\">                0.39</td><td style=\"text-align: right;\">             44.29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 85964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-39-01\n",
      "  done: false\n",
      "  episode_len_mean: 35.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.469999999999956\n",
      "  episode_reward_mean: 7.857100000000002\n",
      "  episode_reward_min: 1.9700000000000062\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 1383\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.413124692440033\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00946987597686142\n",
      "          policy_loss: 0.008810640676390556\n",
      "          total_loss: 0.8289991412843977\n",
      "          vf_explained_var: 0.9176111221313477\n",
      "          vf_loss: 0.8314787854750951\n",
      "    num_agent_steps_sampled: 85964\n",
      "    num_agent_steps_trained: 85964\n",
      "    num_steps_sampled: 85964\n",
      "    num_steps_trained: 85964\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.89048951048951\n",
      "    ram_util_percent: 28.40909090909091\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07212276299517732\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 48.245849332624445\n",
      "    mean_inference_ms: 4.37970427900725\n",
      "    mean_raw_obs_processing_ms: 270.41055307180415\n",
      "  time_since_restore: 5558.080619573593\n",
      "  time_this_iter_s: 501.3399658203125\n",
      "  time_total_s: 10662.987020015717\n",
      "  timers:\n",
      "    learn_throughput: 172.25\n",
      "    learn_time_ms: 11599.415\n",
      "    load_throughput: 43279.685\n",
      "    load_time_ms: 46.165\n",
      "    sample_throughput: 6.095\n",
      "    sample_time_ms: 327791.143\n",
      "    update_time_ms: 9.996\n",
      "  timestamp: 1636414741\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 85964\n",
      "  training_iteration: 68\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.3/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">           10663</td><td style=\"text-align: right;\">85964</td><td style=\"text-align: right;\">  7.8571</td><td style=\"text-align: right;\">               18.47</td><td style=\"text-align: right;\">                1.97</td><td style=\"text-align: right;\">             35.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 87962\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-46-03\n",
      "  done: false\n",
      "  episode_len_mean: 35.88\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.659999999999958\n",
      "  episode_reward_mean: 8.1109\n",
      "  episode_reward_min: 0.2599999999999997\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 1434\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.448130982830411\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.00971935887726083\n",
      "          policy_loss: -0.057150852857601075\n",
      "          total_loss: 0.7476289803073519\n",
      "          vf_explained_var: 0.928865909576416\n",
      "          vf_loss: 0.8163453346207028\n",
      "    num_agent_steps_sampled: 87962\n",
      "    num_agent_steps_trained: 87962\n",
      "    num_steps_sampled: 87962\n",
      "    num_steps_trained: 87962\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.675747508305655\n",
      "    ram_util_percent: 28.434717607973422\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07190113314062663\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 47.94971908431269\n",
      "    mean_inference_ms: 4.368958256242089\n",
      "    mean_raw_obs_processing_ms: 276.0304693298621\n",
      "  time_since_restore: 5980.266990661621\n",
      "  time_this_iter_s: 422.18637108802795\n",
      "  time_total_s: 11085.173391103745\n",
      "  timers:\n",
      "    learn_throughput: 125.135\n",
      "    learn_time_ms: 15966.748\n",
      "    load_throughput: 42423.436\n",
      "    load_time_ms: 47.097\n",
      "    sample_throughput: 5.985\n",
      "    sample_time_ms: 333819.356\n",
      "    update_time_ms: 10.062\n",
      "  timestamp: 1636415163\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 87962\n",
      "  training_iteration: 69\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.4/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         11085.2</td><td style=\"text-align: right;\">87962</td><td style=\"text-align: right;\">  8.1109</td><td style=\"text-align: right;\">               18.66</td><td style=\"text-align: right;\">                0.26</td><td style=\"text-align: right;\">             35.88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 89960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-51-34\n",
      "  done: false\n",
      "  episode_len_mean: 40.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.659999999999958\n",
      "  episode_reward_mean: 8.757100000000001\n",
      "  episode_reward_min: 0.2599999999999997\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 1476\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.375038186141423\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012222022308105875\n",
      "          policy_loss: 0.00685416032515821\n",
      "          total_loss: 0.9537604689598084\n",
      "          vf_explained_var: 0.939556896686554\n",
      "          vf_loss: 0.9569900788012005\n",
      "    num_agent_steps_sampled: 89960\n",
      "    num_agent_steps_trained: 89960\n",
      "    num_steps_sampled: 89960\n",
      "    num_steps_trained: 89960\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.92526539278132\n",
      "    ram_util_percent: 28.482165605095535\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07186882821225579\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 47.754707587321846\n",
      "    mean_inference_ms: 4.360608944608099\n",
      "    mean_raw_obs_processing_ms: 279.25399106584587\n",
      "  time_since_restore: 6310.624889135361\n",
      "  time_this_iter_s: 330.3578984737396\n",
      "  time_total_s: 11415.531289577484\n",
      "  timers:\n",
      "    learn_throughput: 98.26\n",
      "    learn_time_ms: 20333.795\n",
      "    load_throughput: 41008.426\n",
      "    load_time_ms: 48.722\n",
      "    sample_throughput: 6.215\n",
      "    sample_time_ms: 321478.702\n",
      "    update_time_ms: 10.116\n",
      "  timestamp: 1636415494\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 89960\n",
      "  training_iteration: 70\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.4/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         11415.5</td><td style=\"text-align: right;\">89960</td><td style=\"text-align: right;\">  8.7571</td><td style=\"text-align: right;\">               18.66</td><td style=\"text-align: right;\">                0.26</td><td style=\"text-align: right;\">             40.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 91958\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-08_23-59-50\n",
      "  done: false\n",
      "  episode_len_mean: 39.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.249999999999954\n",
      "  episode_reward_mean: 8.678799999999999\n",
      "  episode_reward_min: 1.8300000000000056\n",
      "  episodes_this_iter: 59\n",
      "  episodes_total: 1535\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.3124724899019513\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01377370496879774\n",
      "          policy_loss: -0.04128725032011668\n",
      "          total_loss: 0.4171514405381112\n",
      "          vf_explained_var: 0.9520395994186401\n",
      "          vf_loss: 0.46743130428450447\n",
      "    num_agent_steps_sampled: 91958\n",
      "    num_agent_steps_trained: 91958\n",
      "    num_steps_sampled: 91958\n",
      "    num_steps_trained: 91958\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.18870056497175\n",
      "    ram_util_percent: 28.527542372881356\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07168242032258165\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 47.516799797828064\n",
      "    mean_inference_ms: 4.354840379042302\n",
      "    mean_raw_obs_processing_ms: 283.42548051531173\n",
      "  time_since_restore: 6806.822575330734\n",
      "  time_this_iter_s: 496.19768619537354\n",
      "  time_total_s: 11911.728975772858\n",
      "  timers:\n",
      "    learn_throughput: 80.903\n",
      "    learn_time_ms: 24696.147\n",
      "    load_throughput: 40290.775\n",
      "    load_time_ms: 49.59\n",
      "    sample_throughput: 5.843\n",
      "    sample_time_ms: 341922.676\n",
      "    update_time_ms: 9.657\n",
      "  timestamp: 1636415990\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 91958\n",
      "  training_iteration: 71\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.4/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         11911.7</td><td style=\"text-align: right;\">91958</td><td style=\"text-align: right;\">  8.6788</td><td style=\"text-align: right;\">               18.25</td><td style=\"text-align: right;\">                1.83</td><td style=\"text-align: right;\">             39.26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 93956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-08-19\n",
      "  done: false\n",
      "  episode_len_mean: 32.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.949999999999996\n",
      "  episode_reward_mean: 8.546199999999999\n",
      "  episode_reward_min: 2.4600000000000137\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 1599\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2163931508858998\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013859086698255384\n",
      "          policy_loss: -0.023442515686509156\n",
      "          total_loss: 0.7636838817880267\n",
      "          vf_explained_var: 0.9433857798576355\n",
      "          vf_loss: 0.7951325994162333\n",
      "    num_agent_steps_sampled: 93956\n",
      "    num_agent_steps_trained: 93956\n",
      "    num_steps_sampled: 93956\n",
      "    num_steps_trained: 93956\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.97359009628611\n",
      "    ram_util_percent: 28.643741403026134\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150916827310858\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 47.36899078699585\n",
      "    mean_inference_ms: 4.355546882645771\n",
      "    mean_raw_obs_processing_ms: 292.03147554721767\n",
      "  time_since_restore: 7316.3537039756775\n",
      "  time_this_iter_s: 509.53112864494324\n",
      "  time_total_s: 12421.2601044178\n",
      "  timers:\n",
      "    learn_throughput: 68.765\n",
      "    learn_time_ms: 29055.295\n",
      "    load_throughput: 39508.315\n",
      "    load_time_ms: 50.572\n",
      "    sample_throughput: 5.628\n",
      "    sample_time_ms: 354994.433\n",
      "    update_time_ms: 9.494\n",
      "  timestamp: 1636416499\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 93956\n",
      "  training_iteration: 72\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.7/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         12421.3</td><td style=\"text-align: right;\">93956</td><td style=\"text-align: right;\">  8.5462</td><td style=\"text-align: right;\">               22.95</td><td style=\"text-align: right;\">                2.46</td><td style=\"text-align: right;\">             32.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 95954\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-14-36\n",
      "  done: false\n",
      "  episode_len_mean: 36.46\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.949999999999996\n",
      "  episode_reward_mean: 8.965099999999998\n",
      "  episode_reward_min: 2.350000000000012\n",
      "  episodes_this_iter: 45\n",
      "  episodes_total: 1644\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.328194889000484\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.007879520792622973\n",
      "          policy_loss: -0.11331479682454042\n",
      "          total_loss: 0.5338726339240869\n",
      "          vf_explained_var: 0.9501395225524902\n",
      "          vf_loss: 0.6581055204783167\n",
      "    num_agent_steps_sampled: 95954\n",
      "    num_agent_steps_trained: 95954\n",
      "    num_steps_sampled: 95954\n",
      "    num_steps_trained: 95954\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.36219739292365\n",
      "    ram_util_percent: 28.816759776536315\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07154672247921758\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 47.23868634254999\n",
      "    mean_inference_ms: 4.3476842992051\n",
      "    mean_raw_obs_processing_ms: 298.71596272545383\n",
      "  time_since_restore: 7693.348338603973\n",
      "  time_this_iter_s: 376.9946346282959\n",
      "  time_total_s: 12798.254739046097\n",
      "  timers:\n",
      "    learn_throughput: 59.806\n",
      "    learn_time_ms: 33408.291\n",
      "    load_throughput: 39288.196\n",
      "    load_time_ms: 50.855\n",
      "    sample_throughput: 5.741\n",
      "    sample_time_ms: 348004.835\n",
      "    update_time_ms: 9.116\n",
      "  timestamp: 1636416876\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 95954\n",
      "  training_iteration: 73\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.7/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         12798.3</td><td style=\"text-align: right;\">95954</td><td style=\"text-align: right;\">  8.9651</td><td style=\"text-align: right;\">               22.95</td><td style=\"text-align: right;\">                2.35</td><td style=\"text-align: right;\">             36.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 97952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 42.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.949999999999996\n",
      "  episode_reward_mean: 9.588299999999995\n",
      "  episode_reward_min: 2.350000000000012\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 1691\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2810787609645298\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009203716537508733\n",
      "          policy_loss: 0.039179489850288345\n",
      "          total_loss: 0.6113199625696455\n",
      "          vf_explained_var: 0.9559618234634399\n",
      "          vf_loss: 0.582190142713842\n",
      "    num_agent_steps_sampled: 97952\n",
      "    num_agent_steps_trained: 97952\n",
      "    num_steps_sampled: 97952\n",
      "    num_steps_trained: 97952\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.71382252559727\n",
      "    ram_util_percent: 28.631569965870305\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0715203754572585\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 47.07023036523447\n",
      "    mean_inference_ms: 4.3472042903139005\n",
      "    mean_raw_obs_processing_ms: 296.91736125211173\n",
      "  time_since_restore: 8103.896216630936\n",
      "  time_this_iter_s: 410.5478780269623\n",
      "  time_total_s: 13208.802617073059\n",
      "  timers:\n",
      "    learn_throughput: 52.911\n",
      "    learn_time_ms: 37761.284\n",
      "    load_throughput: 37828.653\n",
      "    load_time_ms: 52.817\n",
      "    sample_throughput: 5.576\n",
      "    sample_time_ms: 358323.421\n",
      "    update_time_ms: 7.992\n",
      "  timestamp: 1636417287\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 97952\n",
      "  training_iteration: 74\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.4/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         13208.8</td><td style=\"text-align: right;\">97952</td><td style=\"text-align: right;\">  9.5883</td><td style=\"text-align: right;\">               22.95</td><td style=\"text-align: right;\">                2.35</td><td style=\"text-align: right;\">             42.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 99950\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-30-19\n",
      "  done: false\n",
      "  episode_len_mean: 36.97\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.130000000000006\n",
      "  episode_reward_mean: 9.269199999999994\n",
      "  episode_reward_min: 4.23000000000001\n",
      "  episodes_this_iter: 56\n",
      "  episodes_total: 1747\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2443254592872801\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.015068073893164459\n",
      "          policy_loss: -0.02474795560396853\n",
      "          total_loss: 0.994323534766833\n",
      "          vf_explained_var: 0.931327760219574\n",
      "          vf_loss: 1.0269943150736036\n",
      "    num_agent_steps_sampled: 99950\n",
      "    num_agent_steps_trained: 99950\n",
      "    num_steps_sampled: 99950\n",
      "    num_steps_trained: 99950\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.382740447957836\n",
      "    ram_util_percent: 28.60118577075099\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07131813184133043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 46.79218089805568\n",
      "    mean_inference_ms: 4.339450149938089\n",
      "    mean_raw_obs_processing_ms: 298.47092241324384\n",
      "  time_since_restore: 8636.116349935532\n",
      "  time_this_iter_s: 532.220133304596\n",
      "  time_total_s: 13741.022750377655\n",
      "  timers:\n",
      "    learn_throughput: 47.44\n",
      "    learn_time_ms: 42116.255\n",
      "    load_throughput: 37021.334\n",
      "    load_time_ms: 53.969\n",
      "    sample_throughput: 5.322\n",
      "    sample_time_ms: 375410.5\n",
      "    update_time_ms: 8.074\n",
      "  timestamp: 1636417819\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 99950\n",
      "  training_iteration: 75\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.5/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">           13741</td><td style=\"text-align: right;\">99950</td><td style=\"text-align: right;\">  9.2692</td><td style=\"text-align: right;\">               23.13</td><td style=\"text-align: right;\">                4.23</td><td style=\"text-align: right;\">             36.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 101948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-39-42\n",
      "  done: false\n",
      "  episode_len_mean: 35.04\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.130000000000006\n",
      "  episode_reward_mean: 9.298199999999996\n",
      "  episode_reward_min: 1.7000000000000113\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 1805\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2243566907587506\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.010061088463769154\n",
      "          policy_loss: -0.011651653193292163\n",
      "          total_loss: 0.9070868819952012\n",
      "          vf_explained_var: 0.9533015489578247\n",
      "          vf_loss: 0.9279637739771889\n",
      "    num_agent_steps_sampled: 101948\n",
      "    num_agent_steps_trained: 101948\n",
      "    num_steps_sampled: 101948\n",
      "    num_steps_trained: 101948\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.43237858032379\n",
      "    ram_util_percent: 28.70149439601494\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07138936983102993\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 46.639832228181206\n",
      "    mean_inference_ms: 4.3408170246307405\n",
      "    mean_raw_obs_processing_ms: 302.2164838831018\n",
      "  time_since_restore: 9199.12592792511\n",
      "  time_this_iter_s: 563.0095779895782\n",
      "  time_total_s: 14304.032328367233\n",
      "  timers:\n",
      "    learn_throughput: 42.988\n",
      "    learn_time_ms: 46477.92\n",
      "    load_throughput: 36123.831\n",
      "    load_time_ms: 55.31\n",
      "    sample_throughput: 4.948\n",
      "    sample_time_ms: 403838.294\n",
      "    update_time_ms: 8.272\n",
      "  timestamp: 1636418382\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 101948\n",
      "  training_iteration: 76\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.6/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">           14304</td><td style=\"text-align: right;\">101948</td><td style=\"text-align: right;\">  9.2982</td><td style=\"text-align: right;\">               23.13</td><td style=\"text-align: right;\">                 1.7</td><td style=\"text-align: right;\">             35.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 103946\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-44-37\n",
      "  done: false\n",
      "  episode_len_mean: 40.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.960000000000004\n",
      "  episode_reward_mean: 9.241699999999998\n",
      "  episode_reward_min: 1.7000000000000113\n",
      "  episodes_this_iter: 42\n",
      "  episodes_total: 1847\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.4001074194908143\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.009186759318344284\n",
      "          policy_loss: 0.024083018515791213\n",
      "          total_loss: 0.5895612811758405\n",
      "          vf_explained_var: 0.9662694334983826\n",
      "          vf_loss: 0.5767233049585706\n",
      "    num_agent_steps_sampled: 103946\n",
      "    num_agent_steps_trained: 103946\n",
      "    num_steps_sampled: 103946\n",
      "    num_steps_trained: 103946\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.0097619047619\n",
      "    ram_util_percent: 28.749285714285712\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07161218720573316\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 46.570221958734244\n",
      "    mean_inference_ms: 4.338461496321428\n",
      "    mean_raw_obs_processing_ms: 306.04846799482453\n",
      "  time_since_restore: 9493.364312171936\n",
      "  time_this_iter_s: 294.2383842468262\n",
      "  time_total_s: 14598.27071261406\n",
      "  timers:\n",
      "    learn_throughput: 42.989\n",
      "    learn_time_ms: 46477.109\n",
      "    load_throughput: 36143.056\n",
      "    load_time_ms: 55.28\n",
      "    sample_throughput: 5.031\n",
      "    sample_time_ms: 397105.817\n",
      "    update_time_ms: 8.264\n",
      "  timestamp: 1636418677\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 103946\n",
      "  training_iteration: 77\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.7/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         14598.3</td><td style=\"text-align: right;\">103946</td><td style=\"text-align: right;\">  9.2417</td><td style=\"text-align: right;\">               22.96</td><td style=\"text-align: right;\">                 1.7</td><td style=\"text-align: right;\">             40.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 105944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_00-52-28\n",
      "  done: false\n",
      "  episode_len_mean: 40.08\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.569999999999915\n",
      "  episode_reward_mean: 9.110499999999995\n",
      "  episode_reward_min: 1.9200000000000137\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 1901\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2548319175129845\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013463069676473299\n",
      "          policy_loss: -0.02620292493984813\n",
      "          total_loss: 0.5829726975233782\n",
      "          vf_explained_var: 0.9630655646324158\n",
      "          vf_loss: 0.6176850128741491\n",
      "    num_agent_steps_sampled: 105944\n",
      "    num_agent_steps_trained: 105944\n",
      "    num_steps_sampled: 105944\n",
      "    num_steps_trained: 105944\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.962500000000006\n",
      "    ram_util_percent: 28.704761904761902\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150960090910204\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 46.2643782490935\n",
      "    mean_inference_ms: 4.337872229806565\n",
      "    mean_raw_obs_processing_ms: 305.7976135447664\n",
      "  time_since_restore: 9964.884835720062\n",
      "  time_this_iter_s: 471.5205235481262\n",
      "  time_total_s: 15069.791236162186\n",
      "  timers:\n",
      "    learn_throughput: 42.99\n",
      "    learn_time_ms: 46476.231\n",
      "    load_throughput: 36678.516\n",
      "    load_time_ms: 54.473\n",
      "    sample_throughput: 5.069\n",
      "    sample_time_ms: 394125.309\n",
      "    update_time_ms: 8.301\n",
      "  timestamp: 1636419148\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 105944\n",
      "  training_iteration: 78\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.6/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         15069.8</td><td style=\"text-align: right;\">105944</td><td style=\"text-align: right;\">  9.1105</td><td style=\"text-align: right;\">               20.57</td><td style=\"text-align: right;\">                1.92</td><td style=\"text-align: right;\">             40.08</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 107942\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-00-35\n",
      "  done: false\n",
      "  episode_len_mean: 36.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.569999999999915\n",
      "  episode_reward_mean: 9.732799999999989\n",
      "  episode_reward_min: 1.9700000000000168\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 1958\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.1940159093765985\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014934635615275998\n",
      "          policy_loss: -0.01153114079719498\n",
      "          total_loss: 0.5860929142861139\n",
      "          vf_explained_var: 0.9594265818595886\n",
      "          vf_loss: 0.6050838270357677\n",
      "    num_agent_steps_sampled: 107942\n",
      "    num_agent_steps_trained: 107942\n",
      "    num_steps_sampled: 107942\n",
      "    num_steps_trained: 107942\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.15654676258993\n",
      "    ram_util_percent: 28.766474820143888\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07136264829786869\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.97659504983736\n",
      "    mean_inference_ms: 4.3375321112954\n",
      "    mean_raw_obs_processing_ms: 307.44772894728703\n",
      "  time_since_restore: 10451.732009649277\n",
      "  time_this_iter_s: 486.8471739292145\n",
      "  time_total_s: 15556.6384100914\n",
      "  timers:\n",
      "    learn_throughput: 42.996\n",
      "    learn_time_ms: 46469.506\n",
      "    load_throughput: 36535.446\n",
      "    load_time_ms: 54.687\n",
      "    sample_throughput: 4.988\n",
      "    sample_time_ms: 400597.934\n",
      "    update_time_ms: 8.23\n",
      "  timestamp: 1636419635\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 107942\n",
      "  training_iteration: 79\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.7/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         15556.6</td><td style=\"text-align: right;\">107942</td><td style=\"text-align: right;\">  9.7328</td><td style=\"text-align: right;\">               20.57</td><td style=\"text-align: right;\">                1.97</td><td style=\"text-align: right;\">             36.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 109940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-06-45\n",
      "  done: false\n",
      "  episode_len_mean: 36.95\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.130000000000006\n",
      "  episode_reward_mean: 10.005399999999987\n",
      "  episode_reward_min: 5.080000000000004\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 2008\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.157391905784607\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.016166385761270764\n",
      "          policy_loss: -0.02781083480942817\n",
      "          total_loss: 1.0233000482831682\n",
      "          vf_explained_var: 0.9432592391967773\n",
      "          vf_loss: 1.0578348802668707\n",
      "    num_agent_steps_sampled: 109940\n",
      "    num_agent_steps_trained: 109940\n",
      "    num_steps_sampled: 109940\n",
      "    num_steps_trained: 109940\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.53453510436433\n",
      "    ram_util_percent: 28.79373814041746\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150307930626947\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.951467833441356\n",
      "    mean_inference_ms: 4.3383587253299165\n",
      "    mean_raw_obs_processing_ms: 310.70937991424273\n",
      "  time_since_restore: 10821.633548498154\n",
      "  time_this_iter_s: 369.90153884887695\n",
      "  time_total_s: 15926.539948940277\n",
      "  timers:\n",
      "    learn_throughput: 42.989\n",
      "    learn_time_ms: 46477.301\n",
      "    load_throughput: 36121.526\n",
      "    load_time_ms: 55.313\n",
      "    sample_throughput: 4.939\n",
      "    sample_time_ms: 404544.845\n",
      "    update_time_ms: 8.15\n",
      "  timestamp: 1636420005\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109940\n",
      "  training_iteration: 80\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.7/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         15926.5</td><td style=\"text-align: right;\">109940</td><td style=\"text-align: right;\"> 10.0054</td><td style=\"text-align: right;\">               23.13</td><td style=\"text-align: right;\">                5.08</td><td style=\"text-align: right;\">             36.95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 111938\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-14-54\n",
      "  done: false\n",
      "  episode_len_mean: 36.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.130000000000006\n",
      "  episode_reward_mean: 10.001599999999991\n",
      "  episode_reward_min: 5.010000000000006\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 2063\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0338018198808034\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.014228750047386579\n",
      "          policy_loss: -0.05012822746343556\n",
      "          total_loss: 1.233716427286466\n",
      "          vf_explained_var: 0.9288076758384705\n",
      "          vf_loss: 1.2899140474342166\n",
      "    num_agent_steps_sampled: 111938\n",
      "    num_agent_steps_trained: 111938\n",
      "    num_steps_sampled: 111938\n",
      "    num_steps_trained: 111938\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.57593123209169\n",
      "    ram_util_percent: 28.89269340974212\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07143990698904243\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.89102306248955\n",
      "    mean_inference_ms: 4.331765340287602\n",
      "    mean_raw_obs_processing_ms: 315.2210335310376\n",
      "  time_since_restore: 11310.595923185349\n",
      "  time_this_iter_s: 488.9623746871948\n",
      "  time_total_s: 16415.502323627472\n",
      "  timers:\n",
      "    learn_throughput: 42.991\n",
      "    learn_time_ms: 46474.91\n",
      "    load_throughput: 35678.423\n",
      "    load_time_ms: 56.0\n",
      "    sample_throughput: 4.948\n",
      "    sample_time_ms: 403823.202\n",
      "    update_time_ms: 8.001\n",
      "  timestamp: 1636420494\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 111938\n",
      "  training_iteration: 81\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.9/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         16415.5</td><td style=\"text-align: right;\">111938</td><td style=\"text-align: right;\"> 10.0016</td><td style=\"text-align: right;\">               23.13</td><td style=\"text-align: right;\">                5.01</td><td style=\"text-align: right;\">              36.6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 113936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-22-17\n",
      "  done: false\n",
      "  episode_len_mean: 38.27\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.170000000000005\n",
      "  episode_reward_mean: 10.12009999999999\n",
      "  episode_reward_min: 1.560000000000012\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 2110\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.2856246448698498\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013040037246031049\n",
      "          policy_loss: -0.017098074690217062\n",
      "          total_loss: 0.6909475913005215\n",
      "          vf_explained_var: 0.9615551829338074\n",
      "          vf_loss: 0.7169899029391152\n",
      "    num_agent_steps_sampled: 113936\n",
      "    num_agent_steps_trained: 113936\n",
      "    num_steps_sampled: 113936\n",
      "    num_steps_trained: 113936\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.77515822784811\n",
      "    ram_util_percent: 29.007753164556963\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150596250749101\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.86172011056711\n",
      "    mean_inference_ms: 4.327832929259578\n",
      "    mean_raw_obs_processing_ms: 316.8660265416629\n",
      "  time_since_restore: 11753.788922071457\n",
      "  time_this_iter_s: 443.1929988861084\n",
      "  time_total_s: 16858.69532251358\n",
      "  timers:\n",
      "    learn_throughput: 42.994\n",
      "    learn_time_ms: 46472.113\n",
      "    load_throughput: 36033.601\n",
      "    load_time_ms: 55.448\n",
      "    sample_throughput: 5.03\n",
      "    sample_time_ms: 397191.411\n",
      "    update_time_ms: 8.655\n",
      "  timestamp: 1636420937\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 113936\n",
      "  training_iteration: 82\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.6/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         16858.7</td><td style=\"text-align: right;\">113936</td><td style=\"text-align: right;\"> 10.1201</td><td style=\"text-align: right;\">               23.17</td><td style=\"text-align: right;\">                1.56</td><td style=\"text-align: right;\">             38.27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 115934\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-32-22\n",
      "  done: false\n",
      "  episode_len_mean: 37.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.170000000000005\n",
      "  episode_reward_mean: 10.413499999999992\n",
      "  episode_reward_min: 1.560000000000012\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 2176\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0115785556180137\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.013025757743058043\n",
      "          policy_loss: -0.011179761375699725\n",
      "          total_loss: 0.6994928460745584\n",
      "          vf_explained_var: 0.9573458433151245\n",
      "          vf_loss: 0.7168806663581303\n",
      "    num_agent_steps_sampled: 115934\n",
      "    num_agent_steps_trained: 115934\n",
      "    num_steps_sampled: 115934\n",
      "    num_steps_trained: 115934\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.30104287369641\n",
      "    ram_util_percent: 28.902780996523752\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07155957651282244\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.78968344290401\n",
      "    mean_inference_ms: 4.335059644494277\n",
      "    mean_raw_obs_processing_ms: 319.3472291302718\n",
      "  time_since_restore: 12358.615469694138\n",
      "  time_this_iter_s: 604.8265476226807\n",
      "  time_total_s: 17463.52187013626\n",
      "  timers:\n",
      "    learn_throughput: 42.992\n",
      "    learn_time_ms: 46473.337\n",
      "    load_throughput: 35327.215\n",
      "    load_time_ms: 56.557\n",
      "    sample_throughput: 4.757\n",
      "    sample_time_ms: 419971.269\n",
      "    update_time_ms: 9.028\n",
      "  timestamp: 1636421542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 115934\n",
      "  training_iteration: 83\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.9/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         17463.5</td><td style=\"text-align: right;\">115934</td><td style=\"text-align: right;\"> 10.4135</td><td style=\"text-align: right;\">               23.17</td><td style=\"text-align: right;\">                1.56</td><td style=\"text-align: right;\">             37.15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 117932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-41-38\n",
      "  done: false\n",
      "  episode_len_mean: 31.66\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.049999999999997\n",
      "  episode_reward_mean: 9.506299999999992\n",
      "  episode_reward_min: 1.8600000000000145\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 2239\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.137314323300407\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.0135492561666033\n",
      "          policy_loss: 0.031007483175822668\n",
      "          total_loss: 0.9205818786507561\n",
      "          vf_explained_var: 0.9476696848869324\n",
      "          vf_loss: 0.8968827524355479\n",
      "    num_agent_steps_sampled: 117932\n",
      "    num_agent_steps_trained: 117932\n",
      "    num_steps_sampled: 117932\n",
      "    num_steps_trained: 117932\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.88045397225725\n",
      "    ram_util_percent: 28.931273644388398\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07159552198987877\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.7388563736498\n",
      "    mean_inference_ms: 4.33651876795208\n",
      "    mean_raw_obs_processing_ms: 324.5726034029362\n",
      "  time_since_restore: 12914.508530139923\n",
      "  time_this_iter_s: 555.8930604457855\n",
      "  time_total_s: 18019.414930582047\n",
      "  timers:\n",
      "    learn_throughput: 42.993\n",
      "    learn_time_ms: 46473.043\n",
      "    load_throughput: 35817.067\n",
      "    load_time_ms: 55.783\n",
      "    sample_throughput: 4.598\n",
      "    sample_time_ms: 434506.477\n",
      "    update_time_ms: 9.033\n",
      "  timestamp: 1636422098\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 117932\n",
      "  training_iteration: 84\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.8/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         18019.4</td><td style=\"text-align: right;\">117932</td><td style=\"text-align: right;\">  9.5063</td><td style=\"text-align: right;\">               23.05</td><td style=\"text-align: right;\">                1.86</td><td style=\"text-align: right;\">             31.66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 119930\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-49-52\n",
      "  done: false\n",
      "  episode_len_mean: 33.84\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.120000000000005\n",
      "  episode_reward_mean: 9.834999999999992\n",
      "  episode_reward_min: 1.9800000000000173\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2299\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0446897730940865\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01276408700384787\n",
      "          policy_loss: -0.05879712195268699\n",
      "          total_loss: 0.8872587360086895\n",
      "          vf_explained_var: 0.9506505131721497\n",
      "          vf_loss: 0.9526735247600646\n",
      "    num_agent_steps_sampled: 119930\n",
      "    num_agent_steps_trained: 119930\n",
      "    num_steps_sampled: 119930\n",
      "    num_steps_trained: 119930\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.81150568181818\n",
      "    ram_util_percent: 28.931818181818183\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07156994803607294\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.67826107257133\n",
      "    mean_inference_ms: 4.339680941122756\n",
      "    mean_raw_obs_processing_ms: 325.73621275554217\n",
      "  time_since_restore: 13408.344646930695\n",
      "  time_this_iter_s: 493.8361167907715\n",
      "  time_total_s: 18513.251047372818\n",
      "  timers:\n",
      "    learn_throughput: 42.992\n",
      "    learn_time_ms: 46474.007\n",
      "    load_throughput: 36036.964\n",
      "    load_time_ms: 55.443\n",
      "    sample_throughput: 4.639\n",
      "    sample_time_ms: 430667.216\n",
      "    update_time_ms: 9.154\n",
      "  timestamp: 1636422592\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 119930\n",
      "  training_iteration: 85\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.8/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         18513.3</td><td style=\"text-align: right;\">119930</td><td style=\"text-align: right;\">   9.835</td><td style=\"text-align: right;\">               23.12</td><td style=\"text-align: right;\">                1.98</td><td style=\"text-align: right;\">             33.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 121928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_01-58-37\n",
      "  done: false\n",
      "  episode_len_mean: 32.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.080000000000005\n",
      "  episode_reward_mean: 9.559699999999994\n",
      "  episode_reward_min: 2.280000000000016\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2359\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.0652773962134408\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.011054242350101592\n",
      "          policy_loss: 0.019146063090080306\n",
      "          total_loss: 0.8333444062443006\n",
      "          vf_explained_var: 0.9654128551483154\n",
      "          vf_loss: 0.8215348462263743\n",
      "    num_agent_steps_sampled: 121928\n",
      "    num_agent_steps_trained: 121928\n",
      "    num_steps_sampled: 121928\n",
      "    num_steps_trained: 121928\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.83663101604279\n",
      "    ram_util_percent: 28.952807486631013\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07152027198558814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.60721106215877\n",
      "    mean_inference_ms: 4.344187047067983\n",
      "    mean_raw_obs_processing_ms: 328.25818670864777\n",
      "  time_since_restore: 13932.940183401108\n",
      "  time_this_iter_s: 524.5955364704132\n",
      "  time_total_s: 19037.84658384323\n",
      "  timers:\n",
      "    learn_throughput: 42.999\n",
      "    learn_time_ms: 46465.991\n",
      "    load_throughput: 36416.088\n",
      "    load_time_ms: 54.866\n",
      "    sample_throughput: 4.681\n",
      "    sample_time_ms: 426834.75\n",
      "    update_time_ms: 9.089\n",
      "  timestamp: 1636423117\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 121928\n",
      "  training_iteration: 86\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.9/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         19037.8</td><td style=\"text-align: right;\">121928</td><td style=\"text-align: right;\">  9.5597</td><td style=\"text-align: right;\">               23.08</td><td style=\"text-align: right;\">                2.28</td><td style=\"text-align: right;\">             32.37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 123926\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-06-27\n",
      "  done: false\n",
      "  episode_len_mean: 32.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.200000000000003\n",
      "  episode_reward_mean: 9.598199999999993\n",
      "  episode_reward_min: 2.1900000000000155\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 2423\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.034100372734524\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01182809703799834\n",
      "          policy_loss: 0.020458337025982994\n",
      "          total_loss: 1.0958794362488247\n",
      "          vf_explained_var: 0.9523130655288696\n",
      "          vf_loss: 1.082213664622534\n",
      "    num_agent_steps_sampled: 123926\n",
      "    num_agent_steps_trained: 123926\n",
      "    num_steps_sampled: 123926\n",
      "    num_steps_trained: 123926\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.85976154992549\n",
      "    ram_util_percent: 29.097615499254843\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07162789903204424\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.63667267356067\n",
      "    mean_inference_ms: 4.343277271408765\n",
      "    mean_raw_obs_processing_ms: 334.75795607532825\n",
      "  time_since_restore: 14403.343005895615\n",
      "  time_this_iter_s: 470.40282249450684\n",
      "  time_total_s: 19508.249406337738\n",
      "  timers:\n",
      "    learn_throughput: 42.988\n",
      "    learn_time_ms: 46478.043\n",
      "    load_throughput: 36723.682\n",
      "    load_time_ms: 54.406\n",
      "    sample_throughput: 4.496\n",
      "    sample_time_ms: 444439.52\n",
      "    update_time_ms: 9.079\n",
      "  timestamp: 1636423587\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 123926\n",
      "  training_iteration: 87\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 32.2/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         19508.2</td><td style=\"text-align: right;\">123926</td><td style=\"text-align: right;\">  9.5982</td><td style=\"text-align: right;\">                23.2</td><td style=\"text-align: right;\">                2.19</td><td style=\"text-align: right;\">                32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 125924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-16-17\n",
      "  done: false\n",
      "  episode_len_mean: 29.07\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.200000000000003\n",
      "  episode_reward_mean: 10.214999999999998\n",
      "  episode_reward_min: 2.1900000000000155\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 2487\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.933320411897841\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01015516697762203\n",
      "          policy_loss: 0.014184952207974026\n",
      "          total_loss: 1.0353746337550027\n",
      "          vf_explained_var: 0.9618438482284546\n",
      "          vf_loss: 1.0274763284694581\n",
      "    num_agent_steps_sampled: 125924\n",
      "    num_agent_steps_trained: 125924\n",
      "    num_steps_sampled: 125924\n",
      "    num_steps_trained: 125924\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.38311533888228\n",
      "    ram_util_percent: 29.173959571938173\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07167809508500962\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.61006245682076\n",
      "    mean_inference_ms: 4.342926212476078\n",
      "    mean_raw_obs_processing_ms: 338.8996764782671\n",
      "  time_since_restore: 14993.073455810547\n",
      "  time_this_iter_s: 589.7304499149323\n",
      "  time_total_s: 20097.97985625267\n",
      "  timers:\n",
      "    learn_throughput: 42.978\n",
      "    learn_time_ms: 46488.866\n",
      "    load_throughput: 37027.402\n",
      "    load_time_ms: 53.96\n",
      "    sample_throughput: 4.379\n",
      "    sample_time_ms: 456250.609\n",
      "    update_time_ms: 9.038\n",
      "  timestamp: 1636424177\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 125924\n",
      "  training_iteration: 88\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 32.0/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">           20098</td><td style=\"text-align: right;\">125924</td><td style=\"text-align: right;\">  10.215</td><td style=\"text-align: right;\">                23.2</td><td style=\"text-align: right;\">                2.19</td><td style=\"text-align: right;\">             29.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 127922\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-23-21\n",
      "  done: false\n",
      "  episode_len_mean: 32.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.200000000000003\n",
      "  episode_reward_mean: 10.859299999999994\n",
      "  episode_reward_min: 2.5300000000000082\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 2544\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.8995607478278024\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.008147990961513812\n",
      "          policy_loss: -0.0649423785507679\n",
      "          total_loss: 0.7330140660206477\n",
      "          vf_explained_var: 0.9657805562019348\n",
      "          vf_loss: 0.8045076540538243\n",
      "    num_agent_steps_sampled: 127922\n",
      "    num_agent_steps_trained: 127922\n",
      "    num_steps_sampled: 127922\n",
      "    num_steps_trained: 127922\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.27487603305786\n",
      "    ram_util_percent: 29.069090909090907\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07149287246521091\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.529325153336885\n",
      "    mean_inference_ms: 4.338371783095177\n",
      "    mean_raw_obs_processing_ms: 342.4848171545059\n",
      "  time_since_restore: 15417.33972978592\n",
      "  time_this_iter_s: 424.2662739753723\n",
      "  time_total_s: 20522.246130228043\n",
      "  timers:\n",
      "    learn_throughput: 42.981\n",
      "    learn_time_ms: 46485.497\n",
      "    load_throughput: 37107.068\n",
      "    load_time_ms: 53.844\n",
      "    sample_throughput: 4.44\n",
      "    sample_time_ms: 449996.336\n",
      "    update_time_ms: 9.026\n",
      "  timestamp: 1636424601\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 127922\n",
      "  training_iteration: 89\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 31.9/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         20522.2</td><td style=\"text-align: right;\">127922</td><td style=\"text-align: right;\"> 10.8593</td><td style=\"text-align: right;\">                23.2</td><td style=\"text-align: right;\">                2.53</td><td style=\"text-align: right;\">             32.54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 129920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-32-07\n",
      "  done: false\n",
      "  episode_len_mean: 33.74\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.19\n",
      "  episode_reward_mean: 11.006099999999995\n",
      "  episode_reward_min: 2.410000000000013\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 2607\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.8860342942533039\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012825825856345823\n",
      "          policy_loss: -0.028723895194984618\n",
      "          total_loss: 0.7359317973433506\n",
      "          vf_explained_var: 0.9681501984596252\n",
      "          vf_loss: 0.7696682932830993\n",
      "    num_agent_steps_sampled: 129920\n",
      "    num_agent_steps_trained: 129920\n",
      "    num_steps_sampled: 129920\n",
      "    num_steps_trained: 129920\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.28946666666666\n",
      "    ram_util_percent: 29.00626666666666\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07142541451331766\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.54050656250036\n",
      "    mean_inference_ms: 4.330874608455678\n",
      "    mean_raw_obs_processing_ms: 348.6314077753586\n",
      "  time_since_restore: 15943.135658502579\n",
      "  time_this_iter_s: 525.7959287166595\n",
      "  time_total_s: 21048.042058944702\n",
      "  timers:\n",
      "    learn_throughput: 42.995\n",
      "    learn_time_ms: 46470.051\n",
      "    load_throughput: 37633.868\n",
      "    load_time_ms: 53.09\n",
      "    sample_throughput: 4.291\n",
      "    sample_time_ms: 465601.133\n",
      "    update_time_ms: 9.345\n",
      "  timestamp: 1636425127\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 129920\n",
      "  training_iteration: 90\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 32.0/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">           21048</td><td style=\"text-align: right;\">129920</td><td style=\"text-align: right;\"> 11.0061</td><td style=\"text-align: right;\">               23.19</td><td style=\"text-align: right;\">                2.41</td><td style=\"text-align: right;\">             33.74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 131918\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-38-52\n",
      "  done: false\n",
      "  episode_len_mean: 35.91\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.19\n",
      "  episode_reward_mean: 10.721899999999996\n",
      "  episode_reward_min: 0.509999999999999\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 2662\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.011393259820484\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.012000094253843492\n",
      "          policy_loss: -0.026058791311723846\n",
      "          total_loss: 0.932048050349667\n",
      "          vf_explained_var: 0.9598470330238342\n",
      "          vf_loss: 0.9646207404988153\n",
      "    num_agent_steps_sampled: 131918\n",
      "    num_agent_steps_trained: 131918\n",
      "    num_steps_sampled: 131918\n",
      "    num_steps_trained: 131918\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.41107266435986\n",
      "    ram_util_percent: 29.040657439446367\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07150321240003646\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.6606108883044\n",
      "    mean_inference_ms: 4.3312715071233745\n",
      "    mean_raw_obs_processing_ms: 350.6207069132537\n",
      "  time_since_restore: 16348.12147974968\n",
      "  time_this_iter_s: 404.98582124710083\n",
      "  time_total_s: 21453.027880191803\n",
      "  timers:\n",
      "    learn_throughput: 42.997\n",
      "    learn_time_ms: 46468.641\n",
      "    load_throughput: 38304.304\n",
      "    load_time_ms: 52.161\n",
      "    sample_throughput: 4.37\n",
      "    sample_time_ms: 457205.712\n",
      "    update_time_ms: 9.391\n",
      "  timestamp: 1636425532\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 131918\n",
      "  training_iteration: 91\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 32.1/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">           21453</td><td style=\"text-align: right;\">131918</td><td style=\"text-align: right;\"> 10.7219</td><td style=\"text-align: right;\">               23.19</td><td style=\"text-align: right;\">                0.51</td><td style=\"text-align: right;\">             35.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_1379e_00000:\n",
      "  agent_timesteps_total: 133916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-09_02-48-30\n",
      "  done: false\n",
      "  episode_len_mean: 31.87\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.210000000000004\n",
      "  episode_reward_mean: 10.969699999999996\n",
      "  episode_reward_min: 2.500000000000011\n",
      "  episodes_this_iter: 68\n",
      "  episodes_total: 2730\n",
      "  experiment_id: 73503dd6be0c4d36b5d2eea88c6f3415\n",
      "  hostname: cdsserver\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 0.6993827950386774\n",
      "          entropy_coeff: 0.009999999999999998\n",
      "          kl: 0.01341681058710361\n",
      "          policy_loss: 0.016916793017160325\n",
      "          total_loss: 1.260288166999817\n",
      "          vf_explained_var: 0.9535560011863708\n",
      "          vf_loss: 1.2463401665290197\n",
      "    num_agent_steps_sampled: 133916\n",
      "    num_agent_steps_trained: 133916\n",
      "    num_steps_sampled: 133916\n",
      "    num_steps_trained: 133916\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.1.96\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.959781287970834\n",
      "    ram_util_percent: 29.282867557715672\n",
      "  pid: 62698\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.07147580145957688\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 45.76250114163914\n",
      "    mean_inference_ms: 4.335798136617875\n",
      "    mean_raw_obs_processing_ms: 354.1226867944287\n",
      "  time_since_restore: 16925.498158454895\n",
      "  time_this_iter_s: 577.3766787052155\n",
      "  time_total_s: 22030.40455889702\n",
      "  timers:\n",
      "    learn_throughput: 42.999\n",
      "    learn_time_ms: 46466.306\n",
      "    load_throughput: 38556.601\n",
      "    load_time_ms: 51.82\n",
      "    sample_throughput: 4.245\n",
      "    sample_time_ms: 470628.174\n",
      "    update_time_ms: 8.691\n",
      "  timestamp: 1636426110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 133916\n",
      "  training_iteration: 92\n",
      "  trial_id: 1379e_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 32.4/110.1 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/16 CPUs, 1.0/1 GPUs, 0.0/56.46 GiB heap, 0.0/28.19 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_22-06-08<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_1379e_00000</td><td>RUNNING </td><td>192.168.1.96:62698</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         22030.4</td><td style=\"text-align: right;\">133916</td><td style=\"text-align: right;\"> 10.9697</td><td style=\"text-align: right;\">               23.21</td><td style=\"text-align: right;\">                 2.5</td><td style=\"text-align: right;\">             31.87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62697)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62699)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=62688)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 256,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 1000,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO MultiTask (C3, C17, C32, C8) pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/4_tasks\",\n",
    "        keep_checkpoints_num=50,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True,\n",
    "        restore=\"/IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_20-28-45/PPO_my_env_78cf0_00000_0_2021-11-08_20-28-45/checkpoint_000050/checkpoint-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
