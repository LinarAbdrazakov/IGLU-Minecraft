{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ffe905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model=6):\n",
    "        super().__init__()\n",
    "        self.d_model= d_model\n",
    "        if self.d_model % 6 != 0:\n",
    "            raise ValueError(\"d_models must be divedable on 6!\")\n",
    "\n",
    "        pe = np.zeros((9, 11, 11, d_model))\n",
    "\n",
    "        for pos_x in range(9):\n",
    "            pe[pos_x,:,:,0:d_model//3:2] = np.sin(0.33 * pos_x / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "            pe[pos_x,:,:,1:d_model//3:2] = np.cos(0.33 * pos_x / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "\n",
    "        for pos_y in range(11):\n",
    "            pe[:,pos_y,:,d_model//3:2*d_model//3:2] = np.sin(0.33 * pos_y / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "            pe[:,pos_y,:,1+d_model//3:2*d_model//3:2] = np.cos(0.33 * pos_y / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "\n",
    "        for pos_z in range(11):\n",
    "            pe[:,:,pos_z,2*d_model//3::2] = np.sin(0.33 * pos_z / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "            pe[:,:,pos_z,1+2*d_model//3::2] = np.cos(0.33 * pos_z / 10_000 ** (6*np.arange(d_model//6)/d_model))\n",
    "            \n",
    "        pe = pe.reshape(9 * 11 * 11, d_model)\n",
    "        self.pe = torch.tensor(pe).float()\n",
    "        \n",
    "    def forward(self):\n",
    "        #x = x * math.sqrt(d_model // 3) # is it needed?\n",
    "        #x = x + self.pe\n",
    "        return self.pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49072be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionNet(nn.Module):\n",
    "    def __init__(self, d_model=6, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.pe = nn.Parameter(PositionalEncoder(d_model)())\n",
    "        \n",
    "        self.img_preproc = nn.Sequential(\n",
    "            nn.Linear(512, 60),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        self.cross_attn = nn.MultiheadAttention(d_model, num_heads, batch_first=True)\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads, batch_first=True)\n",
    "        \n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv3d(6, 8, kernel_size=3, padding=1),            # perceptive field = 3\n",
    "            nn.ELU(),\n",
    "            nn.Conv3d(8, 16, kernel_size=3, padding=1),           # perceptive field = 5\n",
    "            nn.ELU(),\n",
    "            nn.Conv3d(16, 32, kernel_size=3, padding=1),          # perceptive field = 7\n",
    "            nn.ELU(),\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),          # perceptive field = 9\n",
    "            nn.ELU(),\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),         # perceptive field = 11\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool3d(kernel_size=(9, 11, 11))\n",
    "        )\n",
    "        \n",
    "        self.img_mlp = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(128 + 128, 256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, target_features, img_features):\n",
    "        batch_size = target_features.shape[0]\n",
    "        \n",
    "        img_features2 = self.img_preproc(img_features)\n",
    "        target_features = target_features.permute(0, 2, 3, 4, 1).reshape(batch_size, 9 * 11 * 11, self.d_model)\n",
    "        img_features2 = img_features2.reshape(batch_size, -1, self.d_model)\n",
    "        target_features += self.cross_attn(key=img_features2, value=img_features2, query=target_features)[0]\n",
    "        k = q = target_features + self.pe\n",
    "        target_features += self.self_attn(key=k, value=target_features, query=q)[0]\n",
    "        \n",
    "        target_features = target_features.reshape(batch_size, 9, 11, 11, self.d_model).permute(0, 4, 1, 2, 3)\n",
    "        target_features = self.conv_net(target_features).reshape(batch_size, -1)\n",
    "        \n",
    "        img_features = self.img_mlp(img_features)\n",
    "        \n",
    "        features = torch.cat([target_features, img_features], dim=1)\n",
    "        features = self.mlp(features)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae5aace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628762"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FusionNet()\n",
    "sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 6, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 256 \n",
    "        self.policy_network = FusionNet()\n",
    "        \n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        \n",
    "        features = self.policy_network(target_features, visual_features)\n",
    "        \n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2850 tasks in total.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from iglu.tasks import CustomTasks\n",
    "task_names = ['C3', 'C17', 'C32']\n",
    "tasks = []\n",
    "augmented_chats = np.load(\"data/augmented_chats.npy\")\n",
    "augmented_tasks = np.load(\"data/augmented_targets.npy\")\n",
    "augmented_target_names = np.load(\"data/augmented_target_name.npy\")\n",
    "\n",
    "for i in range(augmented_chats.shape[0]):\n",
    "    if augmented_target_names[i] in task_names or True:\n",
    "        task = (augmented_chats[i], augmented_tasks[i])\n",
    "        tasks.append(task)\n",
    "print(\"{} tasks in total.\".format(len(tasks)))\n",
    "    \n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "            \n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=125)\n",
    "    env.update_taskset(CustomTasks(tasks))\n",
    "    #env.update_taskset(TaskSet(preset=['C3', 'C17', 'C32']))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 22:20:00,059\tINFO trainable.py:76 -- Checkpoint size is 10703065 bytes\n",
      "2021-11-18 22:20:00,069\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=101983)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101983)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO (AUG ALL) pretrained (visual pretrained AngelaCNN + CrossAttn 3)</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/ab24a_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/ab24a_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211118_222000-ab24a_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101983)\u001b[0m 2021-11-18 22:20:03,556\tWARNING ppo.py:143 -- `train_batch_size` (5000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1666.\n",
      "\u001b[2m\u001b[36m(pid=101983)\u001b[0m 2021-11-18 22:20:03,556\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=101983)\u001b[0m 2021-11-18 22:20:03,556\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101983)\u001b[0m 2021-11-18 22:20:44,891\tINFO trainable.py:109 -- Trainable.setup took 43.845 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=101983)\u001b[0m 2021-11-18 22:20:44,892\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101983)\u001b[0m 2021-11-18 22:20:44,929\tINFO trainable.py:383 -- Restored on 192.168.3.5 from checkpoint: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59/PPO_my_env_ab24a_00000_0_2021-11-18_22-20-00/tmpo2ph_14wrestore_from_object/checkpoint-75\n",
      "\u001b[2m\u001b[36m(pid=101983)\u001b[0m 2021-11-18 22:20:44,929\tINFO trainable.py:390 -- Current state after restoring: {'_iteration': 75, '_timesteps_total': None, '_time_total': 13971.266767501831, '_episodes_total': 1884}\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 159846\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_22-30-34\n",
      "  done: false\n",
      "  episode_len_mean: 53.38709677419355\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.730000000000002\n",
      "  episode_reward_mean: 1.6088709677419366\n",
      "  episode_reward_min: -1.4100000000000004\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 2070\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 1.9532022974577294\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.038833283949948574\n",
      "          policy_loss: -0.012554831940756541\n",
      "          total_loss: 0.586841287453373\n",
      "          vf_explained_var: 0.6240488290786743\n",
      "          vf_loss: 0.6111614864686108\n",
      "    num_agent_steps_sampled: 159846\n",
      "    num_agent_steps_trained: 159846\n",
      "    num_steps_sampled: 159846\n",
      "    num_steps_trained: 159846\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.58040380047507\n",
      "    ram_util_percent: 44.38729216152018\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0645881568026522\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 48.16772315139957\n",
      "    mean_inference_ms: 19.590319738426246\n",
      "    mean_raw_obs_processing_ms: 1.321185313531048\n",
      "  time_since_restore: 589.867671251297\n",
      "  time_this_iter_s: 589.867671251297\n",
      "  time_total_s: 14561.134438753128\n",
      "  timers:\n",
      "    learn_throughput: 28.299\n",
      "    learn_time_ms: 353222.701\n",
      "    load_throughput: 87710.929\n",
      "    load_time_ms: 113.965\n",
      "    sample_throughput: 42.264\n",
      "    sample_time_ms: 236513.249\n",
      "    update_time_ms: 5.253\n",
      "  timestamp: 1637274634\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 159846\n",
      "  training_iteration: 76\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         14561.1</td><td style=\"text-align: right;\">159846</td><td style=\"text-align: right;\"> 1.60887</td><td style=\"text-align: right;\">               11.73</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           53.3871</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 169842\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_22-39-32\n",
      "  done: false\n",
      "  episode_len_mean: 55.849162011173185\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.680000000000003\n",
      "  episode_reward_mean: 1.2478212290502801\n",
      "  episode_reward_min: -1.4200000000000004\n",
      "  episodes_this_iter: 179\n",
      "  episodes_total: 2249\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.036359779087894\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.028732883416054317\n",
      "          policy_loss: -0.025777513589409533\n",
      "          total_loss: 0.3970910580978851\n",
      "          vf_explained_var: 0.5564389824867249\n",
      "          vf_loss: 0.43461230346581425\n",
      "    num_agent_steps_sampled: 169842\n",
      "    num_agent_steps_trained: 169842\n",
      "    num_steps_sampled: 169842\n",
      "    num_steps_trained: 169842\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.10704041720992\n",
      "    ram_util_percent: 47.64784876140808\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.057313412723543594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 38.01863169241145\n",
      "    mean_inference_ms: 19.268328919491225\n",
      "    mean_raw_obs_processing_ms: 2.1026866114768508\n",
      "  time_since_restore: 1127.1716814041138\n",
      "  time_this_iter_s: 537.3040101528168\n",
      "  time_total_s: 15098.438448905945\n",
      "  timers:\n",
      "    learn_throughput: 28.26\n",
      "    learn_time_ms: 353719.174\n",
      "    load_throughput: 88613.742\n",
      "    load_time_ms: 112.804\n",
      "    sample_throughput: 47.66\n",
      "    sample_time_ms: 209735.218\n",
      "    update_time_ms: 6.186\n",
      "  timestamp: 1637275172\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 169842\n",
      "  training_iteration: 77\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         15098.4</td><td style=\"text-align: right;\">169842</td><td style=\"text-align: right;\"> 1.24782</td><td style=\"text-align: right;\">                9.68</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           55.8492</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 179838\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_22-48-14\n",
      "  done: false\n",
      "  episode_len_mean: 55.35911602209945\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.720000000000004\n",
      "  episode_reward_mean: 1.9670165745856372\n",
      "  episode_reward_min: -1.1600000000000006\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 2430\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.45000000000000007\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.006329729710238\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02545284179714309\n",
      "          policy_loss: -0.029569393495647633\n",
      "          total_loss: 0.40919866186245984\n",
      "          vf_explained_var: 0.5892396569252014\n",
      "          vf_loss: 0.4473775730890981\n",
      "    num_agent_steps_sampled: 179838\n",
      "    num_agent_steps_trained: 179838\n",
      "    num_steps_sampled: 179838\n",
      "    num_steps_trained: 179838\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.26630872483223\n",
      "    ram_util_percent: 46.61087248322146\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05594077973358623\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.895378748340434\n",
      "    mean_inference_ms: 19.314681962018767\n",
      "    mean_raw_obs_processing_ms: 1.7774559765964408\n",
      "  time_since_restore: 1649.5972604751587\n",
      "  time_this_iter_s: 522.4255790710449\n",
      "  time_total_s: 15620.86402797699\n",
      "  timers:\n",
      "    learn_throughput: 28.24\n",
      "    learn_time_ms: 353960.965\n",
      "    load_throughput: 89087.547\n",
      "    load_time_ms: 112.204\n",
      "    sample_throughput: 51.06\n",
      "    sample_time_ms: 195771.341\n",
      "    update_time_ms: 6.592\n",
      "  timestamp: 1637275694\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 179838\n",
      "  training_iteration: 78\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         15620.9</td><td style=\"text-align: right;\">179838</td><td style=\"text-align: right;\"> 1.96702</td><td style=\"text-align: right;\">                9.72</td><td style=\"text-align: right;\">               -1.16</td><td style=\"text-align: right;\">           55.3591</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 189834\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_22-57-19\n",
      "  done: false\n",
      "  episode_len_mean: 54.333333333333336\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.840000000000002\n",
      "  episode_reward_mean: 1.8154098360655753\n",
      "  episode_reward_min: -1.1900000000000002\n",
      "  episodes_this_iter: 183\n",
      "  episodes_total: 2613\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.007105367537962\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.022433403438128614\n",
      "          policy_loss: -0.03074373633509135\n",
      "          total_loss: 0.3270955482694204\n",
      "          vf_explained_var: 0.5780500173568726\n",
      "          vf_loss: 0.36276779036920326\n",
      "    num_agent_steps_sampled: 189834\n",
      "    num_agent_steps_trained: 189834\n",
      "    num_steps_sampled: 189834\n",
      "    num_steps_trained: 189834\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.95321336760927\n",
      "    ram_util_percent: 46.59742930591259\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.055158421787373874\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.48181549826103\n",
      "    mean_inference_ms: 19.267851250961144\n",
      "    mean_raw_obs_processing_ms: 2.5723634574795313\n",
      "  time_since_restore: 2194.760808467865\n",
      "  time_this_iter_s: 545.1635479927063\n",
      "  time_total_s: 16166.027575969696\n",
      "  timers:\n",
      "    learn_throughput: 28.184\n",
      "    learn_time_ms: 354664.146\n",
      "    load_throughput: 89456.434\n",
      "    load_time_ms: 111.742\n",
      "    sample_throughput: 51.554\n",
      "    sample_time_ms: 193892.765\n",
      "    update_time_ms: 6.79\n",
      "  timestamp: 1637276239\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 189834\n",
      "  training_iteration: 79\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">           16166</td><td style=\"text-align: right;\">189834</td><td style=\"text-align: right;\"> 1.81541</td><td style=\"text-align: right;\">               11.84</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           54.3333</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 199830\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_23-06-03\n",
      "  done: false\n",
      "  episode_len_mean: 55.353591160220994\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000004\n",
      "  episode_reward_mean: 2.050939226519339\n",
      "  episode_reward_min: -1.5400000000000005\n",
      "  episodes_this_iter: 181\n",
      "  episodes_total: 2794\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.056528451978921\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01937459087232402\n",
      "          policy_loss: -0.02758696748061343\n",
      "          total_loss: 0.3250884754011507\n",
      "          vf_explained_var: 0.49230796098709106\n",
      "          vf_loss: 0.35362395232966\n",
      "    num_agent_steps_sampled: 199830\n",
      "    num_agent_steps_trained: 199830\n",
      "    num_steps_sampled: 199830\n",
      "    num_steps_trained: 199830\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.17606951871659\n",
      "    ram_util_percent: 46.082085561497315\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05542356434461825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.74410272963633\n",
      "    mean_inference_ms: 19.272443239852645\n",
      "    mean_raw_obs_processing_ms: 2.2895876371847868\n",
      "  time_since_restore: 2718.964625120163\n",
      "  time_this_iter_s: 524.203816652298\n",
      "  time_total_s: 16690.231392621994\n",
      "  timers:\n",
      "    learn_throughput: 28.192\n",
      "    learn_time_ms: 354570.37\n",
      "    load_throughput: 88967.215\n",
      "    load_time_ms: 112.356\n",
      "    sample_throughput: 52.864\n",
      "    sample_time_ms: 189089.682\n",
      "    update_time_ms: 6.308\n",
      "  timestamp: 1637276763\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 199830\n",
      "  training_iteration: 80\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         16690.2</td><td style=\"text-align: right;\">199830</td><td style=\"text-align: right;\"> 2.05094</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           55.3536</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 209826\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_23-15-06\n",
      "  done: false\n",
      "  episode_len_mean: 53.53763440860215\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.290000000000004\n",
      "  episode_reward_mean: 1.8777419354838725\n",
      "  episode_reward_min: -1.3900000000000003\n",
      "  episodes_this_iter: 186\n",
      "  episodes_total: 2980\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.047312106928193\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018749353801040442\n",
      "          policy_loss: -0.02946826264016862\n",
      "          total_loss: 0.3232933225230212\n",
      "          vf_explained_var: 0.5283754467964172\n",
      "          vf_loss: 0.35425098457852433\n",
      "    num_agent_steps_sampled: 209826\n",
      "    num_agent_steps_trained: 209826\n",
      "    num_steps_sampled: 209826\n",
      "    num_steps_trained: 209826\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.61655886157827\n",
      "    ram_util_percent: 46.371927554980594\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0549554338849108\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.366415401391436\n",
      "    mean_inference_ms: 19.259325023755448\n",
      "    mean_raw_obs_processing_ms: 2.3931851267318973\n",
      "  time_since_restore: 3261.0517559051514\n",
      "  time_this_iter_s: 542.0871307849884\n",
      "  time_total_s: 17232.318523406982\n",
      "  timers:\n",
      "    learn_throughput: 28.204\n",
      "    learn_time_ms: 354421.847\n",
      "    load_throughput: 88791.086\n",
      "    load_time_ms: 112.579\n",
      "    sample_throughput: 52.902\n",
      "    sample_time_ms: 188954.181\n",
      "    update_time_ms: 6.054\n",
      "  timestamp: 1637277306\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 209826\n",
      "  training_iteration: 81\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         17232.3</td><td style=\"text-align: right;\">209826</td><td style=\"text-align: right;\"> 1.87774</td><td style=\"text-align: right;\">               11.29</td><td style=\"text-align: right;\">               -1.39</td><td style=\"text-align: right;\">           53.5376</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 219822\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_23-23-54\n",
      "  done: false\n",
      "  episode_len_mean: 53.05820105820106\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.710000000000003\n",
      "  episode_reward_mean: 1.5287830687830704\n",
      "  episode_reward_min: -1.2400000000000002\n",
      "  episodes_this_iter: 189\n",
      "  episodes_total: 3169\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.064307653066145\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018043557160259655\n",
      "          policy_loss: -0.033351991099062804\n",
      "          total_loss: 0.31701066776981\n",
      "          vf_explained_var: 0.5444420576095581\n",
      "          vf_loss: 0.35273663205418165\n",
      "    num_agent_steps_sampled: 219822\n",
      "    num_agent_steps_trained: 219822\n",
      "    num_steps_sampled: 219822\n",
      "    num_steps_trained: 219822\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.06087533156497\n",
      "    ram_util_percent: 46.29986737400531\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05484005577644537\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.066737014216784\n",
      "    mean_inference_ms: 19.253464443484315\n",
      "    mean_raw_obs_processing_ms: 2.212307354008802\n",
      "  time_since_restore: 3789.5755577087402\n",
      "  time_this_iter_s: 528.5238018035889\n",
      "  time_total_s: 17760.84232521057\n",
      "  timers:\n",
      "    learn_throughput: 28.209\n",
      "    learn_time_ms: 354356.894\n",
      "    load_throughput: 88700.998\n",
      "    load_time_ms: 112.693\n",
      "    sample_throughput: 53.489\n",
      "    sample_time_ms: 186878.762\n",
      "    update_time_ms: 5.901\n",
      "  timestamp: 1637277834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 219822\n",
      "  training_iteration: 82\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         17760.8</td><td style=\"text-align: right;\">219822</td><td style=\"text-align: right;\"> 1.52878</td><td style=\"text-align: right;\">                9.71</td><td style=\"text-align: right;\">               -1.24</td><td style=\"text-align: right;\">           53.0582</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 229818\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_23-32-58\n",
      "  done: false\n",
      "  episode_len_mean: 52.204188481675395\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.130000000000013\n",
      "  episode_reward_mean: 1.9652356020942428\n",
      "  episode_reward_min: -1.3800000000000006\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 3360\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0604035628368575\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018441900084007964\n",
      "          policy_loss: -0.04189523018748986\n",
      "          total_loss: 0.29221773889931174\n",
      "          vf_explained_var: 0.632693350315094\n",
      "          vf_loss: 0.3360445786473233\n",
      "    num_agent_steps_sampled: 229818\n",
      "    num_agent_steps_trained: 229818\n",
      "    num_steps_sampled: 229818\n",
      "    num_steps_trained: 229818\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7431701030928\n",
      "    ram_util_percent: 47.29677835051546\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05471480864981355\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.84719353638785\n",
      "    mean_inference_ms: 19.201290931618665\n",
      "    mean_raw_obs_processing_ms: 2.52142834746654\n",
      "  time_since_restore: 4333.042495965958\n",
      "  time_this_iter_s: 543.4669382572174\n",
      "  time_total_s: 18304.30926346779\n",
      "  timers:\n",
      "    learn_throughput: 28.214\n",
      "    learn_time_ms: 354288.348\n",
      "    load_throughput: 88761.338\n",
      "    load_time_ms: 112.617\n",
      "    sample_throughput: 53.395\n",
      "    sample_time_ms: 187209.956\n",
      "    update_time_ms: 6.077\n",
      "  timestamp: 1637278378\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 229818\n",
      "  training_iteration: 83\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         18304.3</td><td style=\"text-align: right;\">229818</td><td style=\"text-align: right;\"> 1.96524</td><td style=\"text-align: right;\">                9.13</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           52.2042</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 239814\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_23-41-43\n",
      "  done: false\n",
      "  episode_len_mean: 52.375\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.660000000000002\n",
      "  episode_reward_mean: 2.1310937500000016\n",
      "  episode_reward_min: -1.3300000000000005\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 3552\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.14138939538634\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018834669596874572\n",
      "          policy_loss: -0.03535059464863651\n",
      "          total_loss: 0.3255577433416849\n",
      "          vf_explained_var: 0.6026785969734192\n",
      "          vf_loss: 0.36325212806111656\n",
      "    num_agent_steps_sampled: 239814\n",
      "    num_agent_steps_trained: 239814\n",
      "    num_steps_sampled: 239814\n",
      "    num_steps_trained: 239814\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.12897196261683\n",
      "    ram_util_percent: 46.7543391188251\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0549118839530518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.671045948433306\n",
      "    mean_inference_ms: 19.191078930960376\n",
      "    mean_raw_obs_processing_ms: 2.3746224549673656\n",
      "  time_since_restore: 4858.289631605148\n",
      "  time_this_iter_s: 525.2471356391907\n",
      "  time_total_s: 18829.55639910698\n",
      "  timers:\n",
      "    learn_throughput: 28.215\n",
      "    learn_time_ms: 354275.328\n",
      "    load_throughput: 88288.885\n",
      "    load_time_ms: 113.219\n",
      "    sample_throughput: 53.915\n",
      "    sample_time_ms: 185402.054\n",
      "    update_time_ms: 5.96\n",
      "  timestamp: 1637278903\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 239814\n",
      "  training_iteration: 84\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         18829.6</td><td style=\"text-align: right;\">239814</td><td style=\"text-align: right;\"> 2.13109</td><td style=\"text-align: right;\">                9.66</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">            52.375</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 249810\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_23-50-46\n",
      "  done: false\n",
      "  episode_len_mean: 51.635416666666664\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.640000000000006\n",
      "  episode_reward_mean: 2.212343750000002\n",
      "  episode_reward_min: -1.2500000000000004\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 3744\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1244007219272447\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018799551536624874\n",
      "          policy_loss: -0.03785467167312981\n",
      "          total_loss: 0.3435990112098427\n",
      "          vf_explained_var: 0.6463435888290405\n",
      "          vf_loss: 0.38366314463773704\n",
      "    num_agent_steps_sampled: 249810\n",
      "    num_agent_steps_trained: 249810\n",
      "    num_steps_sampled: 249810\n",
      "    num_steps_trained: 249810\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.05878552971576\n",
      "    ram_util_percent: 46.98372093023257\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05474309599226768\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.55413885377796\n",
      "    mean_inference_ms: 19.16686113260702\n",
      "    mean_raw_obs_processing_ms: 2.4421507174944295\n",
      "  time_since_restore: 5400.926034450531\n",
      "  time_this_iter_s: 542.6364028453827\n",
      "  time_total_s: 19372.192801952362\n",
      "  timers:\n",
      "    learn_throughput: 28.215\n",
      "    learn_time_ms: 354282.605\n",
      "    load_throughput: 88208.416\n",
      "    load_time_ms: 113.323\n",
      "    sample_throughput: 53.835\n",
      "    sample_time_ms: 185677.392\n",
      "    update_time_ms: 5.727\n",
      "  timestamp: 1637279446\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 249810\n",
      "  training_iteration: 85\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         19372.2</td><td style=\"text-align: right;\">249810</td><td style=\"text-align: right;\"> 2.21234</td><td style=\"text-align: right;\">                9.64</td><td style=\"text-align: right;\">               -1.25</td><td style=\"text-align: right;\">           51.6354</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 259806\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-18_23-59-37\n",
      "  done: false\n",
      "  episode_len_mean: 51.13775510204081\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.490000000000004\n",
      "  episode_reward_mean: 2.159897959183675\n",
      "  episode_reward_min: -1.2200000000000002\n",
      "  episodes_this_iter: 196\n",
      "  episodes_total: 3940\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.116515885371281\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018067073818812895\n",
      "          policy_loss: -0.034748803492106066\n",
      "          total_loss: 0.31866275272092887\n",
      "          vf_explained_var: 0.5907049179077148\n",
      "          vf_loss: 0.35628380134858817\n",
      "    num_agent_steps_sampled: 259806\n",
      "    num_agent_steps_trained: 259806\n",
      "    num_steps_sampled: 259806\n",
      "    num_steps_trained: 259806\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.17941952506597\n",
      "    ram_util_percent: 46.764116094986804\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054809730198443304\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.556951433863944\n",
      "    mean_inference_ms: 19.186533110472\n",
      "    mean_raw_obs_processing_ms: 2.3249088482792293\n",
      "  time_since_restore: 5931.96248292923\n",
      "  time_this_iter_s: 531.0364484786987\n",
      "  time_total_s: 19903.22925043106\n",
      "  timers:\n",
      "    learn_throughput: 28.207\n",
      "    learn_time_ms: 354377.133\n",
      "    load_throughput: 88276.874\n",
      "    load_time_ms: 113.235\n",
      "    sample_throughput: 55.626\n",
      "    sample_time_ms: 179700.137\n",
      "    update_time_ms: 5.54\n",
      "  timestamp: 1637279977\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259806\n",
      "  training_iteration: 86\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         19903.2</td><td style=\"text-align: right;\">259806</td><td style=\"text-align: right;\">  2.1599</td><td style=\"text-align: right;\">               11.49</td><td style=\"text-align: right;\">               -1.22</td><td style=\"text-align: right;\">           51.1378</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 269802\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_00-09-00\n",
      "  done: false\n",
      "  episode_len_mean: 49.84577114427861\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.510000000000005\n",
      "  episode_reward_mean: 2.0262189054726383\n",
      "  episode_reward_min: -1.4800000000000004\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 4141\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.109007846184045\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018043522628879\n",
      "          policy_loss: -0.033804731611454336\n",
      "          total_loss: 0.274707151898154\n",
      "          vf_explained_var: 0.6039535403251648\n",
      "          vf_loss: 0.3113328947984879\n",
      "    num_agent_steps_sampled: 269802\n",
      "    num_agent_steps_trained: 269802\n",
      "    num_steps_sampled: 269802\n",
      "    num_steps_trained: 269802\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.65360696517413\n",
      "    ram_util_percent: 48.22450248756219\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0547885403223415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.509457172161277\n",
      "    mean_inference_ms: 19.141312608326714\n",
      "    mean_raw_obs_processing_ms: 2.662050682698534\n",
      "  time_since_restore: 6495.28061914444\n",
      "  time_this_iter_s: 563.31813621521\n",
      "  time_total_s: 20466.54738664627\n",
      "  timers:\n",
      "    learn_throughput: 28.206\n",
      "    learn_time_ms: 354390.715\n",
      "    load_throughput: 88133.357\n",
      "    load_time_ms: 113.419\n",
      "    sample_throughput: 54.836\n",
      "    sample_time_ms: 182287.872\n",
      "    update_time_ms: 5.332\n",
      "  timestamp: 1637280540\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 269802\n",
      "  training_iteration: 87\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         20466.5</td><td style=\"text-align: right;\">269802</td><td style=\"text-align: right;\"> 2.02622</td><td style=\"text-align: right;\">               11.51</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           49.8458</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 279798\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_00-17-46\n",
      "  done: false\n",
      "  episode_len_mean: 52.135416666666664\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.360000000000007\n",
      "  episode_reward_mean: 2.2168229166666684\n",
      "  episode_reward_min: -1.3200000000000003\n",
      "  episodes_this_iter: 192\n",
      "  episodes_total: 4333\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.10813783340186\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017481179917641906\n",
      "          policy_loss: -0.04048486128353596\n",
      "          total_loss: 0.25676963637937344\n",
      "          vf_explained_var: 0.6538762450218201\n",
      "          vf_loss: 0.3006361790707365\n",
      "    num_agent_steps_sampled: 279798\n",
      "    num_agent_steps_trained: 279798\n",
      "    num_steps_sampled: 279798\n",
      "    num_steps_trained: 279798\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.15973333333334\n",
      "    ram_util_percent: 47.8404\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05484056322128109\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.42640632121187\n",
      "    mean_inference_ms: 19.14244999084107\n",
      "    mean_raw_obs_processing_ms: 2.5497502586674003\n",
      "  time_since_restore: 7021.244189977646\n",
      "  time_this_iter_s: 525.9635708332062\n",
      "  time_total_s: 20992.510957479477\n",
      "  timers:\n",
      "    learn_throughput: 28.208\n",
      "    learn_time_ms: 354370.118\n",
      "    load_throughput: 87931.713\n",
      "    load_time_ms: 113.679\n",
      "    sample_throughput: 54.724\n",
      "    sample_time_ms: 182663.047\n",
      "    update_time_ms: 5.07\n",
      "  timestamp: 1637281066\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 279798\n",
      "  training_iteration: 88\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         20992.5</td><td style=\"text-align: right;\">279798</td><td style=\"text-align: right;\"> 2.21682</td><td style=\"text-align: right;\">               11.36</td><td style=\"text-align: right;\">               -1.32</td><td style=\"text-align: right;\">           52.1354</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 289794\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_00-26-37\n",
      "  done: false\n",
      "  episode_len_mean: 51.54123711340206\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.119999999999987\n",
      "  episode_reward_mean: 2.5147938144329913\n",
      "  episode_reward_min: -1.1900000000000002\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 4527\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.118730873826996\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01948271589424593\n",
      "          policy_loss: -0.03383464088094999\n",
      "          total_loss: 0.3367769025755559\n",
      "          vf_explained_var: 0.6466079354286194\n",
      "          vf_loss: 0.3720726009716381\n",
      "    num_agent_steps_sampled: 289794\n",
      "    num_agent_steps_trained: 289794\n",
      "    num_steps_sampled: 289794\n",
      "    num_steps_trained: 289794\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.234036939314\n",
      "    ram_util_percent: 47.64102902374671\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05507299803455149\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.434064158602382\n",
      "    mean_inference_ms: 19.15014596892143\n",
      "    mean_raw_obs_processing_ms: 2.4613223623364693\n",
      "  time_since_restore: 7552.19214963913\n",
      "  time_this_iter_s: 530.9479596614838\n",
      "  time_total_s: 21523.45891714096\n",
      "  timers:\n",
      "    learn_throughput: 28.227\n",
      "    learn_time_ms: 354134.686\n",
      "    load_throughput: 87818.092\n",
      "    load_time_ms: 113.826\n",
      "    sample_throughput: 55.081\n",
      "    sample_time_ms: 181477.287\n",
      "    update_time_ms: 4.703\n",
      "  timestamp: 1637281597\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 289794\n",
      "  training_iteration: 89\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         21523.5</td><td style=\"text-align: right;\">289794</td><td style=\"text-align: right;\"> 2.51479</td><td style=\"text-align: right;\">               17.12</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           51.5412</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 299790\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_00-35-42\n",
      "  done: false\n",
      "  episode_len_mean: 51.689119170984455\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.260000000000009\n",
      "  episode_reward_mean: 2.0048186528497425\n",
      "  episode_reward_min: -1.3800000000000003\n",
      "  episodes_this_iter: 193\n",
      "  episodes_total: 4720\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1354408805868235\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018330106358572316\n",
      "          policy_loss: -0.04345627858668808\n",
      "          total_loss: 0.28776632504841215\n",
      "          vf_explained_var: 0.6315305233001709\n",
      "          vf_loss: 0.33401777865028526\n",
      "    num_agent_steps_sampled: 299790\n",
      "    num_agent_steps_trained: 299790\n",
      "    num_steps_sampled: 299790\n",
      "    num_steps_trained: 299790\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.98854568854567\n",
      "    ram_util_percent: 47.57799227799229\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05481893797304774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.37411346098725\n",
      "    mean_inference_ms: 19.137238717460587\n",
      "    mean_raw_obs_processing_ms: 2.6118740380981764\n",
      "  time_since_restore: 8096.921766996384\n",
      "  time_this_iter_s: 544.729617357254\n",
      "  time_total_s: 22068.188534498215\n",
      "  timers:\n",
      "    learn_throughput: 28.225\n",
      "    learn_time_ms: 354157.296\n",
      "    load_throughput: 88013.727\n",
      "    load_time_ms: 113.573\n",
      "    sample_throughput: 54.472\n",
      "    sample_time_ms: 183506.739\n",
      "    update_time_ms: 4.98\n",
      "  timestamp: 1637282142\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 299790\n",
      "  training_iteration: 90\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         22068.2</td><td style=\"text-align: right;\">299790</td><td style=\"text-align: right;\"> 2.00482</td><td style=\"text-align: right;\">                9.26</td><td style=\"text-align: right;\">               -1.38</td><td style=\"text-align: right;\">           51.6891</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 309786\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_00-44-40\n",
      "  done: false\n",
      "  episode_len_mean: 52.642105263157895\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.600000000000005\n",
      "  episode_reward_mean: 2.238263157894739\n",
      "  episode_reward_min: -1.4100000000000006\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 4910\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1027946810885125\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0183462175277999\n",
      "          policy_loss: -0.03932151315962238\n",
      "          total_loss: 0.2886414238214164\n",
      "          vf_explained_var: 0.6551259756088257\n",
      "          vf_loss: 0.3304153386099511\n",
      "    num_agent_steps_sampled: 309786\n",
      "    num_agent_steps_trained: 309786\n",
      "    num_steps_sampled: 309786\n",
      "    num_steps_trained: 309786\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.04797913950455\n",
      "    ram_util_percent: 47.39491525423729\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05460471356720757\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.297617459855314\n",
      "    mean_inference_ms: 19.126587694167483\n",
      "    mean_raw_obs_processing_ms: 2.622495941371224\n",
      "  time_since_restore: 8634.91699719429\n",
      "  time_this_iter_s: 537.9952301979065\n",
      "  time_total_s: 22606.18376469612\n",
      "  timers:\n",
      "    learn_throughput: 28.217\n",
      "    learn_time_ms: 354259.055\n",
      "    load_throughput: 88098.244\n",
      "    load_time_ms: 113.464\n",
      "    sample_throughput: 54.624\n",
      "    sample_time_ms: 182994.867\n",
      "    update_time_ms: 5.805\n",
      "  timestamp: 1637282680\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 309786\n",
      "  training_iteration: 91\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         22606.2</td><td style=\"text-align: right;\">309786</td><td style=\"text-align: right;\"> 2.23826</td><td style=\"text-align: right;\">                11.6</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           52.6421</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 319782\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_00-53-27\n",
      "  done: false\n",
      "  episode_len_mean: 52.463157894736845\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.510000000000003\n",
      "  episode_reward_mean: 2.9100526315789494\n",
      "  episode_reward_min: -1.2600000000000002\n",
      "  episodes_this_iter: 190\n",
      "  episodes_total: 5100\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1044199504526744\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01994798069329155\n",
      "          policy_loss: -0.03973337729979808\n",
      "          total_loss: 0.2948696993702791\n",
      "          vf_explained_var: 0.7235881090164185\n",
      "          vf_loss: 0.33544994432490366\n",
      "    num_agent_steps_sampled: 319782\n",
      "    num_agent_steps_trained: 319782\n",
      "    num_steps_sampled: 319782\n",
      "    num_steps_trained: 319782\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.16409574468085\n",
      "    ram_util_percent: 47.13922872340426\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05466885696547876\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.262439342132826\n",
      "    mean_inference_ms: 19.13365540675319\n",
      "    mean_raw_obs_processing_ms: 2.540159177171176\n",
      "  time_since_restore: 9161.985325574875\n",
      "  time_this_iter_s: 527.0683283805847\n",
      "  time_total_s: 23133.252093076706\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354305.274\n",
      "    load_throughput: 88155.446\n",
      "    load_time_ms: 113.391\n",
      "    sample_throughput: 54.682\n",
      "    sample_time_ms: 182803.059\n",
      "    update_time_ms: 5.746\n",
      "  timestamp: 1637283207\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319782\n",
      "  training_iteration: 92\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         23133.3</td><td style=\"text-align: right;\">319782</td><td style=\"text-align: right;\"> 2.91005</td><td style=\"text-align: right;\">               15.51</td><td style=\"text-align: right;\">               -1.26</td><td style=\"text-align: right;\">           52.4632</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 329778\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_01-02-16\n",
      "  done: false\n",
      "  episode_len_mean: 51.76288659793814\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.470000000000004\n",
      "  episode_reward_mean: 2.114123711340208\n",
      "  episode_reward_min: -1.2800000000000002\n",
      "  episodes_this_iter: 194\n",
      "  episodes_total: 5294\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1419399708868507\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018991212961536535\n",
      "          policy_loss: -0.04058729334617848\n",
      "          total_loss: 0.2327289716872959\n",
      "          vf_explained_var: 0.7003730535507202\n",
      "          vf_loss: 0.27550706072826403\n",
      "    num_agent_steps_sampled: 329778\n",
      "    num_agent_steps_trained: 329778\n",
      "    num_steps_sampled: 329778\n",
      "    num_steps_trained: 329778\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.23390728476822\n",
      "    ram_util_percent: 46.835231788079476\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05479435456769108\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.25957134981874\n",
      "    mean_inference_ms: 19.140687438174403\n",
      "    mean_raw_obs_processing_ms: 2.4694913875383255\n",
      "  time_since_restore: 9691.069149017334\n",
      "  time_this_iter_s: 529.0838234424591\n",
      "  time_total_s: 23662.335916519165\n",
      "  timers:\n",
      "    learn_throughput: 28.208\n",
      "    learn_time_ms: 354370.278\n",
      "    load_throughput: 88218.086\n",
      "    load_time_ms: 113.31\n",
      "    sample_throughput: 55.135\n",
      "    sample_time_ms: 181300.299\n",
      "    update_time_ms: 5.329\n",
      "  timestamp: 1637283736\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 329778\n",
      "  training_iteration: 93\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         23662.3</td><td style=\"text-align: right;\">329778</td><td style=\"text-align: right;\"> 2.11412</td><td style=\"text-align: right;\">               13.47</td><td style=\"text-align: right;\">               -1.28</td><td style=\"text-align: right;\">           51.7629</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 339774\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_01-11-19\n",
      "  done: false\n",
      "  episode_len_mean: 50.474747474747474\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.710000000000004\n",
      "  episode_reward_mean: 2.60318181818182\n",
      "  episode_reward_min: -1.4000000000000004\n",
      "  episodes_this_iter: 198\n",
      "  episodes_total: 5492\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1268771765461887\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019603763344010147\n",
      "          policy_loss: -0.038238153082100504\n",
      "          total_loss: 0.2860275623688481\n",
      "          vf_explained_var: 0.6839451789855957\n",
      "          vf_loss: 0.32568567594350595\n",
      "    num_agent_steps_sampled: 339774\n",
      "    num_agent_steps_trained: 339774\n",
      "    num_steps_sampled: 339774\n",
      "    num_steps_trained: 339774\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.10374677002582\n",
      "    ram_util_percent: 47.575710594315254\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054672559780247446\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.237725617732725\n",
      "    mean_inference_ms: 19.12638513512169\n",
      "    mean_raw_obs_processing_ms: 2.5752838451025157\n",
      "  time_since_restore: 10233.69924211502\n",
      "  time_this_iter_s: 542.6300930976868\n",
      "  time_total_s: 24204.96600961685\n",
      "  timers:\n",
      "    learn_throughput: 28.204\n",
      "    learn_time_ms: 354423.602\n",
      "    load_throughput: 88679.83\n",
      "    load_time_ms: 112.72\n",
      "    sample_throughput: 54.627\n",
      "    sample_time_ms: 182985.865\n",
      "    update_time_ms: 5.37\n",
      "  timestamp: 1637284279\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 339774\n",
      "  training_iteration: 94\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">           24205</td><td style=\"text-align: right;\">339774</td><td style=\"text-align: right;\"> 2.60318</td><td style=\"text-align: right;\">               13.71</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           50.4747</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:03:25.791997, resuming normal operation.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 500 encountered ({\"error\":\"Error 1040: Too many connections\"}), retrying request\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:01:38.887292, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 349770\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_01-20-39\n",
      "  done: false\n",
      "  episode_len_mean: 51.07142857142857\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.550000000000006\n",
      "  episode_reward_mean: 2.4663775510204102\n",
      "  episode_reward_min: -1.4200000000000004\n",
      "  episodes_this_iter: 196\n",
      "  episodes_total: 5688\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1335576326971553\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.020200070130574344\n",
      "          policy_loss: -0.04220770990777453\n",
      "          total_loss: 0.255559836378862\n",
      "          vf_explained_var: 0.7146111726760864\n",
      "          vf_loss: 0.2986505511018586\n",
      "    num_agent_steps_sampled: 349770\n",
      "    num_agent_steps_trained: 349770\n",
      "    num_steps_sampled: 349770\n",
      "    num_steps_trained: 349770\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.35462500000001\n",
      "    ram_util_percent: 48.315375\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054566193215820714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.23099356004209\n",
      "    mean_inference_ms: 19.111752051181643\n",
      "    mean_raw_obs_processing_ms: 2.6748113612270954\n",
      "  time_since_restore: 10794.417912721634\n",
      "  time_this_iter_s: 560.7186706066132\n",
      "  time_total_s: 24765.684680223465\n",
      "  timers:\n",
      "    learn_throughput: 28.201\n",
      "    learn_time_ms: 354460.8\n",
      "    load_throughput: 88748.402\n",
      "    load_time_ms: 112.633\n",
      "    sample_throughput: 54.103\n",
      "    sample_time_ms: 184757.162\n",
      "    update_time_ms: 5.578\n",
      "  timestamp: 1637284839\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 349770\n",
      "  training_iteration: 95\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         24765.7</td><td style=\"text-align: right;\">349770</td><td style=\"text-align: right;\"> 2.46638</td><td style=\"text-align: right;\">               13.55</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           51.0714</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:05:37.093084, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 359766\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_01-29-29\n",
      "  done: false\n",
      "  episode_len_mean: 50.421319796954315\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000005\n",
      "  episode_reward_mean: 2.7746192893401034\n",
      "  episode_reward_min: -1.6200000000000008\n",
      "  episodes_this_iter: 197\n",
      "  episodes_total: 5885\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1181244726401256\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017344910571450517\n",
      "          policy_loss: -0.038637270700027176\n",
      "          total_loss: 0.3223237641647139\n",
      "          vf_explained_var: 0.695525586605072\n",
      "          vf_loss: 0.3557996961389141\n",
      "    num_agent_steps_sampled: 359766\n",
      "    num_agent_steps_trained: 359766\n",
      "    num_steps_sampled: 359766\n",
      "    num_steps_trained: 359766\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.35284015852048\n",
      "    ram_util_percent: 47.967239101717304\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05456859567958449\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.249981471671717\n",
      "    mean_inference_ms: 19.11765200537314\n",
      "    mean_raw_obs_processing_ms: 2.6029993109096776\n",
      "  time_since_restore: 11324.318685054779\n",
      "  time_this_iter_s: 529.9007723331451\n",
      "  time_total_s: 25295.58545255661\n",
      "  timers:\n",
      "    learn_throughput: 28.202\n",
      "    learn_time_ms: 354436.989\n",
      "    load_throughput: 89052.345\n",
      "    load_time_ms: 112.249\n",
      "    sample_throughput: 54.13\n",
      "    sample_time_ms: 184667.312\n",
      "    update_time_ms: 5.672\n",
      "  timestamp: 1637285369\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 359766\n",
      "  training_iteration: 96\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         25295.6</td><td style=\"text-align: right;\">359766</td><td style=\"text-align: right;\"> 2.77462</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">               -1.62</td><td style=\"text-align: right;\">           50.4213</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 500 encountered ({\"errors\":[{\"message\":\"Error 1040: Too many connections\",\"path\":[\"project\"]}],\"data\":{\"project\":null}}), retrying request\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:58.750039, resuming normal operation.\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:41.190007, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 369762\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_01-38-30\n",
      "  done: false\n",
      "  episode_len_mean: 52.27748691099477\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.620000000000005\n",
      "  episode_reward_mean: 2.4315706806282744\n",
      "  episode_reward_min: -1.5800000000000007\n",
      "  episodes_this_iter: 191\n",
      "  episodes_total: 6076\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.114718305609791\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01629025553219718\n",
      "          policy_loss: -0.04816527342189085\n",
      "          total_loss: 0.21918457253923115\n",
      "          vf_explained_var: 0.7068532705307007\n",
      "          vf_loss: 0.2637562039878638\n",
      "    num_agent_steps_sampled: 369762\n",
      "    num_agent_steps_trained: 369762\n",
      "    num_steps_sampled: 369762\n",
      "    num_steps_trained: 369762\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.94578469520103\n",
      "    ram_util_percent: 47.60324254215305\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054452189083809915\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.186222919448486\n",
      "    mean_inference_ms: 19.104276686091556\n",
      "    mean_raw_obs_processing_ms: 2.6884701087735627\n",
      "  time_since_restore: 11864.951126813889\n",
      "  time_this_iter_s: 540.6324417591095\n",
      "  time_total_s: 25836.21789431572\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354431.997\n",
      "    load_throughput: 89060.574\n",
      "    load_time_ms: 112.238\n",
      "    sample_throughput: 54.802\n",
      "    sample_time_ms: 182403.44\n",
      "    update_time_ms: 5.872\n",
      "  timestamp: 1637285910\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 369762\n",
      "  training_iteration: 97\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         25836.2</td><td style=\"text-align: right;\">369762</td><td style=\"text-align: right;\"> 2.43157</td><td style=\"text-align: right;\">               11.62</td><td style=\"text-align: right;\">               -1.58</td><td style=\"text-align: right;\">           52.2775</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 379758\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_01-47-20\n",
      "  done: false\n",
      "  episode_len_mean: 51.3948717948718\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.430000000000007\n",
      "  episode_reward_mean: 2.6957435897435924\n",
      "  episode_reward_min: -1.2500000000000004\n",
      "  episodes_this_iter: 195\n",
      "  episodes_total: 6271\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.11464097463941\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01721488290444548\n",
      "          policy_loss: -0.04245764859411303\n",
      "          total_loss: 0.28601943819634484\n",
      "          vf_explained_var: 0.705565333366394\n",
      "          vf_loss: 0.32347839473967394\n",
      "    num_agent_steps_sampled: 379758\n",
      "    num_agent_steps_trained: 379758\n",
      "    num_steps_sampled: 379758\n",
      "    num_steps_trained: 379758\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.30887417218543\n",
      "    ram_util_percent: 47.18278145695364\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0544240828516252\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.19931344162871\n",
      "    mean_inference_ms: 19.10429375192122\n",
      "    mean_raw_obs_processing_ms: 2.6264659046961363\n",
      "  time_since_restore: 12394.559783697128\n",
      "  time_this_iter_s: 529.6086568832397\n",
      "  time_total_s: 26365.82655119896\n",
      "  timers:\n",
      "    learn_throughput: 28.204\n",
      "    learn_time_ms: 354420.406\n",
      "    load_throughput: 89053.651\n",
      "    load_time_ms: 112.247\n",
      "    sample_throughput: 54.689\n",
      "    sample_time_ms: 182779.566\n",
      "    update_time_ms: 5.772\n",
      "  timestamp: 1637286440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 379758\n",
      "  training_iteration: 98\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         26365.8</td><td style=\"text-align: right;\">379758</td><td style=\"text-align: right;\"> 2.69574</td><td style=\"text-align: right;\">               15.43</td><td style=\"text-align: right;\">               -1.25</td><td style=\"text-align: right;\">           51.3949</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:39.600672, resuming normal operation.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 500 encountered ({\"error\":\"Error 1135: Can't create a new thread (errno 11); if you are not out of available memory, you can consult the manual for a possible OS-dependent bug\"}), retrying request\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:33.278162, resuming normal operation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 389754\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_01-56-21\n",
      "  done: false\n",
      "  episode_len_mean: 50.43939393939394\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.520000000000005\n",
      "  episode_reward_mean: 2.6648989898989917\n",
      "  episode_reward_min: -1.3500000000000008\n",
      "  episodes_this_iter: 198\n",
      "  episodes_total: 6469\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1252256998096604\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017240116065177905\n",
      "          policy_loss: -0.044595019281630253\n",
      "          total_loss: 0.30599130257762747\n",
      "          vf_explained_var: 0.6922962665557861\n",
      "          vf_loss: 0.3456551515887656\n",
      "    num_agent_steps_sampled: 389754\n",
      "    num_agent_steps_trained: 389754\n",
      "    num_steps_sampled: 389754\n",
      "    num_steps_trained: 389754\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9992238033635\n",
      "    ram_util_percent: 47.49275549805952\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05428892394647162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.199453949133854\n",
      "    mean_inference_ms: 19.10147701548675\n",
      "    mean_raw_obs_processing_ms: 2.638421927411837\n",
      "  time_since_restore: 12935.893321752548\n",
      "  time_this_iter_s: 541.3335380554199\n",
      "  time_total_s: 26907.16008925438\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354426.791\n",
      "    load_throughput: 89039.618\n",
      "    load_time_ms: 112.265\n",
      "    sample_throughput: 54.382\n",
      "    sample_time_ms: 183811.957\n",
      "    update_time_ms: 5.716\n",
      "  timestamp: 1637286981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 389754\n",
      "  training_iteration: 99\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         26907.2</td><td style=\"text-align: right;\">389754</td><td style=\"text-align: right;\">  2.6649</td><td style=\"text-align: right;\">               13.52</td><td style=\"text-align: right;\">               -1.35</td><td style=\"text-align: right;\">           50.4394</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 399750\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_02-05-42\n",
      "  done: false\n",
      "  episode_len_mean: 49.925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.670000000000005\n",
      "  episode_reward_mean: 2.374950000000002\n",
      "  episode_reward_min: -1.5400000000000007\n",
      "  episodes_this_iter: 200\n",
      "  episodes_total: 6669\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1224945125809636\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015978475212125153\n",
      "          policy_loss: -0.047905664938774586\n",
      "          total_loss: 0.2034526586458226\n",
      "          vf_explained_var: 0.7365640997886658\n",
      "          vf_loss: 0.24831595988869368\n",
      "    num_agent_steps_sampled: 399750\n",
      "    num_agent_steps_trained: 399750\n",
      "    num_steps_sampled: 399750\n",
      "    num_steps_trained: 399750\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.63550000000001\n",
      "    ram_util_percent: 47.474125\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05427813664774748\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.194930357975462\n",
      "    mean_inference_ms: 19.08353011932489\n",
      "    mean_raw_obs_processing_ms: 2.72647031376673\n",
      "  time_since_restore: 13496.490614891052\n",
      "  time_this_iter_s: 560.597293138504\n",
      "  time_total_s: 27467.757382392883\n",
      "  timers:\n",
      "    learn_throughput: 28.205\n",
      "    learn_time_ms: 354410.965\n",
      "    load_throughput: 89198.039\n",
      "    load_time_ms: 112.065\n",
      "    sample_throughput: 53.911\n",
      "    sample_time_ms: 185415.4\n",
      "    update_time_ms: 5.446\n",
      "  timestamp: 1637287542\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 399750\n",
      "  training_iteration: 100\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         27467.8</td><td style=\"text-align: right;\">399750</td><td style=\"text-align: right;\"> 2.37495</td><td style=\"text-align: right;\">               11.67</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">            49.925</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 409746\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_02-15-17\n",
      "  done: false\n",
      "  episode_len_mean: 49.835\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.730000000000004\n",
      "  episode_reward_mean: 2.543100000000002\n",
      "  episode_reward_min: -1.4100000000000004\n",
      "  episodes_this_iter: 200\n",
      "  episodes_total: 6869\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1109789922294846\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01630133136733677\n",
      "          policy_loss: -0.048107423643558425\n",
      "          total_loss: 0.22996303783535246\n",
      "          vf_explained_var: 0.7589372396469116\n",
      "          vf_loss: 0.27442260381717043\n",
      "    num_agent_steps_sampled: 409746\n",
      "    num_agent_steps_trained: 409746\n",
      "    num_steps_sampled: 409746\n",
      "    num_steps_trained: 409746\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.27073170731707\n",
      "    ram_util_percent: 48.45097560975609\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05421724377581359\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.20933586386751\n",
      "    mean_inference_ms: 19.065606715643856\n",
      "    mean_raw_obs_processing_ms: 2.921247746359259\n",
      "  time_since_restore: 14071.658176898956\n",
      "  time_this_iter_s: 575.167562007904\n",
      "  time_total_s: 28042.924944400787\n",
      "  timers:\n",
      "    learn_throughput: 28.209\n",
      "    learn_time_ms: 354352.764\n",
      "    load_throughput: 89094.849\n",
      "    load_time_ms: 112.195\n",
      "    sample_throughput: 52.835\n",
      "    sample_time_ms: 189191.71\n",
      "    update_time_ms: 4.457\n",
      "  timestamp: 1637288117\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 409746\n",
      "  training_iteration: 101\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         28042.9</td><td style=\"text-align: right;\">409746</td><td style=\"text-align: right;\">  2.5431</td><td style=\"text-align: right;\">                9.73</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">            49.835</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 419742\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_02-24-16\n",
      "  done: false\n",
      "  episode_len_mean: 49.950248756218905\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.610000000000005\n",
      "  episode_reward_mean: 2.7194029850746286\n",
      "  episode_reward_min: -1.5700000000000007\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 7070\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.101180482006456\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016528843087667378\n",
      "          policy_loss: -0.04643746427152573\n",
      "          total_loss: 0.2533761336186385\n",
      "          vf_explained_var: 0.7308608293533325\n",
      "          vf_loss: 0.2957222229262522\n",
      "    num_agent_steps_sampled: 419742\n",
      "    num_agent_steps_trained: 419742\n",
      "    num_steps_sampled: 419742\n",
      "    num_steps_trained: 419742\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.35454545454546\n",
      "    ram_util_percent: 47.74558441558441\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05421925808566584\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.27873822005311\n",
      "    mean_inference_ms: 19.069560219143458\n",
      "    mean_raw_obs_processing_ms: 2.86533159681098\n",
      "  time_since_restore: 14610.892251491547\n",
      "  time_this_iter_s: 539.2340745925903\n",
      "  time_total_s: 28582.159018993378\n",
      "  timers:\n",
      "    learn_throughput: 28.211\n",
      "    learn_time_ms: 354331.145\n",
      "    load_throughput: 89073.497\n",
      "    load_time_ms: 112.222\n",
      "    sample_throughput: 52.492\n",
      "    sample_time_ms: 190429.556\n",
      "    update_time_ms: 4.773\n",
      "  timestamp: 1637288656\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 419742\n",
      "  training_iteration: 102\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         28582.2</td><td style=\"text-align: right;\">419742</td><td style=\"text-align: right;\">  2.7194</td><td style=\"text-align: right;\">               11.61</td><td style=\"text-align: right;\">               -1.57</td><td style=\"text-align: right;\">           49.9502</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 429738\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_02-33-25\n",
      "  done: false\n",
      "  episode_len_mean: 50.35353535353536\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.520000000000005\n",
      "  episode_reward_mean: 2.6353030303030325\n",
      "  episode_reward_min: -1.6300000000000008\n",
      "  episodes_this_iter: 198\n",
      "  episodes_total: 7268\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.093954307367524\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016997459596350704\n",
      "          policy_loss: -0.050104112619918664\n",
      "          total_loss: 0.20647217916676383\n",
      "          vf_explained_var: 0.7146643400192261\n",
      "          vf_loss: 0.2517009448783704\n",
      "    num_agent_steps_sampled: 429738\n",
      "    num_agent_steps_trained: 429738\n",
      "    num_steps_sampled: 429738\n",
      "    num_steps_trained: 429738\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.11877394636015\n",
      "    ram_util_percent: 47.727713920817365\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0542632690275094\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.321359344429606\n",
      "    mean_inference_ms: 19.06727208459682\n",
      "    mean_raw_obs_processing_ms: 2.8637509324034793\n",
      "  time_since_restore: 15159.679894924164\n",
      "  time_this_iter_s: 548.7876434326172\n",
      "  time_total_s: 29130.946662425995\n",
      "  timers:\n",
      "    learn_throughput: 28.212\n",
      "    learn_time_ms: 354315.645\n",
      "    load_throughput: 89012.755\n",
      "    load_time_ms: 112.299\n",
      "    sample_throughput: 51.95\n",
      "    sample_time_ms: 192414.591\n",
      "    update_time_ms: 4.875\n",
      "  timestamp: 1637289205\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 429738\n",
      "  training_iteration: 103\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         29130.9</td><td style=\"text-align: right;\">429738</td><td style=\"text-align: right;\">  2.6353</td><td style=\"text-align: right;\">               11.52</td><td style=\"text-align: right;\">               -1.63</td><td style=\"text-align: right;\">           50.3535</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 439734\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_02-42-33\n",
      "  done: false\n",
      "  episode_len_mean: 50.707070707070706\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.740000000000004\n",
      "  episode_reward_mean: 2.7489393939393962\n",
      "  episode_reward_min: -1.6700000000000006\n",
      "  episodes_this_iter: 198\n",
      "  episodes_total: 7466\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.080502146147341\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016043996423119683\n",
      "          policy_loss: -0.04764196864261136\n",
      "          total_loss: 0.20788929754755708\n",
      "          vf_explained_var: 0.7304216027259827\n",
      "          vf_loss: 0.2519694689070305\n",
      "    num_agent_steps_sampled: 439734\n",
      "    num_agent_steps_trained: 439734\n",
      "    num_steps_sampled: 439734\n",
      "    num_steps_trained: 439734\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.68015364916774\n",
      "    ram_util_percent: 47.21984635083226\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05414541096593009\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.342042215086007\n",
      "    mean_inference_ms: 19.07233595484397\n",
      "    mean_raw_obs_processing_ms: 2.868184210816619\n",
      "  time_since_restore: 15707.491506576538\n",
      "  time_this_iter_s: 547.8116116523743\n",
      "  time_total_s: 29678.75827407837\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354300.885\n",
      "    load_throughput: 88919.968\n",
      "    load_time_ms: 112.416\n",
      "    sample_throughput: 51.807\n",
      "    sample_time_ms: 192947.622\n",
      "    update_time_ms: 4.75\n",
      "  timestamp: 1637289753\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 439734\n",
      "  training_iteration: 104\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         29678.8</td><td style=\"text-align: right;\">439734</td><td style=\"text-align: right;\"> 2.74894</td><td style=\"text-align: right;\">               11.74</td><td style=\"text-align: right;\">               -1.67</td><td style=\"text-align: right;\">           50.7071</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 449730\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_02-51-40\n",
      "  done: false\n",
      "  episode_len_mean: 50.18181818181818\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.720000000000004\n",
      "  episode_reward_mean: 2.723636363636366\n",
      "  episode_reward_min: -1.4600000000000006\n",
      "  episodes_this_iter: 198\n",
      "  episodes_total: 7664\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.116172733364335\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016402713855117726\n",
      "          policy_loss: -0.04650248005904337\n",
      "          total_loss: 0.2000929121837142\n",
      "          vf_explained_var: 0.7716162204742432\n",
      "          vf_loss: 0.24284549859271995\n",
      "    num_agent_steps_sampled: 449730\n",
      "    num_agent_steps_trained: 449730\n",
      "    num_steps_sampled: 449730\n",
      "    num_steps_trained: 449730\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.17528809218949\n",
      "    ram_util_percent: 47.79308578745198\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05407016538588715\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.349340477744356\n",
      "    mean_inference_ms: 19.070640725817945\n",
      "    mean_raw_obs_processing_ms: 2.8697722313546774\n",
      "  time_since_restore: 16254.467222929\n",
      "  time_this_iter_s: 546.9757163524628\n",
      "  time_total_s: 30225.733990430832\n",
      "  timers:\n",
      "    learn_throughput: 28.216\n",
      "    learn_time_ms: 354267.578\n",
      "    load_throughput: 88940.453\n",
      "    load_time_ms: 112.39\n",
      "    sample_throughput: 52.169\n",
      "    sample_time_ms: 191606.29\n",
      "    update_time_ms: 4.752\n",
      "  timestamp: 1637290300\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 449730\n",
      "  training_iteration: 105\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         30225.7</td><td style=\"text-align: right;\">449730</td><td style=\"text-align: right;\"> 2.72364</td><td style=\"text-align: right;\">               13.72</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           50.1818</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 459726\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_03-00-32\n",
      "  done: false\n",
      "  episode_len_mean: 50.13930348258707\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.590000000000005\n",
      "  episode_reward_mean: 2.503034825870649\n",
      "  episode_reward_min: -1.4500000000000006\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 7865\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1198166593490355\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016972643895740904\n",
      "          policy_loss: -0.05213744043745961\n",
      "          total_loss: 0.20284682505247562\n",
      "          vf_explained_var: 0.7612043619155884\n",
      "          vf_loss: 0.25040522970476126\n",
      "    num_agent_steps_sampled: 459726\n",
      "    num_agent_steps_trained: 459726\n",
      "    num_steps_sampled: 459726\n",
      "    num_steps_trained: 459726\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.22941952506598\n",
      "    ram_util_percent: 47.99868073878628\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05410932571017821\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.378592077493405\n",
      "    mean_inference_ms: 19.070894736209663\n",
      "    mean_raw_obs_processing_ms: 2.819693470696215\n",
      "  time_since_restore: 16786.317467212677\n",
      "  time_this_iter_s: 531.8502442836761\n",
      "  time_total_s: 30757.584234714508\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354309.269\n",
      "    load_throughput: 88942.661\n",
      "    load_time_ms: 112.387\n",
      "    sample_throughput: 52.128\n",
      "    sample_time_ms: 191759.979\n",
      "    update_time_ms: 4.779\n",
      "  timestamp: 1637290832\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 459726\n",
      "  training_iteration: 106\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         30757.6</td><td style=\"text-align: right;\">459726</td><td style=\"text-align: right;\"> 2.50303</td><td style=\"text-align: right;\">                9.59</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           50.1393</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 469722\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_03-09-39\n",
      "  done: false\n",
      "  episode_len_mean: 48.74634146341464\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.550000000000006\n",
      "  episode_reward_mean: 2.4829756097560995\n",
      "  episode_reward_min: -1.6600000000000008\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 8070\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1119358144132008\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01620910618690701\n",
      "          policy_loss: -0.05265604673534628\n",
      "          total_loss: 0.19069059616616885\n",
      "          vf_explained_var: 0.7539527416229248\n",
      "          vf_loss: 0.2398484216976806\n",
      "    num_agent_steps_sampled: 469722\n",
      "    num_agent_steps_trained: 469722\n",
      "    num_steps_sampled: 469722\n",
      "    num_steps_trained: 469722\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9314980793854\n",
      "    ram_util_percent: 48.31971830985916\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05399489231658813\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.4020425401601\n",
      "    mean_inference_ms: 19.068749782645266\n",
      "    mean_raw_obs_processing_ms: 2.824375280118958\n",
      "  time_since_restore: 17333.33708167076\n",
      "  time_this_iter_s: 547.0196144580841\n",
      "  time_total_s: 31304.603849172592\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354307.287\n",
      "    load_throughput: 89146.698\n",
      "    load_time_ms: 112.13\n",
      "    sample_throughput: 51.954\n",
      "    sample_time_ms: 192401.14\n",
      "    update_time_ms: 4.818\n",
      "  timestamp: 1637291379\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 469722\n",
      "  training_iteration: 107\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         31304.6</td><td style=\"text-align: right;\">469722</td><td style=\"text-align: right;\"> 2.48298</td><td style=\"text-align: right;\">               11.55</td><td style=\"text-align: right;\">               -1.66</td><td style=\"text-align: right;\">           48.7463</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 479718\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_03-19-16\n",
      "  done: false\n",
      "  episode_len_mean: 47.91304347826087\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.260000000000005\n",
      "  episode_reward_mean: 3.0102898550724664\n",
      "  episode_reward_min: -1.33\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 8277\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.087783662286628\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017225883733687605\n",
      "          policy_loss: -0.05272283078966549\n",
      "          total_loss: 0.22108700051295058\n",
      "          vf_explained_var: 0.7719882726669312\n",
      "          vf_loss: 0.2685258578980364\n",
      "    num_agent_steps_sampled: 479718\n",
      "    num_agent_steps_trained: 479718\n",
      "    num_steps_sampled: 479718\n",
      "    num_steps_trained: 479718\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.27363304981776\n",
      "    ram_util_percent: 48.76002430133657\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05399290927181149\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.418070250062858\n",
      "    mean_inference_ms: 19.056425049064558\n",
      "    mean_raw_obs_processing_ms: 2.940419063830273\n",
      "  time_since_restore: 17910.11781668663\n",
      "  time_this_iter_s: 576.7807350158691\n",
      "  time_total_s: 31881.38458418846\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354303.772\n",
      "    load_throughput: 89171.423\n",
      "    load_time_ms: 112.099\n",
      "    sample_throughput: 50.71\n",
      "    sample_time_ms: 197121.682\n",
      "    update_time_ms: 4.978\n",
      "  timestamp: 1637291956\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 479718\n",
      "  training_iteration: 108\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         31881.4</td><td style=\"text-align: right;\">479718</td><td style=\"text-align: right;\"> 3.01029</td><td style=\"text-align: right;\">               13.26</td><td style=\"text-align: right;\">               -1.33</td><td style=\"text-align: right;\">            47.913</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 489714\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_03-28-11\n",
      "  done: false\n",
      "  episode_len_mean: 48.73300970873787\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.780000000000003\n",
      "  episode_reward_mean: 2.727961165048546\n",
      "  episode_reward_min: -1.3900000000000006\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 8483\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0901099593285095\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01695930430784111\n",
      "          policy_loss: -0.05204828778394688\n",
      "          total_loss: 0.2032390396360083\n",
      "          vf_explained_var: 0.7970628142356873\n",
      "          vf_loss: 0.2504314831706759\n",
      "    num_agent_steps_sampled: 489714\n",
      "    num_agent_steps_trained: 489714\n",
      "    num_steps_sampled: 489714\n",
      "    num_steps_trained: 489714\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.2651376146789\n",
      "    ram_util_percent: 47.87116644823067\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053951214351715335\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.465072090457014\n",
      "    mean_inference_ms: 19.063065545543036\n",
      "    mean_raw_obs_processing_ms: 2.8915534274378665\n",
      "  time_since_restore: 18445.45372056961\n",
      "  time_this_iter_s: 535.3359038829803\n",
      "  time_total_s: 32416.72048807144\n",
      "  timers:\n",
      "    learn_throughput: 28.217\n",
      "    learn_time_ms: 354255.848\n",
      "    load_throughput: 88960.117\n",
      "    load_time_ms: 112.365\n",
      "    sample_throughput: 50.852\n",
      "    sample_time_ms: 196569.361\n",
      "    update_time_ms: 5.385\n",
      "  timestamp: 1637292491\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 489714\n",
      "  training_iteration: 109\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         32416.7</td><td style=\"text-align: right;\">489714</td><td style=\"text-align: right;\"> 2.72796</td><td style=\"text-align: right;\">               11.78</td><td style=\"text-align: right;\">               -1.39</td><td style=\"text-align: right;\">            48.733</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 499710\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_03-37-49\n",
      "  done: false\n",
      "  episode_len_mean: 47.680952380952384\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.580000000000005\n",
      "  episode_reward_mean: 2.941476190476193\n",
      "  episode_reward_min: -1.3100000000000003\n",
      "  episodes_this_iter: 210\n",
      "  episodes_total: 8693\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0815262493359517\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017575099968219446\n",
      "          policy_loss: -0.05507742276031824\n",
      "          total_loss: 0.19634034795446467\n",
      "          vf_explained_var: 0.821672260761261\n",
      "          vf_loss: 0.24554085034360906\n",
      "    num_agent_steps_sampled: 499710\n",
      "    num_agent_steps_trained: 499710\n",
      "    num_steps_sampled: 499710\n",
      "    num_steps_trained: 499710\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.56993939393939\n",
      "    ram_util_percent: 48.12872727272727\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05388651366590019\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.464223636975206\n",
      "    mean_inference_ms: 19.043287673445892\n",
      "    mean_raw_obs_processing_ms: 3.005916431942208\n",
      "  time_since_restore: 19023.605705022812\n",
      "  time_this_iter_s: 578.1519844532013\n",
      "  time_total_s: 32994.87247252464\n",
      "  timers:\n",
      "    learn_throughput: 28.218\n",
      "    learn_time_ms: 354239.908\n",
      "    load_throughput: 88700.148\n",
      "    load_time_ms: 112.694\n",
      "    sample_throughput: 50.398\n",
      "    sample_time_ms: 198339.978\n",
      "    update_time_ms: 5.742\n",
      "  timestamp: 1637293069\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 499710\n",
      "  training_iteration: 110\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         32994.9</td><td style=\"text-align: right;\">499710</td><td style=\"text-align: right;\"> 2.94148</td><td style=\"text-align: right;\">               11.58</td><td style=\"text-align: right;\">               -1.31</td><td style=\"text-align: right;\">            47.681</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 509706\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_03-46-45\n",
      "  done: false\n",
      "  episode_len_mean: 48.34466019417476\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.800000000000002\n",
      "  episode_reward_mean: 2.8831067961165076\n",
      "  episode_reward_min: -1.2800000000000002\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 8899\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0957370328855323\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018159608449532152\n",
      "          policy_loss: -0.0553634823724872\n",
      "          total_loss: 0.20544099917995529\n",
      "          vf_explained_var: 0.788053572177887\n",
      "          vf_loss: 0.254181947733975\n",
      "    num_agent_steps_sampled: 509706\n",
      "    num_agent_steps_trained: 509706\n",
      "    num_steps_sampled: 509706\n",
      "    num_steps_trained: 509706\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.32222222222222\n",
      "    ram_util_percent: 47.7443137254902\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05398809526083507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.50638159107881\n",
      "    mean_inference_ms: 19.047883742943394\n",
      "    mean_raw_obs_processing_ms: 2.9561089413253923\n",
      "  time_since_restore: 19559.68337583542\n",
      "  time_this_iter_s: 536.0776708126068\n",
      "  time_total_s: 33530.95014333725\n",
      "  timers:\n",
      "    learn_throughput: 28.215\n",
      "    learn_time_ms: 354280.4\n",
      "    load_throughput: 88781.779\n",
      "    load_time_ms: 112.591\n",
      "    sample_throughput: 51.422\n",
      "    sample_time_ms: 194390.364\n",
      "    update_time_ms: 6.15\n",
      "  timestamp: 1637293605\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 509706\n",
      "  training_iteration: 111\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">           33531</td><td style=\"text-align: right;\">509706</td><td style=\"text-align: right;\"> 2.88311</td><td style=\"text-align: right;\">                13.8</td><td style=\"text-align: right;\">               -1.28</td><td style=\"text-align: right;\">           48.3447</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 519702\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_03-55-52\n",
      "  done: false\n",
      "  episode_len_mean: 48.56038647342995\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.680000000000005\n",
      "  episode_reward_mean: 2.945942028985509\n",
      "  episode_reward_min: -1.3400000000000005\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 9106\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1171973317981245\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01808102990645973\n",
      "          policy_loss: -0.057249166836614844\n",
      "          total_loss: 0.18758231650667312\n",
      "          vf_explained_var: 0.8379780650138855\n",
      "          vf_loss: 0.23854289205640136\n",
      "    num_agent_steps_sampled: 519702\n",
      "    num_agent_steps_trained: 519702\n",
      "    num_steps_sampled: 519702\n",
      "    num_steps_trained: 519702\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.02816901408451\n",
      "    ram_util_percent: 48.11856594110116\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05404406702244013\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.537812637758364\n",
      "    mean_inference_ms: 19.042139760113947\n",
      "    mean_raw_obs_processing_ms: 2.9608316209168595\n",
      "  time_since_restore: 20106.956452846527\n",
      "  time_this_iter_s: 547.2730770111084\n",
      "  time_total_s: 34078.22322034836\n",
      "  timers:\n",
      "    learn_throughput: 28.215\n",
      "    learn_time_ms: 354284.879\n",
      "    load_throughput: 88793.963\n",
      "    load_time_ms: 112.575\n",
      "    sample_throughput: 51.212\n",
      "    sample_time_ms: 195190.121\n",
      "    update_time_ms: 6.093\n",
      "  timestamp: 1637294152\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 519702\n",
      "  training_iteration: 112\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         34078.2</td><td style=\"text-align: right;\">519702</td><td style=\"text-align: right;\"> 2.94594</td><td style=\"text-align: right;\">                9.68</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           48.5604</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 529698\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_04-05-02\n",
      "  done: false\n",
      "  episode_len_mean: 47.87980769230769\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.490000000000007\n",
      "  episode_reward_mean: 2.610096153846156\n",
      "  episode_reward_min: -1.5600000000000005\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 9314\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1195581986961596\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018254066477094034\n",
      "          policy_loss: -0.04817917147751483\n",
      "          total_loss: 0.1987484480491668\n",
      "          vf_explained_var: 0.8285041451454163\n",
      "          vf_loss: 0.24039983873753004\n",
      "    num_agent_steps_sampled: 529698\n",
      "    num_agent_steps_trained: 529698\n",
      "    num_steps_sampled: 529698\n",
      "    num_steps_trained: 529698\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.03961783439489\n",
      "    ram_util_percent: 48.21783439490446\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05411754418997206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.574421972757058\n",
      "    mean_inference_ms: 19.04213272053413\n",
      "    mean_raw_obs_processing_ms: 2.961129896837641\n",
      "  time_since_restore: 20656.89475798607\n",
      "  time_this_iter_s: 549.9383051395416\n",
      "  time_total_s: 34628.1615254879\n",
      "  timers:\n",
      "    learn_throughput: 28.215\n",
      "    learn_time_ms: 354282.4\n",
      "    load_throughput: 88651.928\n",
      "    load_time_ms: 112.756\n",
      "    sample_throughput: 51.181\n",
      "    sample_time_ms: 195308.03\n",
      "    update_time_ms: 6.158\n",
      "  timestamp: 1637294702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 529698\n",
      "  training_iteration: 113\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         34628.2</td><td style=\"text-align: right;\">529698</td><td style=\"text-align: right;\">  2.6101</td><td style=\"text-align: right;\">               11.49</td><td style=\"text-align: right;\">               -1.56</td><td style=\"text-align: right;\">           47.8798</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 539694\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_04-14-07\n",
      "  done: false\n",
      "  episode_len_mean: 49.02439024390244\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.410000000000009\n",
      "  episode_reward_mean: 3.0673170731707344\n",
      "  episode_reward_min: -1.4000000000000004\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 9519\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.120601083834966\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01922168768645145\n",
      "          policy_loss: -0.05505720004128299\n",
      "          total_loss: 0.21044653127586696\n",
      "          vf_explained_var: 0.801264226436615\n",
      "          vf_loss: 0.25751680459950615\n",
      "    num_agent_steps_sampled: 539694\n",
      "    num_agent_steps_trained: 539694\n",
      "    num_steps_sampled: 539694\n",
      "    num_steps_trained: 539694\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.92059202059201\n",
      "    ram_util_percent: 48.356113256113254\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05413203883845257\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.584296015847354\n",
      "    mean_inference_ms: 19.04119798028835\n",
      "    mean_raw_obs_processing_ms: 2.9591232227167406\n",
      "  time_since_restore: 21201.72414469719\n",
      "  time_this_iter_s: 544.8293867111206\n",
      "  time_total_s: 35172.99091219902\n",
      "  timers:\n",
      "    learn_throughput: 28.216\n",
      "    learn_time_ms: 354266.121\n",
      "    load_throughput: 88823.967\n",
      "    load_time_ms: 112.537\n",
      "    sample_throughput: 51.255\n",
      "    sample_time_ms: 195026.006\n",
      "    update_time_ms: 6.622\n",
      "  timestamp: 1637295247\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 539694\n",
      "  training_iteration: 114\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">           35173</td><td style=\"text-align: right;\">539694</td><td style=\"text-align: right;\"> 3.06732</td><td style=\"text-align: right;\">               11.41</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           49.0244</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 549690\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_04-23-16\n",
      "  done: false\n",
      "  episode_len_mean: 48.33980582524272\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.550000000000006\n",
      "  episode_reward_mean: 3.1742233009708767\n",
      "  episode_reward_min: -1.4200000000000004\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 9725\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.0998347274510256\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018042531024264806\n",
      "          policy_loss: -0.055181094752199907\n",
      "          total_loss: 0.2159024575893626\n",
      "          vf_explained_var: 0.8023256659507751\n",
      "          vf_loss: 0.26467980692596976\n",
      "    num_agent_steps_sampled: 549690\n",
      "    num_agent_steps_trained: 549690\n",
      "    num_steps_sampled: 549690\n",
      "    num_steps_trained: 549690\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.85210727969347\n",
      "    ram_util_percent: 48.413026819923374\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05415647000136612\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.615361280146516\n",
      "    mean_inference_ms: 19.040936299729374\n",
      "    mean_raw_obs_processing_ms: 2.961672922564648\n",
      "  time_since_restore: 21750.596143484116\n",
      "  time_this_iter_s: 548.8719987869263\n",
      "  time_total_s: 35721.86291098595\n",
      "  timers:\n",
      "    learn_throughput: 28.217\n",
      "    learn_time_ms: 354255.362\n",
      "    load_throughput: 88779.335\n",
      "    load_time_ms: 112.594\n",
      "    sample_throughput: 51.202\n",
      "    sample_time_ms: 195226.623\n",
      "    update_time_ms: 6.773\n",
      "  timestamp: 1637295796\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 549690\n",
      "  training_iteration: 115\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         35721.9</td><td style=\"text-align: right;\">549690</td><td style=\"text-align: right;\"> 3.17422</td><td style=\"text-align: right;\">               11.55</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           48.3398</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 559686\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_04-32-34\n",
      "  done: false\n",
      "  episode_len_mean: 47.507109004739334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.490000000000009\n",
      "  episode_reward_mean: 2.863127962085311\n",
      "  episode_reward_min: -1.4400000000000004\n",
      "  episodes_this_iter: 211\n",
      "  episodes_total: 9936\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1227961564399154\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019263017289830927\n",
      "          policy_loss: -0.05861408990239722\n",
      "          total_loss: 0.20953453205276754\n",
      "          vf_explained_var: 0.8164215683937073\n",
      "          vf_loss: 0.2601208768904688\n",
      "    num_agent_steps_sampled: 559686\n",
      "    num_agent_steps_trained: 559686\n",
      "    num_steps_sampled: 559686\n",
      "    num_steps_trained: 559686\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77361809045225\n",
      "    ram_util_percent: 48.71708542713568\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054188407565854434\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.629360491424613\n",
      "    mean_inference_ms: 19.0283468963798\n",
      "    mean_raw_obs_processing_ms: 3.035517313117137\n",
      "  time_since_restore: 22308.73868918419\n",
      "  time_this_iter_s: 558.1425457000732\n",
      "  time_total_s: 36280.00545668602\n",
      "  timers:\n",
      "    learn_throughput: 28.216\n",
      "    learn_time_ms: 354268.054\n",
      "    load_throughput: 88495.682\n",
      "    load_time_ms: 112.955\n",
      "    sample_throughput: 50.525\n",
      "    sample_time_ms: 197842.469\n",
      "    update_time_ms: 7.051\n",
      "  timestamp: 1637296354\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 559686\n",
      "  training_iteration: 116\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">           36280</td><td style=\"text-align: right;\">559686</td><td style=\"text-align: right;\"> 2.86313</td><td style=\"text-align: right;\">               11.49</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           47.5071</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 569682\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_04-41-44\n",
      "  done: false\n",
      "  episode_len_mean: 47.628571428571426\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.130000000000008\n",
      "  episode_reward_mean: 3.2582857142857167\n",
      "  episode_reward_min: -1.3100000000000003\n",
      "  episodes_this_iter: 210\n",
      "  episodes_total: 10146\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.11908060453503\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017131163103594665\n",
      "          policy_loss: -0.05552092511615079\n",
      "          total_loss: 0.16086216081880794\n",
      "          vf_explained_var: 0.8228986263275146\n",
      "          vf_loss: 0.21155593936971154\n",
      "    num_agent_steps_sampled: 569682\n",
      "    num_agent_steps_trained: 569682\n",
      "    num_steps_sampled: 569682\n",
      "    num_steps_trained: 569682\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.03686224489795\n",
      "    ram_util_percent: 48.838265306122445\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05419590026049707\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.66279863195444\n",
      "    mean_inference_ms: 19.02390993454601\n",
      "    mean_raw_obs_processing_ms: 3.0761569620521207\n",
      "  time_since_restore: 22857.940061330795\n",
      "  time_this_iter_s: 549.2013721466064\n",
      "  time_total_s: 36829.206828832626\n",
      "  timers:\n",
      "    learn_throughput: 28.213\n",
      "    learn_time_ms: 354298.707\n",
      "    load_throughput: 88151.405\n",
      "    load_time_ms: 113.396\n",
      "    sample_throughput: 50.477\n",
      "    sample_time_ms: 198029.45\n",
      "    update_time_ms: 6.633\n",
      "  timestamp: 1637296904\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 569682\n",
      "  training_iteration: 117\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         36829.2</td><td style=\"text-align: right;\">569682</td><td style=\"text-align: right;\"> 3.25829</td><td style=\"text-align: right;\">               11.13</td><td style=\"text-align: right;\">               -1.31</td><td style=\"text-align: right;\">           47.6286</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 579678\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_04-50-39\n",
      "  done: false\n",
      "  episode_len_mean: 48.09615384615385\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.690000000000005\n",
      "  episode_reward_mean: 3.4041346153846184\n",
      "  episode_reward_min: -1.4400000000000006\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 10354\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.5187500000000003\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.111341636870281\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02009826119395856\n",
      "          policy_loss: -0.05735939017899197\n",
      "          total_loss: 0.2067697427226489\n",
      "          vf_explained_var: 0.8352379202842712\n",
      "          vf_loss: 0.25471831579565496\n",
      "    num_agent_steps_sampled: 579678\n",
      "    num_agent_steps_trained: 579678\n",
      "    num_steps_sampled: 579678\n",
      "    num_steps_trained: 579678\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.37787958115183\n",
      "    ram_util_percent: 48.14162303664923\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05424470937985483\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.697529328984125\n",
      "    mean_inference_ms: 19.02896122549952\n",
      "    mean_raw_obs_processing_ms: 3.035302550550176\n",
      "  time_since_restore: 23393.479383468628\n",
      "  time_this_iter_s: 535.5393221378326\n",
      "  time_total_s: 37364.74615097046\n",
      "  timers:\n",
      "    learn_throughput: 28.209\n",
      "    learn_time_ms: 354353.126\n",
      "    load_throughput: 88529.541\n",
      "    load_time_ms: 112.911\n",
      "    sample_throughput: 51.565\n",
      "    sample_time_ms: 193851.635\n",
      "    update_time_ms: 6.443\n",
      "  timestamp: 1637297439\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 579678\n",
      "  training_iteration: 118\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         37364.7</td><td style=\"text-align: right;\">579678</td><td style=\"text-align: right;\"> 3.40413</td><td style=\"text-align: right;\">               11.69</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           48.0962</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 589674\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_04-59-33\n",
      "  done: false\n",
      "  episode_len_mean: 49.306930693069305\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.330000000000004\n",
      "  episode_reward_mean: 3.5000990099009934\n",
      "  episode_reward_min: -1.2300000000000002\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 10556\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1075038424936166\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015525046673275561\n",
      "          policy_loss: -0.05487845069277039\n",
      "          total_loss: 0.2162644888735153\n",
      "          vf_explained_var: 0.8320192694664001\n",
      "          vf_loss: 0.25684997980916746\n",
      "    num_agent_steps_sampled: 589674\n",
      "    num_agent_steps_trained: 589674\n",
      "    num_steps_sampled: 589674\n",
      "    num_steps_trained: 589674\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.31049868766405\n",
      "    ram_util_percent: 47.96653543307087\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054235951121769974\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.720091226959525\n",
      "    mean_inference_ms: 19.031953028834426\n",
      "    mean_raw_obs_processing_ms: 2.995171872551453\n",
      "  time_since_restore: 23927.24451637268\n",
      "  time_this_iter_s: 533.7651329040527\n",
      "  time_total_s: 37898.51128387451\n",
      "  timers:\n",
      "    learn_throughput: 28.205\n",
      "    learn_time_ms: 354404.847\n",
      "    load_throughput: 88798.1\n",
      "    load_time_ms: 112.57\n",
      "    sample_throughput: 51.621\n",
      "    sample_time_ms: 193642.711\n",
      "    update_time_ms: 6.453\n",
      "  timestamp: 1637297973\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 589674\n",
      "  training_iteration: 119\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         37898.5</td><td style=\"text-align: right;\">589674</td><td style=\"text-align: right;\">  3.5001</td><td style=\"text-align: right;\">               11.33</td><td style=\"text-align: right;\">               -1.23</td><td style=\"text-align: right;\">           49.3069</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 599670\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_05-08-56\n",
      "  done: false\n",
      "  episode_len_mean: 48.14492753623188\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.600000000000005\n",
      "  episode_reward_mean: 3.1126086956521757\n",
      "  episode_reward_min: -1.4600000000000004\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 10763\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.139286236997589\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015566751928601378\n",
      "          policy_loss: -0.05278885679372946\n",
      "          total_loss: 0.21787676737293254\n",
      "          vf_explained_var: 0.8196830153465271\n",
      "          vf_loss: 0.25659547909406055\n",
      "    num_agent_steps_sampled: 599670\n",
      "    num_agent_steps_trained: 599670\n",
      "    num_steps_sampled: 599670\n",
      "    num_steps_trained: 599670\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.80124533001245\n",
      "    ram_util_percent: 48.77559153175592\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05417166370781919\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.72141888115964\n",
      "    mean_inference_ms: 19.023506130701104\n",
      "    mean_raw_obs_processing_ms: 3.075571246623153\n",
      "  time_since_restore: 24490.372130393982\n",
      "  time_this_iter_s: 563.1276140213013\n",
      "  time_total_s: 38461.63889789581\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354434.521\n",
      "    load_throughput: 88825.228\n",
      "    load_time_ms: 112.536\n",
      "    sample_throughput: 52.032\n",
      "    sample_time_ms: 192111.465\n",
      "    update_time_ms: 6.055\n",
      "  timestamp: 1637298536\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 599670\n",
      "  training_iteration: 120\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         38461.6</td><td style=\"text-align: right;\">599670</td><td style=\"text-align: right;\"> 3.11261</td><td style=\"text-align: right;\">                11.6</td><td style=\"text-align: right;\">               -1.46</td><td style=\"text-align: right;\">           48.1449</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 609666\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_05-18-20\n",
      "  done: false\n",
      "  episode_len_mean: 48.760975609756095\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.32000000000001\n",
      "  episode_reward_mean: 3.1372682926829296\n",
      "  episode_reward_min: -1.2900000000000005\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 10968\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.112611931849675\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014644460147807853\n",
      "          policy_loss: -0.05320296689695491\n",
      "          total_loss: 0.1998638353216515\n",
      "          vf_explained_var: 0.8067812919616699\n",
      "          vf_loss: 0.24083100936588753\n",
      "    num_agent_steps_sampled: 609666\n",
      "    num_agent_steps_trained: 609666\n",
      "    num_steps_sampled: 609666\n",
      "    num_steps_trained: 609666\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.46940298507462\n",
      "    ram_util_percent: 48.16878109452736\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054183623075967385\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.733020838050123\n",
      "    mean_inference_ms: 19.021594574245412\n",
      "    mean_raw_obs_processing_ms: 3.1106279409361015\n",
      "  time_since_restore: 25053.850873231888\n",
      "  time_this_iter_s: 563.4787428379059\n",
      "  time_total_s: 39025.11764073372\n",
      "  timers:\n",
      "    learn_throughput: 28.204\n",
      "    learn_time_ms: 354414.807\n",
      "    load_throughput: 88799.906\n",
      "    load_time_ms: 112.568\n",
      "    sample_throughput: 51.295\n",
      "    sample_time_ms: 194871.271\n",
      "    update_time_ms: 5.944\n",
      "  timestamp: 1637299100\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 609666\n",
      "  training_iteration: 121\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         39025.1</td><td style=\"text-align: right;\">609666</td><td style=\"text-align: right;\"> 3.13727</td><td style=\"text-align: right;\">               11.32</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">            48.761</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 619662\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_05-27-13\n",
      "  done: false\n",
      "  episode_len_mean: 49.711442786069654\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.490000000000007\n",
      "  episode_reward_mean: 2.950746268656719\n",
      "  episode_reward_min: -1.1900000000000004\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 11169\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.10796067836773\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014237280928002012\n",
      "          policy_loss: -0.05839227648093328\n",
      "          total_loss: 0.18689588744723826\n",
      "          vf_explained_var: 0.8090219497680664\n",
      "          vf_loss: 0.2339334638890283\n",
      "    num_agent_steps_sampled: 619662\n",
      "    num_agent_steps_trained: 619662\n",
      "    num_steps_sampled: 619662\n",
      "    num_steps_trained: 619662\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.22141918528253\n",
      "    ram_util_percent: 47.90302233902759\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054180417079714153\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.74474219393924\n",
      "    mean_inference_ms: 19.029545352807105\n",
      "    mean_raw_obs_processing_ms: 3.0712920821889527\n",
      "  time_since_restore: 25586.95479607582\n",
      "  time_this_iter_s: 533.1039228439331\n",
      "  time_total_s: 39558.22156357765\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354432.624\n",
      "    load_throughput: 88807.467\n",
      "    load_time_ms: 112.558\n",
      "    sample_throughput: 51.676\n",
      "    sample_time_ms: 193436.546\n",
      "    update_time_ms: 5.955\n",
      "  timestamp: 1637299633\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 619662\n",
      "  training_iteration: 122\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         39558.2</td><td style=\"text-align: right;\">619662</td><td style=\"text-align: right;\"> 2.95075</td><td style=\"text-align: right;\">               11.49</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           49.7114</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 629658\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_05-36-07\n",
      "  done: false\n",
      "  episode_len_mean: 49.73762376237624\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.380000000000003\n",
      "  episode_reward_mean: 3.68173267326733\n",
      "  episode_reward_min: -1.4000000000000004\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 11371\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1297909966194966\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016002222497750913\n",
      "          policy_loss: -0.0563921935318736\n",
      "          total_loss: 0.21978776465219135\n",
      "          vf_explained_var: 0.8423051834106445\n",
      "          vf_loss: 0.26102280303776026\n",
      "    num_agent_steps_sampled: 629658\n",
      "    num_agent_steps_trained: 629658\n",
      "    num_steps_sampled: 629658\n",
      "    num_steps_trained: 629658\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.39737187910643\n",
      "    ram_util_percent: 47.49027595269383\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054166184519698866\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.760864442901145\n",
      "    mean_inference_ms: 19.034576293119695\n",
      "    mean_raw_obs_processing_ms: 3.0337806405972443\n",
      "  time_since_restore: 26120.86678314209\n",
      "  time_this_iter_s: 533.9119870662689\n",
      "  time_total_s: 40092.13355064392\n",
      "  timers:\n",
      "    learn_throughput: 28.201\n",
      "    learn_time_ms: 354454.692\n",
      "    load_throughput: 88891.387\n",
      "    load_time_ms: 112.452\n",
      "    sample_throughput: 52.114\n",
      "    sample_time_ms: 191811.319\n",
      "    update_time_ms: 6.658\n",
      "  timestamp: 1637300167\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 629658\n",
      "  training_iteration: 123\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         40092.1</td><td style=\"text-align: right;\">629658</td><td style=\"text-align: right;\"> 3.68173</td><td style=\"text-align: right;\">               17.38</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           49.7376</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 639654\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_05-45-29\n",
      "  done: false\n",
      "  episode_len_mean: 49.39408866995074\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.620000000000005\n",
      "  episode_reward_mean: 3.361034482758624\n",
      "  episode_reward_min: -1.4300000000000004\n",
      "  episodes_this_iter: 203\n",
      "  episodes_total: 11574\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.143301048958637\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01579189890250616\n",
      "          policy_loss: -0.05145470540683328\n",
      "          total_loss: 0.20336802236396428\n",
      "          vf_explained_var: 0.8380917906761169\n",
      "          vf_loss: 0.2402798161365047\n",
      "    num_agent_steps_sampled: 639654\n",
      "    num_agent_steps_trained: 639654\n",
      "    num_steps_sampled: 639654\n",
      "    num_steps_trained: 639654\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.80000000000001\n",
      "    ram_util_percent: 48.06264009962639\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054114324003830434\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.75512232749369\n",
      "    mean_inference_ms: 19.031245507494905\n",
      "    mean_raw_obs_processing_ms: 3.071737843863506\n",
      "  time_since_restore: 26683.418984889984\n",
      "  time_this_iter_s: 562.5522017478943\n",
      "  time_total_s: 40654.685752391815\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354424.409\n",
      "    load_throughput: 88758.924\n",
      "    load_time_ms: 112.62\n",
      "    sample_throughput: 51.628\n",
      "    sample_time_ms: 193614.196\n",
      "    update_time_ms: 6.352\n",
      "  timestamp: 1637300729\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 639654\n",
      "  training_iteration: 124\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         40654.7</td><td style=\"text-align: right;\">639654</td><td style=\"text-align: right;\"> 3.36103</td><td style=\"text-align: right;\">               13.62</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           49.3941</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 649650\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_05-54-35\n",
      "  done: false\n",
      "  episode_len_mean: 49.37128712871287\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.940000000000008\n",
      "  episode_reward_mean: 2.893267326732676\n",
      "  episode_reward_min: -1.5400000000000007\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 11776\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.125171444167095\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015265013990486426\n",
      "          policy_loss: -0.055566982845931236\n",
      "          total_loss: 0.2001255486263801\n",
      "          vf_explained_var: 0.824100911617279\n",
      "          vf_loss: 0.2421686348297734\n",
      "    num_agent_steps_sampled: 649650\n",
      "    num_agent_steps_trained: 649650\n",
      "    num_steps_sampled: 649650\n",
      "    num_steps_trained: 649650\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.77881899871632\n",
      "    ram_util_percent: 48.41026957637998\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0540706304984682\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.765158484680978\n",
      "    mean_inference_ms: 19.030512905239352\n",
      "    mean_raw_obs_processing_ms: 3.0692008170499188\n",
      "  time_since_restore: 27229.41457939148\n",
      "  time_this_iter_s: 545.9955945014954\n",
      "  time_total_s: 41200.68134689331\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354428.714\n",
      "    load_throughput: 89010.771\n",
      "    load_time_ms: 112.301\n",
      "    sample_throughput: 51.706\n",
      "    sample_time_ms: 193322.214\n",
      "    update_time_ms: 6.338\n",
      "  timestamp: 1637301275\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 649650\n",
      "  training_iteration: 125\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         41200.7</td><td style=\"text-align: right;\">649650</td><td style=\"text-align: right;\"> 2.89327</td><td style=\"text-align: right;\">               12.94</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           49.3713</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 659646\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_06-03-26\n",
      "  done: false\n",
      "  episode_len_mean: 51.17948717948718\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.410000000000007\n",
      "  episode_reward_mean: 3.468461538461542\n",
      "  episode_reward_min: -1.2700000000000002\n",
      "  episodes_this_iter: 195\n",
      "  episodes_total: 11971\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1428585075470337\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016325118817055024\n",
      "          policy_loss: -0.05611806440160817\n",
      "          total_loss: 0.22383764335459255\n",
      "          vf_explained_var: 0.8242485523223877\n",
      "          vf_loss: 0.2641936292017185\n",
      "    num_agent_steps_sampled: 659646\n",
      "    num_agent_steps_trained: 659646\n",
      "    num_steps_sampled: 659646\n",
      "    num_steps_trained: 659646\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.18232189973614\n",
      "    ram_util_percent: 48.03812664907652\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054104629483246916\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.763302573222933\n",
      "    mean_inference_ms: 19.0327587763391\n",
      "    mean_raw_obs_processing_ms: 3.0321086249012525\n",
      "  time_since_restore: 27760.410596847534\n",
      "  time_this_iter_s: 530.9960174560547\n",
      "  time_total_s: 41731.677364349365\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354435.641\n",
      "    load_throughput: 88978.11\n",
      "    load_time_ms: 112.342\n",
      "    sample_throughput: 52.445\n",
      "    sample_time_ms: 190601.102\n",
      "    update_time_ms: 6.004\n",
      "  timestamp: 1637301806\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 659646\n",
      "  training_iteration: 126\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         41731.7</td><td style=\"text-align: right;\">659646</td><td style=\"text-align: right;\"> 3.46846</td><td style=\"text-align: right;\">               13.41</td><td style=\"text-align: right;\">               -1.27</td><td style=\"text-align: right;\">           51.1795</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 669642\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_06-12-33\n",
      "  done: false\n",
      "  episode_len_mean: 49.97487437185929\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.530000000000005\n",
      "  episode_reward_mean: 3.431909547738697\n",
      "  episode_reward_min: -1.2500000000000007\n",
      "  episodes_this_iter: 199\n",
      "  episodes_total: 12170\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1193587906628726\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01443824419824966\n",
      "          policy_loss: -0.058918726538343846\n",
      "          total_loss: 0.17630839901640832\n",
      "          vf_explained_var: 0.8812476396560669\n",
      "          vf_loss: 0.22352858755501906\n",
      "    num_agent_steps_sampled: 669642\n",
      "    num_agent_steps_trained: 669642\n",
      "    num_steps_sampled: 669642\n",
      "    num_steps_trained: 669642\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.06148908857509\n",
      "    ram_util_percent: 48.04492939666239\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05410345118916547\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.753114431031218\n",
      "    mean_inference_ms: 19.03277257914646\n",
      "    mean_raw_obs_processing_ms: 3.037038157187053\n",
      "  time_since_restore: 28306.70369386673\n",
      "  time_this_iter_s: 546.2930970191956\n",
      "  time_total_s: 42277.97046136856\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354434.38\n",
      "    load_throughput: 89241.403\n",
      "    load_time_ms: 112.011\n",
      "    sample_throughput: 52.524\n",
      "    sample_time_ms: 190312.559\n",
      "    update_time_ms: 6.001\n",
      "  timestamp: 1637302353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 669642\n",
      "  training_iteration: 127\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">           42278</td><td style=\"text-align: right;\">669642</td><td style=\"text-align: right;\"> 3.43191</td><td style=\"text-align: right;\">               11.53</td><td style=\"text-align: right;\">               -1.25</td><td style=\"text-align: right;\">           49.9749</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 679638\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_06-22-05\n",
      "  done: false\n",
      "  episode_len_mean: 49.90594059405941\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.620000000000005\n",
      "  episode_reward_mean: 3.4059405940594094\n",
      "  episode_reward_min: -1.3100000000000005\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 12372\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1350066134967958\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016218655864552976\n",
      "          policy_loss: -0.05894012622931447\n",
      "          total_loss: 0.20941841300489497\n",
      "          vf_explained_var: 0.8356194496154785\n",
      "          vf_loss: 0.2527604793116121\n",
      "    num_agent_steps_sampled: 679638\n",
      "    num_agent_steps_trained: 679638\n",
      "    num_steps_sampled: 679638\n",
      "    num_steps_trained: 679638\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.99057527539779\n",
      "    ram_util_percent: 48.076621787025694\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054108785995279345\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.742465882573345\n",
      "    mean_inference_ms: 19.02811383754433\n",
      "    mean_raw_obs_processing_ms: 3.1267026185365654\n",
      "  time_since_restore: 28879.209016799927\n",
      "  time_this_iter_s: 572.505322933197\n",
      "  time_total_s: 42850.47578430176\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354435.967\n",
      "    load_throughput: 88912.123\n",
      "    load_time_ms: 112.426\n",
      "    sample_throughput: 51.524\n",
      "    sample_time_ms: 194006.841\n",
      "    update_time_ms: 6.39\n",
      "  timestamp: 1637302925\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 679638\n",
      "  training_iteration: 128\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         42850.5</td><td style=\"text-align: right;\">679638</td><td style=\"text-align: right;\"> 3.40594</td><td style=\"text-align: right;\">               11.62</td><td style=\"text-align: right;\">               -1.31</td><td style=\"text-align: right;\">           49.9059</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 689634\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_06-30-59\n",
      "  done: false\n",
      "  episode_len_mean: 50.39393939393939\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.590000000000005\n",
      "  episode_reward_mean: 3.930606060606064\n",
      "  episode_reward_min: -1.5400000000000005\n",
      "  episodes_this_iter: 198\n",
      "  episodes_total: 12570\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.127035714033617\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016673933156821426\n",
      "          policy_loss: -0.05145224574796475\n",
      "          total_loss: 0.23173919179316874\n",
      "          vf_explained_var: 0.8434305787086487\n",
      "          vf_loss: 0.2664764895210469\n",
      "    num_agent_steps_sampled: 689634\n",
      "    num_agent_steps_trained: 689634\n",
      "    num_steps_sampled: 689634\n",
      "    num_steps_trained: 689634\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.29934383202098\n",
      "    ram_util_percent: 47.69278215223098\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05408542221897864\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.742029133599146\n",
      "    mean_inference_ms: 19.032044027528954\n",
      "    mean_raw_obs_processing_ms: 3.0921108168276943\n",
      "  time_since_restore: 29413.449704885483\n",
      "  time_this_iter_s: 534.240688085556\n",
      "  time_total_s: 43384.716472387314\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354433.7\n",
      "    load_throughput: 88724.701\n",
      "    load_time_ms: 112.663\n",
      "    sample_throughput: 51.511\n",
      "    sample_time_ms: 194056.0\n",
      "    update_time_ms: 6.372\n",
      "  timestamp: 1637303459\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 689634\n",
      "  training_iteration: 129\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         43384.7</td><td style=\"text-align: right;\">689634</td><td style=\"text-align: right;\"> 3.93061</td><td style=\"text-align: right;\">               13.59</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           50.3939</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 699630\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_06-40-08\n",
      "  done: false\n",
      "  episode_len_mean: 49.925\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.540000000000006\n",
      "  episode_reward_mean: 3.365800000000003\n",
      "  episode_reward_min: -1.2400000000000002\n",
      "  episodes_this_iter: 200\n",
      "  episodes_total: 12770\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1239713835907748\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015617860999181141\n",
      "          policy_loss: -0.05779731687229265\n",
      "          total_loss: 0.20296678474958052\n",
      "          vf_explained_var: 0.8275567889213562\n",
      "          vf_loss: 0.24642437381340737\n",
      "    num_agent_steps_sampled: 699630\n",
      "    num_agent_steps_trained: 699630\n",
      "    num_steps_sampled: 699630\n",
      "    num_steps_trained: 699630\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.03742017879948\n",
      "    ram_util_percent: 48.0522349936143\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05410703391711788\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.75471594285109\n",
      "    mean_inference_ms: 19.0299321755256\n",
      "    mean_raw_obs_processing_ms: 3.089688450546713\n",
      "  time_since_restore: 29962.02296257019\n",
      "  time_this_iter_s: 548.5732576847076\n",
      "  time_total_s: 43933.28973007202\n",
      "  timers:\n",
      "    learn_throughput: 28.201\n",
      "    learn_time_ms: 354451.011\n",
      "    load_throughput: 88809.8\n",
      "    load_time_ms: 112.555\n",
      "    sample_throughput: 51.905\n",
      "    sample_time_ms: 192583.044\n",
      "    update_time_ms: 6.465\n",
      "  timestamp: 1637304008\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 699630\n",
      "  training_iteration: 130\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         43933.3</td><td style=\"text-align: right;\">699630</td><td style=\"text-align: right;\">  3.3658</td><td style=\"text-align: right;\">               13.54</td><td style=\"text-align: right;\">               -1.24</td><td style=\"text-align: right;\">            49.925</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 709626\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_06-49-27\n",
      "  done: false\n",
      "  episode_len_mean: 49.28712871287129\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.670000000000003\n",
      "  episode_reward_mean: 3.1470297029702996\n",
      "  episode_reward_min: -1.4900000000000004\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 12972\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1292646120351004\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015834354317554727\n",
      "          policy_loss: -0.05952202882844136\n",
      "          total_loss: 0.17231093131039485\n",
      "          vf_explained_var: 0.849496603012085\n",
      "          vf_loss: 0.21705296627698414\n",
      "    num_agent_steps_sampled: 709626\n",
      "    num_agent_steps_trained: 709626\n",
      "    num_steps_sampled: 709626\n",
      "    num_steps_trained: 709626\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82982456140353\n",
      "    ram_util_percent: 48.50438596491228\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054099703800783674\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.74981916865572\n",
      "    mean_inference_ms: 19.02700480901972\n",
      "    mean_raw_obs_processing_ms: 3.1182215701948617\n",
      "  time_since_restore: 30521.204310894012\n",
      "  time_this_iter_s: 559.181348323822\n",
      "  time_total_s: 44492.47107839584\n",
      "  timers:\n",
      "    learn_throughput: 28.198\n",
      "    learn_time_ms: 354493.359\n",
      "    load_throughput: 88860.452\n",
      "    load_time_ms: 112.491\n",
      "    sample_throughput: 52.032\n",
      "    sample_time_ms: 192111.36\n",
      "    update_time_ms: 6.35\n",
      "  timestamp: 1637304567\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 709626\n",
      "  training_iteration: 131\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         44492.5</td><td style=\"text-align: right;\">709626</td><td style=\"text-align: right;\"> 3.14703</td><td style=\"text-align: right;\">               11.67</td><td style=\"text-align: right;\">               -1.49</td><td style=\"text-align: right;\">           49.2871</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 719622\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_06-58-34\n",
      "  done: false\n",
      "  episode_len_mean: 49.648514851485146\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.190000000000007\n",
      "  episode_reward_mean: 3.70183168316832\n",
      "  episode_reward_min: -1.4700000000000006\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 13174\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.128817945240013\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016372076902001008\n",
      "          policy_loss: -0.05782246769535758\n",
      "          total_loss: 0.2108581932471643\n",
      "          vf_explained_var: 0.8473324179649353\n",
      "          vf_loss: 0.25267120163689505\n",
      "    num_agent_steps_sampled: 719622\n",
      "    num_agent_steps_trained: 719622\n",
      "    num_steps_sampled: 719622\n",
      "    num_steps_trained: 719622\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.97333333333334\n",
      "    ram_util_percent: 48.079230769230776\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05406327639549861\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.756524521320927\n",
      "    mean_inference_ms: 19.024532881949877\n",
      "    mean_raw_obs_processing_ms: 3.1137054715559698\n",
      "  time_since_restore: 31067.894738435745\n",
      "  time_this_iter_s: 546.6904275417328\n",
      "  time_total_s: 45039.161505937576\n",
      "  timers:\n",
      "    learn_throughput: 28.197\n",
      "    learn_time_ms: 354510.817\n",
      "    load_throughput: 88858.813\n",
      "    load_time_ms: 112.493\n",
      "    sample_throughput: 51.672\n",
      "    sample_time_ms: 193451.385\n",
      "    update_time_ms: 6.369\n",
      "  timestamp: 1637305114\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 719622\n",
      "  training_iteration: 132\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         45039.2</td><td style=\"text-align: right;\">719622</td><td style=\"text-align: right;\"> 3.70183</td><td style=\"text-align: right;\">               13.19</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           49.6485</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 729618\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_07-07-29\n",
      "  done: false\n",
      "  episode_len_mean: 49.433497536945815\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.630000000000004\n",
      "  episode_reward_mean: 3.4633497536945845\n",
      "  episode_reward_min: -1.1600000000000004\n",
      "  episodes_this_iter: 203\n",
      "  episodes_total: 13377\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1331748870481926\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01679270546069292\n",
      "          policy_loss: -0.05772865702320234\n",
      "          total_loss: 0.21077791034936766\n",
      "          vf_explained_var: 0.8448104858398438\n",
      "          vf_loss: 0.25158243459391305\n",
      "    num_agent_steps_sampled: 729618\n",
      "    num_agent_steps_trained: 729618\n",
      "    num_steps_sampled: 729618\n",
      "    num_steps_trained: 729618\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.2880733944954\n",
      "    ram_util_percent: 47.97483617300131\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0540536028501294\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.76924796404692\n",
      "    mean_inference_ms: 19.02719549613621\n",
      "    mean_raw_obs_processing_ms: 3.0838719378890618\n",
      "  time_since_restore: 31603.30677986145\n",
      "  time_this_iter_s: 535.412041425705\n",
      "  time_total_s: 45574.57354736328\n",
      "  timers:\n",
      "    learn_throughput: 28.196\n",
      "    learn_time_ms: 354521.842\n",
      "    load_throughput: 88996.978\n",
      "    load_time_ms: 112.318\n",
      "    sample_throughput: 51.635\n",
      "    sample_time_ms: 193591.126\n",
      "    update_time_ms: 5.652\n",
      "  timestamp: 1637305649\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 729618\n",
      "  training_iteration: 133\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         45574.6</td><td style=\"text-align: right;\">729618</td><td style=\"text-align: right;\"> 3.46335</td><td style=\"text-align: right;\">               13.63</td><td style=\"text-align: right;\">               -1.16</td><td style=\"text-align: right;\">           49.4335</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 739614\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_07-16-36\n",
      "  done: false\n",
      "  episode_len_mean: 49.84422110552764\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.48000000000001\n",
      "  episode_reward_mean: 3.323768844221109\n",
      "  episode_reward_min: -1.3400000000000005\n",
      "  episodes_this_iter: 199\n",
      "  episodes_total: 13576\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1262266097059213\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015567095104923859\n",
      "          policy_loss: -0.06432107434031722\n",
      "          total_loss: 0.1724247663399004\n",
      "          vf_explained_var: 0.8537901639938354\n",
      "          vf_loss: 0.22254431692053037\n",
      "    num_agent_steps_sampled: 739614\n",
      "    num_agent_steps_trained: 739614\n",
      "    num_steps_sampled: 739614\n",
      "    num_steps_trained: 739614\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.94307692307693\n",
      "    ram_util_percent: 48.19615384615383\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05411473898367319\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.776446132359034\n",
      "    mean_inference_ms: 19.02594641153676\n",
      "    mean_raw_obs_processing_ms: 3.0809575430073504\n",
      "  time_since_restore: 32149.726449012756\n",
      "  time_this_iter_s: 546.4196691513062\n",
      "  time_total_s: 46120.99321651459\n",
      "  timers:\n",
      "    learn_throughput: 28.192\n",
      "    learn_time_ms: 354573.383\n",
      "    load_throughput: 89060.707\n",
      "    load_time_ms: 112.238\n",
      "    sample_throughput: 52.083\n",
      "    sample_time_ms: 191925.597\n",
      "    update_time_ms: 6.191\n",
      "  timestamp: 1637306196\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 739614\n",
      "  training_iteration: 134\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">           46121</td><td style=\"text-align: right;\">739614</td><td style=\"text-align: right;\"> 3.32377</td><td style=\"text-align: right;\">               15.48</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           49.8442</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 749610\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_07-25-54\n",
      "  done: false\n",
      "  episode_len_mean: 49.95522388059702\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.370000000000006\n",
      "  episode_reward_mean: 3.2663184079602017\n",
      "  episode_reward_min: -1.4400000000000004\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 13777\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1315381841487193\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016083166951083215\n",
      "          policy_loss: -0.05759525027212538\n",
      "          total_loss: 0.18688597221617204\n",
      "          vf_explained_var: 0.8141146898269653\n",
      "          vf_loss: 0.22915713892142517\n",
      "    num_agent_steps_sampled: 749610\n",
      "    num_agent_steps_trained: 749610\n",
      "    num_steps_sampled: 749610\n",
      "    num_steps_trained: 749610\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.78128140703517\n",
      "    ram_util_percent: 48.532663316582905\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05405413132575738\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.769677361733446\n",
      "    mean_inference_ms: 19.020906768551995\n",
      "    mean_raw_obs_processing_ms: 3.1062349792797583\n",
      "  time_since_restore: 32707.96892762184\n",
      "  time_this_iter_s: 558.2424786090851\n",
      "  time_total_s: 46679.23569512367\n",
      "  timers:\n",
      "    learn_throughput: 28.188\n",
      "    learn_time_ms: 354623.908\n",
      "    load_throughput: 89051.097\n",
      "    load_time_ms: 112.25\n",
      "    sample_throughput: 51.766\n",
      "    sample_time_ms: 193100.289\n",
      "    update_time_ms: 5.906\n",
      "  timestamp: 1637306754\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 749610\n",
      "  training_iteration: 135\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         46679.2</td><td style=\"text-align: right;\">749610</td><td style=\"text-align: right;\"> 3.26632</td><td style=\"text-align: right;\">               13.37</td><td style=\"text-align: right;\">               -1.44</td><td style=\"text-align: right;\">           49.9552</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 759606\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_07-34-47\n",
      "  done: false\n",
      "  episode_len_mean: 49.66169154228856\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.490000000000006\n",
      "  episode_reward_mean: 2.9845273631840823\n",
      "  episode_reward_min: -1.4200000000000006\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 13978\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1412210105413414\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016298206269386672\n",
      "          policy_loss: -0.06078187739463193\n",
      "          total_loss: 0.17379748536140502\n",
      "          vf_explained_var: 0.8138346672058105\n",
      "          vf_loss: 0.21886222104609282\n",
      "    num_agent_steps_sampled: 759606\n",
      "    num_agent_steps_trained: 759606\n",
      "    num_steps_sampled: 759606\n",
      "    num_steps_trained: 759606\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.13061760840998\n",
      "    ram_util_percent: 48.1491458607096\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05403443613257082\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.783500696029392\n",
      "    mean_inference_ms: 19.02183874873592\n",
      "    mean_raw_obs_processing_ms: 3.075139569813217\n",
      "  time_since_restore: 33240.93036150932\n",
      "  time_this_iter_s: 532.9614338874817\n",
      "  time_total_s: 47212.197129011154\n",
      "  timers:\n",
      "    learn_throughput: 28.185\n",
      "    learn_time_ms: 354651.425\n",
      "    load_throughput: 88977.449\n",
      "    load_time_ms: 112.343\n",
      "    sample_throughput: 51.721\n",
      "    sample_time_ms: 193268.908\n",
      "    update_time_ms: 5.872\n",
      "  timestamp: 1637307287\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 759606\n",
      "  training_iteration: 136\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">         47212.2</td><td style=\"text-align: right;\">759606</td><td style=\"text-align: right;\"> 2.98453</td><td style=\"text-align: right;\">               11.49</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           49.6617</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 769602\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_07-43-43\n",
      "  done: false\n",
      "  episode_len_mean: 49.80099502487562\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.340000000000005\n",
      "  episode_reward_mean: 3.1176616915422914\n",
      "  episode_reward_min: -1.3900000000000006\n",
      "  episodes_this_iter: 201\n",
      "  episodes_total: 14179\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1305242258860884\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015150381217339281\n",
      "          policy_loss: -0.06322469932627749\n",
      "          total_loss: 0.17008646997640472\n",
      "          vf_explained_var: 0.8654667735099792\n",
      "          vf_loss: 0.2201019485144461\n",
      "    num_agent_steps_sampled: 769602\n",
      "    num_agent_steps_trained: 769602\n",
      "    num_steps_sampled: 769602\n",
      "    num_steps_trained: 769602\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.25379581151832\n",
      "    ram_util_percent: 47.922905759162305\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05406233675997252\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.803407265596004\n",
      "    mean_inference_ms: 19.025435818811143\n",
      "    mean_raw_obs_processing_ms: 3.046219456872996\n",
      "  time_since_restore: 33776.53153800964\n",
      "  time_this_iter_s: 535.6011765003204\n",
      "  time_total_s: 47747.798305511475\n",
      "  timers:\n",
      "    learn_throughput: 28.183\n",
      "    learn_time_ms: 354678.363\n",
      "    load_throughput: 89142.396\n",
      "    load_time_ms: 112.135\n",
      "    sample_throughput: 52.016\n",
      "    sample_time_ms: 192171.193\n",
      "    update_time_ms: 6.415\n",
      "  timestamp: 1637307823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 769602\n",
      "  training_iteration: 137\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         47747.8</td><td style=\"text-align: right;\">769602</td><td style=\"text-align: right;\"> 3.11766</td><td style=\"text-align: right;\">               11.34</td><td style=\"text-align: right;\">               -1.39</td><td style=\"text-align: right;\">            49.801</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 779598\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_07-53-05\n",
      "  done: false\n",
      "  episode_len_mean: 48.74146341463415\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.620000000000005\n",
      "  episode_reward_mean: 3.2226341463414663\n",
      "  episode_reward_min: -1.1800000000000004\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 14384\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1132136538804294\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015971102669428777\n",
      "          policy_loss: -0.0636934696062549\n",
      "          total_loss: 0.17917627955462942\n",
      "          vf_explained_var: 0.829633355140686\n",
      "          vf_loss: 0.22761771594637997\n",
      "    num_agent_steps_sampled: 779598\n",
      "    num_agent_steps_trained: 779598\n",
      "    num_steps_sampled: 779598\n",
      "    num_steps_trained: 779598\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.84725685785536\n",
      "    ram_util_percent: 48.33329177057357\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054006688574302415\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.809124286349125\n",
      "    mean_inference_ms: 19.01923311986746\n",
      "    mean_raw_obs_processing_ms: 3.0717849355808347\n",
      "  time_since_restore: 34338.309329748154\n",
      "  time_this_iter_s: 561.7777917385101\n",
      "  time_total_s: 48309.576097249985\n",
      "  timers:\n",
      "    learn_throughput: 28.183\n",
      "    learn_time_ms: 354685.207\n",
      "    load_throughput: 89111.494\n",
      "    load_time_ms: 112.174\n",
      "    sample_throughput: 52.31\n",
      "    sample_time_ms: 191091.089\n",
      "    update_time_ms: 6.418\n",
      "  timestamp: 1637308385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 779598\n",
      "  training_iteration: 138\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         48309.6</td><td style=\"text-align: right;\">779598</td><td style=\"text-align: right;\"> 3.22263</td><td style=\"text-align: right;\">               11.62</td><td style=\"text-align: right;\">               -1.18</td><td style=\"text-align: right;\">           48.7415</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 789594\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_08-02-13\n",
      "  done: false\n",
      "  episode_len_mean: 48.955882352941174\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 10.98000000000001\n",
      "  episode_reward_mean: 3.2977450980392184\n",
      "  episode_reward_min: -1.3900000000000003\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 14588\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1128563565422733\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015210490837575592\n",
      "          policy_loss: -0.06331964086427204\n",
      "          total_loss: 0.146330346952544\n",
      "          vf_explained_var: 0.8816300630569458\n",
      "          vf_loss: 0.19612714998278183\n",
      "    num_agent_steps_sampled: 789594\n",
      "    num_agent_steps_trained: 789594\n",
      "    num_steps_sampled: 789594\n",
      "    num_steps_trained: 789594\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.21189258312022\n",
      "    ram_util_percent: 48.18286445012788\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054009813802629855\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.813688777590688\n",
      "    mean_inference_ms: 19.01999429416513\n",
      "    mean_raw_obs_processing_ms: 3.0745288357020635\n",
      "  time_since_restore: 34886.72916793823\n",
      "  time_this_iter_s: 548.4198381900787\n",
      "  time_total_s: 48857.99593544006\n",
      "  timers:\n",
      "    learn_throughput: 28.185\n",
      "    learn_time_ms: 354660.118\n",
      "    load_throughput: 89148.651\n",
      "    load_time_ms: 112.127\n",
      "    sample_throughput: 51.918\n",
      "    sample_time_ms: 192535.08\n",
      "    update_time_ms: 6.053\n",
      "  timestamp: 1637308933\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 789594\n",
      "  training_iteration: 139\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">           48858</td><td style=\"text-align: right;\">789594</td><td style=\"text-align: right;\"> 3.29775</td><td style=\"text-align: right;\">               10.98</td><td style=\"text-align: right;\">               -1.39</td><td style=\"text-align: right;\">           48.9559</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 799590\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_08-11-09\n",
      "  done: false\n",
      "  episode_len_mean: 48.78048780487805\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.440000000000007\n",
      "  episode_reward_mean: 3.3812195121951247\n",
      "  episode_reward_min: -1.1300000000000001\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 14793\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.103546820347568\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01647607270134413\n",
      "          policy_loss: -0.06341833830063617\n",
      "          total_loss: 0.17299083615608948\n",
      "          vf_explained_var: 0.8469244241714478\n",
      "          vf_loss: 0.21991008848632615\n",
      "    num_agent_steps_sampled: 799590\n",
      "    num_agent_steps_trained: 799590\n",
      "    num_steps_sampled: 799590\n",
      "    num_steps_trained: 799590\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.26849673202614\n",
      "    ram_util_percent: 48.275816993464055\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053998515628158154\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.837250657873465\n",
      "    mean_inference_ms: 19.02259641293063\n",
      "    mean_raw_obs_processing_ms: 3.0456823529870656\n",
      "  time_since_restore: 35422.680322408676\n",
      "  time_this_iter_s: 535.9511544704437\n",
      "  time_total_s: 49393.94708991051\n",
      "  timers:\n",
      "    learn_throughput: 28.187\n",
      "    learn_time_ms: 354625.324\n",
      "    load_throughput: 89010.261\n",
      "    load_time_ms: 112.302\n",
      "    sample_throughput: 52.251\n",
      "    sample_time_ms: 191307.392\n",
      "    update_time_ms: 6.3\n",
      "  timestamp: 1637309469\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 799590\n",
      "  training_iteration: 140\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         49393.9</td><td style=\"text-align: right;\">799590</td><td style=\"text-align: right;\"> 3.38122</td><td style=\"text-align: right;\">               11.44</td><td style=\"text-align: right;\">               -1.13</td><td style=\"text-align: right;\">           48.7805</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 809586\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_08-20-16\n",
      "  done: false\n",
      "  episode_len_mean: 49.310344827586206\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.510000000000005\n",
      "  episode_reward_mean: 3.033497536945816\n",
      "  episode_reward_min: -1.4700000000000004\n",
      "  episodes_this_iter: 203\n",
      "  episodes_total: 14996\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1267736571380893\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015877419165489265\n",
      "          policy_loss: -0.06209551139906094\n",
      "          total_loss: 0.16290999862055275\n",
      "          vf_explained_var: 0.8484129905700684\n",
      "          vf_loss: 0.21010249939010325\n",
      "    num_agent_steps_sampled: 809586\n",
      "    num_agent_steps_trained: 809586\n",
      "    num_steps_sampled: 809586\n",
      "    num_steps_trained: 809586\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.20102564102565\n",
      "    ram_util_percent: 48.23564102564102\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053989302183723255\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.847140552324166\n",
      "    mean_inference_ms: 19.022967360957377\n",
      "    mean_raw_obs_processing_ms: 3.0438306924413894\n",
      "  time_since_restore: 35969.891231775284\n",
      "  time_this_iter_s: 547.2109093666077\n",
      "  time_total_s: 49941.157999277115\n",
      "  timers:\n",
      "    learn_throughput: 28.195\n",
      "    learn_time_ms: 354525.765\n",
      "    load_throughput: 88776.647\n",
      "    load_time_ms: 112.597\n",
      "    sample_throughput: 52.553\n",
      "    sample_time_ms: 190209.767\n",
      "    update_time_ms: 6.177\n",
      "  timestamp: 1637310016\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 809586\n",
      "  training_iteration: 141\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         49941.2</td><td style=\"text-align: right;\">809586</td><td style=\"text-align: right;\">  3.0335</td><td style=\"text-align: right;\">               11.51</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">           49.3103</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 819582\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_08-29-38\n",
      "  done: false\n",
      "  episode_len_mean: 49.351485148514854\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.570000000000006\n",
      "  episode_reward_mean: 3.1948514851485177\n",
      "  episode_reward_min: -1.5100000000000005\n",
      "  episodes_this_iter: 202\n",
      "  episodes_total: 15198\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.123465376852985\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015995705987007235\n",
      "          policy_loss: -0.06113033084328485\n",
      "          total_loss: 0.16640832045080584\n",
      "          vf_explained_var: 0.848476231098175\n",
      "          vf_loss: 0.21233308572756\n",
      "    num_agent_steps_sampled: 819582\n",
      "    num_agent_steps_trained: 819582\n",
      "    num_steps_sampled: 819582\n",
      "    num_steps_trained: 819582\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.7584788029925\n",
      "    ram_util_percent: 48.817331670822945\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053961880480452654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.846927282964334\n",
      "    mean_inference_ms: 19.017988519595583\n",
      "    mean_raw_obs_processing_ms: 3.0693598301248923\n",
      "  time_since_restore: 36531.61646747589\n",
      "  time_this_iter_s: 561.7252357006073\n",
      "  time_total_s: 50502.88323497772\n",
      "  timers:\n",
      "    learn_throughput: 28.2\n",
      "    learn_time_ms: 354469.076\n",
      "    load_throughput: 88632.662\n",
      "    load_time_ms: 112.78\n",
      "    sample_throughput: 52.125\n",
      "    sample_time_ms: 191770.759\n",
      "    update_time_ms: 6.0\n",
      "  timestamp: 1637310578\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 819582\n",
      "  training_iteration: 142\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         50502.9</td><td style=\"text-align: right;\">819582</td><td style=\"text-align: right;\"> 3.19485</td><td style=\"text-align: right;\">               11.57</td><td style=\"text-align: right;\">               -1.51</td><td style=\"text-align: right;\">           49.3515</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 829578\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_08-38-53\n",
      "  done: false\n",
      "  episode_len_mean: 49.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.640000000000006\n",
      "  episode_reward_mean: 3.333000000000003\n",
      "  episode_reward_min: -1.3000000000000003\n",
      "  episodes_this_iter: 200\n",
      "  episodes_total: 15398\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.144609675206334\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0157874637593995\n",
      "          policy_loss: -0.062417399618454626\n",
      "          total_loss: 0.15953123840420202\n",
      "          vf_explained_var: 0.8479889035224915\n",
      "          vf_loss: 0.20742891808433167\n",
      "    num_agent_steps_sampled: 829578\n",
      "    num_agent_steps_trained: 829578\n",
      "    num_steps_sampled: 829578\n",
      "    num_steps_trained: 829578\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.69823008849558\n",
      "    ram_util_percent: 48.65221238938052\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053917421130161486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.833103180716634\n",
      "    mean_inference_ms: 19.013472968599487\n",
      "    mean_raw_obs_processing_ms: 3.087789413595702\n",
      "  time_since_restore: 37086.067549705505\n",
      "  time_this_iter_s: 554.4510822296143\n",
      "  time_total_s: 51057.33431720734\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354428.999\n",
      "    load_throughput: 88193.553\n",
      "    load_time_ms: 113.342\n",
      "    sample_throughput: 51.602\n",
      "    sample_time_ms: 193713.865\n",
      "    update_time_ms: 5.855\n",
      "  timestamp: 1637311133\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 829578\n",
      "  training_iteration: 143\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         51057.3</td><td style=\"text-align: right;\">829578</td><td style=\"text-align: right;\">   3.333</td><td style=\"text-align: right;\">               11.64</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">             49.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 839574\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_08-47-59\n",
      "  done: false\n",
      "  episode_len_mean: 49.1078431372549\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.510000000000005\n",
      "  episode_reward_mean: 3.499705882352944\n",
      "  episode_reward_min: -1.3000000000000003\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 15602\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1246853979476485\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01643859993557296\n",
      "          policy_loss: -0.06046817026320398\n",
      "          total_loss: 0.1834197214237065\n",
      "          vf_explained_var: 0.8708444833755493\n",
      "          vf_loss: 0.22768555894909226\n",
      "    num_agent_steps_sampled: 839574\n",
      "    num_agent_steps_trained: 839574\n",
      "    num_steps_sampled: 839574\n",
      "    num_steps_trained: 839574\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.06141025641026\n",
      "    ram_util_percent: 48.75\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05391132586026134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.842251504199712\n",
      "    mean_inference_ms: 19.010753225857076\n",
      "    mean_raw_obs_processing_ms: 3.086846836930323\n",
      "  time_since_restore: 37632.74672842026\n",
      "  time_this_iter_s: 546.6791787147522\n",
      "  time_total_s: 51604.01349592209\n",
      "  timers:\n",
      "    learn_throughput: 28.207\n",
      "    learn_time_ms: 354385.23\n",
      "    load_throughput: 88413.383\n",
      "    load_time_ms: 113.06\n",
      "    sample_throughput: 51.583\n",
      "    sample_time_ms: 193783.866\n",
      "    update_time_ms: 5.52\n",
      "  timestamp: 1637311679\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 839574\n",
      "  training_iteration: 144\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">           51604</td><td style=\"text-align: right;\">839574</td><td style=\"text-align: right;\"> 3.49971</td><td style=\"text-align: right;\">               13.51</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">           49.1078</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 849570\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_08-57-21\n",
      "  done: false\n",
      "  episode_len_mean: 48.68292682926829\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.260000000000007\n",
      "  episode_reward_mean: 3.589463414634149\n",
      "  episode_reward_min: -1.4100000000000004\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 15807\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.119340766314043\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015991157089837865\n",
      "          policy_loss: -0.06805145159538283\n",
      "          total_loss: 0.15704752710483602\n",
      "          vf_explained_var: 0.876018226146698\n",
      "          vf_loss: 0.20986252984940915\n",
      "    num_agent_steps_sampled: 849570\n",
      "    num_agent_steps_trained: 849570\n",
      "    num_steps_sampled: 849570\n",
      "    num_steps_trained: 849570\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75792759051187\n",
      "    ram_util_percent: 49.36554307116104\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05388157452444801\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.844605537798937\n",
      "    mean_inference_ms: 19.006920984510142\n",
      "    mean_raw_obs_processing_ms: 3.106641238035542\n",
      "  time_since_restore: 38194.49180865288\n",
      "  time_this_iter_s: 561.7450802326202\n",
      "  time_total_s: 52165.75857615471\n",
      "  timers:\n",
      "    learn_throughput: 28.217\n",
      "    learn_time_ms: 354260.513\n",
      "    load_throughput: 88119.816\n",
      "    load_time_ms: 113.436\n",
      "    sample_throughput: 51.457\n",
      "    sample_time_ms: 194257.677\n",
      "    update_time_ms: 5.501\n",
      "  timestamp: 1637312241\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 849570\n",
      "  training_iteration: 145\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         52165.8</td><td style=\"text-align: right;\">849570</td><td style=\"text-align: right;\"> 3.58946</td><td style=\"text-align: right;\">               11.26</td><td style=\"text-align: right;\">               -1.41</td><td style=\"text-align: right;\">           48.6829</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 859566\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_09-06-15\n",
      "  done: false\n",
      "  episode_len_mean: 49.200980392156865\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.240000000000009\n",
      "  episode_reward_mean: 3.0539705882352974\n",
      "  episode_reward_min: -1.2900000000000003\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 16011\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1278792230000936\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01578812642464396\n",
      "          policy_loss: -0.06692895748345905\n",
      "          total_loss: 0.14315543002089562\n",
      "          vf_explained_var: 0.8676282167434692\n",
      "          vf_loss: 0.19539585350545116\n",
      "    num_agent_steps_sampled: 859566\n",
      "    num_agent_steps_trained: 859566\n",
      "    num_steps_sampled: 859566\n",
      "    num_steps_trained: 859566\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.30445609436435\n",
      "    ram_util_percent: 48.67038007863697\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05391596578516087\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.863015510209515\n",
      "    mean_inference_ms: 19.00782849286197\n",
      "    mean_raw_obs_processing_ms: 3.08313651708489\n",
      "  time_since_restore: 38728.80161190033\n",
      "  time_this_iter_s: 534.3098032474518\n",
      "  time_total_s: 52700.06837940216\n",
      "  timers:\n",
      "    learn_throughput: 28.228\n",
      "    learn_time_ms: 354119.784\n",
      "    load_throughput: 88165.178\n",
      "    load_time_ms: 113.378\n",
      "    sample_throughput: 51.385\n",
      "    sample_time_ms: 194533.324\n",
      "    update_time_ms: 5.609\n",
      "  timestamp: 1637312775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 859566\n",
      "  training_iteration: 146\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         52700.1</td><td style=\"text-align: right;\">859566</td><td style=\"text-align: right;\"> 3.05397</td><td style=\"text-align: right;\">               13.24</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">            49.201</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 869562\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_09-15-28\n",
      "  done: false\n",
      "  episode_len_mean: 48.33495145631068\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000005\n",
      "  episode_reward_mean: 3.451456310679615\n",
      "  episode_reward_min: -1.4900000000000004\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 16217\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1232444301666504\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017321846882309366\n",
      "          policy_loss: -0.06272086164768245\n",
      "          total_loss: 0.17419856616797788\n",
      "          vf_explained_var: 0.8778234720230103\n",
      "          vf_loss: 0.21869053778474232\n",
      "    num_agent_steps_sampled: 869562\n",
      "    num_agent_steps_trained: 869562\n",
      "    num_steps_sampled: 869562\n",
      "    num_steps_trained: 869562\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.96928934010153\n",
      "    ram_util_percent: 48.456598984771574\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05392010076073704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.8877198680789\n",
      "    mean_inference_ms: 19.006101389976\n",
      "    mean_raw_obs_processing_ms: 3.1060135035276955\n",
      "  time_since_restore: 39281.289058446884\n",
      "  time_this_iter_s: 552.4874465465546\n",
      "  time_total_s: 53252.555825948715\n",
      "  timers:\n",
      "    learn_throughput: 28.24\n",
      "    learn_time_ms: 353963.443\n",
      "    load_throughput: 87786.429\n",
      "    load_time_ms: 113.867\n",
      "    sample_throughput: 50.902\n",
      "    sample_time_ms: 196379.038\n",
      "    update_time_ms: 5.207\n",
      "  timestamp: 1637313328\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 869562\n",
      "  training_iteration: 147\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         53252.6</td><td style=\"text-align: right;\">869562</td><td style=\"text-align: right;\"> 3.45146</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">               -1.49</td><td style=\"text-align: right;\">            48.335</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 879558\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_09-24-24\n",
      "  done: false\n",
      "  episode_len_mean: 48.44927536231884\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.550000000000004\n",
      "  episode_reward_mean: 3.59178743961353\n",
      "  episode_reward_min: -1.3200000000000003\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 16424\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.136419529512704\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016025544140467425\n",
      "          policy_loss: -0.0664140828926573\n",
      "          total_loss: 0.15068042941012358\n",
      "          vf_explained_var: 0.8900564908981323\n",
      "          vf_loss: 0.20195051370203554\n",
      "    num_agent_steps_sampled: 879558\n",
      "    num_agent_steps_trained: 879558\n",
      "    num_steps_sampled: 879558\n",
      "    num_steps_trained: 879558\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.26989528795814\n",
      "    ram_util_percent: 47.69554973821991\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05395318010255237\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.909862423851557\n",
      "    mean_inference_ms: 19.0091509412781\n",
      "    mean_raw_obs_processing_ms: 3.0800640960493335\n",
      "  time_since_restore: 39817.11442065239\n",
      "  time_this_iter_s: 535.8253622055054\n",
      "  time_total_s: 53788.38118815422\n",
      "  timers:\n",
      "    learn_throughput: 28.249\n",
      "    learn_time_ms: 353857.972\n",
      "    load_throughput: 87855.651\n",
      "    load_time_ms: 113.778\n",
      "    sample_throughput: 51.555\n",
      "    sample_time_ms: 193889.912\n",
      "    update_time_ms: 4.864\n",
      "  timestamp: 1637313864\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 879558\n",
      "  training_iteration: 148\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         53788.4</td><td style=\"text-align: right;\">879558</td><td style=\"text-align: right;\"> 3.59179</td><td style=\"text-align: right;\">               13.55</td><td style=\"text-align: right;\">               -1.32</td><td style=\"text-align: right;\">           48.4493</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 889554\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_09-34-11\n",
      "  done: false\n",
      "  episode_len_mean: 47.476190476190474\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.580000000000007\n",
      "  episode_reward_mean: 3.3212857142857164\n",
      "  episode_reward_min: -1.3500000000000005\n",
      "  episodes_this_iter: 210\n",
      "  episodes_total: 16634\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1166436348095474\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016015458056112937\n",
      "          policy_loss: -0.06627682389781661\n",
      "          total_loss: 0.1438516439010005\n",
      "          vf_explained_var: 0.8810619711875916\n",
      "          vf_loss: 0.1948096873330319\n",
      "    num_agent_steps_sampled: 889554\n",
      "    num_agent_steps_trained: 889554\n",
      "    num_steps_sampled: 889554\n",
      "    num_steps_trained: 889554\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 89.64755077658303\n",
      "    ram_util_percent: 48.03620071684588\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054001525284539914\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.933758977102453\n",
      "    mean_inference_ms: 19.0098525630103\n",
      "    mean_raw_obs_processing_ms: 3.1299672637286404\n",
      "  time_since_restore: 40403.887853860855\n",
      "  time_this_iter_s: 586.7734332084656\n",
      "  time_total_s: 54375.154621362686\n",
      "  timers:\n",
      "    learn_throughput: 28.253\n",
      "    learn_time_ms: 353805.005\n",
      "    load_throughput: 87632.904\n",
      "    load_time_ms: 114.067\n",
      "    sample_throughput: 50.542\n",
      "    sample_time_ms: 197777.731\n",
      "    update_time_ms: 4.974\n",
      "  timestamp: 1637314451\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 889554\n",
      "  training_iteration: 149\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         54375.2</td><td style=\"text-align: right;\">889554</td><td style=\"text-align: right;\"> 3.32129</td><td style=\"text-align: right;\">               15.58</td><td style=\"text-align: right;\">               -1.35</td><td style=\"text-align: right;\">           47.4762</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 899550\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_09-43-19\n",
      "  done: false\n",
      "  episode_len_mean: 48.529126213592235\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.840000000000002\n",
      "  episode_reward_mean: 3.6184466019417503\n",
      "  episode_reward_min: -1.2800000000000002\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 16840\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1231495258798563\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017540852332782905\n",
      "          policy_loss: -0.05865497549885443\n",
      "          total_loss: 0.19814156595017762\n",
      "          vf_explained_var: 0.8652583956718445\n",
      "          vf_loss: 0.23806778041189575\n",
      "    num_agent_steps_sampled: 899550\n",
      "    num_agent_steps_trained: 899550\n",
      "    num_steps_sampled: 899550\n",
      "    num_steps_trained: 899550\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.01826309067688\n",
      "    ram_util_percent: 47.70306513409962\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0540049515829899\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.949200462664034\n",
      "    mean_inference_ms: 19.00974592720912\n",
      "    mean_raw_obs_processing_ms: 3.1268058114442896\n",
      "  time_since_restore: 40952.3112077713\n",
      "  time_this_iter_s: 548.4233539104462\n",
      "  time_total_s: 54923.57797527313\n",
      "  timers:\n",
      "    learn_throughput: 28.253\n",
      "    learn_time_ms: 353801.768\n",
      "    load_throughput: 87784.572\n",
      "    load_time_ms: 113.87\n",
      "    sample_throughput: 50.224\n",
      "    sample_time_ms: 199028.468\n",
      "    update_time_ms: 4.57\n",
      "  timestamp: 1637314999\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 899550\n",
      "  training_iteration: 150\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">         54923.6</td><td style=\"text-align: right;\">899550</td><td style=\"text-align: right;\"> 3.61845</td><td style=\"text-align: right;\">               13.84</td><td style=\"text-align: right;\">               -1.28</td><td style=\"text-align: right;\">           48.5291</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 909546\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_09-52-29\n",
      "  done: false\n",
      "  episode_len_mean: 48.50970873786408\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000003\n",
      "  episode_reward_mean: 3.5984466019417507\n",
      "  episode_reward_min: -1.1000000000000003\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 17046\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.157362671166539\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016315461454010746\n",
      "          policy_loss: -0.06990668158129654\n",
      "          total_loss: 0.15869666122136886\n",
      "          vf_explained_var: 0.8781751990318298\n",
      "          vf_loss: 0.21300830760592945\n",
      "    num_agent_steps_sampled: 909546\n",
      "    num_agent_steps_trained: 909546\n",
      "    num_steps_sampled: 909546\n",
      "    num_steps_trained: 909546\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.15031847133758\n",
      "    ram_util_percent: 47.86471337579617\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0539734327896045\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.95985799681057\n",
      "    mean_inference_ms: 19.009908861506975\n",
      "    mean_raw_obs_processing_ms: 3.1250811702605605\n",
      "  time_since_restore: 41502.18351197243\n",
      "  time_this_iter_s: 549.8723042011261\n",
      "  time_total_s: 55473.45027947426\n",
      "  timers:\n",
      "    learn_throughput: 28.248\n",
      "    learn_time_ms: 353869.911\n",
      "    load_throughput: 87983.51\n",
      "    load_time_ms: 113.612\n",
      "    sample_throughput: 50.174\n",
      "    sample_time_ms: 199226.918\n",
      "    update_time_ms: 4.575\n",
      "  timestamp: 1637315549\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 909546\n",
      "  training_iteration: 151\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         55473.5</td><td style=\"text-align: right;\">909546</td><td style=\"text-align: right;\"> 3.59845</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">                -1.1</td><td style=\"text-align: right;\">           48.5097</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 919542\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_10-01-40\n",
      "  done: false\n",
      "  episode_len_mean: 48.21153846153846\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.460000000000006\n",
      "  episode_reward_mean: 3.1963942307692337\n",
      "  episode_reward_min: -1.3000000000000003\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 17254\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1475244065843913\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016561193996250303\n",
      "          policy_loss: -0.06243313054502619\n",
      "          total_loss: 0.15197270330069904\n",
      "          vf_explained_var: 0.887698769569397\n",
      "          vf_loss: 0.19815260715217864\n",
      "    num_agent_steps_sampled: 919542\n",
      "    num_agent_steps_trained: 919542\n",
      "    num_steps_sampled: 919542\n",
      "    num_steps_trained: 919542\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.1663694267516\n",
      "    ram_util_percent: 48.25936305732485\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05397277944042078\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.97440952808481\n",
      "    mean_inference_ms: 19.00625447524263\n",
      "    mean_raw_obs_processing_ms: 3.1457081465949597\n",
      "  time_since_restore: 42052.80262923241\n",
      "  time_this_iter_s: 550.6191172599792\n",
      "  time_total_s: 56024.06939673424\n",
      "  timers:\n",
      "    learn_throughput: 28.243\n",
      "    learn_time_ms: 353922.196\n",
      "    load_throughput: 87704.691\n",
      "    load_time_ms: 113.973\n",
      "    sample_throughput: 50.469\n",
      "    sample_time_ms: 198063.374\n",
      "    update_time_ms: 5.137\n",
      "  timestamp: 1637316100\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 919542\n",
      "  training_iteration: 152\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         56024.1</td><td style=\"text-align: right;\">919542</td><td style=\"text-align: right;\"> 3.19639</td><td style=\"text-align: right;\">               13.46</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">           48.2115</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 929538\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_10-10-36\n",
      "  done: false\n",
      "  episode_len_mean: 48.17307692307692\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.370000000000006\n",
      "  episode_reward_mean: 3.428461538461541\n",
      "  episode_reward_min: -1.3600000000000003\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 17462\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1453645702107362\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01576015825113545\n",
      "          policy_loss: -0.06857792618150353\n",
      "          total_loss: 0.12469305874458597\n",
      "          vf_explained_var: 0.8715499639511108\n",
      "          vf_loss: 0.17882101770722303\n",
      "    num_agent_steps_sampled: 929538\n",
      "    num_agent_steps_trained: 929538\n",
      "    num_steps_sampled: 929538\n",
      "    num_steps_trained: 929538\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.34954248366013\n",
      "    ram_util_percent: 47.46823529411764\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05398913482673286\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.990067811065174\n",
      "    mean_inference_ms: 19.008752689483796\n",
      "    mean_raw_obs_processing_ms: 3.1223500486283964\n",
      "  time_since_restore: 42589.05909061432\n",
      "  time_this_iter_s: 536.2564613819122\n",
      "  time_total_s: 56560.32585811615\n",
      "  timers:\n",
      "    learn_throughput: 28.241\n",
      "    learn_time_ms: 353953.396\n",
      "    load_throughput: 88278.045\n",
      "    load_time_ms: 113.233\n",
      "    sample_throughput: 50.944\n",
      "    sample_time_ms: 196213.584\n",
      "    update_time_ms: 5.145\n",
      "  timestamp: 1637316636\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 929538\n",
      "  training_iteration: 153\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 21.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         56560.3</td><td style=\"text-align: right;\">929538</td><td style=\"text-align: right;\"> 3.42846</td><td style=\"text-align: right;\">               13.37</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">           48.1731</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 939534\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_10-19-46\n",
      "  done: false\n",
      "  episode_len_mean: 48.916256157635466\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.600000000000005\n",
      "  episode_reward_mean: 3.3499507389162586\n",
      "  episode_reward_min: -1.3400000000000003\n",
      "  episodes_this_iter: 203\n",
      "  episodes_total: 17665\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1501598986516517\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016666319222684727\n",
      "          policy_loss: -0.06595496247667816\n",
      "          total_loss: 0.14128755583219152\n",
      "          vf_explained_var: 0.8751918077468872\n",
      "          vf_loss: 0.19077615778122742\n",
      "    num_agent_steps_sampled: 939534\n",
      "    num_agent_steps_trained: 939534\n",
      "    num_steps_sampled: 939534\n",
      "    num_steps_trained: 939534\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.2228025477707\n",
      "    ram_util_percent: 47.86203821656051\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05400045573399072\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.99963514557308\n",
      "    mean_inference_ms: 19.010419719112342\n",
      "    mean_raw_obs_processing_ms: 3.1223757448683287\n",
      "  time_since_restore: 43139.02363324165\n",
      "  time_this_iter_s: 549.9645426273346\n",
      "  time_total_s: 57110.290400743484\n",
      "  timers:\n",
      "    learn_throughput: 28.24\n",
      "    learn_time_ms: 353965.108\n",
      "    load_throughput: 88097.171\n",
      "    load_time_ms: 113.466\n",
      "    sample_throughput: 50.862\n",
      "    sample_time_ms: 196530.635\n",
      "    update_time_ms: 4.68\n",
      "  timestamp: 1637317186\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 939534\n",
      "  training_iteration: 154\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         57110.3</td><td style=\"text-align: right;\">939534</td><td style=\"text-align: right;\"> 3.34995</td><td style=\"text-align: right;\">                11.6</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           48.9163</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 949530\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_10-28-42\n",
      "  done: false\n",
      "  episode_len_mean: 48.86764705882353\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.550000000000006\n",
      "  episode_reward_mean: 3.4950980392156894\n",
      "  episode_reward_min: -1.4500000000000004\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 17869\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.132606369951164\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015655875403192146\n",
      "          policy_loss: -0.07040352707111573\n",
      "          total_loss: 0.13686609038006983\n",
      "          vf_explained_var: 0.8519843220710754\n",
      "          vf_loss: 0.19292963931737206\n",
      "    num_agent_steps_sampled: 949530\n",
      "    num_agent_steps_trained: 949530\n",
      "    num_steps_sampled: 949530\n",
      "    num_steps_trained: 949530\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.28849673202616\n",
      "    ram_util_percent: 47.89830065359477\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053987691721048635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01511696854248\n",
      "    mean_inference_ms: 19.01237131557043\n",
      "    mean_raw_obs_processing_ms: 3.098493090440415\n",
      "  time_since_restore: 43675.07896280289\n",
      "  time_this_iter_s: 536.0553295612335\n",
      "  time_total_s: 57646.34573030472\n",
      "  timers:\n",
      "    learn_throughput: 28.231\n",
      "    learn_time_ms: 354084.661\n",
      "    load_throughput: 88431.789\n",
      "    load_time_ms: 113.036\n",
      "    sample_throughput: 51.567\n",
      "    sample_time_ms: 193843.317\n",
      "    update_time_ms: 4.624\n",
      "  timestamp: 1637317722\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 949530\n",
      "  training_iteration: 155\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         57646.3</td><td style=\"text-align: right;\">949530</td><td style=\"text-align: right;\">  3.4951</td><td style=\"text-align: right;\">               15.55</td><td style=\"text-align: right;\">               -1.45</td><td style=\"text-align: right;\">           48.8676</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 959526\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_10-38-14\n",
      "  done: false\n",
      "  episode_len_mean: 48.07655502392345\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.630000000000003\n",
      "  episode_reward_mean: 3.6743540669856496\n",
      "  episode_reward_min: -1.3400000000000005\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 18078\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1360426322762747\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017357747907971087\n",
      "          policy_loss: -0.06627179448838272\n",
      "          total_loss: 0.15480935184272654\n",
      "          vf_explained_var: 0.8954901695251465\n",
      "          vf_loss: 0.2028984518919933\n",
      "    num_agent_steps_sampled: 959526\n",
      "    num_agent_steps_trained: 959526\n",
      "    num_steps_sampled: 959526\n",
      "    num_steps_trained: 959526\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.63247549019609\n",
      "    ram_util_percent: 49.012622549019596\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05397934257610274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.00264128385251\n",
      "    mean_inference_ms: 19.005004468606938\n",
      "    mean_raw_obs_processing_ms: 3.1597466451375613\n",
      "  time_since_restore: 44247.21584177017\n",
      "  time_this_iter_s: 572.1368789672852\n",
      "  time_total_s: 58218.482609272\n",
      "  timers:\n",
      "    learn_throughput: 28.224\n",
      "    learn_time_ms: 354160.708\n",
      "    load_throughput: 88752.31\n",
      "    load_time_ms: 112.628\n",
      "    sample_throughput: 50.6\n",
      "    sample_time_ms: 197550.467\n",
      "    update_time_ms: 4.469\n",
      "  timestamp: 1637318294\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 959526\n",
      "  training_iteration: 156\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         58218.5</td><td style=\"text-align: right;\">959526</td><td style=\"text-align: right;\"> 3.67435</td><td style=\"text-align: right;\">               17.63</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">           48.0766</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 969522\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_10-47-22\n",
      "  done: false\n",
      "  episode_len_mean: 47.89473684210526\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.530000000000005\n",
      "  episode_reward_mean: 3.458229665071773\n",
      "  episode_reward_min: -1.1900000000000002\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 18287\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1197847829286354\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01717194715533798\n",
      "          policy_loss: -0.06855631150300684\n",
      "          total_loss: 0.1472048094790084\n",
      "          vf_explained_var: 0.8923365473747253\n",
      "          vf_loss: 0.19783912410391083\n",
      "    num_agent_steps_sampled: 969522\n",
      "    num_agent_steps_trained: 969522\n",
      "    num_steps_sampled: 969522\n",
      "    num_steps_trained: 969522\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9502557544757\n",
      "    ram_util_percent: 49.10485933503836\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0539842354276939\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.01099231425911\n",
      "    mean_inference_ms: 19.002583081617146\n",
      "    mean_raw_obs_processing_ms: 3.157724217559956\n",
      "  time_since_restore: 44795.50380754471\n",
      "  time_this_iter_s: 548.2879657745361\n",
      "  time_total_s: 58766.77057504654\n",
      "  timers:\n",
      "    learn_throughput: 28.218\n",
      "    learn_time_ms: 354246.865\n",
      "    load_throughput: 88913.33\n",
      "    load_time_ms: 112.424\n",
      "    sample_throughput: 50.73\n",
      "    sample_time_ms: 197044.317\n",
      "    update_time_ms: 4.517\n",
      "  timestamp: 1637318842\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 969522\n",
      "  training_iteration: 157\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         58766.8</td><td style=\"text-align: right;\">969522</td><td style=\"text-align: right;\"> 3.45823</td><td style=\"text-align: right;\">               13.53</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           47.8947</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 979518\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_10-56-20\n",
      "  done: false\n",
      "  episode_len_mean: 48.23671497584541\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.550000000000006\n",
      "  episode_reward_mean: 3.4923671497584574\n",
      "  episode_reward_min: -1.4200000000000004\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 18494\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.128395951655974\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016339358441008627\n",
      "          policy_loss: -0.06854272517119091\n",
      "          total_loss: 0.13508285014940563\n",
      "          vf_explained_var: 0.8752323985099792\n",
      "          vf_loss: 0.18768643283763953\n",
      "    num_agent_steps_sampled: 979518\n",
      "    num_agent_steps_trained: 979518\n",
      "    num_steps_sampled: 979518\n",
      "    num_steps_trained: 979518\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.30990873533248\n",
      "    ram_util_percent: 48.8470664928292\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054012574160321646\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02825076191492\n",
      "    mean_inference_ms: 19.00615044773827\n",
      "    mean_raw_obs_processing_ms: 3.135203025777862\n",
      "  time_since_restore: 45332.88858270645\n",
      "  time_this_iter_s: 537.3847751617432\n",
      "  time_total_s: 59304.15535020828\n",
      "  timers:\n",
      "    learn_throughput: 28.211\n",
      "    learn_time_ms: 354324.462\n",
      "    load_throughput: 88946.17\n",
      "    load_time_ms: 112.383\n",
      "    sample_throughput: 50.71\n",
      "    sample_time_ms: 197122.437\n",
      "    update_time_ms: 4.85\n",
      "  timestamp: 1637319380\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 979518\n",
      "  training_iteration: 158\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         59304.2</td><td style=\"text-align: right;\">979518</td><td style=\"text-align: right;\"> 3.49237</td><td style=\"text-align: right;\">               11.55</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           48.2367</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 989514\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_11-05-42\n",
      "  done: false\n",
      "  episode_len_mean: 48.794117647058826\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.280000000000008\n",
      "  episode_reward_mean: 3.592058823529415\n",
      "  episode_reward_min: -1.1900000000000006\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 18698\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1282213323087578\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017395527991051683\n",
      "          policy_loss: -0.06174960850744958\n",
      "          total_loss: 0.1584171665876845\n",
      "          vf_explained_var: 0.8907971978187561\n",
      "          vf_loss: 0.2018197996321183\n",
      "    num_agent_steps_sampled: 989514\n",
      "    num_agent_steps_trained: 989514\n",
      "    num_steps_sampled: 989514\n",
      "    num_steps_trained: 989514\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82668329177058\n",
      "    ram_util_percent: 49.31147132169576\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05402196891494663\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.02008558938379\n",
      "    mean_inference_ms: 19.00030466202624\n",
      "    mean_raw_obs_processing_ms: 3.1761813429841435\n",
      "  time_since_restore: 45895.082292079926\n",
      "  time_this_iter_s: 562.1937093734741\n",
      "  time_total_s: 59866.34905958176\n",
      "  timers:\n",
      "    learn_throughput: 28.204\n",
      "    learn_time_ms: 354424.081\n",
      "    load_throughput: 88938.151\n",
      "    load_time_ms: 112.393\n",
      "    sample_throughput: 51.376\n",
      "    sample_time_ms: 194564.981\n",
      "    update_time_ms: 4.997\n",
      "  timestamp: 1637319942\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 989514\n",
      "  training_iteration: 159\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         59866.3</td><td style=\"text-align: right;\">989514</td><td style=\"text-align: right;\"> 3.59206</td><td style=\"text-align: right;\">               13.28</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           48.7941</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 999510\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_11-14-56\n",
      "  done: false\n",
      "  episode_len_mean: 48.057416267942585\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.620000000000005\n",
      "  episode_reward_mean: 4.139808612440195\n",
      "  episode_reward_min: -1.2200000000000002\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 18907\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.113344606218568\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01673916845661738\n",
      "          policy_loss: -0.06493804933185991\n",
      "          total_loss: 0.16223384862208123\n",
      "          vf_explained_var: 0.9161248803138733\n",
      "          vf_loss: 0.21017142524026394\n",
      "    num_agent_steps_sampled: 999510\n",
      "    num_agent_steps_trained: 999510\n",
      "    num_steps_sampled: 999510\n",
      "    num_steps_trained: 999510\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.11430379746834\n",
      "    ram_util_percent: 48.66075949367089\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05401585141420017\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.0369070657181\n",
      "    mean_inference_ms: 18.997795925082535\n",
      "    mean_raw_obs_processing_ms: 3.1763397726305995\n",
      "  time_since_restore: 46448.98953342438\n",
      "  time_this_iter_s: 553.9072413444519\n",
      "  time_total_s: 60420.25630092621\n",
      "  timers:\n",
      "    learn_throughput: 28.2\n",
      "    learn_time_ms: 354469.028\n",
      "    load_throughput: 88793.587\n",
      "    load_time_ms: 112.576\n",
      "    sample_throughput: 51.244\n",
      "    sample_time_ms: 195068.21\n",
      "    update_time_ms: 5.223\n",
      "  timestamp: 1637320496\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 999510\n",
      "  training_iteration: 160\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         60420.3</td><td style=\"text-align: right;\">999510</td><td style=\"text-align: right;\"> 4.13981</td><td style=\"text-align: right;\">               15.62</td><td style=\"text-align: right;\">               -1.22</td><td style=\"text-align: right;\">           48.0574</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1009506\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_11-24-08\n",
      "  done: false\n",
      "  episode_len_mean: 48.43689320388349\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.390000000000006\n",
      "  episode_reward_mean: 3.8219417475728186\n",
      "  episode_reward_min: -1.2300000000000004\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 19113\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1281997080787596\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015944421880221805\n",
      "          policy_loss: -0.0678474310103433\n",
      "          total_loss: 0.12740136742575553\n",
      "          vf_explained_var: 0.8956625461578369\n",
      "          vf_loss: 0.18020740828166407\n",
      "    num_agent_steps_sampled: 1009506\n",
      "    num_agent_steps_trained: 1009506\n",
      "    num_steps_sampled: 1009506\n",
      "    num_steps_trained: 1009506\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.96687817258882\n",
      "    ram_util_percent: 48.222969543147215\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054038237497598736\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.054171443034164\n",
      "    mean_inference_ms: 18.997826612858546\n",
      "    mean_raw_obs_processing_ms: 3.1732342614443807\n",
      "  time_since_restore: 47000.7328453064\n",
      "  time_this_iter_s: 551.743311882019\n",
      "  time_total_s: 60971.99961280823\n",
      "  timers:\n",
      "    learn_throughput: 28.202\n",
      "    learn_time_ms: 354447.398\n",
      "    load_throughput: 88724.644\n",
      "    load_time_ms: 112.663\n",
      "    sample_throughput: 51.189\n",
      "    sample_time_ms: 195276.737\n",
      "    update_time_ms: 5.243\n",
      "  timestamp: 1637321048\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1009506\n",
      "  training_iteration: 161\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">           60972</td><td style=\"text-align: right;\">1009506</td><td style=\"text-align: right;\"> 3.82194</td><td style=\"text-align: right;\">               11.39</td><td style=\"text-align: right;\">               -1.23</td><td style=\"text-align: right;\">           48.4369</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1019502\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_11-33-25\n",
      "  done: false\n",
      "  episode_len_mean: 47.88516746411483\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.670000000000005\n",
      "  episode_reward_mean: 3.5708612440191416\n",
      "  episode_reward_min: -1.2200000000000004\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 19322\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1449732786440947\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016727890863557193\n",
      "          policy_loss: -0.06674124894526837\n",
      "          total_loss: 0.14406452526081884\n",
      "          vf_explained_var: 0.8775285482406616\n",
      "          vf_loss: 0.1941472796596078\n",
      "    num_agent_steps_sampled: 1019502\n",
      "    num_agent_steps_trained: 1019502\n",
      "    num_steps_sampled: 1019502\n",
      "    num_steps_trained: 1019502\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91032745591941\n",
      "    ram_util_percent: 47.971284634760714\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054030746485194146\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08080091467588\n",
      "    mean_inference_ms: 18.99668304381478\n",
      "    mean_raw_obs_processing_ms: 3.190647776864145\n",
      "  time_since_restore: 47557.665744781494\n",
      "  time_this_iter_s: 556.9328994750977\n",
      "  time_total_s: 61528.932512283325\n",
      "  timers:\n",
      "    learn_throughput: 28.201\n",
      "    learn_time_ms: 354451.031\n",
      "    load_throughput: 89158.547\n",
      "    load_time_ms: 112.115\n",
      "    sample_throughput: 51.025\n",
      "    sample_time_ms: 195904.879\n",
      "    update_time_ms: 4.89\n",
      "  timestamp: 1637321605\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1019502\n",
      "  training_iteration: 162\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">         61528.9</td><td style=\"text-align: right;\">1019502</td><td style=\"text-align: right;\"> 3.57086</td><td style=\"text-align: right;\">               15.67</td><td style=\"text-align: right;\">               -1.22</td><td style=\"text-align: right;\">           47.8852</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1029498\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_11-42-35\n",
      "  done: false\n",
      "  episode_len_mean: 48.84313725490196\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.780000000000003\n",
      "  episode_reward_mean: 3.6162254901960815\n",
      "  episode_reward_min: -1.4800000000000004\n",
      "  episodes_this_iter: 204\n",
      "  episodes_total: 19526\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.138988344042177\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016206215221860453\n",
      "          policy_loss: -0.06370623145314355\n",
      "          total_loss: 0.14249190064771852\n",
      "          vf_explained_var: 0.8975666165351868\n",
      "          vf_loss: 0.19066823009293093\n",
      "    num_agent_steps_sampled: 1029498\n",
      "    num_agent_steps_trained: 1029498\n",
      "    num_steps_sampled: 1029498\n",
      "    num_steps_trained: 1029498\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.84363867684479\n",
      "    ram_util_percent: 49.31081424936387\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054028694428215014\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.08665135296111\n",
      "    mean_inference_ms: 18.995651830304915\n",
      "    mean_raw_obs_processing_ms: 3.2072036853023236\n",
      "  time_since_restore: 48108.3702249527\n",
      "  time_this_iter_s: 550.7044801712036\n",
      "  time_total_s: 62079.63699245453\n",
      "  timers:\n",
      "    learn_throughput: 28.201\n",
      "    learn_time_ms: 354449.504\n",
      "    load_throughput: 88505.77\n",
      "    load_time_ms: 112.942\n",
      "    sample_throughput: 50.651\n",
      "    sample_time_ms: 197350.338\n",
      "    update_time_ms: 5.305\n",
      "  timestamp: 1637322155\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1029498\n",
      "  training_iteration: 163\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         62079.6</td><td style=\"text-align: right;\">1029498</td><td style=\"text-align: right;\"> 3.61623</td><td style=\"text-align: right;\">               13.78</td><td style=\"text-align: right;\">               -1.48</td><td style=\"text-align: right;\">           48.8431</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1039494\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_11-51-33\n",
      "  done: false\n",
      "  episode_len_mean: 48.07177033492823\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.490000000000007\n",
      "  episode_reward_mean: 3.384019138755984\n",
      "  episode_reward_min: -1.2300000000000002\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 19735\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1587950842208175\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015935457914282292\n",
      "          policy_loss: -0.07574654261407122\n",
      "          total_loss: 0.09900476567439084\n",
      "          vf_explained_var: 0.9031842350959778\n",
      "          vf_loss: 0.1600362924464331\n",
      "    num_agent_steps_sampled: 1039494\n",
      "    num_agent_steps_trained: 1039494\n",
      "    num_steps_sampled: 1039494\n",
      "    num_steps_trained: 1039494\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.3122555410691\n",
      "    ram_util_percent: 48.881095176010426\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054010581684903795\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.10505446741523\n",
      "    mean_inference_ms: 18.996602204871856\n",
      "    mean_raw_obs_processing_ms: 3.1850633613872934\n",
      "  time_since_restore: 48645.82695364952\n",
      "  time_this_iter_s: 537.4567286968231\n",
      "  time_total_s: 62617.09372115135\n",
      "  timers:\n",
      "    learn_throughput: 28.199\n",
      "    learn_time_ms: 354477.364\n",
      "    load_throughput: 88320.538\n",
      "    load_time_ms: 113.179\n",
      "    sample_throughput: 50.981\n",
      "    sample_time_ms: 196071.668\n",
      "    update_time_ms: 5.325\n",
      "  timestamp: 1637322693\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1039494\n",
      "  training_iteration: 164\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         62617.1</td><td style=\"text-align: right;\">1039494</td><td style=\"text-align: right;\"> 3.38402</td><td style=\"text-align: right;\">               11.49</td><td style=\"text-align: right;\">               -1.23</td><td style=\"text-align: right;\">           48.0718</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1049490\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_12-00-47\n",
      "  done: false\n",
      "  episode_len_mean: 48.1875\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.770000000000003\n",
      "  episode_reward_mean: 3.712836538461542\n",
      "  episode_reward_min: -1.4300000000000004\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 19943\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1183051803743984\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016220597604158157\n",
      "          policy_loss: -0.06950805613149234\n",
      "          total_loss: 0.12224796666295767\n",
      "          vf_explained_var: 0.8987577557563782\n",
      "          vf_loss: 0.17598652500158032\n",
      "    num_agent_steps_sampled: 1049490\n",
      "    num_agent_steps_trained: 1049490\n",
      "    num_steps_sampled: 1049490\n",
      "    num_steps_trained: 1049490\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.79608091024019\n",
      "    ram_util_percent: 48.99658659924147\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05400342165471717\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.12532783645913\n",
      "    mean_inference_ms: 18.99815533429817\n",
      "    mean_raw_obs_processing_ms: 3.184266206399001\n",
      "  time_since_restore: 49200.263377428055\n",
      "  time_this_iter_s: 554.4364237785339\n",
      "  time_total_s: 63171.530144929886\n",
      "  timers:\n",
      "    learn_throughput: 28.203\n",
      "    learn_time_ms: 354433.15\n",
      "    load_throughput: 88436.695\n",
      "    load_time_ms: 113.03\n",
      "    sample_throughput: 50.497\n",
      "    sample_time_ms: 197953.814\n",
      "    update_time_ms: 5.432\n",
      "  timestamp: 1637323247\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1049490\n",
      "  training_iteration: 165\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         63171.5</td><td style=\"text-align: right;\">1049490</td><td style=\"text-align: right;\"> 3.71284</td><td style=\"text-align: right;\">               13.77</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           48.1875</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1059486\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_12-10-02\n",
      "  done: false\n",
      "  episode_len_mean: 47.67942583732057\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.500000000000007\n",
      "  episode_reward_mean: 3.999234449760769\n",
      "  episode_reward_min: -1.5400000000000005\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 20152\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.133204801853402\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017286612498633155\n",
      "          policy_loss: -0.06551213575951707\n",
      "          total_loss: 0.16019745657649107\n",
      "          vf_explained_var: 0.8834856748580933\n",
      "          vf_loss: 0.20766057524405585\n",
      "    num_agent_steps_sampled: 1059486\n",
      "    num_agent_steps_trained: 1059486\n",
      "    num_steps_sampled: 1059486\n",
      "    num_steps_trained: 1059486\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91327433628318\n",
      "    ram_util_percent: 48.73969658659923\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05399511727310247\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.14593535156277\n",
      "    mean_inference_ms: 18.996752581041626\n",
      "    mean_raw_obs_processing_ms: 3.2003532541160933\n",
      "  time_since_restore: 49755.00572681427\n",
      "  time_this_iter_s: 554.7423493862152\n",
      "  time_total_s: 63726.2724943161\n",
      "  timers:\n",
      "    learn_throughput: 28.2\n",
      "    learn_time_ms: 354470.763\n",
      "    load_throughput: 88017.182\n",
      "    load_time_ms: 113.569\n",
      "    sample_throughput: 50.954\n",
      "    sample_time_ms: 196175.986\n",
      "    update_time_ms: 5.504\n",
      "  timestamp: 1637323802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1059486\n",
      "  training_iteration: 166\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         63726.3</td><td style=\"text-align: right;\">1059486</td><td style=\"text-align: right;\"> 3.99923</td><td style=\"text-align: right;\">                13.5</td><td style=\"text-align: right;\">               -1.54</td><td style=\"text-align: right;\">           47.6794</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1069482\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_12-19-11\n",
      "  done: false\n",
      "  episode_len_mean: 48.49029126213592\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 17.179999999999996\n",
      "  episode_reward_mean: 3.481019417475731\n",
      "  episode_reward_min: -1.2300000000000004\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 20358\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1197916411252384\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016972739411056474\n",
      "          policy_loss: -0.07000688841148091\n",
      "          total_loss: 0.1323220828609514\n",
      "          vf_explained_var: 0.8917809724807739\n",
      "          vf_loss: 0.18486086477405844\n",
      "    num_agent_steps_sampled: 1069482\n",
      "    num_agent_steps_trained: 1069482\n",
      "    num_steps_sampled: 1069482\n",
      "    num_steps_trained: 1069482\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9139208173691\n",
      "    ram_util_percent: 48.48582375478928\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05400661042578861\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.14747341781247\n",
      "    mean_inference_ms: 18.994355812395295\n",
      "    mean_raw_obs_processing_ms: 3.198902722514774\n",
      "  time_since_restore: 50303.647634506226\n",
      "  time_this_iter_s: 548.6419076919556\n",
      "  time_total_s: 64274.91440200806\n",
      "  timers:\n",
      "    learn_throughput: 28.191\n",
      "    learn_time_ms: 354579.025\n",
      "    load_throughput: 88019.565\n",
      "    load_time_ms: 113.566\n",
      "    sample_throughput: 50.973\n",
      "    sample_time_ms: 196103.387\n",
      "    update_time_ms: 5.399\n",
      "  timestamp: 1637324351\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1069482\n",
      "  training_iteration: 167\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         64274.9</td><td style=\"text-align: right;\">1069482</td><td style=\"text-align: right;\"> 3.48102</td><td style=\"text-align: right;\">               17.18</td><td style=\"text-align: right;\">               -1.23</td><td style=\"text-align: right;\">           48.4903</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1079478\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_12-28-10\n",
      "  done: false\n",
      "  episode_len_mean: 47.91346153846154\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 15.440000000000005\n",
      "  episode_reward_mean: 3.6080288461538497\n",
      "  episode_reward_min: -1.3900000000000003\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 20566\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.121123639335594\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015851293541699625\n",
      "          policy_loss: -0.06823653672722264\n",
      "          total_loss: 0.12107882601560313\n",
      "          vf_explained_var: 0.8972551226615906\n",
      "          vf_loss: 0.1744153696667762\n",
      "    num_agent_steps_sampled: 1079478\n",
      "    num_agent_steps_trained: 1079478\n",
      "    num_steps_sampled: 1079478\n",
      "    num_steps_trained: 1079478\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.29401820546164\n",
      "    ram_util_percent: 48.073081924577366\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05400937322271683\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.165056313826334\n",
      "    mean_inference_ms: 18.997572964341447\n",
      "    mean_raw_obs_processing_ms: 3.1774172759096047\n",
      "  time_since_restore: 50842.51351737976\n",
      "  time_this_iter_s: 538.8658828735352\n",
      "  time_total_s: 64813.78028488159\n",
      "  timers:\n",
      "    learn_throughput: 28.188\n",
      "    learn_time_ms: 354615.748\n",
      "    load_throughput: 88111.464\n",
      "    load_time_ms: 113.447\n",
      "    sample_throughput: 50.944\n",
      "    sample_time_ms: 196215.445\n",
      "    update_time_ms: 4.998\n",
      "  timestamp: 1637324890\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1079478\n",
      "  training_iteration: 168\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         64813.8</td><td style=\"text-align: right;\">1079478</td><td style=\"text-align: right;\"> 3.60803</td><td style=\"text-align: right;\">               15.44</td><td style=\"text-align: right;\">               -1.39</td><td style=\"text-align: right;\">           47.9135</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1089474\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_12-37-20\n",
      "  done: false\n",
      "  episode_len_mean: 48.25480769230769\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.560000000000008\n",
      "  episode_reward_mean: 3.7129326923076955\n",
      "  episode_reward_min: -1.5000000000000004\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 20774\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1240071040798862\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01677227608568083\n",
      "          policy_loss: -0.06532815386847425\n",
      "          total_loss: 0.13477894753422368\n",
      "          vf_explained_var: 0.9057478904724121\n",
      "          vf_loss: 0.1831378297597903\n",
      "    num_agent_steps_sampled: 1089474\n",
      "    num_agent_steps_trained: 1089474\n",
      "    num_steps_sampled: 1089474\n",
      "    num_steps_trained: 1089474\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.04783163265306\n",
      "    ram_util_percent: 48.07436224489796\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053974380577991234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.17493864924181\n",
      "    mean_inference_ms: 19.000064580682015\n",
      "    mean_raw_obs_processing_ms: 3.175384811725095\n",
      "  time_since_restore: 51392.33743596077\n",
      "  time_this_iter_s: 549.8239185810089\n",
      "  time_total_s: 65363.6042034626\n",
      "  timers:\n",
      "    learn_throughput: 28.188\n",
      "    learn_time_ms: 354615.101\n",
      "    load_throughput: 88398.749\n",
      "    load_time_ms: 113.079\n",
      "    sample_throughput: 51.267\n",
      "    sample_time_ms: 194979.481\n",
      "    update_time_ms: 4.743\n",
      "  timestamp: 1637325440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1089474\n",
      "  training_iteration: 169\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         65363.6</td><td style=\"text-align: right;\">1089474</td><td style=\"text-align: right;\"> 3.71293</td><td style=\"text-align: right;\">               13.56</td><td style=\"text-align: right;\">                -1.5</td><td style=\"text-align: right;\">           48.2548</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1099470\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_12-46-32\n",
      "  done: false\n",
      "  episode_len_mean: 47.32380952380952\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.540000000000008\n",
      "  episode_reward_mean: 3.6898571428571456\n",
      "  episode_reward_min: -1.2700000000000002\n",
      "  episodes_this_iter: 210\n",
      "  episodes_total: 20984\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.133776147657609\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015875972329161294\n",
      "          policy_loss: -0.06790296230915757\n",
      "          total_loss: 0.10920639747916382\n",
      "          vf_explained_var: 0.9025681018829346\n",
      "          vf_loss: 0.16227967074125946\n",
      "    num_agent_steps_sampled: 1099470\n",
      "    num_agent_steps_trained: 1099470\n",
      "    num_steps_sampled: 1099470\n",
      "    num_steps_trained: 1099470\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.05609137055839\n",
      "    ram_util_percent: 48.69631979695431\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05397243060659099\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.18811105286241\n",
      "    mean_inference_ms: 18.997851787807388\n",
      "    mean_raw_obs_processing_ms: 3.191033597278788\n",
      "  time_since_restore: 51944.426303863525\n",
      "  time_this_iter_s: 552.0888679027557\n",
      "  time_total_s: 65915.69307136536\n",
      "  timers:\n",
      "    learn_throughput: 28.19\n",
      "    learn_time_ms: 354597.31\n",
      "    load_throughput: 88524.943\n",
      "    load_time_ms: 112.917\n",
      "    sample_throughput: 51.31\n",
      "    sample_time_ms: 194815.642\n",
      "    update_time_ms: 4.58\n",
      "  timestamp: 1637325992\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1099470\n",
      "  training_iteration: 170\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">         65915.7</td><td style=\"text-align: right;\">1099470</td><td style=\"text-align: right;\"> 3.68986</td><td style=\"text-align: right;\">               13.54</td><td style=\"text-align: right;\">               -1.27</td><td style=\"text-align: right;\">           47.3238</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1109466\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_12-55-29\n",
      "  done: false\n",
      "  episode_len_mean: 47.492890995260666\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.490000000000007\n",
      "  episode_reward_mean: 3.7404739336492923\n",
      "  episode_reward_min: -1.3700000000000003\n",
      "  episodes_this_iter: 211\n",
      "  episodes_total: 21195\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1162956005837543\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016066573418939637\n",
      "          policy_loss: -0.06876504663522935\n",
      "          total_loss: 0.12400575074967769\n",
      "          vf_explained_var: 0.8988093137741089\n",
      "          vf_loss: 0.17733208847710916\n",
      "    num_agent_steps_sampled: 1109466\n",
      "    num_agent_steps_trained: 1109466\n",
      "    num_steps_sampled: 1109466\n",
      "    num_steps_trained: 1109466\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.43415906127771\n",
      "    ram_util_percent: 48.5555410691004\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054002906159303206\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.202798849422265\n",
      "    mean_inference_ms: 18.998931719127196\n",
      "    mean_raw_obs_processing_ms: 3.172634236476365\n",
      "  time_since_restore: 52481.90189552307\n",
      "  time_this_iter_s: 537.4755916595459\n",
      "  time_total_s: 66453.1686630249\n",
      "  timers:\n",
      "    learn_throughput: 28.186\n",
      "    learn_time_ms: 354639.814\n",
      "    load_throughput: 88834.187\n",
      "    load_time_ms: 112.524\n",
      "    sample_throughput: 51.7\n",
      "    sample_time_ms: 193345.885\n",
      "    update_time_ms: 4.909\n",
      "  timestamp: 1637326529\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1109466\n",
      "  training_iteration: 171\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         66453.2</td><td style=\"text-align: right;\">1109466</td><td style=\"text-align: right;\"> 3.74047</td><td style=\"text-align: right;\">               11.49</td><td style=\"text-align: right;\">               -1.37</td><td style=\"text-align: right;\">           47.4929</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1119462\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_13-04-25\n",
      "  done: false\n",
      "  episode_len_mean: 48.3252427184466\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.540000000000006\n",
      "  episode_reward_mean: 3.4212621359223334\n",
      "  episode_reward_min: -1.4000000000000004\n",
      "  episodes_this_iter: 206\n",
      "  episodes_total: 21401\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.137507532734469\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016299779207240073\n",
      "          policy_loss: -0.07054797322094988\n",
      "          total_loss: 0.11060197955472162\n",
      "          vf_explained_var: 0.8933246731758118\n",
      "          vf_loss: 0.165392092124458\n",
      "    num_agent_steps_sampled: 1119462\n",
      "    num_agent_steps_trained: 1119462\n",
      "    num_steps_sampled: 1119462\n",
      "    num_steps_trained: 1119462\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.28926701570681\n",
      "    ram_util_percent: 48.325\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05398139901936287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.213487447688124\n",
      "    mean_inference_ms: 19.00199778086175\n",
      "    mean_raw_obs_processing_ms: 3.151280366266464\n",
      "  time_since_restore: 53017.58901786804\n",
      "  time_this_iter_s: 535.6871223449707\n",
      "  time_total_s: 66988.85578536987\n",
      "  timers:\n",
      "    learn_throughput: 28.188\n",
      "    learn_time_ms: 354622.803\n",
      "    load_throughput: 88842.432\n",
      "    load_time_ms: 112.514\n",
      "    sample_throughput: 52.27\n",
      "    sample_time_ms: 191239.238\n",
      "    update_time_ms: 4.475\n",
      "  timestamp: 1637327065\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1119462\n",
      "  training_iteration: 172\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         66988.9</td><td style=\"text-align: right;\">1119462</td><td style=\"text-align: right;\"> 3.42126</td><td style=\"text-align: right;\">               11.54</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">           48.3252</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1129458\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_13-13-52\n",
      "  done: false\n",
      "  episode_len_mean: 47.45497630331754\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.770000000000003\n",
      "  episode_reward_mean: 3.789478672985785\n",
      "  episode_reward_min: -1.2000000000000002\n",
      "  episodes_this_iter: 211\n",
      "  episodes_total: 21612\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.132328580062552\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0165581352981641\n",
      "          policy_loss: -0.06982717696759005\n",
      "          total_loss: 0.1359707282090758\n",
      "          vf_explained_var: 0.9085447192192078\n",
      "          vf_loss: 0.18939968839775861\n",
      "    num_agent_steps_sampled: 1129458\n",
      "    num_agent_steps_trained: 1129458\n",
      "    num_steps_sampled: 1129458\n",
      "    num_steps_trained: 1129458\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.81433868974042\n",
      "    ram_util_percent: 49.11458590852905\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.053974784399675166\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.215875499966884\n",
      "    mean_inference_ms: 18.995780695546056\n",
      "    mean_raw_obs_processing_ms: 3.1846904484627077\n",
      "  time_since_restore: 53584.477830171585\n",
      "  time_this_iter_s: 566.8888123035431\n",
      "  time_total_s: 67555.74459767342\n",
      "  timers:\n",
      "    learn_throughput: 28.185\n",
      "    learn_time_ms: 354662.002\n",
      "    load_throughput: 89349.466\n",
      "    load_time_ms: 111.875\n",
      "    sample_throughput: 51.841\n",
      "    sample_time_ms: 192819.286\n",
      "    update_time_ms: 4.221\n",
      "  timestamp: 1637327632\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1129458\n",
      "  training_iteration: 173\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         67555.7</td><td style=\"text-align: right;\">1129458</td><td style=\"text-align: right;\"> 3.78948</td><td style=\"text-align: right;\">               11.77</td><td style=\"text-align: right;\">                -1.2</td><td style=\"text-align: right;\">            47.455</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1139454\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_13-22-50\n",
      "  done: false\n",
      "  episode_len_mean: 47.8\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.410000000000005\n",
      "  episode_reward_mean: 3.5949523809523845\n",
      "  episode_reward_min: -1.4300000000000004\n",
      "  episodes_this_iter: 210\n",
      "  episodes_total: 21822\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.111138765112942\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016598222132283548\n",
      "          policy_loss: -0.06948087827220946\n",
      "          total_loss: 0.12604162981316408\n",
      "          vf_explained_var: 0.886981725692749\n",
      "          vf_loss: 0.17882106850441754\n",
      "    num_agent_steps_sampled: 1139454\n",
      "    num_agent_steps_trained: 1139454\n",
      "    num_steps_sampled: 1139454\n",
      "    num_steps_trained: 1139454\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.37770534550197\n",
      "    ram_util_percent: 48.63376792698828\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054014133113864486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.23082848312795\n",
      "    mean_inference_ms: 18.996289593459135\n",
      "    mean_raw_obs_processing_ms: 3.1664880761654386\n",
      "  time_since_restore: 54122.157238960266\n",
      "  time_this_iter_s: 537.679408788681\n",
      "  time_total_s: 68093.4240064621\n",
      "  timers:\n",
      "    learn_throughput: 28.183\n",
      "    learn_time_ms: 354680.834\n",
      "    load_throughput: 89480.968\n",
      "    load_time_ms: 111.711\n",
      "    sample_throughput: 51.84\n",
      "    sample_time_ms: 192822.47\n",
      "    update_time_ms: 4.575\n",
      "  timestamp: 1637328170\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1139454\n",
      "  training_iteration: 174\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">         68093.4</td><td style=\"text-align: right;\">1139454</td><td style=\"text-align: right;\"> 3.59495</td><td style=\"text-align: right;\">               13.41</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">              47.8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1149450\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_13-31-48\n",
      "  done: false\n",
      "  episode_len_mean: 48.23671497584541\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.550000000000004\n",
      "  episode_reward_mean: 4.132318840579713\n",
      "  episode_reward_min: -1.3700000000000003\n",
      "  episodes_this_iter: 207\n",
      "  episodes_total: 22029\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1221282804826176\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017937210030978465\n",
      "          policy_loss: -0.06714520598020408\n",
      "          total_loss: 0.155172944947108\n",
      "          vf_explained_var: 0.8896703720092773\n",
      "          vf_loss: 0.20267622721546055\n",
      "    num_agent_steps_sampled: 1149450\n",
      "    num_agent_steps_trained: 1149450\n",
      "    num_steps_sampled: 1149450\n",
      "    num_steps_trained: 1149450\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.21430429128739\n",
      "    ram_util_percent: 48.34798439531858\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054034539603372754\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.24851823821998\n",
      "    mean_inference_ms: 18.998410413230953\n",
      "    mean_raw_obs_processing_ms: 3.1461680460775794\n",
      "  time_since_restore: 54660.81922054291\n",
      "  time_this_iter_s: 538.6619815826416\n",
      "  time_total_s: 68632.08598804474\n",
      "  timers:\n",
      "    learn_throughput: 28.18\n",
      "    learn_time_ms: 354717.631\n",
      "    load_throughput: 89073.403\n",
      "    load_time_ms: 112.222\n",
      "    sample_throughput: 52.278\n",
      "    sample_time_ms: 191207.521\n",
      "    update_time_ms: 4.588\n",
      "  timestamp: 1637328708\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1149450\n",
      "  training_iteration: 175\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         68632.1</td><td style=\"text-align: right;\">1149450</td><td style=\"text-align: right;\"> 4.13232</td><td style=\"text-align: right;\">               11.55</td><td style=\"text-align: right;\">               -1.37</td><td style=\"text-align: right;\">           48.2367</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1159446\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_13-41-00\n",
      "  done: false\n",
      "  episode_len_mean: 47.54976303317535\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.420000000000007\n",
      "  episode_reward_mean: 3.5796682464455\n",
      "  episode_reward_min: -1.1500000000000004\n",
      "  episodes_this_iter: 211\n",
      "  episodes_total: 22240\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1228926635889644\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016314397692651778\n",
      "          policy_loss: -0.07010958979132617\n",
      "          total_loss: 0.12541152592936877\n",
      "          vf_explained_var: 0.902228832244873\n",
      "          vf_loss: 0.17958380332007165\n",
      "    num_agent_steps_sampled: 1159446\n",
      "    num_agent_steps_trained: 1159446\n",
      "    num_steps_sampled: 1159446\n",
      "    num_steps_trained: 1159446\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91168996188055\n",
      "    ram_util_percent: 48.614739517153744\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054036044712557074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.2574451642364\n",
      "    mean_inference_ms: 18.99864550696068\n",
      "    mean_raw_obs_processing_ms: 3.1609878406853773\n",
      "  time_since_restore: 55212.933564186096\n",
      "  time_this_iter_s: 552.1143436431885\n",
      "  time_total_s: 69184.20033168793\n",
      "  timers:\n",
      "    learn_throughput: 28.178\n",
      "    learn_time_ms: 354740.639\n",
      "    load_throughput: 89194.187\n",
      "    load_time_ms: 112.07\n",
      "    sample_throughput: 52.357\n",
      "    sample_time_ms: 190921.774\n",
      "    update_time_ms: 4.725\n",
      "  timestamp: 1637329260\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1159446\n",
      "  training_iteration: 176\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         69184.2</td><td style=\"text-align: right;\">1159446</td><td style=\"text-align: right;\"> 3.57967</td><td style=\"text-align: right;\">               13.42</td><td style=\"text-align: right;\">               -1.15</td><td style=\"text-align: right;\">           47.5498</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1169442\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_13-50-26\n",
      "  done: false\n",
      "  episode_len_mean: 46.990566037735846\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.640000000000004\n",
      "  episode_reward_mean: 3.648962264150947\n",
      "  episode_reward_min: -1.4200000000000004\n",
      "  episodes_this_iter: 212\n",
      "  episodes_total: 22452\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.132500566440414\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016913495806971702\n",
      "          policy_loss: -0.0722811968890699\n",
      "          total_loss: 0.1316809207821812\n",
      "          vf_explained_var: 0.8908615112304688\n",
      "          vf_loss: 0.1867560646272298\n",
      "    num_agent_steps_sampled: 1169442\n",
      "    num_agent_steps_trained: 1169442\n",
      "    num_steps_sampled: 1169442\n",
      "    num_steps_trained: 1169442\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.95315985130112\n",
      "    ram_util_percent: 48.23977695167285\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05403822354596229\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.2650204448748\n",
      "    mean_inference_ms: 18.99561363625578\n",
      "    mean_raw_obs_processing_ms: 3.17480531719598\n",
      "  time_since_restore: 55778.09089779854\n",
      "  time_this_iter_s: 565.157333612442\n",
      "  time_total_s: 69749.35766530037\n",
      "  timers:\n",
      "    learn_throughput: 28.182\n",
      "    learn_time_ms: 354695.725\n",
      "    load_throughput: 89044.44\n",
      "    load_time_ms: 112.259\n",
      "    sample_throughput: 51.895\n",
      "    sample_time_ms: 192618.262\n",
      "    update_time_ms: 5.037\n",
      "  timestamp: 1637329826\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1169442\n",
      "  training_iteration: 177\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         69749.4</td><td style=\"text-align: right;\">1169442</td><td style=\"text-align: right;\"> 3.64896</td><td style=\"text-align: right;\">               11.64</td><td style=\"text-align: right;\">               -1.42</td><td style=\"text-align: right;\">           46.9906</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1179438\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_13-59-48\n",
      "  done: false\n",
      "  episode_len_mean: 46.967136150234744\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.580000000000005\n",
      "  episode_reward_mean: 3.5183568075117395\n",
      "  episode_reward_min: -1.2900000000000003\n",
      "  episodes_this_iter: 213\n",
      "  episodes_total: 22665\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1398875660685652\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017159654855527447\n",
      "          policy_loss: -0.07095698384483004\n",
      "          total_loss: 0.12274051167302703\n",
      "          vf_explained_var: 0.9070926308631897\n",
      "          vf_loss: 0.1760045315519566\n",
      "    num_agent_steps_sampled: 1179438\n",
      "    num_agent_steps_trained: 1179438\n",
      "    num_steps_sampled: 1179438\n",
      "    num_steps_trained: 1179438\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.93179551122194\n",
      "    ram_util_percent: 48.28952618453864\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054021977155884776\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.27337612139417\n",
      "    mean_inference_ms: 18.995194688626604\n",
      "    mean_raw_obs_processing_ms: 3.1841055888430287\n",
      "  time_since_restore: 56340.16342949867\n",
      "  time_this_iter_s: 562.0725317001343\n",
      "  time_total_s: 70311.4301970005\n",
      "  timers:\n",
      "    learn_throughput: 28.183\n",
      "    learn_time_ms: 354676.485\n",
      "    load_throughput: 88921.458\n",
      "    load_time_ms: 112.414\n",
      "    sample_throughput: 51.273\n",
      "    sample_time_ms: 194957.612\n",
      "    update_time_ms: 5.079\n",
      "  timestamp: 1637330388\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1179438\n",
      "  training_iteration: 178\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   178</td><td style=\"text-align: right;\">         70311.4</td><td style=\"text-align: right;\">1179438</td><td style=\"text-align: right;\"> 3.51836</td><td style=\"text-align: right;\">               11.58</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           46.9671</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1189434\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_14-09-00\n",
      "  done: false\n",
      "  episode_len_mean: 47.29857819905213\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.560000000000006\n",
      "  episode_reward_mean: 4.050331753554506\n",
      "  episode_reward_min: -1.1400000000000001\n",
      "  episodes_this_iter: 211\n",
      "  episodes_total: 22876\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.146425505479177\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017828416768532338\n",
      "          policy_loss: -0.0692170857792891\n",
      "          total_loss: 0.13210282262150713\n",
      "          vf_explained_var: 0.8772870898246765\n",
      "          vf_loss: 0.1821688006169174\n",
      "    num_agent_steps_sampled: 1189434\n",
      "    num_agent_steps_trained: 1189434\n",
      "    num_steps_sampled: 1189434\n",
      "    num_steps_trained: 1189434\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.86535532994922\n",
      "    ram_util_percent: 48.3996192893401\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054010464984532346\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.28175056712125\n",
      "    mean_inference_ms: 18.994278023476248\n",
      "    mean_raw_obs_processing_ms: 3.2000778941178782\n",
      "  time_since_restore: 56892.84645152092\n",
      "  time_this_iter_s: 552.6830220222473\n",
      "  time_total_s: 70864.11321902275\n",
      "  timers:\n",
      "    learn_throughput: 28.183\n",
      "    learn_time_ms: 354678.341\n",
      "    load_throughput: 89130.476\n",
      "    load_time_ms: 112.15\n",
      "    sample_throughput: 51.198\n",
      "    sample_time_ms: 195241.215\n",
      "    update_time_ms: 5.386\n",
      "  timestamp: 1637330940\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1189434\n",
      "  training_iteration: 179\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         70864.1</td><td style=\"text-align: right;\">1189434</td><td style=\"text-align: right;\"> 4.05033</td><td style=\"text-align: right;\">               13.56</td><td style=\"text-align: right;\">               -1.14</td><td style=\"text-align: right;\">           47.2986</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1199430\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_14-18-12\n",
      "  done: false\n",
      "  episode_len_mean: 47.880382775119614\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.310000000000008\n",
      "  episode_reward_mean: 3.6775119617224914\n",
      "  episode_reward_min: -1.6000000000000005\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 23085\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1369849511657852\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015870235194004764\n",
      "          policy_loss: -0.07014658582594571\n",
      "          total_loss: 0.108819935949408\n",
      "          vf_explained_var: 0.8985688090324402\n",
      "          vf_loss: 0.16418199085005855\n",
      "    num_agent_steps_sampled: 1199430\n",
      "    num_agent_steps_trained: 1199430\n",
      "    num_steps_sampled: 1199430\n",
      "    num_steps_trained: 1199430\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.18907242693773\n",
      "    ram_util_percent: 48.668233799237605\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05403398922420532\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.292246357501\n",
      "    mean_inference_ms: 18.994506633090452\n",
      "    mean_raw_obs_processing_ms: 3.1987346287443086\n",
      "  time_since_restore: 57444.33553171158\n",
      "  time_this_iter_s: 551.4890801906586\n",
      "  time_total_s: 71415.60229921341\n",
      "  timers:\n",
      "    learn_throughput: 28.177\n",
      "    learn_time_ms: 354756.681\n",
      "    load_throughput: 89229.875\n",
      "    load_time_ms: 112.025\n",
      "    sample_throughput: 51.235\n",
      "    sample_time_ms: 195102.769\n",
      "    update_time_ms: 5.374\n",
      "  timestamp: 1637331492\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1199430\n",
      "  training_iteration: 180\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   180</td><td style=\"text-align: right;\">         71415.6</td><td style=\"text-align: right;\">1199430</td><td style=\"text-align: right;\"> 3.67751</td><td style=\"text-align: right;\">               13.31</td><td style=\"text-align: right;\">                -1.6</td><td style=\"text-align: right;\">           47.8804</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1209426\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_14-27-22\n",
      "  done: false\n",
      "  episode_len_mean: 47.75598086124402\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.510000000000005\n",
      "  episode_reward_mean: 3.5612918660287116\n",
      "  episode_reward_min: -1.4700000000000004\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 23294\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1318865357153864\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016239719263516764\n",
      "          policy_loss: -0.067629702200698\n",
      "          total_loss: 0.12038286293012876\n",
      "          vf_explained_var: 0.8861465454101562\n",
      "          vf_loss: 0.1723353188393271\n",
      "    num_agent_steps_sampled: 1209426\n",
      "    num_agent_steps_trained: 1209426\n",
      "    num_steps_sampled: 1209426\n",
      "    num_steps_trained: 1209426\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.9932484076433\n",
      "    ram_util_percent: 48.629171974522286\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05401180451348918\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.29730624609164\n",
      "    mean_inference_ms: 18.9941229159604\n",
      "    mean_raw_obs_processing_ms: 3.1981112503214346\n",
      "  time_since_restore: 57994.36165690422\n",
      "  time_this_iter_s: 550.0261251926422\n",
      "  time_total_s: 71965.62842440605\n",
      "  timers:\n",
      "    learn_throughput: 28.177\n",
      "    learn_time_ms: 354752.216\n",
      "    load_throughput: 89027.026\n",
      "    load_time_ms: 112.281\n",
      "    sample_throughput: 50.906\n",
      "    sample_time_ms: 196362.833\n",
      "    update_time_ms: 4.977\n",
      "  timestamp: 1637332042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1209426\n",
      "  training_iteration: 181\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         71965.6</td><td style=\"text-align: right;\">1209426</td><td style=\"text-align: right;\"> 3.56129</td><td style=\"text-align: right;\">               11.51</td><td style=\"text-align: right;\">               -1.47</td><td style=\"text-align: right;\">            47.756</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1219422\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_14-36-18\n",
      "  done: false\n",
      "  episode_len_mean: 48.68780487804878\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.380000000000006\n",
      "  episode_reward_mean: 3.7815121951219544\n",
      "  episode_reward_min: -1.2900000000000003\n",
      "  episodes_this_iter: 205\n",
      "  episodes_total: 23499\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.161163891630479\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018155697971804215\n",
      "          policy_loss: -0.06917311402938205\n",
      "          total_loss: 0.14966117294815665\n",
      "          vf_explained_var: 0.8865032196044922\n",
      "          vf_loss: 0.19908497493609367\n",
      "    num_agent_steps_sampled: 1219422\n",
      "    num_agent_steps_trained: 1219422\n",
      "    num_steps_sampled: 1219422\n",
      "    num_steps_trained: 1219422\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.19725490196078\n",
      "    ram_util_percent: 48.419999999999995\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054039341505345624\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.30539428381936\n",
      "    mean_inference_ms: 18.99517284134568\n",
      "    mean_raw_obs_processing_ms: 3.1804654935426324\n",
      "  time_since_restore: 58530.57423496246\n",
      "  time_this_iter_s: 536.2125780582428\n",
      "  time_total_s: 72501.8410024643\n",
      "  timers:\n",
      "    learn_throughput: 28.173\n",
      "    learn_time_ms: 354805.684\n",
      "    load_throughput: 89128.827\n",
      "    load_time_ms: 112.152\n",
      "    sample_throughput: 50.906\n",
      "    sample_time_ms: 196361.648\n",
      "    update_time_ms: 5.083\n",
      "  timestamp: 1637332578\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1219422\n",
      "  training_iteration: 182\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         72501.8</td><td style=\"text-align: right;\">1219422</td><td style=\"text-align: right;\"> 3.78151</td><td style=\"text-align: right;\">               13.38</td><td style=\"text-align: right;\">               -1.29</td><td style=\"text-align: right;\">           48.6878</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1229418\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_14-45-50\n",
      "  done: false\n",
      "  episode_len_mean: 47.5260663507109\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 11.660000000000004\n",
      "  episode_reward_mean: 3.6336966824644583\n",
      "  episode_reward_min: -1.3500000000000003\n",
      "  episodes_this_iter: 211\n",
      "  episodes_total: 23710\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.155574660487922\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01677190834448781\n",
      "          policy_loss: -0.07273966067205695\n",
      "          total_loss: 0.12154350413149484\n",
      "          vf_explained_var: 0.9031069874763489\n",
      "          vf_loss: 0.17763040609962594\n",
      "    num_agent_steps_sampled: 1229418\n",
      "    num_agent_steps_trained: 1229418\n",
      "    num_steps_sampled: 1229418\n",
      "    num_steps_trained: 1229418\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.82120098039216\n",
      "    ram_util_percent: 49.19914215686274\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05401598067299259\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.30473371783618\n",
      "    mean_inference_ms: 18.992387741188473\n",
      "    mean_raw_obs_processing_ms: 3.21908657132312\n",
      "  time_since_restore: 59102.50565981865\n",
      "  time_this_iter_s: 571.9314248561859\n",
      "  time_total_s: 73073.77242732048\n",
      "  timers:\n",
      "    learn_throughput: 28.174\n",
      "    learn_time_ms: 354796.436\n",
      "    load_throughput: 88958.551\n",
      "    load_time_ms: 112.367\n",
      "    sample_throughput: 50.773\n",
      "    sample_time_ms: 196874.831\n",
      "    update_time_ms: 5.308\n",
      "  timestamp: 1637333150\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1229418\n",
      "  training_iteration: 183\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">         73073.8</td><td style=\"text-align: right;\">1229418</td><td style=\"text-align: right;\">  3.6337</td><td style=\"text-align: right;\">               11.66</td><td style=\"text-align: right;\">               -1.35</td><td style=\"text-align: right;\">           47.5261</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1239414\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_14-54-46\n",
      "  done: false\n",
      "  episode_len_mean: 47.85096153846154\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.540000000000006\n",
      "  episode_reward_mean: 3.8589423076923115\n",
      "  episode_reward_min: -1.2600000000000002\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 23918\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.165029764247228\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017940197846153257\n",
      "          policy_loss: -0.062301903444849774\n",
      "          total_loss: 0.15741322441600172\n",
      "          vf_explained_var: 0.8916301131248474\n",
      "          vf_loss: 0.20049541056133716\n",
      "    num_agent_steps_sampled: 1239414\n",
      "    num_agent_steps_trained: 1239414\n",
      "    num_steps_sampled: 1239414\n",
      "    num_steps_trained: 1239414\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.32539267015707\n",
      "    ram_util_percent: 48.45785340314136\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054061353998260585\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.313562940630696\n",
      "    mean_inference_ms: 18.991425111204954\n",
      "    mean_raw_obs_processing_ms: 3.202180208852562\n",
      "  time_since_restore: 59638.20541238785\n",
      "  time_this_iter_s: 535.6997525691986\n",
      "  time_total_s: 73609.47217988968\n",
      "  timers:\n",
      "    learn_throughput: 28.175\n",
      "    learn_time_ms: 354785.732\n",
      "    load_throughput: 88835.655\n",
      "    load_time_ms: 112.522\n",
      "    sample_throughput: 50.822\n",
      "    sample_time_ms: 196687.285\n",
      "    update_time_ms: 4.973\n",
      "  timestamp: 1637333686\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1239414\n",
      "  training_iteration: 184\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   184</td><td style=\"text-align: right;\">         73609.5</td><td style=\"text-align: right;\">1239414</td><td style=\"text-align: right;\"> 3.85894</td><td style=\"text-align: right;\">               13.54</td><td style=\"text-align: right;\">               -1.26</td><td style=\"text-align: right;\">            47.851</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1249410\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_15-03-45\n",
      "  done: false\n",
      "  episode_len_mean: 47.714285714285715\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.250000000000005\n",
      "  episode_reward_mean: 3.389238095238098\n",
      "  episode_reward_min: -1.3100000000000003\n",
      "  episodes_this_iter: 210\n",
      "  episodes_total: 24128\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.180219031050502\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01560458169163727\n",
      "          policy_loss: -0.06964567655912975\n",
      "          total_loss: 0.11155740895623582\n",
      "          vf_explained_var: 0.8996003270149231\n",
      "          vf_loss: 0.1674560859696528\n",
      "    num_agent_steps_sampled: 1249410\n",
      "    num_agent_steps_trained: 1249410\n",
      "    num_steps_sampled: 1249410\n",
      "    num_steps_trained: 1249410\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.43701298701299\n",
      "    ram_util_percent: 48.03649350649351\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05406490449935338\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.32559301875736\n",
      "    mean_inference_ms: 18.994322406590015\n",
      "    mean_raw_obs_processing_ms: 3.185165057417785\n",
      "  time_since_restore: 60177.521475315094\n",
      "  time_this_iter_s: 539.3160629272461\n",
      "  time_total_s: 74148.78824281693\n",
      "  timers:\n",
      "    learn_throughput: 28.172\n",
      "    learn_time_ms: 354816.576\n",
      "    load_throughput: 88922.382\n",
      "    load_time_ms: 112.413\n",
      "    sample_throughput: 50.813\n",
      "    sample_time_ms: 196722.287\n",
      "    update_time_ms: 5.252\n",
      "  timestamp: 1637334225\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1249410\n",
      "  training_iteration: 185\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         74148.8</td><td style=\"text-align: right;\">1249410</td><td style=\"text-align: right;\"> 3.38924</td><td style=\"text-align: right;\">               13.25</td><td style=\"text-align: right;\">               -1.31</td><td style=\"text-align: right;\">           47.7143</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1259406\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_15-12-55\n",
      "  done: false\n",
      "  episode_len_mean: 47.8421052631579\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.580000000000005\n",
      "  episode_reward_mean: 3.9287081339712953\n",
      "  episode_reward_min: -1.1900000000000002\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 24337\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1816094185214445\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01706629242890284\n",
      "          policy_loss: -0.06791903973069888\n",
      "          total_loss: 0.13097198607951338\n",
      "          vf_explained_var: 0.8936988115310669\n",
      "          vf_loss: 0.18182797246597648\n",
      "    num_agent_steps_sampled: 1259406\n",
      "    num_agent_steps_trained: 1259406\n",
      "    num_steps_sampled: 1259406\n",
      "    num_steps_trained: 1259406\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.91237244897958\n",
      "    ram_util_percent: 48.50663265306122\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.054051396278869436\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.32779217699414\n",
      "    mean_inference_ms: 18.993024220426896\n",
      "    mean_raw_obs_processing_ms: 3.214595203302263\n",
      "  time_since_restore: 60727.02076125145\n",
      "  time_this_iter_s: 549.4992859363556\n",
      "  time_total_s: 74698.28752875328\n",
      "  timers:\n",
      "    learn_throughput: 28.176\n",
      "    learn_time_ms: 354765.074\n",
      "    load_throughput: 89029.502\n",
      "    load_time_ms: 112.277\n",
      "    sample_throughput: 50.867\n",
      "    sample_time_ms: 196512.685\n",
      "    update_time_ms: 5.141\n",
      "  timestamp: 1637334775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1259406\n",
      "  training_iteration: 186\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         74698.3</td><td style=\"text-align: right;\">1259406</td><td style=\"text-align: right;\"> 3.92871</td><td style=\"text-align: right;\">               13.58</td><td style=\"text-align: right;\">               -1.19</td><td style=\"text-align: right;\">           47.8421</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1269402\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_15-21-52\n",
      "  done: false\n",
      "  episode_len_mean: 48.08173076923077\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.470000000000006\n",
      "  episode_reward_mean: 3.2993269230769253\n",
      "  episode_reward_min: -1.1800000000000002\n",
      "  episodes_this_iter: 208\n",
      "  episodes_total: 24545\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.201094838797328\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016557770503100706\n",
      "          policy_loss: -0.06418156716489352\n",
      "          total_loss: 0.13493029851385827\n",
      "          vf_explained_var: 0.8977556824684143\n",
      "          vf_loss: 0.1834021413009651\n",
      "    num_agent_steps_sampled: 1269402\n",
      "    num_agent_steps_trained: 1269402\n",
      "    num_steps_sampled: 1269402\n",
      "    num_steps_trained: 1269402\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.18590078328981\n",
      "    ram_util_percent: 48.18968668407311\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0540689445028975\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.33780102401104\n",
      "    mean_inference_ms: 18.994885932285456\n",
      "    mean_raw_obs_processing_ms: 3.1974721736699916\n",
      "  time_since_restore: 61263.85693836212\n",
      "  time_this_iter_s: 536.836177110672\n",
      "  time_total_s: 75235.12370586395\n",
      "  timers:\n",
      "    learn_throughput: 28.179\n",
      "    learn_time_ms: 354729.486\n",
      "    load_throughput: 89162.586\n",
      "    load_time_ms: 112.11\n",
      "    sample_throughput: 51.601\n",
      "    sample_time_ms: 193716.162\n",
      "    update_time_ms: 5.057\n",
      "  timestamp: 1637335312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1269402\n",
      "  training_iteration: 187\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         75235.1</td><td style=\"text-align: right;\">1269402</td><td style=\"text-align: right;\"> 3.29933</td><td style=\"text-align: right;\">               13.47</td><td style=\"text-align: right;\">               -1.18</td><td style=\"text-align: right;\">           48.0817</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1279398\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_15-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 47.64114832535885\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.740000000000004\n",
      "  episode_reward_mean: 3.703444976076558\n",
      "  episode_reward_min: -1.4300000000000006\n",
      "  episodes_this_iter: 209\n",
      "  episodes_total: 24754\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.187438356660935\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01629508388726498\n",
      "          policy_loss: -0.06586064897738217\n",
      "          total_loss: 0.12612879602182944\n",
      "          vf_explained_var: 0.8742015957832336\n",
      "          vf_loss: 0.17674158847419522\n",
      "    num_agent_steps_sampled: 1279398\n",
      "    num_agent_steps_trained: 1279398\n",
      "    num_steps_sampled: 1279398\n",
      "    num_steps_trained: 1279398\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.5649188514357\n",
      "    ram_util_percent: 48.372534332084896\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05407104246566961\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.34352882122018\n",
      "    mean_inference_ms: 18.996360781895522\n",
      "    mean_raw_obs_processing_ms: 3.2067803128996806\n",
      "  time_since_restore: 61825.464854478836\n",
      "  time_this_iter_s: 561.6079161167145\n",
      "  time_total_s: 75796.73162198067\n",
      "  timers:\n",
      "    learn_throughput: 28.184\n",
      "    learn_time_ms: 354670.112\n",
      "    load_throughput: 89401.612\n",
      "    load_time_ms: 111.81\n",
      "    sample_throughput: 51.598\n",
      "    sample_time_ms: 193729.065\n",
      "    update_time_ms: 5.396\n",
      "  timestamp: 1637335873\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1279398\n",
      "  training_iteration: 188\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">         75796.7</td><td style=\"text-align: right;\">1279398</td><td style=\"text-align: right;\"> 3.70344</td><td style=\"text-align: right;\">               13.74</td><td style=\"text-align: right;\">               -1.43</td><td style=\"text-align: right;\">           47.6411</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101981)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ab24a_00000:\n",
      "  agent_timesteps_total: 1289394\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-19_15-40-37\n",
      "  done: false\n",
      "  episode_len_mean: 47.89047619047619\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 13.600000000000003\n",
      "  episode_reward_mean: 3.9950000000000037\n",
      "  episode_reward_min: -1.1700000000000002\n",
      "  episodes_this_iter: 210\n",
      "  episodes_total: 24964\n",
      "  experiment_id: 61c3754b92a44256b5093c1912448244\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 2.2781249999999997\n",
      "          cur_lr: 5.000000000000001e-05\n",
      "          entropy: 2.1732201084075684\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016140844397435496\n",
      "          policy_loss: -0.0701603643100726\n",
      "          total_loss: 0.11665490858136603\n",
      "          vf_explained_var: 0.9242907166481018\n",
      "          vf_loss: 0.1717766118191003\n",
      "    num_agent_steps_sampled: 1289394\n",
      "    num_agent_steps_trained: 1289394\n",
      "    num_steps_sampled: 1289394\n",
      "    num_steps_trained: 1289394\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75913043478262\n",
      "    ram_util_percent: 48.6175155279503\n",
      "  pid: 101983\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05410460549544151\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.345268065149504\n",
      "    mean_inference_ms: 18.993332168405093\n",
      "    mean_raw_obs_processing_ms: 3.221270127155276\n",
      "  time_since_restore: 62389.595621585846\n",
      "  time_this_iter_s: 564.1307671070099\n",
      "  time_total_s: 76360.86238908768\n",
      "  timers:\n",
      "    learn_throughput: 28.191\n",
      "    learn_time_ms: 354580.074\n",
      "    load_throughput: 89183.107\n",
      "    load_time_ms: 112.084\n",
      "    sample_throughput: 51.271\n",
      "    sample_time_ms: 194964.444\n",
      "    update_time_ms: 5.11\n",
      "  timestamp: 1637336437\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1289394\n",
      "  training_iteration: 189\n",
      "  trial_id: ab24a_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 22.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/24.1 GiB heap, 0.0/12.05 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3/PPO_2021-11-18_22-19-59<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ab24a_00000</td><td>RUNNING </td><td>192.168.3.5:101983</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">         76360.9</td><td style=\"text-align: right;\">1289394</td><td style=\"text-align: right;\">   3.995</td><td style=\"text-align: right;\">                13.6</td><td style=\"text-align: right;\">               -1.17</td><td style=\"text-align: right;\">           47.8905</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101982)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=101984)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 60,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 5_000,\n",
    "             #\"lr\": 1e-4,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO (AUG ALL) pretrained (visual pretrained AngelaCNN + CrossAttn 3)\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/all_tasks_aug_cross_attn3\",\n",
    "        keep_checkpoints_num=100,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True,\n",
    "        restore=\"/IGLU-Minecraft/checkpoints/3_tasks_aug_cross_attn3/PPO_2021-11-18_17-44-45/PPO_my_env_37c4c_00000_0_2021-11-18_17-44-45/checkpoint_000075/checkpoint-75\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dde63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
