{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 256 \n",
    "        self.policy_network = nn.Sequential(\n",
    "            nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            #nn.ELU(),\n",
    "        )\n",
    "        self.action_head = nn.Linear(policy_hidden_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(policy_hidden_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        target_features = target_features.reshape(target_features.shape[0], -1)\n",
    "        features = torch.cat([visual_features, target_features], dim=1)\n",
    "        features = self.policy_network(features)\n",
    "        action = self.action_head(features)\n",
    "        self.last_value = self.value_head(features).squeeze(1)\n",
    "        return action, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592760ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2362368"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_features_dim = 512\n",
    "target_features_dim = 9 * 11 * 11\n",
    "policy_hidden_dim = 256 \n",
    "\n",
    "policy_network = nn.Sequential(\n",
    "    nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(512, policy_hidden_dim),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "    nn.ELU(),\n",
    "    #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "    #nn.ELU(),\n",
    ")\n",
    "\n",
    "sum(p.numel() for p in policy_network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "            \n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=500)\n",
    "    env.update_taskset(TaskSet(preset=['C3',  'C17', 'C20',\n",
    "                                       'C22', 'C32', 'C40',\n",
    "                                       'C85', 'C87', 'C93']))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n",
      "2021-11-06 18:47:04,029\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-11-06 18:47:04,045\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 12.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id c1a69_00000 but id ef0ef_00000 is set.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[2m\u001b[36m(pid=480903)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480903)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO MultiTask <=10 pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/ef0ef_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/ef0ef_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20211106_184704-ef0ef_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480903)\u001b[0m 2021-11-06 18:47:07,458\tWARNING ppo.py:143 -- `train_batch_size` (5000) cannot be achieved with your other settings (num_workers=3 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 1666.\n",
      "\u001b[2m\u001b[36m(pid=480903)\u001b[0m 2021-11-06 18:47:07,458\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=480903)\u001b[0m 2021-11-06 18:47:07,458\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480903)\u001b[0m 2021-11-06 18:47:13,426\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warn(RuntimeWarning(msg))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl_patched.utils.process_watcher' found in sys.modules after import of package 'minerl_patched.utils', but prior to execution of 'minerl_patched.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 9996\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_18-51-05\n",
      "  done: false\n",
      "  episode_len_mean: 200.39583333333334\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.8800000000000023\n",
      "  episode_reward_mean: -1.2727083333333329\n",
      "  episode_reward_min: -3.019999999999994\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 48\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.8797739416106136\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.008081097647910228\n",
      "          policy_loss: -0.02008541603373666\n",
      "          total_loss: 0.06370990906770413\n",
      "          vf_explained_var: -0.22477690875530243\n",
      "          vf_loss: 0.11097684448913762\n",
      "    num_agent_steps_sampled: 9996\n",
      "    num_agent_steps_trained: 9996\n",
      "    num_steps_sampled: 9996\n",
      "    num_steps_trained: 9996\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.8487951807229\n",
      "    ram_util_percent: 43.72620481927711\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04365499263549402\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 60.72206675547315\n",
      "    mean_inference_ms: 2.497032125278263\n",
      "    mean_raw_obs_processing_ms: 0.952678938510001\n",
      "  time_since_restore: 232.09238624572754\n",
      "  time_this_iter_s: 232.09238624572754\n",
      "  time_total_s: 232.09238624572754\n",
      "  timers:\n",
      "    learn_throughput: 1056.534\n",
      "    learn_time_ms: 9461.125\n",
      "    load_throughput: 91934.486\n",
      "    load_time_ms: 108.73\n",
      "    sample_throughput: 44.928\n",
      "    sample_time_ms: 222491.433\n",
      "    update_time_ms: 9.116\n",
      "  timestamp: 1636224665\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9996\n",
      "  training_iteration: 1\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         232.092</td><td style=\"text-align: right;\">9996</td><td style=\"text-align: right;\">-1.27271</td><td style=\"text-align: right;\">                1.88</td><td style=\"text-align: right;\">               -3.02</td><td style=\"text-align: right;\">           200.396</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 19992\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_18-52-53\n",
      "  done: false\n",
      "  episode_len_mean: 202.84536082474227\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 1.8800000000000023\n",
      "  episode_reward_mean: -1.085876288659793\n",
      "  episode_reward_min: -3.019999999999994\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 97\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.8607627041319494\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.011250534336129502\n",
      "          policy_loss: -0.02113158804261022\n",
      "          total_loss: 0.10540727802958244\n",
      "          vf_explained_var: 0.07498275488615036\n",
      "          vf_loss: 0.15289638614297932\n",
      "    num_agent_steps_sampled: 19992\n",
      "    num_agent_steps_trained: 19992\n",
      "    num_steps_sampled: 19992\n",
      "    num_steps_trained: 19992\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.28961038961037\n",
      "    ram_util_percent: 51.29805194805195\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04380210148208071\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 51.91532498776577\n",
      "    mean_inference_ms: 2.5002991476296907\n",
      "    mean_raw_obs_processing_ms: 0.8019794321275325\n",
      "  time_since_restore: 340.4065625667572\n",
      "  time_this_iter_s: 108.31417632102966\n",
      "  time_total_s: 340.4065625667572\n",
      "  timers:\n",
      "    learn_throughput: 1058.708\n",
      "    learn_time_ms: 9441.699\n",
      "    load_throughput: 91096.422\n",
      "    load_time_ms: 109.73\n",
      "    sample_throughput: 62.238\n",
      "    sample_time_ms: 160610.529\n",
      "    update_time_ms: 10.157\n",
      "  timestamp: 1636224773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 19992\n",
      "  training_iteration: 2\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         340.407</td><td style=\"text-align: right;\">19992</td><td style=\"text-align: right;\">-1.08588</td><td style=\"text-align: right;\">                1.88</td><td style=\"text-align: right;\">               -3.02</td><td style=\"text-align: right;\">           202.845</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 29988\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_18-55-01\n",
      "  done: false\n",
      "  episode_len_mean: 204.53\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.110000000000029\n",
      "  episode_reward_mean: -0.7794999999999983\n",
      "  episode_reward_min: -2.849999999999993\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 145\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.8464959556220943\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01322233132716843\n",
      "          policy_loss: -0.02388313355990964\n",
      "          total_loss: 0.17145574445493966\n",
      "          vf_explained_var: 0.163921520113945\n",
      "          vf_loss: 0.22115937053966217\n",
      "    num_agent_steps_sampled: 29988\n",
      "    num_agent_steps_trained: 29988\n",
      "    num_steps_sampled: 29988\n",
      "    num_steps_trained: 29988\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.30327868852457\n",
      "    ram_util_percent: 51.425683060109286\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04378635555464291\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 41.05988963901177\n",
      "    mean_inference_ms: 2.5010373952826326\n",
      "    mean_raw_obs_processing_ms: 0.9150936712050544\n",
      "  time_since_restore: 468.28531861305237\n",
      "  time_this_iter_s: 127.87875604629517\n",
      "  time_total_s: 468.28531861305237\n",
      "  timers:\n",
      "    learn_throughput: 1058.847\n",
      "    learn_time_ms: 9440.455\n",
      "    load_throughput: 91633.625\n",
      "    load_time_ms: 109.087\n",
      "    sample_throughput: 68.23\n",
      "    sample_time_ms: 146504.242\n",
      "    update_time_ms: 11.02\n",
      "  timestamp: 1636224901\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 29988\n",
      "  training_iteration: 3\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         468.285</td><td style=\"text-align: right;\">29988</td><td style=\"text-align: right;\"> -0.7795</td><td style=\"text-align: right;\">                5.11</td><td style=\"text-align: right;\">               -2.85</td><td style=\"text-align: right;\">            204.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 39984\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_18-57-27\n",
      "  done: false\n",
      "  episode_len_mean: 203.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.110000000000029\n",
      "  episode_reward_mean: -0.21619999999999634\n",
      "  episode_reward_min: -3.2299999999999813\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 196\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.825464665176522\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01352720382198351\n",
      "          policy_loss: -0.025367344358665313\n",
      "          total_loss: 0.18918303084583618\n",
      "          vf_explained_var: 0.310432493686676\n",
      "          vf_loss: 0.24009958113519808\n",
      "    num_agent_steps_sampled: 39984\n",
      "    num_agent_steps_trained: 39984\n",
      "    num_steps_sampled: 39984\n",
      "    num_steps_trained: 39984\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.6705314009662\n",
      "    ram_util_percent: 51.62850241545894\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04350196822808467\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 36.391553025725614\n",
      "    mean_inference_ms: 2.4910674850475094\n",
      "    mean_raw_obs_processing_ms: 1.5047743832878342\n",
      "  time_since_restore: 613.7975659370422\n",
      "  time_this_iter_s: 145.51224732398987\n",
      "  time_total_s: 613.7975659370422\n",
      "  timers:\n",
      "    learn_throughput: 1058.973\n",
      "    learn_time_ms: 9439.333\n",
      "    load_throughput: 91230.719\n",
      "    load_time_ms: 109.568\n",
      "    sample_throughput: 69.482\n",
      "    sample_time_ms: 143864.619\n",
      "    update_time_ms: 9.919\n",
      "  timestamp: 1636225047\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39984\n",
      "  training_iteration: 4\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.8/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         613.798</td><td style=\"text-align: right;\">39984</td><td style=\"text-align: right;\"> -0.2162</td><td style=\"text-align: right;\">                5.11</td><td style=\"text-align: right;\">               -3.23</td><td style=\"text-align: right;\">            203.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 49980\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_18-59-23\n",
      "  done: false\n",
      "  episode_len_mean: 205.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 3.740000000000019\n",
      "  episode_reward_mean: -0.036899999999995076\n",
      "  episode_reward_min: -3.2299999999999813\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 243\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.805906440457727\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014333567865945288\n",
      "          policy_loss: -0.02555209455979813\n",
      "          total_loss: 0.2307128119521225\n",
      "          vf_explained_var: 0.2717740833759308\n",
      "          vf_loss: 0.2814572568377878\n",
      "    num_agent_steps_sampled: 49980\n",
      "    num_agent_steps_trained: 49980\n",
      "    num_steps_sampled: 49980\n",
      "    num_steps_trained: 49980\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.90301204819276\n",
      "    ram_util_percent: 52.57289156626506\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04335368188673295\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 34.423742037560686\n",
      "    mean_inference_ms: 2.4831375143580354\n",
      "    mean_raw_obs_processing_ms: 1.7010891721359473\n",
      "  time_since_restore: 730.1286866664886\n",
      "  time_this_iter_s: 116.33112072944641\n",
      "  time_total_s: 730.1286866664886\n",
      "  timers:\n",
      "    learn_throughput: 1057.777\n",
      "    learn_time_ms: 9450.007\n",
      "    load_throughput: 90946.261\n",
      "    load_time_ms: 109.911\n",
      "    sample_throughput: 73.267\n",
      "    sample_time_ms: 136432.975\n",
      "    update_time_ms: 9.023\n",
      "  timestamp: 1636225163\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 49980\n",
      "  training_iteration: 5\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         730.129</td><td style=\"text-align: right;\">49980</td><td style=\"text-align: right;\"> -0.0369</td><td style=\"text-align: right;\">                3.74</td><td style=\"text-align: right;\">               -3.23</td><td style=\"text-align: right;\">            205.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 59976\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-01-44\n",
      "  done: false\n",
      "  episode_len_mean: 207.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.150000000000001\n",
      "  episode_reward_mean: 0.14130000000000598\n",
      "  episode_reward_min: -3.389999999999989\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 292\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7795258112442798\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016481228214389285\n",
      "          policy_loss: -0.025772445094891083\n",
      "          total_loss: 0.24201763234873358\n",
      "          vf_explained_var: 0.44720637798309326\n",
      "          vf_loss: 0.29228908826206995\n",
      "    num_agent_steps_sampled: 59976\n",
      "    num_agent_steps_trained: 59976\n",
      "    num_steps_sampled: 59976\n",
      "    num_steps_trained: 59976\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.75024875621891\n",
      "    ram_util_percent: 52.67910447761195\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04342042896468957\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 33.06064112567588\n",
      "    mean_inference_ms: 2.480720328527227\n",
      "    mean_raw_obs_processing_ms: 1.8942699735320139\n",
      "  time_since_restore: 870.4338202476501\n",
      "  time_this_iter_s: 140.3051335811615\n",
      "  time_total_s: 870.4338202476501\n",
      "  timers:\n",
      "    learn_throughput: 1057.889\n",
      "    learn_time_ms: 9449.005\n",
      "    load_throughput: 91074.523\n",
      "    load_time_ms: 109.756\n",
      "    sample_throughput: 73.78\n",
      "    sample_time_ms: 135483.141\n",
      "    update_time_ms: 8.81\n",
      "  timestamp: 1636225304\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 59976\n",
      "  training_iteration: 6\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         870.434</td><td style=\"text-align: right;\">59976</td><td style=\"text-align: right;\">  0.1413</td><td style=\"text-align: right;\">                5.15</td><td style=\"text-align: right;\">               -3.39</td><td style=\"text-align: right;\">             207.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 69972\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-03-37\n",
      "  done: false\n",
      "  episode_len_mean: 210.17\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.150000000000001\n",
      "  episode_reward_mean: 0.4144000000000077\n",
      "  episode_reward_min: -3.389999999999989\n",
      "  episodes_this_iter: 47\n",
      "  episodes_total: 339\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.758192437326806\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01535587565698042\n",
      "          policy_loss: -0.029103549730637644\n",
      "          total_loss: 0.1653280968626595\n",
      "          vf_explained_var: 0.6362412571907043\n",
      "          vf_loss: 0.21894239662294715\n",
      "    num_agent_steps_sampled: 69972\n",
      "    num_agent_steps_trained: 69972\n",
      "    num_steps_sampled: 69972\n",
      "    num_steps_trained: 69972\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 97.08819875776398\n",
      "    ram_util_percent: 52.57329192546583\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04351429671627074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 32.11706713620096\n",
      "    mean_inference_ms: 2.4797139602912774\n",
      "    mean_raw_obs_processing_ms: 2.055269249207957\n",
      "  time_since_restore: 983.8089761734009\n",
      "  time_this_iter_s: 113.37515592575073\n",
      "  time_total_s: 983.8089761734009\n",
      "  timers:\n",
      "    learn_throughput: 1057.575\n",
      "    learn_time_ms: 9451.814\n",
      "    load_throughput: 91200.469\n",
      "    load_time_ms: 109.605\n",
      "    sample_throughput: 76.332\n",
      "    sample_time_ms: 130954.023\n",
      "    update_time_ms: 8.842\n",
      "  timestamp: 1636225417\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 69972\n",
      "  training_iteration: 7\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         983.809</td><td style=\"text-align: right;\">69972</td><td style=\"text-align: right;\">  0.4144</td><td style=\"text-align: right;\">                5.15</td><td style=\"text-align: right;\">               -3.39</td><td style=\"text-align: right;\">            210.17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 79968\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-06-39\n",
      "  done: false\n",
      "  episode_len_mean: 206.51\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.510000000000003\n",
      "  episode_reward_mean: 0.5555000000000077\n",
      "  episode_reward_min: -3.2299999999999858\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 389\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.737486555026128\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017114823568895734\n",
      "          policy_loss: -0.030752749828637665\n",
      "          total_loss: 0.25078697337920214\n",
      "          vf_explained_var: 0.5811748504638672\n",
      "          vf_loss: 0.3054916237361538\n",
      "    num_agent_steps_sampled: 79968\n",
      "    num_agent_steps_trained: 79968\n",
      "    num_steps_sampled: 79968\n",
      "    num_steps_trained: 79968\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.72692307692307\n",
      "    ram_util_percent: 52.81653846153846\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04349644864299771\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 31.411102768019337\n",
      "    mean_inference_ms: 2.48113972587098\n",
      "    mean_raw_obs_processing_ms: 2.5155798217400482\n",
      "  time_since_restore: 1166.0450851917267\n",
      "  time_this_iter_s: 182.2361090183258\n",
      "  time_total_s: 1166.0450851917267\n",
      "  timers:\n",
      "    learn_throughput: 1057.883\n",
      "    learn_time_ms: 9449.057\n",
      "    load_throughput: 91458.513\n",
      "    load_time_ms: 109.295\n",
      "    sample_throughput: 73.408\n",
      "    sample_time_ms: 136170.144\n",
      "    update_time_ms: 8.361\n",
      "  timestamp: 1636225599\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 79968\n",
      "  training_iteration: 8\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 24.9/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         1166.05</td><td style=\"text-align: right;\">79968</td><td style=\"text-align: right;\">  0.5555</td><td style=\"text-align: right;\">                5.51</td><td style=\"text-align: right;\">               -3.23</td><td style=\"text-align: right;\">            206.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 89964\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-08-46\n",
      "  done: false\n",
      "  episode_len_mean: 204.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.750000000000001\n",
      "  episode_reward_mean: 0.5717000000000075\n",
      "  episode_reward_min: -3.2299999999999858\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 437\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.729132144471519\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017688247730380788\n",
      "          policy_loss: -0.03238563204072734\n",
      "          total_loss: 0.18445001798084912\n",
      "          vf_explained_var: 0.5972334742546082\n",
      "          vf_loss: 0.24058932141265554\n",
      "    num_agent_steps_sampled: 89964\n",
      "    num_agent_steps_trained: 89964\n",
      "    num_steps_sampled: 89964\n",
      "    num_steps_trained: 89964\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 95.33296703296702\n",
      "    ram_util_percent: 52.6587912087912\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04346903953085618\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.844113199934874\n",
      "    mean_inference_ms: 2.4813335352376864\n",
      "    mean_raw_obs_processing_ms: 3.024439145780874\n",
      "  time_since_restore: 1293.100436925888\n",
      "  time_this_iter_s: 127.05535173416138\n",
      "  time_total_s: 1293.100436925888\n",
      "  timers:\n",
      "    learn_throughput: 1057.362\n",
      "    learn_time_ms: 9453.716\n",
      "    load_throughput: 91386.821\n",
      "    load_time_ms: 109.381\n",
      "    sample_throughput: 74.548\n",
      "    sample_time_ms: 134088.84\n",
      "    update_time_ms: 7.921\n",
      "  timestamp: 1636225726\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 89964\n",
      "  training_iteration: 9\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.0/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">          1293.1</td><td style=\"text-align: right;\">89964</td><td style=\"text-align: right;\">  0.5717</td><td style=\"text-align: right;\">                5.75</td><td style=\"text-align: right;\">               -3.23</td><td style=\"text-align: right;\">            204.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 99960\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-11-22\n",
      "  done: false\n",
      "  episode_len_mean: 203.32\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.750000000000001\n",
      "  episode_reward_mean: 0.7403000000000078\n",
      "  episode_reward_min: -2.66999999999999\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 488\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.7009323205703346\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01920845411184645\n",
      "          policy_loss: -0.03443845350963947\n",
      "          total_loss: 0.2022124265296719\n",
      "          vf_explained_var: 0.6428674459457397\n",
      "          vf_loss: 0.25981851301641545\n",
      "    num_agent_steps_sampled: 99960\n",
      "    num_agent_steps_trained: 99960\n",
      "    num_steps_sampled: 99960\n",
      "    num_steps_trained: 99960\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.27297297297297\n",
      "    ram_util_percent: 52.799099099099095\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0434439261932966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 30.351829936662085\n",
      "    mean_inference_ms: 2.4775502665719684\n",
      "    mean_raw_obs_processing_ms: 3.2005600052200385\n",
      "  time_since_restore: 1448.7148125171661\n",
      "  time_this_iter_s: 155.61437559127808\n",
      "  time_total_s: 1448.7148125171661\n",
      "  timers:\n",
      "    learn_throughput: 1057.121\n",
      "    learn_time_ms: 9455.873\n",
      "    load_throughput: 91496.989\n",
      "    load_time_ms: 109.249\n",
      "    sample_throughput: 73.891\n",
      "    sample_time_ms: 135280.947\n",
      "    update_time_ms: 7.776\n",
      "  timestamp: 1636225882\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 99960\n",
      "  training_iteration: 10\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         1448.71</td><td style=\"text-align: right;\">99960</td><td style=\"text-align: right;\">  0.7403</td><td style=\"text-align: right;\">                5.75</td><td style=\"text-align: right;\">               -2.67</td><td style=\"text-align: right;\">            203.32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 109956\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-14-02\n",
      "  done: false\n",
      "  episode_len_mean: 202.2\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.16000000000001\n",
      "  episode_reward_mean: 0.9805000000000085\n",
      "  episode_reward_min: -2.099999999999999\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 536\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.682330435769171\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019681308826636493\n",
      "          policy_loss: -0.0347476195766885\n",
      "          total_loss: 0.1821190401298814\n",
      "          vf_explained_var: 0.5556125044822693\n",
      "          vf_loss: 0.23975370180848826\n",
      "    num_agent_steps_sampled: 109956\n",
      "    num_agent_steps_trained: 109956\n",
      "    num_steps_sampled: 109956\n",
      "    num_steps_trained: 109956\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.3092105263158\n",
      "    ram_util_percent: 52.82412280701755\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043447698105764515\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.969209980064335\n",
      "    mean_inference_ms: 2.4744777099120423\n",
      "    mean_raw_obs_processing_ms: 3.4540619491866074\n",
      "  time_since_restore: 1608.4376873970032\n",
      "  time_this_iter_s: 159.72287487983704\n",
      "  time_total_s: 1608.4376873970032\n",
      "  timers:\n",
      "    learn_throughput: 1056.607\n",
      "    learn_time_ms: 9460.469\n",
      "    load_throughput: 91530.168\n",
      "    load_time_ms: 109.21\n",
      "    sample_throughput: 78.069\n",
      "    sample_time_ms: 128040.921\n",
      "    update_time_ms: 7.33\n",
      "  timestamp: 1636226042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 109956\n",
      "  training_iteration: 11\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         1608.44</td><td style=\"text-align: right;\">109956</td><td style=\"text-align: right;\">  0.9805</td><td style=\"text-align: right;\">                9.16</td><td style=\"text-align: right;\">                -2.1</td><td style=\"text-align: right;\">             202.2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 119952\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-16-48\n",
      "  done: false\n",
      "  episode_len_mean: 201.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.16000000000001\n",
      "  episode_reward_mean: 1.0015000000000098\n",
      "  episode_reward_min: -2.859999999999985\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 586\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.19999999999999998\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6726238466735577\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.020982473071253113\n",
      "          policy_loss: -0.03403046653629878\n",
      "          total_loss: 0.1767531195989786\n",
      "          vf_explained_var: 0.6581957936286926\n",
      "          vf_loss: 0.23331332987604234\n",
      "    num_agent_steps_sampled: 119952\n",
      "    num_agent_steps_trained: 119952\n",
      "    num_steps_sampled: 119952\n",
      "    num_steps_trained: 119952\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.00042194092826\n",
      "    ram_util_percent: 52.79113924050634\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04340972139103718\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.596361805846044\n",
      "    mean_inference_ms: 2.47232316407251\n",
      "    mean_raw_obs_processing_ms: 3.767202021069573\n",
      "  time_since_restore: 1774.5379853248596\n",
      "  time_this_iter_s: 166.10029792785645\n",
      "  time_total_s: 1774.5379853248596\n",
      "  timers:\n",
      "    learn_throughput: 1055.039\n",
      "    learn_time_ms: 9474.534\n",
      "    load_throughput: 91512.986\n",
      "    load_time_ms: 109.23\n",
      "    sample_throughput: 74.704\n",
      "    sample_time_ms: 133808.726\n",
      "    update_time_ms: 6.832\n",
      "  timestamp: 1636226208\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 119952\n",
      "  training_iteration: 12\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         1774.54</td><td style=\"text-align: right;\">119952</td><td style=\"text-align: right;\">  1.0015</td><td style=\"text-align: right;\">                9.16</td><td style=\"text-align: right;\">               -2.86</td><td style=\"text-align: right;\">            201.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 129948\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-19-48\n",
      "  done: false\n",
      "  episode_len_mean: 197.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 8.200000000000028\n",
      "  episode_reward_mean: 0.97300000000001\n",
      "  episode_reward_min: -2.859999999999985\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 636\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6776886135085016\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019911472287438968\n",
      "          policy_loss: -0.03617760359317574\n",
      "          total_loss: 0.19491454140943848\n",
      "          vf_explained_var: 0.6117089986801147\n",
      "          vf_loss: 0.25189558885927893\n",
      "    num_agent_steps_sampled: 129948\n",
      "    num_agent_steps_trained: 129948\n",
      "    num_steps_sampled: 129948\n",
      "    num_steps_trained: 129948\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.47003891050583\n",
      "    ram_util_percent: 52.92801556420233\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04332265807876552\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.28505975898005\n",
      "    mean_inference_ms: 2.468241170484186\n",
      "    mean_raw_obs_processing_ms: 4.267278227112898\n",
      "  time_since_restore: 1955.092553138733\n",
      "  time_this_iter_s: 180.5545678138733\n",
      "  time_total_s: 1955.092553138733\n",
      "  timers:\n",
      "    learn_throughput: 1054.71\n",
      "    learn_time_ms: 9477.485\n",
      "    load_throughput: 91400.308\n",
      "    load_time_ms: 109.365\n",
      "    sample_throughput: 71.875\n",
      "    sample_time_ms: 139075.186\n",
      "    update_time_ms: 6.353\n",
      "  timestamp: 1636226388\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 129948\n",
      "  training_iteration: 13\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         1955.09</td><td style=\"text-align: right;\">129948</td><td style=\"text-align: right;\">   0.973</td><td style=\"text-align: right;\">                 8.2</td><td style=\"text-align: right;\">               -2.86</td><td style=\"text-align: right;\">            197.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 139944\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-22-29\n",
      "  done: false\n",
      "  episode_len_mean: 201.01\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.310000000000036\n",
      "  episode_reward_mean: 1.0113000000000105\n",
      "  episode_reward_min: -2.579999999999983\n",
      "  episodes_this_iter: 49\n",
      "  episodes_total: 685\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.66624738130814\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01743054454060612\n",
      "          policy_loss: -0.040523816008343656\n",
      "          total_loss: 0.13664065229778105\n",
      "          vf_explained_var: 0.6571878790855408\n",
      "          vf_loss: 0.19859777813793247\n",
      "    num_agent_steps_sampled: 139944\n",
      "    num_agent_steps_trained: 139944\n",
      "    num_steps_sampled: 139944\n",
      "    num_steps_trained: 139944\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.47205240174672\n",
      "    ram_util_percent: 53.043668122270724\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04339280764671474\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.14551586547601\n",
      "    mean_inference_ms: 2.467403312337444\n",
      "    mean_raw_obs_processing_ms: 4.4616369568253225\n",
      "  time_since_restore: 2115.355236530304\n",
      "  time_this_iter_s: 160.26268339157104\n",
      "  time_total_s: 2115.355236530304\n",
      "  timers:\n",
      "    learn_throughput: 1053.684\n",
      "    learn_time_ms: 9486.711\n",
      "    load_throughput: 91468.285\n",
      "    load_time_ms: 109.284\n",
      "    sample_throughput: 71.125\n",
      "    sample_time_ms: 140540.955\n",
      "    update_time_ms: 6.664\n",
      "  timestamp: 1636226549\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 139944\n",
      "  training_iteration: 14\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         2115.36</td><td style=\"text-align: right;\">139944</td><td style=\"text-align: right;\">  1.0113</td><td style=\"text-align: right;\">                7.31</td><td style=\"text-align: right;\">               -2.58</td><td style=\"text-align: right;\">            201.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 149940\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-26-13\n",
      "  done: false\n",
      "  episode_len_mean: 201.55\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.310000000000036\n",
      "  episode_reward_mean: 1.4724000000000117\n",
      "  episode_reward_min: -1.4000000000000017\n",
      "  episodes_this_iter: 51\n",
      "  episodes_total: 736\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.3\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.648270601288885\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.020819217417366143\n",
      "          policy_loss: -0.03853266974990694\n",
      "          total_loss: 0.21214430841943646\n",
      "          vf_explained_var: 0.6640358567237854\n",
      "          vf_loss: 0.2709139182845242\n",
      "    num_agent_steps_sampled: 149940\n",
      "    num_agent_steps_trained: 149940\n",
      "    num_steps_sampled: 149940\n",
      "    num_steps_trained: 149940\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.4990625\n",
      "    ram_util_percent: 53.114999999999995\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04346264169002333\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 29.01397349533711\n",
      "    mean_inference_ms: 2.466701838274681\n",
      "    mean_raw_obs_processing_ms: 4.841323617720191\n",
      "  time_since_restore: 2339.3481090068817\n",
      "  time_this_iter_s: 223.99287247657776\n",
      "  time_total_s: 2339.3481090068817\n",
      "  timers:\n",
      "    learn_throughput: 1053.346\n",
      "    learn_time_ms: 9489.756\n",
      "    load_throughput: 91533.085\n",
      "    load_time_ms: 109.206\n",
      "    sample_throughput: 66.065\n",
      "    sample_time_ms: 151304.78\n",
      "    update_time_ms: 6.556\n",
      "  timestamp: 1636226773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 149940\n",
      "  training_iteration: 15\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         2339.35</td><td style=\"text-align: right;\">149940</td><td style=\"text-align: right;\">  1.4724</td><td style=\"text-align: right;\">                7.31</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">            201.55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 159936\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-29-56\n",
      "  done: false\n",
      "  episode_len_mean: 197.24\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 5.8100000000000005\n",
      "  episode_reward_mean: 1.6902000000000124\n",
      "  episode_reward_min: -1.4000000000000017\n",
      "  episodes_this_iter: 50\n",
      "  episodes_total: 786\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6299683621805956\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017379509153834263\n",
      "          policy_loss: -0.038695568177435136\n",
      "          total_loss: 0.19416306102170777\n",
      "          vf_explained_var: 0.5841421484947205\n",
      "          vf_loss: 0.2513375339536076\n",
      "    num_agent_steps_sampled: 159936\n",
      "    num_agent_steps_trained: 159936\n",
      "    num_steps_sampled: 159936\n",
      "    num_steps_trained: 159936\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.43647798742138\n",
      "    ram_util_percent: 53.07201257861636\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043421428394268304\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.807571966995983\n",
      "    mean_inference_ms: 2.4646394899057666\n",
      "    mean_raw_obs_processing_ms: 5.508989028223357\n",
      "  time_since_restore: 2562.6018121242523\n",
      "  time_this_iter_s: 223.2537031173706\n",
      "  time_total_s: 2562.6018121242523\n",
      "  timers:\n",
      "    learn_throughput: 1052.711\n",
      "    learn_time_ms: 9495.483\n",
      "    load_throughput: 92031.473\n",
      "    load_time_ms: 108.615\n",
      "    sample_throughput: 62.634\n",
      "    sample_time_ms: 159594.227\n",
      "    update_time_ms: 6.597\n",
      "  timestamp: 1636226996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 159936\n",
      "  training_iteration: 16\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">          2562.6</td><td style=\"text-align: right;\">159936</td><td style=\"text-align: right;\">  1.6902</td><td style=\"text-align: right;\">                5.81</td><td style=\"text-align: right;\">                -1.4</td><td style=\"text-align: right;\">            197.24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 169932\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-34-48\n",
      "  done: false\n",
      "  episode_len_mean: 189.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.800000000000002\n",
      "  episode_reward_mean: 1.779900000000012\n",
      "  episode_reward_min: -2.6599999999999904\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 841\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.6029515926654523\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01943848362939168\n",
      "          policy_loss: -0.03827319459305105\n",
      "          total_loss: 0.24910938075035174\n",
      "          vf_explained_var: 0.721899688243866\n",
      "          vf_loss: 0.30466477267571496\n",
      "    num_agent_steps_sampled: 169932\n",
      "    num_agent_steps_trained: 169932\n",
      "    num_steps_sampled: 169932\n",
      "    num_steps_trained: 169932\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.7760765550239\n",
      "    ram_util_percent: 53.233971291866034\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04339993697135542\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.591531867635602\n",
      "    mean_inference_ms: 2.4617339374510623\n",
      "    mean_raw_obs_processing_ms: 6.477072007831408\n",
      "  time_since_restore: 2854.9802362918854\n",
      "  time_this_iter_s: 292.37842416763306\n",
      "  time_total_s: 2854.9802362918854\n",
      "  timers:\n",
      "    learn_throughput: 1052.586\n",
      "    learn_time_ms: 9496.607\n",
      "    load_throughput: 92042.141\n",
      "    load_time_ms: 108.602\n",
      "    sample_throughput: 56.318\n",
      "    sample_time_ms: 177492.911\n",
      "    update_time_ms: 7.068\n",
      "  timestamp: 1636227288\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 169932\n",
      "  training_iteration: 17\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         2854.98</td><td style=\"text-align: right;\">169932</td><td style=\"text-align: right;\">  1.7799</td><td style=\"text-align: right;\">                 9.8</td><td style=\"text-align: right;\">               -2.66</td><td style=\"text-align: right;\">            189.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 179928\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-39-26\n",
      "  done: false\n",
      "  episode_len_mean: 174.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.800000000000002\n",
      "  episode_reward_mean: 2.554600000000013\n",
      "  episode_reward_min: -2.6599999999999904\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 899\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.60669840013879\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.019316274494037944\n",
      "          policy_loss: -0.042949062480758395\n",
      "          total_loss: 0.2120262338198785\n",
      "          vf_explained_var: 0.6999718546867371\n",
      "          vf_loss: 0.2723499565839003\n",
      "    num_agent_steps_sampled: 179928\n",
      "    num_agent_steps_trained: 179928\n",
      "    num_steps_sampled: 179928\n",
      "    num_steps_trained: 179928\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.36136363636365\n",
      "    ram_util_percent: 53.11060606060607\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04331992941809831\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.396260496503864\n",
      "    mean_inference_ms: 2.4586753305861335\n",
      "    mean_raw_obs_processing_ms: 7.7958405255091066\n",
      "  time_since_restore: 3132.611764907837\n",
      "  time_this_iter_s: 277.63152861595154\n",
      "  time_total_s: 3132.611764907837\n",
      "  timers:\n",
      "    learn_throughput: 1052.684\n",
      "    learn_time_ms: 9495.727\n",
      "    load_throughput: 91883.19\n",
      "    load_time_ms: 108.79\n",
      "    sample_throughput: 53.445\n",
      "    sample_time_ms: 187032.849\n",
      "    update_time_ms: 7.399\n",
      "  timestamp: 1636227566\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 179928\n",
      "  training_iteration: 18\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         3132.61</td><td style=\"text-align: right;\">179928</td><td style=\"text-align: right;\">  2.5546</td><td style=\"text-align: right;\">                 9.8</td><td style=\"text-align: right;\">               -2.66</td><td style=\"text-align: right;\">            174.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 189924\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-44-16\n",
      "  done: false\n",
      "  episode_len_mean: 175.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 6.260000000000035\n",
      "  episode_reward_mean: 2.571500000000014\n",
      "  episode_reward_min: -1.2400000000000013\n",
      "  episodes_this_iter: 54\n",
      "  episodes_total: 953\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5879794558908187\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.018638033193466103\n",
      "          policy_loss: -0.044602923478899346\n",
      "          total_loss: 0.14832181873627834\n",
      "          vf_explained_var: 0.7777464985847473\n",
      "          vf_loss: 0.21041742228608357\n",
      "    num_agent_steps_sampled: 189924\n",
      "    num_agent_steps_trained: 189924\n",
      "    num_steps_sampled: 189924\n",
      "    num_steps_trained: 189924\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.8256038647343\n",
      "    ram_util_percent: 53.19879227053139\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04323426935881619\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.272562849333372\n",
      "    mean_inference_ms: 2.4562437399872654\n",
      "    mean_raw_obs_processing_ms: 8.680272809449125\n",
      "  time_since_restore: 3422.770003080368\n",
      "  time_this_iter_s: 290.1582381725311\n",
      "  time_total_s: 3422.770003080368\n",
      "  timers:\n",
      "    learn_throughput: 1048.184\n",
      "    learn_time_ms: 9536.497\n",
      "    load_throughput: 91871.834\n",
      "    load_time_ms: 108.804\n",
      "    sample_throughput: 49.168\n",
      "    sample_time_ms: 203301.92\n",
      "    update_time_ms: 7.809\n",
      "  timestamp: 1636227856\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 189924\n",
      "  training_iteration: 19\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         3422.77</td><td style=\"text-align: right;\">189924</td><td style=\"text-align: right;\">  2.5715</td><td style=\"text-align: right;\">                6.26</td><td style=\"text-align: right;\">               -1.24</td><td style=\"text-align: right;\">            175.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 199920\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-48-58\n",
      "  done: false\n",
      "  episode_len_mean: 175.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.800000000000002\n",
      "  episode_reward_mean: 2.955000000000016\n",
      "  episode_reward_min: -1.1200000000000017\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 1011\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.4500000000000001\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5643301436024855\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.02108570113036361\n",
      "          policy_loss: -0.03949755506319368\n",
      "          total_loss: 0.21519595820806983\n",
      "          vf_explained_var: 0.7304996848106384\n",
      "          vf_loss: 0.2708482492301199\n",
      "    num_agent_steps_sampled: 199920\n",
      "    num_agent_steps_trained: 199920\n",
      "    num_steps_sampled: 199920\n",
      "    num_steps_trained: 199920\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.48084577114429\n",
      "    ram_util_percent: 53.00248756218905\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0431448274693207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 28.13065679495199\n",
      "    mean_inference_ms: 2.4533582863820893\n",
      "    mean_raw_obs_processing_ms: 9.677660395398481\n",
      "  time_since_restore: 3704.4675793647766\n",
      "  time_this_iter_s: 281.69757628440857\n",
      "  time_total_s: 3704.4675793647766\n",
      "  timers:\n",
      "    learn_throughput: 1047.53\n",
      "    learn_time_ms: 9542.451\n",
      "    load_throughput: 91725.57\n",
      "    load_time_ms: 108.977\n",
      "    sample_throughput: 46.298\n",
      "    sample_time_ms: 215904.761\n",
      "    update_time_ms: 7.565\n",
      "  timestamp: 1636228138\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 199920\n",
      "  training_iteration: 20\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         3704.47</td><td style=\"text-align: right;\">199920</td><td style=\"text-align: right;\">   2.955</td><td style=\"text-align: right;\">                 9.8</td><td style=\"text-align: right;\">               -1.12</td><td style=\"text-align: right;\">            175.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 209916\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-54-46\n",
      "  done: false\n",
      "  episode_len_mean: 158.21\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.82\n",
      "  episode_reward_mean: 2.7658000000000103\n",
      "  episode_reward_min: -2.259999999999996\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 1077\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.55096442780943\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.017055343247626777\n",
      "          policy_loss: -0.04538892504050691\n",
      "          total_loss: 0.1635411264311172\n",
      "          vf_explained_var: 0.7916896343231201\n",
      "          vf_loss: 0.22292733777823867\n",
      "    num_agent_steps_sampled: 209916\n",
      "    num_agent_steps_trained: 209916\n",
      "    num_steps_sampled: 209916\n",
      "    num_steps_trained: 209916\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.10503018108652\n",
      "    ram_util_percent: 52.97303822937626\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.043017678450090815\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.871227708150005\n",
      "    mean_inference_ms: 2.4485833767955394\n",
      "    mean_raw_obs_processing_ms: 11.806533822447191\n",
      "  time_since_restore: 4052.554951906204\n",
      "  time_this_iter_s: 348.0873725414276\n",
      "  time_total_s: 4052.554951906204\n",
      "  timers:\n",
      "    learn_throughput: 1047.54\n",
      "    learn_time_ms: 9542.358\n",
      "    load_throughput: 91611.427\n",
      "    load_time_ms: 109.113\n",
      "    sample_throughput: 42.583\n",
      "    sample_time_ms: 234741.072\n",
      "    update_time_ms: 7.633\n",
      "  timestamp: 1636228486\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 209916\n",
      "  training_iteration: 21\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.2/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         4052.55</td><td style=\"text-align: right;\">209916</td><td style=\"text-align: right;\">  2.7658</td><td style=\"text-align: right;\">                9.82</td><td style=\"text-align: right;\">               -2.26</td><td style=\"text-align: right;\">            158.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 219912\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_19-59-41\n",
      "  done: false\n",
      "  episode_len_mean: 160.73\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.82\n",
      "  episode_reward_mean: 2.649900000000011\n",
      "  episode_reward_min: -2.259999999999996\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 1135\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.5369529226906278\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01733013650121731\n",
      "          policy_loss: -0.048565820596602735\n",
      "          total_loss: 0.1362491008419639\n",
      "          vf_explained_var: 0.789801836013794\n",
      "          vf_loss: 0.19848660783380526\n",
      "    num_agent_steps_sampled: 219912\n",
      "    num_agent_steps_trained: 219912\n",
      "    num_steps_sampled: 219912\n",
      "    num_steps_trained: 219912\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.95119047619048\n",
      "    ram_util_percent: 53.29976190476191\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04292228798667733\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.690690168176943\n",
      "    mean_inference_ms: 2.4446006411726358\n",
      "    mean_raw_obs_processing_ms: 13.498980462877762\n",
      "  time_since_restore: 4347.4269506931305\n",
      "  time_this_iter_s: 294.87199878692627\n",
      "  time_total_s: 4347.4269506931305\n",
      "  timers:\n",
      "    learn_throughput: 1048.73\n",
      "    learn_time_ms: 9531.528\n",
      "    load_throughput: 91673.704\n",
      "    load_time_ms: 109.039\n",
      "    sample_throughput: 40.367\n",
      "    sample_time_ms: 247629.479\n",
      "    update_time_ms: 7.441\n",
      "  timestamp: 1636228781\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 219912\n",
      "  training_iteration: 22\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.3/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         4347.43</td><td style=\"text-align: right;\">219912</td><td style=\"text-align: right;\">  2.6499</td><td style=\"text-align: right;\">                9.82</td><td style=\"text-align: right;\">               -2.26</td><td style=\"text-align: right;\">            160.73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 229908\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-04-01\n",
      "  done: false\n",
      "  episode_len_mean: 176.5\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.670000000000002\n",
      "  episode_reward_mean: 2.677900000000015\n",
      "  episode_reward_min: -2.7199999999999855\n",
      "  episodes_this_iter: 53\n",
      "  episodes_total: 1188\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.556369695296654\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0180008313053207\n",
      "          policy_loss: -0.04409573866197696\n",
      "          total_loss: 0.16099591307007732\n",
      "          vf_explained_var: 0.7370864152908325\n",
      "          vf_loss: 0.2185047865487062\n",
      "    num_agent_steps_sampled: 229908\n",
      "    num_agent_steps_trained: 229908\n",
      "    num_steps_sampled: 229908\n",
      "    num_steps_trained: 229908\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.65053763440861\n",
      "    ram_util_percent: 53.446774193548386\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04288101309999\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.561553768635605\n",
      "    mean_inference_ms: 2.441616973445104\n",
      "    mean_raw_obs_processing_ms: 14.158878274061841\n",
      "  time_since_restore: 4607.770305633545\n",
      "  time_this_iter_s: 260.34335494041443\n",
      "  time_total_s: 4607.770305633545\n",
      "  timers:\n",
      "    learn_throughput: 1048.137\n",
      "    learn_time_ms: 9536.926\n",
      "    load_throughput: 91725.931\n",
      "    load_time_ms: 108.977\n",
      "    sample_throughput: 39.108\n",
      "    sample_time_ms: 255602.37\n",
      "    update_time_ms: 8.028\n",
      "  timestamp: 1636229041\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 229908\n",
      "  training_iteration: 23\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         4607.77</td><td style=\"text-align: right;\">229908</td><td style=\"text-align: right;\">  2.6779</td><td style=\"text-align: right;\">                9.67</td><td style=\"text-align: right;\">               -2.72</td><td style=\"text-align: right;\">             176.5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 239904\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-08-21\n",
      "  done: false\n",
      "  episode_len_mean: 179.93\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.670000000000002\n",
      "  episode_reward_mean: 2.696100000000016\n",
      "  episode_reward_min: -3.509999999999989\n",
      "  episodes_this_iter: 58\n",
      "  episodes_total: 1246\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.6749999999999999\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.521818524751908\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.020420232074984928\n",
      "          policy_loss: -0.042488070578975044\n",
      "          total_loss: 0.19295878641577996\n",
      "          vf_explained_var: 0.6995707154273987\n",
      "          vf_loss: 0.24688138448529773\n",
      "    num_agent_steps_sampled: 239904\n",
      "    num_agent_steps_trained: 239904\n",
      "    num_steps_sampled: 239904\n",
      "    num_steps_trained: 239904\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.65902964959568\n",
      "    ram_util_percent: 53.36846361185985\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04284757958478485\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.395909726155033\n",
      "    mean_inference_ms: 2.439962653764769\n",
      "    mean_raw_obs_processing_ms: 15.004139295016916\n",
      "  time_since_restore: 4867.595664024353\n",
      "  time_this_iter_s: 259.8253583908081\n",
      "  time_total_s: 4867.595664024353\n",
      "  timers:\n",
      "    learn_throughput: 1048.466\n",
      "    learn_time_ms: 9533.928\n",
      "    load_throughput: 91912.84\n",
      "    load_time_ms: 108.755\n",
      "    sample_throughput: 37.641\n",
      "    sample_time_ms: 265561.67\n",
      "    update_time_ms: 7.886\n",
      "  timestamp: 1636229301\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 239904\n",
      "  training_iteration: 24\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.4/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">          4867.6</td><td style=\"text-align: right;\">239904</td><td style=\"text-align: right;\">  2.6961</td><td style=\"text-align: right;\">                9.67</td><td style=\"text-align: right;\">               -3.51</td><td style=\"text-align: right;\">            179.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 249900\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-12-14\n",
      "  done: false\n",
      "  episode_len_mean: 176.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.89\n",
      "  episode_reward_mean: 2.692000000000014\n",
      "  episode_reward_min: -3.509999999999989\n",
      "  episodes_this_iter: 55\n",
      "  episodes_total: 1301\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.540516776712532\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015767358597539527\n",
      "          policy_loss: -0.04937759722288475\n",
      "          total_loss: 0.1938657844104828\n",
      "          vf_explained_var: 0.7294347882270813\n",
      "          vf_loss: 0.25268409821467525\n",
      "    num_agent_steps_sampled: 249900\n",
      "    num_agent_steps_trained: 249900\n",
      "    num_steps_sampled: 249900\n",
      "    num_steps_trained: 249900\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.56656626506023\n",
      "    ram_util_percent: 53.41054216867471\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.042798081690646576\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.276866677495683\n",
      "    mean_inference_ms: 2.4380923642428387\n",
      "    mean_raw_obs_processing_ms: 15.745312569320685\n",
      "  time_since_restore: 5100.537467002869\n",
      "  time_this_iter_s: 232.94180297851562\n",
      "  time_total_s: 5100.537467002869\n",
      "  timers:\n",
      "    learn_throughput: 1047.748\n",
      "    learn_time_ms: 9540.465\n",
      "    load_throughput: 91824.509\n",
      "    load_time_ms: 108.86\n",
      "    sample_throughput: 37.516\n",
      "    sample_time_ms: 266449.706\n",
      "    update_time_ms: 7.978\n",
      "  timestamp: 1636229534\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 249900\n",
      "  training_iteration: 25\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         5100.54</td><td style=\"text-align: right;\">249900</td><td style=\"text-align: right;\">   2.692</td><td style=\"text-align: right;\">                9.89</td><td style=\"text-align: right;\">               -3.51</td><td style=\"text-align: right;\">            176.03</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 259896\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-17-32\n",
      "  done: false\n",
      "  episode_len_mean: 173.48\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.88\n",
      "  episode_reward_mean: 3.199800000000016\n",
      "  episode_reward_min: -1.3399999999999992\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1361\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4983164151509603\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.016843786240070154\n",
      "          policy_loss: -0.04616760919109369\n",
      "          total_loss: 0.18509108203455296\n",
      "          vf_explained_var: 0.8200007677078247\n",
      "          vf_loss: 0.23918752091116885\n",
      "    num_agent_steps_sampled: 259896\n",
      "    num_agent_steps_trained: 259896\n",
      "    num_steps_sampled: 259896\n",
      "    num_steps_trained: 259896\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.57792494481237\n",
      "    ram_util_percent: 53.501986754966886\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0427553441161297\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.164751625796647\n",
      "    mean_inference_ms: 2.436466197154526\n",
      "    mean_raw_obs_processing_ms: 16.619253366781336\n",
      "  time_since_restore: 5418.168862104416\n",
      "  time_this_iter_s: 317.63139510154724\n",
      "  time_total_s: 5418.168862104416\n",
      "  timers:\n",
      "    learn_throughput: 1047.107\n",
      "    learn_time_ms: 9546.301\n",
      "    load_throughput: 91208.133\n",
      "    load_time_ms: 109.595\n",
      "    sample_throughput: 36.233\n",
      "    sample_time_ms: 275880.096\n",
      "    update_time_ms: 8.897\n",
      "  timestamp: 1636229852\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 259896\n",
      "  training_iteration: 26\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         5418.17</td><td style=\"text-align: right;\">259896</td><td style=\"text-align: right;\">  3.1998</td><td style=\"text-align: right;\">                9.88</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">            173.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 269892\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-22-17\n",
      "  done: false\n",
      "  episode_len_mean: 174.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.920000000000002\n",
      "  episode_reward_mean: 3.238700000000017\n",
      "  episode_reward_min: -1.3399999999999992\n",
      "  episodes_this_iter: 57\n",
      "  episodes_total: 1418\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.498418702834692\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015112260057591826\n",
      "          policy_loss: -0.051145826303997104\n",
      "          total_loss: 0.16731830333224218\n",
      "          vf_explained_var: 0.809043824672699\n",
      "          vf_loss: 0.22814715183698214\n",
      "    num_agent_steps_sampled: 269892\n",
      "    num_agent_steps_trained: 269892\n",
      "    num_steps_sampled: 269892\n",
      "    num_steps_trained: 269892\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.62481572481573\n",
      "    ram_util_percent: 53.61965601965602\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04271967923825473\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 27.052102526894323\n",
      "    mean_inference_ms: 2.435237124578286\n",
      "    mean_raw_obs_processing_ms: 17.351234462295928\n",
      "  time_since_restore: 5702.979123353958\n",
      "  time_this_iter_s: 284.81026124954224\n",
      "  time_total_s: 5702.979123353958\n",
      "  timers:\n",
      "    learn_throughput: 1047.092\n",
      "    learn_time_ms: 9546.439\n",
      "    load_throughput: 91182.386\n",
      "    load_time_ms: 109.626\n",
      "    sample_throughput: 36.333\n",
      "    sample_time_ms: 275123.661\n",
      "    update_time_ms: 8.181\n",
      "  timestamp: 1636230137\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 269892\n",
      "  training_iteration: 27\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         5702.98</td><td style=\"text-align: right;\">269892</td><td style=\"text-align: right;\">  3.2387</td><td style=\"text-align: right;\">                9.92</td><td style=\"text-align: right;\">               -1.34</td><td style=\"text-align: right;\">            174.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 279888\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-29-01\n",
      "  done: false\n",
      "  episode_len_mean: 156.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.9\n",
      "  episode_reward_mean: 3.194700000000013\n",
      "  episode_reward_min: -1.1500000000000015\n",
      "  episodes_this_iter: 66\n",
      "  episodes_total: 1484\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.4896753816523103\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.0169716268013502\n",
      "          policy_loss: -0.04931929438239616\n",
      "          total_loss: 0.20018481615946715\n",
      "          vf_explained_var: 0.7724143266677856\n",
      "          vf_loss: 0.2572170891281631\n",
      "    num_agent_steps_sampled: 279888\n",
      "    num_agent_steps_trained: 279888\n",
      "    num_steps_sampled: 279888\n",
      "    num_steps_trained: 279888\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.08819444444445\n",
      "    ram_util_percent: 53.699131944444446\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04260276155029504\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 26.886022847040216\n",
      "    mean_inference_ms: 2.4310506010731285\n",
      "    mean_raw_obs_processing_ms: 18.687468402975824\n",
      "  time_since_restore: 6106.836093425751\n",
      "  time_this_iter_s: 403.8569700717926\n",
      "  time_total_s: 6106.836093425751\n",
      "  timers:\n",
      "    learn_throughput: 1046.69\n",
      "    learn_time_ms: 9550.108\n",
      "    load_throughput: 91175.247\n",
      "    load_time_ms: 109.635\n",
      "    sample_throughput: 34.739\n",
      "    sample_time_ms: 287742.166\n",
      "    update_time_ms: 8.383\n",
      "  timestamp: 1636230541\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 279888\n",
      "  training_iteration: 28\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.5/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         6106.84</td><td style=\"text-align: right;\">279888</td><td style=\"text-align: right;\">  3.1947</td><td style=\"text-align: right;\">                 9.9</td><td style=\"text-align: right;\">               -1.15</td><td style=\"text-align: right;\">            156.71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 289884\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-34-32\n",
      "  done: false\n",
      "  episode_len_mean: 152.58\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.880000000000003\n",
      "  episode_reward_mean: 3.416800000000013\n",
      "  episode_reward_min: -2.2800000000000016\n",
      "  episodes_this_iter: 61\n",
      "  episodes_total: 1545\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.482929065492418\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.015419580001220906\n",
      "          policy_loss: -0.054298016634316014\n",
      "          total_loss: 0.15187304815452576\n",
      "          vf_explained_var: 0.7938852310180664\n",
      "          vf_loss: 0.21538802972143023\n",
      "    num_agent_steps_sampled: 289884\n",
      "    num_agent_steps_trained: 289884\n",
      "    num_steps_sampled: 289884\n",
      "    num_steps_trained: 289884\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.76744186046511\n",
      "    ram_util_percent: 53.94482029598309\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04253817900747709\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 26.784160839072864\n",
      "    mean_inference_ms: 2.428300651598859\n",
      "    mean_raw_obs_processing_ms: 19.752627903163916\n",
      "  time_since_restore: 6438.568773269653\n",
      "  time_this_iter_s: 331.7326798439026\n",
      "  time_total_s: 6438.568773269653\n",
      "  timers:\n",
      "    learn_throughput: 1051.343\n",
      "    learn_time_ms: 9507.838\n",
      "    load_throughput: 91235.265\n",
      "    load_time_ms: 109.563\n",
      "    sample_throughput: 34.24\n",
      "    sample_time_ms: 291942.131\n",
      "    update_time_ms: 8.284\n",
      "  timestamp: 1636230872\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 289884\n",
      "  training_iteration: 29\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         6438.57</td><td style=\"text-align: right;\">289884</td><td style=\"text-align: right;\">  3.4168</td><td style=\"text-align: right;\">                9.88</td><td style=\"text-align: right;\">               -2.28</td><td style=\"text-align: right;\">            152.58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 299880\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-40-27\n",
      "  done: false\n",
      "  episode_len_mean: 144.52\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.88\n",
      "  episode_reward_mean: 3.882400000000013\n",
      "  episode_reward_min: -2.2800000000000016\n",
      "  episodes_this_iter: 70\n",
      "  episodes_total: 1615\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.47923766079112\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01734041388953302\n",
      "          policy_loss: -0.047824206801019925\n",
      "          total_loss: 0.2063232985110237\n",
      "          vf_explained_var: 0.8125782608985901\n",
      "          vf_loss: 0.2613827116023272\n",
      "    num_agent_steps_sampled: 299880\n",
      "    num_agent_steps_trained: 299880\n",
      "    num_steps_sampled: 299880\n",
      "    num_steps_trained: 299880\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.72766798418972\n",
      "    ram_util_percent: 54.294466403162055\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.042518224938297\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 26.760192846112567\n",
      "    mean_inference_ms: 2.4271791611127\n",
      "    mean_raw_obs_processing_ms: 20.66578234591054\n",
      "  time_since_restore: 6792.995296239853\n",
      "  time_this_iter_s: 354.4265229701996\n",
      "  time_total_s: 6792.995296239853\n",
      "  timers:\n",
      "    learn_throughput: 1051.087\n",
      "    learn_time_ms: 9510.156\n",
      "    load_throughput: 91156.336\n",
      "    load_time_ms: 109.658\n",
      "    sample_throughput: 33.408\n",
      "    sample_time_ms: 299212.447\n",
      "    update_time_ms: 8.261\n",
      "  timestamp: 1636231227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 299880\n",
      "  training_iteration: 30\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 26.1/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">            6793</td><td style=\"text-align: right;\">299880</td><td style=\"text-align: right;\">  3.8824</td><td style=\"text-align: right;\">                9.88</td><td style=\"text-align: right;\">               -2.28</td><td style=\"text-align: right;\">            144.52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 309876\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-45-58\n",
      "  done: false\n",
      "  episode_len_mean: 152.85\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.89\n",
      "  episode_reward_mean: 3.6148000000000144\n",
      "  episode_reward_min: -0.8099999999999868\n",
      "  episodes_this_iter: 63\n",
      "  episodes_total: 1678\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.492918090535025\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.014085976693629224\n",
      "          policy_loss: -0.05295753919352324\n",
      "          total_loss: 0.14076466212351607\n",
      "          vf_explained_var: 0.7937976717948914\n",
      "          vf_loss: 0.20438932918935504\n",
      "    num_agent_steps_sampled: 309876\n",
      "    num_agent_steps_trained: 309876\n",
      "    num_steps_sampled: 309876\n",
      "    num_steps_trained: 309876\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.79556025369979\n",
      "    ram_util_percent: 54.667230443974624\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04247618298904635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 26.727232875647722\n",
      "    mean_inference_ms: 2.425775297384123\n",
      "    mean_raw_obs_processing_ms: 21.483369062176806\n",
      "  time_since_restore: 7124.300342321396\n",
      "  time_this_iter_s: 331.30504608154297\n",
      "  time_total_s: 7124.300342321396\n",
      "  timers:\n",
      "    learn_throughput: 1051.548\n",
      "    learn_time_ms: 9505.983\n",
      "    load_throughput: 91208.014\n",
      "    load_time_ms: 109.596\n",
      "    sample_throughput: 33.596\n",
      "    sample_time_ms: 297536.177\n",
      "    update_time_ms: 8.927\n",
      "  timestamp: 1636231558\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 309876\n",
      "  training_iteration: 31\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.6/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">          7124.3</td><td style=\"text-align: right;\">309876</td><td style=\"text-align: right;\">  3.6148</td><td style=\"text-align: right;\">                9.89</td><td style=\"text-align: right;\">               -0.81</td><td style=\"text-align: right;\">            152.85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 319872\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-51-24\n",
      "  done: false\n",
      "  episode_len_mean: 160.13\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.960000000000031\n",
      "  episode_reward_mean: 3.5064000000000153\n",
      "  episode_reward_min: -1.3000000000000018\n",
      "  episodes_this_iter: 65\n",
      "  episodes_total: 1743\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.478540201472421\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01506501062794037\n",
      "          policy_loss: -0.05790178179104104\n",
      "          total_loss: 0.09355465964788301\n",
      "          vf_explained_var: 0.8439602851867676\n",
      "          vf_loss: 0.16098851958592222\n",
      "    num_agent_steps_sampled: 319872\n",
      "    num_agent_steps_trained: 319872\n",
      "    num_steps_sampled: 319872\n",
      "    num_steps_trained: 319872\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.02995689655172\n",
      "    ram_util_percent: 54.20064655172414\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04246836483656677\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 26.707042467050993\n",
      "    mean_inference_ms: 2.4255442525395443\n",
      "    mean_raw_obs_processing_ms: 21.928055329813304\n",
      "  time_since_restore: 7449.744167089462\n",
      "  time_this_iter_s: 325.4438247680664\n",
      "  time_total_s: 7449.744167089462\n",
      "  timers:\n",
      "    learn_throughput: 1049.935\n",
      "    learn_time_ms: 9520.585\n",
      "    load_throughput: 91104.894\n",
      "    load_time_ms: 109.72\n",
      "    sample_throughput: 33.256\n",
      "    sample_time_ms: 300577.996\n",
      "    update_time_ms: 9.322\n",
      "  timestamp: 1636231884\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319872\n",
      "  training_iteration: 32\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         7449.74</td><td style=\"text-align: right;\">319872</td><td style=\"text-align: right;\">  3.5064</td><td style=\"text-align: right;\">                9.96</td><td style=\"text-align: right;\">                -1.3</td><td style=\"text-align: right;\">            160.13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_ef0ef_00000:\n",
      "  agent_timesteps_total: 329868\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-06_20-56-25\n",
      "  done: false\n",
      "  episode_len_mean: 155.57\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 9.960000000000031\n",
      "  episode_reward_mean: 3.8893000000000155\n",
      "  episode_reward_min: -1.3599999999999883\n",
      "  episodes_this_iter: 64\n",
      "  episodes_total: 1807\n",
      "  experiment_id: d164439ba9304db690d8b387f5275ed7\n",
      "  hostname: linar-Z390-GAMING-X\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 1.0125\n",
      "          cur_lr: 0.00010000000000000002\n",
      "          entropy: 2.461630885417645\n",
      "          entropy_coeff: 0.01\n",
      "          kl: 0.01599660218432368\n",
      "          policy_loss: -0.05600094480646981\n",
      "          total_loss: 0.13853544527266778\n",
      "          vf_explained_var: 0.8291873335838318\n",
      "          vf_loss: 0.20295613838566673\n",
      "    num_agent_steps_sampled: 329868\n",
      "    num_agent_steps_trained: 329868\n",
      "    num_steps_sampled: 329868\n",
      "    num_steps_trained: 329868\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.3.5\n",
      "  num_healthy_workers: 3\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.45953488372092\n",
      "    ram_util_percent: 53.940232558139535\n",
      "  pid: 480903\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.04243301047584035\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 26.662231830973898\n",
      "    mean_inference_ms: 2.4242924325099837\n",
      "    mean_raw_obs_processing_ms: 22.40827084171263\n",
      "  time_since_restore: 7750.858315944672\n",
      "  time_this_iter_s: 301.11414885520935\n",
      "  time_total_s: 7750.858315944672\n",
      "  timers:\n",
      "    learn_throughput: 1050.308\n",
      "    learn_time_ms: 9517.212\n",
      "    load_throughput: 91177.309\n",
      "    load_time_ms: 109.633\n",
      "    sample_throughput: 32.81\n",
      "    sample_time_ms: 304659.692\n",
      "    update_time_ms: 8.37\n",
      "  timestamp: 1636232185\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 329868\n",
      "  training_iteration: 33\n",
      "  trial_id: ef0ef_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 25.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4.0/8 CPUs, 1.0/1 GPUs, 0.0/21.82 GiB heap, 0.0/10.91 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /IGLU-Minecraft/checkpoints/10_blocks_max/PPO_2021-11-06_18-47-03<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_ef0ef_00000</td><td>RUNNING </td><td>192.168.3.5:480903</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         7750.86</td><td style=\"text-align: right;\">329868</td><td style=\"text-align: right;\">  3.8893</td><td style=\"text-align: right;\">                9.96</td><td style=\"text-align: right;\">               -1.36</td><td style=\"text-align: right;\">            155.57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480896)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480902)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=480901)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 3,\n",
    "             \"sgd_minibatch_size\": 256,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 5_000,\n",
    "             \"lr\": 1e-4,\n",
    "             #\"gamma\": 0.99,\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO MultiTask <=10 pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger],\n",
    "        local_dir=\"/IGLU-Minecraft/checkpoints/10_blocks_max\",\n",
    "        keep_checkpoints_num=50,\n",
    "        checkpoint_freq=5,\n",
    "        checkpoint_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
