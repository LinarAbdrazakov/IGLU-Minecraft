{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4, padding=0),  \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv2d(64, 64, kernel_size=2, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        features_dim = 64\n",
    "        self.encoder = VisualEncoder()\n",
    "        self.encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AlinaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.gru\n",
    "        self.action_head = nn.Linear(features_dim, action_space.n)\n",
    "        self.value_head = nn.Linear(features_dim, 1)\n",
    "        self.last_value = None\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.encoder.cuda()\n",
    "            self.action_head.cuda()\n",
    "            self.value_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        if self.use_cuda:\n",
    "            obs.cuda()\n",
    "            \n",
    "        features = self.encoder(obs)\n",
    "        #action = self.action_head(features)\n",
    "        #self.last_value = self.value_head(features).squeeze(1)\n",
    "        return features, state\n",
    "    \n",
    "    @override(TorchModelV2)\n",
    "    def value_function(self):\n",
    "        assert self.last_value is not None, \"must call forward() first\"\n",
    "        return self.last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=1000)\n",
    "    env.update_taskset(TaskSet(preset=['C17']))\n",
    "    env = PovOnlyWrapper(env)\n",
    "    env = IgluActionWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/services.py:238: UserWarning: Not all Ray Dashboard dependencies were found. To use the dashboard please install Ray using `pip install ray[default]`. To disable this message, set RAY_DISABLE_IMPORT_WARNING env var to '1'.\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 3.6/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/8.87 GiB heap, 0.0/4.44 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/PPO_2021-09-27_11-26-38<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c7a10_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 11:26:38,439\tINFO wandb.py:170 -- Already logged into W&B.\n",
      "2021-09-27 11:26:38,448\tERROR syncer.py:72 -- Log sync requires rsync to be installed.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinar\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">PPO C17 pretrained (AlinaCNN)</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/c7a10_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/c7a10_00000</a><br/>\n",
       "                Run data is saved locally in <code>/IGLU-Minecraft/wandb/run-20210927_112639-c7a10_00000</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m 2021-09-27 11:26:41,855\tINFO ppo.py:159 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m 2021-09-27 11:26:41,855\tINFO trainer.py:728 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m /root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2021-09-27 11:26:45,427\tERROR trial_runner.py:773 -- Trial PPO_my_env_c7a10_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 739, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 746, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/_private/client_mode_hook.py\", line 82, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/worker.py\", line 1623, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=165, ip=192.168.3.5)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 136, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 592, in __init__\n",
      "    super().__init__(config, logger_creator)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trainable.py\", line 103, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 146, in setup\n",
      "    super().setup(config)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 739, in setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 175, in _init\n",
      "    num_workers=self.config[\"num_workers\"])\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 827, in _make_workers\n",
      "    logdir=self.logdir)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 85, in __init__\n",
      "    lambda p, pid: (pid, p.observation_space, p.action_space)))\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=169, ip=192.168.3.5)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 584, in __init__\n",
      "    seed=seed)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1376, in _build_policy_map\n",
      "    conf, merged_conf)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/policy_map.py\", line 137, in create_policy\n",
      "    merged_config)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/policy_template.py\", line 281, in __init__\n",
      "    stats_fn=stats_fn,\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/policy.py\", line 751, in _initialize_loss_from_dummy_batch\n",
      "    self._dummy_batch, explore=False)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/torch_policy.py\", line 300, in compute_actions_from_input_dict\n",
      "    seq_lens, explore, timestep)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/utils/threading.py\", line 21, in wrapper\n",
      "    return func(self, *a, **k)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/torch_policy.py\", line 364, in _compute_action_helper\n",
      "    seq_lens)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/modelv2.py\", line 230, in __call__\n",
      "    res = self.forward(restored, state or [], seq_lens)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 208, in forward\n",
      "    return super().forward(input_dict, state, seq_lens)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 83, in forward\n",
      "    output, new_state = self.forward_rnn(inputs, state, seq_lens)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 225, in forward_rnn\n",
      "    torch.unsqueeze(state[1], 0)])\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 677, in forward\n",
      "    self.check_forward_args(input, hx, batch_sizes)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 620, in check_forward_args\n",
      "    self.check_input(input, batch_sizes)\n",
      "  File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 207, in check_input\n",
      "    self.input_size, input.size(-1)))\n",
      "RuntimeError: input.size(-1) must be equal to input_size. Expected 12288, got 64\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m 2021-09-27 11:26:45,420\tERROR worker.py:428 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=165, ip=192.168.3.5)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 136, in __init__\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     Trainer.__init__(self, config, env, logger_creator)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 592, in __init__\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     super().__init__(config, logger_creator)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/trainable.py\", line 103, in __init__\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 146, in setup\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     super().setup(config)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 739, in setup\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     self._init(self.config, self.env_creator)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py\", line 175, in _init\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     num_workers=self.config[\"num_workers\"])\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/agents/trainer.py\", line 827, in _make_workers\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     logdir=self.logdir)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py\", line 85, in __init__\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     lambda p, pid: (pid, p.observation_space, p.action_space)))\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=169, ip=192.168.3.5)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 584, in __init__\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     seed=seed)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1376, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     conf, merged_conf)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/policy_map.py\", line 137, in create_policy\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     merged_config)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/policy_template.py\", line 281, in __init__\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     stats_fn=stats_fn,\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/policy.py\", line 751, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     self._dummy_batch, explore=False)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/torch_policy.py\", line 300, in compute_actions_from_input_dict\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     seq_lens, explore, timestep)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/utils/threading.py\", line 21, in wrapper\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     return func(self, *a, **k)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/torch_policy.py\", line 364, in _compute_action_helper\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     seq_lens)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/modelv2.py\", line 230, in __call__\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     res = self.forward(restored, state or [], seq_lens)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 208, in forward\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     return super().forward(input_dict, state, seq_lens)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 83, in forward\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     output, new_state = self.forward_rnn(inputs, state, seq_lens)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 225, in forward_rnn\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     torch.unsqueeze(state[1], 0)])\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 677, in forward\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 620, in check_forward_args\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     self.check_input(input, batch_sizes)\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 207, in check_input\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m     self.input_size, input.size(-1)))\n",
      "\u001b[2m\u001b[36m(pid=165)\u001b[0m RuntimeError: input.size(-1) must be equal to input_size. Expected 12288, got 64\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m 2021-09-27 11:26:45,397\tERROR worker.py:428 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=169, ip=192.168.3.5)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 584, in __init__\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     seed=seed)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1376, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     conf, merged_conf)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/policy_map.py\", line 137, in create_policy\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     merged_config)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/policy_template.py\", line 281, in __init__\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     stats_fn=stats_fn,\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/policy.py\", line 751, in _initialize_loss_from_dummy_batch\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     self._dummy_batch, explore=False)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/torch_policy.py\", line 300, in compute_actions_from_input_dict\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     seq_lens, explore, timestep)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/utils/threading.py\", line 21, in wrapper\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     return func(self, *a, **k)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/policy/torch_policy.py\", line 364, in _compute_action_helper\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     seq_lens)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/modelv2.py\", line 230, in __call__\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     res = self.forward(restored, state or [], seq_lens)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 208, in forward\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     return super().forward(input_dict, state, seq_lens)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 83, in forward\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     output, new_state = self.forward_rnn(inputs, state, seq_lens)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/ray/rllib/models/torch/recurrent_net.py\", line 225, in forward_rnn\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     torch.unsqueeze(state[1], 0)])\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     return forward_call(*input, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 677, in forward\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     self.check_forward_args(input, hx, batch_sizes)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 620, in check_forward_args\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     self.check_input(input, batch_sizes)\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m   File \"/root/miniconda/envs/py37/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 207, in check_input\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m     self.input_size, input.size(-1)))\n",
      "\u001b[2m\u001b[36m(pid=169)\u001b[0m RuntimeError: input.size(-1) must be equal to input_size. Expected 12288, got 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_my_env_c7a10_00000:\n",
      "  {}\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 383<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/IGLU-Minecraft/wandb/run-20210927_112639-c7a10_00000/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/IGLU-Minecraft/wandb/run-20210927_112639-c7a10_00000/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">PPO C17 pretrained (AlinaCNN)</strong>: <a href=\"https://wandb.ai/linar/IGLU-Minecraft/runs/c7a10_00000\" target=\"_blank\">https://wandb.ai/linar/IGLU-Minecraft/runs/c7a10_00000</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 3.6/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/8.87 GiB heap, 0.0/4.44 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/PPO_2021-09-27_11-26-38<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c7a10_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c7a10_00000</td><td style=\"text-align: right;\">           1</td><td>/root/ray_results/PPO_2021-09-27_11-26-38/PPO_my_env_c7a10_00000_0_2021-09-27_11-26-38/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 3.6/15.6 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/8.87 GiB heap, 0.0/4.44 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /root/ray_results/PPO_2021-09-27_11-26-38<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c7a10_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_my_env_c7a10_00000</td><td style=\"text-align: right;\">           1</td><td>/root/ray_results/PPO_2021-09-27_11-26-38/PPO_my_env_c7a10_00000_0_2021-09-27_11-26-38/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PPO_my_env_c7a10_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56/3276268976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         },\n\u001b[0;32m---> 32\u001b[0;31m         loggers=[WandbLogger])\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/py37/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [PPO_my_env_c7a10_00000])"
     ]
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "tune.run(PPOTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 1,\n",
    "             \"sgd_minibatch_size\": 256,\n",
    "             \"clip_param\": 0.2,\n",
    "             \"entropy_coeff\": 0.01,\n",
    "             \"lambda\": 0.95,\n",
    "             \"train_batch_size\": 1000,\n",
    "             \"model\": {\n",
    "                     # Auto-wrap the custom(!) model with an LSTM.\n",
    "                    \"use_lstm\": True,\n",
    "                    # To further customize the LSTM auto-wrapper.\n",
    "                    \"lstm_cell_size\": 64,\n",
    "                    # Specify our custom model from above.\n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"PPO C17 pretrained (AlinaCNN)\"\n",
    "                  }\n",
    "              }\n",
    "\n",
    "        },\n",
    "        loggers=[WandbLogger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.GRU(64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9fecb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24960"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in rnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e60675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = VisualEncoder()\n",
    "sum(p.numel() for p in net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73263eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
