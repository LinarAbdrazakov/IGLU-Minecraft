{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d79e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda/envs/py37/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents import ppo\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.utils.annotations import override\n",
    "\n",
    "#from models import VisualEncoder\n",
    "from train import *\n",
    "from wrappers_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9fd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, stride=2, padding=0),  \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(), \n",
    "            nn.Conv2d(128, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=2, stride=2, padding=0),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7deb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "class MyModelClass(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "        visual_features_dim = 512\n",
    "        target_features_dim = 9 * 11 * 11 \n",
    "        self.visual_encoder = VisualEncoder()\n",
    "        self.visual_encoder.load_state_dict(\n",
    "            torch.load(\"/IGLU-Minecraft/models/AngelaCNN/encoder_weigths.pth\", map_location=torch.device('cpu'))\n",
    "        )\n",
    "        self.target_encoder = nn.Sequential(\n",
    "            nn.Conv3d(7, 1, kernel_size=1, stride=1, padding=0),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        policy_hidden_dim = 256 \n",
    "        self.policy_network = nn.Sequential(\n",
    "            nn.Linear(visual_features_dim + target_features_dim, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(512, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            nn.ELU(),\n",
    "            #nn.Linear(policy_hidden_dim, policy_hidden_dim),\n",
    "            #nn.ELU(),\n",
    "        )\n",
    "        self.qvalue_head = nn.Linear(policy_hidden_dim, num_outputs)\n",
    "        \n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if self.use_cuda:\n",
    "            self.visual_encoder.cuda()\n",
    "            self.target_encoder.cuda()\n",
    "            self.policy_network.cuda()\n",
    "            self.qvalue_head.cuda()\n",
    "        \n",
    "    @override(TorchModelV2)\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        obs = input_dict['obs']\n",
    "        pov = obs['pov'].permute(0, 3, 1, 2).float() / 255.0\n",
    "        target = one_hot(obs['target_grid'].long(), num_classes=7).permute(0, 4, 1, 2, 3).float()\n",
    "        if self.use_cuda:\n",
    "            pov.cuda()\n",
    "            target.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            visual_features = self.visual_encoder(pov)\n",
    "            \n",
    "        target_features = self.target_encoder(target)\n",
    "        target_features = target_features.reshape(target_features.shape[0], -1)\n",
    "        features = torch.cat([visual_features, target_features], dim=1)\n",
    "        features = self.policy_network(features)\n",
    "        qvalues = self.qvalue_head(features)\n",
    "        return qvalues, state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelCatalog.register_custom_model(\"my_torch_model\", MyModelClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc09c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualObservationWrapper(ObsWrapper):\n",
    "    def __init__(self, env, include_target=False):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = {   \n",
    "            'pov': gym.spaces.Box(low=0, high=255, shape=(64, 64, 3)),\n",
    "            'inventory': gym.spaces.Box(low=0.0, high=20.0, shape=(6,)),\n",
    "            'compass': gym.spaces.Box(low=-180.0, high=180.0, shape=(1,))\n",
    "        }\n",
    "        if include_target:\n",
    "            self.observation_space['target_grid'] = \\\n",
    "                gym.spaces.Box(low=0, high=6, shape=(9, 11, 11))\n",
    "        self.observation_space = gym.spaces.Dict(self.observation_space)\n",
    "\n",
    "    def observation(self, obs, reward=None, done=None, info=None):\n",
    "        if info is not None:\n",
    "            if 'target_grid' in info:\n",
    "                target_grid = info['target_grid']\n",
    "                del info['target_grid']\n",
    "            else:\n",
    "                logger.error(f'info: {info}')\n",
    "                if hasattr(self.unwrapped, 'should_reset'):\n",
    "                    self.unwrapped.should_reset(True)\n",
    "                target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        else:\n",
    "            target_grid = self.env.unwrapped.tasks.current.target_grid\n",
    "        return {\n",
    "            'pov': obs['pov'].astype(np.float32),\n",
    "            'inventory': obs['inventory'],\n",
    "            'compass': np.array([obs['compass']['angle'].item()]),\n",
    "            'target_grid': target_grid\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b86a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "class RewardWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, rew):\n",
    "        if rew == 0:\n",
    "            rew = -0.01\n",
    "        if abs(rew) == 1:\n",
    "            rew /= 10\n",
    "        return rew\n",
    "    \n",
    "def env_creator(env_config):\n",
    "    env = gym.make('IGLUSilentBuilder-v0', max_steps=250)\n",
    "    env.update_taskset(TaskSet(preset=['C3', 'C17', 'C32', 'C8']))\n",
    "    #env = PovOnlyWrapper(env)\n",
    "    env = VisualObservationWrapper(env, include_target=True)\n",
    "    env = SelectAndPlace(env)\n",
    "    env = Discretization(env, flat_action_space('human-level'))\n",
    "    env = RewardWrapper(env)\n",
    "    return env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "register_env(\"my_env\", env_creator)\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.agents.dqn import ApexTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0adede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 20:57:44,941\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #2...\n",
      "2021-11-13 20:57:45,443\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #3...\n",
      "2021-11-13 20:57:45,945\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #4...\n",
      "2021-11-13 20:57:46,447\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #5...\n",
      "2021-11-13 20:57:46,950\tWARNING ray_trial_executor.py:818 -- Cluster resources cannot be detected or are 0. You can resume this experiment by passing in `resume=True` to `run`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/0 CPUs, 0/0 GPUs, 0.0/0.0 GiB heap, 0.0/0.0 GiB objects<br>Result logdir: /root/ray_results/APEX_2021-11-13_20-57-46<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_5ad0b_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/0 CPUs, 0/0 GPUs, 0.0/0.0 GiB heap, 0.0/0.0 GiB objects<br>Result logdir: /root/ray_results/APEX_2021-11-13_20-57-46<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_5ad0b_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 20:57:56,951\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #2...\n",
      "2021-11-13 20:57:57,453\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #3...\n",
      "2021-11-13 20:57:57,956\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #4...\n",
      "2021-11-13 20:57:58,457\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #5...\n",
      "2021-11-13 20:57:58,960\tWARNING ray_trial_executor.py:818 -- Cluster resources cannot be detected or are 0. You can resume this experiment by passing in `resume=True` to `run`.\n",
      "2021-11-13 20:57:58,962\tWARNING util.py:164 -- The `on_step_begin` operation took 2.011 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/0 CPUs, 0/0 GPUs, 0.0/0.0 GiB heap, 0.0/0.0 GiB objects<br>Result logdir: /root/ray_results/APEX_2021-11-13_20-57-46<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_5ad0b_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/0 CPUs, 0/0 GPUs, 0.0/0.0 GiB heap, 0.0/0.0 GiB objects<br>Result logdir: /root/ray_results/APEX_2021-11-13_20-57-46<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_5ad0b_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 20:58:08,962\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #2...\n",
      "2021-11-13 20:58:09,464\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #3...\n",
      "2021-11-13 20:58:09,967\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #4...\n",
      "2021-11-13 20:58:10,469\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #5...\n",
      "2021-11-13 20:58:10,971\tWARNING ray_trial_executor.py:818 -- Cluster resources cannot be detected or are 0. You can resume this experiment by passing in `resume=True` to `run`.\n",
      "2021-11-13 20:58:10,971\tWARNING util.py:164 -- The `on_step_begin` operation took 2.010 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/0 CPUs, 0/0 GPUs, 0.0/0.0 GiB heap, 0.0/0.0 GiB objects<br>Result logdir: /root/ray_results/APEX_2021-11-13_20-57-46<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_5ad0b_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/0 CPUs, 0/0 GPUs, 0.0/0.0 GiB heap, 0.0/0.0 GiB objects<br>Result logdir: /root/ray_results/APEX_2021-11-13_20-57-46<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_5ad0b_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 20:58:20,973\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #2...\n",
      "2021-11-13 20:58:21,474\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #3...\n",
      "2021-11-13 20:58:21,976\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #4...\n",
      "2021-11-13 20:58:22,480\tWARNING ray_trial_executor.py:801 -- Cluster resources not detected or are 0. Attempt #5...\n",
      "2021-11-13 20:58:22,981\tWARNING ray_trial_executor.py:818 -- Cluster resources cannot be detected or are 0. You can resume this experiment by passing in `resume=True` to `run`.\n",
      "2021-11-13 20:58:22,982\tWARNING util.py:164 -- The `on_step_begin` operation took 2.010 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.7/47.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/0 CPUs, 0/0 GPUs, 0.0/0.0 GiB heap, 0.0/0.0 GiB objects<br>Result logdir: /root/ray_results/APEX_2021-11-13_20-57-46<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>APEX_my_env_5ad0b_00000</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune.integration.wandb import WandbLogger\n",
    "\n",
    "analysis = tune.run(ApexTrainer, \n",
    "         config={\n",
    "             \"env\": \"my_env\", \n",
    "             \"framework\": \"torch\",\n",
    "             #\"gamma\": 0.99,\n",
    "             \"num_gpus\": 1,\n",
    "             \"num_workers\": 2,\n",
    "             \"buffer_size\": 50_000,\n",
    "             \"learning_starts\": 2_000,\n",
    "             \"train_batch_size\": 1000,\n",
    "             \"target_network_update_freq\": 2000,\n",
    "             #\"prioritized_replay_alpha\": 0.5,\n",
    "             #\"final_prioritized_replay_beta\": 1.0,\n",
    "             \"min_iter_time_s\": 30, \n",
    "             \"rollout_fragment_length\": 4,\n",
    "             \"collect_metrics_timeout\": 1800,\n",
    "             \n",
    "             \"v_min\": -10.0,\n",
    "             \"v_max\": 100.0,\n",
    "             \n",
    "             \"exploration_config\": {\n",
    "                  \"initial_epsilon\": 1,\n",
    "                  \"epsilon_timesteps\": 50_000,\n",
    "                  \"final_epsilon\": 0.05,\n",
    "              },\n",
    "             \"model\": {\n",
    "                    # Specify our custom model from above.\n",
    "                 \n",
    "                    \"custom_model\": \"my_torch_model\",\n",
    "                    # Extra kwargs to be passed to your model's c'tor.\n",
    "                    \"custom_model_config\": {},\n",
    "              },\n",
    "             \"logger_config\": {\n",
    "                  \"wandb\": {\n",
    "                      \"project\": \"IGLU-Minecraft\",\n",
    "                      \"name\": \"APEX MultiTask (C3, C17, C32, C8) pretrained (AngelaCNN) (3 noops after placement) r: -0.01 div10\"\n",
    "                  }\n",
    "              },\n",
    "              #\"training_intensity\": 50,\n",
    "              \"lr\": 1e-5,\n",
    "             \n",
    "              \"evaluation_num_workers\": 1,\n",
    "              \"evaluation_interval\": 1,\n",
    "              \"evaluation_num_episodes\": 1,\n",
    "              \"evaluation_config\": {\n",
    "                  #\"input\": \"sampler\",\n",
    "                  \"explore\": False,  \n",
    "              },\n",
    "        },\n",
    "        #loggers=[WandbLogger],\n",
    "        #local_dir=\"/IGLU-Minecraft/checkpoints/4_tasks\",\n",
    "        #keep_checkpoints_num=50,\n",
    "        #checkpoint_freq=5,\n",
    "        #checkpoint_at_end=True,\n",
    "        #restore=\"/IGLU-Minecraft/checkpoints/4_tasks/PPO_2021-11-08_20-28-45/PPO_my_env_78cf0_00000_0_2021-11-08_20-28-45/checkpoint_000050/checkpoint-50\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967c7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a7d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
